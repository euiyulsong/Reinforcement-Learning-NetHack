[2022-06-09 13:40:28,822][root][INFO] - name: null
wandb: false
project: nethack_challenge
entity: user1
group: group1
mock: false
single_ttyrec: true
num_seeds: 0
write_profiler_trace: false
fn_penalty_step: constant
penalty_time: 0.0
penalty_step: -0.01
reward_lose: 0
reward_win: 100
state_counter: none
character: mon-hum-neu-mal
mode: train
env: challenge
num_actors: 256
total_steps: 500000000.0
batch_size: 64
unroll_length: 80
num_learner_threads: 1
num_inference_threads: 1
disable_cuda: false
learner_device: cuda:1
actor_device: cuda:3
learning_rate: 0.0002
grad_norm_clipping: 40
alpha: 0.99
momentum: 0
epsilon: 1.0e-06
entropy_cost: 0.001
baseline_cost: 0.5
discounting: 0.999
normalize_reward: true
model: baseline
use_lstm: true
hidden_dim: 256
embedding_dim: 64
layers: 5
crop_dim: 9
use_index_select: true
restrict_action_space: true
msg:
  hidden_dim: 64
  embedding_dim: 32
load_dir: null

[2022-06-09 13:40:28,836][root][INFO] - Symlinked log directory: /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/latest
[2022-06-09 13:40:28,840][root][INFO] - Creating archive directory: /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/archives
[2022-06-09 13:40:28,840][root][INFO] - Logging results to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28
[2022-06-09 13:40:28,895][palaas/out][INFO] - Found log directory: /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28
[2022-06-09 13:40:28,895][palaas/out][INFO] - Saving arguments to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/meta.json
[2022-06-09 13:40:28,896][palaas/out][INFO] - Saving messages to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/out.log
[2022-06-09 13:40:28,896][palaas/out][INFO] - Saving logs data to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/logs.csv
[2022-06-09 13:40:28,897][palaas/out][INFO] - Saving logs' fields to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/fields.csv
[2022-06-09 13:40:28,934][root][INFO] - Using CUDA.
[2022-06-09 13:40:28,982][root][INFO] - Using model baseline
[2022-06-09 13:40:28,982][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:33,252][root][INFO] - Number of model parameters: 12330098
[2022-06-09 13:40:33,253][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,070][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,070][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,071][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,071][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,071][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,071][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,072][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,072][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,072][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,072][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,072][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,072][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,072][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,074][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,075][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,076][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,076][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,076][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,076][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,078][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,079][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,079][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,080][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,080][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,081][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,084][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,084][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,085][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,085][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,085][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,085][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,085][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,085][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,085][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,085][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,085][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,086][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,086][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,086][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,086][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,086][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,087][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,087][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,087][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,087][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,086][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,085][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,095][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,095][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,095][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,095][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,095][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,095][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,095][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,095][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,095][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,095][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,096][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,096][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,101][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,107][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,115][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,119][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,119][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,127][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,144][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,144][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,144][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,145][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,145][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,145][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,145][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,145][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,145][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,146][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,146][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,146][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,146][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,146][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,147][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,147][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,147][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,149][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,150][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,150][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,150][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,144][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,157][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,157][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,157][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,158][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,158][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,158][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,158][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,159][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,159][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,184][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,180][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,185][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,185][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,185][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,185][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,180][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,186][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,186][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,185][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,180][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,187][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,184][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,180][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,180][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,190][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,190][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,180][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,190][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,191][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,185][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,190][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,191][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,191][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,191][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,188][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,180][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,192][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,182][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,180][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,192][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,192][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,192][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,192][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,192][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,193][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,193][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,193][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,193][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,193][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,190][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,180][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,190][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,197][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,180][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,197][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,180][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,180][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,180][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,197][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,198][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,198][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,180][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,193][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,193][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,180][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,180][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,196][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,199][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,180][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,180][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,180][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,199][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,180][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,180][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,180][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,180][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,181][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,182][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,180][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,182][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,182][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,180][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,180][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,181][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,182][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,182][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,182][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,181][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,182][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,182][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,182][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,182][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,182][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,183][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,183][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,183][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,183][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,183][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,182][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,183][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,182][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,183][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,184][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,183][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,184][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,184][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,185][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,186][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,187][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,185][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,187][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,185][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,185][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,187][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,188][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,188][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,188][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,189][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,182][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,182][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,187][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,219][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,219][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,182][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,183][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,188][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,185][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,189][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,189][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,189][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,189][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,183][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,183][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,189][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,189][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,189][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,189][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,189][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,189][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,183][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,184][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,184][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,185][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,186][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,188][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,188][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,185][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,188][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,188][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,187][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,188][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,192][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,192][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,190][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,194][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,193][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,194][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,194][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,194][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,185][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,189][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,195][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,195][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,195][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,196][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,195][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,196][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,196][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:37,239][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 13:40:42,066][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 5.0)
[2022-06-09 13:40:42,157][palaas/out][INFO] - Updated log fields: ['_tick', '_time', 'train_seconds', 'step', 'mean_episode_return', 'mean_episode_step', 'total_loss', 'pg_loss', 'baseline_loss', 'entropy_loss', 'learner_queue_size']
[2022-06-09 13:40:47,070][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint_0.tar
[2022-06-09 13:40:47,537][root][INFO] - Step 15360 @ 3069.6 SPS. Inference batcher size: 23. Learner queue size: 33. Other stats: (train_seconds = 10.0, step = 20480, mean_episode_return = -0.23, mean_episode_step = 68.988, total_loss = 26.353, pg_loss = 27.852, baseline_loss = 15.829, entropy_loss = -17.328, learner_queue_size = 64, _tick = 2, _time = 1.6547e+09)
[2022-06-09 13:40:52,542][root][INFO] - Step 30720 @ 2807.0 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 15.5, step = 30720, mean_episode_return = None, mean_episode_step = 129.25, total_loss = -62.287, pg_loss = -48.971, baseline_loss = 6.0982, entropy_loss = -19.413, learner_queue_size = 64, _tick = 2, _time = 1.6547e+09)
[2022-06-09 13:40:57,546][root][INFO] - Step 46080 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 20.5, step = 46080, mean_episode_return = None, mean_episode_step = 183.98, total_loss = -81.467, pg_loss = -66.198, baseline_loss = 4.51, entropy_loss = -19.778, learner_queue_size = 64, _tick = 4, _time = 1.6547e+09)
[2022-06-09 13:41:02,552][root][INFO] - Step 61440 @ 3068.1 SPS. Inference batcher size: 7. Learner queue size: 64. Other stats: (train_seconds = 25.5, step = 61440, mean_episode_return = None, mean_episode_step = 240.72, total_loss = -39.921, pg_loss = -24.789, baseline_loss = 3.6053, entropy_loss = -18.737, learner_queue_size = 64, _tick = 6, _time = 1.6547e+09)
[2022-06-09 13:41:07,558][root][INFO] - Step 76800 @ 3068.6 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 30.5, step = 76800, mean_episode_return = None, mean_episode_step = 314.25, total_loss = -60.94, pg_loss = -44.586, baseline_loss = 2.663, entropy_loss = -19.018, learner_queue_size = 64, _tick = 7, _time = 1.6547e+09)
[2022-06-09 13:41:12,560][root][INFO] - Step 92160 @ 3070.6 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 35.5, step = 92160, mean_episode_return = -2.0775, mean_episode_step = 334.9, total_loss = 63.276, pg_loss = 71.04, baseline_loss = 11.489, entropy_loss = -19.254, learner_queue_size = 64, _tick = 8, _time = 1.6547e+09)
[2022-06-09 13:41:17,566][root][INFO] - Step 102400 @ 2045.7 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 40.5, step = 102400, mean_episode_return = -2.33, mean_episode_step = 391.24, total_loss = -14.124, pg_loss = 0.13458, baseline_loss = 4.9468, entropy_loss = -19.206, learner_queue_size = 64, _tick = 9, _time = 1.6547e+09)
[2022-06-09 13:41:22,570][root][INFO] - Step 117760 @ 3069.5 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 45.5, step = 117760, mean_episode_return = -4.2433, mean_episode_step = 431.76, total_loss = 0.40264, pg_loss = 17.792, baseline_loss = 3.3713, entropy_loss = -20.76, learner_queue_size = 64, _tick = 11, _time = 1.6547e+09)
[2022-06-09 13:41:27,574][root][INFO] - Step 128000 @ 2046.3 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 50.5, step = 128000, mean_episode_return = -4.72, mean_episode_step = 511.41, total_loss = 60.029, pg_loss = 74.111, baseline_loss = 6.0347, entropy_loss = -20.116, learner_queue_size = 64, _tick = 13, _time = 1.6547e+09)
[2022-06-09 13:41:32,578][root][INFO] - Step 143360 @ 3069.6 SPS. Inference batcher size: 68. Learner queue size: 64. Other stats: (train_seconds = 55.5, step = 143360, mean_episode_return = None, mean_episode_step = 522.33, total_loss = -98.492, pg_loss = -79.214, baseline_loss = 1.1767, entropy_loss = -20.454, learner_queue_size = 64, _tick = 15, _time = 1.6547e+09)
[2022-06-09 13:41:37,582][root][INFO] - Step 153600 @ 2046.4 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 60.5, step = 153600, mean_episode_return = -4.58, mean_episode_step = 559.44, total_loss = -44.927, pg_loss = -26.686, baseline_loss = 2.6889, entropy_loss = -20.93, learner_queue_size = 64, _tick = 17, _time = 1.6547e+09)
[2022-06-09 13:41:42,586][root][INFO] - Step 168960 @ 3069.6 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 65.5, step = 168960, mean_episode_return = -4.34, mean_episode_step = 650.65, total_loss = 139.89, pg_loss = 137.17, baseline_loss = 24.008, entropy_loss = -21.29, learner_queue_size = 64, _tick = 19, _time = 1.6547e+09)
[2022-06-09 13:41:47,590][root][INFO] - Step 184320 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 70.5, step = 184320, mean_episode_return = -8.2901, mean_episode_step = 697.12, total_loss = 46.731, pg_loss = 64.547, baseline_loss = 3.4878, entropy_loss = -21.303, learner_queue_size = 64, _tick = 20, _time = 1.6547e+09)
[2022-06-09 13:41:52,594][root][INFO] - Step 199680 @ 3069.5 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 75.5, step = 199680, mean_episode_return = -7.1201, mean_episode_step = 733.02, total_loss = -65.924, pg_loss = -48.111, baseline_loss = 3.1788, entropy_loss = -20.991, learner_queue_size = 64, _tick = 22, _time = 1.6547e+09)
[2022-06-09 13:41:57,598][root][INFO] - Step 215040 @ 3069.6 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 80.5, step = 215040, mean_episode_return = -7.2001, mean_episode_step = 800.74, total_loss = -33.203, pg_loss = -15.133, baseline_loss = 2.1892, entropy_loss = -20.26, learner_queue_size = 64, _tick = 24, _time = 1.6547e+09)
[2022-06-09 13:42:02,602][root][INFO] - Step 230400 @ 3069.5 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 85.5, step = 230400, mean_episode_return = -8.0935, mean_episode_step = 858.31, total_loss = 132.21, pg_loss = 142.57, baseline_loss = 10.41, entropy_loss = -20.764, learner_queue_size = 64, _tick = 26, _time = 1.6547e+09)
[2022-06-09 13:42:07,607][root][INFO] - Step 245760 @ 3068.8 SPS. Inference batcher size: 4. Learner queue size: 64. Other stats: (train_seconds = 90.5, step = 245760, mean_episode_return = -11.15, mean_episode_step = 848.0, total_loss = 28.315, pg_loss = 46.072, baseline_loss = 2.8918, entropy_loss = -20.649, learner_queue_size = 64, _tick = 29, _time = 1.6547e+09)
[2022-06-09 13:42:12,610][root][INFO] - Step 256000 @ 2046.8 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 95.5, step = 256000, mean_episode_return = None, mean_episode_step = 923.62, total_loss = 6.4869, pg_loss = 18.085, baseline_loss = 9.1515, entropy_loss = -20.749, learner_queue_size = 64, _tick = 30, _time = 1.6547e+09)
[2022-06-09 13:42:17,614][root][INFO] - Step 271360 @ 3069.6 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 100.5, step = 271360, mean_episode_return = -5.7201, mean_episode_step = 953.09, total_loss = -20.67, pg_loss = -5.1332, baseline_loss = 5.2703, entropy_loss = -20.807, learner_queue_size = 64, _tick = 32, _time = 1.6547e+09)
[2022-06-09 13:42:22,618][root][INFO] - Step 286720 @ 3069.5 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 105.6, step = 286720, mean_episode_return = None, mean_episode_step = 1035.5, total_loss = 192.75, pg_loss = 181.71, baseline_loss = 31.707, entropy_loss = -20.666, learner_queue_size = 64, _tick = 32, _time = 1.6547e+09)
[2022-06-09 13:42:27,622][root][INFO] - Step 302080 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 110.6, step = 302080, mean_episode_return = None, mean_episode_step = 1064.3, total_loss = -155.37, pg_loss = -135.46, baseline_loss = 0.82423, entropy_loss = -20.736, learner_queue_size = 64, _tick = 34, _time = 1.6547e+09)
[2022-06-09 13:42:32,626][root][INFO] - Step 317440 @ 3069.6 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 115.6, step = 317440, mean_episode_return = None, mean_episode_step = 1073.2, total_loss = -13.215, pg_loss = 6.0579, baseline_loss = 1.6956, entropy_loss = -20.968, learner_queue_size = 64, _tick = 35, _time = 1.6547e+09)
[2022-06-09 13:42:37,630][root][INFO] - Step 332800 @ 3069.5 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 120.6, step = 332800, mean_episode_return = -1.17, mean_episode_step = 1134.5, total_loss = -86.682, pg_loss = -67.36, baseline_loss = 1.9612, entropy_loss = -21.284, learner_queue_size = 64, _tick = 38, _time = 1.6547e+09)
[2022-06-09 13:42:42,634][root][INFO] - Step 348160 @ 3069.5 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 125.6, step = 348160, mean_episode_return = -12.48, mean_episode_step = 1255.5, total_loss = 39.422, pg_loss = 56.052, baseline_loss = 4.3079, entropy_loss = -20.938, learner_queue_size = 64, _tick = 40, _time = 1.6547e+09)
[2022-06-09 13:42:47,638][root][INFO] - Step 358400 @ 2046.4 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 130.6, step = 358400, mean_episode_return = None, mean_episode_step = 1248.2, total_loss = -113.47, pg_loss = -93.706, baseline_loss = 1.2146, entropy_loss = -20.979, learner_queue_size = 64, _tick = 41, _time = 1.6547e+09)
[2022-06-09 13:42:52,642][root][INFO] - Step 373760 @ 3069.6 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 135.6, step = 373760, mean_episode_return = None, mean_episode_step = 1277.3, total_loss = -40.236, pg_loss = -19.871, baseline_loss = 0.78148, entropy_loss = -21.146, learner_queue_size = 64, _tick = 41, _time = 1.6547e+09)
[2022-06-09 13:42:57,646][root][INFO] - Step 389120 @ 3069.5 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 140.6, step = 389120, mean_episode_return = None, mean_episode_step = 1315.9, total_loss = -35.793, pg_loss = -15.256, baseline_loss = 0.67106, entropy_loss = -21.208, learner_queue_size = 64, _tick = 42, _time = 1.6547e+09)
[2022-06-09 13:43:02,650][root][INFO] - Step 404480 @ 3069.6 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 145.6, step = 404480, mean_episode_return = -13.6, mean_episode_step = 1383.3, total_loss = -35.297, pg_loss = -15.826, baseline_loss = 1.5163, entropy_loss = -20.988, learner_queue_size = 64, _tick = 43, _time = 1.6547e+09)
[2022-06-09 13:43:07,654][root][INFO] - Step 419840 @ 3069.5 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 150.6, step = 419840, mean_episode_return = -15.06, mean_episode_step = 1479.4, total_loss = -17.952, pg_loss = -0.81185, baseline_loss = 4.0043, entropy_loss = -21.144, learner_queue_size = 64, _tick = 45, _time = 1.6547e+09)
[2022-06-09 13:43:12,658][root][INFO] - Step 435200 @ 3069.5 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 155.6, step = 435200, mean_episode_return = None, mean_episode_step = 1439.6, total_loss = -3.3243, pg_loss = 16.16, baseline_loss = 1.9143, entropy_loss = -21.398, learner_queue_size = 64, _tick = 46, _time = 1.6547e+09)
[2022-06-09 13:43:17,662][root][INFO] - Step 445440 @ 2046.4 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 160.6, step = 445440, mean_episode_return = None, mean_episode_step = 1667.8, total_loss = -92.282, pg_loss = -71.965, baseline_loss = 0.78112, entropy_loss = -21.098, learner_queue_size = 64, _tick = 47, _time = 1.6547e+09)
[2022-06-09 13:43:22,666][root][INFO] - Step 460800 @ 3069.4 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 165.6, step = 460800, mean_episode_return = None, mean_episode_step = 1666.0, total_loss = 299.69, pg_loss = 253.62, baseline_loss = 67.3, entropy_loss = -21.229, learner_queue_size = 64, _tick = 48, _time = 1.6547e+09)
[2022-06-09 13:43:27,670][root][INFO] - Step 476160 @ 3069.7 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 170.6, step = 476160, mean_episode_return = -16.73, mean_episode_step = 1621.6, total_loss = -72.953, pg_loss = -54.933, baseline_loss = 3.2164, entropy_loss = -21.237, learner_queue_size = 64, _tick = 50, _time = 1.6547e+09)
[2022-06-09 13:43:32,674][root][INFO] - Step 491520 @ 3069.3 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 175.6, step = 491520, mean_episode_return = None, mean_episode_step = 1664.6, total_loss = -3.2164, pg_loss = 16.357, baseline_loss = 1.6334, entropy_loss = -21.206, learner_queue_size = 64, _tick = 51, _time = 1.6547e+09)
[2022-06-09 13:43:37,678][root][INFO] - Step 506880 @ 3069.4 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 180.6, step = 506880, mean_episode_return = None, mean_episode_step = 1757.7, total_loss = -31.445, pg_loss = -13.584, baseline_loss = 3.1842, entropy_loss = -21.044, learner_queue_size = 64, _tick = 52, _time = 1.6547e+09)
[2022-06-09 13:43:42,683][root][INFO] - Step 522240 @ 3069.4 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 185.6, step = 522240, mean_episode_return = None, mean_episode_step = 1851.2, total_loss = -80.704, pg_loss = -61.404, baseline_loss = 1.3555, entropy_loss = -20.656, learner_queue_size = 64, _tick = 53, _time = 1.6547e+09)
[2022-06-09 13:43:47,686][root][INFO] - Step 532480 @ 2046.7 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 190.6, step = 532480, mean_episode_return = -20.44, mean_episode_step = 1763.1, total_loss = 153.78, pg_loss = 156.81, baseline_loss = 17.923, entropy_loss = -20.958, learner_queue_size = 64, _tick = 54, _time = 1.6547e+09)
[2022-06-09 13:43:52,690][root][INFO] - Step 547840 @ 3069.6 SPS. Inference batcher size: 4. Learner queue size: 64. Other stats: (train_seconds = 195.6, step = 547840, mean_episode_return = None, mean_episode_step = 1853.9, total_loss = 601.15, pg_loss = 447.86, baseline_loss = 173.98, entropy_loss = -20.693, learner_queue_size = 64, _tick = 55, _time = 1.6547e+09)
[2022-06-09 13:43:57,694][root][INFO] - Step 563200 @ 3069.6 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 200.6, step = 563200, mean_episode_return = None, mean_episode_step = 2007.3, total_loss = -98.99, pg_loss = -79.122, baseline_loss = 0.70945, entropy_loss = -20.578, learner_queue_size = 64, _tick = 55, _time = 1.6547e+09)
[2022-06-09 13:44:02,698][root][INFO] - Step 578560 @ 3069.6 SPS. Inference batcher size: 13. Learner queue size: 64. Other stats: (train_seconds = 205.6, step = 578560, mean_episode_return = None, mean_episode_step = 2019.1, total_loss = -52.402, pg_loss = -32.158, baseline_loss = 0.46886, entropy_loss = -20.712, learner_queue_size = 64, _tick = 55, _time = 1.6547e+09)
[2022-06-09 13:44:07,702][root][INFO] - Step 593920 @ 3069.5 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 210.6, step = 593920, mean_episode_return = -18.94, mean_episode_step = 2109.0, total_loss = 73.161, pg_loss = 82.7, baseline_loss = 11.469, entropy_loss = -21.009, learner_queue_size = 64, _tick = 57, _time = 1.6547e+09)
[2022-06-09 13:44:12,706][root][INFO] - Step 609280 @ 3069.5 SPS. Inference batcher size: 72. Learner queue size: 64. Other stats: (train_seconds = 215.6, step = 609280, mean_episode_return = -10.733, mean_episode_step = 2037.2, total_loss = 88.087, pg_loss = 92.002, baseline_loss = 17.033, entropy_loss = -20.947, learner_queue_size = 64, _tick = 59, _time = 1.6547e+09)
[2022-06-09 13:44:17,710][root][INFO] - Step 619520 @ 2046.4 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 220.6, step = 619520, mean_episode_return = None, mean_episode_step = 2137.9, total_loss = 56.347, pg_loss = 62.795, baseline_loss = 14.815, entropy_loss = -21.263, learner_queue_size = 64, _tick = 59, _time = 1.6547e+09)
[2022-06-09 13:44:22,714][root][INFO] - Step 629760 @ 2046.4 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 225.6, step = 629760, mean_episode_return = -22.84, mean_episode_step = 2129.9, total_loss = -15.673, pg_loss = 2.5772, baseline_loss = 3.0525, entropy_loss = -21.303, learner_queue_size = 64, _tick = 60, _time = 1.6547e+09)
[2022-06-09 13:44:27,718][root][INFO] - Step 645120 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 230.7, step = 645120, mean_episode_return = -32.341, mean_episode_step = 2236.8, total_loss = 84.42, pg_loss = 86.704, baseline_loss = 19.021, entropy_loss = -21.305, learner_queue_size = 64, _tick = 62, _time = 1.6547e+09)
[2022-06-09 13:44:32,722][root][INFO] - Step 660480 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 235.7, step = 660480, mean_episode_return = None, mean_episode_step = 2111.0, total_loss = -167.75, pg_loss = -149.13, baseline_loss = 2.1351, entropy_loss = -20.757, learner_queue_size = 64, _tick = 63, _time = 1.6547e+09)
[2022-06-09 13:44:37,727][root][INFO] - Step 675840 @ 3068.9 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 240.7, step = 675840, mean_episode_return = None, mean_episode_step = 2265.0, total_loss = -47.336, pg_loss = -29.366, baseline_loss = 2.8352, entropy_loss = -20.805, learner_queue_size = 64, _tick = 64, _time = 1.6547e+09)
[2022-06-09 13:44:42,734][root][INFO] - Step 691200 @ 3067.8 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 245.7, step = 691200, mean_episode_return = None, mean_episode_step = 2451.3, total_loss = -27.345, pg_loss = -7.6403, baseline_loss = 1.3281, entropy_loss = -21.032, learner_queue_size = 64, _tick = 64, _time = 1.6547e+09)
[2022-06-09 13:44:47,738][root][INFO] - Step 706560 @ 3069.5 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 250.7, step = 706560, mean_episode_return = -9.2577, mean_episode_step = 2589.2, total_loss = 61.66, pg_loss = 73.515, baseline_loss = 9.2023, entropy_loss = -21.057, learner_queue_size = 64, _tick = 66, _time = 1.6547e+09)
[2022-06-09 13:44:52,742][root][INFO] - Step 721920 @ 3069.6 SPS. Inference batcher size: 72. Learner queue size: 64. Other stats: (train_seconds = 255.7, step = 721920, mean_episode_return = -25.54, mean_episode_step = 2257.1, total_loss = -4.8055, pg_loss = 12.858, baseline_loss = 3.3974, entropy_loss = -21.061, learner_queue_size = 64, _tick = 68, _time = 1.6547e+09)
[2022-06-09 13:44:57,746][root][INFO] - Step 732160 @ 2046.4 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 260.7, step = 732160, mean_episode_return = None, mean_episode_step = 2396.1, total_loss = -44.345, pg_loss = -24.159, baseline_loss = 0.91528, entropy_loss = -21.101, learner_queue_size = 64, _tick = 68, _time = 1.6547e+09)
[2022-06-09 13:45:02,750][root][INFO] - Step 747520 @ 3069.5 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 265.7, step = 747520, mean_episode_return = -23.31, mean_episode_step = 2395.2, total_loss = 453.08, pg_loss = 395.68, baseline_loss = 78.518, entropy_loss = -21.114, learner_queue_size = 64, _tick = 70, _time = 1.6547e+09)
[2022-06-09 13:45:07,755][root][INFO] - Step 762880 @ 3068.9 SPS. Inference batcher size: 79. Learner queue size: 64. Other stats: (train_seconds = 270.7, step = 762880, mean_episode_return = None, mean_episode_step = 2508.7, total_loss = 189.28, pg_loss = 190.74, baseline_loss = 19.685, entropy_loss = -21.145, learner_queue_size = 64, _tick = 71, _time = 1.6547e+09)
[2022-06-09 13:45:12,758][root][INFO] - Step 773120 @ 2046.8 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 275.7, step = 773120, mean_episode_return = None, mean_episode_step = 2544.2, total_loss = -99.141, pg_loss = -81.967, baseline_loss = 3.8733, entropy_loss = -21.047, learner_queue_size = 64, _tick = 72, _time = 1.6547e+09)
[2022-06-09 13:45:17,762][root][INFO] - Step 788480 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 280.7, step = 788480, mean_episode_return = -10.117, mean_episode_step = 2489.5, total_loss = 94.873, pg_loss = 107.24, baseline_loss = 8.7988, entropy_loss = -21.163, learner_queue_size = 64, _tick = 74, _time = 1.6547e+09)
[2022-06-09 13:45:22,766][root][INFO] - Step 803840 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 285.7, step = 803840, mean_episode_return = -21.76, mean_episode_step = 2641.1, total_loss = 87.585, pg_loss = 98.345, baseline_loss = 10.292, entropy_loss = -21.051, learner_queue_size = 64, _tick = 76, _time = 1.6547e+09)
[2022-06-09 13:45:27,770][root][INFO] - Step 819200 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 290.7, step = 819200, mean_episode_return = None, mean_episode_step = 2953.5, total_loss = -32.492, pg_loss = -13.392, baseline_loss = 1.9505, entropy_loss = -21.051, learner_queue_size = 64, _tick = 76, _time = 1.6547e+09)
[2022-06-09 13:45:32,774][root][INFO] - Step 834560 @ 3069.6 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 295.7, step = 834560, mean_episode_return = -27.241, mean_episode_step = 2801.9, total_loss = -77.559, pg_loss = -57.671, baseline_loss = 1.0038, entropy_loss = -20.892, learner_queue_size = 64, _tick = 77, _time = 1.6547e+09)
[2022-06-09 13:45:37,778][root][INFO] - Step 849920 @ 3069.5 SPS. Inference batcher size: 110. Learner queue size: 64. Other stats: (train_seconds = 300.7, step = 849920, mean_episode_return = None, mean_episode_step = 2963.9, total_loss = -47.919, pg_loss = -27.379, baseline_loss = 0.29672, entropy_loss = -20.836, learner_queue_size = 64, _tick = 77, _time = 1.6547e+09)
[2022-06-09 13:45:42,782][root][INFO] - Step 865280 @ 3069.6 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 305.7, step = 865280, mean_episode_return = None, mean_episode_step = 2803.7, total_loss = -82.642, pg_loss = -61.961, baseline_loss = 0.2634, entropy_loss = -20.945, learner_queue_size = 64, _tick = 79, _time = 1.6547e+09)
[2022-06-09 13:45:47,786][root][INFO] - Step 875520 @ 2046.4 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 310.7, step = 875520, mean_episode_return = None, mean_episode_step = 2769.8, total_loss = -42.141, pg_loss = -23.697, baseline_loss = 2.4592, entropy_loss = -20.903, learner_queue_size = 64, _tick = 79, _time = 1.6547e+09)
[2022-06-09 13:45:52,790][root][INFO] - Step 890880 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 315.7, step = 890880, mean_episode_return = None, mean_episode_step = 2941.8, total_loss = -23.416, pg_loss = -4.0828, baseline_loss = 1.742, entropy_loss = -21.075, learner_queue_size = 64, _tick = 80, _time = 1.6547e+09)
[2022-06-09 13:45:57,794][root][INFO] - Step 906240 @ 3069.5 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 320.7, step = 906240, mean_episode_return = -10.45, mean_episode_step = 2779.3, total_loss = -32.087, pg_loss = -16.244, baseline_loss = 4.837, entropy_loss = -20.68, learner_queue_size = 64, _tick = 82, _time = 1.6547e+09)
[2022-06-09 13:46:02,798][root][INFO] - Step 921600 @ 3069.5 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 325.7, step = 921600, mean_episode_return = None, mean_episode_step = 3068.7, total_loss = -38.88, pg_loss = -21.068, baseline_loss = 2.6674, entropy_loss = -20.479, learner_queue_size = 64, _tick = 84, _time = 1.6547e+09)
[2022-06-09 13:46:07,802][root][INFO] - Step 936960 @ 3069.5 SPS. Inference batcher size: 7. Learner queue size: 64. Other stats: (train_seconds = 330.7, step = 936960, mean_episode_return = None, mean_episode_step = 2973.4, total_loss = -39.931, pg_loss = -21.431, baseline_loss = 2.1194, entropy_loss = -20.62, learner_queue_size = 64, _tick = 85, _time = 1.6547e+09)
[2022-06-09 13:46:12,806][root][INFO] - Step 952320 @ 3069.5 SPS. Inference batcher size: 90. Learner queue size: 64. Other stats: (train_seconds = 335.7, step = 952320, mean_episode_return = -5.9001, mean_episode_step = 2914.2, total_loss = -43.741, pg_loss = -24.274, baseline_loss = 1.532, entropy_loss = -20.999, learner_queue_size = 64, _tick = 86, _time = 1.6547e+09)
[2022-06-09 13:46:17,810][root][INFO] - Step 967680 @ 3069.6 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 340.7, step = 967680, mean_episode_return = -36.72, mean_episode_step = 3322.8, total_loss = 310.06, pg_loss = 264.75, baseline_loss = 66.403, entropy_loss = -21.098, learner_queue_size = 64, _tick = 87, _time = 1.6547e+09)
[2022-06-09 13:46:22,814][root][INFO] - Step 977920 @ 2046.4 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 345.7, step = 977920, mean_episode_return = None, mean_episode_step = 3028.2, total_loss = -78.746, pg_loss = -58.318, baseline_loss = 0.50877, entropy_loss = -20.937, learner_queue_size = 64, _tick = 88, _time = 1.6547e+09)
[2022-06-09 13:46:27,818][root][INFO] - Step 993280 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 350.8, step = 993280, mean_episode_return = -28.301, mean_episode_step = 3151.5, total_loss = 19.354, pg_loss = 36.581, baseline_loss = 3.7906, entropy_loss = -21.017, learner_queue_size = 64, _tick = 89, _time = 1.6547e+09)
[2022-06-09 13:46:32,822][root][INFO] - Step 1008640 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 355.8, step = 1008640, mean_episode_return = None, mean_episode_step = 3387.6, total_loss = -29.304, pg_loss = -11.695, baseline_loss = 3.4004, entropy_loss = -21.009, learner_queue_size = 64, _tick = 90, _time = 1.6547e+09)
[2022-06-09 13:46:37,826][root][INFO] - Step 1024000 @ 3069.6 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 360.8, step = 1024000, mean_episode_return = -19.311, mean_episode_step = 3537.6, total_loss = -81.905, pg_loss = -63.162, baseline_loss = 2.3451, entropy_loss = -21.088, learner_queue_size = 64, _tick = 93, _time = 1.6547e+09)
[2022-06-09 13:46:42,830][root][INFO] - Step 1034240 @ 2046.3 SPS. Inference batcher size: 13. Learner queue size: 64. Other stats: (train_seconds = 365.8, step = 1034240, mean_episode_return = None, mean_episode_step = 3225.9, total_loss = -105.39, pg_loss = -84.671, baseline_loss = 0.42206, entropy_loss = -21.14, learner_queue_size = 64, _tick = 94, _time = 1.6547e+09)
[2022-06-09 13:46:47,834][root][INFO] - Step 1049600 @ 3069.6 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 370.8, step = 1049600, mean_episode_return = -4.85, mean_episode_step = 3381.2, total_loss = 78.061, pg_loss = 40.199, baseline_loss = 58.825, entropy_loss = -20.963, learner_queue_size = 64, _tick = 96, _time = 1.6548e+09)
[2022-06-09 13:46:52,838][root][INFO] - Step 1064960 @ 3069.5 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 375.8, step = 1064960, mean_episode_return = None, mean_episode_step = 3393.4, total_loss = 78.082, pg_loss = 76.023, baseline_loss = 23.042, entropy_loss = -20.983, learner_queue_size = 64, _tick = 96, _time = 1.6548e+09)
[2022-06-09 13:46:57,842][root][INFO] - Step 1080320 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 380.8, step = 1080320, mean_episode_return = None, mean_episode_step = 3513.0, total_loss = -76.989, pg_loss = -57.014, baseline_loss = 0.77988, entropy_loss = -20.756, learner_queue_size = 64, _tick = 96, _time = 1.6548e+09)
[2022-06-09 13:47:02,846][root][INFO] - Step 1095680 @ 3069.6 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 385.8, step = 1095680, mean_episode_return = None, mean_episode_step = 3422.0, total_loss = -56.522, pg_loss = -35.959, baseline_loss = 0.36687, entropy_loss = -20.929, learner_queue_size = 64, _tick = 96, _time = 1.6548e+09)
[2022-06-09 13:47:07,850][root][INFO] - Step 1111040 @ 3069.5 SPS. Inference batcher size: 81. Learner queue size: 64. Other stats: (train_seconds = 390.8, step = 1111040, mean_episode_return = -0.31, mean_episode_step = 3597.5, total_loss = 48.806, pg_loss = 65.725, baseline_loss = 4.1048, entropy_loss = -21.024, learner_queue_size = 64, _tick = 98, _time = 1.6548e+09)
[2022-06-09 13:47:12,854][root][INFO] - Step 1126400 @ 3069.6 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 395.8, step = 1126400, mean_episode_return = None, mean_episode_step = 3696.5, total_loss = 44.545, pg_loss = 62.693, baseline_loss = 2.9286, entropy_loss = -21.077, learner_queue_size = 64, _tick = 98, _time = 1.6548e+09)
[2022-06-09 13:47:17,858][root][INFO] - Step 1141760 @ 3069.5 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 400.8, step = 1141760, mean_episode_return = -44.599, mean_episode_step = 3794.4, total_loss = 71.344, pg_loss = 73.389, baseline_loss = 18.968, entropy_loss = -21.013, learner_queue_size = 64, _tick = 101, _time = 1.6548e+09)
[2022-06-09 13:47:22,863][root][INFO] - Step 1157120 @ 3068.9 SPS. Inference batcher size: 89. Learner queue size: 64. Other stats: (train_seconds = 405.8, step = 1157120, mean_episode_return = None, mean_episode_step = 3661.6, total_loss = 32.976, pg_loss = 49.28, baseline_loss = 4.4211, entropy_loss = -20.726, learner_queue_size = 64, _tick = 102, _time = 1.6548e+09)
[2022-06-09 13:47:27,866][root][INFO] - Step 1167360 @ 2046.8 SPS. Inference batcher size: 13. Learner queue size: 64. Other stats: (train_seconds = 410.8, step = 1167360, mean_episode_return = -13.14, mean_episode_step = 3683.7, total_loss = 744.26, pg_loss = 596.0, baseline_loss = 168.83, entropy_loss = -20.567, learner_queue_size = 64, _tick = 104, _time = 1.6548e+09)
[2022-06-09 13:47:32,870][root][INFO] - Step 1182720 @ 3069.5 SPS. Inference batcher size: 73. Learner queue size: 64. Other stats: (train_seconds = 415.8, step = 1182720, mean_episode_return = None, mean_episode_step = 3524.6, total_loss = -23.189, pg_loss = -16.684, baseline_loss = 13.797, entropy_loss = -20.302, learner_queue_size = 64, _tick = 106, _time = 1.6548e+09)
[2022-06-09 13:47:37,874][root][INFO] - Step 1192960 @ 2046.4 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 420.8, step = 1192960, mean_episode_return = -16.01, mean_episode_step = 3662.0, total_loss = 94.745, pg_loss = 102.23, baseline_loss = 12.713, entropy_loss = -20.196, learner_queue_size = 64, _tick = 107, _time = 1.6548e+09)
[2022-06-09 13:47:42,878][root][INFO] - Step 1208320 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 425.8, step = 1208320, mean_episode_return = -40.599, mean_episode_step = 3707.0, total_loss = -95.959, pg_loss = -77.329, baseline_loss = 1.573, entropy_loss = -20.202, learner_queue_size = 64, _tick = 108, _time = 1.6548e+09)
[2022-06-09 13:47:47,882][root][INFO] - Step 1223680 @ 3069.6 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 430.8, step = 1223680, mean_episode_return = -14.305, mean_episode_step = 3699.5, total_loss = -39.662, pg_loss = -27.199, baseline_loss = 7.8666, entropy_loss = -20.329, learner_queue_size = 64, _tick = 111, _time = 1.6548e+09)
[2022-06-09 13:47:52,886][root][INFO] - Step 1239040 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 435.8, step = 1239040, mean_episode_return = None, mean_episode_step = 3910.3, total_loss = -125.04, pg_loss = -107.05, baseline_loss = 2.5973, entropy_loss = -20.596, learner_queue_size = 64, _tick = 111, _time = 1.6548e+09)
[2022-06-09 13:47:57,890][root][INFO] - Step 1254400 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 440.8, step = 1254400, mean_episode_return = None, mean_episode_step = 3541.8, total_loss = 332.47, pg_loss = 277.46, baseline_loss = 75.211, entropy_loss = -20.205, learner_queue_size = 64, _tick = 111, _time = 1.6548e+09)
[2022-06-09 13:48:02,894][root][INFO] - Step 1269760 @ 3069.5 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 445.8, step = 1269760, mean_episode_return = 19.642, mean_episode_step = 3882.1, total_loss = 87.626, pg_loss = 98.555, baseline_loss = 9.4082, entropy_loss = -20.337, learner_queue_size = 64, _tick = 113, _time = 1.6548e+09)
[2022-06-09 13:48:07,898][root][INFO] - Step 1280000 @ 2046.4 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 450.8, step = 1280000, mean_episode_return = None, mean_episode_step = 3892.1, total_loss = 55.066, pg_loss = 59.98, baseline_loss = 15.456, entropy_loss = -20.37, learner_queue_size = 64, _tick = 113, _time = 1.6548e+09)
[2022-06-09 13:48:12,902][root][INFO] - Step 1295360 @ 3069.6 SPS. Inference batcher size: 14. Learner queue size: 64. Other stats: (train_seconds = 455.8, step = 1295360, mean_episode_return = None, mean_episode_step = 3930.0, total_loss = 27.885, pg_loss = 18.393, baseline_loss = 29.749, entropy_loss = -20.256, learner_queue_size = 64, _tick = 114, _time = 1.6548e+09)
[2022-06-09 13:48:17,906][root][INFO] - Step 1310720 @ 3069.5 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 460.8, step = 1310720, mean_episode_return = None, mean_episode_step = 4044.8, total_loss = 166.36, pg_loss = 160.49, baseline_loss = 26.155, entropy_loss = -20.276, learner_queue_size = 64, _tick = 115, _time = 1.6548e+09)
[2022-06-09 13:48:22,910][root][INFO] - Step 1320960 @ 2046.4 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 465.8, step = 1320960, mean_episode_return = -32.381, mean_episode_step = 3871.6, total_loss = -116.78, pg_loss = -98.644, baseline_loss = 2.1803, entropy_loss = -20.311, learner_queue_size = 64, _tick = 116, _time = 1.6548e+09)
[2022-06-09 13:48:27,914][root][INFO] - Step 1336320 @ 3069.5 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 470.8, step = 1336320, mean_episode_return = -39.848, mean_episode_step = 4170.0, total_loss = 241.27, pg_loss = 220.79, baseline_loss = 40.481, entropy_loss = -20.0, learner_queue_size = 64, _tick = 118, _time = 1.6548e+09)
[2022-06-09 13:48:32,918][root][INFO] - Step 1351680 @ 3069.6 SPS. Inference batcher size: 83. Learner queue size: 64. Other stats: (train_seconds = 475.9, step = 1351680, mean_episode_return = None, mean_episode_step = 3998.8, total_loss = 185.58, pg_loss = 155.92, baseline_loss = 49.482, entropy_loss = -19.82, learner_queue_size = 64, _tick = 119, _time = 1.6548e+09)
[2022-06-09 13:48:37,923][root][INFO] - Step 1367040 @ 3069.2 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 480.9, step = 1367040, mean_episode_return = None, mean_episode_step = 4179.0, total_loss = 141.25, pg_loss = 120.03, baseline_loss = 40.725, entropy_loss = -19.503, learner_queue_size = 64, _tick = 120, _time = 1.6548e+09)
[2022-06-09 13:48:42,926][root][INFO] - Step 1377280 @ 2046.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 485.9, step = 1377280, mean_episode_return = None, mean_episode_step = 4242.4, total_loss = -81.039, pg_loss = -66.902, baseline_loss = 5.4673, entropy_loss = -19.605, learner_queue_size = 64, _tick = 120, _time = 1.6548e+09)
[2022-06-09 13:48:47,930][root][INFO] - Step 1392640 @ 3069.6 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 490.9, step = 1392640, mean_episode_return = None, mean_episode_step = 4250.5, total_loss = -34.587, pg_loss = -25.635, baseline_loss = 10.622, entropy_loss = -19.574, learner_queue_size = 64, _tick = 121, _time = 1.6548e+09)
[2022-06-09 13:48:52,934][root][INFO] - Step 1408000 @ 3069.5 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 495.9, step = 1408000, mean_episode_return = None, mean_episode_step = 4556.7, total_loss = 215.94, pg_loss = 201.63, baseline_loss = 33.925, entropy_loss = -19.612, learner_queue_size = 64, _tick = 121, _time = 1.6548e+09)
[2022-06-09 13:48:57,938][root][INFO] - Step 1423360 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 500.9, step = 1423360, mean_episode_return = -53.807, mean_episode_step = 4288.8, total_loss = -2.905, pg_loss = 5.7798, baseline_loss = 10.953, entropy_loss = -19.638, learner_queue_size = 64, _tick = 122, _time = 1.6548e+09)
[2022-06-09 13:49:02,942][root][INFO] - Step 1438720 @ 3069.5 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 505.9, step = 1438720, mean_episode_return = -26.151, mean_episode_step = 4319.5, total_loss = -83.12, pg_loss = -66.503, baseline_loss = 2.6626, entropy_loss = -19.279, learner_queue_size = 64, _tick = 125, _time = 1.6548e+09)
[2022-06-09 13:49:07,946][root][INFO] - Step 1454080 @ 3069.6 SPS. Inference batcher size: 7. Learner queue size: 64. Other stats: (train_seconds = 510.9, step = 1454080, mean_episode_return = None, mean_episode_step = 4473.2, total_loss = 69.081, pg_loss = 68.101, baseline_loss = 19.976, entropy_loss = -18.995, learner_queue_size = 64, _tick = 125, _time = 1.6548e+09)
[2022-06-09 13:49:12,950][root][INFO] - Step 1469440 @ 3069.4 SPS. Inference batcher size: 72. Learner queue size: 64. Other stats: (train_seconds = 515.9, step = 1469440, mean_episode_return = None, mean_episode_step = 4279.3, total_loss = 109.72, pg_loss = 104.03, baseline_loss = 24.252, entropy_loss = -18.563, learner_queue_size = 64, _tick = 125, _time = 1.6548e+09)
[2022-06-09 13:49:17,954][root][INFO] - Step 1479680 @ 2046.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 520.9, step = 1479680, mean_episode_return = None, mean_episode_step = 4666.7, total_loss = -94.427, pg_loss = -76.906, baseline_loss = 1.4987, entropy_loss = -19.02, learner_queue_size = 64, _tick = 125, _time = 1.6548e+09)
[2022-06-09 13:49:22,958][root][INFO] - Step 1495040 @ 3069.6 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 525.9, step = 1495040, mean_episode_return = None, mean_episode_step = 4651.9, total_loss = -84.166, pg_loss = -65.098, baseline_loss = 0.54313, entropy_loss = -19.611, learner_queue_size = 64, _tick = 125, _time = 1.6548e+09)
[2022-06-09 13:49:27,962][root][INFO] - Step 1510400 @ 3069.5 SPS. Inference batcher size: 14. Learner queue size: 64. Other stats: (train_seconds = 530.9, step = 1510400, mean_episode_return = 5.209, mean_episode_step = 4610.7, total_loss = 16.903, pg_loss = 29.987, baseline_loss = 6.5149, entropy_loss = -19.598, learner_queue_size = 64, _tick = 127, _time = 1.6548e+09)
[2022-06-09 13:49:32,966][root][INFO] - Step 1520640 @ 2046.3 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 535.9, step = 1520640, mean_episode_return = None, mean_episode_step = 4993.4, total_loss = 150.04, pg_loss = 136.29, baseline_loss = 33.465, entropy_loss = -19.72, learner_queue_size = 64, _tick = 127, _time = 1.6548e+09)
[2022-06-09 13:49:37,970][root][INFO] - Step 1536000 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 540.9, step = 1536000, mean_episode_return = None, mean_episode_step = 4446.9, total_loss = 99.43, pg_loss = 102.42, baseline_loss = 17.026, entropy_loss = -20.019, learner_queue_size = 64, _tick = 128, _time = 1.6548e+09)
[2022-06-09 13:49:42,974][root][INFO] - Step 1551360 @ 3069.3 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 545.9, step = 1551360, mean_episode_return = -5.8403, mean_episode_step = 4358.8, total_loss = 59.217, pg_loss = 50.814, baseline_loss = 28.29, entropy_loss = -19.887, learner_queue_size = 64, _tick = 129, _time = 1.6548e+09)
[2022-06-09 13:49:47,978][root][INFO] - Step 1566720 @ 3069.8 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 550.9, step = 1566720, mean_episode_return = -10.561, mean_episode_step = 4649.3, total_loss = 338.76, pg_loss = 297.65, baseline_loss = 60.679, entropy_loss = -19.571, learner_queue_size = 64, _tick = 131, _time = 1.6548e+09)
[2022-06-09 13:49:52,982][root][INFO] - Step 1582080 @ 3069.4 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 555.9, step = 1582080, mean_episode_return = -37.517, mean_episode_step = 4678.0, total_loss = -155.26, pg_loss = -136.53, baseline_loss = 0.69033, entropy_loss = -19.425, learner_queue_size = 64, _tick = 133, _time = 1.6548e+09)
[2022-06-09 13:49:57,986][root][INFO] - Step 1592320 @ 2046.4 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 560.9, step = 1592320, mean_episode_return = None, mean_episode_step = 4811.4, total_loss = 189.79, pg_loss = 176.49, baseline_loss = 32.954, entropy_loss = -19.649, learner_queue_size = 64, _tick = 134, _time = 1.6548e+09)
[2022-06-09 13:50:02,990][root][INFO] - Step 1607680 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 565.9, step = 1607680, mean_episode_return = None, mean_episode_step = 4659.8, total_loss = -19.847, pg_loss = -22.404, baseline_loss = 22.416, entropy_loss = -19.859, learner_queue_size = 64, _tick = 135, _time = 1.6548e+09)
[2022-06-09 13:50:07,995][root][INFO] - Step 1623040 @ 3068.9 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 570.9, step = 1623040, mean_episode_return = None, mean_episode_step = 4853.1, total_loss = 54.256, pg_loss = 37.703, baseline_loss = 35.961, entropy_loss = -19.408, learner_queue_size = 64, _tick = 136, _time = 1.6548e+09)
[2022-06-09 13:50:12,998][root][INFO] - Step 1633280 @ 2046.8 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 575.9, step = 1633280, mean_episode_return = -12.65, mean_episode_step = 5198.0, total_loss = 675.22, pg_loss = 491.29, baseline_loss = 203.17, entropy_loss = -19.233, learner_queue_size = 64, _tick = 137, _time = 1.6548e+09)
[2022-06-09 13:50:18,002][root][INFO] - Step 1648640 @ 3069.6 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 580.9, step = 1648640, mean_episode_return = None, mean_episode_step = 4962.5, total_loss = -163.35, pg_loss = -145.96, baseline_loss = 1.7763, entropy_loss = -19.167, learner_queue_size = 64, _tick = 137, _time = 1.6548e+09)
[2022-06-09 13:50:23,006][root][INFO] - Step 1664000 @ 3069.6 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 585.9, step = 1664000, mean_episode_return = None, mean_episode_step = 5064.5, total_loss = 1700.6, pg_loss = 978.7, baseline_loss = 741.28, entropy_loss = -19.424, learner_queue_size = 64, _tick = 138, _time = 1.6548e+09)
[2022-06-09 13:50:28,010][root][INFO] - Step 1679360 @ 3069.5 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 590.9, step = 1679360, mean_episode_return = None, mean_episode_step = 5233.5, total_loss = -203.25, pg_loss = -185.44, baseline_loss = 1.8873, entropy_loss = -19.694, learner_queue_size = 64, _tick = 140, _time = 1.6548e+09)
[2022-06-09 13:50:33,014][root][INFO] - Step 1694720 @ 3069.6 SPS. Inference batcher size: 13. Learner queue size: 64. Other stats: (train_seconds = 595.9, step = 1694720, mean_episode_return = None, mean_episode_step = 5178.5, total_loss = 384.82, pg_loss = 292.13, baseline_loss = 112.36, entropy_loss = -19.674, learner_queue_size = 64, _tick = 142, _time = 1.6548e+09)
[2022-06-09 13:50:38,018][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 13:50:38,542][root][INFO] - Step 1704960 @ 2046.3 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 601.0, step = 1710080, mean_episode_return = None, mean_episode_step = 5004.2, total_loss = -175.1, pg_loss = -162.25, baseline_loss = 6.6781, entropy_loss = -19.535, learner_queue_size = 64, _tick = 142, _time = 1.6548e+09)
[2022-06-09 13:50:43,546][root][INFO] - Step 1720320 @ 2778.6 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 606.5, step = 1720320, mean_episode_return = None, mean_episode_step = 5465.1, total_loss = -67.494, pg_loss = -59.266, baseline_loss = 11.178, entropy_loss = -19.405, learner_queue_size = 64, _tick = 143, _time = 1.6548e+09)
[2022-06-09 13:50:48,551][root][INFO] - Step 1735680 @ 3069.0 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 611.5, step = 1735680, mean_episode_return = -41.765, mean_episode_step = 4730.9, total_loss = 175.07, pg_loss = 147.11, baseline_loss = 46.829, entropy_loss = -18.873, learner_queue_size = 64, _tick = 144, _time = 1.6548e+09)
[2022-06-09 13:50:53,554][root][INFO] - Step 1751040 @ 3070.1 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 616.5, step = 1751040, mean_episode_return = None, mean_episode_step = 5001.5, total_loss = 82.414, pg_loss = 69.393, baseline_loss = 32.109, entropy_loss = -19.088, learner_queue_size = 64, _tick = 145, _time = 1.6548e+09)
[2022-06-09 13:50:58,558][root][INFO] - Step 1761280 @ 2046.3 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 621.5, step = 1761280, mean_episode_return = None, mean_episode_step = 5237.4, total_loss = -132.23, pg_loss = -128.12, baseline_loss = 15.156, entropy_loss = -19.266, learner_queue_size = 64, _tick = 145, _time = 1.6548e+09)
[2022-06-09 13:51:03,562][root][INFO] - Step 1776640 @ 3069.6 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 626.5, step = 1776640, mean_episode_return = None, mean_episode_step = 5346.2, total_loss = -65.015, pg_loss = -49.433, baseline_loss = 4.1101, entropy_loss = -19.692, learner_queue_size = 64, _tick = 146, _time = 1.6548e+09)
[2022-06-09 13:51:08,567][root][INFO] - Step 1792000 @ 3069.1 SPS. Inference batcher size: 93. Learner queue size: 64. Other stats: (train_seconds = 631.5, step = 1792000, mean_episode_return = None, mean_episode_step = 5421.7, total_loss = -56.187, pg_loss = -47.519, baseline_loss = 10.88, entropy_loss = -19.548, learner_queue_size = 64, _tick = 146, _time = 1.6548e+09)
[2022-06-09 13:51:13,570][root][INFO] - Step 1807360 @ 3069.9 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 636.5, step = 1807360, mean_episode_return = 23.673, mean_episode_step = 4873.5, total_loss = -119.69, pg_loss = -107.06, baseline_loss = 6.553, entropy_loss = -19.185, learner_queue_size = 64, _tick = 148, _time = 1.6548e+09)
[2022-06-09 13:51:18,574][root][INFO] - Step 1822720 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 641.5, step = 1822720, mean_episode_return = None, mean_episode_step = 5259.8, total_loss = 73.032, pg_loss = 71.675, baseline_loss = 20.158, entropy_loss = -18.8, learner_queue_size = 64, _tick = 149, _time = 1.6548e+09)
[2022-06-09 13:51:23,578][root][INFO] - Step 1838080 @ 3069.5 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 646.5, step = 1838080, mean_episode_return = -26.083, mean_episode_step = 5270.4, total_loss = 387.53, pg_loss = 342.16, baseline_loss = 64.637, entropy_loss = -19.27, learner_queue_size = 64, _tick = 151, _time = 1.6548e+09)
[2022-06-09 13:51:28,582][root][INFO] - Step 1848320 @ 2046.4 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 651.5, step = 1848320, mean_episode_return = None, mean_episode_step = 5343.9, total_loss = -39.009, pg_loss = -29.324, baseline_loss = 9.5611, entropy_loss = -19.246, learner_queue_size = 64, _tick = 152, _time = 1.6548e+09)
[2022-06-09 13:51:33,586][root][INFO] - Step 1863680 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 656.5, step = 1863680, mean_episode_return = None, mean_episode_step = 5580.8, total_loss = 645.05, pg_loss = 461.15, baseline_loss = 202.91, entropy_loss = -19.014, learner_queue_size = 64, _tick = 154, _time = 1.6548e+09)
[2022-06-09 13:51:38,590][root][INFO] - Step 1879040 @ 3069.5 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 661.5, step = 1879040, mean_episode_return = -58.345, mean_episode_step = 5547.9, total_loss = -32.536, pg_loss = -34.951, baseline_loss = 21.391, entropy_loss = -18.976, learner_queue_size = 64, _tick = 156, _time = 1.6548e+09)
[2022-06-09 13:51:43,594][root][INFO] - Step 1894400 @ 3069.5 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 666.5, step = 1894400, mean_episode_return = None, mean_episode_step = 5517.6, total_loss = -137.01, pg_loss = -121.41, baseline_loss = 3.0401, entropy_loss = -18.641, learner_queue_size = 64, _tick = 157, _time = 1.6548e+09)
[2022-06-09 13:51:48,598][root][INFO] - Step 1909760 @ 3069.5 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 671.5, step = 1909760, mean_episode_return = None, mean_episode_step = 5112.2, total_loss = -33.193, pg_loss = -29.696, baseline_loss = 14.901, entropy_loss = -18.398, learner_queue_size = 64, _tick = 158, _time = 1.6548e+09)
[2022-06-09 13:51:53,602][root][INFO] - Step 1925120 @ 3069.6 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 676.5, step = 1925120, mean_episode_return = None, mean_episode_step = 5765.1, total_loss = 177.47, pg_loss = 165.91, baseline_loss = 29.772, entropy_loss = -18.207, learner_queue_size = 64, _tick = 159, _time = 1.6548e+09)
[2022-06-09 13:51:58,606][root][INFO] - Step 1935360 @ 2046.4 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 681.5, step = 1935360, mean_episode_return = None, mean_episode_step = 5371.4, total_loss = -49.227, pg_loss = -44.469, baseline_loss = 13.553, entropy_loss = -18.311, learner_queue_size = 64, _tick = 159, _time = 1.6548e+09)
[2022-06-09 13:52:03,610][root][INFO] - Step 1950720 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 686.5, step = 1950720, mean_episode_return = None, mean_episode_step = 5481.6, total_loss = 24.292, pg_loss = 34.17, baseline_loss = 8.3367, entropy_loss = -18.215, learner_queue_size = 64, _tick = 160, _time = 1.6548e+09)
[2022-06-09 13:52:08,614][root][INFO] - Step 1966080 @ 3069.6 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 691.5, step = 1966080, mean_episode_return = -46.167, mean_episode_step = 5694.4, total_loss = 562.87, pg_loss = 350.67, baseline_loss = 230.13, entropy_loss = -17.93, learner_queue_size = 64, _tick = 162, _time = 1.6548e+09)
[2022-06-09 13:52:13,618][root][INFO] - Step 1976320 @ 2046.4 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 696.6, step = 1976320, mean_episode_return = None, mean_episode_step = 5086.8, total_loss = 803.36, pg_loss = 617.9, baseline_loss = 203.66, entropy_loss = -18.205, learner_queue_size = 64, _tick = 163, _time = 1.6548e+09)
[2022-06-09 13:52:18,625][root][INFO] - Step 1991680 @ 3067.7 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 701.6, step = 1991680, mean_episode_return = None, mean_episode_step = 5176.4, total_loss = 419.2, pg_loss = 365.35, baseline_loss = 71.831, entropy_loss = -17.98, learner_queue_size = 64, _tick = 165, _time = 1.6548e+09)
[2022-06-09 13:52:23,630][root][INFO] - Step 2007040 @ 3068.9 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 706.6, step = 2007040, mean_episode_return = None, mean_episode_step = 5791.4, total_loss = 28.144, pg_loss = 19.994, baseline_loss = 26.109, entropy_loss = -17.96, learner_queue_size = 64, _tick = 166, _time = 1.6548e+09)
[2022-06-09 13:52:28,634][root][INFO] - Step 2022400 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 711.6, step = 2022400, mean_episode_return = None, mean_episode_step = 5933.5, total_loss = -27.675, pg_loss = -39.837, baseline_loss = 29.877, entropy_loss = -17.715, learner_queue_size = 64, _tick = 168, _time = 1.6548e+09)
[2022-06-09 13:52:33,638][root][INFO] - Step 2037760 @ 3069.5 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 716.6, step = 2037760, mean_episode_return = None, mean_episode_step = 6002.6, total_loss = 287.55, pg_loss = 230.08, baseline_loss = 74.388, entropy_loss = -16.919, learner_queue_size = 64, _tick = 168, _time = 1.6548e+09)
[2022-06-09 13:52:38,642][root][INFO] - Step 2048000 @ 2046.3 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 721.6, step = 2048000, mean_episode_return = 12.321, mean_episode_step = 5916.1, total_loss = 22.215, pg_loss = 29.862, baseline_loss = 9.3034, entropy_loss = -16.951, learner_queue_size = 64, _tick = 170, _time = 1.6548e+09)
[2022-06-09 13:52:43,646][root][INFO] - Step 2063360 @ 3069.6 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 726.6, step = 2063360, mean_episode_return = None, mean_episode_step = 5776.2, total_loss = 84.134, pg_loss = 78.426, baseline_loss = 23.171, entropy_loss = -17.463, learner_queue_size = 64, _tick = 172, _time = 1.6548e+09)
[2022-06-09 13:52:48,650][root][INFO] - Step 2078720 @ 3069.5 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 731.6, step = 2078720, mean_episode_return = None, mean_episode_step = 5128.7, total_loss = -72.838, pg_loss = -60.978, baseline_loss = 4.9062, entropy_loss = -16.766, learner_queue_size = 64, _tick = 173, _time = 1.6548e+09)
[2022-06-09 13:52:53,654][root][INFO] - Step 2094080 @ 3069.6 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 736.6, step = 2094080, mean_episode_return = -7.1103, mean_episode_step = 5327.3, total_loss = 178.84, pg_loss = 160.26, baseline_loss = 35.558, entropy_loss = -16.986, learner_queue_size = 64, _tick = 175, _time = 1.6548e+09)
[2022-06-09 13:52:58,658][root][INFO] - Step 2109440 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 741.6, step = 2109440, mean_episode_return = -24.16, mean_episode_step = 5195.8, total_loss = 208.96, pg_loss = 157.32, baseline_loss = 68.731, entropy_loss = -17.094, learner_queue_size = 64, _tick = 177, _time = 1.6548e+09)
[2022-06-09 13:53:03,663][root][INFO] - Step 2124800 @ 3069.2 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 746.6, step = 2124800, mean_episode_return = None, mean_episode_step = 5187.1, total_loss = -73.308, pg_loss = -65.782, baseline_loss = 9.6586, entropy_loss = -17.185, learner_queue_size = 64, _tick = 177, _time = 1.6548e+09)
[2022-06-09 13:53:08,666][root][INFO] - Step 2140160 @ 3069.9 SPS. Inference batcher size: 86. Learner queue size: 64. Other stats: (train_seconds = 751.6, step = 2140160, mean_episode_return = -2.8689, mean_episode_step = 5259.3, total_loss = 292.35, pg_loss = 237.35, baseline_loss = 72.711, entropy_loss = -17.715, learner_queue_size = 64, _tick = 179, _time = 1.6548e+09)
[2022-06-09 13:53:13,670][root][INFO] - Step 2150400 @ 2046.4 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 756.6, step = 2150400, mean_episode_return = None, mean_episode_step = 5828.9, total_loss = 12.389, pg_loss = 3.5381, baseline_loss = 26.118, entropy_loss = -17.267, learner_queue_size = 64, _tick = 179, _time = 1.6548e+09)
[2022-06-09 13:53:18,674][root][INFO] - Step 2165760 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 761.6, step = 2165760, mean_episode_return = -26.78, mean_episode_step = 4989.8, total_loss = -100.31, pg_loss = -99.725, baseline_loss = 16.954, entropy_loss = -17.535, learner_queue_size = 64, _tick = 182, _time = 1.6548e+09)
[2022-06-09 13:53:23,678][root][INFO] - Step 2181120 @ 3069.6 SPS. Inference batcher size: 4. Learner queue size: 64. Other stats: (train_seconds = 766.6, step = 2181120, mean_episode_return = -56.512, mean_episode_step = 4831.3, total_loss = 280.99, pg_loss = 233.08, baseline_loss = 64.862, entropy_loss = -16.957, learner_queue_size = 64, _tick = 185, _time = 1.6548e+09)
[2022-06-09 13:53:28,682][root][INFO] - Step 2196480 @ 3069.6 SPS. Inference batcher size: 68. Learner queue size: 64. Other stats: (train_seconds = 771.6, step = 2196480, mean_episode_return = -71.187, mean_episode_step = 4621.8, total_loss = 60.06, pg_loss = 44.163, baseline_loss = 32.6, entropy_loss = -16.703, learner_queue_size = 64, _tick = 187, _time = 1.6548e+09)
[2022-06-09 13:53:33,686][root][INFO] - Step 2211840 @ 3069.4 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 776.6, step = 2211840, mean_episode_return = -62.001, mean_episode_step = 5338.3, total_loss = 91.517, pg_loss = 47.58, baseline_loss = 60.339, entropy_loss = -16.401, learner_queue_size = 64, _tick = 190, _time = 1.6548e+09)
[2022-06-09 13:53:38,690][root][INFO] - Step 2222080 @ 2046.4 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 781.6, step = 2222080, mean_episode_return = -3.6322, mean_episode_step = 4909.1, total_loss = -89.662, pg_loss = -87.2, baseline_loss = 14.356, entropy_loss = -16.818, learner_queue_size = 64, _tick = 191, _time = 1.6548e+09)
[2022-06-09 13:53:43,694][root][INFO] - Step 2237440 @ 3069.6 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 786.6, step = 2237440, mean_episode_return = -67.836, mean_episode_step = 5392.4, total_loss = 158.66, pg_loss = 137.13, baseline_loss = 37.682, entropy_loss = -16.143, learner_queue_size = 64, _tick = 194, _time = 1.6548e+09)
[2022-06-09 13:53:48,698][root][INFO] - Step 2252800 @ 3069.5 SPS. Inference batcher size: 7. Learner queue size: 64. Other stats: (train_seconds = 791.6, step = 2252800, mean_episode_return = 25.594, mean_episode_step = 5199.5, total_loss = -5.9975, pg_loss = -9.1666, baseline_loss = 20.509, entropy_loss = -17.34, learner_queue_size = 64, _tick = 197, _time = 1.6548e+09)
[2022-06-09 13:53:53,702][root][INFO] - Step 2268160 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 796.6, step = 2268160, mean_episode_return = None, mean_episode_step = 4492.1, total_loss = -67.685, pg_loss = -69.579, baseline_loss = 18.913, entropy_loss = -17.019, learner_queue_size = 64, _tick = 198, _time = 1.6548e+09)
[2022-06-09 13:53:58,706][root][INFO] - Step 2283520 @ 3069.6 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 801.6, step = 2283520, mean_episode_return = 20.879, mean_episode_step = 5037.8, total_loss = -97.182, pg_loss = -83.05, baseline_loss = 1.8935, entropy_loss = -16.026, learner_queue_size = 64, _tick = 201, _time = 1.6548e+09)
[2022-06-09 13:54:03,711][root][INFO] - Step 2298880 @ 3069.5 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 806.6, step = 2298880, mean_episode_return = -24.661, mean_episode_step = 5059.3, total_loss = -150.64, pg_loss = -135.11, baseline_loss = 1.1733, entropy_loss = -16.698, learner_queue_size = 64, _tick = 203, _time = 1.6548e+09)
[2022-06-09 13:54:08,718][root][INFO] - Step 2314240 @ 3067.2 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 811.7, step = 2314240, mean_episode_return = -58.857, mean_episode_step = 5411.5, total_loss = -28.51, pg_loss = -24.798, baseline_loss = 12.571, entropy_loss = -16.283, learner_queue_size = 64, _tick = 206, _time = 1.6548e+09)
[2022-06-09 13:54:13,722][root][INFO] - Step 2324480 @ 2046.3 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 816.7, step = 2324480, mean_episode_return = None, mean_episode_step = 4745.1, total_loss = -125.96, pg_loss = -111.55, baseline_loss = 2.3702, entropy_loss = -16.78, learner_queue_size = 64, _tick = 207, _time = 1.6548e+09)
[2022-06-09 13:54:18,726][root][INFO] - Step 2339840 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 821.7, step = 2339840, mean_episode_return = -33.082, mean_episode_step = 5165.9, total_loss = 135.2, pg_loss = 136.8, baseline_loss = 15.986, entropy_loss = -17.59, learner_queue_size = 64, _tick = 210, _time = 1.6548e+09)
[2022-06-09 13:54:23,740][root][INFO] - Step 2355200 @ 3063.7 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 826.7, step = 2355200, mean_episode_return = -19.077, mean_episode_step = 4361.3, total_loss = -109.18, pg_loss = -94.944, baseline_loss = 2.6458, entropy_loss = -16.885, learner_queue_size = 64, _tick = 213, _time = 1.6548e+09)
[2022-06-09 13:54:28,742][root][INFO] - Step 2370560 @ 3070.6 SPS. Inference batcher size: 90. Learner queue size: 64. Other stats: (train_seconds = 831.7, step = 2370560, mean_episode_return = -54.722, mean_episode_step = 4559.7, total_loss = 45.596, pg_loss = 44.62, baseline_loss = 18.311, entropy_loss = -17.335, learner_queue_size = 64, _tick = 215, _time = 1.6548e+09)
[2022-06-09 13:54:33,746][root][INFO] - Step 2385920 @ 3069.5 SPS. Inference batcher size: 94. Learner queue size: 64. Other stats: (train_seconds = 836.7, step = 2385920, mean_episode_return = -26.531, mean_episode_step = 4005.3, total_loss = 201.37, pg_loss = 174.44, baseline_loss = 44.269, entropy_loss = -17.34, learner_queue_size = 64, _tick = 217, _time = 1.6548e+09)
[2022-06-09 13:54:38,750][root][INFO] - Step 2401280 @ 3069.6 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 841.7, step = 2401280, mean_episode_return = 22.585, mean_episode_step = 4303.8, total_loss = -281.78, pg_loss = -268.02, baseline_loss = 3.2052, entropy_loss = -16.963, learner_queue_size = 64, _tick = 220, _time = 1.6548e+09)
[2022-06-09 13:54:43,756][root][INFO] - Step 2411520 @ 2045.7 SPS. Inference batcher size: 18. Learner queue size: 64. Other stats: (train_seconds = 846.7, step = 2411520, mean_episode_return = -2.22, mean_episode_step = 4216.6, total_loss = 318.55, pg_loss = 258.98, baseline_loss = 76.874, entropy_loss = -17.304, learner_queue_size = 64, _tick = 222, _time = 1.6548e+09)
[2022-06-09 13:54:48,758][root][INFO] - Step 2426880 @ 3070.5 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 851.7, step = 2426880, mean_episode_return = -49.194, mean_episode_step = 3944.4, total_loss = -119.62, pg_loss = -109.87, baseline_loss = 8.0062, entropy_loss = -17.754, learner_queue_size = 64, _tick = 225, _time = 1.6548e+09)
[2022-06-09 13:54:53,762][root][INFO] - Step 2442240 @ 3069.6 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 856.7, step = 2442240, mean_episode_return = None, mean_episode_step = 4371.1, total_loss = -81.003, pg_loss = -69.704, baseline_loss = 6.0365, entropy_loss = -17.336, learner_queue_size = 64, _tick = 226, _time = 1.6548e+09)
[2022-06-09 13:54:58,766][root][INFO] - Step 2452480 @ 2046.3 SPS. Inference batcher size: 11. Learner queue size: 64. Other stats: (train_seconds = 861.7, step = 2452480, mean_episode_return = None, mean_episode_step = 4369.8, total_loss = 32.68, pg_loss = 21.343, baseline_loss = 29.026, entropy_loss = -17.689, learner_queue_size = 64, _tick = 226, _time = 1.6548e+09)
[2022-06-09 13:55:03,770][root][INFO] - Step 2467840 @ 3069.6 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 866.7, step = 2467840, mean_episode_return = -46.875, mean_episode_step = 4433.1, total_loss = 21.15, pg_loss = 15.3, baseline_loss = 23.704, entropy_loss = -17.853, learner_queue_size = 64, _tick = 229, _time = 1.6548e+09)
[2022-06-09 13:55:08,774][root][INFO] - Step 2483200 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 871.7, step = 2483200, mean_episode_return = -45.915, mean_episode_step = 4170.1, total_loss = 194.2, pg_loss = 180.71, baseline_loss = 31.351, entropy_loss = -17.859, learner_queue_size = 64, _tick = 231, _time = 1.6548e+09)
[2022-06-09 13:55:13,778][root][INFO] - Step 2498560 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 876.7, step = 2498560, mean_episode_return = -75.286, mean_episode_step = 4494.2, total_loss = -94.514, pg_loss = -80.8, baseline_loss = 4.1435, entropy_loss = -17.857, learner_queue_size = 64, _tick = 234, _time = 1.6548e+09)
[2022-06-09 13:55:18,782][root][INFO] - Step 2513920 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 881.7, step = 2513920, mean_episode_return = -66.951, mean_episode_step = 4222.6, total_loss = -55.587, pg_loss = -43.221, baseline_loss = 4.9896, entropy_loss = -17.356, learner_queue_size = 64, _tick = 237, _time = 1.6548e+09)
[2022-06-09 13:55:23,786][root][INFO] - Step 2529280 @ 3069.5 SPS. Inference batcher size: 74. Learner queue size: 64. Other stats: (train_seconds = 886.7, step = 2529280, mean_episode_return = -67.757, mean_episode_step = 4183.0, total_loss = -95.47, pg_loss = -87.468, baseline_loss = 9.4317, entropy_loss = -17.434, learner_queue_size = 64, _tick = 239, _time = 1.6548e+09)
[2022-06-09 13:55:28,790][root][INFO] - Step 2544640 @ 3069.5 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 891.7, step = 2544640, mean_episode_return = -71.575, mean_episode_step = 3724.0, total_loss = 148.41, pg_loss = 100.04, baseline_loss = 65.804, entropy_loss = -17.428, learner_queue_size = 64, _tick = 242, _time = 1.6548e+09)
[2022-06-09 13:55:33,796][root][INFO] - Step 2554880 @ 2045.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 896.7, step = 2554880, mean_episode_return = -69.342, mean_episode_step = 3790.1, total_loss = -157.77, pg_loss = -142.98, baseline_loss = 2.5481, entropy_loss = -17.336, learner_queue_size = 64, _tick = 244, _time = 1.6548e+09)
[2022-06-09 13:55:38,798][root][INFO] - Step 2570240 @ 3070.9 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 901.7, step = 2570240, mean_episode_return = -34.71, mean_episode_step = 4054.6, total_loss = 94.668, pg_loss = 81.542, baseline_loss = 30.442, entropy_loss = -17.316, learner_queue_size = 64, _tick = 246, _time = 1.6548e+09)
[2022-06-09 13:55:43,802][root][INFO] - Step 2585600 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 906.7, step = 2585600, mean_episode_return = None, mean_episode_step = 3327.9, total_loss = 185.02, pg_loss = 137.12, baseline_loss = 65.242, entropy_loss = -17.338, learner_queue_size = 64, _tick = 248, _time = 1.6548e+09)
[2022-06-09 13:55:48,806][root][INFO] - Step 2600960 @ 3069.5 SPS. Inference batcher size: 73. Learner queue size: 64. Other stats: (train_seconds = 911.7, step = 2600960, mean_episode_return = -42.919, mean_episode_step = 3161.0, total_loss = 344.96, pg_loss = 190.23, baseline_loss = 172.16, entropy_loss = -17.429, learner_queue_size = 64, _tick = 251, _time = 1.6548e+09)
[2022-06-09 13:55:53,810][root][INFO] - Step 2611200 @ 2046.4 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 916.7, step = 2611200, mean_episode_return = -0.62, mean_episode_step = 2658.1, total_loss = 160.19, pg_loss = 136.59, baseline_loss = 41.05, entropy_loss = -17.451, learner_queue_size = 64, _tick = 253, _time = 1.6548e+09)
[2022-06-09 13:55:58,816][root][INFO] - Step 2626560 @ 3068.3 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 921.8, step = 2626560, mean_episode_return = -40.19, mean_episode_step = 3283.5, total_loss = 122.29, pg_loss = 66.979, baseline_loss = 72.608, entropy_loss = -17.299, learner_queue_size = 64, _tick = 256, _time = 1.6548e+09)
[2022-06-09 13:56:03,822][root][INFO] - Step 2641920 @ 3068.4 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 926.8, step = 2641920, mean_episode_return = -49.676, mean_episode_step = 3020.5, total_loss = 350.99, pg_loss = 314.01, baseline_loss = 54.071, entropy_loss = -17.092, learner_queue_size = 64, _tick = 259, _time = 1.6548e+09)
[2022-06-09 13:56:08,826][root][INFO] - Step 2652160 @ 2046.4 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 931.8, step = 2652160, mean_episode_return = -34.836, mean_episode_step = 2874.5, total_loss = 155.59, pg_loss = 121.24, baseline_loss = 51.335, entropy_loss = -16.986, learner_queue_size = 64, _tick = 261, _time = 1.6548e+09)
[2022-06-09 13:56:13,830][root][INFO] - Step 2667520 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 936.8, step = 2667520, mean_episode_return = -4.326, mean_episode_step = 2367.5, total_loss = -56.722, pg_loss = -100.77, baseline_loss = 60.681, entropy_loss = -16.628, learner_queue_size = 64, _tick = 264, _time = 1.6548e+09)
[2022-06-09 13:56:18,834][root][INFO] - Step 2682880 @ 3069.4 SPS. Inference batcher size: 80. Learner queue size: 64. Other stats: (train_seconds = 941.8, step = 2682880, mean_episode_return = None, mean_episode_step = 2961.5, total_loss = 211.27, pg_loss = 142.84, baseline_loss = 85.018, entropy_loss = -16.583, learner_queue_size = 64, _tick = 265, _time = 1.6548e+09)
[2022-06-09 13:56:23,838][root][INFO] - Step 2698240 @ 3069.6 SPS. Inference batcher size: 74. Learner queue size: 64. Other stats: (train_seconds = 946.8, step = 2698240, mean_episode_return = 19.96, mean_episode_step = 2589.6, total_loss = 401.54, pg_loss = 329.96, baseline_loss = 88.383, entropy_loss = -16.797, learner_queue_size = 64, _tick = 268, _time = 1.6548e+09)
[2022-06-09 13:56:28,842][root][INFO] - Step 2708480 @ 2046.4 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 951.8, step = 2708480, mean_episode_return = 4.4097, mean_episode_step = 2900.4, total_loss = -107.3, pg_loss = -112.83, baseline_loss = 22.307, entropy_loss = -16.786, learner_queue_size = 64, _tick = 269, _time = 1.6548e+09)
[2022-06-09 13:56:33,846][root][INFO] - Step 2723840 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 956.8, step = 2723840, mean_episode_return = 30.299, mean_episode_step = 3215.4, total_loss = 265.69, pg_loss = 197.29, baseline_loss = 85.07, entropy_loss = -16.671, learner_queue_size = 64, _tick = 272, _time = 1.6548e+09)
[2022-06-09 13:56:38,868][root][INFO] - Step 2739200 @ 3058.6 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 961.8, step = 2739200, mean_episode_return = 0.48896, mean_episode_step = 2631.2, total_loss = 378.91, pg_loss = 310.25, baseline_loss = 85.525, entropy_loss = -16.861, learner_queue_size = 64, _tick = 274, _time = 1.6548e+09)
[2022-06-09 13:56:43,870][root][INFO] - Step 2754560 @ 3070.7 SPS. Inference batcher size: 91. Learner queue size: 64. Other stats: (train_seconds = 966.8, step = 2754560, mean_episode_return = -35.031, mean_episode_step = 3196.0, total_loss = 152.58, pg_loss = 106.87, baseline_loss = 62.59, entropy_loss = -16.877, learner_queue_size = 64, _tick = 277, _time = 1.6548e+09)
[2022-06-09 13:56:48,874][root][INFO] - Step 2769920 @ 3069.6 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 971.8, step = 2769920, mean_episode_return = 4.74, mean_episode_step = 2597.1, total_loss = 102.2, pg_loss = 70.934, baseline_loss = 48.34, entropy_loss = -17.078, learner_queue_size = 64, _tick = 280, _time = 1.6548e+09)
[2022-06-09 13:56:53,878][root][INFO] - Step 2785280 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 976.8, step = 2785280, mean_episode_return = 15.315, mean_episode_step = 2800.2, total_loss = 239.14, pg_loss = 157.69, baseline_loss = 97.986, entropy_loss = -16.544, learner_queue_size = 64, _tick = 283, _time = 1.6548e+09)
[2022-06-09 13:56:58,882][root][INFO] - Step 2795520 @ 2046.4 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 981.8, step = 2795520, mean_episode_return = None, mean_episode_step = 3167.3, total_loss = 131.06, pg_loss = 61.175, baseline_loss = 86.282, entropy_loss = -16.399, learner_queue_size = 64, _tick = 284, _time = 1.6548e+09)
[2022-06-09 13:57:03,886][root][INFO] - Step 2810880 @ 3069.4 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 986.8, step = 2810880, mean_episode_return = 9.2845, mean_episode_step = 2966.2, total_loss = -204.7, pg_loss = -198.93, baseline_loss = 10.444, entropy_loss = -16.214, learner_queue_size = 64, _tick = 286, _time = 1.6548e+09)
[2022-06-09 13:57:08,890][root][INFO] - Step 2826240 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 991.8, step = 2826240, mean_episode_return = -13.251, mean_episode_step = 2118.8, total_loss = -53.482, pg_loss = -51.368, baseline_loss = 14.343, entropy_loss = -16.457, learner_queue_size = 64, _tick = 288, _time = 1.6548e+09)
[2022-06-09 13:57:13,894][root][INFO] - Step 2841600 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 996.8, step = 2841600, mean_episode_return = 27.376, mean_episode_step = 2707.9, total_loss = 113.24, pg_loss = 88.368, baseline_loss = 41.531, entropy_loss = -16.659, learner_queue_size = 64, _tick = 290, _time = 1.6548e+09)
[2022-06-09 13:57:18,898][root][INFO] - Step 2856960 @ 3069.5 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 1001.8, step = 2856960, mean_episode_return = 65.774, mean_episode_step = 2494.0, total_loss = 164.88, pg_loss = 100.35, baseline_loss = 81.199, entropy_loss = -16.665, learner_queue_size = 64, _tick = 293, _time = 1.6548e+09)
[2022-06-09 13:57:23,902][root][INFO] - Step 2867200 @ 2046.3 SPS. Inference batcher size: 5. Learner queue size: 64. Other stats: (train_seconds = 1006.8, step = 2867200, mean_episode_return = None, mean_episode_step = 2398.5, total_loss = -107.78, pg_loss = -106.38, baseline_loss = 14.906, entropy_loss = -16.304, learner_queue_size = 64, _tick = 294, _time = 1.6548e+09)
[2022-06-09 13:57:28,906][root][INFO] - Step 2882560 @ 3069.6 SPS. Inference batcher size: 11. Learner queue size: 64. Other stats: (train_seconds = 1011.8, step = 2882560, mean_episode_return = -36.31, mean_episode_step = 2366.7, total_loss = 230.6, pg_loss = 158.1, baseline_loss = 88.013, entropy_loss = -15.514, learner_queue_size = 64, _tick = 296, _time = 1.6548e+09)
[2022-06-09 13:57:33,910][root][INFO] - Step 2897920 @ 3069.3 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 1016.8, step = 2897920, mean_episode_return = None, mean_episode_step = 2515.8, total_loss = 40.734, pg_loss = 24.871, baseline_loss = 31.751, entropy_loss = -15.889, learner_queue_size = 64, _tick = 297, _time = 1.6548e+09)
[2022-06-09 13:57:38,914][root][INFO] - Step 2913280 @ 3069.8 SPS. Inference batcher size: 78. Learner queue size: 64. Other stats: (train_seconds = 1021.8, step = 2913280, mean_episode_return = 93.118, mean_episode_step = 2958.8, total_loss = -148.99, pg_loss = -143.15, baseline_loss = 10.482, entropy_loss = -16.321, learner_queue_size = 64, _tick = 300, _time = 1.6548e+09)
[2022-06-09 13:57:43,918][root][INFO] - Step 2928640 @ 3069.5 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1026.9, step = 2928640, mean_episode_return = 13.48, mean_episode_step = 2763.0, total_loss = -19.502, pg_loss = -33.973, baseline_loss = 30.803, entropy_loss = -16.331, learner_queue_size = 64, _tick = 303, _time = 1.6548e+09)
[2022-06-09 13:57:48,923][root][INFO] - Step 2944000 @ 3068.8 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1031.9, step = 2944000, mean_episode_return = -79.797, mean_episode_step = 2610.0, total_loss = 99.054, pg_loss = 88.919, baseline_loss = 26.67, entropy_loss = -16.536, learner_queue_size = 64, _tick = 306, _time = 1.6548e+09)
[2022-06-09 13:57:53,926][root][INFO] - Step 2954240 @ 2046.9 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1036.9, step = 2954240, mean_episode_return = None, mean_episode_step = 2617.5, total_loss = -34.31, pg_loss = -36.807, baseline_loss = 18.648, entropy_loss = -16.151, learner_queue_size = 64, _tick = 306, _time = 1.6548e+09)
[2022-06-09 13:57:58,930][root][INFO] - Step 2969600 @ 3069.4 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1041.9, step = 2969600, mean_episode_return = 14.72, mean_episode_step = 2790.7, total_loss = -214.48, pg_loss = -200.76, baseline_loss = 2.4529, entropy_loss = -16.174, learner_queue_size = 64, _tick = 309, _time = 1.6548e+09)
[2022-06-09 13:58:03,934][root][INFO] - Step 2984960 @ 3069.7 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1046.9, step = 2984960, mean_episode_return = -1.8431, mean_episode_step = 2879.2, total_loss = -40.241, pg_loss = -58.895, baseline_loss = 34.521, entropy_loss = -15.867, learner_queue_size = 64, _tick = 312, _time = 1.6548e+09)
[2022-06-09 13:58:08,938][root][INFO] - Step 3000320 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1051.9, step = 3000320, mean_episode_return = None, mean_episode_step = 2400.4, total_loss = -58.88, pg_loss = -71.323, baseline_loss = 28.542, entropy_loss = -16.099, learner_queue_size = 64, _tick = 313, _time = 1.6548e+09)
[2022-06-09 13:58:13,942][root][INFO] - Step 3015680 @ 3069.6 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 1056.9, step = 3015680, mean_episode_return = None, mean_episode_step = 2691.9, total_loss = -120.11, pg_loss = -125.92, baseline_loss = 21.437, entropy_loss = -15.626, learner_queue_size = 64, _tick = 314, _time = 1.6548e+09)
[2022-06-09 13:58:18,946][root][INFO] - Step 3031040 @ 3069.5 SPS. Inference batcher size: 11. Learner queue size: 64. Other stats: (train_seconds = 1061.9, step = 3031040, mean_episode_return = -10.527, mean_episode_step = 2709.2, total_loss = -77.293, pg_loss = -102.44, baseline_loss = 40.68, entropy_loss = -15.534, learner_queue_size = 64, _tick = 317, _time = 1.6548e+09)
[2022-06-09 13:58:23,950][root][INFO] - Step 3046400 @ 3069.5 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 1066.9, step = 3046400, mean_episode_return = -11.66, mean_episode_step = 2784.3, total_loss = 120.31, pg_loss = 105.75, baseline_loss = 30.307, entropy_loss = -15.748, learner_queue_size = 64, _tick = 319, _time = 1.6548e+09)
[2022-06-09 13:58:28,954][root][INFO] - Step 3056640 @ 2046.4 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1071.9, step = 3056640, mean_episode_return = -13.64, mean_episode_step = 2465.7, total_loss = -197.43, pg_loss = -194.31, baseline_loss = 12.536, entropy_loss = -15.654, learner_queue_size = 64, _tick = 321, _time = 1.6548e+09)
[2022-06-09 13:58:33,966][root][INFO] - Step 3072000 @ 3064.6 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1076.9, step = 3072000, mean_episode_return = 41.35, mean_episode_step = 2335.2, total_loss = -0.046954, pg_loss = -22.907, baseline_loss = 38.224, entropy_loss = -15.364, learner_queue_size = 64, _tick = 324, _time = 1.6548e+09)
[2022-06-09 13:58:38,970][root][INFO] - Step 3087360 @ 3069.5 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1081.9, step = 3087360, mean_episode_return = None, mean_episode_step = 2572.6, total_loss = 513.22, pg_loss = 417.5, baseline_loss = 111.06, entropy_loss = -15.343, learner_queue_size = 64, _tick = 324, _time = 1.6548e+09)
[2022-06-09 13:58:43,978][root][INFO] - Step 3102720 @ 3066.8 SPS. Inference batcher size: 80. Learner queue size: 64. Other stats: (train_seconds = 1086.9, step = 3102720, mean_episode_return = -6.6001, mean_episode_step = 2616.2, total_loss = 231.63, pg_loss = 181.74, baseline_loss = 64.891, entropy_loss = -15.007, learner_queue_size = 64, _tick = 326, _time = 1.6548e+09)
[2022-06-09 13:58:48,982][root][INFO] - Step 3118080 @ 3069.6 SPS. Inference batcher size: 5. Learner queue size: 64. Other stats: (train_seconds = 1091.9, step = 3118080, mean_episode_return = None, mean_episode_step = 2743.4, total_loss = 123.18, pg_loss = 84.641, baseline_loss = 53.717, entropy_loss = -15.18, learner_queue_size = 64, _tick = 328, _time = 1.6548e+09)
[2022-06-09 13:58:53,986][root][INFO] - Step 3133440 @ 3069.7 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 1096.9, step = 3133440, mean_episode_return = 25.09, mean_episode_step = 2845.4, total_loss = 50.667, pg_loss = 35.422, baseline_loss = 29.197, entropy_loss = -13.952, learner_queue_size = 64, _tick = 331, _time = 1.6548e+09)
[2022-06-09 13:58:58,990][root][INFO] - Step 3148800 @ 3069.3 SPS. Inference batcher size: 9. Learner queue size: 64. Other stats: (train_seconds = 1101.9, step = 3148800, mean_episode_return = -59.949, mean_episode_step = 2260.8, total_loss = -41.136, pg_loss = -70.838, baseline_loss = 43.554, entropy_loss = -13.852, learner_queue_size = 64, _tick = 334, _time = 1.6548e+09)
[2022-06-09 13:59:03,994][root][INFO] - Step 3159040 @ 2046.6 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1106.9, step = 3159040, mean_episode_return = None, mean_episode_step = 3178.6, total_loss = -56.079, pg_loss = -53.649, baseline_loss = 11.083, entropy_loss = -13.513, learner_queue_size = 64, _tick = 335, _time = 1.6548e+09)
[2022-06-09 13:59:08,998][root][INFO] - Step 3174400 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 1111.9, step = 3174400, mean_episode_return = 42.581, mean_episode_step = 3045.9, total_loss = -82.796, pg_loss = -99.387, baseline_loss = 30.404, entropy_loss = -13.813, learner_queue_size = 64, _tick = 336, _time = 1.6548e+09)
[2022-06-09 13:59:14,002][root][INFO] - Step 3189760 @ 3069.6 SPS. Inference batcher size: 73. Learner queue size: 64. Other stats: (train_seconds = 1116.9, step = 3189760, mean_episode_return = None, mean_episode_step = 2218.6, total_loss = -11.823, pg_loss = -40.099, baseline_loss = 42.102, entropy_loss = -13.826, learner_queue_size = 64, _tick = 338, _time = 1.6548e+09)
[2022-06-09 13:59:19,006][root][INFO] - Step 3205120 @ 3069.6 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 1121.9, step = 3205120, mean_episode_return = 19.461, mean_episode_step = 2583.3, total_loss = -271.36, pg_loss = -304.07, baseline_loss = 47.259, entropy_loss = -14.546, learner_queue_size = 64, _tick = 340, _time = 1.6548e+09)
[2022-06-09 13:59:24,010][root][INFO] - Step 3220480 @ 3069.4 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1126.9, step = 3220480, mean_episode_return = 19.925, mean_episode_step = 3037.9, total_loss = 215.63, pg_loss = 131.67, baseline_loss = 98.751, entropy_loss = -14.794, learner_queue_size = 64, _tick = 342, _time = 1.6548e+09)
[2022-06-09 13:59:29,014][root][INFO] - Step 3235840 @ 3069.6 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 1131.9, step = 3235840, mean_episode_return = 5.1499, mean_episode_step = 2077.1, total_loss = -85.511, pg_loss = -97.14, baseline_loss = 25.099, entropy_loss = -13.47, learner_queue_size = 64, _tick = 344, _time = 1.6548e+09)
[2022-06-09 13:59:34,018][root][INFO] - Step 3251200 @ 3069.6 SPS. Inference batcher size: 84. Learner queue size: 64. Other stats: (train_seconds = 1137.0, step = 3251200, mean_episode_return = 30.38, mean_episode_step = 2240.0, total_loss = 211.76, pg_loss = 116.73, baseline_loss = 108.75, entropy_loss = -13.719, learner_queue_size = 64, _tick = 346, _time = 1.6548e+09)
[2022-06-09 13:59:39,022][root][INFO] - Step 3261440 @ 2046.3 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1142.0, step = 3261440, mean_episode_return = None, mean_episode_step = 2257.6, total_loss = 163.19, pg_loss = 94.032, baseline_loss = 82.746, entropy_loss = -13.593, learner_queue_size = 64, _tick = 347, _time = 1.6548e+09)
[2022-06-09 13:59:44,026][root][INFO] - Step 3276800 @ 3069.6 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1147.0, step = 3276800, mean_episode_return = 2.7397, mean_episode_step = 2598.8, total_loss = 83.43, pg_loss = 33.916, baseline_loss = 62.27, entropy_loss = -12.755, learner_queue_size = 64, _tick = 350, _time = 1.6548e+09)
[2022-06-09 13:59:49,030][root][INFO] - Step 3292160 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1152.0, step = 3292160, mean_episode_return = None, mean_episode_step = 2539.9, total_loss = -161.38, pg_loss = -151.96, baseline_loss = 2.7328, entropy_loss = -12.147, learner_queue_size = 64, _tick = 352, _time = 1.6548e+09)
[2022-06-09 13:59:54,034][root][INFO] - Step 3307520 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1157.0, step = 3307520, mean_episode_return = -26.929, mean_episode_step = 2739.7, total_loss = 73.949, pg_loss = 38.192, baseline_loss = 48.036, entropy_loss = -12.28, learner_queue_size = 64, _tick = 354, _time = 1.6548e+09)
[2022-06-09 13:59:59,038][root][INFO] - Step 3322880 @ 3069.4 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 1162.0, step = 3322880, mean_episode_return = 24.477, mean_episode_step = 2157.1, total_loss = -104.32, pg_loss = -130.21, baseline_loss = 38.165, entropy_loss = -12.275, learner_queue_size = 64, _tick = 357, _time = 1.6548e+09)
[2022-06-09 14:00:04,042][root][INFO] - Step 3338240 @ 3069.8 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1167.0, step = 3338240, mean_episode_return = None, mean_episode_step = 2448.7, total_loss = 94.54, pg_loss = 59.676, baseline_loss = 47.627, entropy_loss = -12.763, learner_queue_size = 64, _tick = 359, _time = 1.6548e+09)
[2022-06-09 14:00:09,046][root][INFO] - Step 3353600 @ 3069.6 SPS. Inference batcher size: 68. Learner queue size: 64. Other stats: (train_seconds = 1172.0, step = 3353600, mean_episode_return = None, mean_episode_step = 3024.0, total_loss = -95.397, pg_loss = -109.36, baseline_loss = 27.062, entropy_loss = -13.103, learner_queue_size = 64, _tick = 360, _time = 1.6548e+09)
[2022-06-09 14:00:14,050][root][INFO] - Step 3363840 @ 2046.4 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 1177.0, step = 3363840, mean_episode_return = 88.39, mean_episode_step = 2703.9, total_loss = 30.658, pg_loss = 5.9335, baseline_loss = 37.327, entropy_loss = -12.603, learner_queue_size = 64, _tick = 362, _time = 1.6548e+09)
[2022-06-09 14:00:19,054][root][INFO] - Step 3379200 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1182.0, step = 3379200, mean_episode_return = 29.48, mean_episode_step = 2238.9, total_loss = 303.11, pg_loss = 90.94, baseline_loss = 225.5, entropy_loss = -13.334, learner_queue_size = 64, _tick = 364, _time = 1.6548e+09)
[2022-06-09 14:00:24,062][root][INFO] - Step 3394560 @ 3066.8 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 1187.0, step = 3394560, mean_episode_return = None, mean_episode_step = 2741.8, total_loss = -21.154, pg_loss = -29.393, baseline_loss = 20.959, entropy_loss = -12.719, learner_queue_size = 64, _tick = 365, _time = 1.6548e+09)
[2022-06-09 14:00:29,066][root][INFO] - Step 3409920 @ 3069.8 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 1192.0, step = 3409920, mean_episode_return = 20.8, mean_episode_step = 2244.3, total_loss = 35.667, pg_loss = -0.14199, baseline_loss = 47.655, entropy_loss = -11.847, learner_queue_size = 64, _tick = 368, _time = 1.6548e+09)
[2022-06-09 14:00:34,070][root][INFO] - Step 3425280 @ 3069.5 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 1197.0, step = 3425280, mean_episode_return = None, mean_episode_step = 2447.4, total_loss = 66.061, pg_loss = 29.262, baseline_loss = 49.194, entropy_loss = -12.396, learner_queue_size = 64, _tick = 369, _time = 1.6548e+09)
[2022-06-09 14:00:39,074][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 14:00:39,308][root][INFO] - Step 3435520 @ 2046.4 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1202.0, step = 3435520, mean_episode_return = None, mean_episode_step = 2508.7, total_loss = 18.461, pg_loss = 11.794, baseline_loss = 18.174, entropy_loss = -11.507, learner_queue_size = 64, _tick = 370, _time = 1.6548e+09)
[2022-06-09 14:00:44,314][root][INFO] - Step 3450880 @ 2931.3 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 1207.2, step = 3450880, mean_episode_return = 49.761, mean_episode_step = 2628.8, total_loss = 206.48, pg_loss = 131.0, baseline_loss = 86.845, entropy_loss = -11.364, learner_queue_size = 64, _tick = 373, _time = 1.6548e+09)
[2022-06-09 14:00:49,318][root][INFO] - Step 3466240 @ 3069.6 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 1212.3, step = 3466240, mean_episode_return = -14.44, mean_episode_step = 2664.9, total_loss = 283.7, pg_loss = 184.58, baseline_loss = 111.45, entropy_loss = -12.334, learner_queue_size = 64, _tick = 376, _time = 1.6548e+09)
[2022-06-09 14:00:54,322][root][INFO] - Step 3481600 @ 3069.4 SPS. Inference batcher size: 80. Learner queue size: 64. Other stats: (train_seconds = 1217.3, step = 3481600, mean_episode_return = 2.9595, mean_episode_step = 2549.1, total_loss = -1.5657, pg_loss = -46.665, baseline_loss = 57.285, entropy_loss = -12.185, learner_queue_size = 64, _tick = 379, _time = 1.6548e+09)
[2022-06-09 14:00:59,326][root][INFO] - Step 3491840 @ 2046.4 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 1222.3, step = 3491840, mean_episode_return = None, mean_episode_step = 2379.8, total_loss = 188.8, pg_loss = 134.36, baseline_loss = 66.039, entropy_loss = -11.597, learner_queue_size = 64, _tick = 380, _time = 1.6548e+09)
[2022-06-09 14:01:04,330][root][INFO] - Step 3507200 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1227.3, step = 3507200, mean_episode_return = 30.066, mean_episode_step = 2219.5, total_loss = 155.18, pg_loss = 37.138, baseline_loss = 130.09, entropy_loss = -12.044, learner_queue_size = 64, _tick = 383, _time = 1.6548e+09)
[2022-06-09 14:01:09,334][root][INFO] - Step 3522560 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1232.3, step = 3522560, mean_episode_return = -43.139, mean_episode_step = 2911.4, total_loss = 232.7, pg_loss = 133.14, baseline_loss = 111.24, entropy_loss = -11.679, learner_queue_size = 64, _tick = 384, _time = 1.6548e+09)
[2022-06-09 14:01:14,338][root][INFO] - Step 3537920 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1237.3, step = 3537920, mean_episode_return = None, mean_episode_step = 3046.2, total_loss = -43.395, pg_loss = -62.838, baseline_loss = 31.131, entropy_loss = -11.688, learner_queue_size = 64, _tick = 385, _time = 1.6548e+09)
[2022-06-09 14:01:19,342][root][INFO] - Step 3553280 @ 3069.6 SPS. Inference batcher size: 91. Learner queue size: 64. Other stats: (train_seconds = 1242.3, step = 3553280, mean_episode_return = 55.049, mean_episode_step = 2822.2, total_loss = 11.365, pg_loss = -33.824, baseline_loss = 56.894, entropy_loss = -11.705, learner_queue_size = 64, _tick = 388, _time = 1.6548e+09)
[2022-06-09 14:01:24,348][root][INFO] - Step 3568640 @ 3068.2 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 1247.3, step = 3568640, mean_episode_return = 26.136, mean_episode_step = 2624.2, total_loss = -141.49, pg_loss = -147.35, baseline_loss = 16.444, entropy_loss = -10.581, learner_queue_size = 64, _tick = 391, _time = 1.6548e+09)
[2022-06-09 14:01:29,354][root][INFO] - Step 3584000 @ 3068.3 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 1252.3, step = 3584000, mean_episode_return = 41.036, mean_episode_step = 2438.1, total_loss = 105.47, pg_loss = 36.53, baseline_loss = 79.357, entropy_loss = -10.421, learner_queue_size = 64, _tick = 393, _time = 1.6548e+09)
[2022-06-09 14:01:34,358][root][INFO] - Step 3599360 @ 3069.6 SPS. Inference batcher size: 81. Learner queue size: 64. Other stats: (train_seconds = 1257.3, step = 3599360, mean_episode_return = 48.612, mean_episode_step = 2667.5, total_loss = 31.628, pg_loss = -20.235, baseline_loss = 62.585, entropy_loss = -10.722, learner_queue_size = 64, _tick = 396, _time = 1.6548e+09)
[2022-06-09 14:01:39,362][root][INFO] - Step 3609600 @ 2046.3 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1262.3, step = 3609600, mean_episode_return = 8.5549, mean_episode_step = 2645.4, total_loss = -90.481, pg_loss = -93.531, baseline_loss = 14.174, entropy_loss = -11.124, learner_queue_size = 64, _tick = 398, _time = 1.6548e+09)
[2022-06-09 14:01:44,366][root][INFO] - Step 3624960 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1267.3, step = 3624960, mean_episode_return = None, mean_episode_step = 2708.4, total_loss = -144.37, pg_loss = -135.04, baseline_loss = 1.5853, entropy_loss = -10.923, learner_queue_size = 64, _tick = 400, _time = 1.6548e+09)
[2022-06-09 14:01:49,370][root][INFO] - Step 3640320 @ 3069.5 SPS. Inference batcher size: 4. Learner queue size: 64. Other stats: (train_seconds = 1272.3, step = 3640320, mean_episode_return = 39.251, mean_episode_step = 3241.4, total_loss = 51.845, pg_loss = 31.643, baseline_loss = 30.831, entropy_loss = -10.628, learner_queue_size = 64, _tick = 403, _time = 1.6548e+09)
[2022-06-09 14:01:54,374][root][INFO] - Step 3650560 @ 2046.3 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1277.3, step = 3650560, mean_episode_return = -22.141, mean_episode_step = 2536.6, total_loss = 107.99, pg_loss = 53.05, baseline_loss = 66.544, entropy_loss = -11.6, learner_queue_size = 64, _tick = 405, _time = 1.6548e+09)
[2022-06-09 14:01:59,378][root][INFO] - Step 3665920 @ 3069.6 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1282.3, step = 3665920, mean_episode_return = 45.19, mean_episode_step = 2634.3, total_loss = 91.111, pg_loss = 51.6, baseline_loss = 50.841, entropy_loss = -11.331, learner_queue_size = 64, _tick = 408, _time = 1.6548e+09)
[2022-06-09 14:02:04,382][root][INFO] - Step 3681280 @ 3069.5 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 1287.3, step = 3681280, mean_episode_return = 45.546, mean_episode_step = 3411.5, total_loss = 184.06, pg_loss = 124.54, baseline_loss = 71.002, entropy_loss = -11.477, learner_queue_size = 64, _tick = 410, _time = 1.6548e+09)
[2022-06-09 14:02:09,386][root][INFO] - Step 3696640 @ 3069.5 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 1292.3, step = 3696640, mean_episode_return = None, mean_episode_step = 2473.0, total_loss = -39.325, pg_loss = -56.161, baseline_loss = 28.706, entropy_loss = -11.871, learner_queue_size = 64, _tick = 411, _time = 1.6548e+09)
[2022-06-09 14:02:14,390][root][INFO] - Step 3712000 @ 3069.6 SPS. Inference batcher size: 74. Learner queue size: 64. Other stats: (train_seconds = 1297.3, step = 3712000, mean_episode_return = 23.305, mean_episode_step = 3401.4, total_loss = -182.21, pg_loss = -195.36, baseline_loss = 25.244, entropy_loss = -12.091, learner_queue_size = 64, _tick = 412, _time = 1.6548e+09)
[2022-06-09 14:02:19,394][root][INFO] - Step 3727360 @ 3069.6 SPS. Inference batcher size: 86. Learner queue size: 64. Other stats: (train_seconds = 1302.3, step = 3727360, mean_episode_return = 58.454, mean_episode_step = 2696.3, total_loss = -106.09, pg_loss = -107.09, baseline_loss = 13.248, entropy_loss = -12.248, learner_queue_size = 64, _tick = 415, _time = 1.6548e+09)
[2022-06-09 14:02:24,398][root][INFO] - Step 3737600 @ 2046.3 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1307.3, step = 3737600, mean_episode_return = 63.965, mean_episode_step = 3056.5, total_loss = 81.681, pg_loss = 37.74, baseline_loss = 56.137, entropy_loss = -12.196, learner_queue_size = 64, _tick = 417, _time = 1.6548e+09)
[2022-06-09 14:02:29,404][root][INFO] - Step 3752960 @ 3068.3 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1312.3, step = 3752960, mean_episode_return = None, mean_episode_step = 2611.1, total_loss = 99.44, pg_loss = 74.593, baseline_loss = 36.651, entropy_loss = -11.803, learner_queue_size = 64, _tick = 419, _time = 1.6548e+09)
[2022-06-09 14:02:34,410][root][INFO] - Step 3768320 @ 3068.3 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 1317.3, step = 3768320, mean_episode_return = 24.86, mean_episode_step = 2717.0, total_loss = 23.237, pg_loss = -28.22, baseline_loss = 63.799, entropy_loss = -12.342, learner_queue_size = 64, _tick = 420, _time = 1.6548e+09)
[2022-06-09 14:02:39,414][root][INFO] - Step 3783680 @ 3069.4 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1322.4, step = 3783680, mean_episode_return = 35.18, mean_episode_step = 2594.3, total_loss = -33.235, pg_loss = -66.281, baseline_loss = 45.225, entropy_loss = -12.18, learner_queue_size = 64, _tick = 423, _time = 1.6548e+09)
[2022-06-09 14:02:44,418][root][INFO] - Step 3799040 @ 3069.9 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 1327.4, step = 3799040, mean_episode_return = None, mean_episode_step = 2897.2, total_loss = 413.84, pg_loss = 319.48, baseline_loss = 106.43, entropy_loss = -12.076, learner_queue_size = 64, _tick = 425, _time = 1.6548e+09)
[2022-06-09 14:02:49,423][root][INFO] - Step 3814400 @ 3068.8 SPS. Inference batcher size: 85. Learner queue size: 64. Other stats: (train_seconds = 1332.4, step = 3814400, mean_episode_return = 19.644, mean_episode_step = 2843.6, total_loss = 11.204, pg_loss = -27.743, baseline_loss = 50.706, entropy_loss = -11.759, learner_queue_size = 64, _tick = 428, _time = 1.6548e+09)
[2022-06-09 14:02:54,428][root][INFO] - Step 3824640 @ 2045.9 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1337.4, step = 3824640, mean_episode_return = None, mean_episode_step = 2225.9, total_loss = 236.06, pg_loss = 187.62, baseline_loss = 59.71, entropy_loss = -11.274, learner_queue_size = 64, _tick = 429, _time = 1.6548e+09)
[2022-06-09 14:02:59,434][root][INFO] - Step 3840000 @ 3068.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1342.4, step = 3840000, mean_episode_return = 44.998, mean_episode_step = 2126.5, total_loss = -88.101, pg_loss = -94.423, baseline_loss = 17.696, entropy_loss = -11.375, learner_queue_size = 64, _tick = 432, _time = 1.6548e+09)
[2022-06-09 14:03:04,438][root][INFO] - Step 3855360 @ 3069.5 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 1347.4, step = 3855360, mean_episode_return = 69.53, mean_episode_step = 2495.2, total_loss = -156.15, pg_loss = -148.02, baseline_loss = 3.3217, entropy_loss = -11.448, learner_queue_size = 64, _tick = 435, _time = 1.6548e+09)
[2022-06-09 14:03:09,442][root][INFO] - Step 3870720 @ 3069.5 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 1352.4, step = 3870720, mean_episode_return = None, mean_episode_step = 2527.7, total_loss = 181.91, pg_loss = 126.34, baseline_loss = 66.837, entropy_loss = -11.271, learner_queue_size = 64, _tick = 436, _time = 1.6548e+09)
[2022-06-09 14:03:14,446][root][INFO] - Step 3886080 @ 3069.5 SPS. Inference batcher size: 72. Learner queue size: 64. Other stats: (train_seconds = 1357.4, step = 3886080, mean_episode_return = None, mean_episode_step = 2861.7, total_loss = 146.03, pg_loss = 70.277, baseline_loss = 87.413, entropy_loss = -11.663, learner_queue_size = 64, _tick = 438, _time = 1.6548e+09)
[2022-06-09 14:03:19,450][root][INFO] - Step 3901440 @ 3069.6 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1362.4, step = 3901440, mean_episode_return = None, mean_episode_step = 2878.5, total_loss = 45.373, pg_loss = 29.488, baseline_loss = 27.839, entropy_loss = -11.955, learner_queue_size = 64, _tick = 440, _time = 1.6548e+09)
[2022-06-09 14:03:24,454][root][INFO] - Step 3911680 @ 2046.3 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1367.4, step = 3911680, mean_episode_return = 20.72, mean_episode_step = 2624.3, total_loss = 95.832, pg_loss = 55.515, baseline_loss = 52.337, entropy_loss = -12.021, learner_queue_size = 64, _tick = 442, _time = 1.6548e+09)
[2022-06-09 14:03:29,458][root][INFO] - Step 3927040 @ 3069.6 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 1372.4, step = 3927040, mean_episode_return = None, mean_episode_step = 2776.8, total_loss = 148.23, pg_loss = 96.154, baseline_loss = 64.043, entropy_loss = -11.968, learner_queue_size = 64, _tick = 444, _time = 1.6548e+09)
[2022-06-09 14:03:34,462][root][INFO] - Step 3942400 @ 3069.5 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 1377.4, step = 3942400, mean_episode_return = -9.4904, mean_episode_step = 2890.0, total_loss = -94.566, pg_loss = -108.75, baseline_loss = 26.095, entropy_loss = -11.914, learner_queue_size = 64, _tick = 447, _time = 1.6548e+09)
[2022-06-09 14:03:39,466][root][INFO] - Step 3957760 @ 3069.6 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 1382.4, step = 3957760, mean_episode_return = 21.38, mean_episode_step = 2282.8, total_loss = -186.74, pg_loss = -186.17, baseline_loss = 11.253, entropy_loss = -11.825, learner_queue_size = 64, _tick = 450, _time = 1.6548e+09)
[2022-06-09 14:03:44,470][root][INFO] - Step 3973120 @ 3069.5 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 1387.4, step = 3973120, mean_episode_return = 3.6516, mean_episode_step = 2801.5, total_loss = 148.45, pg_loss = 88.808, baseline_loss = 71.271, entropy_loss = -11.629, learner_queue_size = 64, _tick = 453, _time = 1.6548e+09)
[2022-06-09 14:03:49,474][root][INFO] - Step 3988480 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1392.4, step = 3988480, mean_episode_return = None, mean_episode_step = 2671.5, total_loss = 203.03, pg_loss = 153.53, baseline_loss = 61.69, entropy_loss = -12.19, learner_queue_size = 64, _tick = 454, _time = 1.6548e+09)
[2022-06-09 14:03:54,478][root][INFO] - Step 4003840 @ 3069.5 SPS. Inference batcher size: 73. Learner queue size: 64. Other stats: (train_seconds = 1397.4, step = 4003840, mean_episode_return = None, mean_episode_step = 2193.7, total_loss = 159.61, pg_loss = 101.53, baseline_loss = 70.353, entropy_loss = -12.278, learner_queue_size = 64, _tick = 455, _time = 1.6548e+09)
[2022-06-09 14:03:59,482][root][INFO] - Step 4014080 @ 2046.3 SPS. Inference batcher size: 18. Learner queue size: 64. Other stats: (train_seconds = 1402.4, step = 4014080, mean_episode_return = 25.895, mean_episode_step = 2659.4, total_loss = -91.558, pg_loss = -143.53, baseline_loss = 64.216, entropy_loss = -12.245, learner_queue_size = 64, _tick = 457, _time = 1.6548e+09)
[2022-06-09 14:04:04,487][root][INFO] - Step 4029440 @ 3069.2 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1407.4, step = 4029440, mean_episode_return = -57.919, mean_episode_step = 2660.2, total_loss = 187.3, pg_loss = 99.601, baseline_loss = 99.886, entropy_loss = -12.189, learner_queue_size = 64, _tick = 460, _time = 1.6548e+09)
[2022-06-09 14:04:09,490][root][INFO] - Step 4044800 @ 3069.9 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1412.4, step = 4044800, mean_episode_return = 25.49, mean_episode_step = 2420.6, total_loss = 93.334, pg_loss = 49.332, baseline_loss = 55.934, entropy_loss = -11.932, learner_queue_size = 64, _tick = 463, _time = 1.6548e+09)
[2022-06-09 14:04:14,494][root][INFO] - Step 4060160 @ 3069.6 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1417.4, step = 4060160, mean_episode_return = 15.229, mean_episode_step = 2425.7, total_loss = -46.271, pg_loss = -50.373, baseline_loss = 16.052, entropy_loss = -11.95, learner_queue_size = 64, _tick = 464, _time = 1.6548e+09)
[2022-06-09 14:04:19,498][root][INFO] - Step 4075520 @ 3069.5 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1422.4, step = 4075520, mean_episode_return = 69.723, mean_episode_step = 2354.3, total_loss = 48.074, pg_loss = 29.461, baseline_loss = 30.859, entropy_loss = -12.247, learner_queue_size = 64, _tick = 466, _time = 1.6548e+09)
[2022-06-09 14:04:24,502][root][INFO] - Step 4090880 @ 3069.5 SPS. Inference batcher size: 74. Learner queue size: 64. Other stats: (train_seconds = 1427.4, step = 4090880, mean_episode_return = None, mean_episode_step = 2653.0, total_loss = 152.37, pg_loss = 106.11, baseline_loss = 58.94, entropy_loss = -12.681, learner_queue_size = 64, _tick = 468, _time = 1.6548e+09)
[2022-06-09 14:04:29,506][root][INFO] - Step 4101120 @ 2046.3 SPS. Inference batcher size: 6. Learner queue size: 64. Other stats: (train_seconds = 1432.4, step = 4101120, mean_episode_return = 37.664, mean_episode_step = 2885.6, total_loss = 19.147, pg_loss = -12.353, baseline_loss = 44.233, entropy_loss = -12.734, learner_queue_size = 64, _tick = 469, _time = 1.6548e+09)
[2022-06-09 14:04:34,510][root][INFO] - Step 4116480 @ 3069.6 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 1437.4, step = 4116480, mean_episode_return = 23.217, mean_episode_step = 2731.4, total_loss = -110.16, pg_loss = -125.36, baseline_loss = 27.708, entropy_loss = -12.507, learner_queue_size = 64, _tick = 472, _time = 1.6548e+09)
[2022-06-09 14:04:39,514][root][INFO] - Step 4131840 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1442.5, step = 4131840, mean_episode_return = 18.535, mean_episode_step = 2680.3, total_loss = 204.31, pg_loss = 141.61, baseline_loss = 75.153, entropy_loss = -12.45, learner_queue_size = 64, _tick = 475, _time = 1.6548e+09)
[2022-06-09 14:04:44,518][root][INFO] - Step 4147200 @ 3069.6 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 1447.5, step = 4147200, mean_episode_return = None, mean_episode_step = 2841.4, total_loss = 212.58, pg_loss = 160.88, baseline_loss = 64.674, entropy_loss = -12.965, learner_queue_size = 64, _tick = 477, _time = 1.6548e+09)
[2022-06-09 14:04:49,522][root][INFO] - Step 4157440 @ 2046.4 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1452.5, step = 4157440, mean_episode_return = 3.2495, mean_episode_step = 2634.8, total_loss = 193.35, pg_loss = 123.63, baseline_loss = 82.946, entropy_loss = -13.222, learner_queue_size = 64, _tick = 479, _time = 1.6548e+09)
[2022-06-09 14:04:54,526][root][INFO] - Step 4172800 @ 3069.6 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1457.5, step = 4172800, mean_episode_return = 82.528, mean_episode_step = 2228.0, total_loss = -101.26, pg_loss = -120.13, baseline_loss = 32.118, entropy_loss = -13.249, learner_queue_size = 64, _tick = 482, _time = 1.6548e+09)
[2022-06-09 14:04:59,530][root][INFO] - Step 4188160 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1462.5, step = 4188160, mean_episode_return = 10.94, mean_episode_step = 2025.3, total_loss = 301.3, pg_loss = 239.62, baseline_loss = 75.011, entropy_loss = -13.327, learner_queue_size = 64, _tick = 485, _time = 1.6548e+09)
[2022-06-09 14:05:04,534][root][INFO] - Step 4198400 @ 2046.4 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1467.5, step = 4198400, mean_episode_return = 15.785, mean_episode_step = 2141.1, total_loss = 141.18, pg_loss = 78.216, baseline_loss = 76.348, entropy_loss = -13.387, learner_queue_size = 64, _tick = 487, _time = 1.6548e+09)
[2022-06-09 14:05:09,538][root][INFO] - Step 4213760 @ 3069.1 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1472.5, step = 4213760, mean_episode_return = 38.13, mean_episode_step = 1798.3, total_loss = -99.281, pg_loss = -108.4, baseline_loss = 21.758, entropy_loss = -12.638, learner_queue_size = 64, _tick = 490, _time = 1.6548e+09)
[2022-06-09 14:05:14,542][root][INFO] - Step 4224000 @ 2046.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1477.5, step = 4224000, mean_episode_return = 55.641, mean_episode_step = 2510.5, total_loss = 1.5886, pg_loss = -32.458, baseline_loss = 46.714, entropy_loss = -12.667, learner_queue_size = 64, _tick = 492, _time = 1.6548e+09)
[2022-06-09 14:05:19,548][root][INFO] - Step 4239360 @ 3068.0 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1482.5, step = 4239360, mean_episode_return = 68.052, mean_episode_step = 1926.7, total_loss = 91.126, pg_loss = 33.831, baseline_loss = 69.845, entropy_loss = -12.55, learner_queue_size = 64, _tick = 494, _time = 1.6548e+09)
[2022-06-09 14:05:24,554][root][INFO] - Step 4254720 @ 3068.7 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1487.5, step = 4254720, mean_episode_return = None, mean_episode_step = 2202.1, total_loss = 451.1, pg_loss = 351.46, baseline_loss = 112.57, entropy_loss = -12.934, learner_queue_size = 64, _tick = 496, _time = 1.6548e+09)
[2022-06-09 14:05:29,558][root][INFO] - Step 4270080 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1492.5, step = 4270080, mean_episode_return = 77.859, mean_episode_step = 2354.8, total_loss = 185.0, pg_loss = 80.306, baseline_loss = 117.57, entropy_loss = -12.877, learner_queue_size = 64, _tick = 498, _time = 1.6548e+09)
[2022-06-09 14:05:34,562][root][INFO] - Step 4285440 @ 3069.4 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 1497.5, step = 4285440, mean_episode_return = 39.123, mean_episode_step = 1954.1, total_loss = -121.42, pg_loss = -144.68, baseline_loss = 36.148, entropy_loss = -12.889, learner_queue_size = 64, _tick = 500, _time = 1.6548e+09)
[2022-06-09 14:05:39,570][root][INFO] - Step 4300800 @ 3067.2 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1502.5, step = 4300800, mean_episode_return = 6.1455, mean_episode_step = 2592.2, total_loss = 303.04, pg_loss = 222.08, baseline_loss = 93.953, entropy_loss = -12.988, learner_queue_size = 64, _tick = 502, _time = 1.6548e+09)
[2022-06-09 14:05:44,574][root][INFO] - Step 4311040 @ 2046.4 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1507.5, step = 4311040, mean_episode_return = -10.76, mean_episode_step = 2247.5, total_loss = 167.34, pg_loss = 125.56, baseline_loss = 54.773, entropy_loss = -12.998, learner_queue_size = 64, _tick = 504, _time = 1.6548e+09)
[2022-06-09 14:05:49,578][root][INFO] - Step 4326400 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1512.5, step = 4326400, mean_episode_return = 30.183, mean_episode_step = 1814.7, total_loss = 119.2, pg_loss = 61.183, baseline_loss = 70.96, entropy_loss = -12.946, learner_queue_size = 64, _tick = 505, _time = 1.6548e+09)
[2022-06-09 14:05:54,582][root][INFO] - Step 4341760 @ 3069.5 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 1517.5, step = 4341760, mean_episode_return = None, mean_episode_step = 2112.9, total_loss = -66.485, pg_loss = -77.359, baseline_loss = 23.502, entropy_loss = -12.628, learner_queue_size = 64, _tick = 507, _time = 1.6548e+09)
[2022-06-09 14:05:59,586][root][INFO] - Step 4357120 @ 3069.5 SPS. Inference batcher size: 68. Learner queue size: 64. Other stats: (train_seconds = 1522.5, step = 4357120, mean_episode_return = 58.648, mean_episode_step = 2445.7, total_loss = -27.952, pg_loss = -95.572, baseline_loss = 80.268, entropy_loss = -12.648, learner_queue_size = 64, _tick = 509, _time = 1.6548e+09)
[2022-06-09 14:06:04,590][root][INFO] - Step 4372480 @ 3069.6 SPS. Inference batcher size: 86. Learner queue size: 64. Other stats: (train_seconds = 1527.5, step = 4372480, mean_episode_return = None, mean_episode_step = 1841.2, total_loss = 144.57, pg_loss = 103.66, baseline_loss = 52.998, entropy_loss = -12.088, learner_queue_size = 64, _tick = 511, _time = 1.6548e+09)
[2022-06-09 14:06:09,594][root][INFO] - Step 4387840 @ 3069.5 SPS. Inference batcher size: 92. Learner queue size: 64. Other stats: (train_seconds = 1532.5, step = 4387840, mean_episode_return = 4.7802, mean_episode_step = 2211.5, total_loss = -171.82, pg_loss = -180.29, baseline_loss = 20.019, entropy_loss = -11.547, learner_queue_size = 64, _tick = 514, _time = 1.6548e+09)
[2022-06-09 14:06:14,598][root][INFO] - Step 4398080 @ 2046.4 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1537.5, step = 4398080, mean_episode_return = 97.21, mean_episode_step = 2277.5, total_loss = 9.0322, pg_loss = -57.181, baseline_loss = 78.216, entropy_loss = -12.003, learner_queue_size = 64, _tick = 516, _time = 1.6548e+09)
[2022-06-09 14:06:19,599][root][INFO] - Step 4408320 @ 2047.6 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1542.5, step = 4408320, mean_episode_return = None, mean_episode_step = 2161.5, total_loss = -78.61, pg_loss = -101.53, baseline_loss = 36.165, entropy_loss = -13.241, learner_queue_size = 64, _tick = 517, _time = 1.6548e+09)
[2022-06-09 14:06:24,602][root][INFO] - Step 4423680 @ 3070.2 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1547.5, step = 4423680, mean_episode_return = 19.718, mean_episode_step = 2601.2, total_loss = -244.58, pg_loss = -254.6, baseline_loss = 21.847, entropy_loss = -11.827, learner_queue_size = 64, _tick = 520, _time = 1.6548e+09)
[2022-06-09 14:06:29,606][root][INFO] - Step 4439040 @ 3069.5 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1552.5, step = 4439040, mean_episode_return = 29.717, mean_episode_step = 2438.8, total_loss = 46.025, pg_loss = 27.185, baseline_loss = 31.027, entropy_loss = -12.187, learner_queue_size = 64, _tick = 522, _time = 1.6548e+09)
[2022-06-09 14:06:34,610][root][INFO] - Step 4454400 @ 3069.5 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 1557.5, step = 4454400, mean_episode_return = 35.886, mean_episode_step = 2082.4, total_loss = 214.87, pg_loss = 157.81, baseline_loss = 68.714, entropy_loss = -11.652, learner_queue_size = 64, _tick = 524, _time = 1.6548e+09)
[2022-06-09 14:06:39,614][root][INFO] - Step 4469760 @ 3069.4 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 1562.6, step = 4469760, mean_episode_return = None, mean_episode_step = 2074.6, total_loss = 134.8, pg_loss = 108.0, baseline_loss = 38.182, entropy_loss = -11.38, learner_queue_size = 64, _tick = 524, _time = 1.6548e+09)
[2022-06-09 14:06:44,618][root][INFO] - Step 4480000 @ 2046.4 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1567.6, step = 4480000, mean_episode_return = 72.828, mean_episode_step = 2453.0, total_loss = -193.57, pg_loss = -199.07, baseline_loss = 17.782, entropy_loss = -12.283, learner_queue_size = 64, _tick = 525, _time = 1.6548e+09)
[2022-06-09 14:06:49,622][root][INFO] - Step 4495360 @ 3069.6 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 1572.6, step = 4495360, mean_episode_return = 81.182, mean_episode_step = 1870.1, total_loss = 160.94, pg_loss = 86.356, baseline_loss = 87.023, entropy_loss = -12.444, learner_queue_size = 64, _tick = 528, _time = 1.6548e+09)
[2022-06-09 14:06:54,626][root][INFO] - Step 4510720 @ 3069.5 SPS. Inference batcher size: 90. Learner queue size: 64. Other stats: (train_seconds = 1577.6, step = 4510720, mean_episode_return = 12.0, mean_episode_step = 2139.9, total_loss = -22.949, pg_loss = -41.502, baseline_loss = 31.666, entropy_loss = -13.113, learner_queue_size = 64, _tick = 530, _time = 1.6548e+09)
[2022-06-09 14:06:59,630][root][INFO] - Step 4526080 @ 3069.6 SPS. Inference batcher size: 88. Learner queue size: 64. Other stats: (train_seconds = 1582.6, step = 4526080, mean_episode_return = 14.266, mean_episode_step = 2327.1, total_loss = -111.29, pg_loss = -115.71, baseline_loss = 17.26, entropy_loss = -12.848, learner_queue_size = 64, _tick = 533, _time = 1.6548e+09)
[2022-06-09 14:07:04,634][root][INFO] - Step 4536320 @ 2046.3 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1587.6, step = 4536320, mean_episode_return = 71.13, mean_episode_step = 2397.2, total_loss = 56.973, pg_loss = 12.383, baseline_loss = 57.297, entropy_loss = -12.708, learner_queue_size = 64, _tick = 534, _time = 1.6548e+09)
[2022-06-09 14:07:09,640][root][INFO] - Step 4551680 @ 3068.2 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 1592.6, step = 4551680, mean_episode_return = 4.8394, mean_episode_step = 2204.4, total_loss = 10.868, pg_loss = -7.5099, baseline_loss = 30.694, entropy_loss = -12.316, learner_queue_size = 64, _tick = 537, _time = 1.6548e+09)
[2022-06-09 14:07:14,646][root][INFO] - Step 4567040 @ 3068.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1597.6, step = 4567040, mean_episode_return = 52.75, mean_episode_step = 2155.5, total_loss = 42.917, pg_loss = 16.459, baseline_loss = 39.122, entropy_loss = -12.663, learner_queue_size = 64, _tick = 540, _time = 1.6548e+09)
[2022-06-09 14:07:19,650][root][INFO] - Step 4577280 @ 2046.4 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1602.6, step = 4577280, mean_episode_return = 21.584, mean_episode_step = 1951.0, total_loss = -112.5, pg_loss = -133.65, baseline_loss = 33.707, entropy_loss = -12.556, learner_queue_size = 64, _tick = 542, _time = 1.6548e+09)
[2022-06-09 14:07:24,654][root][INFO] - Step 4592640 @ 3069.5 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 1607.6, step = 4592640, mean_episode_return = 26.18, mean_episode_step = 1792.0, total_loss = 399.46, pg_loss = 319.14, baseline_loss = 91.873, entropy_loss = -11.546, learner_queue_size = 64, _tick = 545, _time = 1.6548e+09)
[2022-06-09 14:07:29,658][root][INFO] - Step 4608000 @ 3069.5 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 1612.6, step = 4608000, mean_episode_return = 29.592, mean_episode_step = 2400.5, total_loss = -77.938, pg_loss = -93.885, baseline_loss = 28.312, entropy_loss = -12.365, learner_queue_size = 64, _tick = 547, _time = 1.6548e+09)
[2022-06-09 14:07:34,662][root][INFO] - Step 4623360 @ 3069.5 SPS. Inference batcher size: 87. Learner queue size: 64. Other stats: (train_seconds = 1617.6, step = 4623360, mean_episode_return = None, mean_episode_step = 1998.5, total_loss = 206.71, pg_loss = 157.96, baseline_loss = 60.382, entropy_loss = -11.627, learner_queue_size = 64, _tick = 549, _time = 1.6548e+09)
[2022-06-09 14:07:39,666][root][INFO] - Step 4633600 @ 2046.4 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1622.6, step = 4633600, mean_episode_return = 19.306, mean_episode_step = 1646.1, total_loss = -93.535, pg_loss = -121.31, baseline_loss = 38.803, entropy_loss = -11.023, learner_queue_size = 64, _tick = 551, _time = 1.6548e+09)
[2022-06-09 14:07:44,670][root][INFO] - Step 4648960 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1627.6, step = 4648960, mean_episode_return = None, mean_episode_step = 2191.9, total_loss = 2.6914, pg_loss = -24.808, baseline_loss = 38.559, entropy_loss = -11.059, learner_queue_size = 64, _tick = 553, _time = 1.6548e+09)
[2022-06-09 14:07:49,674][root][INFO] - Step 4664320 @ 3069.5 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 1632.6, step = 4664320, mean_episode_return = 60.381, mean_episode_step = 2187.8, total_loss = 128.68, pg_loss = 104.51, baseline_loss = 34.979, entropy_loss = -10.812, learner_queue_size = 64, _tick = 556, _time = 1.6548e+09)
[2022-06-09 14:07:54,678][root][INFO] - Step 4679680 @ 3069.6 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 1637.6, step = 4679680, mean_episode_return = None, mean_episode_step = 2046.3, total_loss = 56.535, pg_loss = 41.01, baseline_loss = 27.146, entropy_loss = -11.621, learner_queue_size = 64, _tick = 558, _time = 1.6548e+09)
[2022-06-09 14:07:59,682][root][INFO] - Step 4695040 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1642.6, step = 4695040, mean_episode_return = 45.117, mean_episode_step = 2258.8, total_loss = 216.84, pg_loss = 124.15, baseline_loss = 104.68, entropy_loss = -12.003, learner_queue_size = 64, _tick = 559, _time = 1.6548e+09)
[2022-06-09 14:08:04,686][root][INFO] - Step 4705280 @ 2046.4 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1647.6, step = 4705280, mean_episode_return = 44.071, mean_episode_step = 2030.3, total_loss = -248.74, pg_loss = -278.59, baseline_loss = 42.214, entropy_loss = -12.364, learner_queue_size = 64, _tick = 561, _time = 1.6548e+09)
[2022-06-09 14:08:09,690][root][INFO] - Step 4720640 @ 3069.5 SPS. Inference batcher size: 95. Learner queue size: 64. Other stats: (train_seconds = 1652.6, step = 4720640, mean_episode_return = 57.777, mean_episode_step = 1993.8, total_loss = -90.855, pg_loss = -101.56, baseline_loss = 22.543, entropy_loss = -11.84, learner_queue_size = 64, _tick = 564, _time = 1.6548e+09)
[2022-06-09 14:08:14,694][root][INFO] - Step 4730880 @ 2046.4 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1657.6, step = 4730880, mean_episode_return = 75.96, mean_episode_step = 1814.0, total_loss = 87.468, pg_loss = 46.929, baseline_loss = 52.537, entropy_loss = -11.999, learner_queue_size = 64, _tick = 565, _time = 1.6548e+09)
[2022-06-09 14:08:19,698][root][INFO] - Step 4746240 @ 3069.5 SPS. Inference batcher size: 78. Learner queue size: 64. Other stats: (train_seconds = 1662.6, step = 4746240, mean_episode_return = 77.889, mean_episode_step = 2032.9, total_loss = 189.18, pg_loss = 145.42, baseline_loss = 54.852, entropy_loss = -11.094, learner_queue_size = 64, _tick = 568, _time = 1.6548e+09)
[2022-06-09 14:08:24,702][root][INFO] - Step 4761600 @ 3069.6 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 1667.6, step = 4761600, mean_episode_return = 106.66, mean_episode_step = 2197.5, total_loss = -42.993, pg_loss = -63.084, baseline_loss = 31.573, entropy_loss = -11.482, learner_queue_size = 64, _tick = 571, _time = 1.6548e+09)
[2022-06-09 14:08:29,706][root][INFO] - Step 4776960 @ 3069.5 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 1672.6, step = 4776960, mean_episode_return = None, mean_episode_step = 1989.4, total_loss = 319.51, pg_loss = 260.82, baseline_loss = 70.058, entropy_loss = -11.369, learner_queue_size = 64, _tick = 573, _time = 1.6548e+09)
[2022-06-09 14:08:34,710][root][INFO] - Step 4792320 @ 3069.6 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1677.6, step = 4792320, mean_episode_return = 28.21, mean_episode_step = 1979.9, total_loss = 78.133, pg_loss = 21.435, baseline_loss = 68.596, entropy_loss = -11.898, learner_queue_size = 64, _tick = 575, _time = 1.6548e+09)
[2022-06-09 14:08:39,714][root][INFO] - Step 4802560 @ 2046.3 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1682.6, step = 4802560, mean_episode_return = 4.31, mean_episode_step = 2118.7, total_loss = -14.658, pg_loss = -31.543, baseline_loss = 28.914, entropy_loss = -12.029, learner_queue_size = 64, _tick = 577, _time = 1.6548e+09)
[2022-06-09 14:08:44,718][root][INFO] - Step 4817920 @ 3069.6 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1687.7, step = 4817920, mean_episode_return = None, mean_episode_step = 2558.6, total_loss = 257.15, pg_loss = 206.95, baseline_loss = 62.351, entropy_loss = -12.156, learner_queue_size = 64, _tick = 579, _time = 1.6548e+09)
[2022-06-09 14:08:49,722][root][INFO] - Step 4833280 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1692.7, step = 4833280, mean_episode_return = None, mean_episode_step = 2430.7, total_loss = -112.52, pg_loss = -112.66, baseline_loss = 12.508, entropy_loss = -12.366, learner_queue_size = 64, _tick = 581, _time = 1.6548e+09)
[2022-06-09 14:08:54,728][root][INFO] - Step 4848640 @ 3068.4 SPS. Inference batcher size: 74. Learner queue size: 64. Other stats: (train_seconds = 1697.7, step = 4848640, mean_episode_return = 124.91, mean_episode_step = 2454.3, total_loss = 46.232, pg_loss = -50.039, baseline_loss = 108.66, entropy_loss = -12.389, learner_queue_size = 64, _tick = 583, _time = 1.6548e+09)
[2022-06-09 14:08:59,734][root][INFO] - Step 4864000 @ 3068.2 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1702.7, step = 4864000, mean_episode_return = 27.7, mean_episode_step = 2328.4, total_loss = 49.54, pg_loss = 26.01, baseline_loss = 34.85, entropy_loss = -11.321, learner_queue_size = 64, _tick = 586, _time = 1.6548e+09)
[2022-06-09 14:09:04,738][root][INFO] - Step 4874240 @ 2046.3 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1707.7, step = 4874240, mean_episode_return = 64.7, mean_episode_step = 2007.8, total_loss = -163.16, pg_loss = -178.03, baseline_loss = 26.074, entropy_loss = -11.2, learner_queue_size = 64, _tick = 588, _time = 1.6548e+09)
[2022-06-09 14:09:09,742][root][INFO] - Step 4889600 @ 3069.6 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1712.7, step = 4889600, mean_episode_return = 7.6694, mean_episode_step = 2069.9, total_loss = -39.124, pg_loss = -61.174, baseline_loss = 33.883, entropy_loss = -11.834, learner_queue_size = 64, _tick = 591, _time = 1.6548e+09)
[2022-06-09 14:09:14,746][root][INFO] - Step 4904960 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1717.7, step = 4904960, mean_episode_return = -14.81, mean_episode_step = 1930.7, total_loss = -87.459, pg_loss = -84.371, baseline_loss = 8.593, entropy_loss = -11.68, learner_queue_size = 64, _tick = 593, _time = 1.6548e+09)
[2022-06-09 14:09:19,750][root][INFO] - Step 4920320 @ 3069.4 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1722.7, step = 4920320, mean_episode_return = 34.291, mean_episode_step = 2507.9, total_loss = -55.707, pg_loss = -68.533, baseline_loss = 24.415, entropy_loss = -11.589, learner_queue_size = 64, _tick = 595, _time = 1.6548e+09)
[2022-06-09 14:09:24,754][root][INFO] - Step 4935680 @ 3069.7 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 1727.7, step = 4935680, mean_episode_return = 34.806, mean_episode_step = 2323.3, total_loss = -82.104, pg_loss = -93.402, baseline_loss = 22.469, entropy_loss = -11.171, learner_queue_size = 64, _tick = 597, _time = 1.6548e+09)
[2022-06-09 14:09:29,758][root][INFO] - Step 4951040 @ 3069.5 SPS. Inference batcher size: 73. Learner queue size: 64. Other stats: (train_seconds = 1732.7, step = 4951040, mean_episode_return = 62.813, mean_episode_step = 1982.9, total_loss = 197.94, pg_loss = 160.57, baseline_loss = 48.525, entropy_loss = -11.155, learner_queue_size = 64, _tick = 600, _time = 1.6548e+09)
[2022-06-09 14:09:34,762][root][INFO] - Step 4966400 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1737.7, step = 4966400, mean_episode_return = 110.89, mean_episode_step = 2168.8, total_loss = 253.54, pg_loss = 182.17, baseline_loss = 82.579, entropy_loss = -11.211, learner_queue_size = 64, _tick = 601, _time = 1.6548e+09)
[2022-06-09 14:09:39,766][root][INFO] - Step 4976640 @ 2046.4 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1742.7, step = 4976640, mean_episode_return = None, mean_episode_step = 2249.2, total_loss = 110.29, pg_loss = 85.172, baseline_loss = 36.298, entropy_loss = -11.182, learner_queue_size = 64, _tick = 602, _time = 1.6548e+09)
[2022-06-09 14:09:44,770][root][INFO] - Step 4992000 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1747.7, step = 4992000, mean_episode_return = 6.3195, mean_episode_step = 2061.1, total_loss = -98.567, pg_loss = -97.816, baseline_loss = 10.468, entropy_loss = -11.219, learner_queue_size = 64, _tick = 605, _time = 1.6548e+09)
[2022-06-09 14:09:49,774][root][INFO] - Step 5007360 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1752.7, step = 5007360, mean_episode_return = None, mean_episode_step = 2200.1, total_loss = 68.855, pg_loss = 45.409, baseline_loss = 34.833, entropy_loss = -11.388, learner_queue_size = 64, _tick = 607, _time = 1.6548e+09)
[2022-06-09 14:09:54,778][root][INFO] - Step 5022720 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1757.7, step = 5022720, mean_episode_return = 48.45, mean_episode_step = 2138.7, total_loss = -11.574, pg_loss = -42.054, baseline_loss = 42.714, entropy_loss = -12.234, learner_queue_size = 64, _tick = 609, _time = 1.6548e+09)
[2022-06-09 14:09:59,782][root][INFO] - Step 5038080 @ 3069.5 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 1762.7, step = 5038080, mean_episode_return = 17.2, mean_episode_step = 2625.6, total_loss = 43.202, pg_loss = 26.523, baseline_loss = 28.438, entropy_loss = -11.759, learner_queue_size = 64, _tick = 612, _time = 1.6548e+09)
[2022-06-09 14:10:04,788][root][INFO] - Step 5053440 @ 3068.4 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1767.7, step = 5053440, mean_episode_return = 65.056, mean_episode_step = 2018.6, total_loss = 44.329, pg_loss = 13.927, baseline_loss = 42.527, entropy_loss = -12.125, learner_queue_size = 64, _tick = 614, _time = 1.6548e+09)
[2022-06-09 14:10:09,790][root][INFO] - Step 5068800 @ 3070.7 SPS. Inference batcher size: 75. Learner queue size: 64. Other stats: (train_seconds = 1772.7, step = 5068800, mean_episode_return = 136.26, mean_episode_step = 2241.7, total_loss = 23.021, pg_loss = 0.56526, baseline_loss = 34.683, entropy_loss = -12.227, learner_queue_size = 64, _tick = 617, _time = 1.6548e+09)
[2022-06-09 14:10:14,794][root][INFO] - Step 5079040 @ 2046.4 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1777.7, step = 5079040, mean_episode_return = 223.39, mean_episode_step = 2153.9, total_loss = 13.189, pg_loss = 3.4651, baseline_loss = 21.215, entropy_loss = -11.491, learner_queue_size = 64, _tick = 619, _time = 1.6548e+09)
[2022-06-09 14:10:19,798][root][INFO] - Step 5094400 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1782.7, step = 5094400, mean_episode_return = -0.26713, mean_episode_step = 2574.4, total_loss = 245.35, pg_loss = 162.7, baseline_loss = 94.672, entropy_loss = -12.024, learner_queue_size = 64, _tick = 622, _time = 1.6548e+09)
[2022-06-09 14:10:24,802][root][INFO] - Step 5109760 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1787.7, step = 5109760, mean_episode_return = 12.515, mean_episode_step = 2443.7, total_loss = -223.73, pg_loss = -228.85, baseline_loss = 17.127, entropy_loss = -12.006, learner_queue_size = 64, _tick = 624, _time = 1.6548e+09)
[2022-06-09 14:10:29,806][root][INFO] - Step 5125120 @ 3069.5 SPS. Inference batcher size: 87. Learner queue size: 64. Other stats: (train_seconds = 1792.7, step = 5125120, mean_episode_return = 44.132, mean_episode_step = 2012.1, total_loss = 223.61, pg_loss = 178.12, baseline_loss = 57.961, entropy_loss = -12.467, learner_queue_size = 64, _tick = 625, _time = 1.6548e+09)
[2022-06-09 14:10:34,812][root][INFO] - Step 5140480 @ 3068.4 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 1797.7, step = 5140480, mean_episode_return = 78.45, mean_episode_step = 2479.5, total_loss = 210.86, pg_loss = 148.13, baseline_loss = 75.332, entropy_loss = -12.598, learner_queue_size = 64, _tick = 627, _time = 1.6548e+09)
[2022-06-09 14:10:39,818][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 14:10:40,056][root][INFO] - Step 5155840 @ 3068.4 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1802.8, step = 5155840, mean_episode_return = None, mean_episode_step = 2380.1, total_loss = 54.905, pg_loss = 33.065, baseline_loss = 34.552, entropy_loss = -12.712, learner_queue_size = 64, _tick = 628, _time = 1.6548e+09)
[2022-06-09 14:10:45,058][root][INFO] - Step 5166080 @ 1954.2 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 1808.0, step = 5166080, mean_episode_return = 49.429, mean_episode_step = 2159.8, total_loss = -33.933, pg_loss = -51.151, baseline_loss = 29.591, entropy_loss = -12.373, learner_queue_size = 64, _tick = 630, _time = 1.6548e+09)
[2022-06-09 14:10:50,062][root][INFO] - Step 5181440 @ 3069.5 SPS. Inference batcher size: 10. Learner queue size: 64. Other stats: (train_seconds = 1813.0, step = 5181440, mean_episode_return = -39.228, mean_episode_step = 2711.2, total_loss = -53.799, pg_loss = -79.62, baseline_loss = 38.427, entropy_loss = -12.606, learner_queue_size = 64, _tick = 633, _time = 1.6548e+09)
[2022-06-09 14:10:55,066][root][INFO] - Step 5196800 @ 3069.6 SPS. Inference batcher size: 67. Learner queue size: 64. Other stats: (train_seconds = 1818.0, step = 5196800, mean_episode_return = 62.713, mean_episode_step = 2575.1, total_loss = 38.007, pg_loss = 20.281, baseline_loss = 29.796, entropy_loss = -12.07, learner_queue_size = 64, _tick = 636, _time = 1.6548e+09)
[2022-06-09 14:11:00,070][root][INFO] - Step 5207040 @ 2046.4 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1823.0, step = 5207040, mean_episode_return = 73.667, mean_episode_step = 2377.4, total_loss = 5.3274, pg_loss = -8.8477, baseline_loss = 26.426, entropy_loss = -12.251, learner_queue_size = 64, _tick = 637, _time = 1.6548e+09)
[2022-06-09 14:11:05,074][root][INFO] - Step 5222400 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1828.0, step = 5222400, mean_episode_return = 73.071, mean_episode_step = 2131.6, total_loss = -10.972, pg_loss = -23.001, baseline_loss = 24.505, entropy_loss = -12.475, learner_queue_size = 64, _tick = 640, _time = 1.6548e+09)
[2022-06-09 14:11:10,078][root][INFO] - Step 5237760 @ 3069.6 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 1833.0, step = 5237760, mean_episode_return = None, mean_episode_step = 2011.5, total_loss = 58.8, pg_loss = 48.531, baseline_loss = 22.584, entropy_loss = -12.315, learner_queue_size = 64, _tick = 642, _time = 1.6548e+09)
[2022-06-09 14:11:15,082][root][INFO] - Step 5248000 @ 2046.4 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 1838.0, step = 5248000, mean_episode_return = 33.658, mean_episode_step = 2153.2, total_loss = -68.077, pg_loss = -104.12, baseline_loss = 48.497, entropy_loss = -12.451, learner_queue_size = 64, _tick = 643, _time = 1.6548e+09)
[2022-06-09 14:11:20,086][root][INFO] - Step 5263360 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1843.0, step = 5263360, mean_episode_return = 24.944, mean_episode_step = 2130.0, total_loss = -206.49, pg_loss = -203.45, baseline_loss = 9.4486, entropy_loss = -12.492, learner_queue_size = 64, _tick = 646, _time = 1.6548e+09)
[2022-06-09 14:11:25,090][root][INFO] - Step 5278720 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1848.0, step = 5278720, mean_episode_return = None, mean_episode_step = 1993.1, total_loss = -62.462, pg_loss = -68.001, baseline_loss = 18.213, entropy_loss = -12.674, learner_queue_size = 64, _tick = 647, _time = 1.6548e+09)
[2022-06-09 14:11:30,094][root][INFO] - Step 5294080 @ 3069.6 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1853.0, step = 5294080, mean_episode_return = 136.75, mean_episode_step = 2474.0, total_loss = -93.359, pg_loss = -95.469, baseline_loss = 14.597, entropy_loss = -12.487, learner_queue_size = 64, _tick = 650, _time = 1.6548e+09)
[2022-06-09 14:11:35,098][root][INFO] - Step 5309440 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1858.0, step = 5309440, mean_episode_return = 39.735, mean_episode_step = 1960.6, total_loss = -2.4576, pg_loss = -34.35, baseline_loss = 44.747, entropy_loss = -12.856, learner_queue_size = 64, _tick = 652, _time = 1.6548e+09)
[2022-06-09 14:11:40,102][root][INFO] - Step 5324800 @ 3069.6 SPS. Inference batcher size: 78. Learner queue size: 64. Other stats: (train_seconds = 1863.0, step = 5324800, mean_episode_return = -9.0401, mean_episode_step = 2308.9, total_loss = 131.42, pg_loss = 88.164, baseline_loss = 56.354, entropy_loss = -13.094, learner_queue_size = 64, _tick = 655, _time = 1.6548e+09)
[2022-06-09 14:11:45,106][root][INFO] - Step 5335040 @ 2046.4 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1868.0, step = 5335040, mean_episode_return = 92.7, mean_episode_step = 2070.1, total_loss = 183.0, pg_loss = 139.29, baseline_loss = 56.676, entropy_loss = -12.962, learner_queue_size = 64, _tick = 657, _time = 1.6548e+09)
[2022-06-09 14:11:50,110][root][INFO] - Step 5350400 @ 3069.5 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 1873.0, step = 5350400, mean_episode_return = 47.255, mean_episode_step = 2361.9, total_loss = -272.38, pg_loss = -276.24, baseline_loss = 16.3, entropy_loss = -12.438, learner_queue_size = 64, _tick = 660, _time = 1.6548e+09)
[2022-06-09 14:11:55,114][root][INFO] - Step 5365760 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1878.1, step = 5365760, mean_episode_return = 8.778, mean_episode_step = 2130.8, total_loss = 51.396, pg_loss = 17.273, baseline_loss = 46.427, entropy_loss = -12.304, learner_queue_size = 64, _tick = 663, _time = 1.6548e+09)
[2022-06-09 14:12:00,118][root][INFO] - Step 5381120 @ 3069.5 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 1883.1, step = 5381120, mean_episode_return = 42.913, mean_episode_step = 2235.4, total_loss = 105.42, pg_loss = 69.671, baseline_loss = 47.55, entropy_loss = -11.806, learner_queue_size = 64, _tick = 666, _time = 1.6548e+09)
[2022-06-09 14:12:05,123][root][INFO] - Step 5396480 @ 3069.2 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 1888.1, step = 5396480, mean_episode_return = 14.305, mean_episode_step = 2084.3, total_loss = 153.86, pg_loss = 99.625, baseline_loss = 66.491, entropy_loss = -12.253, learner_queue_size = 64, _tick = 669, _time = 1.6548e+09)
[2022-06-09 14:12:10,126][root][INFO] - Step 5406720 @ 2046.7 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 1893.1, step = 5406720, mean_episode_return = 43.121, mean_episode_step = 2165.7, total_loss = -44.627, pg_loss = -60.743, baseline_loss = 27.954, entropy_loss = -11.838, learner_queue_size = 64, _tick = 671, _time = 1.6548e+09)
[2022-06-09 14:12:15,132][root][INFO] - Step 5422080 @ 3068.2 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1898.1, step = 5422080, mean_episode_return = None, mean_episode_step = 1507.9, total_loss = 98.642, pg_loss = 75.505, baseline_loss = 35.201, entropy_loss = -12.064, learner_queue_size = 64, _tick = 673, _time = 1.6548e+09)
[2022-06-09 14:12:20,138][root][INFO] - Step 5437440 @ 3068.4 SPS. Inference batcher size: 13. Learner queue size: 64. Other stats: (train_seconds = 1903.1, step = 5437440, mean_episode_return = 36.213, mean_episode_step = 2261.4, total_loss = -133.83, pg_loss = -141.82, baseline_loss = 19.868, entropy_loss = -11.877, learner_queue_size = 64, _tick = 676, _time = 1.6548e+09)
[2022-06-09 14:12:25,142][root][INFO] - Step 5452800 @ 3069.6 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 1908.1, step = 5452800, mean_episode_return = 4.8263, mean_episode_step = 1878.5, total_loss = -12.084, pg_loss = -59.856, baseline_loss = 59.76, entropy_loss = -11.988, learner_queue_size = 64, _tick = 679, _time = 1.6548e+09)
[2022-06-09 14:12:30,146][root][INFO] - Step 5463040 @ 2046.4 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1913.1, step = 5463040, mean_episode_return = 22.35, mean_episode_step = 1815.3, total_loss = -111.73, pg_loss = -108.69, baseline_loss = 8.9924, entropy_loss = -12.026, learner_queue_size = 64, _tick = 681, _time = 1.6548e+09)
[2022-06-09 14:12:35,150][root][INFO] - Step 5478400 @ 3069.6 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1918.1, step = 5478400, mean_episode_return = None, mean_episode_step = 1969.8, total_loss = 94.348, pg_loss = 76.693, baseline_loss = 29.463, entropy_loss = -11.808, learner_queue_size = 64, _tick = 682, _time = 1.6548e+09)
[2022-06-09 14:12:40,154][root][INFO] - Step 5493760 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 1923.1, step = 5493760, mean_episode_return = None, mean_episode_step = 1873.3, total_loss = 37.891, pg_loss = 16.674, baseline_loss = 32.851, entropy_loss = -11.634, learner_queue_size = 64, _tick = 684, _time = 1.6548e+09)
[2022-06-09 14:12:45,158][root][INFO] - Step 5509120 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1928.1, step = 5509120, mean_episode_return = 68.58, mean_episode_step = 2197.9, total_loss = 370.54, pg_loss = 291.79, baseline_loss = 90.768, entropy_loss = -12.021, learner_queue_size = 64, _tick = 687, _time = 1.6548e+09)
[2022-06-09 14:12:50,162][root][INFO] - Step 5524480 @ 3069.6 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1933.1, step = 5524480, mean_episode_return = None, mean_episode_step = 2043.1, total_loss = -65.823, pg_loss = -81.937, baseline_loss = 27.896, entropy_loss = -11.783, learner_queue_size = 64, _tick = 688, _time = 1.6548e+09)
[2022-06-09 14:12:55,166][root][INFO] - Step 5539840 @ 3069.5 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 1938.1, step = 5539840, mean_episode_return = None, mean_episode_step = 2152.6, total_loss = 45.092, pg_loss = 5.5127, baseline_loss = 51.122, entropy_loss = -11.543, learner_queue_size = 64, _tick = 689, _time = 1.6548e+09)
[2022-06-09 14:13:00,170][root][INFO] - Step 5555200 @ 3069.5 SPS. Inference batcher size: 68. Learner queue size: 64. Other stats: (train_seconds = 1943.1, step = 5555200, mean_episode_return = None, mean_episode_step = 1894.8, total_loss = -217.1, pg_loss = -207.7, baseline_loss = 2.0162, entropy_loss = -11.42, learner_queue_size = 64, _tick = 690, _time = 1.6548e+09)
[2022-06-09 14:13:05,175][root][INFO] - Step 5570560 @ 3068.8 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 1948.1, step = 5570560, mean_episode_return = 8.9794, mean_episode_step = 1973.1, total_loss = 43.104, pg_loss = 11.519, baseline_loss = 42.342, entropy_loss = -10.757, learner_queue_size = 64, _tick = 693, _time = 1.6548e+09)
[2022-06-09 14:13:10,178][root][INFO] - Step 5580800 @ 2046.9 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1953.1, step = 5580800, mean_episode_return = None, mean_episode_step = 2244.1, total_loss = -65.799, pg_loss = -71.18, baseline_loss = 16.697, entropy_loss = -11.316, learner_queue_size = 64, _tick = 694, _time = 1.6548e+09)
[2022-06-09 14:13:15,182][root][INFO] - Step 5596160 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1958.1, step = 5596160, mean_episode_return = 49.631, mean_episode_step = 2196.6, total_loss = 1.4586, pg_loss = -14.437, baseline_loss = 27.792, entropy_loss = -11.897, learner_queue_size = 64, _tick = 696, _time = 1.6548e+09)
[2022-06-09 14:13:20,186][root][INFO] - Step 5611520 @ 3069.6 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1963.1, step = 5611520, mean_episode_return = 76.603, mean_episode_step = 2192.4, total_loss = 432.67, pg_loss = 292.25, baseline_loss = 152.11, entropy_loss = -11.692, learner_queue_size = 64, _tick = 699, _time = 1.6548e+09)
[2022-06-09 14:13:25,190][root][INFO] - Step 5626880 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1968.1, step = 5626880, mean_episode_return = 40.507, mean_episode_step = 2234.2, total_loss = 25.245, pg_loss = -28.746, baseline_loss = 65.763, entropy_loss = -11.771, learner_queue_size = 64, _tick = 702, _time = 1.6548e+09)
[2022-06-09 14:13:30,194][root][INFO] - Step 5642240 @ 3069.5 SPS. Inference batcher size: 67. Learner queue size: 64. Other stats: (train_seconds = 1973.1, step = 5642240, mean_episode_return = 3.3472, mean_episode_step = 1661.0, total_loss = 56.433, pg_loss = 11.323, baseline_loss = 56.384, entropy_loss = -11.274, learner_queue_size = 64, _tick = 704, _time = 1.6548e+09)
[2022-06-09 14:13:35,199][root][INFO] - Step 5657600 @ 3069.3 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 1978.1, step = 5657600, mean_episode_return = None, mean_episode_step = 2087.5, total_loss = -129.96, pg_loss = -128.51, baseline_loss = 9.679, entropy_loss = -11.131, learner_queue_size = 64, _tick = 706, _time = 1.6548e+09)
[2022-06-09 14:13:40,206][root][INFO] - Step 5672960 @ 3067.3 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1983.1, step = 5672960, mean_episode_return = 55.365, mean_episode_step = 1874.7, total_loss = -79.773, pg_loss = -83.718, baseline_loss = 15.711, entropy_loss = -11.765, learner_queue_size = 64, _tick = 708, _time = 1.6548e+09)
[2022-06-09 14:13:45,210][root][INFO] - Step 5683200 @ 2046.4 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1988.1, step = 5683200, mean_episode_return = 48.371, mean_episode_step = 1724.8, total_loss = 21.352, pg_loss = 7.8236, baseline_loss = 25.546, entropy_loss = -12.018, learner_queue_size = 64, _tick = 710, _time = 1.6548e+09)
[2022-06-09 14:13:50,214][root][INFO] - Step 5698560 @ 3069.5 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 1993.2, step = 5698560, mean_episode_return = 104.77, mean_episode_step = 2473.8, total_loss = 59.886, pg_loss = 39.624, baseline_loss = 32.186, entropy_loss = -11.924, learner_queue_size = 64, _tick = 713, _time = 1.6548e+09)
[2022-06-09 14:13:55,218][root][INFO] - Step 5713920 @ 3069.6 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 1998.2, step = 5713920, mean_episode_return = 35.011, mean_episode_step = 1955.3, total_loss = 22.587, pg_loss = -12.431, baseline_loss = 46.529, entropy_loss = -11.511, learner_queue_size = 64, _tick = 716, _time = 1.6548e+09)
[2022-06-09 14:14:00,222][root][INFO] - Step 5724160 @ 2046.4 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 2003.2, step = 5724160, mean_episode_return = 31.418, mean_episode_step = 2221.3, total_loss = -58.226, pg_loss = -76.755, baseline_loss = 29.451, entropy_loss = -10.922, learner_queue_size = 64, _tick = 718, _time = 1.6548e+09)
[2022-06-09 14:14:05,226][root][INFO] - Step 5739520 @ 3069.5 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 2008.2, step = 5739520, mean_episode_return = 71.952, mean_episode_step = 1832.8, total_loss = 138.01, pg_loss = 88.608, baseline_loss = 60.322, entropy_loss = -10.917, learner_queue_size = 64, _tick = 721, _time = 1.6548e+09)
[2022-06-09 14:14:10,230][root][INFO] - Step 5754880 @ 3069.5 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 2013.2, step = 5754880, mean_episode_return = 50.131, mean_episode_step = 2564.4, total_loss = -136.15, pg_loss = -134.04, baseline_loss = 9.3035, entropy_loss = -11.42, learner_queue_size = 64, _tick = 723, _time = 1.6548e+09)
[2022-06-09 14:14:15,234][root][INFO] - Step 5770240 @ 3069.6 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 2018.2, step = 5770240, mean_episode_return = None, mean_episode_step = 1854.4, total_loss = 158.99, pg_loss = 126.43, baseline_loss = 43.994, entropy_loss = -11.44, learner_queue_size = 64, _tick = 725, _time = 1.6548e+09)
[2022-06-09 14:14:20,238][root][INFO] - Step 5785600 @ 3069.5 SPS. Inference batcher size: 75. Learner queue size: 64. Other stats: (train_seconds = 2023.2, step = 5785600, mean_episode_return = -1.5253, mean_episode_step = 1707.4, total_loss = -50.783, pg_loss = -65.385, baseline_loss = 26.187, entropy_loss = -11.584, learner_queue_size = 64, _tick = 727, _time = 1.6548e+09)
[2022-06-09 14:14:25,242][root][INFO] - Step 5800960 @ 3069.5 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 2028.2, step = 5800960, mean_episode_return = None, mean_episode_step = 2258.1, total_loss = 357.91, pg_loss = 288.87, baseline_loss = 80.811, entropy_loss = -11.77, learner_queue_size = 64, _tick = 729, _time = 1.6548e+09)
[2022-06-09 14:14:30,246][root][INFO] - Step 5811200 @ 2046.4 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 2033.2, step = 5811200, mean_episode_return = 93.38, mean_episode_step = 2037.9, total_loss = 141.96, pg_loss = 85.408, baseline_loss = 68.015, entropy_loss = -11.466, learner_queue_size = 64, _tick = 731, _time = 1.6548e+09)
[2022-06-09 14:14:35,250][root][INFO] - Step 5826560 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 2038.2, step = 5826560, mean_episode_return = 32.633, mean_episode_step = 2444.3, total_loss = -94.613, pg_loss = -96.973, baseline_loss = 14.72, entropy_loss = -12.36, learner_queue_size = 64, _tick = 733, _time = 1.6548e+09)
[2022-06-09 14:14:40,254][root][INFO] - Step 5841920 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 2043.2, step = 5841920, mean_episode_return = 38.895, mean_episode_step = 1862.0, total_loss = -20.709, pg_loss = -64.973, baseline_loss = 56.907, entropy_loss = -12.643, learner_queue_size = 64, _tick = 735, _time = 1.6548e+09)
[2022-06-09 14:14:45,259][root][INFO] - Step 5857280 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 2048.2, step = 5857280, mean_episode_return = 73.179, mean_episode_step = 2114.3, total_loss = 441.77, pg_loss = 353.92, baseline_loss = 99.367, entropy_loss = -11.522, learner_queue_size = 64, _tick = 736, _time = 1.6548e+09)
[2022-06-09 14:14:50,262][root][INFO] - Step 5872640 @ 3069.6 SPS. Inference batcher size: 91. Learner queue size: 64. Other stats: (train_seconds = 2053.2, step = 5872640, mean_episode_return = 9.1294, mean_episode_step = 2435.3, total_loss = 26.525, pg_loss = 1.4696, baseline_loss = 36.669, entropy_loss = -11.613, learner_queue_size = 64, _tick = 739, _time = 1.6548e+09)
[2022-06-09 14:14:55,266][root][INFO] - Step 5888000 @ 3069.6 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 2058.2, step = 5888000, mean_episode_return = 13.12, mean_episode_step = 2076.4, total_loss = -109.45, pg_loss = -117.21, baseline_loss = 19.674, entropy_loss = -11.913, learner_queue_size = 64, _tick = 741, _time = 1.6548e+09)
[2022-06-09 14:15:00,270][root][INFO] - Step 5903360 @ 3069.5 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 2063.2, step = 5903360, mean_episode_return = 14.7, mean_episode_step = 2119.3, total_loss = -31.229, pg_loss = -48.14, baseline_loss = 28.64, entropy_loss = -11.729, learner_queue_size = 64, _tick = 744, _time = 1.6548e+09)
[2022-06-09 14:15:05,274][root][INFO] - Step 5918720 @ 3069.6 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 2068.2, step = 5918720, mean_episode_return = 11.146, mean_episode_step = 2309.2, total_loss = -138.46, pg_loss = -153.1, baseline_loss = 26.146, entropy_loss = -11.506, learner_queue_size = 64, _tick = 746, _time = 1.6548e+09)
[2022-06-09 14:15:10,278][root][INFO] - Step 5934080 @ 3069.5 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 2073.2, step = 5934080, mean_episode_return = None, mean_episode_step = 1992.6, total_loss = 26.482, pg_loss = 1.6861, baseline_loss = 36.216, entropy_loss = -11.421, learner_queue_size = 64, _tick = 748, _time = 1.6548e+09)
[2022-06-09 14:15:15,282][root][INFO] - Step 5944320 @ 2046.4 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 2078.2, step = 5944320, mean_episode_return = 73.272, mean_episode_step = 2038.3, total_loss = 233.94, pg_loss = 183.74, baseline_loss = 62.236, entropy_loss = -12.044, learner_queue_size = 64, _tick = 750, _time = 1.6548e+09)
[2022-06-09 14:15:20,286][root][INFO] - Step 5959680 @ 3069.6 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 2083.2, step = 5959680, mean_episode_return = 34.373, mean_episode_step = 2279.6, total_loss = -68.138, pg_loss = -88.935, baseline_loss = 32.8, entropy_loss = -12.002, learner_queue_size = 64, _tick = 753, _time = 1.6548e+09)
[2022-06-09 14:15:25,290][root][INFO] - Step 5975040 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 2088.2, step = 5975040, mean_episode_return = None, mean_episode_step = 2184.8, total_loss = 32.04, pg_loss = 9.9973, baseline_loss = 33.717, entropy_loss = -11.674, learner_queue_size = 64, _tick = 755, _time = 1.6548e+09)
[2022-06-09 14:15:30,294][root][INFO] - Step 5990400 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 2093.2, step = 5990400, mean_episode_return = 15.87, mean_episode_step = 2255.8, total_loss = 152.87, pg_loss = 120.92, baseline_loss = 44.168, entropy_loss = -12.22, learner_queue_size = 64, _tick = 757, _time = 1.6548e+09)
[2022-06-09 14:15:35,298][root][INFO] - Step 6000640 @ 2046.4 SPS. Inference batcher size: 10. Learner queue size: 64. Other stats: (train_seconds = 2098.2, step = 6000640, mean_episode_return = 44.102, mean_episode_step = 2129.0, total_loss = 58.931, pg_loss = 42.981, baseline_loss = 28.087, entropy_loss = -12.137, learner_queue_size = 64, _tick = 759, _time = 1.6548e+09)
[2022-06-09 14:15:40,303][root][INFO] - Step 6016000 @ 3069.2 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 2103.2, step = 6016000, mean_episode_return = 85.869, mean_episode_step = 1825.2, total_loss = 28.803, pg_loss = -11.208, baseline_loss = 52.469, entropy_loss = -12.459, learner_queue_size = 64, _tick = 762, _time = 1.6548e+09)
[2022-06-09 14:15:45,307][root][INFO] - Step 6031360 @ 3069.5 SPS. Inference batcher size: 3. Learner queue size: 64. Other stats: (train_seconds = 2108.2, step = 6031360, mean_episode_return = 97.118, mean_episode_step = 2417.7, total_loss = -43.625, pg_loss = -67.181, baseline_loss = 35.529, entropy_loss = -11.973, learner_queue_size = 64, _tick = 764, _time = 1.6548e+09)
[2022-06-09 14:15:50,310][root][INFO] - Step 6046720 @ 3069.9 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 2113.2, step = 6046720, mean_episode_return = 101.93, mean_episode_step = 1919.0, total_loss = 42.885, pg_loss = 28.608, baseline_loss = 25.614, entropy_loss = -11.337, learner_queue_size = 64, _tick = 767, _time = 1.6548e+09)
[2022-06-09 14:15:55,314][root][INFO] - Step 6062080 @ 3069.6 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 2118.2, step = 6062080, mean_episode_return = 58.722, mean_episode_step = 2036.0, total_loss = -62.32, pg_loss = -82.139, baseline_loss = 31.47, entropy_loss = -11.651, learner_queue_size = 64, _tick = 770, _time = 1.6548e+09)
[2022-06-09 14:16:00,318][root][INFO] - Step 6077440 @ 3069.4 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 2123.3, step = 6077440, mean_episode_return = 53.592, mean_episode_step = 2008.4, total_loss = 429.88, pg_loss = 345.1, baseline_loss = 97.149, entropy_loss = -12.377, learner_queue_size = 64, _tick = 773, _time = 1.6548e+09)
[2022-06-09 14:16:05,322][root][INFO] - Step 6087680 @ 2046.4 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 2128.3, step = 6087680, mean_episode_return = 30.13, mean_episode_step = 2072.7, total_loss = 376.32, pg_loss = 276.17, baseline_loss = 112.57, entropy_loss = -12.424, learner_queue_size = 64, _tick = 775, _time = 1.6548e+09)
[2022-06-09 14:16:10,327][root][INFO] - Step 6103040 @ 3069.1 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 2133.3, step = 6103040, mean_episode_return = None, mean_episode_step = 1863.4, total_loss = -108.94, pg_loss = -111.4, baseline_loss = 14.785, entropy_loss = -12.326, learner_queue_size = 64, _tick = 776, _time = 1.6548e+09)
[2022-06-09 14:16:15,330][root][INFO] - Step 6118400 @ 3070.0 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 2138.3, step = 6118400, mean_episode_return = 33.624, mean_episode_step = 2105.7, total_loss = -112.87, pg_loss = -122.66, baseline_loss = 22.2, entropy_loss = -12.416, learner_queue_size = 64, _tick = 779, _time = 1.6548e+09)
[2022-06-09 14:16:20,334][root][INFO] - Step 6133760 @ 3069.5 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 2143.3, step = 6133760, mean_episode_return = 47.212, mean_episode_step = 2113.3, total_loss = -45.043, pg_loss = -63.334, baseline_loss = 29.979, entropy_loss = -11.688, learner_queue_size = 64, _tick = 782, _time = 1.6548e+09)
[2022-06-09 14:16:25,338][root][INFO] - Step 6149120 @ 3069.6 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 2148.3, step = 6149120, mean_episode_return = 67.047, mean_episode_step = 1792.7, total_loss = -210.7, pg_loss = -210.08, baseline_loss = 11.239, entropy_loss = -11.852, learner_queue_size = 64, _tick = 785, _time = 1.6548e+09)
[2022-06-09 14:16:30,342][root][INFO] - Step 6164480 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 2153.3, step = 6164480, mean_episode_return = 15.631, mean_episode_step = 1898.0, total_loss = -28.884, pg_loss = -39.628, baseline_loss = 22.349, entropy_loss = -11.605, learner_queue_size = 64, _tick = 788, _time = 1.6548e+09)
[2022-06-09 14:16:35,346][root][INFO] - Step 6179840 @ 3069.5 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 2158.3, step = 6179840, mean_episode_return = None, mean_episode_step = 2039.3, total_loss = -11.188, pg_loss = -15.043, baseline_loss = 16.272, entropy_loss = -12.417, learner_queue_size = 64, _tick = 788, _time = 1.6548e+09)
[2022-06-09 14:16:40,354][root][INFO] - Step 6195200 @ 3067.1 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 2163.3, step = 6195200, mean_episode_return = None, mean_episode_step = 2124.9, total_loss = 243.3, pg_loss = 183.77, baseline_loss = 72.208, entropy_loss = -12.682, learner_queue_size = 64, _tick = 789, _time = 1.6548e+09)
[2022-06-09 14:16:45,360][root][INFO] - Step 6210560 @ 3068.3 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 2168.3, step = 6210560, mean_episode_return = 31.843, mean_episode_step = 1981.2, total_loss = -36.333, pg_loss = -82.361, baseline_loss = 58.677, entropy_loss = -12.649, learner_queue_size = 64, _tick = 791, _time = 1.6548e+09)
[2022-06-09 14:16:50,362][root][INFO] - Step 6225920 @ 3070.7 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 2173.3, step = 6225920, mean_episode_return = 48.235, mean_episode_step = 2422.0, total_loss = 208.51, pg_loss = 160.03, baseline_loss = 61.267, entropy_loss = -12.788, learner_queue_size = 64, _tick = 794, _time = 1.6548e+09)
[2022-06-09 14:16:55,366][root][INFO] - Step 6241280 @ 3069.6 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 2178.3, step = 6241280, mean_episode_return = 35.855, mean_episode_step = 2133.5, total_loss = -177.23, pg_loss = -182.87, baseline_loss = 18.363, entropy_loss = -12.729, learner_queue_size = 64, _tick = 797, _time = 1.6548e+09)
[2022-06-09 14:17:00,370][root][INFO] - Step 6261760 @ 4092.8 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 2183.3, step = 6261760, mean_episode_return = 13.28, mean_episode_step = 2213.1, total_loss = -101.41, pg_loss = -122.89, baseline_loss = 33.973, entropy_loss = -12.492, learner_queue_size = 64, _tick = 801, _time = 1.6548e+09)
[2022-06-09 14:17:05,374][root][INFO] - Step 6277120 @ 3069.6 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 2188.3, step = 6277120, mean_episode_return = None, mean_episode_step = 2002.5, total_loss = 173.41, pg_loss = 136.88, baseline_loss = 49.611, entropy_loss = -13.078, learner_queue_size = 64, _tick = 803, _time = 1.6548e+09)
[2022-06-09 14:17:10,378][root][INFO] - Step 6292480 @ 3069.5 SPS. Inference batcher size: 74. Learner queue size: 64. Other stats: (train_seconds = 2193.3, step = 6292480, mean_episode_return = 59.944, mean_episode_step = 1982.5, total_loss = 181.62, pg_loss = 129.78, baseline_loss = 65.197, entropy_loss = -13.366, learner_queue_size = 64, _tick = 805, _time = 1.6548e+09)
[2022-06-09 14:17:15,382][root][INFO] - Step 6307840 @ 3069.5 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 2198.3, step = 6307840, mean_episode_return = 28.737, mean_episode_step = 1936.3, total_loss = 392.86, pg_loss = 262.53, baseline_loss = 143.41, entropy_loss = -13.081, learner_queue_size = 64, _tick = 808, _time = 1.6548e+09)
[2022-06-09 14:17:20,386][root][INFO] - Step 6323200 @ 3069.6 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 2203.3, step = 6323200, mean_episode_return = 41.234, mean_episode_step = 1782.0, total_loss = -189.75, pg_loss = -243.47, baseline_loss = 66.867, entropy_loss = -13.149, learner_queue_size = 64, _tick = 811, _time = 1.6548e+09)
[2022-06-09 14:17:25,390][root][INFO] - Step 6338560 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 2208.3, step = 6338560, mean_episode_return = 31.238, mean_episode_step = 1620.2, total_loss = -190.08, pg_loss = -221.24, baseline_loss = 44.107, entropy_loss = -12.942, learner_queue_size = 64, _tick = 813, _time = 1.6548e+09)
[2022-06-09 14:17:30,394][root][INFO] - Step 6353920 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 2213.3, step = 6353920, mean_episode_return = 200.21, mean_episode_step = 2257.5, total_loss = 45.391, pg_loss = 26.811, baseline_loss = 31.633, entropy_loss = -13.053, learner_queue_size = 64, _tick = 816, _time = 1.6548e+09)
[2022-06-09 14:17:35,398][root][INFO] - Step 6369280 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 2218.3, step = 6369280, mean_episode_return = 12.773, mean_episode_step = 2187.9, total_loss = 17.083, pg_loss = -12.433, baseline_loss = 41.955, entropy_loss = -12.44, learner_queue_size = 64, _tick = 819, _time = 1.6548e+09)
[2022-06-09 14:17:40,402][root][INFO] - Step 6384640 @ 3069.4 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 2223.3, step = 6384640, mean_episode_return = 96.663, mean_episode_step = 1569.4, total_loss = 103.19, pg_loss = 75.483, baseline_loss = 39.679, entropy_loss = -11.971, learner_queue_size = 64, _tick = 821, _time = 1.6548e+09)
[2022-06-09 14:17:45,406][root][INFO] - Step 6400000 @ 3069.6 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 2228.3, step = 6400000, mean_episode_return = None, mean_episode_step = 1912.9, total_loss = 194.03, pg_loss = 145.49, baseline_loss = 60.815, entropy_loss = -12.276, learner_queue_size = 64, _tick = 823, _time = 1.6548e+09)
[2022-06-09 14:17:50,410][root][INFO] - Step 6415360 @ 3069.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 2233.3, step = 6415360, mean_episode_return = None, mean_episode_step = 1629.0, total_loss = 19.858, pg_loss = 7.1514, baseline_loss = 25.041, entropy_loss = -12.334, learner_queue_size = 64, _tick = 823, _time = 1.6548e+09)
[2022-06-09 14:17:55,415][root][INFO] - Step 6430720 @ 3068.8 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 2238.4, step = 6430720, mean_episode_return = 628.43, mean_episode_step = 2082.1, total_loss = 53.98, pg_loss = 35.035, baseline_loss = 31.357, entropy_loss = -12.412, learner_queue_size = 64, _tick = 826, _time = 1.6548e+09)
[2022-06-09 14:18:00,418][root][INFO] - Step 6446080 @ 3070.2 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 2243.4, step = 6446080, mean_episode_return = -0.45, mean_episode_step = 1795.0, total_loss = 9.1159, pg_loss = -9.3306, baseline_loss = 31.31, entropy_loss = -12.864, learner_queue_size = 64, _tick = 829, _time = 1.6548e+09)
[2022-06-09 14:18:05,424][root][INFO] - Step 6461440 @ 3068.3 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 2248.4, step = 6461440, mean_episode_return = 5.9044, mean_episode_step = 1932.8, total_loss = 102.71, pg_loss = 67.641, baseline_loss = 46.735, entropy_loss = -11.668, learner_queue_size = 64, _tick = 832, _time = 1.6548e+09)
[2022-06-09 14:18:10,430][root][INFO] - Step 6476800 @ 3068.4 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 2253.4, step = 6476800, mean_episode_return = 18.8, mean_episode_step = 2096.5, total_loss = -44.017, pg_loss = -54.89, baseline_loss = 22.681, entropy_loss = -11.808, learner_queue_size = 64, _tick = 835, _time = 1.6548e+09)
[2022-06-09 14:18:15,434][root][INFO] - Step 6497280 @ 4092.7 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 2258.4, step = 6497280, mean_episode_return = 16.35, mean_episode_step = 2245.4, total_loss = 91.106, pg_loss = 64.781, baseline_loss = 37.904, entropy_loss = -11.58, learner_queue_size = 64, _tick = 838, _time = 1.6548e+09)
[2022-06-09 14:18:20,440][root][INFO] - Step 6512640 @ 3068.2 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 2263.4, step = 6512640, mean_episode_return = 88.792, mean_episode_step = 1548.2, total_loss = -154.06, pg_loss = -174.09, baseline_loss = 31.991, entropy_loss = -11.96, learner_queue_size = 64, _tick = 840, _time = 1.6548e+09)
[2022-06-09 14:18:25,446][root][INFO] - Step 6528000 @ 3068.4 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 2268.4, step = 6528000, mean_episode_return = 49.691, mean_episode_step = 2209.4, total_loss = 284.26, pg_loss = 226.93, baseline_loss = 68.7, entropy_loss = -11.373, learner_queue_size = 64, _tick = 843, _time = 1.6548e+09)
[2022-06-09 14:18:30,450][root][INFO] - Step 6543360 @ 3069.5 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 2273.4, step = 6543360, mean_episode_return = 13.32, mean_episode_step = 2054.7, total_loss = 119.34, pg_loss = 74.474, baseline_loss = 56.341, entropy_loss = -11.471, learner_queue_size = 64, _tick = 844, _time = 1.6548e+09)
[2022-06-09 14:18:35,454][root][INFO] - Step 6558720 @ 3069.6 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 2278.4, step = 6558720, mean_episode_return = -5.9905, mean_episode_step = 2100.2, total_loss = -319.59, pg_loss = -324.59, baseline_loss = 17.174, entropy_loss = -12.168, learner_queue_size = 64, _tick = 846, _time = 1.6548e+09)
[2022-06-09 14:18:40,458][root][INFO] - Step 6574080 @ 3069.6 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 2283.4, step = 6574080, mean_episode_return = None, mean_episode_step = 2284.5, total_loss = 68.408, pg_loss = 44.864, baseline_loss = 35.398, entropy_loss = -11.854, learner_queue_size = 64, _tick = 848, _time = 1.6548e+09)
[2022-06-09 14:18:45,462][root][INFO] - Step 6589440 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 2288.4, step = 6589440, mean_episode_return = None, mean_episode_step = 1831.8, total_loss = 48.942, pg_loss = 33.674, baseline_loss = 27.107, entropy_loss = -11.839, learner_queue_size = 64, _tick = 850, _time = 1.6548e+09)
[2022-06-09 14:18:50,466][root][INFO] - Step 6604800 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 2293.4, step = 6604800, mean_episode_return = 10.996, mean_episode_step = 2268.8, total_loss = 46.304, pg_loss = 23.621, baseline_loss = 34.958, entropy_loss = -12.276, learner_queue_size = 64, _tick = 853, _time = 1.6548e+09)
[2022-06-09 14:18:55,470][root][INFO] - Step 6620160 @ 3069.6 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 2298.4, step = 6620160, mean_episode_return = 34.956, mean_episode_step = 1842.3, total_loss = -46.348, pg_loss = -66.691, baseline_loss = 32.743, entropy_loss = -12.4, learner_queue_size = 64, _tick = 855, _time = 1.6548e+09)
[2022-06-09 14:19:00,474][root][INFO] - Step 6635520 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 2303.4, step = 6635520, mean_episode_return = None, mean_episode_step = 1562.9, total_loss = -90.134, pg_loss = -98.719, baseline_loss = 20.637, entropy_loss = -12.052, learner_queue_size = 64, _tick = 856, _time = 1.6548e+09)
[2022-06-09 14:19:05,478][root][INFO] - Step 6656000 @ 4092.8 SPS. Inference batcher size: 99. Learner queue size: 64. Other stats: (train_seconds = 2308.4, step = 6656000, mean_episode_return = 37.171, mean_episode_step = 1998.5, total_loss = -37.106, pg_loss = -50.592, baseline_loss = 25.815, entropy_loss = -12.329, learner_queue_size = 64, _tick = 858, _time = 1.6548e+09)
[2022-06-09 14:19:10,482][root][INFO] - Step 6671360 @ 3069.5 SPS. Inference batcher size: 2. Learner queue size: 64. Other stats: (train_seconds = 2313.4, step = 6671360, mean_episode_return = None, mean_episode_step = 2100.1, total_loss = -127.76, pg_loss = -125.54, baseline_loss = 9.9604, entropy_loss = -12.18, learner_queue_size = 64, _tick = 860, _time = 1.6548e+09)
[2022-06-09 14:19:15,486][root][INFO] - Step 6686720 @ 3069.5 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 2318.4, step = 6686720, mean_episode_return = None, mean_episode_step = 1794.8, total_loss = 204.03, pg_loss = 163.22, baseline_loss = 52.999, entropy_loss = -12.193, learner_queue_size = 64, _tick = 862, _time = 1.6548e+09)
[2022-06-09 14:19:20,490][root][INFO] - Step 6702080 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 2323.4, step = 6702080, mean_episode_return = None, mean_episode_step = 2253.1, total_loss = -105.84, pg_loss = -105.35, baseline_loss = 11.493, entropy_loss = -11.985, learner_queue_size = 64, _tick = 863, _time = 1.6548e+09)
[2022-06-09 14:19:25,494][root][INFO] - Step 6717440 @ 3069.6 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 2328.4, step = 6717440, mean_episode_return = None, mean_episode_step = 1818.0, total_loss = 62.006, pg_loss = 35.181, baseline_loss = 38.801, entropy_loss = -11.976, learner_queue_size = 64, _tick = 864, _time = 1.6548e+09)
[2022-06-09 14:19:30,498][root][INFO] - Step 6732800 @ 3069.6 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 2333.4, step = 6732800, mean_episode_return = 3.8995, mean_episode_step = 1750.3, total_loss = -10.569, pg_loss = -29.373, baseline_loss = 30.736, entropy_loss = -11.932, learner_queue_size = 64, _tick = 867, _time = 1.6548e+09)
[2022-06-09 14:19:35,502][root][INFO] - Step 6748160 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 2338.4, step = 6748160, mean_episode_return = 86.49, mean_episode_step = 2165.8, total_loss = 24.397, pg_loss = 8.1221, baseline_loss = 28.072, entropy_loss = -11.798, learner_queue_size = 64, _tick = 869, _time = 1.6548e+09)
[2022-06-09 14:19:40,506][root][INFO] - Step 6763520 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 2343.4, step = 6763520, mean_episode_return = 13.85, mean_episode_step = 2223.6, total_loss = -60.092, pg_loss = -70.463, baseline_loss = 22.641, entropy_loss = -12.27, learner_queue_size = 64, _tick = 870, _time = 1.6548e+09)
[2022-06-09 14:19:45,511][root][INFO] - Step 6778880 @ 3068.6 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 2348.4, step = 6778880, mean_episode_return = -3.81, mean_episode_step = 2725.9, total_loss = -101.82, pg_loss = -96.617, baseline_loss = 7.2888, entropy_loss = -12.487, learner_queue_size = 64, _tick = 871, _time = 1.6548e+09)
[2022-06-09 14:19:50,517][root][INFO] - Step 6794240 @ 3068.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 2353.5, step = 6794240, mean_episode_return = None, mean_episode_step = 2544.0, total_loss = 224.74, pg_loss = 174.09, baseline_loss = 62.901, entropy_loss = -12.245, learner_queue_size = 64, _tick = 873, _time = 1.6548e+09)
[2022-06-09 14:19:55,522][root][INFO] - Step 6809600 @ 3069.0 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 2358.5, step = 6809600, mean_episode_return = 121.21, mean_episode_step = 1960.1, total_loss = -155.52, pg_loss = -154.74, baseline_loss = 11.592, entropy_loss = -12.374, learner_queue_size = 64, _tick = 876, _time = 1.6548e+09)
[2022-06-09 14:20:00,526][root][INFO] - Step 6830080 @ 4092.7 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 2363.5, step = 6830080, mean_episode_return = 68.651, mean_episode_step = 1731.2, total_loss = 115.48, pg_loss = 91.728, baseline_loss = 36.225, entropy_loss = -12.47, learner_queue_size = 64, _tick = 879, _time = 1.6548e+09)
[2022-06-09 14:20:05,530][root][INFO] - Step 6845440 @ 3069.6 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 2368.5, step = 6845440, mean_episode_return = 95.017, mean_episode_step = 1930.8, total_loss = -153.22, pg_loss = -147.62, baseline_loss = 7.1064, entropy_loss = -12.702, learner_queue_size = 64, _tick = 881, _time = 1.6548e+09)
[2022-06-09 14:20:10,534][root][INFO] - Step 6860800 @ 3069.6 SPS. Inference batcher size: 88. Learner queue size: 64. Other stats: (train_seconds = 2373.5, step = 6860800, mean_episode_return = 37.985, mean_episode_step = 1854.0, total_loss = -4.5676, pg_loss = -13.274, baseline_loss = 21.842, entropy_loss = -13.135, learner_queue_size = 64, _tick = 883, _time = 1.6548e+09)
[2022-06-09 14:20:15,538][root][INFO] - Step 6876160 @ 3069.5 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 2378.5, step = 6876160, mean_episode_return = None, mean_episode_step = 2218.2, total_loss = -131.61, pg_loss = -122.9, baseline_loss = 3.947, entropy_loss = -12.654, learner_queue_size = 64, _tick = 885, _time = 1.6548e+09)
[2022-06-09 14:20:20,542][root][INFO] - Step 6891520 @ 3069.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 2383.5, step = 6891520, mean_episode_return = 31.98, mean_episode_step = 2501.5, total_loss = -40.477, pg_loss = -44.296, baseline_loss = 16.54, entropy_loss = -12.721, learner_queue_size = 64, _tick = 888, _time = 1.6548e+09)
[2022-06-09 14:20:25,546][root][INFO] - Step 6906880 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 2388.5, step = 6906880, mean_episode_return = 14.07, mean_episode_step = 2240.8, total_loss = 150.13, pg_loss = 139.73, baseline_loss = 23.367, entropy_loss = -12.967, learner_queue_size = 64, _tick = 890, _time = 1.6548e+09)
[2022-06-09 14:20:30,550][root][INFO] - Step 6922240 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 2393.5, step = 6922240, mean_episode_return = 10.855, mean_episode_step = 2121.7, total_loss = 303.33, pg_loss = 257.53, baseline_loss = 58.77, entropy_loss = -12.971, learner_queue_size = 64, _tick = 892, _time = 1.6548e+09)
[2022-06-09 14:20:35,554][root][INFO] - Step 6937600 @ 3069.6 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 2398.5, step = 6937600, mean_episode_return = 88.56, mean_episode_step = 2214.9, total_loss = 1748.5, pg_loss = 768.7, baseline_loss = 992.86, entropy_loss = -13.068, learner_queue_size = 64, _tick = 894, _time = 1.6548e+09)
[2022-06-09 14:20:40,558][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 14:20:40,910][root][INFO] - Step 6952960 @ 3069.5 SPS. Inference batcher size: 82. Learner queue size: 64. Other stats: (train_seconds = 2403.5, step = 6958080, mean_episode_return = 83.062, mean_episode_step = 2362.5, total_loss = -94.881, pg_loss = -90.076, baseline_loss = 8.0753, entropy_loss = -12.88, learner_queue_size = 64, _tick = 898, _time = 1.6548e+09)
[2022-06-09 14:20:45,914][root][INFO] - Step 6973440 @ 3823.7 SPS. Inference batcher size: 73. Learner queue size: 64. Other stats: (train_seconds = 2408.9, step = 6973440, mean_episode_return = 41.297, mean_episode_step = 2196.6, total_loss = -30.159, pg_loss = -34.434, baseline_loss = 16.678, entropy_loss = -12.403, learner_queue_size = 64, _tick = 901, _time = 1.6548e+09)
[2022-06-09 14:20:50,918][root][INFO] - Step 6988800 @ 3069.6 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 2413.9, step = 6988800, mean_episode_return = None, mean_episode_step = 2250.6, total_loss = -18.182, pg_loss = -13.237, baseline_loss = 7.1962, entropy_loss = -12.141, learner_queue_size = 64, _tick = 903, _time = 1.6548e+09)
[2022-06-09 14:20:55,922][root][INFO] - Step 7004160 @ 3069.5 SPS. Inference batcher size: 101. Learner queue size: 64. Other stats: (train_seconds = 2418.9, step = 7004160, mean_episode_return = -8.3304, mean_episode_step = 2258.2, total_loss = -37.113, pg_loss = -33.582, baseline_loss = 9.6855, entropy_loss = -13.216, learner_queue_size = 64, _tick = 905, _time = 1.6548e+09)
[2022-06-09 14:21:00,926][root][INFO] - Step 7019520 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 2423.9, step = 7019520, mean_episode_return = 16.918, mean_episode_step = 2282.9, total_loss = 6.1802, pg_loss = 6.3573, baseline_loss = 13.125, entropy_loss = -13.302, learner_queue_size = 64, _tick = 908, _time = 1.6548e+09)
[2022-06-09 14:21:05,930][root][INFO] - Step 7034880 @ 3069.5 SPS. Inference batcher size: 11. Learner queue size: 64. Other stats: (train_seconds = 2428.9, step = 7034880, mean_episode_return = 55.599, mean_episode_step = 2223.4, total_loss = 123.14, pg_loss = 103.1, baseline_loss = 32.826, entropy_loss = -12.788, learner_queue_size = 64, _tick = 911, _time = 1.6548e+09)
[2022-06-09 14:21:10,934][root][INFO] - Step 7050240 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 2433.9, step = 7050240, mean_episode_return = None, mean_episode_step = 2108.7, total_loss = 281.62, pg_loss = 254.1, baseline_loss = 40.598, entropy_loss = -13.076, learner_queue_size = 64, _tick = 913, _time = 1.6548e+09)
[2022-06-09 14:21:15,938][root][INFO] - Step 7065600 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 2438.9, step = 7065600, mean_episode_return = 96.942, mean_episode_step = 2022.7, total_loss = -42.165, pg_loss = -58.035, baseline_loss = 28.943, entropy_loss = -13.073, learner_queue_size = 64, _tick = 916, _time = 1.6548e+09)
[2022-06-09 14:21:20,942][root][INFO] - Step 7086080 @ 4092.7 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 2443.9, step = 7086080, mean_episode_return = None, mean_episode_step = 1904.2, total_loss = 133.96, pg_loss = 115.48, baseline_loss = 31.61, entropy_loss = -13.127, learner_queue_size = 64, _tick = 917, _time = 1.6548e+09)
[2022-06-09 14:21:25,946][root][INFO] - Step 7101440 @ 3069.4 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 2448.9, step = 7101440, mean_episode_return = 24.174, mean_episode_step = 2003.6, total_loss = -1.4076, pg_loss = -7.7222, baseline_loss = 19.133, entropy_loss = -12.818, learner_queue_size = 64, _tick = 920, _time = 1.6548e+09)
[2022-06-09 14:21:30,950][root][INFO] - Step 7116800 @ 3069.6 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 2453.9, step = 7116800, mean_episode_return = None, mean_episode_step = 2098.2, total_loss = -9.371, pg_loss = -13.938, baseline_loss = 17.983, entropy_loss = -13.416, learner_queue_size = 64, _tick = 920, _time = 1.6548e+09)
[2022-06-09 14:21:35,954][root][INFO] - Step 7132160 @ 3069.6 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 2458.9, step = 7132160, mean_episode_return = 21.63, mean_episode_step = 2267.4, total_loss = 40.291, pg_loss = 26.922, baseline_loss = 27.038, entropy_loss = -13.668, learner_queue_size = 64, _tick = 922, _time = 1.6548e+09)
[2022-06-09 14:21:40,958][root][INFO] - Step 7147520 @ 3069.5 SPS. Inference batcher size: 83. Learner queue size: 64. Other stats: (train_seconds = 2463.9, step = 7147520, mean_episode_return = 60.889, mean_episode_step = 1884.6, total_loss = -27.268, pg_loss = -27.257, baseline_loss = 13.856, entropy_loss = -13.868, learner_queue_size = 64, _tick = 925, _time = 1.6548e+09)
[2022-06-09 14:21:45,962][root][INFO] - Step 7162880 @ 3069.6 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 2468.9, step = 7162880, mean_episode_return = -5.5604, mean_episode_step = 2399.5, total_loss = -41.442, pg_loss = -43.836, baseline_loss = 17.034, entropy_loss = -14.64, learner_queue_size = 64, _tick = 927, _time = 1.6548e+09)
[2022-06-09 14:21:50,966][root][INFO] - Step 7178240 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 2473.9, step = 7178240, mean_episode_return = -8.5804, mean_episode_step = 2210.8, total_loss = 109.49, pg_loss = 103.67, baseline_loss = 20.63, entropy_loss = -14.816, learner_queue_size = 64, _tick = 930, _time = 1.6548e+09)
[2022-06-09 14:21:55,970][root][INFO] - Step 7193600 @ 3069.5 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 2478.9, step = 7193600, mean_episode_return = 38.846, mean_episode_step = 2040.0, total_loss = 171.96, pg_loss = 156.95, baseline_loss = 29.542, entropy_loss = -14.541, learner_queue_size = 64, _tick = 933, _time = 1.6548e+09)
[2022-06-09 14:22:00,974][root][INFO] - Step 7208960 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 2483.9, step = 7208960, mean_episode_return = 24.648, mean_episode_step = 2340.3, total_loss = 5.6518, pg_loss = -23.647, baseline_loss = 43.301, entropy_loss = -14.003, learner_queue_size = 64, _tick = 936, _time = 1.6548e+09)
[2022-06-09 14:22:05,978][root][INFO] - Step 7224320 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 2488.9, step = 7224320, mean_episode_return = 55.616, mean_episode_step = 2137.7, total_loss = -23.369, pg_loss = -33.186, baseline_loss = 23.58, entropy_loss = -13.764, learner_queue_size = 64, _tick = 939, _time = 1.6548e+09)
[2022-06-09 14:22:10,982][root][INFO] - Step 7239680 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 2493.9, step = 7239680, mean_episode_return = None, mean_episode_step = 1984.2, total_loss = -57.232, pg_loss = -57.913, baseline_loss = 14.118, entropy_loss = -13.437, learner_queue_size = 64, _tick = 940, _time = 1.6548e+09)
[2022-06-09 14:22:15,986][root][INFO] - Step 7255040 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 2498.9, step = 7255040, mean_episode_return = 9.3241, mean_episode_step = 2141.9, total_loss = 8.2549, pg_loss = -6.9997, baseline_loss = 28.927, entropy_loss = -13.672, learner_queue_size = 64, _tick = 943, _time = 1.6548e+09)
[2022-06-09 14:22:20,990][root][INFO] - Step 7275520 @ 4092.7 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 2503.9, step = 7275520, mean_episode_return = 62.652, mean_episode_step = 2136.2, total_loss = 146.95, pg_loss = 122.28, baseline_loss = 38.494, entropy_loss = -13.828, learner_queue_size = 64, _tick = 947, _time = 1.6548e+09)
[2022-06-09 14:22:25,994][root][INFO] - Step 7290880 @ 3069.5 SPS. Inference batcher size: 75. Learner queue size: 64. Other stats: (train_seconds = 2508.9, step = 7290880, mean_episode_return = 71.174, mean_episode_step = 2130.3, total_loss = 86.01, pg_loss = 62.396, baseline_loss = 37.267, entropy_loss = -13.654, learner_queue_size = 64, _tick = 950, _time = 1.6548e+09)
[2022-06-09 14:22:30,998][root][INFO] - Step 7306240 @ 3069.6 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 2513.9, step = 7306240, mean_episode_return = 10.233, mean_episode_step = 2259.7, total_loss = 8.2182, pg_loss = -11.508, baseline_loss = 33.505, entropy_loss = -13.779, learner_queue_size = 64, _tick = 953, _time = 1.6548e+09)
[2022-06-09 14:22:36,017][root][INFO] - Step 7321600 @ 3060.6 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 2519.0, step = 7321600, mean_episode_return = 23.34, mean_episode_step = 2514.0, total_loss = -154.82, pg_loss = -146.18, baseline_loss = 4.8904, entropy_loss = -13.529, learner_queue_size = 64, _tick = 956, _time = 1.6548e+09)
[2022-06-09 14:22:41,022][root][INFO] - Step 7336960 @ 3068.6 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 2524.0, step = 7336960, mean_episode_return = 18.09, mean_episode_step = 2321.5, total_loss = 10.279, pg_loss = -21.603, baseline_loss = 45.114, entropy_loss = -13.232, learner_queue_size = 64, _tick = 959, _time = 1.6548e+09)
[2022-06-09 14:22:46,026][root][INFO] - Step 7352320 @ 3069.6 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 2529.0, step = 7352320, mean_episode_return = 33.59, mean_episode_step = 1696.8, total_loss = 172.82, pg_loss = 137.61, baseline_loss = 48.054, entropy_loss = -12.845, learner_queue_size = 64, _tick = 961, _time = 1.6548e+09)
[2022-06-09 14:22:51,030][root][INFO] - Step 7367680 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 2534.0, step = 7367680, mean_episode_return = -31.051, mean_episode_step = 1747.0, total_loss = 35.67, pg_loss = 10.753, baseline_loss = 38.366, entropy_loss = -13.45, learner_queue_size = 64, _tick = 962, _time = 1.6548e+09)
[2022-06-09 14:22:56,034][root][INFO] - Step 7383040 @ 3069.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 2539.0, step = 7383040, mean_episode_return = 17.4, mean_episode_step = 1957.5, total_loss = -48.318, pg_loss = -49.834, baseline_loss = 14.347, entropy_loss = -12.831, learner_queue_size = 64, _tick = 965, _time = 1.6548e+09)
[2022-06-09 14:23:01,038][root][INFO] - Step 7398400 @ 3069.5 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 2544.0, step = 7398400, mean_episode_return = 100.05, mean_episode_step = 1933.3, total_loss = -93.2, pg_loss = -102.87, baseline_loss = 22.392, entropy_loss = -12.726, learner_queue_size = 64, _tick = 968, _time = 1.6548e+09)
[2022-06-09 14:23:06,042][root][INFO] - Step 7413760 @ 3069.5 SPS. Inference batcher size: 13. Learner queue size: 64. Other stats: (train_seconds = 2549.0, step = 7413760, mean_episode_return = 46.99, mean_episode_step = 1814.3, total_loss = -36.315, pg_loss = -47.631, baseline_loss = 24.194, entropy_loss = -12.878, learner_queue_size = 64, _tick = 970, _time = 1.6548e+09)
[2022-06-09 14:23:11,046][root][INFO] - Step 7429120 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 2554.0, step = 7429120, mean_episode_return = 45.922, mean_episode_step = 2328.9, total_loss = 73.715, pg_loss = 56.635, baseline_loss = 29.764, entropy_loss = -12.684, learner_queue_size = 64, _tick = 972, _time = 1.6548e+09)
[2022-06-09 14:23:16,050][root][INFO] - Step 7444480 @ 3069.5 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 2559.0, step = 7444480, mean_episode_return = 42.26, mean_episode_step = 2243.6, total_loss = 87.203, pg_loss = 71.379, baseline_loss = 28.758, entropy_loss = -12.933, learner_queue_size = 64, _tick = 974, _time = 1.6548e+09)
[2022-06-09 14:23:21,054][root][INFO] - Step 7464960 @ 4092.8 SPS. Inference batcher size: 86. Learner queue size: 64. Other stats: (train_seconds = 2564.0, step = 7464960, mean_episode_return = 136.58, mean_episode_step = 1827.9, total_loss = -132.65, pg_loss = -143.38, baseline_loss = 23.717, entropy_loss = -12.983, learner_queue_size = 64, _tick = 975, _time = 1.6548e+09)
[2022-06-09 14:23:26,058][root][INFO] - Step 7480320 @ 3069.3 SPS. Inference batcher size: 97. Learner queue size: 64. Other stats: (train_seconds = 2569.0, step = 7480320, mean_episode_return = None, mean_episode_step = 2419.5, total_loss = 122.99, pg_loss = 74.529, baseline_loss = 61.49, entropy_loss = -13.031, learner_queue_size = 64, _tick = 977, _time = 1.6548e+09)
[2022-06-09 14:23:31,062][root][INFO] - Step 7495680 @ 3069.8 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 2574.0, step = 7495680, mean_episode_return = 91.265, mean_episode_step = 2137.4, total_loss = 3.5175, pg_loss = -12.689, baseline_loss = 28.992, entropy_loss = -12.785, learner_queue_size = 64, _tick = 978, _time = 1.6548e+09)
[2022-06-09 14:23:36,066][root][INFO] - Step 7511040 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 2579.0, step = 7511040, mean_episode_return = 20.665, mean_episode_step = 2183.5, total_loss = 17.75, pg_loss = -2.2982, baseline_loss = 32.9, entropy_loss = -12.851, learner_queue_size = 64, _tick = 980, _time = 1.6548e+09)
[2022-06-09 14:23:41,070][root][INFO] - Step 7526400 @ 3069.5 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 2584.0, step = 7526400, mean_episode_return = -30.841, mean_episode_step = 2219.9, total_loss = 385.05, pg_loss = 330.59, baseline_loss = 67.163, entropy_loss = -12.703, learner_queue_size = 64, _tick = 983, _time = 1.6548e+09)
[2022-06-09 14:23:46,074][root][INFO] - Step 7541760 @ 3069.5 SPS. Inference batcher size: 12. Learner queue size: 64. Other stats: (train_seconds = 2589.0, step = 7541760, mean_episode_return = 19.5, mean_episode_step = 2425.0, total_loss = -132.03, pg_loss = -135.68, baseline_loss = 16.551, entropy_loss = -12.903, learner_queue_size = 64, _tick = 985, _time = 1.6548e+09)
[2022-06-09 14:23:51,078][root][INFO] - Step 7557120 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 2594.0, step = 7557120, mean_episode_return = 30.262, mean_episode_step = 2352.3, total_loss = -164.93, pg_loss = -174.65, baseline_loss = 22.748, entropy_loss = -13.022, learner_queue_size = 64, _tick = 988, _time = 1.6548e+09)
[2022-06-09 14:23:56,082][root][INFO] - Step 7572480 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 2599.0, step = 7572480, mean_episode_return = None, mean_episode_step = 2179.0, total_loss = 110.96, pg_loss = 94.099, baseline_loss = 29.718, entropy_loss = -12.853, learner_queue_size = 64, _tick = 989, _time = 1.6548e+09)
[2022-06-09 14:24:01,086][root][INFO] - Step 7587840 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 2604.0, step = 7587840, mean_episode_return = None, mean_episode_step = 1673.3, total_loss = -1.4366, pg_loss = -1.6043, baseline_loss = 12.541, entropy_loss = -12.373, learner_queue_size = 64, _tick = 991, _time = 1.6548e+09)
[2022-06-09 14:24:06,090][root][INFO] - Step 7603200 @ 3069.6 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 2609.0, step = 7603200, mean_episode_return = None, mean_episode_step = 2380.1, total_loss = -26.538, pg_loss = -25.886, baseline_loss = 12.698, entropy_loss = -13.349, learner_queue_size = 64, _tick = 991, _time = 1.6548e+09)
[2022-06-09 14:24:11,094][root][INFO] - Step 7623680 @ 4092.7 SPS. Inference batcher size: 78. Learner queue size: 64. Other stats: (train_seconds = 2614.0, step = 7623680, mean_episode_return = 38.588, mean_episode_step = 2432.0, total_loss = -37.488, pg_loss = -48.274, baseline_loss = 24.325, entropy_loss = -13.54, learner_queue_size = 64, _tick = 994, _time = 1.6548e+09)
[2022-06-09 14:24:16,098][root][INFO] - Step 7639040 @ 3069.6 SPS. Inference batcher size: 86. Learner queue size: 64. Other stats: (train_seconds = 2619.0, step = 7639040, mean_episode_return = None, mean_episode_step = 2630.6, total_loss = -38.294, pg_loss = -35.602, baseline_loss = 10.969, entropy_loss = -13.66, learner_queue_size = 64, _tick = 996, _time = 1.6548e+09)
[2022-06-09 14:24:21,102][root][INFO] - Step 7654400 @ 3069.4 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 2624.0, step = 7654400, mean_episode_return = None, mean_episode_step = 2416.8, total_loss = 20.411, pg_loss = 17.091, baseline_loss = 16.921, entropy_loss = -13.601, learner_queue_size = 64, _tick = 997, _time = 1.6548e+09)
[2022-06-09 14:24:26,106][root][INFO] - Step 7669760 @ 3069.6 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 2629.0, step = 7669760, mean_episode_return = None, mean_episode_step = 2203.7, total_loss = 3.5392, pg_loss = -2.9142, baseline_loss = 20.563, entropy_loss = -14.109, learner_queue_size = 64, _tick = 998, _time = 1.6548e+09)
[2022-06-09 14:24:31,110][root][INFO] - Step 7685120 @ 3069.6 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 2634.0, step = 7685120, mean_episode_return = 43.871, mean_episode_step = 2126.4, total_loss = 138.73, pg_loss = 116.37, baseline_loss = 36.421, entropy_loss = -14.058, learner_queue_size = 64, _tick = 1000, _time = 1.6548e+09)
[2022-06-09 14:24:36,114][root][INFO] - Step 7700480 @ 3069.5 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 2639.1, step = 7700480, mean_episode_return = 42.072, mean_episode_step = 2318.6, total_loss = 66.713, pg_loss = 63.866, baseline_loss = 17.064, entropy_loss = -14.217, learner_queue_size = 64, _tick = 1003, _time = 1.6548e+09)
[2022-06-09 14:24:41,118][root][INFO] - Step 7715840 @ 3069.6 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 2644.1, step = 7715840, mean_episode_return = 31.544, mean_episode_step = 2369.2, total_loss = 60.935, pg_loss = 22.145, baseline_loss = 52.884, entropy_loss = -14.094, learner_queue_size = 64, _tick = 1006, _time = 1.6548e+09)
[2022-06-09 14:24:46,122][root][INFO] - Step 7736320 @ 4092.8 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 2649.1, step = 7736320, mean_episode_return = 94.487, mean_episode_step = 2033.5, total_loss = -89.264, pg_loss = -86.474, baseline_loss = 10.982, entropy_loss = -13.772, learner_queue_size = 64, _tick = 1010, _time = 1.6548e+09)
[2022-06-09 14:24:51,126][root][INFO] - Step 7751680 @ 3069.5 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 2654.1, step = 7751680, mean_episode_return = 38.022, mean_episode_step = 2136.9, total_loss = 51.465, pg_loss = 42.49, baseline_loss = 22.69, entropy_loss = -13.715, learner_queue_size = 64, _tick = 1013, _time = 1.6548e+09)
[2022-06-09 14:24:56,130][root][INFO] - Step 7767040 @ 3069.6 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 2659.1, step = 7767040, mean_episode_return = 33.121, mean_episode_step = 2572.7, total_loss = 29.419, pg_loss = 4.4188, baseline_loss = 38.723, entropy_loss = -13.723, learner_queue_size = 64, _tick = 1015, _time = 1.6548e+09)
[2022-06-09 14:25:01,134][root][INFO] - Step 7782400 @ 3069.5 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 2664.1, step = 7782400, mean_episode_return = 40.025, mean_episode_step = 2277.9, total_loss = 148.78, pg_loss = 122.95, baseline_loss = 39.755, entropy_loss = -13.926, learner_queue_size = 64, _tick = 1016, _time = 1.6548e+09)
[2022-06-09 14:25:06,138][root][INFO] - Step 7797760 @ 3069.6 SPS. Inference batcher size: 2. Learner queue size: 64. Other stats: (train_seconds = 2669.1, step = 7797760, mean_episode_return = 39.311, mean_episode_step = 2324.7, total_loss = -206.51, pg_loss = -195.86, baseline_loss = 3.361, entropy_loss = -14.015, learner_queue_size = 64, _tick = 1019, _time = 1.6548e+09)
[2022-06-09 14:25:11,142][root][INFO] - Step 7813120 @ 3069.6 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 2674.1, step = 7813120, mean_episode_return = 42.141, mean_episode_step = 2418.7, total_loss = 165.84, pg_loss = 142.05, baseline_loss = 37.481, entropy_loss = -13.698, learner_queue_size = 64, _tick = 1022, _time = 1.6548e+09)
[2022-06-09 14:25:16,146][root][INFO] - Step 7828480 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 2679.1, step = 7828480, mean_episode_return = 18.281, mean_episode_step = 2271.0, total_loss = -166.79, pg_loss = -176.07, baseline_loss = 23.199, entropy_loss = -13.925, learner_queue_size = 64, _tick = 1025, _time = 1.6548e+09)
[2022-06-09 14:25:21,150][root][INFO] - Step 7843840 @ 3069.6 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 2684.1, step = 7843840, mean_episode_return = None, mean_episode_step = 2605.3, total_loss = -42.554, pg_loss = -49.847, baseline_loss = 20.976, entropy_loss = -13.684, learner_queue_size = 64, _tick = 1027, _time = 1.6548e+09)
[2022-06-09 14:25:26,154][root][INFO] - Step 7859200 @ 3069.5 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 2689.1, step = 7859200, mean_episode_return = 60.635, mean_episode_step = 1867.4, total_loss = -28.583, pg_loss = -32.837, baseline_loss = 17.093, entropy_loss = -12.84, learner_queue_size = 64, _tick = 1030, _time = 1.6548e+09)
[2022-06-09 14:25:31,158][root][INFO] - Step 7874560 @ 3069.5 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 2694.1, step = 7874560, mean_episode_return = 49.451, mean_episode_step = 1944.4, total_loss = 262.45, pg_loss = 222.7, baseline_loss = 52.891, entropy_loss = -13.14, learner_queue_size = 64, _tick = 1032, _time = 1.6548e+09)
[2022-06-09 14:25:36,162][root][INFO] - Step 7889920 @ 3069.5 SPS. Inference batcher size: 11. Learner queue size: 64. Other stats: (train_seconds = 2699.1, step = 7889920, mean_episode_return = 88.355, mean_episode_step = 2620.2, total_loss = 213.64, pg_loss = 172.33, baseline_loss = 54.408, entropy_loss = -13.107, learner_queue_size = 64, _tick = 1034, _time = 1.6548e+09)
[2022-06-09 14:25:41,168][root][INFO] - Step 7905280 @ 3068.3 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 2704.1, step = 7905280, mean_episode_return = 32.302, mean_episode_step = 2276.5, total_loss = -123.94, pg_loss = -124.92, baseline_loss = 14.11, entropy_loss = -13.124, learner_queue_size = 64, _tick = 1037, _time = 1.6548e+09)
[2022-06-09 14:25:46,174][root][INFO] - Step 7925760 @ 4091.2 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 2709.1, step = 7925760, mean_episode_return = 9.4199, mean_episode_step = 2373.6, total_loss = 96.838, pg_loss = 81.461, baseline_loss = 29.27, entropy_loss = -13.893, learner_queue_size = 64, _tick = 1040, _time = 1.6548e+09)
[2022-06-09 14:25:51,178][root][INFO] - Step 7941120 @ 3069.6 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 2714.1, step = 7941120, mean_episode_return = 140.13, mean_episode_step = 2271.7, total_loss = 104.75, pg_loss = 73.183, baseline_loss = 45.262, entropy_loss = -13.699, learner_queue_size = 64, _tick = 1043, _time = 1.6548e+09)
[2022-06-09 14:25:56,182][root][INFO] - Step 7956480 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 2719.1, step = 7956480, mean_episode_return = 56.37, mean_episode_step = 1951.4, total_loss = 132.34, pg_loss = 97.223, baseline_loss = 48.737, entropy_loss = -13.618, learner_queue_size = 64, _tick = 1046, _time = 1.6548e+09)
[2022-06-09 14:26:01,188][root][INFO] - Step 7971840 @ 3068.3 SPS. Inference batcher size: 2. Learner queue size: 64. Other stats: (train_seconds = 2724.1, step = 7971840, mean_episode_return = 23.738, mean_episode_step = 1981.2, total_loss = -263.7, pg_loss = -255.26, baseline_loss = 5.3154, entropy_loss = -13.754, learner_queue_size = 64, _tick = 1049, _time = 1.6548e+09)
[2022-06-09 14:26:06,194][root][INFO] - Step 7987200 @ 3068.1 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 2729.1, step = 7987200, mean_episode_return = 26.56, mean_episode_step = 2159.6, total_loss = -6.3087, pg_loss = -15.998, baseline_loss = 23.222, entropy_loss = -13.533, learner_queue_size = 64, _tick = 1051, _time = 1.6548e+09)
[2022-06-09 14:26:11,198][root][INFO] - Step 8002560 @ 3069.8 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 2734.1, step = 8002560, mean_episode_return = None, mean_episode_step = 1910.2, total_loss = -87.216, pg_loss = -86.079, baseline_loss = 12.316, entropy_loss = -13.453, learner_queue_size = 64, _tick = 1053, _time = 1.6548e+09)
[2022-06-09 14:26:16,202][root][INFO] - Step 8017920 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 2739.1, step = 8017920, mean_episode_return = None, mean_episode_step = 2044.1, total_loss = 177.73, pg_loss = 151.17, baseline_loss = 39.969, entropy_loss = -13.406, learner_queue_size = 64, _tick = 1055, _time = 1.6548e+09)
[2022-06-09 14:26:21,206][root][INFO] - Step 8033280 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 2744.1, step = 8033280, mean_episode_return = 27.1, mean_episode_step = 1912.1, total_loss = -100.55, pg_loss = -117.17, baseline_loss = 30.05, entropy_loss = -13.433, learner_queue_size = 64, _tick = 1057, _time = 1.6548e+09)
[2022-06-09 14:26:26,210][root][INFO] - Step 8048640 @ 3069.6 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 2749.1, step = 8048640, mean_episode_return = 60.997, mean_episode_step = 1881.8, total_loss = -61.093, pg_loss = -80.786, baseline_loss = 33.519, entropy_loss = -13.826, learner_queue_size = 64, _tick = 1060, _time = 1.6548e+09)
[2022-06-09 14:26:31,214][root][INFO] - Step 8064000 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 2754.1, step = 8064000, mean_episode_return = None, mean_episode_step = 1641.8, total_loss = 269.44, pg_loss = 233.86, baseline_loss = 49.341, entropy_loss = -13.753, learner_queue_size = 64, _tick = 1062, _time = 1.6548e+09)
[2022-06-09 14:26:36,219][root][INFO] - Step 8079360 @ 3068.8 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 2759.2, step = 8079360, mean_episode_return = -5.3703, mean_episode_step = 1922.7, total_loss = 12.949, pg_loss = -7.3759, baseline_loss = 33.931, entropy_loss = -13.606, learner_queue_size = 64, _tick = 1065, _time = 1.6548e+09)
[2022-06-09 14:26:41,251][root][INFO] - Step 8099840 @ 4069.7 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 2764.2, step = 8099840, mean_episode_return = 33.004, mean_episode_step = 1724.3, total_loss = 75.468, pg_loss = 36.769, baseline_loss = 52.265, entropy_loss = -13.567, learner_queue_size = 64, _tick = 1068, _time = 1.6548e+09)
[2022-06-09 14:26:46,254][root][INFO] - Step 8115200 @ 3070.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 2769.2, step = 8115200, mean_episode_return = 54.42, mean_episode_step = 2100.1, total_loss = 189.57, pg_loss = 149.52, baseline_loss = 53.441, entropy_loss = -13.395, learner_queue_size = 64, _tick = 1071, _time = 1.6548e+09)
[2022-06-09 14:26:51,258][root][INFO] - Step 8130560 @ 3069.3 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 2774.2, step = 8130560, mean_episode_return = 149.09, mean_episode_step = 2069.8, total_loss = -74.758, pg_loss = -81.36, baseline_loss = 20.104, entropy_loss = -13.501, learner_queue_size = 64, _tick = 1074, _time = 1.6548e+09)
[2022-06-09 14:26:56,262][root][INFO] - Step 8145920 @ 3069.7 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 2779.2, step = 8145920, mean_episode_return = 33.293, mean_episode_step = 1806.5, total_loss = -164.73, pg_loss = -172.63, baseline_loss = 21.207, entropy_loss = -13.314, learner_queue_size = 64, _tick = 1077, _time = 1.6548e+09)
[2022-06-09 14:27:01,266][root][INFO] - Step 8161280 @ 3069.5 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 2784.2, step = 8161280, mean_episode_return = None, mean_episode_step = 1962.2, total_loss = 204.26, pg_loss = 165.91, baseline_loss = 51.653, entropy_loss = -13.301, learner_queue_size = 64, _tick = 1078, _time = 1.6548e+09)
[2022-06-09 14:27:06,270][root][INFO] - Step 8176640 @ 3069.5 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 2789.2, step = 8176640, mean_episode_return = 76.02, mean_episode_step = 2138.8, total_loss = -90.519, pg_loss = -104.4, baseline_loss = 27.04, entropy_loss = -13.16, learner_queue_size = 64, _tick = 1080, _time = 1.6548e+09)
[2022-06-09 14:27:11,274][root][INFO] - Step 8192000 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 2794.2, step = 8192000, mean_episode_return = 108.55, mean_episode_step = 1911.1, total_loss = -89.677, pg_loss = -99.343, baseline_loss = 22.77, entropy_loss = -13.104, learner_queue_size = 64, _tick = 1083, _time = 1.6548e+09)
[2022-06-09 14:27:16,278][root][INFO] - Step 8207360 @ 3069.5 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 2799.2, step = 8207360, mean_episode_return = 12.2, mean_episode_step = 2181.4, total_loss = 190.66, pg_loss = 158.18, baseline_loss = 45.845, entropy_loss = -13.357, learner_queue_size = 64, _tick = 1085, _time = 1.6548e+09)
[2022-06-09 14:27:21,282][root][INFO] - Step 8222720 @ 3069.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 2804.2, step = 8222720, mean_episode_return = 22.688, mean_episode_step = 2206.3, total_loss = -71.974, pg_loss = -79.324, baseline_loss = 20.79, entropy_loss = -13.439, learner_queue_size = 64, _tick = 1088, _time = 1.6548e+09)
[2022-06-09 14:27:26,286][root][INFO] - Step 8238080 @ 3069.5 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 2809.2, step = 8238080, mean_episode_return = 115.78, mean_episode_step = 2025.7, total_loss = -61.326, pg_loss = -56.274, baseline_loss = 7.6345, entropy_loss = -12.687, learner_queue_size = 64, _tick = 1091, _time = 1.6548e+09)
[2022-06-09 14:27:31,290][root][INFO] - Step 8253440 @ 3069.5 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 2814.2, step = 8253440, mean_episode_return = None, mean_episode_step = 1996.7, total_loss = -73.54, pg_loss = -73.688, baseline_loss = 13.191, entropy_loss = -13.044, learner_queue_size = 64, _tick = 1092, _time = 1.6548e+09)
[2022-06-09 14:27:36,294][root][INFO] - Step 8268800 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 2819.2, step = 8268800, mean_episode_return = 14.88, mean_episode_step = 2167.1, total_loss = -184.19, pg_loss = -174.67, baseline_loss = 3.6068, entropy_loss = -13.128, learner_queue_size = 64, _tick = 1095, _time = 1.6548e+09)
[2022-06-09 14:27:41,300][root][INFO] - Step 8284160 @ 3068.2 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 2824.2, step = 8284160, mean_episode_return = 17.627, mean_episode_step = 2009.8, total_loss = -261.06, pg_loss = -257.94, baseline_loss = 9.9349, entropy_loss = -13.063, learner_queue_size = 64, _tick = 1098, _time = 1.6548e+09)
[2022-06-09 14:27:46,306][root][INFO] - Step 8304640 @ 4091.3 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 2829.2, step = 8304640, mean_episode_return = 76.903, mean_episode_step = 1728.6, total_loss = 185.76, pg_loss = 154.18, baseline_loss = 44.833, entropy_loss = -13.246, learner_queue_size = 64, _tick = 1102, _time = 1.6548e+09)
[2022-06-09 14:27:51,310][root][INFO] - Step 8320000 @ 3069.6 SPS. Inference batcher size: 87. Learner queue size: 64. Other stats: (train_seconds = 2834.2, step = 8320000, mean_episode_return = 34.889, mean_episode_step = 2025.4, total_loss = 133.12, pg_loss = 97.458, baseline_loss = 48.832, entropy_loss = -13.172, learner_queue_size = 64, _tick = 1105, _time = 1.6548e+09)
[2022-06-09 14:27:56,314][root][INFO] - Step 8335360 @ 3069.5 SPS. Inference batcher size: 80. Learner queue size: 64. Other stats: (train_seconds = 2839.3, step = 8335360, mean_episode_return = None, mean_episode_step = 2192.2, total_loss = -29.565, pg_loss = -38.303, baseline_loss = 21.86, entropy_loss = -13.122, learner_queue_size = 64, _tick = 1107, _time = 1.6548e+09)
[2022-06-09 14:28:01,318][root][INFO] - Step 8350720 @ 3069.6 SPS. Inference batcher size: 72. Learner queue size: 64. Other stats: (train_seconds = 2844.3, step = 8350720, mean_episode_return = 106.88, mean_episode_step = 1811.3, total_loss = -19.308, pg_loss = -26.86, baseline_loss = 20.716, entropy_loss = -13.164, learner_queue_size = 64, _tick = 1110, _time = 1.6548e+09)
[2022-06-09 14:28:06,329][root][INFO] - Step 8366080 @ 3065.2 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 2849.3, step = 8366080, mean_episode_return = 33.589, mean_episode_step = 2143.6, total_loss = 67.927, pg_loss = 62.416, baseline_loss = 18.648, entropy_loss = -13.137, learner_queue_size = 64, _tick = 1113, _time = 1.6548e+09)
[2022-06-09 14:28:11,334][root][INFO] - Step 8381440 @ 3069.0 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 2854.3, step = 8381440, mean_episode_return = 61.665, mean_episode_step = 1945.3, total_loss = -50.478, pg_loss = -56.094, baseline_loss = 18.711, entropy_loss = -13.095, learner_queue_size = 64, _tick = 1116, _time = 1.6548e+09)
[2022-06-09 14:28:16,338][root][INFO] - Step 8396800 @ 3069.6 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 2859.3, step = 8396800, mean_episode_return = 45.191, mean_episode_step = 1873.5, total_loss = -105.28, pg_loss = -106.65, baseline_loss = 14.706, entropy_loss = -13.332, learner_queue_size = 64, _tick = 1118, _time = 1.6548e+09)
[2022-06-09 14:28:21,342][root][INFO] - Step 8412160 @ 3069.5 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 2864.3, step = 8412160, mean_episode_return = 2.8095, mean_episode_step = 2396.0, total_loss = 155.15, pg_loss = 122.05, baseline_loss = 46.401, entropy_loss = -13.308, learner_queue_size = 64, _tick = 1120, _time = 1.6548e+09)
[2022-06-09 14:28:26,346][root][INFO] - Step 8427520 @ 3069.6 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 2869.3, step = 8427520, mean_episode_return = 23.499, mean_episode_step = 2053.6, total_loss = 89.245, pg_loss = 65.213, baseline_loss = 37.157, entropy_loss = -13.125, learner_queue_size = 64, _tick = 1123, _time = 1.6548e+09)
[2022-06-09 14:28:31,350][root][INFO] - Step 8448000 @ 4092.7 SPS. Inference batcher size: 85. Learner queue size: 64. Other stats: (train_seconds = 2874.3, step = 8448000, mean_episode_return = None, mean_episode_step = 1496.9, total_loss = 52.685, pg_loss = 41.228, baseline_loss = 24.281, entropy_loss = -12.824, learner_queue_size = 64, _tick = 1126, _time = 1.6548e+09)
[2022-06-09 14:28:36,354][root][INFO] - Step 8463360 @ 3069.5 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 2879.3, step = 8463360, mean_episode_return = 24.23, mean_episode_step = 1928.8, total_loss = 89.833, pg_loss = 62.241, baseline_loss = 40.441, entropy_loss = -12.85, learner_queue_size = 64, _tick = 1129, _time = 1.6548e+09)
[2022-06-09 14:28:41,358][root][INFO] - Step 8478720 @ 3069.5 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 2884.3, step = 8478720, mean_episode_return = 69.406, mean_episode_step = 2249.8, total_loss = 45.248, pg_loss = 36.121, baseline_loss = 21.814, entropy_loss = -12.686, learner_queue_size = 64, _tick = 1132, _time = 1.6548e+09)
[2022-06-09 14:28:46,362][root][INFO] - Step 8494080 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 2889.3, step = 8494080, mean_episode_return = 57.472, mean_episode_step = 2392.2, total_loss = 16.261, pg_loss = 3.6963, baseline_loss = 25.234, entropy_loss = -12.669, learner_queue_size = 64, _tick = 1134, _time = 1.6548e+09)
[2022-06-09 14:28:51,366][root][INFO] - Step 8509440 @ 3069.5 SPS. Inference batcher size: 89. Learner queue size: 64. Other stats: (train_seconds = 2894.3, step = 8509440, mean_episode_return = None, mean_episode_step = 2055.2, total_loss = -24.37, pg_loss = -21.693, baseline_loss = 10.377, entropy_loss = -13.055, learner_queue_size = 64, _tick = 1136, _time = 1.6548e+09)
[2022-06-09 14:28:56,370][root][INFO] - Step 8524800 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 2899.3, step = 8524800, mean_episode_return = 16.807, mean_episode_step = 2348.0, total_loss = -112.98, pg_loss = -115.75, baseline_loss = 15.858, entropy_loss = -13.089, learner_queue_size = 64, _tick = 1138, _time = 1.6548e+09)
[2022-06-09 14:29:01,374][root][INFO] - Step 8540160 @ 3069.6 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 2904.3, step = 8540160, mean_episode_return = 276.7, mean_episode_step = 2714.7, total_loss = -106.94, pg_loss = -110.53, baseline_loss = 17.027, entropy_loss = -13.435, learner_queue_size = 64, _tick = 1141, _time = 1.6548e+09)
[2022-06-09 14:29:06,378][root][INFO] - Step 8555520 @ 3069.5 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 2909.3, step = 8555520, mean_episode_return = -16.976, mean_episode_step = 2264.4, total_loss = -19.838, pg_loss = -22.304, baseline_loss = 15.99, entropy_loss = -13.524, learner_queue_size = 64, _tick = 1143, _time = 1.6548e+09)
[2022-06-09 14:29:11,382][root][INFO] - Step 8570880 @ 3069.5 SPS. Inference batcher size: 2. Learner queue size: 64. Other stats: (train_seconds = 2914.3, step = 8570880, mean_episode_return = 27.975, mean_episode_step = 2192.6, total_loss = 70.477, pg_loss = 43.073, baseline_loss = 40.825, entropy_loss = -13.421, learner_queue_size = 64, _tick = 1146, _time = 1.6548e+09)
[2022-06-09 14:29:16,386][root][INFO] - Step 8586240 @ 3069.6 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 2919.3, step = 8586240, mean_episode_return = 108.13, mean_episode_step = 2033.7, total_loss = 106.83, pg_loss = 70.025, baseline_loss = 50.015, entropy_loss = -13.205, learner_queue_size = 64, _tick = 1149, _time = 1.6548e+09)
[2022-06-09 14:29:21,390][root][INFO] - Step 8601600 @ 3069.5 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 2924.3, step = 8601600, mean_episode_return = 73.72, mean_episode_step = 2034.2, total_loss = 91.939, pg_loss = 69.257, baseline_loss = 36.294, entropy_loss = -13.612, learner_queue_size = 64, _tick = 1152, _time = 1.6548e+09)
[2022-06-09 14:29:26,396][root][INFO] - Step 8616960 @ 3068.2 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 2929.3, step = 8616960, mean_episode_return = None, mean_episode_step = 2012.7, total_loss = -20.92, pg_loss = -32.097, baseline_loss = 24.948, entropy_loss = -13.772, learner_queue_size = 64, _tick = 1154, _time = 1.6548e+09)
[2022-06-09 14:29:31,402][root][INFO] - Step 8637440 @ 4091.3 SPS. Inference batcher size: 96. Learner queue size: 64. Other stats: (train_seconds = 2934.3, step = 8637440, mean_episode_return = 22.414, mean_episode_step = 2232.7, total_loss = -125.74, pg_loss = -130.41, baseline_loss = 18.237, entropy_loss = -13.564, learner_queue_size = 64, _tick = 1158, _time = 1.6548e+09)
[2022-06-09 14:29:36,406][root][INFO] - Step 8652800 @ 3069.4 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 2939.3, step = 8652800, mean_episode_return = 53.023, mean_episode_step = 1908.5, total_loss = 175.88, pg_loss = 137.42, baseline_loss = 51.994, entropy_loss = -13.537, learner_queue_size = 64, _tick = 1160, _time = 1.6548e+09)
[2022-06-09 14:29:41,412][root][INFO] - Step 8668160 @ 3068.3 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 2944.3, step = 8668160, mean_episode_return = None, mean_episode_step = 1850.3, total_loss = 163.99, pg_loss = 130.23, baseline_loss = 47.114, entropy_loss = -13.356, learner_queue_size = 64, _tick = 1162, _time = 1.6548e+09)
[2022-06-09 14:29:46,418][root][INFO] - Step 8683520 @ 3068.4 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 2949.4, step = 8683520, mean_episode_return = None, mean_episode_step = 1887.0, total_loss = 389.53, pg_loss = 294.04, baseline_loss = 108.86, entropy_loss = -13.375, learner_queue_size = 64, _tick = 1164, _time = 1.6548e+09)
[2022-06-09 14:29:51,422][root][INFO] - Step 8698880 @ 3069.5 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 2954.4, step = 8698880, mean_episode_return = 39.333, mean_episode_step = 2011.3, total_loss = -111.94, pg_loss = -147.51, baseline_loss = 48.981, entropy_loss = -13.405, learner_queue_size = 64, _tick = 1167, _time = 1.6548e+09)
[2022-06-09 14:29:56,426][root][INFO] - Step 8714240 @ 3069.6 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 2959.4, step = 8714240, mean_episode_return = 62.666, mean_episode_step = 1848.6, total_loss = -117.1, pg_loss = -121.12, baseline_loss = 17.455, entropy_loss = -13.433, learner_queue_size = 64, _tick = 1170, _time = 1.6548e+09)
[2022-06-09 14:30:01,430][root][INFO] - Step 8729600 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 2964.4, step = 8729600, mean_episode_return = 1.1746, mean_episode_step = 1675.8, total_loss = 58.36, pg_loss = 42.227, baseline_loss = 29.316, entropy_loss = -13.183, learner_queue_size = 64, _tick = 1173, _time = 1.6548e+09)
[2022-06-09 14:30:06,434][root][INFO] - Step 8744960 @ 3069.6 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 2969.4, step = 8744960, mean_episode_return = 98.65, mean_episode_step = 1792.8, total_loss = -92.917, pg_loss = -89.092, baseline_loss = 9.4837, entropy_loss = -13.309, learner_queue_size = 64, _tick = 1175, _time = 1.6548e+09)
[2022-06-09 14:30:11,438][root][INFO] - Step 8760320 @ 3069.5 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 2974.4, step = 8760320, mean_episode_return = 75.418, mean_episode_step = 1645.4, total_loss = -10.166, pg_loss = -29.21, baseline_loss = 32.172, entropy_loss = -13.128, learner_queue_size = 64, _tick = 1178, _time = 1.6548e+09)
[2022-06-09 14:30:16,442][root][INFO] - Step 8775680 @ 3069.5 SPS. Inference batcher size: 14. Learner queue size: 64. Other stats: (train_seconds = 2979.4, step = 8775680, mean_episode_return = 95.089, mean_episode_step = 1887.9, total_loss = 51.967, pg_loss = 26.769, baseline_loss = 38.236, entropy_loss = -13.038, learner_queue_size = 64, _tick = 1181, _time = 1.6548e+09)
[2022-06-09 14:30:21,446][root][INFO] - Step 8791040 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 2984.4, step = 8791040, mean_episode_return = 47.323, mean_episode_step = 1727.4, total_loss = -23.867, pg_loss = -28.47, baseline_loss = 17.899, entropy_loss = -13.297, learner_queue_size = 64, _tick = 1184, _time = 1.6548e+09)
[2022-06-09 14:30:26,450][root][INFO] - Step 8806400 @ 3069.6 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 2989.4, step = 8806400, mean_episode_return = 18.88, mean_episode_step = 1807.8, total_loss = 28.01, pg_loss = 3.2074, baseline_loss = 37.902, entropy_loss = -13.099, learner_queue_size = 64, _tick = 1186, _time = 1.6548e+09)
[2022-06-09 14:30:31,456][root][INFO] - Step 8821760 @ 3068.2 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 2994.4, step = 8821760, mean_episode_return = 5.0697, mean_episode_step = 1824.2, total_loss = -74.623, pg_loss = -89.527, baseline_loss = 27.806, entropy_loss = -12.903, learner_queue_size = 64, _tick = 1189, _time = 1.6548e+09)
[2022-06-09 14:30:36,462][root][INFO] - Step 8842240 @ 4091.3 SPS. Inference batcher size: 80. Learner queue size: 64. Other stats: (train_seconds = 2999.4, step = 8842240, mean_episode_return = 17.383, mean_episode_step = 1536.0, total_loss = 175.06, pg_loss = 116.99, baseline_loss = 70.78, entropy_loss = -12.71, learner_queue_size = 64, _tick = 1193, _time = 1.6548e+09)
[2022-06-09 14:30:41,466][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 14:30:41,673][root][INFO] - Step 8857600 @ 3069.5 SPS. Inference batcher size: 81. Learner queue size: 64. Other stats: (train_seconds = 3004.4, step = 8857600, mean_episode_return = 1.9497, mean_episode_step = 1619.7, total_loss = 101.35, pg_loss = 81.876, baseline_loss = 31.814, entropy_loss = -12.345, learner_queue_size = 64, _tick = 1195, _time = 1.6548e+09)
[2022-06-09 14:30:46,678][root][INFO] - Step 8872960 @ 2947.1 SPS. Inference batcher size: 76. Learner queue size: 64. Other stats: (train_seconds = 3009.6, step = 8872960, mean_episode_return = -3.6703, mean_episode_step = 2055.9, total_loss = -30.358, pg_loss = -41.991, baseline_loss = 24.147, entropy_loss = -12.514, learner_queue_size = 64, _tick = 1197, _time = 1.6548e+09)
[2022-06-09 14:30:51,682][root][INFO] - Step 8888320 @ 3069.5 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 3014.6, step = 8888320, mean_episode_return = 27.472, mean_episode_step = 1744.1, total_loss = 152.21, pg_loss = 102.19, baseline_loss = 62.31, entropy_loss = -12.291, learner_queue_size = 64, _tick = 1199, _time = 1.6548e+09)
[2022-06-09 14:30:56,699][root][INFO] - Step 8903680 @ 3061.6 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 3019.6, step = 8903680, mean_episode_return = 62.971, mean_episode_step = 1666.5, total_loss = 301.3, pg_loss = 245.93, baseline_loss = 67.331, entropy_loss = -11.966, learner_queue_size = 64, _tick = 1201, _time = 1.6548e+09)
[2022-06-09 14:31:01,702][root][INFO] - Step 8919040 @ 3070.1 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 3024.6, step = 8919040, mean_episode_return = 73.95, mean_episode_step = 1737.9, total_loss = -94.173, pg_loss = -116.97, baseline_loss = 34.767, entropy_loss = -11.967, learner_queue_size = 64, _tick = 1202, _time = 1.6548e+09)
[2022-06-09 14:31:06,706][root][INFO] - Step 8934400 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 3029.6, step = 8934400, mean_episode_return = 26.05, mean_episode_step = 1747.2, total_loss = 163.28, pg_loss = 124.76, baseline_loss = 50.666, entropy_loss = -12.148, learner_queue_size = 64, _tick = 1204, _time = 1.6548e+09)
[2022-06-09 14:31:11,710][root][INFO] - Step 8949760 @ 3069.5 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 3034.6, step = 8949760, mean_episode_return = None, mean_episode_step = 2239.7, total_loss = -14.299, pg_loss = -26.873, baseline_loss = 24.434, entropy_loss = -11.859, learner_queue_size = 64, _tick = 1205, _time = 1.6548e+09)
[2022-06-09 14:31:16,714][root][INFO] - Step 8965120 @ 3069.6 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 3039.6, step = 8965120, mean_episode_return = 25.074, mean_episode_step = 1883.6, total_loss = -53.318, pg_loss = -71.526, baseline_loss = 29.605, entropy_loss = -11.397, learner_queue_size = 64, _tick = 1207, _time = 1.6548e+09)
[2022-06-09 14:31:21,718][root][INFO] - Step 8985600 @ 4092.7 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 3044.7, step = 8985600, mean_episode_return = 9.9799, mean_episode_step = 2258.1, total_loss = -91.07, pg_loss = -99.194, baseline_loss = 19.214, entropy_loss = -11.09, learner_queue_size = 64, _tick = 1211, _time = 1.6548e+09)
[2022-06-09 14:31:26,722][root][INFO] - Step 9000960 @ 3069.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 3049.7, step = 9000960, mean_episode_return = 23.325, mean_episode_step = 1714.4, total_loss = -20.042, pg_loss = -35.972, baseline_loss = 27.63, entropy_loss = -11.699, learner_queue_size = 64, _tick = 1214, _time = 1.6548e+09)
[2022-06-09 14:31:31,726][root][INFO] - Step 9016320 @ 3069.5 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 3054.7, step = 9016320, mean_episode_return = 55.899, mean_episode_step = 2314.3, total_loss = -64.475, pg_loss = -78.405, baseline_loss = 25.427, entropy_loss = -11.497, learner_queue_size = 64, _tick = 1216, _time = 1.6548e+09)
[2022-06-09 14:31:36,730][root][INFO] - Step 9031680 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 3059.7, step = 9031680, mean_episode_return = 25.38, mean_episode_step = 2023.7, total_loss = 47.492, pg_loss = 21.845, baseline_loss = 37.315, entropy_loss = -11.669, learner_queue_size = 64, _tick = 1219, _time = 1.6548e+09)
[2022-06-09 14:31:41,735][root][INFO] - Step 9047040 @ 3069.1 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 3064.7, step = 9047040, mean_episode_return = -10.99, mean_episode_step = 1801.9, total_loss = -123.81, pg_loss = -138.78, baseline_loss = 26.565, entropy_loss = -11.587, learner_queue_size = 64, _tick = 1222, _time = 1.6548e+09)
[2022-06-09 14:31:46,741][root][INFO] - Step 9062400 @ 3067.9 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 3069.7, step = 9062400, mean_episode_return = -3.6404, mean_episode_step = 2247.6, total_loss = -191.58, pg_loss = -200.68, baseline_loss = 20.864, entropy_loss = -11.763, learner_queue_size = 64, _tick = 1225, _time = 1.6548e+09)
[2022-06-09 14:31:51,746][root][INFO] - Step 9077760 @ 3069.2 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 3074.7, step = 9077760, mean_episode_return = None, mean_episode_step = 2152.0, total_loss = 165.57, pg_loss = 140.71, baseline_loss = 36.852, entropy_loss = -11.988, learner_queue_size = 64, _tick = 1225, _time = 1.6548e+09)
[2022-06-09 14:31:56,750][root][INFO] - Step 9093120 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 3079.7, step = 9093120, mean_episode_return = -42.102, mean_episode_step = 2006.3, total_loss = -75.204, pg_loss = -94.491, baseline_loss = 31.395, entropy_loss = -12.108, learner_queue_size = 64, _tick = 1228, _time = 1.6548e+09)
[2022-06-09 14:32:01,754][root][INFO] - Step 9108480 @ 3069.4 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 3084.7, step = 9108480, mean_episode_return = 63.52, mean_episode_step = 1999.0, total_loss = -20.614, pg_loss = -41.686, baseline_loss = 33.111, entropy_loss = -12.04, learner_queue_size = 64, _tick = 1231, _time = 1.6548e+09)
[2022-06-09 14:32:06,758][root][INFO] - Step 9128960 @ 4092.8 SPS. Inference batcher size: 86. Learner queue size: 64. Other stats: (train_seconds = 3089.7, step = 9128960, mean_episode_return = 48.01, mean_episode_step = 1923.4, total_loss = -54.103, pg_loss = -52.153, baseline_loss = 9.535, entropy_loss = -11.485, learner_queue_size = 64, _tick = 1235, _time = 1.6548e+09)
[2022-06-09 14:32:11,762][root][INFO] - Step 9144320 @ 3069.6 SPS. Inference batcher size: 71. Learner queue size: 64. Other stats: (train_seconds = 3094.7, step = 9144320, mean_episode_return = 52.756, mean_episode_step = 2024.7, total_loss = 46.203, pg_loss = 26.925, baseline_loss = 31.191, entropy_loss = -11.913, learner_queue_size = 64, _tick = 1236, _time = 1.6548e+09)
[2022-06-09 14:32:16,766][root][INFO] - Step 9159680 @ 3069.6 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 3099.7, step = 9159680, mean_episode_return = -6.9003, mean_episode_step = 2396.2, total_loss = -51.285, pg_loss = -51.822, baseline_loss = 12.662, entropy_loss = -12.124, learner_queue_size = 64, _tick = 1239, _time = 1.6548e+09)
[2022-06-09 14:32:21,770][root][INFO] - Step 9175040 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 3104.7, step = 9175040, mean_episode_return = 38.263, mean_episode_step = 2048.0, total_loss = 72.113, pg_loss = 54.634, baseline_loss = 29.661, entropy_loss = -12.182, learner_queue_size = 64, _tick = 1240, _time = 1.6548e+09)
[2022-06-09 14:32:26,774][root][INFO] - Step 9190400 @ 3069.6 SPS. Inference batcher size: 6. Learner queue size: 64. Other stats: (train_seconds = 3109.7, step = 9190400, mean_episode_return = 96.179, mean_episode_step = 1658.1, total_loss = -59.758, pg_loss = -69.478, baseline_loss = 21.941, entropy_loss = -12.222, learner_queue_size = 64, _tick = 1242, _time = 1.6548e+09)
[2022-06-09 14:32:31,778][root][INFO] - Step 9205760 @ 3069.6 SPS. Inference batcher size: 2. Learner queue size: 64. Other stats: (train_seconds = 3114.7, step = 9205760, mean_episode_return = 56.451, mean_episode_step = 2179.1, total_loss = 168.21, pg_loss = 142.84, baseline_loss = 37.756, entropy_loss = -12.379, learner_queue_size = 64, _tick = 1245, _time = 1.6548e+09)
[2022-06-09 14:32:36,785][root][INFO] - Step 9221120 @ 3067.8 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 3119.7, step = 9221120, mean_episode_return = 99.064, mean_episode_step = 2418.3, total_loss = 0.93255, pg_loss = -5.8117, baseline_loss = 18.892, entropy_loss = -12.147, learner_queue_size = 64, _tick = 1247, _time = 1.6548e+09)
[2022-06-09 14:32:41,790][root][INFO] - Step 9236480 @ 3068.9 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 3124.7, step = 9236480, mean_episode_return = 46.251, mean_episode_step = 2374.2, total_loss = 48.707, pg_loss = 37.644, baseline_loss = 23.389, entropy_loss = -12.325, learner_queue_size = 64, _tick = 1249, _time = 1.6548e+09)
[2022-06-09 14:32:46,794][root][INFO] - Step 9256960 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 3129.7, step = 9256960, mean_episode_return = 25.343, mean_episode_step = 1999.3, total_loss = 45.35, pg_loss = 29.307, baseline_loss = 28.714, entropy_loss = -12.671, learner_queue_size = 64, _tick = 1252, _time = 1.6548e+09)
[2022-06-09 14:32:51,800][root][INFO] - Step 9272320 @ 3068.3 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 3134.7, step = 9272320, mean_episode_return = None, mean_episode_step = 1796.7, total_loss = 9.0338, pg_loss = 1.7319, baseline_loss = 20.052, entropy_loss = -12.75, learner_queue_size = 64, _tick = 1253, _time = 1.6548e+09)
[2022-06-09 14:32:56,802][root][INFO] - Step 9287680 @ 3070.7 SPS. Inference batcher size: 68. Learner queue size: 64. Other stats: (train_seconds = 3139.7, step = 9287680, mean_episode_return = 33.422, mean_episode_step = 2322.4, total_loss = -194.14, pg_loss = -186.98, baseline_loss = 5.6916, entropy_loss = -12.857, learner_queue_size = 64, _tick = 1256, _time = 1.6548e+09)
[2022-06-09 14:33:01,806][root][INFO] - Step 9303040 @ 3069.7 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 3144.7, step = 9303040, mean_episode_return = None, mean_episode_step = 2321.3, total_loss = -84.037, pg_loss = -87.112, baseline_loss = 16.11, entropy_loss = -13.036, learner_queue_size = 64, _tick = 1257, _time = 1.6548e+09)
[2022-06-09 14:33:06,810][root][INFO] - Step 9318400 @ 3069.6 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 3149.7, step = 9318400, mean_episode_return = 37.091, mean_episode_step = 1880.4, total_loss = 33.604, pg_loss = 17.353, baseline_loss = 29.289, entropy_loss = -13.038, learner_queue_size = 64, _tick = 1260, _time = 1.6548e+09)
[2022-06-09 14:33:11,814][root][INFO] - Step 9333760 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 3154.7, step = 9333760, mean_episode_return = 98.245, mean_episode_step = 1954.8, total_loss = -10.88, pg_loss = -26.698, baseline_loss = 28.496, entropy_loss = -12.677, learner_queue_size = 64, _tick = 1263, _time = 1.6548e+09)
[2022-06-09 14:33:16,818][root][INFO] - Step 9349120 @ 3069.5 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 3159.8, step = 9349120, mean_episode_return = 50.185, mean_episode_step = 1844.1, total_loss = -13.955, pg_loss = -22.936, baseline_loss = 21.932, entropy_loss = -12.951, learner_queue_size = 64, _tick = 1266, _time = 1.6548e+09)
[2022-06-09 14:33:21,822][root][INFO] - Step 9364480 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 3164.8, step = 9364480, mean_episode_return = 65.42, mean_episode_step = 1848.1, total_loss = 57.452, pg_loss = 37.175, baseline_loss = 33.768, entropy_loss = -13.491, learner_queue_size = 64, _tick = 1269, _time = 1.6548e+09)
[2022-06-09 14:33:26,826][root][INFO] - Step 9379840 @ 3069.5 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 3169.8, step = 9379840, mean_episode_return = 19.206, mean_episode_step = 1834.2, total_loss = -91.304, pg_loss = -85.62, baseline_loss = 7.5336, entropy_loss = -13.218, learner_queue_size = 64, _tick = 1272, _time = 1.6548e+09)
[2022-06-09 14:33:31,830][root][INFO] - Step 9400320 @ 4092.8 SPS. Inference batcher size: 15. Learner queue size: 64. Other stats: (train_seconds = 3174.8, step = 9400320, mean_episode_return = 42.808, mean_episode_step = 1956.9, total_loss = 26.468, pg_loss = 17.92, baseline_loss = 21.731, entropy_loss = -13.184, learner_queue_size = 64, _tick = 1275, _time = 1.6548e+09)
[2022-06-09 14:33:36,834][root][INFO] - Step 9415680 @ 3069.5 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 3179.8, step = 9415680, mean_episode_return = None, mean_episode_step = 2069.5, total_loss = 153.95, pg_loss = 129.06, baseline_loss = 38.154, entropy_loss = -13.267, learner_queue_size = 64, _tick = 1276, _time = 1.6548e+09)
[2022-06-09 14:33:41,838][root][INFO] - Step 9431040 @ 3069.6 SPS. Inference batcher size: 73. Learner queue size: 64. Other stats: (train_seconds = 3184.8, step = 9431040, mean_episode_return = None, mean_episode_step = 2252.8, total_loss = -195.49, pg_loss = -183.38, baseline_loss = 1.117, entropy_loss = -13.222, learner_queue_size = 64, _tick = 1277, _time = 1.6548e+09)
[2022-06-09 14:33:46,842][root][INFO] - Step 9446400 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 3189.8, step = 9446400, mean_episode_return = None, mean_episode_step = 2274.3, total_loss = 5.9919, pg_loss = 1.3269, baseline_loss = 18.038, entropy_loss = -13.373, learner_queue_size = 64, _tick = 1279, _time = 1.6548e+09)
[2022-06-09 14:33:51,846][root][INFO] - Step 9461760 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 3194.8, step = 9461760, mean_episode_return = 3.2493, mean_episode_step = 2221.1, total_loss = 191.72, pg_loss = 163.1, baseline_loss = 42.05, entropy_loss = -13.43, learner_queue_size = 64, _tick = 1281, _time = 1.6548e+09)
[2022-06-09 14:33:56,850][root][INFO] - Step 9477120 @ 3069.5 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 3199.8, step = 9477120, mean_episode_return = 84.196, mean_episode_step = 2056.1, total_loss = -31.982, pg_loss = -38.682, baseline_loss = 19.816, entropy_loss = -13.116, learner_queue_size = 64, _tick = 1284, _time = 1.6548e+09)
[2022-06-09 14:34:01,854][root][INFO] - Step 9492480 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 3204.8, step = 9492480, mean_episode_return = 27.296, mean_episode_step = 2201.9, total_loss = 7.0841, pg_loss = -9.0774, baseline_loss = 28.877, entropy_loss = -12.716, learner_queue_size = 64, _tick = 1287, _time = 1.6548e+09)
[2022-06-09 14:34:06,858][root][INFO] - Step 9507840 @ 3069.6 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 3209.8, step = 9507840, mean_episode_return = 95.327, mean_episode_step = 2204.5, total_loss = 90.035, pg_loss = 74.782, baseline_loss = 28.52, entropy_loss = -13.268, learner_queue_size = 64, _tick = 1290, _time = 1.6548e+09)
[2022-06-09 14:34:11,862][root][INFO] - Step 9528320 @ 4092.7 SPS. Inference batcher size: 106. Learner queue size: 64. Other stats: (train_seconds = 3214.8, step = 9528320, mean_episode_return = 46.584, mean_episode_step = 2242.0, total_loss = 192.16, pg_loss = 153.99, baseline_loss = 50.761, entropy_loss = -12.591, learner_queue_size = 64, _tick = 1294, _time = 1.6548e+09)
[2022-06-09 14:34:16,866][root][INFO] - Step 9543680 @ 3069.5 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 3219.8, step = 9543680, mean_episode_return = 58.951, mean_episode_step = 2470.3, total_loss = -93.347, pg_loss = -85.526, baseline_loss = 4.6949, entropy_loss = -12.516, learner_queue_size = 64, _tick = 1297, _time = 1.6548e+09)
[2022-06-09 14:34:21,926][root][INFO] - Step 9559040 @ 3035.7 SPS. Inference batcher size: 68. Learner queue size: 64. Other stats: (train_seconds = 3224.9, step = 9559040, mean_episode_return = -5.4604, mean_episode_step = 2220.2, total_loss = 105.91, pg_loss = 91.507, baseline_loss = 27.636, entropy_loss = -13.231, learner_queue_size = 64, _tick = 1299, _time = 1.6548e+09)
[2022-06-09 14:34:26,941][root][INFO] - Step 9574400 @ 3063.0 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 3229.9, step = 9574400, mean_episode_return = 16.91, mean_episode_step = 2078.7, total_loss = 281.07, pg_loss = 251.79, baseline_loss = 42.771, entropy_loss = -13.494, learner_queue_size = 64, _tick = 1302, _time = 1.6548e+09)
[2022-06-09 14:34:31,946][root][INFO] - Step 9589760 @ 3068.7 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 3234.9, step = 9589760, mean_episode_return = 1.2747, mean_episode_step = 2017.5, total_loss = 197.38, pg_loss = 150.69, baseline_loss = 60.422, entropy_loss = -13.735, learner_queue_size = 64, _tick = 1305, _time = 1.6548e+09)
[2022-06-09 14:34:36,950][root][INFO] - Step 9605120 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 3239.9, step = 9605120, mean_episode_return = 66.533, mean_episode_step = 2149.4, total_loss = 123.14, pg_loss = 94.546, baseline_loss = 41.951, entropy_loss = -13.361, learner_queue_size = 64, _tick = 1308, _time = 1.6548e+09)
[2022-06-09 14:34:41,954][root][INFO] - Step 9620480 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 3244.9, step = 9620480, mean_episode_return = -12.629, mean_episode_step = 1951.3, total_loss = 39.968, pg_loss = 27.325, baseline_loss = 25.147, entropy_loss = -12.504, learner_queue_size = 64, _tick = 1311, _time = 1.6548e+09)
[2022-06-09 14:34:46,958][root][INFO] - Step 9635840 @ 3069.4 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 3249.9, step = 9635840, mean_episode_return = 51.821, mean_episode_step = 1604.7, total_loss = -42.485, pg_loss = -42.424, baseline_loss = 11.722, entropy_loss = -11.783, learner_queue_size = 64, _tick = 1314, _time = 1.6548e+09)
[2022-06-09 14:34:51,962][root][INFO] - Step 9656320 @ 4092.9 SPS. Inference batcher size: 94. Learner queue size: 64. Other stats: (train_seconds = 3254.9, step = 9656320, mean_episode_return = None, mean_episode_step = 1860.1, total_loss = 269.7, pg_loss = 219.55, baseline_loss = 62.207, entropy_loss = -12.055, learner_queue_size = 64, _tick = 1317, _time = 1.6548e+09)
[2022-06-09 14:34:56,966][root][INFO] - Step 9671680 @ 3069.5 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 3259.9, step = 9671680, mean_episode_return = None, mean_episode_step = 2064.4, total_loss = -10.996, pg_loss = -19.339, baseline_loss = 20.282, entropy_loss = -11.938, learner_queue_size = 64, _tick = 1319, _time = 1.6548e+09)
[2022-06-09 14:35:01,970][root][INFO] - Step 9687040 @ 3069.6 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 3264.9, step = 9687040, mean_episode_return = 35.93, mean_episode_step = 1579.3, total_loss = 364.35, pg_loss = 276.36, baseline_loss = 100.36, entropy_loss = -12.367, learner_queue_size = 64, _tick = 1321, _time = 1.6548e+09)
[2022-06-09 14:35:06,974][root][INFO] - Step 9702400 @ 3069.5 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 3269.9, step = 9702400, mean_episode_return = 39.669, mean_episode_step = 1699.9, total_loss = 31.978, pg_loss = 7.9391, baseline_loss = 36.556, entropy_loss = -12.518, learner_queue_size = 64, _tick = 1323, _time = 1.6548e+09)
[2022-06-09 14:35:11,978][root][INFO] - Step 9717760 @ 3069.6 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 3274.9, step = 9717760, mean_episode_return = None, mean_episode_step = 1876.4, total_loss = -167.52, pg_loss = -155.99, baseline_loss = 0.96857, entropy_loss = -12.498, learner_queue_size = 64, _tick = 1325, _time = 1.6548e+09)
[2022-06-09 14:35:16,982][root][INFO] - Step 9733120 @ 3069.5 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 3279.9, step = 9733120, mean_episode_return = 51.351, mean_episode_step = 1774.7, total_loss = -41.783, pg_loss = -59.744, baseline_loss = 30.685, entropy_loss = -12.725, learner_queue_size = 64, _tick = 1328, _time = 1.6548e+09)
[2022-06-09 14:35:21,986][root][INFO] - Step 9748480 @ 3069.5 SPS. Inference batcher size: 100. Learner queue size: 64. Other stats: (train_seconds = 3284.9, step = 9748480, mean_episode_return = 23.83, mean_episode_step = 1878.2, total_loss = -33.088, pg_loss = -37.6, baseline_loss = 17.34, entropy_loss = -12.828, learner_queue_size = 64, _tick = 1331, _time = 1.6548e+09)
[2022-06-09 14:35:26,990][root][INFO] - Step 9763840 @ 3069.5 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 3289.9, step = 9763840, mean_episode_return = None, mean_episode_step = 2238.5, total_loss = 63.272, pg_loss = 50.877, baseline_loss = 25.14, entropy_loss = -12.745, learner_queue_size = 64, _tick = 1333, _time = 1.6548e+09)
[2022-06-09 14:35:31,994][root][INFO] - Step 9779200 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 3294.9, step = 9779200, mean_episode_return = 75.825, mean_episode_step = 2371.4, total_loss = 37.92, pg_loss = 4.3453, baseline_loss = 46.548, entropy_loss = -12.974, learner_queue_size = 64, _tick = 1336, _time = 1.6548e+09)
[2022-06-09 14:35:36,998][root][INFO] - Step 9794560 @ 3069.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 3299.9, step = 9794560, mean_episode_return = 25.764, mean_episode_step = 2250.9, total_loss = -62.944, pg_loss = -70.617, baseline_loss = 20.695, entropy_loss = -13.023, learner_queue_size = 64, _tick = 1339, _time = 1.6548e+09)
[2022-06-09 14:35:42,002][root][INFO] - Step 9809920 @ 3069.6 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 3304.9, step = 9809920, mean_episode_return = None, mean_episode_step = 2051.8, total_loss = 14.602, pg_loss = 9.2162, baseline_loss = 18.179, entropy_loss = -12.794, learner_queue_size = 64, _tick = 1341, _time = 1.6548e+09)
[2022-06-09 14:35:47,006][root][INFO] - Step 9825280 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 3309.9, step = 9825280, mean_episode_return = 18.435, mean_episode_step = 2148.0, total_loss = -109.55, pg_loss = -115.12, baseline_loss = 18.332, entropy_loss = -12.765, learner_queue_size = 64, _tick = 1344, _time = 1.6548e+09)
[2022-06-09 14:35:52,012][root][INFO] - Step 9840640 @ 3068.3 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 3314.9, step = 9840640, mean_episode_return = None, mean_episode_step = 2254.1, total_loss = 267.83, pg_loss = 223.98, baseline_loss = 56.672, entropy_loss = -12.822, learner_queue_size = 64, _tick = 1346, _time = 1.6548e+09)
[2022-06-09 14:35:57,014][root][INFO] - Step 9861120 @ 4094.4 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 3319.9, step = 9861120, mean_episode_return = 12.66, mean_episode_step = 2128.9, total_loss = -107.51, pg_loss = -116.8, baseline_loss = 22.19, entropy_loss = -12.899, learner_queue_size = 64, _tick = 1350, _time = 1.6548e+09)
[2022-06-09 14:36:02,018][root][INFO] - Step 9876480 @ 3069.5 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 3325.0, step = 9876480, mean_episode_return = 60.284, mean_episode_step = 2038.9, total_loss = -124.1, pg_loss = -134.05, baseline_loss = 22.897, entropy_loss = -12.946, learner_queue_size = 64, _tick = 1352, _time = 1.6548e+09)
[2022-06-09 14:36:07,022][root][INFO] - Step 9891840 @ 3069.6 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 3330.0, step = 9891840, mean_episode_return = 15.0, mean_episode_step = 1707.8, total_loss = -28.948, pg_loss = -34.114, baseline_loss = 17.715, entropy_loss = -12.549, learner_queue_size = 64, _tick = 1355, _time = 1.6548e+09)
[2022-06-09 14:36:12,026][root][INFO] - Step 9907200 @ 3069.5 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 3335.0, step = 9907200, mean_episode_return = 59.377, mean_episode_step = 1653.6, total_loss = 82.059, pg_loss = 55.134, baseline_loss = 39.354, entropy_loss = -12.43, learner_queue_size = 64, _tick = 1358, _time = 1.6548e+09)
[2022-06-09 14:36:17,030][root][INFO] - Step 9922560 @ 3069.6 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 3340.0, step = 9922560, mean_episode_return = 4.7194, mean_episode_step = 2061.4, total_loss = -113.0, pg_loss = -108.59, baseline_loss = 8.0921, entropy_loss = -12.503, learner_queue_size = 64, _tick = 1361, _time = 1.6548e+09)
[2022-06-09 14:36:22,034][root][INFO] - Step 9937920 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 3345.0, step = 9937920, mean_episode_return = 29.145, mean_episode_step = 2089.2, total_loss = 44.051, pg_loss = 23.284, baseline_loss = 33.557, entropy_loss = -12.79, learner_queue_size = 64, _tick = 1363, _time = 1.6548e+09)
[2022-06-09 14:36:27,038][root][INFO] - Step 9953280 @ 3069.6 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 3350.0, step = 9953280, mean_episode_return = 62.828, mean_episode_step = 1968.3, total_loss = 8.1158, pg_loss = -3.5575, baseline_loss = 24.86, entropy_loss = -13.186, learner_queue_size = 64, _tick = 1365, _time = 1.6548e+09)
[2022-06-09 14:36:32,042][root][INFO] - Step 9968640 @ 3069.6 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 3355.0, step = 9968640, mean_episode_return = 14.392, mean_episode_step = 1870.3, total_loss = -132.44, pg_loss = -126.24, baseline_loss = 6.9781, entropy_loss = -13.183, learner_queue_size = 64, _tick = 1368, _time = 1.6548e+09)
[2022-06-09 14:36:37,046][root][INFO] - Step 9984000 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 3360.0, step = 9984000, mean_episode_return = 64.519, mean_episode_step = 1919.5, total_loss = 207.3, pg_loss = 190.86, baseline_loss = 29.435, entropy_loss = -13.0, learner_queue_size = 64, _tick = 1370, _time = 1.6548e+09)
[2022-06-09 14:36:42,050][root][INFO] - Step 9999360 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 3365.0, step = 9999360, mean_episode_return = None, mean_episode_step = 2134.6, total_loss = -45.484, pg_loss = -40.903, baseline_loss = 8.532, entropy_loss = -13.113, learner_queue_size = 64, _tick = 1372, _time = 1.6548e+09)
[2022-06-09 14:36:47,054][root][INFO] - Step 10019840 @ 4092.7 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 3370.0, step = 10019840, mean_episode_return = -3.4353, mean_episode_step = 1967.9, total_loss = -13.953, pg_loss = -15.538, baseline_loss = 14.899, entropy_loss = -13.314, learner_queue_size = 64, _tick = 1375, _time = 1.6548e+09)
[2022-06-09 14:36:52,058][root][INFO] - Step 10035200 @ 3069.5 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 3375.0, step = 10035200, mean_episode_return = None, mean_episode_step = 1849.6, total_loss = 82.07, pg_loss = 71.721, baseline_loss = 23.823, entropy_loss = -13.474, learner_queue_size = 64, _tick = 1376, _time = 1.6548e+09)
[2022-06-09 14:36:57,062][root][INFO] - Step 10050560 @ 3069.6 SPS. Inference batcher size: 76. Learner queue size: 64. Other stats: (train_seconds = 3380.0, step = 10050560, mean_episode_return = -2.11, mean_episode_step = 2173.8, total_loss = 121.12, pg_loss = 91.266, baseline_loss = 43.108, entropy_loss = -13.253, learner_queue_size = 64, _tick = 1379, _time = 1.6548e+09)
[2022-06-09 14:37:02,066][root][INFO] - Step 10065920 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 3385.0, step = 10065920, mean_episode_return = 64.94, mean_episode_step = 2139.1, total_loss = 24.605, pg_loss = -2.5951, baseline_loss = 40.577, entropy_loss = -13.376, learner_queue_size = 64, _tick = 1382, _time = 1.6548e+09)
[2022-06-09 14:37:07,070][root][INFO] - Step 10081280 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 3390.0, step = 10081280, mean_episode_return = 38.58, mean_episode_step = 2059.9, total_loss = -76.666, pg_loss = -68.92, baseline_loss = 5.2896, entropy_loss = -13.035, learner_queue_size = 64, _tick = 1385, _time = 1.6548e+09)
[2022-06-09 14:37:12,074][root][INFO] - Step 10096640 @ 3069.6 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 3395.0, step = 10096640, mean_episode_return = 95.038, mean_episode_step = 1638.1, total_loss = 381.38, pg_loss = 286.97, baseline_loss = 107.34, entropy_loss = -12.932, learner_queue_size = 64, _tick = 1387, _time = 1.6548e+09)
[2022-06-09 14:37:17,080][root][INFO] - Step 10112000 @ 3068.3 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 3400.0, step = 10112000, mean_episode_return = -47.788, mean_episode_step = 1769.9, total_loss = 34.445, pg_loss = 34.851, baseline_loss = 12.713, entropy_loss = -13.119, learner_queue_size = 64, _tick = 1388, _time = 1.6548e+09)
[2022-06-09 14:37:22,086][root][INFO] - Step 10127360 @ 3068.4 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 3405.0, step = 10127360, mean_episode_return = 33.548, mean_episode_step = 2008.5, total_loss = 85.745, pg_loss = 74.643, baseline_loss = 24.412, entropy_loss = -13.309, learner_queue_size = 64, _tick = 1391, _time = 1.6548e+09)
[2022-06-09 14:37:27,090][root][INFO] - Step 10147840 @ 4092.7 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 3410.0, step = 10147840, mean_episode_return = 35.849, mean_episode_step = 2039.0, total_loss = -9.0925, pg_loss = -16.353, baseline_loss = 20.665, entropy_loss = -13.405, learner_queue_size = 64, _tick = 1394, _time = 1.6548e+09)
[2022-06-09 14:37:32,094][root][INFO] - Step 10163200 @ 3069.5 SPS. Inference batcher size: 87. Learner queue size: 64. Other stats: (train_seconds = 3415.0, step = 10163200, mean_episode_return = 33.597, mean_episode_step = 2190.9, total_loss = 59.729, pg_loss = 31.293, baseline_loss = 41.79, entropy_loss = -13.355, learner_queue_size = 64, _tick = 1396, _time = 1.6548e+09)
[2022-06-09 14:37:37,098][root][INFO] - Step 10178560 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 3420.0, step = 10178560, mean_episode_return = 1.6397, mean_episode_step = 2111.8, total_loss = -26.131, pg_loss = -28.107, baseline_loss = 15.058, entropy_loss = -13.082, learner_queue_size = 64, _tick = 1398, _time = 1.6548e+09)
[2022-06-09 14:37:42,102][root][INFO] - Step 10193920 @ 3069.5 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 3425.0, step = 10193920, mean_episode_return = None, mean_episode_step = 1729.8, total_loss = 158.78, pg_loss = 146.26, baseline_loss = 25.572, entropy_loss = -13.046, learner_queue_size = 64, _tick = 1400, _time = 1.6548e+09)
[2022-06-09 14:37:47,107][root][INFO] - Step 10209280 @ 3068.9 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 3430.0, step = 10209280, mean_episode_return = 53.824, mean_episode_step = 1914.5, total_loss = -208.67, pg_loss = -204.53, baseline_loss = 9.0813, entropy_loss = -13.212, learner_queue_size = 64, _tick = 1402, _time = 1.6548e+09)
[2022-06-09 14:37:52,110][root][INFO] - Step 10224640 @ 3070.2 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 3435.0, step = 10224640, mean_episode_return = 22.877, mean_episode_step = 2014.2, total_loss = 293.42, pg_loss = 240.91, baseline_loss = 65.873, entropy_loss = -13.361, learner_queue_size = 64, _tick = 1405, _time = 1.6548e+09)
[2022-06-09 14:37:57,114][root][INFO] - Step 10240000 @ 3069.5 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 3440.1, step = 10240000, mean_episode_return = 59.812, mean_episode_step = 2155.1, total_loss = -149.71, pg_loss = -153.19, baseline_loss = 16.644, entropy_loss = -13.163, learner_queue_size = 64, _tick = 1408, _time = 1.6548e+09)
[2022-06-09 14:38:02,118][root][INFO] - Step 10255360 @ 3069.6 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 3445.1, step = 10255360, mean_episode_return = None, mean_episode_step = 1778.8, total_loss = 79.439, pg_loss = 66.471, baseline_loss = 26.869, entropy_loss = -13.902, learner_queue_size = 64, _tick = 1410, _time = 1.6548e+09)
[2022-06-09 14:38:07,122][root][INFO] - Step 10270720 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 3450.1, step = 10270720, mean_episode_return = 14.355, mean_episode_step = 1949.1, total_loss = 25.225, pg_loss = 11.916, baseline_loss = 27.314, entropy_loss = -14.005, learner_queue_size = 64, _tick = 1413, _time = 1.6548e+09)
[2022-06-09 14:38:12,126][root][INFO] - Step 10286080 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 3455.1, step = 10286080, mean_episode_return = 37.265, mean_episode_step = 1859.1, total_loss = -187.02, pg_loss = -190.47, baseline_loss = 17.629, entropy_loss = -14.188, learner_queue_size = 64, _tick = 1415, _time = 1.6548e+09)
[2022-06-09 14:38:17,134][root][INFO] - Step 10306560 @ 4089.6 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 3460.1, step = 10306560, mean_episode_return = 38.645, mean_episode_step = 1859.5, total_loss = 296.82, pg_loss = 252.47, baseline_loss = 58.605, entropy_loss = -14.253, learner_queue_size = 64, _tick = 1419, _time = 1.6548e+09)
[2022-06-09 14:38:22,138][root][INFO] - Step 10321920 @ 3069.4 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 3465.1, step = 10321920, mean_episode_return = 5.4198, mean_episode_step = 1741.4, total_loss = 100.76, pg_loss = 76.267, baseline_loss = 38.628, entropy_loss = -14.134, learner_queue_size = 64, _tick = 1421, _time = 1.6548e+09)
[2022-06-09 14:38:27,142][root][INFO] - Step 10337280 @ 3069.6 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 3470.1, step = 10337280, mean_episode_return = 42.253, mean_episode_step = 2083.8, total_loss = -71.042, pg_loss = -85.858, baseline_loss = 29.321, entropy_loss = -14.505, learner_queue_size = 64, _tick = 1423, _time = 1.6548e+09)
[2022-06-09 14:38:32,146][root][INFO] - Step 10352640 @ 3069.5 SPS. Inference batcher size: 9. Learner queue size: 64. Other stats: (train_seconds = 3475.1, step = 10352640, mean_episode_return = 63.792, mean_episode_step = 1819.6, total_loss = 96.963, pg_loss = 66.829, baseline_loss = 44.606, entropy_loss = -14.471, learner_queue_size = 64, _tick = 1426, _time = 1.6548e+09)
[2022-06-09 14:38:37,150][root][INFO] - Step 10368000 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 3480.1, step = 10368000, mean_episode_return = None, mean_episode_step = 1875.8, total_loss = -111.2, pg_loss = -115.88, baseline_loss = 18.837, entropy_loss = -14.154, learner_queue_size = 64, _tick = 1427, _time = 1.6548e+09)
[2022-06-09 14:38:42,154][root][INFO] - Step 10383360 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 3485.1, step = 10383360, mean_episode_return = 30.89, mean_episode_step = 1819.6, total_loss = 147.74, pg_loss = 125.47, baseline_loss = 36.194, entropy_loss = -13.919, learner_queue_size = 64, _tick = 1430, _time = 1.6548e+09)
[2022-06-09 14:38:47,158][root][INFO] - Step 10398720 @ 3069.6 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 3490.1, step = 10398720, mean_episode_return = 122.52, mean_episode_step = 1708.5, total_loss = 57.798, pg_loss = 29.688, baseline_loss = 41.579, entropy_loss = -13.469, learner_queue_size = 64, _tick = 1431, _time = 1.6548e+09)
[2022-06-09 14:38:52,162][root][INFO] - Step 10414080 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 3495.1, step = 10414080, mean_episode_return = 34.081, mean_episode_step = 2033.9, total_loss = 179.66, pg_loss = 148.03, baseline_loss = 44.666, entropy_loss = -13.041, learner_queue_size = 64, _tick = 1434, _time = 1.6548e+09)
[2022-06-09 14:38:57,166][root][INFO] - Step 10429440 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 3500.1, step = 10429440, mean_episode_return = 56.978, mean_episode_step = 1747.6, total_loss = -60.107, pg_loss = -80.19, baseline_loss = 33.117, entropy_loss = -13.034, learner_queue_size = 64, _tick = 1437, _time = 1.6548e+09)
[2022-06-09 14:39:02,170][root][INFO] - Step 10449920 @ 4092.7 SPS. Inference batcher size: 84. Learner queue size: 64. Other stats: (train_seconds = 3505.1, step = 10449920, mean_episode_return = 67.331, mean_episode_step = 2142.1, total_loss = 205.24, pg_loss = 159.64, baseline_loss = 58.547, entropy_loss = -12.948, learner_queue_size = 64, _tick = 1440, _time = 1.6548e+09)
[2022-06-09 14:39:07,174][root][INFO] - Step 10465280 @ 3069.6 SPS. Inference batcher size: 88. Learner queue size: 64. Other stats: (train_seconds = 3510.1, step = 10465280, mean_episode_return = None, mean_episode_step = 1930.2, total_loss = 72.604, pg_loss = 38.301, baseline_loss = 47.254, entropy_loss = -12.952, learner_queue_size = 64, _tick = 1441, _time = 1.6548e+09)
[2022-06-09 14:39:12,178][root][INFO] - Step 10480640 @ 3069.5 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 3515.1, step = 10480640, mean_episode_return = 45.005, mean_episode_step = 2054.7, total_loss = 185.16, pg_loss = 112.82, baseline_loss = 85.228, entropy_loss = -12.886, learner_queue_size = 64, _tick = 1444, _time = 1.6548e+09)
[2022-06-09 14:39:17,182][root][INFO] - Step 10496000 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 3520.1, step = 10496000, mean_episode_return = 80.434, mean_episode_step = 2052.7, total_loss = 30.42, pg_loss = -6.46, baseline_loss = 49.528, entropy_loss = -12.649, learner_queue_size = 64, _tick = 1447, _time = 1.6548e+09)
[2022-06-09 14:39:22,186][root][INFO] - Step 10511360 @ 3069.5 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 3525.1, step = 10511360, mean_episode_return = 38.293, mean_episode_step = 2163.6, total_loss = -118.65, pg_loss = -118.58, baseline_loss = 11.788, entropy_loss = -11.857, learner_queue_size = 64, _tick = 1450, _time = 1.6548e+09)
[2022-06-09 14:39:27,190][root][INFO] - Step 10526720 @ 3069.6 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 3530.1, step = 10526720, mean_episode_return = 0.099304, mean_episode_step = 1898.1, total_loss = 231.8, pg_loss = 200.7, baseline_loss = 43.14, entropy_loss = -12.042, learner_queue_size = 64, _tick = 1453, _time = 1.6548e+09)
[2022-06-09 14:39:32,194][root][INFO] - Step 10542080 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 3535.1, step = 10542080, mean_episode_return = None, mean_episode_step = 1818.4, total_loss = -172.52, pg_loss = -168.27, baseline_loss = 7.9601, entropy_loss = -12.205, learner_queue_size = 64, _tick = 1455, _time = 1.6548e+09)
[2022-06-09 14:39:37,198][root][INFO] - Step 10557440 @ 3069.6 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 3540.1, step = 10557440, mean_episode_return = 7.5899, mean_episode_step = 2044.5, total_loss = 329.04, pg_loss = 278.79, baseline_loss = 62.95, entropy_loss = -12.706, learner_queue_size = 64, _tick = 1458, _time = 1.6548e+09)
[2022-06-09 14:39:42,202][root][INFO] - Step 10572800 @ 3069.6 SPS. Inference batcher size: 13. Learner queue size: 64. Other stats: (train_seconds = 3545.1, step = 10572800, mean_episode_return = 49.167, mean_episode_step = 1748.2, total_loss = -26.251, pg_loss = -39.11, baseline_loss = 25.776, entropy_loss = -12.916, learner_queue_size = 64, _tick = 1460, _time = 1.6548e+09)
[2022-06-09 14:39:47,206][root][INFO] - Step 10588160 @ 3069.5 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 3550.1, step = 10588160, mean_episode_return = 31.773, mean_episode_step = 1876.6, total_loss = -69.686, pg_loss = -65.781, baseline_loss = 9.1975, entropy_loss = -13.102, learner_queue_size = 64, _tick = 1463, _time = 1.6548e+09)
[2022-06-09 14:39:52,210][root][INFO] - Step 10603520 @ 3069.6 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 3555.1, step = 10603520, mean_episode_return = 19.034, mean_episode_step = 2167.2, total_loss = -71.009, pg_loss = -75.968, baseline_loss = 17.648, entropy_loss = -12.689, learner_queue_size = 64, _tick = 1465, _time = 1.6548e+09)
[2022-06-09 14:39:57,216][root][INFO] - Step 10624000 @ 4091.1 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 3560.2, step = 10624000, mean_episode_return = 150.85, mean_episode_step = 1819.6, total_loss = 104.43, pg_loss = 85.496, baseline_loss = 31.912, entropy_loss = -12.98, learner_queue_size = 64, _tick = 1469, _time = 1.6548e+09)
[2022-06-09 14:40:02,222][root][INFO] - Step 10639360 @ 3068.3 SPS. Inference batcher size: 81. Learner queue size: 64. Other stats: (train_seconds = 3565.2, step = 10639360, mean_episode_return = 51.475, mean_episode_step = 1862.0, total_loss = 4.5208, pg_loss = -8.5705, baseline_loss = 26.264, entropy_loss = -13.173, learner_queue_size = 64, _tick = 1472, _time = 1.6548e+09)
[2022-06-09 14:40:07,228][root][INFO] - Step 10654720 @ 3068.3 SPS. Inference batcher size: 83. Learner queue size: 64. Other stats: (train_seconds = 3570.2, step = 10654720, mean_episode_return = 48.013, mean_episode_step = 2056.3, total_loss = -189.14, pg_loss = -189.63, baseline_loss = 13.973, entropy_loss = -13.479, learner_queue_size = 64, _tick = 1475, _time = 1.6548e+09)
[2022-06-09 14:40:12,234][root][INFO] - Step 10670080 @ 3068.3 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 3575.2, step = 10670080, mean_episode_return = 93.756, mean_episode_step = 1921.5, total_loss = 33.515, pg_loss = 18.805, baseline_loss = 28.398, entropy_loss = -13.688, learner_queue_size = 64, _tick = 1478, _time = 1.6548e+09)
[2022-06-09 14:40:17,238][root][INFO] - Step 10685440 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 3580.2, step = 10685440, mean_episode_return = -27.721, mean_episode_step = 1833.2, total_loss = 0.54679, pg_loss = -8.439, baseline_loss = 23.072, entropy_loss = -14.086, learner_queue_size = 64, _tick = 1479, _time = 1.6548e+09)
[2022-06-09 14:40:22,242][root][INFO] - Step 10700800 @ 3069.6 SPS. Inference batcher size: 18. Learner queue size: 64. Other stats: (train_seconds = 3585.2, step = 10700800, mean_episode_return = 66.159, mean_episode_step = 1672.2, total_loss = 207.07, pg_loss = 174.11, baseline_loss = 47.011, entropy_loss = -14.052, learner_queue_size = 64, _tick = 1482, _time = 1.6548e+09)
[2022-06-09 14:40:27,246][root][INFO] - Step 10716160 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 3590.2, step = 10716160, mean_episode_return = 48.484, mean_episode_step = 1766.6, total_loss = -112.16, pg_loss = -112.28, baseline_loss = 14.02, entropy_loss = -13.905, learner_queue_size = 64, _tick = 1485, _time = 1.6548e+09)
[2022-06-09 14:40:32,250][root][INFO] - Step 10731520 @ 3069.6 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 3595.2, step = 10731520, mean_episode_return = 7.2198, mean_episode_step = 1686.5, total_loss = 361.13, pg_loss = 283.22, baseline_loss = 92.331, entropy_loss = -14.42, learner_queue_size = 64, _tick = 1488, _time = 1.6548e+09)
[2022-06-09 14:40:37,254][root][INFO] - Step 10746880 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 3600.2, step = 10746880, mean_episode_return = 14.716, mean_episode_step = 1771.4, total_loss = 124.29, pg_loss = 84.729, baseline_loss = 53.969, entropy_loss = -14.404, learner_queue_size = 64, _tick = 1491, _time = 1.6548e+09)
[2022-06-09 14:40:42,258][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 14:40:42,765][root][INFO] - Step 10762240 @ 3069.6 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 3605.2, step = 10767360, mean_episode_return = 54.503, mean_episode_step = 1593.9, total_loss = 143.04, pg_loss = 111.43, baseline_loss = 46.003, entropy_loss = -14.387, learner_queue_size = 64, _tick = 1494, _time = 1.6548e+09)
[2022-06-09 14:40:47,770][root][INFO] - Step 10782720 @ 3715.5 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 3610.7, step = 10782720, mean_episode_return = 103.43, mean_episode_step = 1765.3, total_loss = 7.2058, pg_loss = -5.5364, baseline_loss = 26.939, entropy_loss = -14.197, learner_queue_size = 64, _tick = 1497, _time = 1.6548e+09)
[2022-06-09 14:40:52,795][root][INFO] - Step 10798080 @ 3056.5 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 3615.7, step = 10798080, mean_episode_return = 63.005, mean_episode_step = 1640.5, total_loss = 150.16, pg_loss = 119.22, baseline_loss = 45.154, entropy_loss = -14.215, learner_queue_size = 64, _tick = 1499, _time = 1.6548e+09)
[2022-06-09 14:40:57,798][root][INFO] - Step 10813440 @ 3070.4 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 3620.7, step = 10813440, mean_episode_return = None, mean_episode_step = 2011.5, total_loss = 418.41, pg_loss = 350.98, baseline_loss = 81.356, entropy_loss = -13.926, learner_queue_size = 64, _tick = 1501, _time = 1.6548e+09)
[2022-06-09 14:41:02,802][root][INFO] - Step 10828800 @ 3069.5 SPS. Inference batcher size: 4. Learner queue size: 64. Other stats: (train_seconds = 3625.7, step = 10828800, mean_episode_return = 102.99, mean_episode_step = 1867.5, total_loss = 242.67, pg_loss = 202.59, baseline_loss = 54.175, entropy_loss = -14.1, learner_queue_size = 64, _tick = 1504, _time = 1.6548e+09)
[2022-06-09 14:41:07,806][root][INFO] - Step 10844160 @ 3069.5 SPS. Inference batcher size: 11. Learner queue size: 64. Other stats: (train_seconds = 3630.7, step = 10844160, mean_episode_return = 48.182, mean_episode_step = 1691.8, total_loss = 48.207, pg_loss = 20.802, baseline_loss = 41.843, entropy_loss = -14.439, learner_queue_size = 64, _tick = 1506, _time = 1.6548e+09)
[2022-06-09 14:41:12,810][root][INFO] - Step 10859520 @ 3069.4 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 3635.7, step = 10859520, mean_episode_return = None, mean_episode_step = 1884.1, total_loss = 102.59, pg_loss = 93.777, baseline_loss = 23.154, entropy_loss = -14.337, learner_queue_size = 64, _tick = 1508, _time = 1.6548e+09)
[2022-06-09 14:41:17,816][root][INFO] - Step 10874880 @ 3068.4 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 3640.8, step = 10874880, mean_episode_return = 33.545, mean_episode_step = 1861.1, total_loss = 104.51, pg_loss = 67.874, baseline_loss = 51.136, entropy_loss = -14.506, learner_queue_size = 64, _tick = 1510, _time = 1.6548e+09)
[2022-06-09 14:41:22,822][root][INFO] - Step 10890240 @ 3068.4 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 3645.8, step = 10890240, mean_episode_return = None, mean_episode_step = 1965.8, total_loss = -90.031, pg_loss = -82.726, baseline_loss = 7.054, entropy_loss = -14.359, learner_queue_size = 64, _tick = 1512, _time = 1.6548e+09)
[2022-06-09 14:41:27,826][root][INFO] - Step 10910720 @ 4092.6 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 3650.8, step = 10910720, mean_episode_return = 24.881, mean_episode_step = 1953.5, total_loss = -56.902, pg_loss = -67.798, baseline_loss = 25.557, entropy_loss = -14.662, learner_queue_size = 64, _tick = 1516, _time = 1.6548e+09)
[2022-06-09 14:41:32,830][root][INFO] - Step 10926080 @ 3069.5 SPS. Inference batcher size: 67. Learner queue size: 64. Other stats: (train_seconds = 3655.8, step = 10926080, mean_episode_return = 40.0, mean_episode_step = 1775.8, total_loss = -13.716, pg_loss = -21.084, baseline_loss = 22.256, entropy_loss = -14.888, learner_queue_size = 64, _tick = 1518, _time = 1.6548e+09)
[2022-06-09 14:41:37,834][root][INFO] - Step 10941440 @ 3069.6 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 3660.8, step = 10941440, mean_episode_return = 62.26, mean_episode_step = 2068.1, total_loss = -19.818, pg_loss = -42.91, baseline_loss = 37.488, entropy_loss = -14.396, learner_queue_size = 64, _tick = 1521, _time = 1.6548e+09)
[2022-06-09 14:41:42,838][root][INFO] - Step 10956800 @ 3069.5 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 3665.8, step = 10956800, mean_episode_return = 139.25, mean_episode_step = 1775.5, total_loss = -250.67, pg_loss = -241.61, baseline_loss = 5.4129, entropy_loss = -14.477, learner_queue_size = 64, _tick = 1524, _time = 1.6548e+09)
[2022-06-09 14:41:47,842][root][INFO] - Step 10972160 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 3670.8, step = 10972160, mean_episode_return = 32.724, mean_episode_step = 2236.5, total_loss = 95.126, pg_loss = 47.769, baseline_loss = 61.728, entropy_loss = -14.371, learner_queue_size = 64, _tick = 1527, _time = 1.6548e+09)
[2022-06-09 14:41:52,846][root][INFO] - Step 10987520 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 3675.8, step = 10987520, mean_episode_return = 22.12, mean_episode_step = 2054.3, total_loss = -142.27, pg_loss = -138.72, baseline_loss = 10.786, entropy_loss = -14.342, learner_queue_size = 64, _tick = 1530, _time = 1.6548e+09)
[2022-06-09 14:41:57,850][root][INFO] - Step 11002880 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 3680.8, step = 11002880, mean_episode_return = 8.5697, mean_episode_step = 1843.0, total_loss = 156.81, pg_loss = 142.44, baseline_loss = 29.079, entropy_loss = -14.707, learner_queue_size = 64, _tick = 1532, _time = 1.6548e+09)
[2022-06-09 14:42:02,854][root][INFO] - Step 11018240 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 3685.8, step = 11018240, mean_episode_return = 94.055, mean_episode_step = 2041.1, total_loss = 21.344, pg_loss = -3.5013, baseline_loss = 39.143, entropy_loss = -14.297, learner_queue_size = 64, _tick = 1534, _time = 1.6548e+09)
[2022-06-09 14:42:07,859][root][INFO] - Step 11038720 @ 4092.0 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 3690.8, step = 11038720, mean_episode_return = None, mean_episode_step = 1896.9, total_loss = -52.182, pg_loss = -54.936, baseline_loss = 17.124, entropy_loss = -14.37, learner_queue_size = 64, _tick = 1537, _time = 1.6548e+09)
[2022-06-09 14:42:12,862][root][INFO] - Step 11054080 @ 3070.1 SPS. Inference batcher size: 95. Learner queue size: 64. Other stats: (train_seconds = 3695.8, step = 11054080, mean_episode_return = 59.02, mean_episode_step = 2097.8, total_loss = -186.47, pg_loss = -179.07, baseline_loss = 6.7169, entropy_loss = -14.114, learner_queue_size = 64, _tick = 1539, _time = 1.6548e+09)
[2022-06-09 14:42:17,866][root][INFO] - Step 11069440 @ 3069.5 SPS. Inference batcher size: 12. Learner queue size: 64. Other stats: (train_seconds = 3700.8, step = 11069440, mean_episode_return = 31.661, mean_episode_step = 1669.6, total_loss = -97.25, pg_loss = -101.19, baseline_loss = 18.245, entropy_loss = -14.302, learner_queue_size = 64, _tick = 1542, _time = 1.6548e+09)
[2022-06-09 14:42:22,873][root][INFO] - Step 11084800 @ 3068.0 SPS. Inference batcher size: 77. Learner queue size: 64. Other stats: (train_seconds = 3705.8, step = 11084800, mean_episode_return = 50.07, mean_episode_step = 2016.4, total_loss = 18.883, pg_loss = -8.0372, baseline_loss = 41.129, entropy_loss = -14.209, learner_queue_size = 64, _tick = 1544, _time = 1.6548e+09)
[2022-06-09 14:42:27,878][root][INFO] - Step 11100160 @ 3068.8 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 3710.8, step = 11100160, mean_episode_return = 6.0194, mean_episode_step = 2117.5, total_loss = -69.516, pg_loss = -68.018, baseline_loss = 13.026, entropy_loss = -14.524, learner_queue_size = 64, _tick = 1547, _time = 1.6548e+09)
[2022-06-09 14:42:32,882][root][INFO] - Step 11115520 @ 3069.5 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 3715.8, step = 11115520, mean_episode_return = None, mean_episode_step = 2227.7, total_loss = -14.911, pg_loss = -14.906, baseline_loss = 14.298, entropy_loss = -14.303, learner_queue_size = 64, _tick = 1549, _time = 1.6548e+09)
[2022-06-09 14:42:37,886][root][INFO] - Step 11130880 @ 3069.5 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 3720.8, step = 11130880, mean_episode_return = None, mean_episode_step = 1855.9, total_loss = 146.55, pg_loss = 123.29, baseline_loss = 37.405, entropy_loss = -14.146, learner_queue_size = 64, _tick = 1551, _time = 1.6548e+09)
[2022-06-09 14:42:42,890][root][INFO] - Step 11146240 @ 3069.6 SPS. Inference batcher size: 11. Learner queue size: 64. Other stats: (train_seconds = 3725.8, step = 11146240, mean_episode_return = 25.85, mean_episode_step = 1710.7, total_loss = -63.844, pg_loss = -90.428, baseline_loss = 40.858, entropy_loss = -14.274, learner_queue_size = 64, _tick = 1554, _time = 1.6548e+09)
[2022-06-09 14:42:47,894][root][INFO] - Step 11161600 @ 3069.6 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 3730.8, step = 11161600, mean_episode_return = 11.531, mean_episode_step = 2205.4, total_loss = 277.07, pg_loss = 227.81, baseline_loss = 63.612, entropy_loss = -14.357, learner_queue_size = 64, _tick = 1556, _time = 1.6548e+09)
[2022-06-09 14:42:52,898][root][INFO] - Step 11176960 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 3735.8, step = 11176960, mean_episode_return = 47.23, mean_episode_step = 1846.7, total_loss = 145.29, pg_loss = 106.03, baseline_loss = 53.365, entropy_loss = -14.11, learner_queue_size = 64, _tick = 1558, _time = 1.6548e+09)
[2022-06-09 14:42:57,902][root][INFO] - Step 11197440 @ 4092.7 SPS. Inference batcher size: 102. Learner queue size: 64. Other stats: (train_seconds = 3740.8, step = 11197440, mean_episode_return = 144.11, mean_episode_step = 1971.9, total_loss = 23.876, pg_loss = 8.7837, baseline_loss = 28.831, entropy_loss = -13.74, learner_queue_size = 64, _tick = 1562, _time = 1.6548e+09)
[2022-06-09 14:43:02,906][root][INFO] - Step 11212800 @ 3069.5 SPS. Inference batcher size: 77. Learner queue size: 64. Other stats: (train_seconds = 3745.8, step = 11212800, mean_episode_return = 42.39, mean_episode_step = 1755.5, total_loss = -160.78, pg_loss = -158.8, baseline_loss = 11.483, entropy_loss = -13.463, learner_queue_size = 64, _tick = 1565, _time = 1.6548e+09)
[2022-06-09 14:43:07,910][root][INFO] - Step 11228160 @ 3069.5 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 3750.8, step = 11228160, mean_episode_return = -0.47032, mean_episode_step = 2124.1, total_loss = -202.03, pg_loss = -199.51, baseline_loss = 10.781, entropy_loss = -13.293, learner_queue_size = 64, _tick = 1568, _time = 1.6548e+09)
[2022-06-09 14:43:12,914][root][INFO] - Step 11243520 @ 3069.5 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 3755.9, step = 11243520, mean_episode_return = 30.844, mean_episode_step = 1853.6, total_loss = -0.65712, pg_loss = -27.865, baseline_loss = 40.512, entropy_loss = -13.303, learner_queue_size = 64, _tick = 1570, _time = 1.6548e+09)
[2022-06-09 14:43:17,918][root][INFO] - Step 11258880 @ 3069.6 SPS. Inference batcher size: 68. Learner queue size: 64. Other stats: (train_seconds = 3760.9, step = 11258880, mean_episode_return = 23.425, mean_episode_step = 1936.4, total_loss = -230.4, pg_loss = -233.76, baseline_loss = 16.478, entropy_loss = -13.116, learner_queue_size = 64, _tick = 1573, _time = 1.6548e+09)
[2022-06-09 14:43:22,922][root][INFO] - Step 11274240 @ 3069.5 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 3765.9, step = 11274240, mean_episode_return = 24.36, mean_episode_step = 2218.0, total_loss = -88.213, pg_loss = -99.917, baseline_loss = 24.828, entropy_loss = -13.125, learner_queue_size = 64, _tick = 1575, _time = 1.6548e+09)
[2022-06-09 14:43:27,926][root][INFO] - Step 11289600 @ 3069.5 SPS. Inference batcher size: 18. Learner queue size: 64. Other stats: (train_seconds = 3770.9, step = 11289600, mean_episode_return = 34.482, mean_episode_step = 1882.1, total_loss = -216.9, pg_loss = -233.78, baseline_loss = 29.941, entropy_loss = -13.058, learner_queue_size = 64, _tick = 1577, _time = 1.6548e+09)
[2022-06-09 14:43:32,930][root][INFO] - Step 11304960 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 3775.9, step = 11304960, mean_episode_return = 83.756, mean_episode_step = 1900.3, total_loss = 97.986, pg_loss = 68.962, baseline_loss = 42.205, entropy_loss = -13.18, learner_queue_size = 64, _tick = 1578, _time = 1.6548e+09)
[2022-06-09 14:43:37,934][root][INFO] - Step 11320320 @ 3069.6 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 3780.9, step = 11320320, mean_episode_return = 34.658, mean_episode_step = 1919.2, total_loss = 174.19, pg_loss = 134.37, baseline_loss = 53.611, entropy_loss = -13.792, learner_queue_size = 64, _tick = 1580, _time = 1.6548e+09)
[2022-06-09 14:43:42,938][root][INFO] - Step 11335680 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 3785.9, step = 11335680, mean_episode_return = 66.01, mean_episode_step = 2113.0, total_loss = 54.415, pg_loss = 31.723, baseline_loss = 36.222, entropy_loss = -13.53, learner_queue_size = 64, _tick = 1583, _time = 1.6548e+09)
[2022-06-09 14:43:47,942][root][INFO] - Step 11351040 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 3790.9, step = 11351040, mean_episode_return = 58.575, mean_episode_step = 2061.7, total_loss = -137.97, pg_loss = -133.84, baseline_loss = 9.5111, entropy_loss = -13.645, learner_queue_size = 64, _tick = 1586, _time = 1.6548e+09)
[2022-06-09 14:43:52,946][root][INFO] - Step 11366400 @ 3069.6 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 3795.9, step = 11366400, mean_episode_return = 40.02, mean_episode_step = 1777.3, total_loss = 18.132, pg_loss = 1.6228, baseline_loss = 30.053, entropy_loss = -13.543, learner_queue_size = 64, _tick = 1588, _time = 1.6548e+09)
[2022-06-09 14:43:57,952][root][INFO] - Step 11381760 @ 3068.3 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 3800.9, step = 11381760, mean_episode_return = 47.486, mean_episode_step = 2206.7, total_loss = -161.49, pg_loss = -177.06, baseline_loss = 28.865, entropy_loss = -13.293, learner_queue_size = 64, _tick = 1591, _time = 1.6548e+09)
[2022-06-09 14:44:02,958][root][INFO] - Step 11397120 @ 3068.4 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 3805.9, step = 11397120, mean_episode_return = 43.884, mean_episode_step = 2120.2, total_loss = -32.218, pg_loss = -51.073, baseline_loss = 31.388, entropy_loss = -12.533, learner_queue_size = 64, _tick = 1594, _time = 1.6548e+09)
[2022-06-09 14:44:07,962][root][INFO] - Step 11417600 @ 4092.7 SPS. Inference batcher size: 12. Learner queue size: 64. Other stats: (train_seconds = 3810.9, step = 11417600, mean_episode_return = None, mean_episode_step = 1903.7, total_loss = 282.45, pg_loss = 231.93, baseline_loss = 62.846, entropy_loss = -12.331, learner_queue_size = 64, _tick = 1597, _time = 1.6548e+09)
[2022-06-09 14:44:12,966][root][INFO] - Step 11432960 @ 3069.6 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 3815.9, step = 11432960, mean_episode_return = None, mean_episode_step = 1807.3, total_loss = -74.89, pg_loss = -76.97, baseline_loss = 14.291, entropy_loss = -12.212, learner_queue_size = 64, _tick = 1599, _time = 1.6548e+09)
[2022-06-09 14:44:17,970][root][INFO] - Step 11448320 @ 3069.5 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 3820.9, step = 11448320, mean_episode_return = -20.88, mean_episode_step = 2022.9, total_loss = -22.273, pg_loss = -30.736, baseline_loss = 20.643, entropy_loss = -12.18, learner_queue_size = 64, _tick = 1601, _time = 1.6548e+09)
[2022-06-09 14:44:22,974][root][INFO] - Step 11463680 @ 3069.5 SPS. Inference batcher size: 101. Learner queue size: 64. Other stats: (train_seconds = 3825.9, step = 11463680, mean_episode_return = 42.41, mean_episode_step = 1957.5, total_loss = -79.995, pg_loss = -91.151, baseline_loss = 23.497, entropy_loss = -12.341, learner_queue_size = 64, _tick = 1603, _time = 1.6548e+09)
[2022-06-09 14:44:27,978][root][INFO] - Step 11479040 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 3830.9, step = 11479040, mean_episode_return = 64.918, mean_episode_step = 1901.0, total_loss = -175.89, pg_loss = -177.19, baseline_loss = 13.323, entropy_loss = -12.019, learner_queue_size = 64, _tick = 1606, _time = 1.6548e+09)
[2022-06-09 14:44:32,982][root][INFO] - Step 11494400 @ 3069.5 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 3835.9, step = 11494400, mean_episode_return = 58.024, mean_episode_step = 2127.7, total_loss = 60.453, pg_loss = 23.976, baseline_loss = 48.581, entropy_loss = -12.104, learner_queue_size = 64, _tick = 1609, _time = 1.6548e+09)
[2022-06-09 14:44:37,986][root][INFO] - Step 11509760 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 3840.9, step = 11509760, mean_episode_return = 4.9281, mean_episode_step = 2020.0, total_loss = 71.037, pg_loss = 37.787, baseline_loss = 45.542, entropy_loss = -12.292, learner_queue_size = 64, _tick = 1611, _time = 1.6548e+09)
[2022-06-09 14:44:42,990][root][INFO] - Step 11530240 @ 4092.7 SPS. Inference batcher size: 11. Learner queue size: 64. Other stats: (train_seconds = 3845.9, step = 11530240, mean_episode_return = 49.939, mean_episode_step = 2088.2, total_loss = 52.343, pg_loss = 24.934, baseline_loss = 40.466, entropy_loss = -13.057, learner_queue_size = 64, _tick = 1614, _time = 1.6548e+09)
[2022-06-09 14:44:47,994][root][INFO] - Step 11545600 @ 3069.5 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 3850.9, step = 11545600, mean_episode_return = 128.57, mean_episode_step = 1732.5, total_loss = -128.34, pg_loss = -124.88, baseline_loss = 9.6127, entropy_loss = -13.071, learner_queue_size = 64, _tick = 1615, _time = 1.6548e+09)
[2022-06-09 14:44:52,998][root][INFO] - Step 11560960 @ 3069.6 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 3855.9, step = 11560960, mean_episode_return = 23.81, mean_episode_step = 2125.5, total_loss = 88.534, pg_loss = 73.117, baseline_loss = 28.57, entropy_loss = -13.153, learner_queue_size = 64, _tick = 1618, _time = 1.6548e+09)
[2022-06-09 14:44:58,014][root][INFO] - Step 11576320 @ 3062.4 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 3860.9, step = 11576320, mean_episode_return = 98.498, mean_episode_step = 2016.4, total_loss = 23.835, pg_loss = 13.204, baseline_loss = 24.011, entropy_loss = -13.38, learner_queue_size = 64, _tick = 1621, _time = 1.6548e+09)
[2022-06-09 14:45:03,018][root][INFO] - Step 11591680 @ 3069.3 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 3866.0, step = 11591680, mean_episode_return = -7.2804, mean_episode_step = 1717.9, total_loss = -52.455, pg_loss = -56.361, baseline_loss = 17.416, entropy_loss = -13.511, learner_queue_size = 64, _tick = 1622, _time = 1.6548e+09)
[2022-06-09 14:45:08,022][root][INFO] - Step 11607040 @ 3069.6 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 3871.0, step = 11607040, mean_episode_return = 81.247, mean_episode_step = 2443.7, total_loss = -119.79, pg_loss = -135.48, baseline_loss = 29.435, entropy_loss = -13.749, learner_queue_size = 64, _tick = 1625, _time = 1.6548e+09)
[2022-06-09 14:45:13,026][root][INFO] - Step 11622400 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 3876.0, step = 11622400, mean_episode_return = 22.46, mean_episode_step = 2105.2, total_loss = -160.03, pg_loss = -150.34, baseline_loss = 4.1513, entropy_loss = -13.841, learner_queue_size = 64, _tick = 1627, _time = 1.6548e+09)
[2022-06-09 14:45:18,030][root][INFO] - Step 11637760 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 3881.0, step = 11637760, mean_episode_return = -6.8306, mean_episode_step = 2302.4, total_loss = -119.92, pg_loss = -125.22, baseline_loss = 19.236, entropy_loss = -13.935, learner_queue_size = 64, _tick = 1630, _time = 1.6548e+09)
[2022-06-09 14:45:23,034][root][INFO] - Step 11653120 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 3886.0, step = 11653120, mean_episode_return = -60.366, mean_episode_step = 2383.5, total_loss = -75.306, pg_loss = -78.572, baseline_loss = 17.124, entropy_loss = -13.858, learner_queue_size = 64, _tick = 1632, _time = 1.6548e+09)
[2022-06-09 14:45:28,038][root][INFO] - Step 11668480 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 3891.0, step = 11668480, mean_episode_return = None, mean_episode_step = 1994.2, total_loss = -23.892, pg_loss = -23.912, baseline_loss = 14.098, entropy_loss = -14.078, learner_queue_size = 64, _tick = 1634, _time = 1.6548e+09)
[2022-06-09 14:45:33,042][root][INFO] - Step 11688960 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 3896.0, step = 11688960, mean_episode_return = 106.99, mean_episode_step = 2346.2, total_loss = 139.01, pg_loss = 107.62, baseline_loss = 45.562, entropy_loss = -14.176, learner_queue_size = 64, _tick = 1637, _time = 1.6548e+09)
[2022-06-09 14:45:38,046][root][INFO] - Step 11704320 @ 3069.5 SPS. Inference batcher size: 77. Learner queue size: 64. Other stats: (train_seconds = 3901.0, step = 11704320, mean_episode_return = 62.828, mean_episode_step = 2146.3, total_loss = 41.512, pg_loss = 6.7515, baseline_loss = 48.784, entropy_loss = -14.024, learner_queue_size = 64, _tick = 1639, _time = 1.6548e+09)
[2022-06-09 14:45:43,050][root][INFO] - Step 11719680 @ 3069.5 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 3906.0, step = 11719680, mean_episode_return = 54.125, mean_episode_step = 2027.8, total_loss = 87.524, pg_loss = 74.625, baseline_loss = 26.791, entropy_loss = -13.892, learner_queue_size = 64, _tick = 1642, _time = 1.6548e+09)
[2022-06-09 14:45:48,054][root][INFO] - Step 11735040 @ 3069.3 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 3911.0, step = 11735040, mean_episode_return = 48.064, mean_episode_step = 2400.3, total_loss = -141.7, pg_loss = -137.99, baseline_loss = 10.335, entropy_loss = -14.039, learner_queue_size = 64, _tick = 1645, _time = 1.6548e+09)
[2022-06-09 14:45:53,058][root][INFO] - Step 11750400 @ 3069.8 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 3916.0, step = 11750400, mean_episode_return = 83.839, mean_episode_step = 2212.6, total_loss = 47.795, pg_loss = 25.988, baseline_loss = 36.061, entropy_loss = -14.254, learner_queue_size = 64, _tick = 1648, _time = 1.6548e+09)
[2022-06-09 14:45:58,062][root][INFO] - Step 11765760 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 3921.0, step = 11765760, mean_episode_return = 20.52, mean_episode_step = 2014.4, total_loss = -110.31, pg_loss = -104.74, baseline_loss = 8.7647, entropy_loss = -14.34, learner_queue_size = 64, _tick = 1650, _time = 1.6548e+09)
[2022-06-09 14:46:03,066][root][INFO] - Step 11781120 @ 3069.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 3926.0, step = 11781120, mean_episode_return = None, mean_episode_step = 2204.6, total_loss = 106.26, pg_loss = 95.427, baseline_loss = 25.721, entropy_loss = -14.89, learner_queue_size = 64, _tick = 1652, _time = 1.6548e+09)
[2022-06-09 14:46:08,070][root][INFO] - Step 11796480 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 3931.0, step = 11796480, mean_episode_return = 45.342, mean_episode_step = 1954.1, total_loss = 103.86, pg_loss = 82.704, baseline_loss = 35.804, entropy_loss = -14.647, learner_queue_size = 64, _tick = 1654, _time = 1.6548e+09)
[2022-06-09 14:46:13,074][root][INFO] - Step 11811840 @ 3069.6 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 3936.0, step = 11811840, mean_episode_return = 85.329, mean_episode_step = 2110.8, total_loss = 28.076, pg_loss = 17.839, baseline_loss = 24.657, entropy_loss = -14.42, learner_queue_size = 64, _tick = 1657, _time = 1.6548e+09)
[2022-06-09 14:46:18,080][root][INFO] - Step 11827200 @ 3068.3 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 3941.0, step = 11827200, mean_episode_return = 51.343, mean_episode_step = 2334.4, total_loss = 36.017, pg_loss = 29.728, baseline_loss = 20.277, entropy_loss = -13.988, learner_queue_size = 64, _tick = 1659, _time = 1.6548e+09)
[2022-06-09 14:46:23,086][root][INFO] - Step 11847680 @ 4091.2 SPS. Inference batcher size: 3. Learner queue size: 64. Other stats: (train_seconds = 3946.0, step = 11847680, mean_episode_return = None, mean_episode_step = 2303.5, total_loss = 114.41, pg_loss = 105.02, baseline_loss = 22.207, entropy_loss = -12.813, learner_queue_size = 64, _tick = 1662, _time = 1.6548e+09)
[2022-06-09 14:46:28,090][root][INFO] - Step 11863040 @ 3069.6 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 3951.0, step = 11863040, mean_episode_return = 52.266, mean_episode_step = 2463.6, total_loss = -136.96, pg_loss = -128.77, baseline_loss = 4.7014, entropy_loss = -12.889, learner_queue_size = 64, _tick = 1664, _time = 1.6548e+09)
[2022-06-09 14:46:33,094][root][INFO] - Step 11878400 @ 3069.5 SPS. Inference batcher size: 76. Learner queue size: 64. Other stats: (train_seconds = 3956.0, step = 11878400, mean_episode_return = None, mean_episode_step = 2187.2, total_loss = -93.119, pg_loss = -84.172, baseline_loss = 4.5696, entropy_loss = -13.517, learner_queue_size = 64, _tick = 1665, _time = 1.6548e+09)
[2022-06-09 14:46:38,098][root][INFO] - Step 11893760 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 3961.0, step = 11893760, mean_episode_return = 85.613, mean_episode_step = 2226.9, total_loss = -4.6472, pg_loss = -3.2342, baseline_loss = 12.262, entropy_loss = -13.675, learner_queue_size = 64, _tick = 1666, _time = 1.6548e+09)
[2022-06-09 14:46:43,115][root][INFO] - Step 11909120 @ 3061.4 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 3966.1, step = 11909120, mean_episode_return = 45.323, mean_episode_step = 2865.2, total_loss = -76.171, pg_loss = -74.775, baseline_loss = 12.136, entropy_loss = -13.532, learner_queue_size = 64, _tick = 1669, _time = 1.6548e+09)
[2022-06-09 14:46:48,118][root][INFO] - Step 11924480 @ 3070.3 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 3971.1, step = 11924480, mean_episode_return = None, mean_episode_step = 2395.3, total_loss = 44.286, pg_loss = 34.359, baseline_loss = 23.579, entropy_loss = -13.652, learner_queue_size = 64, _tick = 1670, _time = 1.6548e+09)
[2022-06-09 14:46:53,122][root][INFO] - Step 11939840 @ 3069.6 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 3976.1, step = 11939840, mean_episode_return = 52.21, mean_episode_step = 2225.4, total_loss = -122.67, pg_loss = -120.78, baseline_loss = 12.501, entropy_loss = -14.388, learner_queue_size = 64, _tick = 1673, _time = 1.6548e+09)
[2022-06-09 14:46:58,126][root][INFO] - Step 11955200 @ 3069.5 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 3981.1, step = 11955200, mean_episode_return = None, mean_episode_step = 2625.3, total_loss = -20.771, pg_loss = -17.541, baseline_loss = 11.656, entropy_loss = -14.887, learner_queue_size = 64, _tick = 1675, _time = 1.6548e+09)
[2022-06-09 14:47:03,130][root][INFO] - Step 11970560 @ 3069.6 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 3986.1, step = 11970560, mean_episode_return = 30.336, mean_episode_step = 2130.2, total_loss = 338.23, pg_loss = 299.77, baseline_loss = 53.403, entropy_loss = -14.941, learner_queue_size = 64, _tick = 1678, _time = 1.6548e+09)
[2022-06-09 14:47:08,134][root][INFO] - Step 11985920 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 3991.1, step = 11985920, mean_episode_return = 46.495, mean_episode_step = 2682.0, total_loss = -133.13, pg_loss = -129.91, baseline_loss = 11.74, entropy_loss = -14.961, learner_queue_size = 64, _tick = 1681, _time = 1.6548e+09)
[2022-06-09 14:47:13,138][root][INFO] - Step 12006400 @ 4092.7 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 3996.1, step = 12006400, mean_episode_return = 5.9747, mean_episode_step = 2016.1, total_loss = -165.3, pg_loss = -158.2, baseline_loss = 7.866, entropy_loss = -14.965, learner_queue_size = 64, _tick = 1684, _time = 1.6548e+09)
[2022-06-09 14:47:18,144][root][INFO] - Step 12021760 @ 3068.5 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 4001.1, step = 12021760, mean_episode_return = None, mean_episode_step = 2047.7, total_loss = -41.748, pg_loss = -35.498, baseline_loss = 8.936, entropy_loss = -15.186, learner_queue_size = 64, _tick = 1685, _time = 1.6548e+09)
[2022-06-09 14:47:23,146][root][INFO] - Step 12037120 @ 3070.5 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 4006.1, step = 12037120, mean_episode_return = 59.067, mean_episode_step = 2523.9, total_loss = -93.91, pg_loss = -96.713, baseline_loss = 17.732, entropy_loss = -14.929, learner_queue_size = 64, _tick = 1688, _time = 1.6548e+09)
[2022-06-09 14:47:28,150][root][INFO] - Step 12052480 @ 3069.5 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 4011.1, step = 12052480, mean_episode_return = None, mean_episode_step = 2400.7, total_loss = -135.6, pg_loss = -121.58, baseline_loss = 1.046, entropy_loss = -15.066, learner_queue_size = 64, _tick = 1690, _time = 1.6548e+09)
[2022-06-09 14:47:33,154][root][INFO] - Step 12067840 @ 3069.6 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 4016.1, step = 12067840, mean_episode_return = 132.63, mean_episode_step = 2183.3, total_loss = -39.751, pg_loss = -45.136, baseline_loss = 20.654, entropy_loss = -15.269, learner_queue_size = 64, _tick = 1693, _time = 1.6548e+09)
[2022-06-09 14:47:38,158][root][INFO] - Step 12083200 @ 3069.5 SPS. Inference batcher size: 75. Learner queue size: 64. Other stats: (train_seconds = 4021.1, step = 12083200, mean_episode_return = 97.995, mean_episode_step = 2609.4, total_loss = -140.59, pg_loss = -128.11, baseline_loss = 2.9471, entropy_loss = -15.428, learner_queue_size = 64, _tick = 1696, _time = 1.6548e+09)
[2022-06-09 14:47:43,164][root][INFO] - Step 12098560 @ 3068.2 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 4026.1, step = 12098560, mean_episode_return = None, mean_episode_step = 2580.5, total_loss = 229.57, pg_loss = 209.08, baseline_loss = 36.066, entropy_loss = -15.583, learner_queue_size = 64, _tick = 1697, _time = 1.6548e+09)
[2022-06-09 14:47:48,170][root][INFO] - Step 12113920 @ 3068.4 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 4031.1, step = 12113920, mean_episode_return = -33.281, mean_episode_step = 2030.3, total_loss = 85.86, pg_loss = 79.272, baseline_loss = 22.005, entropy_loss = -15.417, learner_queue_size = 64, _tick = 1700, _time = 1.6548e+09)
[2022-06-09 14:47:53,174][root][INFO] - Step 12129280 @ 3069.6 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 4036.1, step = 12129280, mean_episode_return = 32.27, mean_episode_step = 2194.0, total_loss = -43.302, pg_loss = -50.136, baseline_loss = 22.066, entropy_loss = -15.232, learner_queue_size = 64, _tick = 1703, _time = 1.6548e+09)
[2022-06-09 14:47:58,179][root][INFO] - Step 12144640 @ 3069.4 SPS. Inference batcher size: 7. Learner queue size: 64. Other stats: (train_seconds = 4041.1, step = 12144640, mean_episode_return = 103.0, mean_episode_step = 2108.7, total_loss = 157.79, pg_loss = 137.49, baseline_loss = 35.711, entropy_loss = -15.41, learner_queue_size = 64, _tick = 1706, _time = 1.6548e+09)
[2022-06-09 14:48:03,182][root][INFO] - Step 12160000 @ 3069.7 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 4046.1, step = 12160000, mean_episode_return = 114.3, mean_episode_step = 2380.6, total_loss = 33.411, pg_loss = 28.576, baseline_loss = 20.069, entropy_loss = -15.234, learner_queue_size = 64, _tick = 1709, _time = 1.6548e+09)
[2022-06-09 14:48:08,186][root][INFO] - Step 12175360 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 4051.1, step = 12175360, mean_episode_return = 24.06, mean_episode_step = 2289.4, total_loss = -62.653, pg_loss = -56.367, baseline_loss = 8.8273, entropy_loss = -15.114, learner_queue_size = 64, _tick = 1711, _time = 1.6548e+09)
[2022-06-09 14:48:13,190][root][INFO] - Step 12190720 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 4056.1, step = 12190720, mean_episode_return = 40.09, mean_episode_step = 2231.7, total_loss = 148.48, pg_loss = 138.2, baseline_loss = 25.678, entropy_loss = -15.399, learner_queue_size = 64, _tick = 1713, _time = 1.6548e+09)
[2022-06-09 14:48:18,194][root][INFO] - Step 12206080 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 4061.1, step = 12206080, mean_episode_return = 45.511, mean_episode_step = 2263.2, total_loss = -39.169, pg_loss = -46.794, baseline_loss = 23.323, entropy_loss = -15.698, learner_queue_size = 64, _tick = 1716, _time = 1.6548e+09)
[2022-06-09 14:48:23,198][root][INFO] - Step 12226560 @ 4092.7 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 4066.1, step = 12226560, mean_episode_return = None, mean_episode_step = 2086.8, total_loss = 133.54, pg_loss = 127.86, baseline_loss = 21.166, entropy_loss = -15.482, learner_queue_size = 64, _tick = 1718, _time = 1.6548e+09)
[2022-06-09 14:48:28,202][root][INFO] - Step 12241920 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 4071.1, step = 12241920, mean_episode_return = 28.582, mean_episode_step = 2124.6, total_loss = 34.855, pg_loss = 7.1587, baseline_loss = 43.577, entropy_loss = -15.88, learner_queue_size = 64, _tick = 1721, _time = 1.6548e+09)
[2022-06-09 14:48:33,206][root][INFO] - Step 12257280 @ 3069.6 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 4076.1, step = 12257280, mean_episode_return = 74.585, mean_episode_step = 2020.6, total_loss = -143.58, pg_loss = -139.63, baseline_loss = 11.253, entropy_loss = -15.202, learner_queue_size = 64, _tick = 1724, _time = 1.6548e+09)
[2022-06-09 14:48:38,210][root][INFO] - Step 12272640 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 4081.1, step = 12272640, mean_episode_return = 28.33, mean_episode_step = 2074.3, total_loss = -11.509, pg_loss = -14.369, baseline_loss = 18.542, entropy_loss = -15.682, learner_queue_size = 64, _tick = 1726, _time = 1.6548e+09)
[2022-06-09 14:48:43,220][root][INFO] - Step 12288000 @ 3066.2 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 4086.2, step = 12288000, mean_episode_return = 141.5, mean_episode_step = 2034.9, total_loss = -66.877, pg_loss = -74.422, baseline_loss = 22.802, entropy_loss = -15.257, learner_queue_size = 64, _tick = 1729, _time = 1.6548e+09)
[2022-06-09 14:48:48,222][root][INFO] - Step 12303360 @ 3070.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 4091.2, step = 12303360, mean_episode_return = None, mean_episode_step = 1859.0, total_loss = -4.0638, pg_loss = 0.89708, baseline_loss = 10.57, entropy_loss = -15.531, learner_queue_size = 64, _tick = 1731, _time = 1.6548e+09)
[2022-06-09 14:48:53,226][root][INFO] - Step 12318720 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 4096.2, step = 12318720, mean_episode_return = None, mean_episode_step = 1887.2, total_loss = 78.054, pg_loss = 74.422, baseline_loss = 18.851, entropy_loss = -15.219, learner_queue_size = 64, _tick = 1732, _time = 1.6548e+09)
[2022-06-09 14:48:58,230][root][INFO] - Step 12334080 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 4101.2, step = 12334080, mean_episode_return = 107.79, mean_episode_step = 2002.6, total_loss = -25.209, pg_loss = -43.235, baseline_loss = 33.044, entropy_loss = -15.018, learner_queue_size = 64, _tick = 1735, _time = 1.6548e+09)
[2022-06-09 14:49:03,234][root][INFO] - Step 12349440 @ 3069.5 SPS. Inference batcher size: 15. Learner queue size: 64. Other stats: (train_seconds = 4106.2, step = 12349440, mean_episode_return = 9.4975, mean_episode_step = 2088.0, total_loss = 31.273, pg_loss = 14.599, baseline_loss = 31.952, entropy_loss = -15.278, learner_queue_size = 64, _tick = 1738, _time = 1.6548e+09)
[2022-06-09 14:49:08,238][root][INFO] - Step 12369920 @ 4092.7 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 4111.2, step = 12369920, mean_episode_return = 0.79256, mean_episode_step = 1692.1, total_loss = -113.01, pg_loss = -132.76, baseline_loss = 34.675, entropy_loss = -14.929, learner_queue_size = 64, _tick = 1742, _time = 1.6548e+09)
[2022-06-09 14:49:13,242][root][INFO] - Step 12385280 @ 3069.6 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 4116.2, step = 12385280, mean_episode_return = -44.329, mean_episode_step = 1542.6, total_loss = 18.907, pg_loss = 14.14, baseline_loss = 19.65, entropy_loss = -14.884, learner_queue_size = 64, _tick = 1745, _time = 1.6548e+09)
[2022-06-09 14:49:18,247][root][INFO] - Step 12400640 @ 3069.0 SPS. Inference batcher size: 78. Learner queue size: 64. Other stats: (train_seconds = 4121.2, step = 12400640, mean_episode_return = 9.6868, mean_episode_step = 1694.8, total_loss = 85.364, pg_loss = 73.673, baseline_loss = 26.793, entropy_loss = -15.103, learner_queue_size = 64, _tick = 1747, _time = 1.6548e+09)
[2022-06-09 14:49:23,250][root][INFO] - Step 12416000 @ 3070.0 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 4126.2, step = 12416000, mean_episode_return = 45.383, mean_episode_step = 2040.5, total_loss = 181.82, pg_loss = 146.23, baseline_loss = 50.603, entropy_loss = -15.012, learner_queue_size = 64, _tick = 1750, _time = 1.6548e+09)
[2022-06-09 14:49:28,254][root][INFO] - Step 12431360 @ 3069.7 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 4131.2, step = 12431360, mean_episode_return = 14.235, mean_episode_step = 1798.9, total_loss = 38.514, pg_loss = 24.819, baseline_loss = 28.665, entropy_loss = -14.971, learner_queue_size = 64, _tick = 1753, _time = 1.6548e+09)
[2022-06-09 14:49:33,258][root][INFO] - Step 12446720 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 4136.2, step = 12446720, mean_episode_return = 56.114, mean_episode_step = 1576.9, total_loss = 266.87, pg_loss = 213.87, baseline_loss = 67.838, entropy_loss = -14.834, learner_queue_size = 64, _tick = 1755, _time = 1.6548e+09)
[2022-06-09 14:49:38,262][root][INFO] - Step 12462080 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 4141.2, step = 12462080, mean_episode_return = None, mean_episode_step = 1673.0, total_loss = 116.7, pg_loss = 96.773, baseline_loss = 34.747, entropy_loss = -14.82, learner_queue_size = 64, _tick = 1756, _time = 1.6548e+09)
[2022-06-09 14:49:43,266][root][INFO] - Step 12477440 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 4146.2, step = 12477440, mean_episode_return = None, mean_episode_step = 1817.6, total_loss = -26.478, pg_loss = -30.671, baseline_loss = 19.081, entropy_loss = -14.888, learner_queue_size = 64, _tick = 1758, _time = 1.6548e+09)
[2022-06-09 14:49:48,270][root][INFO] - Step 12492800 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 4151.2, step = 12492800, mean_episode_return = 17.39, mean_episode_step = 1924.0, total_loss = -78.509, pg_loss = -79.248, baseline_loss = 15.406, entropy_loss = -14.667, learner_queue_size = 64, _tick = 1761, _time = 1.6548e+09)
[2022-06-09 14:49:53,274][root][INFO] - Step 12508160 @ 3069.5 SPS. Inference batcher size: 18. Learner queue size: 64. Other stats: (train_seconds = 4156.2, step = 12508160, mean_episode_return = None, mean_episode_step = 1663.0, total_loss = -37.356, pg_loss = -46.201, baseline_loss = 23.411, entropy_loss = -14.566, learner_queue_size = 64, _tick = 1763, _time = 1.6548e+09)
[2022-06-09 14:49:58,279][root][INFO] - Step 12523520 @ 3068.8 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 4161.2, step = 12523520, mean_episode_return = 59.015, mean_episode_step = 1624.1, total_loss = -131.33, pg_loss = -134.49, baseline_loss = 17.455, entropy_loss = -14.291, learner_queue_size = 64, _tick = 1766, _time = 1.6548e+09)
[2022-06-09 14:50:03,282][root][INFO] - Step 12544000 @ 4093.7 SPS. Inference batcher size: 81. Learner queue size: 64. Other stats: (train_seconds = 4166.2, step = 12544000, mean_episode_return = 50.49, mean_episode_step = 2022.9, total_loss = -201.72, pg_loss = -211.92, baseline_loss = 24.787, entropy_loss = -14.583, learner_queue_size = 64, _tick = 1769, _time = 1.6548e+09)
[2022-06-09 14:50:08,286][root][INFO] - Step 12559360 @ 3069.6 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 4171.2, step = 12559360, mean_episode_return = 8.2955, mean_episode_step = 2100.4, total_loss = -208.88, pg_loss = -200.22, baseline_loss = 5.7733, entropy_loss = -14.437, learner_queue_size = 64, _tick = 1771, _time = 1.6548e+09)
[2022-06-09 14:50:13,290][root][INFO] - Step 12574720 @ 3069.5 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 4176.2, step = 12574720, mean_episode_return = 26.38, mean_episode_step = 2333.2, total_loss = 158.13, pg_loss = 137.24, baseline_loss = 35.578, entropy_loss = -14.682, learner_queue_size = 64, _tick = 1774, _time = 1.6548e+09)
[2022-06-09 14:50:18,294][root][INFO] - Step 12590080 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 4181.2, step = 12590080, mean_episode_return = 17.43, mean_episode_step = 1816.5, total_loss = 103.33, pg_loss = 79.815, baseline_loss = 38.016, entropy_loss = -14.498, learner_queue_size = 64, _tick = 1776, _time = 1.6548e+09)
[2022-06-09 14:50:23,298][root][INFO] - Step 12605440 @ 3069.6 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 4186.2, step = 12605440, mean_episode_return = 83.264, mean_episode_step = 2251.0, total_loss = 36.881, pg_loss = 10.483, baseline_loss = 41.037, entropy_loss = -14.639, learner_queue_size = 64, _tick = 1777, _time = 1.6548e+09)
[2022-06-09 14:50:28,302][root][INFO] - Step 12620800 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 4191.2, step = 12620800, mean_episode_return = None, mean_episode_step = 1967.7, total_loss = 35.318, pg_loss = 28.42, baseline_loss = 21.439, entropy_loss = -14.542, learner_queue_size = 64, _tick = 1779, _time = 1.6548e+09)
[2022-06-09 14:50:33,306][root][INFO] - Step 12636160 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 4196.2, step = 12636160, mean_episode_return = -86.48, mean_episode_step = 1981.7, total_loss = -38.428, pg_loss = -36.467, baseline_loss = 13.438, entropy_loss = -15.399, learner_queue_size = 64, _tick = 1781, _time = 1.6548e+09)
[2022-06-09 14:50:38,310][root][INFO] - Step 12651520 @ 3069.6 SPS. Inference batcher size: 6. Learner queue size: 64. Other stats: (train_seconds = 4201.2, step = 12651520, mean_episode_return = 28.14, mean_episode_step = 1875.9, total_loss = 172.82, pg_loss = 139.36, baseline_loss = 48.517, entropy_loss = -15.052, learner_queue_size = 64, _tick = 1783, _time = 1.6548e+09)
[2022-06-09 14:50:43,314][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 14:50:43,665][root][INFO] - Step 12672000 @ 4092.7 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 4206.2, step = 12672000, mean_episode_return = None, mean_episode_step = 2344.1, total_loss = -13.751, pg_loss = -16.137, baseline_loss = 17.495, entropy_loss = -15.109, learner_queue_size = 64, _tick = 1786, _time = 1.6548e+09)
[2022-06-09 14:50:48,670][root][INFO] - Step 12687360 @ 2867.8 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 4211.6, step = 12687360, mean_episode_return = 5.3, mean_episode_step = 2071.8, total_loss = 83.548, pg_loss = 59.93, baseline_loss = 38.616, entropy_loss = -14.998, learner_queue_size = 64, _tick = 1789, _time = 1.6548e+09)
[2022-06-09 14:50:53,674][root][INFO] - Step 12702720 @ 3069.5 SPS. Inference batcher size: 99. Learner queue size: 64. Other stats: (train_seconds = 4216.6, step = 12702720, mean_episode_return = 15.21, mean_episode_step = 2096.4, total_loss = 97.832, pg_loss = 85.722, baseline_loss = 27.342, entropy_loss = -15.232, learner_queue_size = 64, _tick = 1792, _time = 1.6548e+09)
[2022-06-09 14:50:58,679][root][INFO] - Step 12718080 @ 3068.7 SPS. Inference batcher size: 68. Learner queue size: 64. Other stats: (train_seconds = 4221.6, step = 12718080, mean_episode_return = 92.744, mean_episode_step = 2055.2, total_loss = 29.716, pg_loss = 20.32, baseline_loss = 24.505, entropy_loss = -15.109, learner_queue_size = 64, _tick = 1795, _time = 1.6548e+09)
[2022-06-09 14:51:03,682][root][INFO] - Step 12733440 @ 3070.4 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 4226.6, step = 12733440, mean_episode_return = 210.05, mean_episode_step = 2045.8, total_loss = -135.86, pg_loss = -144.38, baseline_loss = 23.57, entropy_loss = -15.045, learner_queue_size = 64, _tick = 1798, _time = 1.6548e+09)
[2022-06-09 14:51:08,686][root][INFO] - Step 12748800 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 4231.6, step = 12748800, mean_episode_return = 163.93, mean_episode_step = 2408.7, total_loss = -27.994, pg_loss = -31.549, baseline_loss = 18.311, entropy_loss = -14.757, learner_queue_size = 64, _tick = 1801, _time = 1.6548e+09)
[2022-06-09 14:51:13,690][root][INFO] - Step 12764160 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 4236.6, step = 12764160, mean_episode_return = 1.9099, mean_episode_step = 1985.4, total_loss = -67.144, pg_loss = -66.613, baseline_loss = 13.913, entropy_loss = -14.443, learner_queue_size = 64, _tick = 1804, _time = 1.6548e+09)
[2022-06-09 14:51:18,694][root][INFO] - Step 12779520 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 4241.6, step = 12779520, mean_episode_return = 34.859, mean_episode_step = 2067.3, total_loss = -63.31, pg_loss = -89.555, baseline_loss = 40.412, entropy_loss = -14.167, learner_queue_size = 64, _tick = 1807, _time = 1.6548e+09)
[2022-06-09 14:51:23,700][root][INFO] - Step 12794880 @ 3068.4 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 4246.6, step = 12794880, mean_episode_return = 49.894, mean_episode_step = 2165.0, total_loss = -191.22, pg_loss = -186.83, baseline_loss = 10.025, entropy_loss = -14.411, learner_queue_size = 64, _tick = 1809, _time = 1.6548e+09)
[2022-06-09 14:51:28,702][root][INFO] - Step 12815360 @ 4094.2 SPS. Inference batcher size: 71. Learner queue size: 64. Other stats: (train_seconds = 4251.6, step = 12815360, mean_episode_return = None, mean_episode_step = 1986.6, total_loss = -73.956, pg_loss = -72.847, baseline_loss = 13.738, entropy_loss = -14.847, learner_queue_size = 64, _tick = 1812, _time = 1.6548e+09)
[2022-06-09 14:51:33,706][root][INFO] - Step 12830720 @ 3069.5 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 4256.6, step = 12830720, mean_episode_return = None, mean_episode_step = 2229.6, total_loss = 88.573, pg_loss = 79.974, baseline_loss = 23.387, entropy_loss = -14.788, learner_queue_size = 64, _tick = 1814, _time = 1.6548e+09)
[2022-06-09 14:51:38,710][root][INFO] - Step 12846080 @ 3069.6 SPS. Inference batcher size: 81. Learner queue size: 64. Other stats: (train_seconds = 4261.6, step = 12846080, mean_episode_return = 15.337, mean_episode_step = 2030.5, total_loss = 4.0099, pg_loss = -13.056, baseline_loss = 31.794, entropy_loss = -14.729, learner_queue_size = 64, _tick = 1816, _time = 1.6548e+09)
[2022-06-09 14:51:43,725][root][INFO] - Step 12861440 @ 3063.0 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 4266.7, step = 12861440, mean_episode_return = 54.923, mean_episode_step = 1764.3, total_loss = -186.61, pg_loss = -174.34, baseline_loss = 2.2613, entropy_loss = -14.532, learner_queue_size = 64, _tick = 1819, _time = 1.6548e+09)
[2022-06-09 14:51:48,730][root][INFO] - Step 12876800 @ 3068.8 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 4271.7, step = 12876800, mean_episode_return = 27.201, mean_episode_step = 2202.0, total_loss = 7.4831, pg_loss = 0.27306, baseline_loss = 21.693, entropy_loss = -14.483, learner_queue_size = 64, _tick = 1822, _time = 1.6548e+09)
[2022-06-09 14:51:53,734][root][INFO] - Step 12892160 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 4276.7, step = 12892160, mean_episode_return = 38.41, mean_episode_step = 2049.7, total_loss = 32.548, pg_loss = 19.445, baseline_loss = 27.944, entropy_loss = -14.841, learner_queue_size = 64, _tick = 1825, _time = 1.6548e+09)
[2022-06-09 14:51:58,738][root][INFO] - Step 12907520 @ 3069.6 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 4281.7, step = 12907520, mean_episode_return = None, mean_episode_step = 1839.3, total_loss = 100.54, pg_loss = 91.296, baseline_loss = 24.623, entropy_loss = -15.382, learner_queue_size = 64, _tick = 1827, _time = 1.6548e+09)
[2022-06-09 14:52:03,742][root][INFO] - Step 12922880 @ 3069.5 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 4286.7, step = 12922880, mean_episode_return = 19.871, mean_episode_step = 1742.8, total_loss = -93.987, pg_loss = -86.491, baseline_loss = 7.547, entropy_loss = -15.043, learner_queue_size = 64, _tick = 1830, _time = 1.6548e+09)
[2022-06-09 14:52:08,746][root][INFO] - Step 12943360 @ 4092.8 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 4291.7, step = 12943360, mean_episode_return = 68.0, mean_episode_step = 1797.5, total_loss = 118.64, pg_loss = 105.22, baseline_loss = 29.026, entropy_loss = -15.598, learner_queue_size = 64, _tick = 1833, _time = 1.6548e+09)
[2022-06-09 14:52:13,750][root][INFO] - Step 12958720 @ 3069.5 SPS. Inference batcher size: 80. Learner queue size: 64. Other stats: (train_seconds = 4296.7, step = 12958720, mean_episode_return = -10.841, mean_episode_step = 1716.3, total_loss = 38.054, pg_loss = 33.999, baseline_loss = 19.511, entropy_loss = -15.456, learner_queue_size = 64, _tick = 1836, _time = 1.6548e+09)
[2022-06-09 14:52:18,754][root][INFO] - Step 12974080 @ 3069.6 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 4301.7, step = 12974080, mean_episode_return = 71.812, mean_episode_step = 1648.0, total_loss = 75.113, pg_loss = 65.378, baseline_loss = 24.812, entropy_loss = -15.077, learner_queue_size = 64, _tick = 1839, _time = 1.6548e+09)
[2022-06-09 14:52:23,758][root][INFO] - Step 12989440 @ 3069.6 SPS. Inference batcher size: 72. Learner queue size: 64. Other stats: (train_seconds = 4306.7, step = 12989440, mean_episode_return = 22.99, mean_episode_step = 2135.4, total_loss = 157.57, pg_loss = 138.1, baseline_loss = 34.654, entropy_loss = -15.183, learner_queue_size = 64, _tick = 1842, _time = 1.6548e+09)
[2022-06-09 14:52:28,762][root][INFO] - Step 13004800 @ 3069.6 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 4311.7, step = 13004800, mean_episode_return = 0.41597, mean_episode_step = 1776.1, total_loss = 139.09, pg_loss = 109.62, baseline_loss = 44.296, entropy_loss = -14.825, learner_queue_size = 64, _tick = 1845, _time = 1.6548e+09)
[2022-06-09 14:52:33,766][root][INFO] - Step 13020160 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 4316.7, step = 13020160, mean_episode_return = 42.555, mean_episode_step = 1970.3, total_loss = 135.46, pg_loss = 113.74, baseline_loss = 36.515, entropy_loss = -14.795, learner_queue_size = 64, _tick = 1848, _time = 1.6548e+09)
[2022-06-09 14:52:38,770][root][INFO] - Step 13035520 @ 3069.6 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 4321.7, step = 13035520, mean_episode_return = 20.428, mean_episode_step = 1724.8, total_loss = -364.35, pg_loss = -373.22, baseline_loss = 23.7, entropy_loss = -14.83, learner_queue_size = 64, _tick = 1851, _time = 1.6548e+09)
[2022-06-09 14:52:43,774][root][INFO] - Step 13050880 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 4326.7, step = 13050880, mean_episode_return = 52.573, mean_episode_step = 1428.4, total_loss = 258.38, pg_loss = 219.11, baseline_loss = 53.737, entropy_loss = -14.46, learner_queue_size = 64, _tick = 1854, _time = 1.6548e+09)
[2022-06-09 14:52:48,780][root][INFO] - Step 13066240 @ 3068.3 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 4331.7, step = 13066240, mean_episode_return = 21.11, mean_episode_step = 1750.6, total_loss = 120.59, pg_loss = 88.491, baseline_loss = 46.421, entropy_loss = -14.323, learner_queue_size = 64, _tick = 1856, _time = 1.6548e+09)
[2022-06-09 14:52:53,788][root][INFO] - Step 13086720 @ 4089.6 SPS. Inference batcher size: 68. Learner queue size: 64. Other stats: (train_seconds = 4336.7, step = 13086720, mean_episode_return = 19.459, mean_episode_step = 1529.3, total_loss = -261.25, pg_loss = -269.05, baseline_loss = 22.124, entropy_loss = -14.321, learner_queue_size = 64, _tick = 1859, _time = 1.6548e+09)
[2022-06-09 14:52:58,790][root][INFO] - Step 13102080 @ 3070.6 SPS. Inference batcher size: 75. Learner queue size: 64. Other stats: (train_seconds = 4341.7, step = 13102080, mean_episode_return = 38.862, mean_episode_step = 2023.5, total_loss = -46.722, pg_loss = -43.579, baseline_loss = 11.562, entropy_loss = -14.705, learner_queue_size = 64, _tick = 1861, _time = 1.6548e+09)
[2022-06-09 14:53:03,794][root][INFO] - Step 13117440 @ 3069.5 SPS. Inference batcher size: 72. Learner queue size: 64. Other stats: (train_seconds = 4346.7, step = 13117440, mean_episode_return = 96.218, mean_episode_step = 1730.4, total_loss = 50.471, pg_loss = 10.084, baseline_loss = 54.966, entropy_loss = -14.579, learner_queue_size = 64, _tick = 1864, _time = 1.6548e+09)
[2022-06-09 14:53:08,798][root][INFO] - Step 13132800 @ 3069.7 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 4351.7, step = 13132800, mean_episode_return = 51.06, mean_episode_step = 1767.1, total_loss = -79.902, pg_loss = -80.749, baseline_loss = 14.866, entropy_loss = -14.02, learner_queue_size = 64, _tick = 1867, _time = 1.6548e+09)
[2022-06-09 14:53:13,802][root][INFO] - Step 13148160 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 4356.7, step = 13148160, mean_episode_return = 66.654, mean_episode_step = 1851.1, total_loss = -60.731, pg_loss = -72.241, baseline_loss = 25.991, entropy_loss = -14.481, learner_queue_size = 64, _tick = 1869, _time = 1.6548e+09)
[2022-06-09 14:53:18,806][root][INFO] - Step 13163520 @ 3069.6 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 4361.7, step = 13163520, mean_episode_return = None, mean_episode_step = 2024.7, total_loss = 168.05, pg_loss = 141.27, baseline_loss = 41.232, entropy_loss = -14.459, learner_queue_size = 64, _tick = 1871, _time = 1.6548e+09)
[2022-06-09 14:53:23,810][root][INFO] - Step 13178880 @ 3069.5 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 4366.7, step = 13178880, mean_episode_return = 76.005, mean_episode_step = 2174.5, total_loss = -31.213, pg_loss = -42.22, baseline_loss = 24.91, entropy_loss = -13.903, learner_queue_size = 64, _tick = 1874, _time = 1.6548e+09)
[2022-06-09 14:53:28,814][root][INFO] - Step 13194240 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 4371.8, step = 13194240, mean_episode_return = 28.635, mean_episode_step = 1816.1, total_loss = -129.57, pg_loss = -129.22, baseline_loss = 13.06, entropy_loss = -13.41, learner_queue_size = 64, _tick = 1877, _time = 1.6548e+09)
[2022-06-09 14:53:33,818][root][INFO] - Step 13209600 @ 3069.6 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 4376.8, step = 13209600, mean_episode_return = 86.789, mean_episode_step = 1769.3, total_loss = 50.491, pg_loss = 23.084, baseline_loss = 40.927, entropy_loss = -13.521, learner_queue_size = 64, _tick = 1879, _time = 1.6548e+09)
[2022-06-09 14:53:38,823][root][INFO] - Step 13224960 @ 3068.7 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 4381.8, step = 13224960, mean_episode_return = 18.545, mean_episode_step = 1525.1, total_loss = 90.78, pg_loss = 52.843, baseline_loss = 50.997, entropy_loss = -13.061, learner_queue_size = 64, _tick = 1882, _time = 1.6548e+09)
[2022-06-09 14:53:43,830][root][INFO] - Step 13245440 @ 4090.7 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 4386.8, step = 13245440, mean_episode_return = 60.61, mean_episode_step = 1603.0, total_loss = -130.31, pg_loss = -137.58, baseline_loss = 20.158, entropy_loss = -12.88, learner_queue_size = 64, _tick = 1885, _time = 1.6548e+09)
[2022-06-09 14:53:48,834][root][INFO] - Step 13260800 @ 3069.2 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 4391.8, step = 13260800, mean_episode_return = None, mean_episode_step = 1738.6, total_loss = -103.16, pg_loss = -101.01, baseline_loss = 10.641, entropy_loss = -12.795, learner_queue_size = 64, _tick = 1887, _time = 1.6548e+09)
[2022-06-09 14:53:53,841][root][INFO] - Step 13276160 @ 3068.0 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 4396.8, step = 13276160, mean_episode_return = -27.453, mean_episode_step = 1702.4, total_loss = -163.83, pg_loss = -170.43, baseline_loss = 19.625, entropy_loss = -13.028, learner_queue_size = 64, _tick = 1890, _time = 1.6548e+09)
[2022-06-09 14:53:58,846][root][INFO] - Step 13291520 @ 3068.9 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 4401.8, step = 13291520, mean_episode_return = 50.334, mean_episode_step = 1671.5, total_loss = 296.0, pg_loss = 242.36, baseline_loss = 66.439, entropy_loss = -12.804, learner_queue_size = 64, _tick = 1893, _time = 1.6548e+09)
[2022-06-09 14:54:03,850][root][INFO] - Step 13306880 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 4406.8, step = 13306880, mean_episode_return = None, mean_episode_step = 1705.9, total_loss = -73.605, pg_loss = -71.217, baseline_loss = 10.72, entropy_loss = -13.108, learner_queue_size = 64, _tick = 1893, _time = 1.6548e+09)
[2022-06-09 14:54:08,854][root][INFO] - Step 13322240 @ 3069.5 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 4411.8, step = 13322240, mean_episode_return = 80.379, mean_episode_step = 1949.6, total_loss = 72.209, pg_loss = 55.515, baseline_loss = 30.255, entropy_loss = -13.561, learner_queue_size = 64, _tick = 1895, _time = 1.6548e+09)
[2022-06-09 14:54:13,860][root][INFO] - Step 13337600 @ 3068.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 4416.8, step = 13337600, mean_episode_return = None, mean_episode_step = 1887.1, total_loss = 41.27, pg_loss = 31.042, baseline_loss = 24.062, entropy_loss = -13.834, learner_queue_size = 64, _tick = 1897, _time = 1.6548e+09)
[2022-06-09 14:54:18,862][root][INFO] - Step 13358080 @ 4094.3 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 4421.8, step = 13358080, mean_episode_return = None, mean_episode_step = 1815.5, total_loss = 99.718, pg_loss = 74.659, baseline_loss = 39.244, entropy_loss = -14.185, learner_queue_size = 64, _tick = 1899, _time = 1.6548e+09)
[2022-06-09 14:54:23,866][root][INFO] - Step 13373440 @ 3069.5 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 4426.8, step = 13373440, mean_episode_return = 15.025, mean_episode_step = 1882.9, total_loss = 114.35, pg_loss = 84.37, baseline_loss = 43.936, entropy_loss = -13.952, learner_queue_size = 64, _tick = 1902, _time = 1.6548e+09)
[2022-06-09 14:54:28,870][root][INFO] - Step 13388800 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 4431.8, step = 13388800, mean_episode_return = 35.461, mean_episode_step = 1842.3, total_loss = -64.016, pg_loss = -69.379, baseline_loss = 19.091, entropy_loss = -13.728, learner_queue_size = 64, _tick = 1905, _time = 1.6548e+09)
[2022-06-09 14:54:33,874][root][INFO] - Step 13404160 @ 3069.5 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 4436.8, step = 13404160, mean_episode_return = 31.272, mean_episode_step = 1946.7, total_loss = -162.12, pg_loss = -154.98, baseline_loss = 6.6136, entropy_loss = -13.751, learner_queue_size = 64, _tick = 1907, _time = 1.6548e+09)
[2022-06-09 14:54:38,878][root][INFO] - Step 13419520 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 4441.8, step = 13419520, mean_episode_return = 74.417, mean_episode_step = 1842.9, total_loss = 33.884, pg_loss = 15.185, baseline_loss = 32.442, entropy_loss = -13.743, learner_queue_size = 64, _tick = 1910, _time = 1.6548e+09)
[2022-06-09 14:54:43,882][root][INFO] - Step 13434880 @ 3069.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 4446.8, step = 13434880, mean_episode_return = 18.285, mean_episode_step = 1804.0, total_loss = -37.997, pg_loss = -39.166, baseline_loss = 15.109, entropy_loss = -13.94, learner_queue_size = 64, _tick = 1913, _time = 1.6548e+09)
[2022-06-09 14:54:48,888][root][INFO] - Step 13450240 @ 3068.3 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 4451.8, step = 13450240, mean_episode_return = 26.936, mean_episode_step = 2090.8, total_loss = 111.52, pg_loss = 89.593, baseline_loss = 36.448, entropy_loss = -14.524, learner_queue_size = 64, _tick = 1915, _time = 1.6548e+09)
[2022-06-09 14:54:53,893][root][INFO] - Step 13465600 @ 3069.2 SPS. Inference batcher size: 14. Learner queue size: 64. Other stats: (train_seconds = 4456.8, step = 13465600, mean_episode_return = 5.1497, mean_episode_step = 2045.0, total_loss = -117.44, pg_loss = -112.96, baseline_loss = 9.9411, entropy_loss = -14.419, learner_queue_size = 64, _tick = 1917, _time = 1.6548e+09)
[2022-06-09 14:54:58,898][root][INFO] - Step 13486080 @ 4091.5 SPS. Inference batcher size: 72. Learner queue size: 64. Other stats: (train_seconds = 4461.8, step = 13486080, mean_episode_return = -15.85, mean_episode_step = 2004.7, total_loss = 523.13, pg_loss = 451.07, baseline_loss = 86.288, entropy_loss = -14.219, learner_queue_size = 64, _tick = 1919, _time = 1.6548e+09)
[2022-06-09 14:55:03,902][root][INFO] - Step 13501440 @ 3069.6 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 4466.8, step = 13501440, mean_episode_return = 71.849, mean_episode_step = 2289.6, total_loss = -83.448, pg_loss = -98.597, baseline_loss = 29.358, entropy_loss = -14.209, learner_queue_size = 64, _tick = 1921, _time = 1.6548e+09)
[2022-06-09 14:55:08,906][root][INFO] - Step 13516800 @ 3069.5 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 4471.8, step = 13516800, mean_episode_return = 51.392, mean_episode_step = 1918.6, total_loss = -108.48, pg_loss = -111.4, baseline_loss = 17.199, entropy_loss = -14.281, learner_queue_size = 64, _tick = 1923, _time = 1.6548e+09)
[2022-06-09 14:55:13,910][root][INFO] - Step 13532160 @ 3069.6 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 4476.8, step = 13532160, mean_episode_return = None, mean_episode_step = 2231.7, total_loss = 106.58, pg_loss = 54.104, baseline_loss = 67.041, entropy_loss = -14.569, learner_queue_size = 64, _tick = 1925, _time = 1.6548e+09)
[2022-06-09 14:55:18,914][root][INFO] - Step 13547520 @ 3069.6 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 4481.8, step = 13547520, mean_episode_return = -21.45, mean_episode_step = 2109.3, total_loss = -166.95, pg_loss = -158.45, baseline_loss = 6.3828, entropy_loss = -14.888, learner_queue_size = 64, _tick = 1927, _time = 1.6548e+09)
[2022-06-09 14:55:23,918][root][INFO] - Step 13562880 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 4486.9, step = 13562880, mean_episode_return = 47.445, mean_episode_step = 2241.5, total_loss = -81.429, pg_loss = -85.247, baseline_loss = 18.992, entropy_loss = -15.173, learner_queue_size = 64, _tick = 1928, _time = 1.6548e+09)
[2022-06-09 14:55:28,924][root][INFO] - Step 13578240 @ 3068.3 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 4491.9, step = 13578240, mean_episode_return = None, mean_episode_step = 2023.5, total_loss = 17.741, pg_loss = 16.929, baseline_loss = 16.092, entropy_loss = -15.28, learner_queue_size = 64, _tick = 1930, _time = 1.6548e+09)
[2022-06-09 14:55:33,930][root][INFO] - Step 13598720 @ 4091.1 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 4496.9, step = 13598720, mean_episode_return = 80.867, mean_episode_step = 1898.4, total_loss = -60.064, pg_loss = -52.978, baseline_loss = 8.1531, entropy_loss = -15.239, learner_queue_size = 64, _tick = 1934, _time = 1.6548e+09)
[2022-06-09 14:55:38,934][root][INFO] - Step 13614080 @ 3069.6 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 4501.9, step = 13614080, mean_episode_return = 129.35, mean_episode_step = 2109.8, total_loss = 143.31, pg_loss = 123.83, baseline_loss = 34.89, entropy_loss = -15.407, learner_queue_size = 64, _tick = 1936, _time = 1.6548e+09)
[2022-06-09 14:55:43,938][root][INFO] - Step 13629440 @ 3069.5 SPS. Inference batcher size: 77. Learner queue size: 64. Other stats: (train_seconds = 4506.9, step = 13629440, mean_episode_return = 46.915, mean_episode_step = 2009.1, total_loss = 85.806, pg_loss = 69.592, baseline_loss = 31.606, entropy_loss = -15.391, learner_queue_size = 64, _tick = 1938, _time = 1.6548e+09)
[2022-06-09 14:55:48,942][root][INFO] - Step 13644800 @ 3069.4 SPS. Inference batcher size: 76. Learner queue size: 64. Other stats: (train_seconds = 4511.9, step = 13644800, mean_episode_return = 39.085, mean_episode_step = 2024.4, total_loss = -9.8166, pg_loss = -9.9941, baseline_loss = 15.538, entropy_loss = -15.36, learner_queue_size = 64, _tick = 1941, _time = 1.6548e+09)
[2022-06-09 14:55:53,946][root][INFO] - Step 13660160 @ 3069.7 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 4516.9, step = 13660160, mean_episode_return = -4.5302, mean_episode_step = 2262.7, total_loss = 57.15, pg_loss = 49.654, baseline_loss = 22.694, entropy_loss = -15.199, learner_queue_size = 64, _tick = 1944, _time = 1.6548e+09)
[2022-06-09 14:55:58,950][root][INFO] - Step 13675520 @ 3069.6 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 4521.9, step = 13675520, mean_episode_return = 21.953, mean_episode_step = 2024.7, total_loss = -0.38485, pg_loss = -11.331, baseline_loss = 26.222, entropy_loss = -15.275, learner_queue_size = 64, _tick = 1947, _time = 1.6548e+09)
[2022-06-09 14:56:03,954][root][INFO] - Step 13690880 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 4526.9, step = 13690880, mean_episode_return = 94.424, mean_episode_step = 2025.5, total_loss = -190.45, pg_loss = -185.1, baseline_loss = 9.5706, entropy_loss = -14.914, learner_queue_size = 64, _tick = 1950, _time = 1.6548e+09)
[2022-06-09 14:56:08,958][root][INFO] - Step 13706240 @ 3069.6 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 4531.9, step = 13706240, mean_episode_return = 35.22, mean_episode_step = 2062.5, total_loss = -158.4, pg_loss = -153.36, baseline_loss = 9.8893, entropy_loss = -14.922, learner_queue_size = 64, _tick = 1952, _time = 1.6548e+09)
[2022-06-09 14:56:13,962][root][INFO] - Step 13721600 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 4536.9, step = 13721600, mean_episode_return = -48.466, mean_episode_step = 1932.7, total_loss = -63.179, pg_loss = -60.956, baseline_loss = 12.763, entropy_loss = -14.987, learner_queue_size = 64, _tick = 1955, _time = 1.6548e+09)
[2022-06-09 14:56:18,968][root][INFO] - Step 13742080 @ 4091.4 SPS. Inference batcher size: 82. Learner queue size: 64. Other stats: (train_seconds = 4541.9, step = 13742080, mean_episode_return = None, mean_episode_step = 1786.2, total_loss = 533.08, pg_loss = 476.02, baseline_loss = 72.089, entropy_loss = -15.032, learner_queue_size = 64, _tick = 1958, _time = 1.6548e+09)
[2022-06-09 14:56:23,974][root][INFO] - Step 13757440 @ 3068.3 SPS. Inference batcher size: 78. Learner queue size: 64. Other stats: (train_seconds = 4546.9, step = 13757440, mean_episode_return = None, mean_episode_step = 1826.7, total_loss = 56.453, pg_loss = 51.179, baseline_loss = 20.487, entropy_loss = -15.213, learner_queue_size = 64, _tick = 1960, _time = 1.6548e+09)
[2022-06-09 14:56:28,980][root][INFO] - Step 13772800 @ 3068.3 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 4551.9, step = 13772800, mean_episode_return = -21.05, mean_episode_step = 1809.9, total_loss = 96.377, pg_loss = 89.609, baseline_loss = 22.453, entropy_loss = -15.685, learner_queue_size = 64, _tick = 1961, _time = 1.6548e+09)
[2022-06-09 14:56:33,986][root][INFO] - Step 13788160 @ 3068.1 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 4556.9, step = 13788160, mean_episode_return = 35.456, mean_episode_step = 2249.9, total_loss = -11.904, pg_loss = -24.474, baseline_loss = 27.806, entropy_loss = -15.236, learner_queue_size = 64, _tick = 1964, _time = 1.6548e+09)
[2022-06-09 14:56:38,990][root][INFO] - Step 13803520 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 4561.9, step = 13803520, mean_episode_return = 17.15, mean_episode_step = 2057.1, total_loss = -144.02, pg_loss = -138.95, baseline_loss = 10.218, entropy_loss = -15.289, learner_queue_size = 64, _tick = 1967, _time = 1.6548e+09)
[2022-06-09 14:56:43,994][root][INFO] - Step 13818880 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 4566.9, step = 13818880, mean_episode_return = 36.275, mean_episode_step = 2151.8, total_loss = -47.016, pg_loss = -60.182, baseline_loss = 28.518, entropy_loss = -15.351, learner_queue_size = 64, _tick = 1970, _time = 1.6548e+09)
[2022-06-09 14:56:48,998][root][INFO] - Step 13834240 @ 3069.5 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 4571.9, step = 13834240, mean_episode_return = 79.707, mean_episode_step = 1804.7, total_loss = -55.836, pg_loss = -61.571, baseline_loss = 20.616, entropy_loss = -14.881, learner_queue_size = 64, _tick = 1972, _time = 1.6548e+09)
[2022-06-09 14:56:54,002][root][INFO] - Step 13849600 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 4576.9, step = 13849600, mean_episode_return = 81.556, mean_episode_step = 1908.1, total_loss = -199.5, pg_loss = -189.88, baseline_loss = 5.4161, entropy_loss = -15.031, learner_queue_size = 64, _tick = 1975, _time = 1.6548e+09)
[2022-06-09 14:56:59,006][root][INFO] - Step 13870080 @ 4092.8 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 4581.9, step = 13870080, mean_episode_return = 93.894, mean_episode_step = 2063.7, total_loss = 85.442, pg_loss = 69.101, baseline_loss = 31.384, entropy_loss = -15.043, learner_queue_size = 64, _tick = 1979, _time = 1.6548e+09)
[2022-06-09 14:57:04,010][root][INFO] - Step 13885440 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 4586.9, step = 13885440, mean_episode_return = 78.867, mean_episode_step = 1845.0, total_loss = 64.737, pg_loss = 43.777, baseline_loss = 35.667, entropy_loss = -14.707, learner_queue_size = 64, _tick = 1982, _time = 1.6548e+09)
[2022-06-09 14:57:09,014][root][INFO] - Step 13900800 @ 3069.5 SPS. Inference batcher size: 77. Learner queue size: 64. Other stats: (train_seconds = 4592.0, step = 13900800, mean_episode_return = 40.95, mean_episode_step = 1919.3, total_loss = -28.25, pg_loss = -37.52, baseline_loss = 23.629, entropy_loss = -14.359, learner_queue_size = 64, _tick = 1985, _time = 1.6548e+09)
[2022-06-09 14:57:14,018][root][INFO] - Step 13916160 @ 3069.6 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 4597.0, step = 13916160, mean_episode_return = 23.08, mean_episode_step = 1880.5, total_loss = -159.2, pg_loss = -154.26, baseline_loss = 9.2106, entropy_loss = -14.148, learner_queue_size = 64, _tick = 1987, _time = 1.6548e+09)
[2022-06-09 14:57:19,022][root][INFO] - Step 13931520 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 4602.0, step = 13931520, mean_episode_return = 14.331, mean_episode_step = 1879.0, total_loss = -61.968, pg_loss = -83.505, baseline_loss = 36.27, entropy_loss = -14.733, learner_queue_size = 64, _tick = 1989, _time = 1.6548e+09)
[2022-06-09 14:57:24,026][root][INFO] - Step 13946880 @ 3069.6 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 4607.0, step = 13946880, mean_episode_return = 37.512, mean_episode_step = 2074.8, total_loss = -79.549, pg_loss = -93.065, baseline_loss = 27.997, entropy_loss = -14.48, learner_queue_size = 64, _tick = 1992, _time = 1.6548e+09)
[2022-06-09 14:57:29,030][root][INFO] - Step 13962240 @ 3069.6 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 4612.0, step = 13962240, mean_episode_return = 40.85, mean_episode_step = 1812.2, total_loss = -25.664, pg_loss = -33.292, baseline_loss = 21.76, entropy_loss = -14.132, learner_queue_size = 64, _tick = 1995, _time = 1.6548e+09)
[2022-06-09 14:57:34,034][root][INFO] - Step 13977600 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 4617.0, step = 13977600, mean_episode_return = None, mean_episode_step = 1975.8, total_loss = -127.79, pg_loss = -119.38, baseline_loss = 5.8677, entropy_loss = -14.276, learner_queue_size = 64, _tick = 1996, _time = 1.6548e+09)
[2022-06-09 14:57:39,038][root][INFO] - Step 13992960 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 4622.0, step = 13992960, mean_episode_return = 16.25, mean_episode_step = 1863.1, total_loss = 392.88, pg_loss = 328.63, baseline_loss = 78.246, entropy_loss = -14.002, learner_queue_size = 64, _tick = 1999, _time = 1.6548e+09)
[2022-06-09 14:57:44,042][root][INFO] - Step 14008320 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 4627.0, step = 14008320, mean_episode_return = None, mean_episode_step = 1975.4, total_loss = -5.8758, pg_loss = -4.6313, baseline_loss = 12.784, entropy_loss = -14.029, learner_queue_size = 64, _tick = 2001, _time = 1.6548e+09)
[2022-06-09 14:57:49,046][root][INFO] - Step 14023680 @ 3069.6 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 4632.0, step = 14023680, mean_episode_return = 0.29479, mean_episode_step = 2025.0, total_loss = -53.581, pg_loss = -58.136, baseline_loss = 18.793, entropy_loss = -14.239, learner_queue_size = 64, _tick = 2004, _time = 1.6548e+09)
[2022-06-09 14:57:54,050][root][INFO] - Step 14044160 @ 4092.7 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 4637.0, step = 14044160, mean_episode_return = 10.964, mean_episode_step = 1828.7, total_loss = -41.835, pg_loss = -42.043, baseline_loss = 14.612, entropy_loss = -14.404, learner_queue_size = 64, _tick = 2008, _time = 1.6548e+09)
[2022-06-09 14:57:59,056][root][INFO] - Step 14059520 @ 3068.3 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 4642.0, step = 14059520, mean_episode_return = None, mean_episode_step = 2025.4, total_loss = -19.791, pg_loss = -17.773, baseline_loss = 12.501, entropy_loss = -14.519, learner_queue_size = 64, _tick = 2009, _time = 1.6548e+09)
[2022-06-09 14:58:04,063][root][INFO] - Step 14074880 @ 3068.0 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 4647.0, step = 14074880, mean_episode_return = 16.883, mean_episode_step = 1785.3, total_loss = 34.761, pg_loss = 25.648, baseline_loss = 23.819, entropy_loss = -14.705, learner_queue_size = 64, _tick = 2012, _time = 1.6548e+09)
[2022-06-09 14:58:09,066][root][INFO] - Step 14090240 @ 3069.8 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 4652.0, step = 14090240, mean_episode_return = -0.13027, mean_episode_step = 2112.6, total_loss = 56.164, pg_loss = 52.184, baseline_loss = 18.683, entropy_loss = -14.703, learner_queue_size = 64, _tick = 2015, _time = 1.6548e+09)
[2022-06-09 14:58:14,070][root][INFO] - Step 14105600 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 4657.0, step = 14105600, mean_episode_return = None, mean_episode_step = 2203.8, total_loss = -18.769, pg_loss = -17.639, baseline_loss = 13.642, entropy_loss = -14.773, learner_queue_size = 64, _tick = 2015, _time = 1.6548e+09)
[2022-06-09 14:58:19,074][root][INFO] - Step 14120960 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 4662.0, step = 14120960, mean_episode_return = 144.8, mean_episode_step = 2448.3, total_loss = -72.958, pg_loss = -67.848, baseline_loss = 10.003, entropy_loss = -15.114, learner_queue_size = 64, _tick = 2018, _time = 1.6548e+09)
[2022-06-09 14:58:24,078][root][INFO] - Step 14136320 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 4667.0, step = 14136320, mean_episode_return = 38.388, mean_episode_step = 2134.2, total_loss = 229.2, pg_loss = 190.78, baseline_loss = 53.606, entropy_loss = -15.188, learner_queue_size = 64, _tick = 2020, _time = 1.6548e+09)
[2022-06-09 14:58:29,082][root][INFO] - Step 14151680 @ 3069.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 4672.0, step = 14151680, mean_episode_return = 21.579, mean_episode_step = 2175.8, total_loss = 10.622, pg_loss = 10.037, baseline_loss = 16.03, entropy_loss = -15.445, learner_queue_size = 64, _tick = 2022, _time = 1.6548e+09)
[2022-06-09 14:58:34,086][root][INFO] - Step 14167040 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 4677.0, step = 14167040, mean_episode_return = None, mean_episode_step = 2197.5, total_loss = 26.424, pg_loss = 29.859, baseline_loss = 11.801, entropy_loss = -15.237, learner_queue_size = 64, _tick = 2023, _time = 1.6548e+09)
[2022-06-09 14:58:39,090][root][INFO] - Step 14182400 @ 3069.6 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 4682.0, step = 14182400, mean_episode_return = 34.644, mean_episode_step = 1990.8, total_loss = 15.494, pg_loss = 12.484, baseline_loss = 18.282, entropy_loss = -15.272, learner_queue_size = 64, _tick = 2026, _time = 1.6548e+09)
[2022-06-09 14:58:44,096][root][INFO] - Step 14202880 @ 4091.3 SPS. Inference batcher size: 82. Learner queue size: 64. Other stats: (train_seconds = 4687.0, step = 14202880, mean_episode_return = None, mean_episode_step = 2349.6, total_loss = -63.83, pg_loss = -58.105, baseline_loss = 9.7181, entropy_loss = -15.443, learner_queue_size = 64, _tick = 2029, _time = 1.6548e+09)
[2022-06-09 14:58:49,102][root][INFO] - Step 14218240 @ 3068.2 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 4692.0, step = 14218240, mean_episode_return = 16.685, mean_episode_step = 2157.2, total_loss = -48.088, pg_loss = -46.995, baseline_loss = 14.171, entropy_loss = -15.265, learner_queue_size = 64, _tick = 2032, _time = 1.6548e+09)
[2022-06-09 14:58:54,108][root][INFO] - Step 14233600 @ 3068.3 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 4697.0, step = 14233600, mean_episode_return = 28.23, mean_episode_step = 2284.3, total_loss = -61.902, pg_loss = -58.072, baseline_loss = 11.175, entropy_loss = -15.005, learner_queue_size = 64, _tick = 2035, _time = 1.6548e+09)
[2022-06-09 14:58:59,114][root][INFO] - Step 14248960 @ 3068.3 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 4702.0, step = 14248960, mean_episode_return = 25.11, mean_episode_step = 2218.7, total_loss = 130.85, pg_loss = 126.48, baseline_loss = 19.299, entropy_loss = -14.923, learner_queue_size = 64, _tick = 2037, _time = 1.6548e+09)
[2022-06-09 14:59:04,118][root][INFO] - Step 14264320 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 4707.1, step = 14264320, mean_episode_return = 22.05, mean_episode_step = 1969.3, total_loss = 129.63, pg_loss = 110.9, baseline_loss = 33.878, entropy_loss = -15.151, learner_queue_size = 64, _tick = 2040, _time = 1.6548e+09)
[2022-06-09 14:59:09,125][root][INFO] - Step 14279680 @ 3067.8 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 4712.1, step = 14279680, mean_episode_return = None, mean_episode_step = 2057.1, total_loss = 13.516, pg_loss = 8.3364, baseline_loss = 20.33, entropy_loss = -15.151, learner_queue_size = 64, _tick = 2040, _time = 1.6548e+09)
[2022-06-09 14:59:14,132][root][INFO] - Step 14295040 @ 3067.8 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 4717.1, step = 14295040, mean_episode_return = 68.18, mean_episode_step = 2387.9, total_loss = 126.36, pg_loss = 113.59, baseline_loss = 27.605, entropy_loss = -14.834, learner_queue_size = 64, _tick = 2043, _time = 1.6548e+09)
[2022-06-09 14:59:19,134][root][INFO] - Step 14310400 @ 3070.6 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 4722.1, step = 14310400, mean_episode_return = 31.543, mean_episode_step = 2302.8, total_loss = 155.24, pg_loss = 132.75, baseline_loss = 37.07, entropy_loss = -14.587, learner_queue_size = 64, _tick = 2046, _time = 1.6548e+09)
[2022-06-09 14:59:24,138][root][INFO] - Step 14325760 @ 3069.6 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 4727.1, step = 14325760, mean_episode_return = 60.687, mean_episode_step = 2279.7, total_loss = 119.15, pg_loss = 107.4, baseline_loss = 25.988, entropy_loss = -14.237, learner_queue_size = 64, _tick = 2048, _time = 1.6548e+09)
[2022-06-09 14:59:29,142][root][INFO] - Step 14341120 @ 3069.6 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 4732.1, step = 14341120, mean_episode_return = 35.421, mean_episode_step = 2221.0, total_loss = 29.598, pg_loss = 24.329, baseline_loss = 19.785, entropy_loss = -14.517, learner_queue_size = 64, _tick = 2051, _time = 1.6548e+09)
[2022-06-09 14:59:34,146][root][INFO] - Step 14356480 @ 3069.4 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 4737.1, step = 14356480, mean_episode_return = 52.632, mean_episode_step = 2583.8, total_loss = -11.65, pg_loss = -11.813, baseline_loss = 15.068, entropy_loss = -14.905, learner_queue_size = 64, _tick = 2052, _time = 1.6548e+09)
[2022-06-09 14:59:39,150][root][INFO] - Step 14376960 @ 4092.8 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 4742.1, step = 14376960, mean_episode_return = 82.679, mean_episode_step = 2263.9, total_loss = 117.94, pg_loss = 97.21, baseline_loss = 35.379, entropy_loss = -14.648, learner_queue_size = 64, _tick = 2056, _time = 1.6548e+09)
[2022-06-09 14:59:44,154][root][INFO] - Step 14392320 @ 3069.4 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 4747.1, step = 14392320, mean_episode_return = 40.343, mean_episode_step = 2169.7, total_loss = -7.6654, pg_loss = -16.08, baseline_loss = 22.769, entropy_loss = -14.355, learner_queue_size = 64, _tick = 2059, _time = 1.6548e+09)
[2022-06-09 14:59:49,158][root][INFO] - Step 14407680 @ 3069.7 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 4752.1, step = 14407680, mean_episode_return = 23.235, mean_episode_step = 2461.1, total_loss = 14.494, pg_loss = -29.521, baseline_loss = 58.233, entropy_loss = -14.219, learner_queue_size = 64, _tick = 2062, _time = 1.6548e+09)
[2022-06-09 14:59:54,162][root][INFO] - Step 14423040 @ 3069.4 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 4757.1, step = 14423040, mean_episode_return = 104.46, mean_episode_step = 2281.9, total_loss = -53.657, pg_loss = -51.425, baseline_loss = 11.792, entropy_loss = -14.025, learner_queue_size = 64, _tick = 2065, _time = 1.6548e+09)
[2022-06-09 14:59:59,166][root][INFO] - Step 14438400 @ 3069.7 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 4762.1, step = 14438400, mean_episode_return = 27.307, mean_episode_step = 1925.8, total_loss = 125.3, pg_loss = 100.64, baseline_loss = 38.33, entropy_loss = -13.671, learner_queue_size = 64, _tick = 2068, _time = 1.6548e+09)
[2022-06-09 15:00:04,171][root][INFO] - Step 14453760 @ 3069.1 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 4767.1, step = 14453760, mean_episode_return = None, mean_episode_step = 2163.7, total_loss = 261.74, pg_loss = 220.72, baseline_loss = 54.698, entropy_loss = -13.68, learner_queue_size = 64, _tick = 2070, _time = 1.6548e+09)
[2022-06-09 15:00:09,174][root][INFO] - Step 14469120 @ 3069.9 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 4772.1, step = 14469120, mean_episode_return = -16.609, mean_episode_step = 2502.9, total_loss = -164.93, pg_loss = -179.79, baseline_loss = 28.516, entropy_loss = -13.654, learner_queue_size = 64, _tick = 2072, _time = 1.6548e+09)
[2022-06-09 15:00:14,178][root][INFO] - Step 14484480 @ 3069.6 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 4777.1, step = 14484480, mean_episode_return = 72.749, mean_episode_step = 2301.1, total_loss = -154.32, pg_loss = -176.17, baseline_loss = 35.66, entropy_loss = -13.814, learner_queue_size = 64, _tick = 2074, _time = 1.6548e+09)
[2022-06-09 15:00:19,182][root][INFO] - Step 14499840 @ 3069.5 SPS. Inference batcher size: 14. Learner queue size: 64. Other stats: (train_seconds = 4782.1, step = 14499840, mean_episode_return = 12.809, mean_episode_step = 1963.6, total_loss = 41.209, pg_loss = 11.817, baseline_loss = 43.159, entropy_loss = -13.768, learner_queue_size = 64, _tick = 2076, _time = 1.6548e+09)
[2022-06-09 15:00:24,186][root][INFO] - Step 14515200 @ 3069.5 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 4787.1, step = 14515200, mean_episode_return = None, mean_episode_step = 1835.6, total_loss = 95.885, pg_loss = 84.316, baseline_loss = 24.97, entropy_loss = -13.401, learner_queue_size = 64, _tick = 2078, _time = 1.6548e+09)
[2022-06-09 15:00:29,190][root][INFO] - Step 14530560 @ 3069.6 SPS. Inference batcher size: 15. Learner queue size: 64. Other stats: (train_seconds = 4792.1, step = 14530560, mean_episode_return = None, mean_episode_step = 2324.9, total_loss = -16.141, pg_loss = -20.509, baseline_loss = 17.48, entropy_loss = -13.111, learner_queue_size = 64, _tick = 2080, _time = 1.6548e+09)
[2022-06-09 15:00:34,194][root][INFO] - Step 14551040 @ 4092.7 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 4797.1, step = 14551040, mean_episode_return = 29.731, mean_episode_step = 1893.5, total_loss = -50.674, pg_loss = -57.131, baseline_loss = 19.424, entropy_loss = -12.966, learner_queue_size = 64, _tick = 2084, _time = 1.6548e+09)
[2022-06-09 15:00:39,198][root][INFO] - Step 14566400 @ 3069.6 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 4802.1, step = 14566400, mean_episode_return = None, mean_episode_step = 1751.6, total_loss = 247.79, pg_loss = 221.62, baseline_loss = 39.098, entropy_loss = -12.928, learner_queue_size = 64, _tick = 2085, _time = 1.6548e+09)
[2022-06-09 15:00:44,202][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 15:00:44,462][root][INFO] - Step 14581760 @ 3069.5 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 4807.1, step = 14581760, mean_episode_return = None, mean_episode_step = 2073.1, total_loss = 53.711, pg_loss = 41.683, baseline_loss = 25.337, entropy_loss = -13.309, learner_queue_size = 64, _tick = 2087, _time = 1.6548e+09)
[2022-06-09 15:00:49,466][root][INFO] - Step 14597120 @ 2917.9 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 4812.4, step = 14597120, mean_episode_return = -4.6197, mean_episode_step = 1833.8, total_loss = -10.129, pg_loss = -19.691, baseline_loss = 22.526, entropy_loss = -12.964, learner_queue_size = 64, _tick = 2090, _time = 1.6548e+09)
[2022-06-09 15:00:54,470][root][INFO] - Step 14612480 @ 3069.5 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 4817.4, step = 14612480, mean_episode_return = None, mean_episode_step = 1862.0, total_loss = 82.208, pg_loss = 65.961, baseline_loss = 29.349, entropy_loss = -13.102, learner_queue_size = 64, _tick = 2091, _time = 1.6548e+09)
[2022-06-09 15:00:59,474][root][INFO] - Step 14627840 @ 3069.6 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 4822.4, step = 14627840, mean_episode_return = 70.342, mean_episode_step = 1809.5, total_loss = -30.758, pg_loss = -39.642, baseline_loss = 22.093, entropy_loss = -13.209, learner_queue_size = 64, _tick = 2094, _time = 1.6548e+09)
[2022-06-09 15:01:04,478][root][INFO] - Step 14643200 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 4827.4, step = 14643200, mean_episode_return = 39.342, mean_episode_step = 1863.6, total_loss = -163.65, pg_loss = -154.16, baseline_loss = 3.3327, entropy_loss = -12.818, learner_queue_size = 64, _tick = 2097, _time = 1.6548e+09)
[2022-06-09 15:01:09,482][root][INFO] - Step 14658560 @ 3069.6 SPS. Inference batcher size: 11. Learner queue size: 64. Other stats: (train_seconds = 4832.4, step = 14658560, mean_episode_return = 111.5, mean_episode_step = 2009.8, total_loss = -22.721, pg_loss = -40.196, baseline_loss = 30.387, entropy_loss = -12.912, learner_queue_size = 64, _tick = 2100, _time = 1.6548e+09)
[2022-06-09 15:01:14,486][root][INFO] - Step 14673920 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 4837.4, step = 14673920, mean_episode_return = None, mean_episode_step = 1868.2, total_loss = 62.147, pg_loss = 52.609, baseline_loss = 22.109, entropy_loss = -12.572, learner_queue_size = 64, _tick = 2100, _time = 1.6548e+09)
[2022-06-09 15:01:19,490][root][INFO] - Step 14694400 @ 4092.7 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 4842.4, step = 14694400, mean_episode_return = 51.464, mean_episode_step = 2109.9, total_loss = -130.1, pg_loss = -123.68, baseline_loss = 6.3958, entropy_loss = -12.819, learner_queue_size = 64, _tick = 2104, _time = 1.6548e+09)
[2022-06-09 15:01:24,494][root][INFO] - Step 14709760 @ 3069.6 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 4847.4, step = 14709760, mean_episode_return = None, mean_episode_step = 2021.7, total_loss = -176.06, pg_loss = -164.1, baseline_loss = 1.0835, entropy_loss = -13.042, learner_queue_size = 64, _tick = 2105, _time = 1.6548e+09)
[2022-06-09 15:01:29,498][root][INFO] - Step 14725120 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 4852.4, step = 14725120, mean_episode_return = None, mean_episode_step = 2065.0, total_loss = 210.14, pg_loss = 173.12, baseline_loss = 50.29, entropy_loss = -13.271, learner_queue_size = 64, _tick = 2106, _time = 1.6548e+09)
[2022-06-09 15:01:34,502][root][INFO] - Step 14740480 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 4857.4, step = 14740480, mean_episode_return = 46.228, mean_episode_step = 2431.5, total_loss = -112.0, pg_loss = -103.29, baseline_loss = 5.1651, entropy_loss = -13.878, learner_queue_size = 64, _tick = 2108, _time = 1.6548e+09)
[2022-06-09 15:01:39,506][root][INFO] - Step 14755840 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 4862.4, step = 14755840, mean_episode_return = 99.917, mean_episode_step = 1915.8, total_loss = 41.66, pg_loss = 42.175, baseline_loss = 12.966, entropy_loss = -13.48, learner_queue_size = 64, _tick = 2111, _time = 1.6548e+09)
[2022-06-09 15:01:44,510][root][INFO] - Step 14771200 @ 3069.6 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 4867.4, step = 14771200, mean_episode_return = 59.245, mean_episode_step = 2405.1, total_loss = 333.35, pg_loss = 272.37, baseline_loss = 74.887, entropy_loss = -13.915, learner_queue_size = 64, _tick = 2113, _time = 1.6548e+09)
[2022-06-09 15:01:49,514][root][INFO] - Step 14786560 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 4872.4, step = 14786560, mean_episode_return = 38.66, mean_episode_step = 1844.5, total_loss = -193.19, pg_loss = -187.48, baseline_loss = 8.3308, entropy_loss = -14.04, learner_queue_size = 64, _tick = 2116, _time = 1.6548e+09)
[2022-06-09 15:01:54,518][root][INFO] - Step 14807040 @ 4092.7 SPS. Inference batcher size: 88. Learner queue size: 64. Other stats: (train_seconds = 4877.5, step = 14807040, mean_episode_return = None, mean_episode_step = 1949.8, total_loss = -82.336, pg_loss = -80.666, baseline_loss = 12.793, entropy_loss = -14.463, learner_queue_size = 64, _tick = 2119, _time = 1.6548e+09)
[2022-06-09 15:01:59,522][root][INFO] - Step 14822400 @ 3069.6 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 4882.5, step = 14822400, mean_episode_return = -2.4955, mean_episode_step = 2495.2, total_loss = -89.865, pg_loss = -94.055, baseline_loss = 18.508, entropy_loss = -14.319, learner_queue_size = 64, _tick = 2122, _time = 1.6548e+09)
[2022-06-09 15:02:04,526][root][INFO] - Step 14837760 @ 3069.6 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 4887.5, step = 14837760, mean_episode_return = 54.671, mean_episode_step = 2114.4, total_loss = 503.26, pg_loss = 292.09, baseline_loss = 225.58, entropy_loss = -14.414, learner_queue_size = 64, _tick = 2124, _time = 1.6548e+09)
[2022-06-09 15:02:09,530][root][INFO] - Step 14853120 @ 3069.5 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 4892.5, step = 14853120, mean_episode_return = None, mean_episode_step = 2102.3, total_loss = 243.6, pg_loss = 205.63, baseline_loss = 52.345, entropy_loss = -14.374, learner_queue_size = 64, _tick = 2126, _time = 1.6548e+09)
[2022-06-09 15:02:14,534][root][INFO] - Step 14868480 @ 3069.5 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 4897.5, step = 14868480, mean_episode_return = 5.2894, mean_episode_step = 2097.6, total_loss = -37.565, pg_loss = -34.886, baseline_loss = 11.591, entropy_loss = -14.27, learner_queue_size = 64, _tick = 2128, _time = 1.6548e+09)
[2022-06-09 15:02:19,538][root][INFO] - Step 14883840 @ 3069.5 SPS. Inference batcher size: 18. Learner queue size: 64. Other stats: (train_seconds = 4902.5, step = 14883840, mean_episode_return = 15.165, mean_episode_step = 1976.3, total_loss = 34.905, pg_loss = 23.722, baseline_loss = 25.837, entropy_loss = -14.654, learner_queue_size = 64, _tick = 2131, _time = 1.6548e+09)
[2022-06-09 15:02:24,542][root][INFO] - Step 14899200 @ 3069.6 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 4907.5, step = 14899200, mean_episode_return = 90.33, mean_episode_step = 1833.5, total_loss = 18.348, pg_loss = 3.0016, baseline_loss = 30.172, entropy_loss = -14.826, learner_queue_size = 64, _tick = 2133, _time = 1.6548e+09)
[2022-06-09 15:02:29,546][root][INFO] - Step 14914560 @ 3069.5 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 4912.5, step = 14914560, mean_episode_return = 64.961, mean_episode_step = 1669.5, total_loss = -156.22, pg_loss = -153.47, baseline_loss = 11.818, entropy_loss = -14.573, learner_queue_size = 64, _tick = 2136, _time = 1.6548e+09)
[2022-06-09 15:02:34,550][root][INFO] - Step 14935040 @ 4092.7 SPS. Inference batcher size: 93. Learner queue size: 64. Other stats: (train_seconds = 4917.5, step = 14935040, mean_episode_return = 70.443, mean_episode_step = 2200.1, total_loss = 355.88, pg_loss = 299.84, baseline_loss = 70.849, entropy_loss = -14.806, learner_queue_size = 64, _tick = 2139, _time = 1.6548e+09)
[2022-06-09 15:02:39,554][root][INFO] - Step 14950400 @ 3069.6 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 4922.5, step = 14950400, mean_episode_return = 65.927, mean_episode_step = 2060.3, total_loss = -166.14, pg_loss = -159.49, baseline_loss = 7.9536, entropy_loss = -14.606, learner_queue_size = 64, _tick = 2142, _time = 1.6548e+09)
[2022-06-09 15:02:44,558][root][INFO] - Step 14965760 @ 3069.6 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 4927.5, step = 14965760, mean_episode_return = 35.531, mean_episode_step = 1955.0, total_loss = -109.62, pg_loss = -108.67, baseline_loss = 13.747, entropy_loss = -14.688, learner_queue_size = 64, _tick = 2144, _time = 1.6548e+09)
[2022-06-09 15:02:49,562][root][INFO] - Step 14981120 @ 3069.5 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 4932.5, step = 14981120, mean_episode_return = 48.262, mean_episode_step = 2029.7, total_loss = -118.09, pg_loss = -126.24, baseline_loss = 23.07, entropy_loss = -14.919, learner_queue_size = 64, _tick = 2147, _time = 1.6548e+09)
[2022-06-09 15:02:54,568][root][INFO] - Step 14996480 @ 3068.3 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 4937.5, step = 14996480, mean_episode_return = 77.374, mean_episode_step = 2145.3, total_loss = 257.3, pg_loss = 206.96, baseline_loss = 65.392, entropy_loss = -15.053, learner_queue_size = 64, _tick = 2150, _time = 1.6548e+09)
[2022-06-09 15:02:59,574][root][INFO] - Step 15011840 @ 3068.4 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 4942.5, step = 15011840, mean_episode_return = 13.386, mean_episode_step = 1965.4, total_loss = 17.969, pg_loss = 10.892, baseline_loss = 21.932, entropy_loss = -14.855, learner_queue_size = 64, _tick = 2153, _time = 1.6548e+09)
[2022-06-09 15:03:04,578][root][INFO] - Step 15027200 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 4947.5, step = 15027200, mean_episode_return = -16.239, mean_episode_step = 1703.0, total_loss = 102.68, pg_loss = 78.553, baseline_loss = 39.283, entropy_loss = -15.157, learner_queue_size = 64, _tick = 2156, _time = 1.6548e+09)
[2022-06-09 15:03:09,584][root][INFO] - Step 15042560 @ 3068.3 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 4952.5, step = 15042560, mean_episode_return = 16.84, mean_episode_step = 2035.6, total_loss = -41.585, pg_loss = -54.712, baseline_loss = 28.25, entropy_loss = -15.124, learner_queue_size = 64, _tick = 2159, _time = 1.6548e+09)
[2022-06-09 15:03:14,590][root][INFO] - Step 15057920 @ 3068.3 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 4957.5, step = 15057920, mean_episode_return = 7.2798, mean_episode_step = 2088.6, total_loss = 147.12, pg_loss = 134.31, baseline_loss = 28.087, entropy_loss = -15.275, learner_queue_size = 64, _tick = 2161, _time = 1.6548e+09)
[2022-06-09 15:03:19,596][root][INFO] - Step 15078400 @ 4091.1 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 4962.5, step = 15078400, mean_episode_return = 12.488, mean_episode_step = 1711.2, total_loss = 289.85, pg_loss = 248.59, baseline_loss = 56.368, entropy_loss = -15.11, learner_queue_size = 64, _tick = 2165, _time = 1.6548e+09)
[2022-06-09 15:03:24,598][root][INFO] - Step 15093760 @ 3070.7 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 4967.5, step = 15093760, mean_episode_return = 53.723, mean_episode_step = 1661.1, total_loss = -18.555, pg_loss = -56.623, baseline_loss = 53.014, entropy_loss = -14.946, learner_queue_size = 64, _tick = 2168, _time = 1.6548e+09)
[2022-06-09 15:03:29,604][root][INFO] - Step 15109120 @ 3068.3 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 4972.5, step = 15109120, mean_episode_return = 35.864, mean_episode_step = 1797.4, total_loss = -167.56, pg_loss = -182.8, baseline_loss = 30.408, entropy_loss = -15.171, learner_queue_size = 64, _tick = 2171, _time = 1.6548e+09)
[2022-06-09 15:03:34,610][root][INFO] - Step 15124480 @ 3068.4 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 4977.5, step = 15124480, mean_episode_return = 26.29, mean_episode_step = 1861.3, total_loss = 50.904, pg_loss = 42.749, baseline_loss = 23.179, entropy_loss = -15.024, learner_queue_size = 64, _tick = 2174, _time = 1.6548e+09)
[2022-06-09 15:03:39,636][root][INFO] - Step 15139840 @ 3056.4 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 4982.6, step = 15139840, mean_episode_return = 28.42, mean_episode_step = 1650.2, total_loss = 270.97, pg_loss = 243.23, baseline_loss = 42.803, entropy_loss = -15.066, learner_queue_size = 64, _tick = 2177, _time = 1.6548e+09)
[2022-06-09 15:03:44,638][root][INFO] - Step 15155200 @ 3070.5 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 4987.6, step = 15155200, mean_episode_return = -10.66, mean_episode_step = 1748.0, total_loss = -140.53, pg_loss = -148.64, baseline_loss = 22.963, entropy_loss = -14.857, learner_queue_size = 64, _tick = 2180, _time = 1.6548e+09)
[2022-06-09 15:03:49,642][root][INFO] - Step 15170560 @ 3069.6 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 4992.6, step = 15170560, mean_episode_return = 33.024, mean_episode_step = 1730.9, total_loss = -277.08, pg_loss = -275.32, baseline_loss = 12.8, entropy_loss = -14.558, learner_queue_size = 64, _tick = 2183, _time = 1.6548e+09)
[2022-06-09 15:03:54,646][root][INFO] - Step 15185920 @ 3069.5 SPS. Inference batcher size: 12. Learner queue size: 64. Other stats: (train_seconds = 4997.6, step = 15185920, mean_episode_return = 16.32, mean_episode_step = 1951.0, total_loss = -97.09, pg_loss = -98.357, baseline_loss = 15.793, entropy_loss = -14.526, learner_queue_size = 64, _tick = 2186, _time = 1.6548e+09)
[2022-06-09 15:03:59,650][root][INFO] - Step 15201280 @ 3069.6 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 5002.6, step = 15201280, mean_episode_return = 51.201, mean_episode_step = 1758.8, total_loss = 348.06, pg_loss = 314.31, baseline_loss = 48.448, entropy_loss = -14.7, learner_queue_size = 64, _tick = 2189, _time = 1.6548e+09)
[2022-06-09 15:04:04,654][root][INFO] - Step 15221760 @ 4092.4 SPS. Inference batcher size: 84. Learner queue size: 64. Other stats: (train_seconds = 5007.6, step = 15221760, mean_episode_return = None, mean_episode_step = 1997.9, total_loss = 149.44, pg_loss = 128.83, baseline_loss = 35.092, entropy_loss = -14.479, learner_queue_size = 64, _tick = 2192, _time = 1.6548e+09)
[2022-06-09 15:04:09,658][root][INFO] - Step 15237120 @ 3069.8 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 5012.6, step = 15237120, mean_episode_return = 49.792, mean_episode_step = 1757.0, total_loss = 75.163, pg_loss = 28.646, baseline_loss = 60.907, entropy_loss = -14.39, learner_queue_size = 64, _tick = 2195, _time = 1.6548e+09)
[2022-06-09 15:04:14,662][root][INFO] - Step 15252480 @ 3069.6 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 5017.6, step = 15252480, mean_episode_return = 55.243, mean_episode_step = 1701.2, total_loss = 76.316, pg_loss = 62.84, baseline_loss = 28.25, entropy_loss = -14.774, learner_queue_size = 64, _tick = 2197, _time = 1.6548e+09)
[2022-06-09 15:04:19,666][root][INFO] - Step 15267840 @ 3069.5 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 5022.6, step = 15267840, mean_episode_return = 46.85, mean_episode_step = 1748.8, total_loss = -99.769, pg_loss = -103.36, baseline_loss = 18.386, entropy_loss = -14.796, learner_queue_size = 64, _tick = 2200, _time = 1.6548e+09)
[2022-06-09 15:04:24,670][root][INFO] - Step 15283200 @ 3069.6 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 5027.6, step = 15283200, mean_episode_return = 41.958, mean_episode_step = 1569.9, total_loss = -176.46, pg_loss = -176.51, baseline_loss = 14.903, entropy_loss = -14.851, learner_queue_size = 64, _tick = 2203, _time = 1.6548e+09)
[2022-06-09 15:04:29,674][root][INFO] - Step 15298560 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 5032.6, step = 15298560, mean_episode_return = 23.85, mean_episode_step = 1736.2, total_loss = 33.58, pg_loss = 19.29, baseline_loss = 28.889, entropy_loss = -14.599, learner_queue_size = 64, _tick = 2206, _time = 1.6548e+09)
[2022-06-09 15:04:34,678][root][INFO] - Step 15313920 @ 3069.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 5037.6, step = 15313920, mean_episode_return = 65.661, mean_episode_step = 1394.2, total_loss = 55.401, pg_loss = 32.344, baseline_loss = 37.305, entropy_loss = -14.249, learner_queue_size = 64, _tick = 2209, _time = 1.6548e+09)
[2022-06-09 15:04:39,682][root][INFO] - Step 15329280 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 5042.6, step = 15329280, mean_episode_return = None, mean_episode_step = 1733.4, total_loss = 113.84, pg_loss = 96.223, baseline_loss = 31.746, entropy_loss = -14.133, learner_queue_size = 64, _tick = 2210, _time = 1.6548e+09)
[2022-06-09 15:04:44,686][root][INFO] - Step 15344640 @ 3069.5 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 5047.6, step = 15344640, mean_episode_return = 21.92, mean_episode_step = 1833.8, total_loss = 133.73, pg_loss = 107.12, baseline_loss = 41.062, entropy_loss = -14.45, learner_queue_size = 64, _tick = 2213, _time = 1.6548e+09)
[2022-06-09 15:04:49,690][root][INFO] - Step 15365120 @ 4092.8 SPS. Inference batcher size: 2. Learner queue size: 64. Other stats: (train_seconds = 5052.6, step = 15365120, mean_episode_return = 62.382, mean_episode_step = 1967.1, total_loss = -249.22, pg_loss = -252.93, baseline_loss = 18.434, entropy_loss = -14.722, learner_queue_size = 64, _tick = 2217, _time = 1.6548e+09)
[2022-06-09 15:04:54,694][root][INFO] - Step 15380480 @ 3069.5 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 5057.6, step = 15380480, mean_episode_return = 47.17, mean_episode_step = 1446.3, total_loss = -117.6, pg_loss = -121.82, baseline_loss = 18.914, entropy_loss = -14.689, learner_queue_size = 64, _tick = 2220, _time = 1.6548e+09)
[2022-06-09 15:04:59,699][root][INFO] - Step 15395840 @ 3069.6 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 5062.6, step = 15395840, mean_episode_return = 50.45, mean_episode_step = 1622.2, total_loss = -75.541, pg_loss = -77.716, baseline_loss = 17.229, entropy_loss = -15.055, learner_queue_size = 64, _tick = 2222, _time = 1.6548e+09)
[2022-06-09 15:05:04,702][root][INFO] - Step 15411200 @ 3069.6 SPS. Inference batcher size: 76. Learner queue size: 64. Other stats: (train_seconds = 5067.6, step = 15411200, mean_episode_return = 45.351, mean_episode_step = 1663.7, total_loss = 240.58, pg_loss = 205.32, baseline_loss = 50.26, entropy_loss = -15.003, learner_queue_size = 64, _tick = 2225, _time = 1.6548e+09)
[2022-06-09 15:05:09,706][root][INFO] - Step 15426560 @ 3069.5 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 5072.6, step = 15426560, mean_episode_return = 62.227, mean_episode_step = 1495.5, total_loss = -92.406, pg_loss = -103.4, baseline_loss = 26.056, entropy_loss = -15.058, learner_queue_size = 64, _tick = 2228, _time = 1.6548e+09)
[2022-06-09 15:05:14,710][root][INFO] - Step 15441920 @ 3069.6 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 5077.6, step = 15441920, mean_episode_return = None, mean_episode_step = 1737.5, total_loss = 154.08, pg_loss = 136.52, baseline_loss = 32.48, entropy_loss = -14.914, learner_queue_size = 64, _tick = 2229, _time = 1.6548e+09)
[2022-06-09 15:05:19,714][root][INFO] - Step 15457280 @ 3069.4 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 5082.7, step = 15457280, mean_episode_return = 17.825, mean_episode_step = 1806.9, total_loss = -142.16, pg_loss = -147.6, baseline_loss = 20.491, entropy_loss = -15.053, learner_queue_size = 64, _tick = 2232, _time = 1.6548e+09)
[2022-06-09 15:05:24,718][root][INFO] - Step 15472640 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 5087.7, step = 15472640, mean_episode_return = -8.7105, mean_episode_step = 1620.3, total_loss = 173.78, pg_loss = 154.79, baseline_loss = 34.088, entropy_loss = -15.104, learner_queue_size = 64, _tick = 2235, _time = 1.6548e+09)
[2022-06-09 15:05:29,722][root][INFO] - Step 15488000 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 5092.7, step = 15488000, mean_episode_return = None, mean_episode_step = 1991.8, total_loss = -19.458, pg_loss = -14.893, baseline_loss = 10.193, entropy_loss = -14.758, learner_queue_size = 64, _tick = 2237, _time = 1.6548e+09)
[2022-06-09 15:05:34,726][root][INFO] - Step 15508480 @ 4092.8 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 5097.7, step = 15508480, mean_episode_return = 28.706, mean_episode_step = 1815.4, total_loss = -54.684, pg_loss = -59.541, baseline_loss = 19.843, entropy_loss = -14.986, learner_queue_size = 64, _tick = 2241, _time = 1.6548e+09)
[2022-06-09 15:05:39,730][root][INFO] - Step 15523840 @ 3069.5 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 5102.7, step = 15523840, mean_episode_return = 10.422, mean_episode_step = 1572.9, total_loss = 22.152, pg_loss = 5.5205, baseline_loss = 31.733, entropy_loss = -15.101, learner_queue_size = 64, _tick = 2242, _time = 1.6548e+09)
[2022-06-09 15:05:44,736][root][INFO] - Step 15539200 @ 3068.3 SPS. Inference batcher size: 15. Learner queue size: 64. Other stats: (train_seconds = 5107.7, step = 15539200, mean_episode_return = None, mean_episode_step = 2047.2, total_loss = -129.67, pg_loss = -121.21, baseline_loss = 7.0041, entropy_loss = -15.462, learner_queue_size = 64, _tick = 2244, _time = 1.6548e+09)
[2022-06-09 15:05:49,742][root][INFO] - Step 15554560 @ 3068.3 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 5112.7, step = 15554560, mean_episode_return = None, mean_episode_step = 1950.7, total_loss = 156.97, pg_loss = 131.92, baseline_loss = 40.414, entropy_loss = -15.367, learner_queue_size = 64, _tick = 2246, _time = 1.6548e+09)
[2022-06-09 15:05:54,746][root][INFO] - Step 15569920 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 5117.7, step = 15569920, mean_episode_return = 11.09, mean_episode_step = 1972.5, total_loss = -9.7318, pg_loss = -34.17, baseline_loss = 39.896, entropy_loss = -15.457, learner_queue_size = 64, _tick = 2249, _time = 1.6548e+09)
[2022-06-09 15:05:59,750][root][INFO] - Step 15585280 @ 3069.5 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 5122.7, step = 15585280, mean_episode_return = None, mean_episode_step = 1845.8, total_loss = 256.02, pg_loss = 235.53, baseline_loss = 35.493, entropy_loss = -15.012, learner_queue_size = 64, _tick = 2251, _time = 1.6548e+09)
[2022-06-09 15:06:04,754][root][INFO] - Step 15600640 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 5127.7, step = 15600640, mean_episode_return = 125.66, mean_episode_step = 1719.5, total_loss = 161.54, pg_loss = 132.86, baseline_loss = 43.677, entropy_loss = -14.996, learner_queue_size = 64, _tick = 2254, _time = 1.6548e+09)
[2022-06-09 15:06:09,759][root][INFO] - Step 15616000 @ 3069.2 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 5132.7, step = 15616000, mean_episode_return = None, mean_episode_step = 1907.9, total_loss = -34.002, pg_loss = -35.871, baseline_loss = 16.705, entropy_loss = -14.836, learner_queue_size = 64, _tick = 2255, _time = 1.6548e+09)
[2022-06-09 15:06:14,762][root][INFO] - Step 15636480 @ 4093.1 SPS. Inference batcher size: 97. Learner queue size: 64. Other stats: (train_seconds = 5137.7, step = 15636480, mean_episode_return = 94.739, mean_episode_step = 1646.5, total_loss = -0.40082, pg_loss = -4.383, baseline_loss = 18.872, entropy_loss = -14.89, learner_queue_size = 64, _tick = 2258, _time = 1.6548e+09)
[2022-06-09 15:06:19,766][root][INFO] - Step 15651840 @ 3069.6 SPS. Inference batcher size: 73. Learner queue size: 64. Other stats: (train_seconds = 5142.7, step = 15651840, mean_episode_return = 53.86, mean_episode_step = 1889.9, total_loss = 52.095, pg_loss = 35.695, baseline_loss = 31.02, entropy_loss = -14.62, learner_queue_size = 64, _tick = 2261, _time = 1.6548e+09)
[2022-06-09 15:06:24,770][root][INFO] - Step 15667200 @ 3069.5 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 5147.7, step = 15667200, mean_episode_return = None, mean_episode_step = 1948.5, total_loss = 10.246, pg_loss = 12.033, baseline_loss = 12.708, entropy_loss = -14.495, learner_queue_size = 64, _tick = 2262, _time = 1.6548e+09)
[2022-06-09 15:06:29,774][root][INFO] - Step 15682560 @ 3069.5 SPS. Inference batcher size: 72. Learner queue size: 64. Other stats: (train_seconds = 5152.7, step = 15682560, mean_episode_return = 39.568, mean_episode_step = 1784.9, total_loss = -17.625, pg_loss = -38.248, baseline_loss = 35.34, entropy_loss = -14.717, learner_queue_size = 64, _tick = 2264, _time = 1.6548e+09)
[2022-06-09 15:06:34,778][root][INFO] - Step 15697920 @ 3069.5 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 5157.7, step = 15697920, mean_episode_return = 37.161, mean_episode_step = 1825.9, total_loss = 54.804, pg_loss = 46.266, baseline_loss = 23.322, entropy_loss = -14.785, learner_queue_size = 64, _tick = 2267, _time = 1.6548e+09)
[2022-06-09 15:06:39,782][root][INFO] - Step 15713280 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 5162.7, step = 15713280, mean_episode_return = 48.223, mean_episode_step = 2038.4, total_loss = -75.194, pg_loss = -86.789, baseline_loss = 26.473, entropy_loss = -14.878, learner_queue_size = 64, _tick = 2270, _time = 1.6548e+09)
[2022-06-09 15:06:44,786][root][INFO] - Step 15728640 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 5167.7, step = 15728640, mean_episode_return = 105.32, mean_episode_step = 1879.9, total_loss = 224.18, pg_loss = 189.58, baseline_loss = 49.574, entropy_loss = -14.966, learner_queue_size = 64, _tick = 2272, _time = 1.6548e+09)
[2022-06-09 15:06:49,790][root][INFO] - Step 15744000 @ 3069.5 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 5172.7, step = 15744000, mean_episode_return = 64.19, mean_episode_step = 1826.4, total_loss = -6.0221, pg_loss = -8.701, baseline_loss = 17.481, entropy_loss = -14.803, learner_queue_size = 64, _tick = 2274, _time = 1.6548e+09)
[2022-06-09 15:06:54,794][root][INFO] - Step 15759360 @ 3069.6 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 5177.7, step = 15759360, mean_episode_return = 6.3732, mean_episode_step = 1886.0, total_loss = -17.311, pg_loss = -28.224, baseline_loss = 25.787, entropy_loss = -14.875, learner_queue_size = 64, _tick = 2277, _time = 1.6548e+09)
[2022-06-09 15:06:59,798][root][INFO] - Step 15779840 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 5182.7, step = 15779840, mean_episode_return = 14.813, mean_episode_step = 2108.2, total_loss = 150.17, pg_loss = 121.71, baseline_loss = 43.511, entropy_loss = -15.045, learner_queue_size = 64, _tick = 2280, _time = 1.6548e+09)
[2022-06-09 15:07:04,805][root][INFO] - Step 15795200 @ 3067.7 SPS. Inference batcher size: 73. Learner queue size: 64. Other stats: (train_seconds = 5187.7, step = 15795200, mean_episode_return = 45.144, mean_episode_step = 1913.4, total_loss = -197.28, pg_loss = -220.74, baseline_loss = 38.336, entropy_loss = -14.877, learner_queue_size = 64, _tick = 2283, _time = 1.6548e+09)
[2022-06-09 15:07:09,810][root][INFO] - Step 15810560 @ 3068.7 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 5192.7, step = 15810560, mean_episode_return = None, mean_episode_step = 2211.4, total_loss = 49.142, pg_loss = 40.723, baseline_loss = 23.25, entropy_loss = -14.831, learner_queue_size = 64, _tick = 2284, _time = 1.6548e+09)
[2022-06-09 15:07:14,814][root][INFO] - Step 15825920 @ 3069.8 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 5197.7, step = 15825920, mean_episode_return = None, mean_episode_step = 1893.4, total_loss = 417.29, pg_loss = 347.74, baseline_loss = 84.42, entropy_loss = -14.863, learner_queue_size = 64, _tick = 2286, _time = 1.6548e+09)
[2022-06-09 15:07:19,818][root][INFO] - Step 15841280 @ 3069.5 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 5202.8, step = 15841280, mean_episode_return = 62.515, mean_episode_step = 2343.6, total_loss = -135.89, pg_loss = -136.27, baseline_loss = 15.116, entropy_loss = -14.732, learner_queue_size = 64, _tick = 2289, _time = 1.6548e+09)
[2022-06-09 15:07:24,822][root][INFO] - Step 15856640 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 5207.8, step = 15856640, mean_episode_return = 9.6146, mean_episode_step = 1747.2, total_loss = -86.573, pg_loss = -88.798, baseline_loss = 16.937, entropy_loss = -14.711, learner_queue_size = 64, _tick = 2291, _time = 1.6548e+09)
[2022-06-09 15:07:29,826][root][INFO] - Step 15872000 @ 3069.4 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 5212.8, step = 15872000, mean_episode_return = 54.687, mean_episode_step = 2055.0, total_loss = -88.891, pg_loss = -104.46, baseline_loss = 30.32, entropy_loss = -14.755, learner_queue_size = 64, _tick = 2294, _time = 1.6548e+09)
[2022-06-09 15:07:34,830][root][INFO] - Step 15887360 @ 3069.6 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 5217.8, step = 15887360, mean_episode_return = None, mean_episode_step = 2218.8, total_loss = -25.409, pg_loss = -33.547, baseline_loss = 22.716, entropy_loss = -14.577, learner_queue_size = 64, _tick = 2296, _time = 1.6548e+09)
[2022-06-09 15:07:39,834][root][INFO] - Step 15907840 @ 4092.7 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 5222.8, step = 15907840, mean_episode_return = -18.16, mean_episode_step = 1864.5, total_loss = 4.3391, pg_loss = 3.8396, baseline_loss = 14.556, entropy_loss = -14.056, learner_queue_size = 64, _tick = 2300, _time = 1.6548e+09)
[2022-06-09 15:07:44,838][root][INFO] - Step 15923200 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 5227.8, step = 15923200, mean_episode_return = -9.0202, mean_episode_step = 1826.4, total_loss = -17.085, pg_loss = -21.751, baseline_loss = 19.181, entropy_loss = -14.516, learner_queue_size = 64, _tick = 2303, _time = 1.6548e+09)
[2022-06-09 15:07:49,844][root][INFO] - Step 15938560 @ 3068.1 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 5232.8, step = 15938560, mean_episode_return = 30.505, mean_episode_step = 1805.3, total_loss = 57.615, pg_loss = 32.738, baseline_loss = 39.648, entropy_loss = -14.77, learner_queue_size = 64, _tick = 2306, _time = 1.6548e+09)
[2022-06-09 15:07:54,850][root][INFO] - Step 15953920 @ 3068.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 5237.8, step = 15953920, mean_episode_return = 36.799, mean_episode_step = 1992.9, total_loss = 138.46, pg_loss = 107.28, baseline_loss = 45.738, entropy_loss = -14.55, learner_queue_size = 64, _tick = 2309, _time = 1.6548e+09)
[2022-06-09 15:07:59,854][root][INFO] - Step 15969280 @ 3069.6 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 5242.8, step = 15969280, mean_episode_return = 16.406, mean_episode_step = 1942.0, total_loss = -115.98, pg_loss = -113.72, baseline_loss = 12.507, entropy_loss = -14.764, learner_queue_size = 64, _tick = 2311, _time = 1.6548e+09)
[2022-06-09 15:08:04,858][root][INFO] - Step 15984640 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 5247.8, step = 15984640, mean_episode_return = 52.112, mean_episode_step = 2012.3, total_loss = 49.086, pg_loss = 44.395, baseline_loss = 19.471, entropy_loss = -14.78, learner_queue_size = 64, _tick = 2313, _time = 1.6548e+09)
[2022-06-09 15:08:09,862][root][INFO] - Step 16000000 @ 3069.5 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 5252.8, step = 16000000, mean_episode_return = 79.206, mean_episode_step = 1727.8, total_loss = 224.59, pg_loss = 193.19, baseline_loss = 46.017, entropy_loss = -14.623, learner_queue_size = 64, _tick = 2316, _time = 1.6548e+09)
[2022-06-09 15:08:14,866][root][INFO] - Step 16015360 @ 3069.4 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 5257.8, step = 16015360, mean_episode_return = None, mean_episode_step = 1943.1, total_loss = 147.56, pg_loss = 95.476, baseline_loss = 66.642, entropy_loss = -14.555, learner_queue_size = 64, _tick = 2318, _time = 1.6548e+09)
[2022-06-09 15:08:19,870][root][INFO] - Step 16030720 @ 3069.7 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 5262.8, step = 16030720, mean_episode_return = 50.875, mean_episode_step = 1821.4, total_loss = 211.12, pg_loss = 179.9, baseline_loss = 46.008, entropy_loss = -14.789, learner_queue_size = 64, _tick = 2321, _time = 1.6548e+09)
[2022-06-09 15:08:24,874][root][INFO] - Step 16051200 @ 4092.7 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 5267.8, step = 16051200, mean_episode_return = 30.891, mean_episode_step = 1929.2, total_loss = 370.42, pg_loss = 318.03, baseline_loss = 67.369, entropy_loss = -14.974, learner_queue_size = 64, _tick = 2325, _time = 1.6548e+09)
[2022-06-09 15:08:29,878][root][INFO] - Step 16066560 @ 3069.5 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 5272.8, step = 16066560, mean_episode_return = None, mean_episode_step = 2212.4, total_loss = 182.88, pg_loss = 159.21, baseline_loss = 38.468, entropy_loss = -14.805, learner_queue_size = 64, _tick = 2326, _time = 1.6548e+09)
[2022-06-09 15:08:34,882][root][INFO] - Step 16081920 @ 3069.6 SPS. Inference batcher size: 79. Learner queue size: 64. Other stats: (train_seconds = 5277.8, step = 16081920, mean_episode_return = 17.28, mean_episode_step = 2077.1, total_loss = -48.886, pg_loss = -51.626, baseline_loss = 17.529, entropy_loss = -14.789, learner_queue_size = 64, _tick = 2328, _time = 1.6548e+09)
[2022-06-09 15:08:39,886][root][INFO] - Step 16097280 @ 3069.3 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 5282.8, step = 16097280, mean_episode_return = 44.131, mean_episode_step = 1873.4, total_loss = -51.966, pg_loss = -61.701, baseline_loss = 24.537, entropy_loss = -14.802, learner_queue_size = 64, _tick = 2331, _time = 1.6548e+09)
[2022-06-09 15:08:44,890][root][INFO] - Step 16112640 @ 3069.8 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 5287.8, step = 16112640, mean_episode_return = 9.6895, mean_episode_step = 1989.5, total_loss = 402.56, pg_loss = 338.29, baseline_loss = 79.095, entropy_loss = -14.826, learner_queue_size = 64, _tick = 2334, _time = 1.6548e+09)
[2022-06-09 15:08:49,894][root][INFO] - Step 16128000 @ 3069.5 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 5292.8, step = 16128000, mean_episode_return = 33.729, mean_episode_step = 2288.6, total_loss = -225.56, pg_loss = -219.58, baseline_loss = 9.0308, entropy_loss = -15.014, learner_queue_size = 64, _tick = 2337, _time = 1.6548e+09)
[2022-06-09 15:08:54,898][root][INFO] - Step 16143360 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 5297.8, step = 16143360, mean_episode_return = 60.95, mean_episode_step = 2259.6, total_loss = -55.67, pg_loss = -63.837, baseline_loss = 23.227, entropy_loss = -15.059, learner_queue_size = 64, _tick = 2340, _time = 1.6548e+09)
[2022-06-09 15:08:59,902][root][INFO] - Step 16158720 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 5302.8, step = 16158720, mean_episode_return = 84.068, mean_episode_step = 2048.5, total_loss = -242.71, pg_loss = -234.06, baseline_loss = 6.1715, entropy_loss = -14.828, learner_queue_size = 64, _tick = 2343, _time = 1.6548e+09)
[2022-06-09 15:09:04,906][root][INFO] - Step 16174080 @ 3069.6 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 5307.8, step = 16174080, mean_episode_return = 95.669, mean_episode_step = 2379.9, total_loss = 109.79, pg_loss = 91.541, baseline_loss = 33.187, entropy_loss = -14.934, learner_queue_size = 64, _tick = 2345, _time = 1.6548e+09)
[2022-06-09 15:09:09,910][root][INFO] - Step 16189440 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 5312.8, step = 16189440, mean_episode_return = 40.851, mean_episode_step = 2276.6, total_loss = 56.962, pg_loss = 47.889, baseline_loss = 24.014, entropy_loss = -14.94, learner_queue_size = 64, _tick = 2348, _time = 1.6548e+09)
[2022-06-09 15:09:14,914][root][INFO] - Step 16209920 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 5317.8, step = 16209920, mean_episode_return = 38.841, mean_episode_step = 2028.0, total_loss = 132.97, pg_loss = 110.7, baseline_loss = 37.241, entropy_loss = -14.933, learner_queue_size = 64, _tick = 2351, _time = 1.6548e+09)
[2022-06-09 15:09:19,918][root][INFO] - Step 16225280 @ 3069.5 SPS. Inference batcher size: 80. Learner queue size: 64. Other stats: (train_seconds = 5322.9, step = 16225280, mean_episode_return = 56.672, mean_episode_step = 1954.5, total_loss = 190.63, pg_loss = 164.68, baseline_loss = 40.779, entropy_loss = -14.835, learner_queue_size = 64, _tick = 2355, _time = 1.6548e+09)
[2022-06-09 15:09:24,922][root][INFO] - Step 16240640 @ 3069.6 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 5327.9, step = 16240640, mean_episode_return = 74.618, mean_episode_step = 2207.9, total_loss = -86.986, pg_loss = -91.742, baseline_loss = 19.813, entropy_loss = -15.056, learner_queue_size = 64, _tick = 2357, _time = 1.6548e+09)
[2022-06-09 15:09:29,926][root][INFO] - Step 16256000 @ 3069.5 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 5332.9, step = 16256000, mean_episode_return = None, mean_episode_step = 2029.4, total_loss = -11.087, pg_loss = -10.901, baseline_loss = 15.05, entropy_loss = -15.235, learner_queue_size = 64, _tick = 2358, _time = 1.6548e+09)
[2022-06-09 15:09:34,932][root][INFO] - Step 16271360 @ 3068.3 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 5337.9, step = 16271360, mean_episode_return = 14.067, mean_episode_step = 2093.6, total_loss = 32.129, pg_loss = 23.991, baseline_loss = 23.578, entropy_loss = -15.44, learner_queue_size = 64, _tick = 2361, _time = 1.6548e+09)
[2022-06-09 15:09:39,934][root][INFO] - Step 16286720 @ 3070.8 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 5342.9, step = 16286720, mean_episode_return = 14.55, mean_episode_step = 2129.8, total_loss = -33.735, pg_loss = -30.859, baseline_loss = 12.695, entropy_loss = -15.57, learner_queue_size = 64, _tick = 2364, _time = 1.6548e+09)
[2022-06-09 15:09:44,938][root][INFO] - Step 16302080 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 5347.9, step = 16302080, mean_episode_return = -9.1004, mean_episode_step = 2084.3, total_loss = 15.549, pg_loss = 6.7833, baseline_loss = 24.365, entropy_loss = -15.599, learner_queue_size = 64, _tick = 2367, _time = 1.6548e+09)
[2022-06-09 15:09:49,942][root][INFO] - Step 16317440 @ 3069.5 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 5352.9, step = 16317440, mean_episode_return = None, mean_episode_step = 1795.7, total_loss = 125.41, pg_loss = 122.69, baseline_loss = 18.061, entropy_loss = -15.344, learner_queue_size = 64, _tick = 2369, _time = 1.6548e+09)
[2022-06-09 15:09:54,946][root][INFO] - Step 16332800 @ 3069.6 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 5357.9, step = 16332800, mean_episode_return = 38.407, mean_episode_step = 1859.8, total_loss = -69.422, pg_loss = -65.34, baseline_loss = 11.113, entropy_loss = -15.195, learner_queue_size = 64, _tick = 2372, _time = 1.6548e+09)
[2022-06-09 15:09:59,950][root][INFO] - Step 16353280 @ 4092.7 SPS. Inference batcher size: 94. Learner queue size: 64. Other stats: (train_seconds = 5362.9, step = 16353280, mean_episode_return = 66.824, mean_episode_step = 2091.4, total_loss = 41.853, pg_loss = 35.019, baseline_loss = 22.052, entropy_loss = -15.218, learner_queue_size = 64, _tick = 2375, _time = 1.6548e+09)
[2022-06-09 15:10:04,954][root][INFO] - Step 16368640 @ 3069.5 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 5367.9, step = 16368640, mean_episode_return = 52.257, mean_episode_step = 2019.8, total_loss = 137.7, pg_loss = 109.09, baseline_loss = 43.651, entropy_loss = -15.041, learner_queue_size = 64, _tick = 2378, _time = 1.6548e+09)
[2022-06-09 15:10:09,958][root][INFO] - Step 16384000 @ 3069.6 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 5372.9, step = 16384000, mean_episode_return = 39.978, mean_episode_step = 1564.4, total_loss = -212.08, pg_loss = -206.78, baseline_loss = 9.5235, entropy_loss = -14.829, learner_queue_size = 64, _tick = 2380, _time = 1.6548e+09)
[2022-06-09 15:10:14,962][root][INFO] - Step 16399360 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 5377.9, step = 16399360, mean_episode_return = 26.041, mean_episode_step = 1686.9, total_loss = -0.075909, pg_loss = -8.7433, baseline_loss = 23.528, entropy_loss = -14.861, learner_queue_size = 64, _tick = 2383, _time = 1.6548e+09)
[2022-06-09 15:10:19,966][root][INFO] - Step 16414720 @ 3069.6 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 5382.9, step = 16414720, mean_episode_return = 92.497, mean_episode_step = 1752.7, total_loss = 85.531, pg_loss = 74.531, baseline_loss = 25.765, entropy_loss = -14.765, learner_queue_size = 64, _tick = 2386, _time = 1.6548e+09)
[2022-06-09 15:10:24,970][root][INFO] - Step 16430080 @ 3069.5 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 5387.9, step = 16430080, mean_episode_return = 15.27, mean_episode_step = 1956.2, total_loss = -144.81, pg_loss = -138.21, baseline_loss = 8.2044, entropy_loss = -14.802, learner_queue_size = 64, _tick = 2389, _time = 1.6548e+09)
[2022-06-09 15:10:29,976][root][INFO] - Step 16445440 @ 3068.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 5392.9, step = 16445440, mean_episode_return = None, mean_episode_step = 1911.9, total_loss = 53.018, pg_loss = 44.56, baseline_loss = 23.37, entropy_loss = -14.911, learner_queue_size = 64, _tick = 2389, _time = 1.6548e+09)
[2022-06-09 15:10:34,978][root][INFO] - Step 16460800 @ 3070.4 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 5397.9, step = 16460800, mean_episode_return = 72.434, mean_episode_step = 2179.3, total_loss = -64.826, pg_loss = -79.646, baseline_loss = 29.507, entropy_loss = -14.687, learner_queue_size = 64, _tick = 2392, _time = 1.6548e+09)
[2022-06-09 15:10:39,984][root][INFO] - Step 16476160 @ 3068.2 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 5402.9, step = 16476160, mean_episode_return = -10.53, mean_episode_step = 1977.5, total_loss = -13.329, pg_loss = -16.189, baseline_loss = 17.457, entropy_loss = -14.597, learner_queue_size = 64, _tick = 2394, _time = 1.6548e+09)
[2022-06-09 15:10:44,990][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 15:10:45,262][root][INFO] - Step 16496640 @ 4091.3 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 5407.9, step = 16496640, mean_episode_return = 26.893, mean_episode_step = 1704.9, total_loss = -268.76, pg_loss = -257.13, baseline_loss = 2.8407, entropy_loss = -14.465, learner_queue_size = 64, _tick = 2398, _time = 1.6548e+09)
[2022-06-09 15:10:50,266][root][INFO] - Step 16512000 @ 2911.3 SPS. Inference batcher size: 14. Learner queue size: 64. Other stats: (train_seconds = 5413.2, step = 16512000, mean_episode_return = 43.03, mean_episode_step = 2183.9, total_loss = 58.615, pg_loss = 41.68, baseline_loss = 31.376, entropy_loss = -14.441, learner_queue_size = 64, _tick = 2401, _time = 1.6548e+09)
[2022-06-09 15:10:55,270][root][INFO] - Step 16527360 @ 3069.5 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 5418.2, step = 16527360, mean_episode_return = -18.061, mean_episode_step = 1747.9, total_loss = 11.003, pg_loss = 7.3943, baseline_loss = 17.927, entropy_loss = -14.318, learner_queue_size = 64, _tick = 2404, _time = 1.6548e+09)
[2022-06-09 15:11:00,274][root][INFO] - Step 16542720 @ 3069.6 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 5423.2, step = 16542720, mean_episode_return = None, mean_episode_step = 2075.7, total_loss = 319.11, pg_loss = 265.77, baseline_loss = 67.532, entropy_loss = -14.193, learner_queue_size = 64, _tick = 2405, _time = 1.6548e+09)
[2022-06-09 15:11:05,278][root][INFO] - Step 16558080 @ 3069.6 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 5428.2, step = 16558080, mean_episode_return = 145.89, mean_episode_step = 1686.9, total_loss = -30.469, pg_loss = -33.974, baseline_loss = 17.888, entropy_loss = -14.382, learner_queue_size = 64, _tick = 2408, _time = 1.6548e+09)
[2022-06-09 15:11:10,282][root][INFO] - Step 16573440 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 5433.2, step = 16573440, mean_episode_return = None, mean_episode_step = 1742.4, total_loss = -10.608, pg_loss = -14.218, baseline_loss = 17.958, entropy_loss = -14.348, learner_queue_size = 64, _tick = 2409, _time = 1.6548e+09)
[2022-06-09 15:11:15,286][root][INFO] - Step 16593920 @ 4092.7 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 5438.2, step = 16593920, mean_episode_return = 8.36, mean_episode_step = 1794.4, total_loss = -23.488, pg_loss = -29.543, baseline_loss = 20.344, entropy_loss = -14.288, learner_queue_size = 64, _tick = 2413, _time = 1.6548e+09)
[2022-06-09 15:11:20,290][root][INFO] - Step 16609280 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 5443.2, step = 16609280, mean_episode_return = None, mean_episode_step = 1870.3, total_loss = 170.94, pg_loss = 151.35, baseline_loss = 33.981, entropy_loss = -14.393, learner_queue_size = 64, _tick = 2414, _time = 1.6548e+09)
[2022-06-09 15:11:25,294][root][INFO] - Step 16624640 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 5448.2, step = 16624640, mean_episode_return = 19.48, mean_episode_step = 1801.2, total_loss = -77.377, pg_loss = -77.597, baseline_loss = 14.442, entropy_loss = -14.222, learner_queue_size = 64, _tick = 2417, _time = 1.6548e+09)
[2022-06-09 15:11:30,298][root][INFO] - Step 16640000 @ 3069.6 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 5453.2, step = 16640000, mean_episode_return = 22.393, mean_episode_step = 1958.3, total_loss = 58.465, pg_loss = 40.411, baseline_loss = 32.381, entropy_loss = -14.327, learner_queue_size = 64, _tick = 2419, _time = 1.6548e+09)
[2022-06-09 15:11:35,302][root][INFO] - Step 16655360 @ 3069.6 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 5458.2, step = 16655360, mean_episode_return = 21.824, mean_episode_step = 2096.0, total_loss = 82.527, pg_loss = 52.686, baseline_loss = 44.525, entropy_loss = -14.684, learner_queue_size = 64, _tick = 2422, _time = 1.6548e+09)
[2022-06-09 15:11:40,306][root][INFO] - Step 16670720 @ 3069.5 SPS. Inference batcher size: 7. Learner queue size: 64. Other stats: (train_seconds = 5463.2, step = 16670720, mean_episode_return = 60.307, mean_episode_step = 1951.3, total_loss = 84.435, pg_loss = 61.992, baseline_loss = 36.911, entropy_loss = -14.467, learner_queue_size = 64, _tick = 2425, _time = 1.6548e+09)
[2022-06-09 15:11:45,310][root][INFO] - Step 16686080 @ 3069.6 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 5468.2, step = 16686080, mean_episode_return = 56.041, mean_episode_step = 1497.1, total_loss = -10.433, pg_loss = -11.262, baseline_loss = 15.382, entropy_loss = -14.553, learner_queue_size = 64, _tick = 2428, _time = 1.6548e+09)
[2022-06-09 15:11:50,314][root][INFO] - Step 16701440 @ 3069.5 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 5473.3, step = 16701440, mean_episode_return = 25.501, mean_episode_step = 1898.1, total_loss = 214.97, pg_loss = 191.11, baseline_loss = 38.319, entropy_loss = -14.463, learner_queue_size = 64, _tick = 2431, _time = 1.6548e+09)
[2022-06-09 15:11:55,318][root][INFO] - Step 16716800 @ 3069.6 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 5478.3, step = 16716800, mean_episode_return = 20.87, mean_episode_step = 1856.5, total_loss = 54.04, pg_loss = 40.325, baseline_loss = 28.077, entropy_loss = -14.362, learner_queue_size = 64, _tick = 2432, _time = 1.6548e+09)
[2022-06-09 15:12:00,322][root][INFO] - Step 16737280 @ 4092.7 SPS. Inference batcher size: 88. Learner queue size: 64. Other stats: (train_seconds = 5483.3, step = 16737280, mean_episode_return = 25.935, mean_episode_step = 1972.8, total_loss = 438.45, pg_loss = 394.71, baseline_loss = 58.159, entropy_loss = -14.412, learner_queue_size = 64, _tick = 2436, _time = 1.6548e+09)
[2022-06-09 15:12:05,326][root][INFO] - Step 16752640 @ 3069.6 SPS. Inference batcher size: 97. Learner queue size: 64. Other stats: (train_seconds = 5488.3, step = 16752640, mean_episode_return = 64.101, mean_episode_step = 2234.8, total_loss = 322.24, pg_loss = 279.14, baseline_loss = 57.553, entropy_loss = -14.452, learner_queue_size = 64, _tick = 2438, _time = 1.6548e+09)
[2022-06-09 15:12:10,330][root][INFO] - Step 16768000 @ 3069.5 SPS. Inference batcher size: 73. Learner queue size: 64. Other stats: (train_seconds = 5493.3, step = 16768000, mean_episode_return = None, mean_episode_step = 1700.4, total_loss = 291.44, pg_loss = 253.16, baseline_loss = 52.776, entropy_loss = -14.495, learner_queue_size = 64, _tick = 2440, _time = 1.6548e+09)
[2022-06-09 15:12:15,334][root][INFO] - Step 16783360 @ 3069.5 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 5498.3, step = 16783360, mean_episode_return = 70.976, mean_episode_step = 1735.4, total_loss = -172.63, pg_loss = -179.8, baseline_loss = 21.482, entropy_loss = -14.308, learner_queue_size = 64, _tick = 2443, _time = 1.6548e+09)
[2022-06-09 15:12:20,338][root][INFO] - Step 16798720 @ 3069.5 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 5503.3, step = 16798720, mean_episode_return = 32.647, mean_episode_step = 1869.5, total_loss = 184.92, pg_loss = 130.53, baseline_loss = 68.707, entropy_loss = -14.313, learner_queue_size = 64, _tick = 2445, _time = 1.6548e+09)
[2022-06-09 15:12:25,342][root][INFO] - Step 16814080 @ 3069.6 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 5508.3, step = 16814080, mean_episode_return = None, mean_episode_step = 1759.7, total_loss = 63.258, pg_loss = 56.656, baseline_loss = 21.275, entropy_loss = -14.672, learner_queue_size = 64, _tick = 2447, _time = 1.6548e+09)
[2022-06-09 15:12:30,346][root][INFO] - Step 16829440 @ 3069.5 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 5513.3, step = 16829440, mean_episode_return = 50.11, mean_episode_step = 1990.1, total_loss = -170.51, pg_loss = -158.15, baseline_loss = 2.2625, entropy_loss = -14.625, learner_queue_size = 64, _tick = 2450, _time = 1.6548e+09)
[2022-06-09 15:12:35,350][root][INFO] - Step 16844800 @ 3069.6 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 5518.3, step = 16844800, mean_episode_return = None, mean_episode_step = 1656.4, total_loss = 153.69, pg_loss = 141.23, baseline_loss = 27.31, entropy_loss = -14.855, learner_queue_size = 64, _tick = 2452, _time = 1.6548e+09)
[2022-06-09 15:12:40,354][root][INFO] - Step 16860160 @ 3069.6 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 5523.3, step = 16860160, mean_episode_return = 33.362, mean_episode_step = 1781.8, total_loss = 40.437, pg_loss = 16.344, baseline_loss = 38.919, entropy_loss = -14.825, learner_queue_size = 64, _tick = 2455, _time = 1.6548e+09)
[2022-06-09 15:12:45,358][root][INFO] - Step 16880640 @ 4092.8 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 5528.3, step = 16880640, mean_episode_return = None, mean_episode_step = 2156.6, total_loss = 232.92, pg_loss = 208.01, baseline_loss = 40.16, entropy_loss = -15.246, learner_queue_size = 64, _tick = 2456, _time = 1.6548e+09)
[2022-06-09 15:12:50,362][root][INFO] - Step 16896000 @ 3069.5 SPS. Inference batcher size: 74. Learner queue size: 64. Other stats: (train_seconds = 5533.3, step = 16896000, mean_episode_return = None, mean_episode_step = 2453.7, total_loss = -77.804, pg_loss = -69.997, baseline_loss = 7.3728, entropy_loss = -15.18, learner_queue_size = 64, _tick = 2458, _time = 1.6548e+09)
[2022-06-09 15:12:55,366][root][INFO] - Step 16911360 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 5538.3, step = 16911360, mean_episode_return = -44.009, mean_episode_step = 1827.4, total_loss = 127.14, pg_loss = 115.82, baseline_loss = 26.394, entropy_loss = -15.068, learner_queue_size = 64, _tick = 2461, _time = 1.6548e+09)
[2022-06-09 15:13:00,370][root][INFO] - Step 16926720 @ 3069.5 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 5543.3, step = 16926720, mean_episode_return = 24.42, mean_episode_step = 2394.2, total_loss = -131.94, pg_loss = -125.67, baseline_loss = 9.0531, entropy_loss = -15.323, learner_queue_size = 64, _tick = 2463, _time = 1.6548e+09)
[2022-06-09 15:13:05,374][root][INFO] - Step 16942080 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 5548.3, step = 16942080, mean_episode_return = 45.63, mean_episode_step = 2352.2, total_loss = 49.603, pg_loss = 37.244, baseline_loss = 27.505, entropy_loss = -15.147, learner_queue_size = 64, _tick = 2464, _time = 1.6548e+09)
[2022-06-09 15:13:10,378][root][INFO] - Step 16957440 @ 3069.6 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 5553.3, step = 16957440, mean_episode_return = 37.716, mean_episode_step = 2044.1, total_loss = 19.619, pg_loss = 9.032, baseline_loss = 25.836, entropy_loss = -15.249, learner_queue_size = 64, _tick = 2466, _time = 1.6548e+09)
[2022-06-09 15:13:15,382][root][INFO] - Step 16972800 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 5558.3, step = 16972800, mean_episode_return = 43.907, mean_episode_step = 2103.7, total_loss = -52.354, pg_loss = -51.652, baseline_loss = 14.303, entropy_loss = -15.005, learner_queue_size = 64, _tick = 2468, _time = 1.6548e+09)
[2022-06-09 15:13:20,386][root][INFO] - Step 16988160 @ 3069.6 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 5563.3, step = 16988160, mean_episode_return = 30.223, mean_episode_step = 2066.0, total_loss = 97.739, pg_loss = 77.492, baseline_loss = 35.539, entropy_loss = -15.291, learner_queue_size = 64, _tick = 2471, _time = 1.6548e+09)
[2022-06-09 15:13:25,390][root][INFO] - Step 17003520 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 5568.3, step = 17003520, mean_episode_return = 37.685, mean_episode_step = 2034.8, total_loss = -234.02, pg_loss = -222.02, baseline_loss = 3.282, entropy_loss = -15.275, learner_queue_size = 64, _tick = 2474, _time = 1.6548e+09)
[2022-06-09 15:13:30,394][root][INFO] - Step 17018880 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 5573.3, step = 17018880, mean_episode_return = 64.866, mean_episode_step = 2405.3, total_loss = -52.811, pg_loss = -50.913, baseline_loss = 13.659, entropy_loss = -15.558, learner_queue_size = 64, _tick = 2477, _time = 1.6548e+09)
[2022-06-09 15:13:35,398][root][INFO] - Step 17039360 @ 4092.8 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 5578.3, step = 17039360, mean_episode_return = 11.72, mean_episode_step = 2001.7, total_loss = 390.53, pg_loss = 325.28, baseline_loss = 80.663, entropy_loss = -15.412, learner_queue_size = 64, _tick = 2480, _time = 1.6548e+09)
[2022-06-09 15:13:40,402][root][INFO] - Step 17054720 @ 3069.4 SPS. Inference batcher size: 76. Learner queue size: 64. Other stats: (train_seconds = 5583.3, step = 17054720, mean_episode_return = 76.299, mean_episode_step = 2125.2, total_loss = -169.17, pg_loss = -165.75, baseline_loss = 12.13, entropy_loss = -15.543, learner_queue_size = 64, _tick = 2482, _time = 1.6548e+09)
[2022-06-09 15:13:45,406][root][INFO] - Step 17070080 @ 3069.7 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 5588.3, step = 17070080, mean_episode_return = 159.7, mean_episode_step = 2058.4, total_loss = -214.15, pg_loss = -203.47, baseline_loss = 4.8496, entropy_loss = -15.531, learner_queue_size = 64, _tick = 2485, _time = 1.6548e+09)
[2022-06-09 15:13:50,410][root][INFO] - Step 17085440 @ 3069.5 SPS. Inference batcher size: 18. Learner queue size: 64. Other stats: (train_seconds = 5593.3, step = 17085440, mean_episode_return = 16.366, mean_episode_step = 2604.2, total_loss = -123.04, pg_loss = -119.55, baseline_loss = 12.175, entropy_loss = -15.665, learner_queue_size = 64, _tick = 2487, _time = 1.6548e+09)
[2022-06-09 15:13:55,414][root][INFO] - Step 17100800 @ 3069.6 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 5598.3, step = 17100800, mean_episode_return = 83.365, mean_episode_step = 2299.3, total_loss = -237.06, pg_loss = -228.98, baseline_loss = 7.6395, entropy_loss = -15.717, learner_queue_size = 64, _tick = 2490, _time = 1.6548e+09)
[2022-06-09 15:14:00,418][root][INFO] - Step 17116160 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 5603.4, step = 17116160, mean_episode_return = 54.463, mean_episode_step = 2088.6, total_loss = 145.16, pg_loss = 116.52, baseline_loss = 44.206, entropy_loss = -15.558, learner_queue_size = 64, _tick = 2493, _time = 1.6548e+09)
[2022-06-09 15:14:05,422][root][INFO] - Step 17131520 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 5608.4, step = 17131520, mean_episode_return = 73.032, mean_episode_step = 2023.9, total_loss = -73.078, pg_loss = -78.228, baseline_loss = 20.491, entropy_loss = -15.342, learner_queue_size = 64, _tick = 2495, _time = 1.6548e+09)
[2022-06-09 15:14:10,426][root][INFO] - Step 17146880 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 5613.4, step = 17146880, mean_episode_return = -9.2088, mean_episode_step = 2079.3, total_loss = -194.22, pg_loss = -193.86, baseline_loss = 15.096, entropy_loss = -15.457, learner_queue_size = 64, _tick = 2497, _time = 1.6548e+09)
[2022-06-09 15:14:15,432][root][INFO] - Step 17162240 @ 3068.2 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 5618.4, step = 17162240, mean_episode_return = None, mean_episode_step = 2067.8, total_loss = -79.968, pg_loss = -75.446, baseline_loss = 10.907, entropy_loss = -15.429, learner_queue_size = 64, _tick = 2498, _time = 1.6548e+09)
[2022-06-09 15:14:20,438][root][INFO] - Step 17182720 @ 4091.2 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 5623.4, step = 17182720, mean_episode_return = 18.911, mean_episode_step = 2245.3, total_loss = -125.15, pg_loss = -139.47, baseline_loss = 29.763, entropy_loss = -15.436, learner_queue_size = 64, _tick = 2502, _time = 1.6548e+09)
[2022-06-09 15:14:25,442][root][INFO] - Step 17198080 @ 3069.4 SPS. Inference batcher size: 81. Learner queue size: 64. Other stats: (train_seconds = 5628.4, step = 17198080, mean_episode_return = 8.3048, mean_episode_step = 1733.5, total_loss = 82.294, pg_loss = 66.333, baseline_loss = 31.595, entropy_loss = -15.634, learner_queue_size = 64, _tick = 2505, _time = 1.6548e+09)
[2022-06-09 15:14:30,446][root][INFO] - Step 17213440 @ 3069.6 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 5633.4, step = 17213440, mean_episode_return = None, mean_episode_step = 2044.6, total_loss = 775.86, pg_loss = 637.75, baseline_loss = 153.76, entropy_loss = -15.646, learner_queue_size = 64, _tick = 2507, _time = 1.6548e+09)
[2022-06-09 15:14:35,450][root][INFO] - Step 17228800 @ 3069.5 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 5638.4, step = 17228800, mean_episode_return = -15.391, mean_episode_step = 2143.2, total_loss = 457.27, pg_loss = 381.95, baseline_loss = 90.841, entropy_loss = -15.515, learner_queue_size = 64, _tick = 2510, _time = 1.6548e+09)
[2022-06-09 15:14:40,454][root][INFO] - Step 17244160 @ 3069.5 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 5643.4, step = 17244160, mean_episode_return = 67.508, mean_episode_step = 2048.5, total_loss = -52.678, pg_loss = -74.297, baseline_loss = 36.969, entropy_loss = -15.35, learner_queue_size = 64, _tick = 2512, _time = 1.6548e+09)
[2022-06-09 15:14:45,458][root][INFO] - Step 17259520 @ 3069.6 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 5648.4, step = 17259520, mean_episode_return = -17.911, mean_episode_step = 2164.0, total_loss = 75.166, pg_loss = 44.69, baseline_loss = 45.843, entropy_loss = -15.367, learner_queue_size = 64, _tick = 2514, _time = 1.6548e+09)
[2022-06-09 15:14:50,462][root][INFO] - Step 17274880 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 5653.4, step = 17274880, mean_episode_return = None, mean_episode_step = 2209.3, total_loss = -103.57, pg_loss = -99.504, baseline_loss = 11.559, entropy_loss = -15.627, learner_queue_size = 64, _tick = 2516, _time = 1.6548e+09)
[2022-06-09 15:14:55,466][root][INFO] - Step 17290240 @ 3069.4 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 5658.4, step = 17290240, mean_episode_return = 93.508, mean_episode_step = 2007.8, total_loss = -67.576, pg_loss = -67.523, baseline_loss = 15.749, entropy_loss = -15.803, learner_queue_size = 64, _tick = 2518, _time = 1.6548e+09)
[2022-06-09 15:15:00,470][root][INFO] - Step 17305600 @ 3069.8 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 5663.4, step = 17305600, mean_episode_return = 46.276, mean_episode_step = 2164.7, total_loss = -27.536, pg_loss = -54.376, baseline_loss = 42.409, entropy_loss = -15.57, learner_queue_size = 64, _tick = 2521, _time = 1.6548e+09)
[2022-06-09 15:15:05,474][root][INFO] - Step 17320960 @ 3069.5 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 5668.4, step = 17320960, mean_episode_return = 49.71, mean_episode_step = 1874.5, total_loss = -62.806, pg_loss = -74.698, baseline_loss = 27.287, entropy_loss = -15.395, learner_queue_size = 64, _tick = 2524, _time = 1.6548e+09)
[2022-06-09 15:15:10,478][root][INFO] - Step 17336320 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 5673.4, step = 17336320, mean_episode_return = 14.299, mean_episode_step = 1930.6, total_loss = 27.105, pg_loss = 11.022, baseline_loss = 31.298, entropy_loss = -15.215, learner_queue_size = 64, _tick = 2527, _time = 1.6548e+09)
[2022-06-09 15:15:15,482][root][INFO] - Step 17351680 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 5678.4, step = 17351680, mean_episode_return = None, mean_episode_step = 2127.0, total_loss = -60.817, pg_loss = -60.101, baseline_loss = 14.321, entropy_loss = -15.037, learner_queue_size = 64, _tick = 2527, _time = 1.6548e+09)
[2022-06-09 15:15:20,486][root][INFO] - Step 17367040 @ 3069.5 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 5683.4, step = 17367040, mean_episode_return = 58.913, mean_episode_step = 2053.5, total_loss = 155.01, pg_loss = 34.03, baseline_loss = 135.95, entropy_loss = -14.964, learner_queue_size = 64, _tick = 2530, _time = 1.6548e+09)
[2022-06-09 15:15:25,490][root][INFO] - Step 17387520 @ 4092.7 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 5688.4, step = 17387520, mean_episode_return = 16.752, mean_episode_step = 1719.6, total_loss = -101.17, pg_loss = -118.91, baseline_loss = 32.426, entropy_loss = -14.687, learner_queue_size = 64, _tick = 2533, _time = 1.6548e+09)
[2022-06-09 15:15:30,494][root][INFO] - Step 17402880 @ 3069.6 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 5693.4, step = 17402880, mean_episode_return = 23.415, mean_episode_step = 2180.1, total_loss = -152.04, pg_loss = -149.42, baseline_loss = 12.123, entropy_loss = -14.744, learner_queue_size = 64, _tick = 2536, _time = 1.6548e+09)
[2022-06-09 15:15:35,498][root][INFO] - Step 17418240 @ 3069.5 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 5698.4, step = 17418240, mean_episode_return = 72.363, mean_episode_step = 2077.6, total_loss = 63.259, pg_loss = 55.75, baseline_loss = 22.302, entropy_loss = -14.793, learner_queue_size = 64, _tick = 2539, _time = 1.6548e+09)
[2022-06-09 15:15:40,515][root][INFO] - Step 17433600 @ 3061.9 SPS. Inference batcher size: 18. Learner queue size: 64. Other stats: (train_seconds = 5703.5, step = 17433600, mean_episode_return = 79.639, mean_episode_step = 1938.8, total_loss = -84.171, pg_loss = -82.621, baseline_loss = 13.69, entropy_loss = -15.241, learner_queue_size = 64, _tick = 2542, _time = 1.6548e+09)
[2022-06-09 15:15:45,518][root][INFO] - Step 17448960 @ 3069.7 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 5708.5, step = 17448960, mean_episode_return = 43.78, mean_episode_step = 1765.4, total_loss = 292.54, pg_loss = 250.39, baseline_loss = 57.575, entropy_loss = -15.427, learner_queue_size = 64, _tick = 2545, _time = 1.6548e+09)
[2022-06-09 15:15:50,522][root][INFO] - Step 17464320 @ 3069.7 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 5713.5, step = 17464320, mean_episode_return = 102.01, mean_episode_step = 1957.0, total_loss = 223.52, pg_loss = 185.43, baseline_loss = 53.613, entropy_loss = -15.529, learner_queue_size = 64, _tick = 2547, _time = 1.6548e+09)
[2022-06-09 15:15:55,526][root][INFO] - Step 17479680 @ 3069.6 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 5718.5, step = 17479680, mean_episode_return = None, mean_episode_step = 1616.0, total_loss = 123.7, pg_loss = 112.93, baseline_loss = 26.193, entropy_loss = -15.422, learner_queue_size = 64, _tick = 2549, _time = 1.6548e+09)
[2022-06-09 15:16:00,530][root][INFO] - Step 17495040 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 5723.5, step = 17495040, mean_episode_return = 19.927, mean_episode_step = 1938.8, total_loss = 5.5824, pg_loss = -9.6176, baseline_loss = 30.45, entropy_loss = -15.25, learner_queue_size = 64, _tick = 2551, _time = 1.6548e+09)
[2022-06-09 15:16:05,534][root][INFO] - Step 17510400 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 5728.5, step = 17510400, mean_episode_return = 88.904, mean_episode_step = 1803.3, total_loss = -74.411, pg_loss = -101.71, baseline_loss = 42.315, entropy_loss = -15.017, learner_queue_size = 64, _tick = 2554, _time = 1.6548e+09)
[2022-06-09 15:16:10,538][root][INFO] - Step 17525760 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 5733.5, step = 17525760, mean_episode_return = 43.465, mean_episode_step = 1683.6, total_loss = -189.67, pg_loss = -183.78, baseline_loss = 8.7095, entropy_loss = -14.595, learner_queue_size = 64, _tick = 2557, _time = 1.6548e+09)
[2022-06-09 15:16:15,542][root][INFO] - Step 17546240 @ 4092.8 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 5738.5, step = 17546240, mean_episode_return = 119.75, mean_episode_step = 1872.4, total_loss = 35.855, pg_loss = 11.521, baseline_loss = 39.08, entropy_loss = -14.745, learner_queue_size = 64, _tick = 2560, _time = 1.6548e+09)
[2022-06-09 15:16:20,546][root][INFO] - Step 17561600 @ 3069.5 SPS. Inference batcher size: 73. Learner queue size: 64. Other stats: (train_seconds = 5743.5, step = 17561600, mean_episode_return = 29.03, mean_episode_step = 2032.9, total_loss = 0.99492, pg_loss = -5.9619, baseline_loss = 21.865, entropy_loss = -14.908, learner_queue_size = 64, _tick = 2563, _time = 1.6548e+09)
[2022-06-09 15:16:25,550][root][INFO] - Step 17576960 @ 3069.6 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 5748.5, step = 17576960, mean_episode_return = 70.909, mean_episode_step = 1814.4, total_loss = 234.36, pg_loss = 180.6, baseline_loss = 68.411, entropy_loss = -14.645, learner_queue_size = 64, _tick = 2566, _time = 1.6548e+09)
[2022-06-09 15:16:30,554][root][INFO] - Step 17592320 @ 3069.4 SPS. Inference batcher size: 79. Learner queue size: 64. Other stats: (train_seconds = 5753.5, step = 17592320, mean_episode_return = 107.8, mean_episode_step = 1916.1, total_loss = 308.19, pg_loss = 238.15, baseline_loss = 84.578, entropy_loss = -14.537, learner_queue_size = 64, _tick = 2568, _time = 1.6548e+09)
[2022-06-09 15:16:35,558][root][INFO] - Step 17607680 @ 3069.7 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 5758.5, step = 17607680, mean_episode_return = 9.0603, mean_episode_step = 1948.7, total_loss = 36.164, pg_loss = 29.036, baseline_loss = 21.953, entropy_loss = -14.826, learner_queue_size = 64, _tick = 2571, _time = 1.6548e+09)
[2022-06-09 15:16:40,562][root][INFO] - Step 17623040 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 5763.5, step = 17623040, mean_episode_return = -3.7803, mean_episode_step = 1566.4, total_loss = -75.112, pg_loss = -75.281, baseline_loss = 14.933, entropy_loss = -14.764, learner_queue_size = 64, _tick = 2574, _time = 1.6548e+09)
[2022-06-09 15:16:45,566][root][INFO] - Step 17638400 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 5768.5, step = 17638400, mean_episode_return = 55.931, mean_episode_step = 1781.4, total_loss = -155.32, pg_loss = -157.93, baseline_loss = 17.664, entropy_loss = -15.062, learner_queue_size = 64, _tick = 2576, _time = 1.6548e+09)
[2022-06-09 15:16:50,570][root][INFO] - Step 17653760 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 5773.5, step = 17653760, mean_episode_return = 24.111, mean_episode_step = 1865.9, total_loss = 26.453, pg_loss = 20.724, baseline_loss = 20.95, entropy_loss = -15.221, learner_queue_size = 64, _tick = 2578, _time = 1.6548e+09)
[2022-06-09 15:16:55,574][root][INFO] - Step 17674240 @ 4092.8 SPS. Inference batcher size: 78. Learner queue size: 64. Other stats: (train_seconds = 5778.5, step = 17674240, mean_episode_return = 23.795, mean_episode_step = 1911.1, total_loss = 30.953, pg_loss = 21.054, baseline_loss = 25.013, entropy_loss = -15.114, learner_queue_size = 64, _tick = 2582, _time = 1.6548e+09)
[2022-06-09 15:17:00,578][root][INFO] - Step 17689600 @ 3069.5 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 5783.5, step = 17689600, mean_episode_return = 22.436, mean_episode_step = 2049.3, total_loss = -86.333, pg_loss = -88.416, baseline_loss = 17.7, entropy_loss = -15.617, learner_queue_size = 64, _tick = 2584, _time = 1.6548e+09)
[2022-06-09 15:17:05,582][root][INFO] - Step 17704960 @ 3069.6 SPS. Inference batcher size: 80. Learner queue size: 64. Other stats: (train_seconds = 5788.5, step = 17704960, mean_episode_return = 24.217, mean_episode_step = 1781.9, total_loss = 30.92, pg_loss = 13.908, baseline_loss = 32.503, entropy_loss = -15.491, learner_queue_size = 64, _tick = 2587, _time = 1.6548e+09)
[2022-06-09 15:17:10,586][root][INFO] - Step 17720320 @ 3069.6 SPS. Inference batcher size: 80. Learner queue size: 64. Other stats: (train_seconds = 5793.5, step = 17720320, mean_episode_return = 8.7297, mean_episode_step = 1916.7, total_loss = 35.743, pg_loss = 40.894, baseline_loss = 10.681, entropy_loss = -15.833, learner_queue_size = 64, _tick = 2590, _time = 1.6548e+09)
[2022-06-09 15:17:15,590][root][INFO] - Step 17735680 @ 3069.6 SPS. Inference batcher size: 9. Learner queue size: 64. Other stats: (train_seconds = 5798.5, step = 17735680, mean_episode_return = 101.26, mean_episode_step = 1901.1, total_loss = 47.382, pg_loss = 30.692, baseline_loss = 32.23, entropy_loss = -15.54, learner_queue_size = 64, _tick = 2593, _time = 1.6548e+09)
[2022-06-09 15:17:20,594][root][INFO] - Step 17751040 @ 3069.5 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 5803.5, step = 17751040, mean_episode_return = 28.235, mean_episode_step = 1986.4, total_loss = -110.51, pg_loss = -101.98, baseline_loss = 6.631, entropy_loss = -15.164, learner_queue_size = 64, _tick = 2596, _time = 1.6548e+09)
[2022-06-09 15:17:25,598][root][INFO] - Step 17766400 @ 3069.6 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 5808.5, step = 17766400, mean_episode_return = None, mean_episode_step = 2232.8, total_loss = 125.25, pg_loss = 107.2, baseline_loss = 33.167, entropy_loss = -15.12, learner_queue_size = 64, _tick = 2598, _time = 1.6548e+09)
[2022-06-09 15:17:30,602][root][INFO] - Step 17781760 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 5813.5, step = 17781760, mean_episode_return = 80.129, mean_episode_step = 1927.9, total_loss = -98.164, pg_loss = -93.66, baseline_loss = 10.333, entropy_loss = -14.837, learner_queue_size = 64, _tick = 2601, _time = 1.6548e+09)
[2022-06-09 15:17:35,608][root][INFO] - Step 17797120 @ 3068.3 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 5818.5, step = 17797120, mean_episode_return = 83.738, mean_episode_step = 2057.3, total_loss = 195.52, pg_loss = 147.99, baseline_loss = 62.482, entropy_loss = -14.948, learner_queue_size = 64, _tick = 2604, _time = 1.6548e+09)
[2022-06-09 15:17:40,614][root][INFO] - Step 17817600 @ 4091.1 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 5823.5, step = 17817600, mean_episode_return = None, mean_episode_step = 2086.0, total_loss = -8.3551, pg_loss = -13.669, baseline_loss = 20.272, entropy_loss = -14.958, learner_queue_size = 64, _tick = 2607, _time = 1.6548e+09)
[2022-06-09 15:17:45,618][root][INFO] - Step 17832960 @ 3069.5 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 5828.6, step = 17832960, mean_episode_return = 102.24, mean_episode_step = 1952.6, total_loss = 2.6976, pg_loss = -3.907, baseline_loss = 21.429, entropy_loss = -14.825, learner_queue_size = 64, _tick = 2609, _time = 1.6548e+09)
[2022-06-09 15:17:50,622][root][INFO] - Step 17848320 @ 3069.5 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 5833.6, step = 17848320, mean_episode_return = 11.185, mean_episode_step = 2160.6, total_loss = -6.6341, pg_loss = -13.02, baseline_loss = 21.198, entropy_loss = -14.811, learner_queue_size = 64, _tick = 2612, _time = 1.6548e+09)
[2022-06-09 15:17:55,626][root][INFO] - Step 17863680 @ 3069.6 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 5838.6, step = 17863680, mean_episode_return = 11.364, mean_episode_step = 2022.0, total_loss = 220.19, pg_loss = 191.59, baseline_loss = 43.119, entropy_loss = -14.518, learner_queue_size = 64, _tick = 2614, _time = 1.6548e+09)
[2022-06-09 15:18:00,630][root][INFO] - Step 17879040 @ 3069.6 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 5843.6, step = 17879040, mean_episode_return = 7.6297, mean_episode_step = 2213.2, total_loss = -199.3, pg_loss = -187.26, baseline_loss = 2.6527, entropy_loss = -14.692, learner_queue_size = 64, _tick = 2616, _time = 1.6548e+09)
[2022-06-09 15:18:05,634][root][INFO] - Step 17894400 @ 3069.5 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 5848.6, step = 17894400, mean_episode_return = None, mean_episode_step = 1910.9, total_loss = 192.79, pg_loss = 164.98, baseline_loss = 42.303, entropy_loss = -14.493, learner_queue_size = 64, _tick = 2618, _time = 1.6548e+09)
[2022-06-09 15:18:10,638][root][INFO] - Step 17909760 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 5853.6, step = 17909760, mean_episode_return = 33.186, mean_episode_step = 1772.4, total_loss = 72.866, pg_loss = 55.636, baseline_loss = 31.594, entropy_loss = -14.364, learner_queue_size = 64, _tick = 2621, _time = 1.6548e+09)
[2022-06-09 15:18:15,643][root][INFO] - Step 17930240 @ 4092.1 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 5858.6, step = 17930240, mean_episode_return = 9.6496, mean_episode_step = 1999.6, total_loss = 10.275, pg_loss = -1.0091, baseline_loss = 26.04, entropy_loss = -14.755, learner_queue_size = 64, _tick = 2623, _time = 1.6548e+09)
[2022-06-09 15:18:20,646][root][INFO] - Step 17945600 @ 3070.0 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 5863.6, step = 17945600, mean_episode_return = 80.871, mean_episode_step = 2130.9, total_loss = -112.28, pg_loss = -128.39, baseline_loss = 30.842, entropy_loss = -14.74, learner_queue_size = 64, _tick = 2625, _time = 1.6548e+09)
[2022-06-09 15:18:25,650][root][INFO] - Step 17960960 @ 3069.5 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 5868.6, step = 17960960, mean_episode_return = 36.951, mean_episode_step = 1990.6, total_loss = 12.263, pg_loss = 3.2141, baseline_loss = 23.711, entropy_loss = -14.662, learner_queue_size = 64, _tick = 2627, _time = 1.6548e+09)
[2022-06-09 15:18:30,654][root][INFO] - Step 17976320 @ 3069.6 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 5873.6, step = 17976320, mean_episode_return = 66.452, mean_episode_step = 2003.6, total_loss = -69.688, pg_loss = -73.459, baseline_loss = 18.471, entropy_loss = -14.7, learner_queue_size = 64, _tick = 2630, _time = 1.6548e+09)
[2022-06-09 15:18:35,658][root][INFO] - Step 17991680 @ 3069.5 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 5878.6, step = 17991680, mean_episode_return = 51.59, mean_episode_step = 1836.1, total_loss = 54.793, pg_loss = 41.327, baseline_loss = 28.026, entropy_loss = -14.56, learner_queue_size = 64, _tick = 2632, _time = 1.6548e+09)
[2022-06-09 15:18:40,662][root][INFO] - Step 18007040 @ 3069.6 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 5883.6, step = 18007040, mean_episode_return = None, mean_episode_step = 2037.2, total_loss = -146.39, pg_loss = -136.72, baseline_loss = 4.784, entropy_loss = -14.449, learner_queue_size = 64, _tick = 2632, _time = 1.6548e+09)
[2022-06-09 15:18:45,666][root][INFO] - Step 18022400 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 5888.6, step = 18022400, mean_episode_return = None, mean_episode_step = 2232.0, total_loss = -128.16, pg_loss = -122.48, baseline_loss = 8.8915, entropy_loss = -14.565, learner_queue_size = 64, _tick = 2633, _time = 1.6548e+09)
[2022-06-09 15:18:50,670][root][INFO] - Step 18037760 @ 3069.5 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 5893.6, step = 18037760, mean_episode_return = 22.565, mean_episode_step = 2134.9, total_loss = -174.52, pg_loss = -181.09, baseline_loss = 21.302, entropy_loss = -14.724, learner_queue_size = 64, _tick = 2635, _time = 1.6548e+09)
[2022-06-09 15:18:55,674][root][INFO] - Step 18053120 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 5898.6, step = 18053120, mean_episode_return = 19.523, mean_episode_step = 2307.8, total_loss = 227.59, pg_loss = 191.99, baseline_loss = 50.668, entropy_loss = -15.062, learner_queue_size = 64, _tick = 2637, _time = 1.6548e+09)
[2022-06-09 15:19:00,678][root][INFO] - Step 18068480 @ 3069.6 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 5903.6, step = 18068480, mean_episode_return = 31.22, mean_episode_step = 1792.5, total_loss = -94.498, pg_loss = -90.706, baseline_loss = 11.343, entropy_loss = -15.135, learner_queue_size = 64, _tick = 2639, _time = 1.6548e+09)
[2022-06-09 15:19:05,682][root][INFO] - Step 18088960 @ 4092.8 SPS. Inference batcher size: 110. Learner queue size: 64. Other stats: (train_seconds = 5908.6, step = 18088960, mean_episode_return = 4.9533, mean_episode_step = 2145.0, total_loss = 74.148, pg_loss = 44.501, baseline_loss = 44.659, entropy_loss = -15.012, learner_queue_size = 64, _tick = 2643, _time = 1.6548e+09)
[2022-06-09 15:19:10,686][root][INFO] - Step 18104320 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 5913.6, step = 18104320, mean_episode_return = 81.283, mean_episode_step = 2283.7, total_loss = -98.104, pg_loss = -100.92, baseline_loss = 17.666, entropy_loss = -14.852, learner_queue_size = 64, _tick = 2646, _time = 1.6548e+09)
[2022-06-09 15:19:15,690][root][INFO] - Step 18119680 @ 3069.5 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 5918.6, step = 18119680, mean_episode_return = 44.264, mean_episode_step = 1740.3, total_loss = -223.29, pg_loss = -232.81, baseline_loss = 24.088, entropy_loss = -14.566, learner_queue_size = 64, _tick = 2649, _time = 1.6548e+09)
[2022-06-09 15:19:20,694][root][INFO] - Step 18135040 @ 3069.5 SPS. Inference batcher size: 100. Learner queue size: 64. Other stats: (train_seconds = 5923.6, step = 18135040, mean_episode_return = 30.01, mean_episode_step = 2144.3, total_loss = -120.4, pg_loss = -127.87, baseline_loss = 22.176, entropy_loss = -14.704, learner_queue_size = 64, _tick = 2652, _time = 1.6548e+09)
[2022-06-09 15:19:25,698][root][INFO] - Step 18150400 @ 3069.5 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 5928.6, step = 18150400, mean_episode_return = None, mean_episode_step = 1814.4, total_loss = -79.377, pg_loss = -78.086, baseline_loss = 13.492, entropy_loss = -14.783, learner_queue_size = 64, _tick = 2654, _time = 1.6548e+09)
[2022-06-09 15:19:30,702][root][INFO] - Step 18165760 @ 3069.5 SPS. Inference batcher size: 74. Learner queue size: 64. Other stats: (train_seconds = 5933.6, step = 18165760, mean_episode_return = -10.69, mean_episode_step = 1828.6, total_loss = -92.592, pg_loss = -96.196, baseline_loss = 18.367, entropy_loss = -14.763, learner_queue_size = 64, _tick = 2657, _time = 1.6548e+09)
[2022-06-09 15:19:35,706][root][INFO] - Step 18181120 @ 3069.6 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 5938.6, step = 18181120, mean_episode_return = -23.939, mean_episode_step = 1760.9, total_loss = -92.995, pg_loss = -98.264, baseline_loss = 20.213, entropy_loss = -14.944, learner_queue_size = 64, _tick = 2659, _time = 1.6548e+09)
[2022-06-09 15:19:40,710][root][INFO] - Step 18196480 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 5943.6, step = 18196480, mean_episode_return = -15.12, mean_episode_step = 2024.6, total_loss = 99.446, pg_loss = 88.393, baseline_loss = 25.762, entropy_loss = -14.709, learner_queue_size = 64, _tick = 2662, _time = 1.6548e+09)
[2022-06-09 15:19:45,714][root][INFO] - Step 18211840 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 5948.6, step = 18211840, mean_episode_return = None, mean_episode_step = 2204.9, total_loss = 148.76, pg_loss = 131.97, baseline_loss = 31.968, entropy_loss = -15.182, learner_queue_size = 64, _tick = 2664, _time = 1.6548e+09)
[2022-06-09 15:19:50,718][root][INFO] - Step 18227200 @ 3069.5 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 5953.7, step = 18227200, mean_episode_return = None, mean_episode_step = 2246.5, total_loss = 138.68, pg_loss = 113.81, baseline_loss = 39.938, entropy_loss = -15.069, learner_queue_size = 64, _tick = 2666, _time = 1.6548e+09)
[2022-06-09 15:19:55,724][root][INFO] - Step 18242560 @ 3068.3 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 5958.7, step = 18242560, mean_episode_return = 90.258, mean_episode_step = 2132.5, total_loss = 66.243, pg_loss = 56.897, baseline_loss = 24.288, entropy_loss = -14.943, learner_queue_size = 64, _tick = 2669, _time = 1.6548e+09)
[2022-06-09 15:20:00,730][root][INFO] - Step 18257920 @ 3068.3 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 5963.7, step = 18257920, mean_episode_return = 61.882, mean_episode_step = 2126.2, total_loss = 72.219, pg_loss = 56.936, baseline_loss = 30.348, entropy_loss = -15.065, learner_queue_size = 64, _tick = 2672, _time = 1.6548e+09)
[2022-06-09 15:20:05,734][root][INFO] - Step 18278400 @ 4092.6 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 5968.7, step = 18278400, mean_episode_return = 56.836, mean_episode_step = 2263.3, total_loss = 53.459, pg_loss = 34.315, baseline_loss = 34.4, entropy_loss = -15.255, learner_queue_size = 64, _tick = 2676, _time = 1.6548e+09)
[2022-06-09 15:20:10,738][root][INFO] - Step 18293760 @ 3069.6 SPS. Inference batcher size: 68. Learner queue size: 64. Other stats: (train_seconds = 5973.7, step = 18293760, mean_episode_return = 85.447, mean_episode_step = 1686.2, total_loss = 6.7899, pg_loss = 1.9857, baseline_loss = 20.095, entropy_loss = -15.291, learner_queue_size = 64, _tick = 2679, _time = 1.6548e+09)
[2022-06-09 15:20:15,742][root][INFO] - Step 18309120 @ 3069.5 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 5978.7, step = 18309120, mean_episode_return = 56.516, mean_episode_step = 2065.5, total_loss = 58.472, pg_loss = 33.097, baseline_loss = 41.03, entropy_loss = -15.655, learner_queue_size = 64, _tick = 2681, _time = 1.6548e+09)
[2022-06-09 15:20:20,746][root][INFO] - Step 18324480 @ 3069.5 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 5983.7, step = 18324480, mean_episode_return = 73.948, mean_episode_step = 1645.6, total_loss = -106.11, pg_loss = -103.26, baseline_loss = 12.757, entropy_loss = -15.608, learner_queue_size = 64, _tick = 2684, _time = 1.6548e+09)
[2022-06-09 15:20:25,750][root][INFO] - Step 18339840 @ 3069.6 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 5988.7, step = 18339840, mean_episode_return = 27.76, mean_episode_step = 1876.5, total_loss = 47.927, pg_loss = 33.799, baseline_loss = 29.93, entropy_loss = -15.802, learner_queue_size = 64, _tick = 2687, _time = 1.6548e+09)
[2022-06-09 15:20:30,754][root][INFO] - Step 18355200 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 5993.7, step = 18355200, mean_episode_return = None, mean_episode_step = 2017.7, total_loss = 111.75, pg_loss = 105.81, baseline_loss = 21.52, entropy_loss = -15.58, learner_queue_size = 64, _tick = 2689, _time = 1.6548e+09)
[2022-06-09 15:20:35,758][root][INFO] - Step 18370560 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 5998.7, step = 18370560, mean_episode_return = 153.61, mean_episode_step = 1579.0, total_loss = 68.483, pg_loss = 57.445, baseline_loss = 26.824, entropy_loss = -15.786, learner_queue_size = 64, _tick = 2692, _time = 1.6548e+09)
[2022-06-09 15:20:40,762][root][INFO] - Step 18385920 @ 3069.6 SPS. Inference batcher size: 8. Learner queue size: 64. Other stats: (train_seconds = 6003.7, step = 18385920, mean_episode_return = 119.56, mean_episode_step = 1578.0, total_loss = 389.84, pg_loss = 275.84, baseline_loss = 129.44, entropy_loss = -15.44, learner_queue_size = 64, _tick = 2695, _time = 1.6548e+09)
[2022-06-09 15:20:45,766][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 15:20:46,283][root][INFO] - Step 18401280 @ 3069.5 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 6008.7, step = 18406400, mean_episode_return = 29.25, mean_episode_step = 1490.9, total_loss = 25.804, pg_loss = 14.09, baseline_loss = 27.296, entropy_loss = -15.582, learner_queue_size = 64, _tick = 2699, _time = 1.6548e+09)
[2022-06-09 15:20:51,286][root][INFO] - Step 18421760 @ 3710.1 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 6014.2, step = 18421760, mean_episode_return = -4.1506, mean_episode_step = 1894.2, total_loss = 87.246, pg_loss = 72.961, baseline_loss = 29.886, entropy_loss = -15.602, learner_queue_size = 64, _tick = 2702, _time = 1.6548e+09)
[2022-06-09 15:20:56,291][root][INFO] - Step 18437120 @ 3069.2 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 6019.2, step = 18437120, mean_episode_return = 2.0762, mean_episode_step = 1731.6, total_loss = -201.86, pg_loss = -202.17, baseline_loss = 15.924, entropy_loss = -15.62, learner_queue_size = 64, _tick = 2705, _time = 1.6548e+09)
[2022-06-09 15:21:01,294][root][INFO] - Step 18452480 @ 3069.9 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 6024.2, step = 18452480, mean_episode_return = 44.015, mean_episode_step = 1527.5, total_loss = 167.51, pg_loss = 140.08, baseline_loss = 42.77, entropy_loss = -15.343, learner_queue_size = 64, _tick = 2707, _time = 1.6548e+09)
[2022-06-09 15:21:06,298][root][INFO] - Step 18467840 @ 3069.4 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 6029.2, step = 18467840, mean_episode_return = 56.127, mean_episode_step = 1680.1, total_loss = -85.02, pg_loss = -86.725, baseline_loss = 16.991, entropy_loss = -15.286, learner_queue_size = 64, _tick = 2709, _time = 1.6548e+09)
[2022-06-09 15:21:11,302][root][INFO] - Step 18483200 @ 3069.7 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 6034.2, step = 18483200, mean_episode_return = 70.775, mean_episode_step = 1561.7, total_loss = 1230.1, pg_loss = 640.9, baseline_loss = 604.6, entropy_loss = -15.37, learner_queue_size = 64, _tick = 2712, _time = 1.6548e+09)
[2022-06-09 15:21:16,304][root][INFO] - Step 18498560 @ 3070.8 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 6039.2, step = 18498560, mean_episode_return = 30.616, mean_episode_step = 1526.8, total_loss = 39.351, pg_loss = 32.76, baseline_loss = 21.568, entropy_loss = -14.976, learner_queue_size = 64, _tick = 2715, _time = 1.6548e+09)
[2022-06-09 15:21:21,310][root][INFO] - Step 18513920 @ 3068.3 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 6044.2, step = 18513920, mean_episode_return = 29.241, mean_episode_step = 1587.7, total_loss = 110.55, pg_loss = 79.612, baseline_loss = 45.943, entropy_loss = -15.003, learner_queue_size = 64, _tick = 2716, _time = 1.6548e+09)
[2022-06-09 15:21:26,314][root][INFO] - Step 18529280 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 6049.3, step = 18529280, mean_episode_return = 9.0991, mean_episode_step = 1280.8, total_loss = 34.406, pg_loss = 25.638, baseline_loss = 23.619, entropy_loss = -14.851, learner_queue_size = 64, _tick = 2719, _time = 1.6548e+09)
[2022-06-09 15:21:31,318][root][INFO] - Step 18544640 @ 3069.6 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 6054.3, step = 18544640, mean_episode_return = None, mean_episode_step = 1705.3, total_loss = 79.478, pg_loss = 60.216, baseline_loss = 34.168, entropy_loss = -14.906, learner_queue_size = 64, _tick = 2720, _time = 1.6548e+09)
[2022-06-09 15:21:36,324][root][INFO] - Step 18560000 @ 3068.3 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 6059.3, step = 18560000, mean_episode_return = None, mean_episode_step = 1907.6, total_loss = 126.76, pg_loss = 105.27, baseline_loss = 36.619, entropy_loss = -15.133, learner_queue_size = 64, _tick = 2722, _time = 1.6548e+09)
[2022-06-09 15:21:41,330][root][INFO] - Step 18580480 @ 4091.1 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 6064.3, step = 18580480, mean_episode_return = 51.521, mean_episode_step = 1681.4, total_loss = -1.5348, pg_loss = -10.615, baseline_loss = 24.247, entropy_loss = -15.167, learner_queue_size = 64, _tick = 2726, _time = 1.6548e+09)
[2022-06-09 15:21:46,334][root][INFO] - Step 18595840 @ 3069.6 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 6069.3, step = 18595840, mean_episode_return = 33.556, mean_episode_step = 1820.9, total_loss = -233.27, pg_loss = -225.28, baseline_loss = 7.0453, entropy_loss = -15.032, learner_queue_size = 64, _tick = 2729, _time = 1.6548e+09)
[2022-06-09 15:21:51,338][root][INFO] - Step 18611200 @ 3069.5 SPS. Inference batcher size: 86. Learner queue size: 64. Other stats: (train_seconds = 6074.3, step = 18611200, mean_episode_return = None, mean_episode_step = 1870.0, total_loss = -34.188, pg_loss = -38.318, baseline_loss = 18.927, entropy_loss = -14.798, learner_queue_size = 64, _tick = 2730, _time = 1.6548e+09)
[2022-06-09 15:21:56,342][root][INFO] - Step 18626560 @ 3069.6 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 6079.3, step = 18626560, mean_episode_return = -16.661, mean_episode_step = 1740.3, total_loss = 103.02, pg_loss = 75.97, baseline_loss = 41.705, entropy_loss = -14.651, learner_queue_size = 64, _tick = 2732, _time = 1.6548e+09)
[2022-06-09 15:22:01,347][root][INFO] - Step 18641920 @ 3069.0 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 6084.3, step = 18641920, mean_episode_return = 43.262, mean_episode_step = 1693.6, total_loss = -8.6672, pg_loss = -29.424, baseline_loss = 35.287, entropy_loss = -14.53, learner_queue_size = 64, _tick = 2734, _time = 1.6548e+09)
[2022-06-09 15:22:06,350][root][INFO] - Step 18657280 @ 3070.1 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 6089.3, step = 18657280, mean_episode_return = None, mean_episode_step = 1791.8, total_loss = 471.77, pg_loss = 384.64, baseline_loss = 101.87, entropy_loss = -14.736, learner_queue_size = 64, _tick = 2736, _time = 1.6548e+09)
[2022-06-09 15:22:11,354][root][INFO] - Step 18672640 @ 3069.5 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 6094.3, step = 18672640, mean_episode_return = 25.41, mean_episode_step = 1810.5, total_loss = 22.53, pg_loss = -8.1231, baseline_loss = 45.283, entropy_loss = -14.63, learner_queue_size = 64, _tick = 2738, _time = 1.6548e+09)
[2022-06-09 15:22:16,358][root][INFO] - Step 18693120 @ 4092.7 SPS. Inference batcher size: 82. Learner queue size: 64. Other stats: (train_seconds = 6099.3, step = 18693120, mean_episode_return = 5.57, mean_episode_step = 1990.0, total_loss = -226.08, pg_loss = -230.43, baseline_loss = 18.938, entropy_loss = -14.588, learner_queue_size = 64, _tick = 2742, _time = 1.6548e+09)
[2022-06-09 15:22:21,362][root][INFO] - Step 18708480 @ 3069.6 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 6104.3, step = 18708480, mean_episode_return = 55.09, mean_episode_step = 2029.9, total_loss = 331.38, pg_loss = 249.16, baseline_loss = 96.708, entropy_loss = -14.484, learner_queue_size = 64, _tick = 2745, _time = 1.6548e+09)
[2022-06-09 15:22:26,366][root][INFO] - Step 18723840 @ 3069.5 SPS. Inference batcher size: 67. Learner queue size: 64. Other stats: (train_seconds = 6109.3, step = 18723840, mean_episode_return = None, mean_episode_step = 2033.7, total_loss = 79.313, pg_loss = 68.716, baseline_loss = 25.048, entropy_loss = -14.451, learner_queue_size = 64, _tick = 2747, _time = 1.6548e+09)
[2022-06-09 15:22:31,370][root][INFO] - Step 18739200 @ 3069.6 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 6114.3, step = 18739200, mean_episode_return = 36.218, mean_episode_step = 1917.5, total_loss = -21.874, pg_loss = -32.571, baseline_loss = 25.388, entropy_loss = -14.691, learner_queue_size = 64, _tick = 2749, _time = 1.6548e+09)
[2022-06-09 15:22:36,374][root][INFO] - Step 18754560 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 6119.3, step = 18754560, mean_episode_return = 35.023, mean_episode_step = 1899.8, total_loss = -218.21, pg_loss = -227.38, baseline_loss = 23.912, entropy_loss = -14.75, learner_queue_size = 64, _tick = 2752, _time = 1.6548e+09)
[2022-06-09 15:22:41,378][root][INFO] - Step 18769920 @ 3069.6 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 6124.3, step = 18769920, mean_episode_return = 14.416, mean_episode_step = 1680.2, total_loss = -151.84, pg_loss = -161.56, baseline_loss = 24.459, entropy_loss = -14.736, learner_queue_size = 64, _tick = 2755, _time = 1.6548e+09)
[2022-06-09 15:22:46,382][root][INFO] - Step 18785280 @ 3069.5 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 6129.3, step = 18785280, mean_episode_return = None, mean_episode_step = 1769.5, total_loss = 259.43, pg_loss = 198.43, baseline_loss = 75.983, entropy_loss = -14.985, learner_queue_size = 64, _tick = 2757, _time = 1.6548e+09)
[2022-06-09 15:22:51,386][root][INFO] - Step 18800640 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 6134.3, step = 18800640, mean_episode_return = 91.227, mean_episode_step = 1879.0, total_loss = -108.29, pg_loss = -122.23, baseline_loss = 29.027, entropy_loss = -15.085, learner_queue_size = 64, _tick = 2760, _time = 1.6548e+09)
[2022-06-09 15:22:56,390][root][INFO] - Step 18816000 @ 3069.4 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 6139.3, step = 18816000, mean_episode_return = 0.90978, mean_episode_step = 1584.7, total_loss = -19.982, pg_loss = -30.248, baseline_loss = 25.031, entropy_loss = -14.766, learner_queue_size = 64, _tick = 2763, _time = 1.6548e+09)
[2022-06-09 15:23:01,394][root][INFO] - Step 18831360 @ 3069.8 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 6144.3, step = 18831360, mean_episode_return = 15.985, mean_episode_step = 1840.4, total_loss = 8.573, pg_loss = -3.6474, baseline_loss = 26.943, entropy_loss = -14.722, learner_queue_size = 64, _tick = 2766, _time = 1.6548e+09)
[2022-06-09 15:23:06,398][root][INFO] - Step 18846720 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 6149.3, step = 18846720, mean_episode_return = 66.755, mean_episode_step = 2044.9, total_loss = -164.85, pg_loss = -157.99, baseline_loss = 7.293, entropy_loss = -14.152, learner_queue_size = 64, _tick = 2768, _time = 1.6548e+09)
[2022-06-09 15:23:11,402][root][INFO] - Step 18867200 @ 4092.8 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 6154.3, step = 18867200, mean_episode_return = 36.94, mean_episode_step = 1976.6, total_loss = -132.95, pg_loss = -144.78, baseline_loss = 25.885, entropy_loss = -14.054, learner_queue_size = 64, _tick = 2771, _time = 1.6548e+09)
[2022-06-09 15:23:16,406][root][INFO] - Step 18882560 @ 3069.4 SPS. Inference batcher size: 71. Learner queue size: 64. Other stats: (train_seconds = 6159.3, step = 18882560, mean_episode_return = 33.254, mean_episode_step = 1900.6, total_loss = -47.562, pg_loss = -60.755, baseline_loss = 27.079, entropy_loss = -13.885, learner_queue_size = 64, _tick = 2774, _time = 1.6548e+09)
[2022-06-09 15:23:21,410][root][INFO] - Step 18897920 @ 3069.6 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 6164.3, step = 18897920, mean_episode_return = 28.211, mean_episode_step = 1785.4, total_loss = -67.506, pg_loss = -69.574, baseline_loss = 15.829, entropy_loss = -13.76, learner_queue_size = 64, _tick = 2776, _time = 1.6548e+09)
[2022-06-09 15:23:26,414][root][INFO] - Step 18913280 @ 3069.6 SPS. Inference batcher size: 3. Learner queue size: 64. Other stats: (train_seconds = 6169.3, step = 18913280, mean_episode_return = 95.688, mean_episode_step = 1739.7, total_loss = -54.69, pg_loss = -60.601, baseline_loss = 19.865, entropy_loss = -13.955, learner_queue_size = 64, _tick = 2779, _time = 1.6548e+09)
[2022-06-09 15:23:31,416][root][INFO] - Step 18928640 @ 3070.6 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 6174.4, step = 18928640, mean_episode_return = 43.508, mean_episode_step = 1872.7, total_loss = 170.58, pg_loss = 141.64, baseline_loss = 42.812, entropy_loss = -13.867, learner_queue_size = 64, _tick = 2782, _time = 1.6548e+09)
[2022-06-09 15:23:36,422][root][INFO] - Step 18944000 @ 3068.4 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 6179.4, step = 18944000, mean_episode_return = 122.66, mean_episode_step = 1803.7, total_loss = 46.93, pg_loss = 24.894, baseline_loss = 36.063, entropy_loss = -14.028, learner_queue_size = 64, _tick = 2784, _time = 1.6548e+09)
[2022-06-09 15:23:41,426][root][INFO] - Step 18959360 @ 3069.6 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 6184.4, step = 18959360, mean_episode_return = 38.682, mean_episode_step = 1887.4, total_loss = 67.404, pg_loss = 50.174, baseline_loss = 31.186, entropy_loss = -13.956, learner_queue_size = 64, _tick = 2786, _time = 1.6548e+09)
[2022-06-09 15:23:46,431][root][INFO] - Step 18979840 @ 4092.0 SPS. Inference batcher size: 101. Learner queue size: 64. Other stats: (train_seconds = 6189.4, step = 18979840, mean_episode_return = -5.1, mean_episode_step = 1751.8, total_loss = -24.603, pg_loss = -32.8, baseline_loss = 22.001, entropy_loss = -13.805, learner_queue_size = 64, _tick = 2789, _time = 1.6548e+09)
[2022-06-09 15:23:51,434][root][INFO] - Step 18995200 @ 3070.0 SPS. Inference batcher size: 91. Learner queue size: 64. Other stats: (train_seconds = 6194.4, step = 18995200, mean_episode_return = 38.226, mean_episode_step = 2047.4, total_loss = 5.6277, pg_loss = -12.412, baseline_loss = 31.897, entropy_loss = -13.857, learner_queue_size = 64, _tick = 2792, _time = 1.6548e+09)
[2022-06-09 15:23:56,438][root][INFO] - Step 19010560 @ 3069.5 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 6199.4, step = 19010560, mean_episode_return = None, mean_episode_step = 1841.2, total_loss = 97.269, pg_loss = 82.33, baseline_loss = 28.303, entropy_loss = -13.364, learner_queue_size = 64, _tick = 2793, _time = 1.6548e+09)
[2022-06-09 15:24:01,442][root][INFO] - Step 19025920 @ 3069.5 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 6204.4, step = 19025920, mean_episode_return = 59.843, mean_episode_step = 1998.7, total_loss = -83.496, pg_loss = -89.191, baseline_loss = 19.259, entropy_loss = -13.564, learner_queue_size = 64, _tick = 2795, _time = 1.6548e+09)
[2022-06-09 15:24:06,446][root][INFO] - Step 19041280 @ 3069.6 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 6209.4, step = 19041280, mean_episode_return = None, mean_episode_step = 1999.9, total_loss = -132.24, pg_loss = -126.06, baseline_loss = 7.3662, entropy_loss = -13.547, learner_queue_size = 64, _tick = 2796, _time = 1.6548e+09)
[2022-06-09 15:24:11,450][root][INFO] - Step 19056640 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 6214.4, step = 19056640, mean_episode_return = 57.091, mean_episode_step = 2410.1, total_loss = -188.75, pg_loss = -179.5, baseline_loss = 4.3655, entropy_loss = -13.62, learner_queue_size = 64, _tick = 2799, _time = 1.6548e+09)
[2022-06-09 15:24:16,454][root][INFO] - Step 19072000 @ 3069.5 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 6219.4, step = 19072000, mean_episode_return = 54.782, mean_episode_step = 2356.2, total_loss = -151.69, pg_loss = -147.93, baseline_loss = 9.9701, entropy_loss = -13.734, learner_queue_size = 64, _tick = 2801, _time = 1.6548e+09)
[2022-06-09 15:24:21,458][root][INFO] - Step 19087360 @ 3069.5 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 6224.4, step = 19087360, mean_episode_return = 7.5794, mean_episode_step = 2119.3, total_loss = 260.56, pg_loss = 225.2, baseline_loss = 49.176, entropy_loss = -13.813, learner_queue_size = 64, _tick = 2804, _time = 1.6548e+09)
[2022-06-09 15:24:26,462][root][INFO] - Step 19102720 @ 3069.6 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 6229.4, step = 19102720, mean_episode_return = 50.661, mean_episode_step = 2088.2, total_loss = 71.268, pg_loss = 60.493, baseline_loss = 24.422, entropy_loss = -13.646, learner_queue_size = 64, _tick = 2806, _time = 1.6548e+09)
[2022-06-09 15:24:31,466][root][INFO] - Step 19118080 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 6234.4, step = 19118080, mean_episode_return = 10.08, mean_episode_step = 2392.4, total_loss = 35.441, pg_loss = 19.952, baseline_loss = 29.192, entropy_loss = -13.703, learner_queue_size = 64, _tick = 2808, _time = 1.6548e+09)
[2022-06-09 15:24:36,470][root][INFO] - Step 19138560 @ 4092.8 SPS. Inference batcher size: 74. Learner queue size: 64. Other stats: (train_seconds = 6239.4, step = 19138560, mean_episode_return = None, mean_episode_step = 2307.9, total_loss = -171.75, pg_loss = -158.33, baseline_loss = 1.0083, entropy_loss = -14.435, learner_queue_size = 64, _tick = 2811, _time = 1.6548e+09)
[2022-06-09 15:24:41,474][root][INFO] - Step 19153920 @ 3069.5 SPS. Inference batcher size: 74. Learner queue size: 64. Other stats: (train_seconds = 6244.4, step = 19153920, mean_episode_return = -2.3854, mean_episode_step = 2487.7, total_loss = -108.33, pg_loss = -108.33, baseline_loss = 14.367, entropy_loss = -14.36, learner_queue_size = 64, _tick = 2813, _time = 1.6548e+09)
[2022-06-09 15:24:46,478][root][INFO] - Step 19169280 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 6249.4, step = 19169280, mean_episode_return = 31.635, mean_episode_step = 2358.4, total_loss = 44.403, pg_loss = 33.305, baseline_loss = 25.415, entropy_loss = -14.318, learner_queue_size = 64, _tick = 2816, _time = 1.6548e+09)
[2022-06-09 15:24:51,484][root][INFO] - Step 19184640 @ 3068.2 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 6254.4, step = 19184640, mean_episode_return = 78.934, mean_episode_step = 2452.9, total_loss = -8.6007, pg_loss = -18.474, baseline_loss = 24.394, entropy_loss = -14.52, learner_queue_size = 64, _tick = 2819, _time = 1.6548e+09)
[2022-06-09 15:24:56,490][root][INFO] - Step 19200000 @ 3068.3 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 6259.4, step = 19200000, mean_episode_return = 34.78, mean_episode_step = 2524.4, total_loss = 83.331, pg_loss = 75.938, baseline_loss = 22.179, entropy_loss = -14.786, learner_queue_size = 64, _tick = 2822, _time = 1.6548e+09)
[2022-06-09 15:25:01,494][root][INFO] - Step 19215360 @ 3069.7 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 6264.4, step = 19215360, mean_episode_return = 34.691, mean_episode_step = 2132.4, total_loss = -28.432, pg_loss = -38.287, baseline_loss = 24.48, entropy_loss = -14.625, learner_queue_size = 64, _tick = 2825, _time = 1.6548e+09)
[2022-06-09 15:25:06,500][root][INFO] - Step 19230720 @ 3068.3 SPS. Inference batcher size: 15. Learner queue size: 64. Other stats: (train_seconds = 6269.4, step = 19230720, mean_episode_return = None, mean_episode_step = 1999.2, total_loss = 8.303, pg_loss = 10.506, baseline_loss = 12.136, entropy_loss = -14.339, learner_queue_size = 64, _tick = 2825, _time = 1.6548e+09)
[2022-06-09 15:25:11,506][root][INFO] - Step 19246080 @ 3068.4 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 6274.4, step = 19246080, mean_episode_return = None, mean_episode_step = 2710.5, total_loss = 44.714, pg_loss = 32.691, baseline_loss = 26.564, entropy_loss = -14.542, learner_queue_size = 64, _tick = 2826, _time = 1.6548e+09)
[2022-06-09 15:25:16,510][root][INFO] - Step 19261440 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 6279.4, step = 19261440, mean_episode_return = 60.388, mean_episode_step = 2369.1, total_loss = 47.142, pg_loss = 33.034, baseline_loss = 28.703, entropy_loss = -14.594, learner_queue_size = 64, _tick = 2828, _time = 1.6548e+09)
[2022-06-09 15:25:21,514][root][INFO] - Step 19281920 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 6284.4, step = 19281920, mean_episode_return = None, mean_episode_step = 2166.0, total_loss = 32.243, pg_loss = 24.761, baseline_loss = 21.944, entropy_loss = -14.462, learner_queue_size = 64, _tick = 2830, _time = 1.6548e+09)
[2022-06-09 15:25:26,518][root][INFO] - Step 19297280 @ 3069.4 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 6289.5, step = 19297280, mean_episode_return = 56.693, mean_episode_step = 2211.0, total_loss = 3.1624, pg_loss = 2.1195, baseline_loss = 15.828, entropy_loss = -14.785, learner_queue_size = 64, _tick = 2833, _time = 1.6548e+09)
[2022-06-09 15:25:31,522][root][INFO] - Step 19312640 @ 3069.7 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 6294.5, step = 19312640, mean_episode_return = 9.9745, mean_episode_step = 2304.8, total_loss = -15.165, pg_loss = -18.513, baseline_loss = 18.482, entropy_loss = -15.134, learner_queue_size = 64, _tick = 2836, _time = 1.6548e+09)
[2022-06-09 15:25:36,526][root][INFO] - Step 19328000 @ 3069.5 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 6299.5, step = 19328000, mean_episode_return = -1.4505, mean_episode_step = 2196.9, total_loss = 28.762, pg_loss = 22.643, baseline_loss = 21.18, entropy_loss = -15.061, learner_queue_size = 64, _tick = 2838, _time = 1.6548e+09)
[2022-06-09 15:25:41,530][root][INFO] - Step 19343360 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 6304.5, step = 19343360, mean_episode_return = 74.729, mean_episode_step = 2646.2, total_loss = 200.02, pg_loss = 178.91, baseline_loss = 36.292, entropy_loss = -15.182, learner_queue_size = 64, _tick = 2840, _time = 1.6548e+09)
[2022-06-09 15:25:46,534][root][INFO] - Step 19358720 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 6309.5, step = 19358720, mean_episode_return = 14.214, mean_episode_step = 2129.7, total_loss = -107.84, pg_loss = -101.72, baseline_loss = 9.1225, entropy_loss = -15.234, learner_queue_size = 64, _tick = 2843, _time = 1.6548e+09)
[2022-06-09 15:25:51,538][root][INFO] - Step 19374080 @ 3069.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 6314.5, step = 19374080, mean_episode_return = 12.48, mean_episode_step = 2340.3, total_loss = 84.467, pg_loss = 75.302, baseline_loss = 24.374, entropy_loss = -15.21, learner_queue_size = 64, _tick = 2845, _time = 1.6548e+09)
[2022-06-09 15:25:56,544][root][INFO] - Step 19389440 @ 3068.3 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 6319.5, step = 19389440, mean_episode_return = 4.9196, mean_episode_step = 1872.2, total_loss = -171.78, pg_loss = -164.78, baseline_loss = 8.3113, entropy_loss = -15.313, learner_queue_size = 64, _tick = 2847, _time = 1.6548e+09)
[2022-06-09 15:26:01,550][root][INFO] - Step 19404800 @ 3068.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 6324.5, step = 19404800, mean_episode_return = None, mean_episode_step = 2287.1, total_loss = -138.52, pg_loss = -129.24, baseline_loss = 6.1254, entropy_loss = -15.401, learner_queue_size = 64, _tick = 2849, _time = 1.6548e+09)
[2022-06-09 15:26:06,554][root][INFO] - Step 19425280 @ 4092.5 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 6329.5, step = 19425280, mean_episode_return = 26.304, mean_episode_step = 1898.7, total_loss = 118.09, pg_loss = 98.976, baseline_loss = 34.446, entropy_loss = -15.332, learner_queue_size = 64, _tick = 2852, _time = 1.6548e+09)
[2022-06-09 15:26:11,558][root][INFO] - Step 19440640 @ 3069.6 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 6334.5, step = 19440640, mean_episode_return = -15.21, mean_episode_step = 2228.1, total_loss = -92.899, pg_loss = -83.48, baseline_loss = 5.7528, entropy_loss = -15.171, learner_queue_size = 64, _tick = 2855, _time = 1.6548e+09)
[2022-06-09 15:26:16,562][root][INFO] - Step 19456000 @ 3069.5 SPS. Inference batcher size: 86. Learner queue size: 64. Other stats: (train_seconds = 6339.5, step = 19456000, mean_episode_return = None, mean_episode_step = 2463.7, total_loss = -97.394, pg_loss = -89.012, baseline_loss = 6.8895, entropy_loss = -15.271, learner_queue_size = 64, _tick = 2856, _time = 1.6548e+09)
[2022-06-09 15:26:21,566][root][INFO] - Step 19471360 @ 3069.6 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 6344.5, step = 19471360, mean_episode_return = 28.545, mean_episode_step = 2065.9, total_loss = -19.612, pg_loss = -20.284, baseline_loss = 15.69, entropy_loss = -15.017, learner_queue_size = 64, _tick = 2859, _time = 1.6548e+09)
[2022-06-09 15:26:26,570][root][INFO] - Step 19486720 @ 3069.5 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 6349.5, step = 19486720, mean_episode_return = 11.771, mean_episode_step = 2548.0, total_loss = 243.85, pg_loss = 213.94, baseline_loss = 45.107, entropy_loss = -15.199, learner_queue_size = 64, _tick = 2862, _time = 1.6548e+09)
[2022-06-09 15:26:31,574][root][INFO] - Step 19502080 @ 3069.6 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 6354.5, step = 19502080, mean_episode_return = None, mean_episode_step = 2217.8, total_loss = 218.34, pg_loss = 181.96, baseline_loss = 51.572, entropy_loss = -15.193, learner_queue_size = 64, _tick = 2863, _time = 1.6548e+09)
[2022-06-09 15:26:36,578][root][INFO] - Step 19517440 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 6359.5, step = 19517440, mean_episode_return = 45.651, mean_episode_step = 2146.1, total_loss = 508.86, pg_loss = 434.98, baseline_loss = 88.701, entropy_loss = -14.822, learner_queue_size = 64, _tick = 2866, _time = 1.6548e+09)
[2022-06-09 15:26:41,582][root][INFO] - Step 19532800 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 6364.5, step = 19532800, mean_episode_return = 83.525, mean_episode_step = 2299.2, total_loss = -215.36, pg_loss = -203.13, baseline_loss = 2.669, entropy_loss = -14.891, learner_queue_size = 64, _tick = 2869, _time = 1.6548e+09)
[2022-06-09 15:26:46,591][root][INFO] - Step 19548160 @ 3066.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 6369.5, step = 19548160, mean_episode_return = -5.3306, mean_episode_step = 2228.6, total_loss = -113.79, pg_loss = -110.01, baseline_loss = 11.083, entropy_loss = -14.855, learner_queue_size = 64, _tick = 2872, _time = 1.6548e+09)
[2022-06-09 15:26:51,599][root][INFO] - Step 19563520 @ 3066.8 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 6374.5, step = 19563520, mean_episode_return = 56.006, mean_episode_step = 2255.5, total_loss = 39.872, pg_loss = 29.581, baseline_loss = 24.992, entropy_loss = -14.7, learner_queue_size = 64, _tick = 2875, _time = 1.6548e+09)
[2022-06-09 15:26:56,602][root][INFO] - Step 19584000 @ 4093.9 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 6379.5, step = 19584000, mean_episode_return = 25.82, mean_episode_step = 2060.7, total_loss = 265.93, pg_loss = 233.1, baseline_loss = 47.625, entropy_loss = -14.8, learner_queue_size = 64, _tick = 2877, _time = 1.6548e+09)
[2022-06-09 15:27:01,606][root][INFO] - Step 19599360 @ 3069.6 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 6384.5, step = 19599360, mean_episode_return = 46.051, mean_episode_step = 2547.5, total_loss = -93.643, pg_loss = -92.078, baseline_loss = 13.476, entropy_loss = -15.04, learner_queue_size = 64, _tick = 2879, _time = 1.6548e+09)
[2022-06-09 15:27:06,610][root][INFO] - Step 19614720 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 6389.5, step = 19614720, mean_episode_return = 49.409, mean_episode_step = 2080.3, total_loss = -166.71, pg_loss = -167.13, baseline_loss = 15.432, entropy_loss = -15.015, learner_queue_size = 64, _tick = 2882, _time = 1.6548e+09)
[2022-06-09 15:27:11,614][root][INFO] - Step 19630080 @ 3069.5 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 6394.5, step = 19630080, mean_episode_return = 139.22, mean_episode_step = 2186.3, total_loss = -7.3153, pg_loss = -6.9316, baseline_loss = 14.65, entropy_loss = -15.034, learner_queue_size = 64, _tick = 2885, _time = 1.6548e+09)
[2022-06-09 15:27:16,618][root][INFO] - Step 19645440 @ 3069.5 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 6399.6, step = 19645440, mean_episode_return = 43.782, mean_episode_step = 2306.8, total_loss = -43.249, pg_loss = -39.317, baseline_loss = 11.053, entropy_loss = -14.985, learner_queue_size = 64, _tick = 2888, _time = 1.6548e+09)
[2022-06-09 15:27:21,622][root][INFO] - Step 19660800 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 6404.6, step = 19660800, mean_episode_return = None, mean_episode_step = 2280.5, total_loss = 121.89, pg_loss = 91.162, baseline_loss = 45.948, entropy_loss = -15.221, learner_queue_size = 64, _tick = 2890, _time = 1.6548e+09)
[2022-06-09 15:27:26,626][root][INFO] - Step 19676160 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 6409.6, step = 19676160, mean_episode_return = -43.719, mean_episode_step = 2141.8, total_loss = 88.778, pg_loss = 76.194, baseline_loss = 27.66, entropy_loss = -15.076, learner_queue_size = 64, _tick = 2892, _time = 1.6548e+09)
[2022-06-09 15:27:31,630][root][INFO] - Step 19691520 @ 3069.6 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 6414.6, step = 19691520, mean_episode_return = 64.322, mean_episode_step = 2239.2, total_loss = 77.853, pg_loss = 68.22, baseline_loss = 24.75, entropy_loss = -15.117, learner_queue_size = 64, _tick = 2895, _time = 1.6548e+09)
[2022-06-09 15:27:36,634][root][INFO] - Step 19706880 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 6419.6, step = 19706880, mean_episode_return = 17.12, mean_episode_step = 2252.8, total_loss = -58.214, pg_loss = -59.954, baseline_loss = 17.146, entropy_loss = -15.406, learner_queue_size = 64, _tick = 2897, _time = 1.6548e+09)
[2022-06-09 15:27:41,638][root][INFO] - Step 19722240 @ 3069.5 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 6424.6, step = 19722240, mean_episode_return = 62.488, mean_episode_step = 2455.9, total_loss = -106.07, pg_loss = -107.56, baseline_loss = 17.27, entropy_loss = -15.78, learner_queue_size = 64, _tick = 2899, _time = 1.6548e+09)
[2022-06-09 15:27:46,642][root][INFO] - Step 19742720 @ 4092.7 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 6429.6, step = 19742720, mean_episode_return = 27.137, mean_episode_step = 2039.2, total_loss = 141.61, pg_loss = 104.83, baseline_loss = 52.444, entropy_loss = -15.669, learner_queue_size = 64, _tick = 2902, _time = 1.6548e+09)
[2022-06-09 15:27:51,646][root][INFO] - Step 19758080 @ 3069.5 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 6434.6, step = 19758080, mean_episode_return = 49.344, mean_episode_step = 2142.3, total_loss = 137.93, pg_loss = 120.98, baseline_loss = 32.43, entropy_loss = -15.479, learner_queue_size = 64, _tick = 2904, _time = 1.6548e+09)
[2022-06-09 15:27:56,650][root][INFO] - Step 19773440 @ 3069.6 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 6439.6, step = 19773440, mean_episode_return = -30.821, mean_episode_step = 2108.4, total_loss = 110.35, pg_loss = 94.51, baseline_loss = 31.182, entropy_loss = -15.343, learner_queue_size = 64, _tick = 2907, _time = 1.6548e+09)
[2022-06-09 15:28:01,654][root][INFO] - Step 19788800 @ 3069.5 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 6444.6, step = 19788800, mean_episode_return = 134.87, mean_episode_step = 2205.5, total_loss = -116.9, pg_loss = -111.27, baseline_loss = 9.53, entropy_loss = -15.159, learner_queue_size = 64, _tick = 2910, _time = 1.6548e+09)
[2022-06-09 15:28:06,658][root][INFO] - Step 19804160 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 6449.6, step = 19804160, mean_episode_return = 31.265, mean_episode_step = 2503.1, total_loss = 252.29, pg_loss = 214.76, baseline_loss = 52.811, entropy_loss = -15.275, learner_queue_size = 64, _tick = 2913, _time = 1.6548e+09)
[2022-06-09 15:28:11,662][root][INFO] - Step 19819520 @ 3069.6 SPS. Inference batcher size: 2. Learner queue size: 64. Other stats: (train_seconds = 6454.6, step = 19819520, mean_episode_return = 18.27, mean_episode_step = 2633.8, total_loss = 52.566, pg_loss = 44.424, baseline_loss = 23.377, entropy_loss = -15.235, learner_queue_size = 64, _tick = 2915, _time = 1.6548e+09)
[2022-06-09 15:28:16,666][root][INFO] - Step 19834880 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 6459.6, step = 19834880, mean_episode_return = 45.185, mean_episode_step = 2506.6, total_loss = 120.58, pg_loss = 99.037, baseline_loss = 36.733, entropy_loss = -15.186, learner_queue_size = 64, _tick = 2917, _time = 1.6548e+09)
[2022-06-09 15:28:21,670][root][INFO] - Step 19850240 @ 3069.6 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 6464.6, step = 19850240, mean_episode_return = 73.656, mean_episode_step = 2118.4, total_loss = -202.66, pg_loss = -209.66, baseline_loss = 22.274, entropy_loss = -15.276, learner_queue_size = 64, _tick = 2920, _time = 1.6548e+09)
[2022-06-09 15:28:26,674][root][INFO] - Step 19865600 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 6469.6, step = 19865600, mean_episode_return = 59.16, mean_episode_step = 2257.2, total_loss = -6.5959, pg_loss = -12.625, baseline_loss = 21.283, entropy_loss = -15.254, learner_queue_size = 64, _tick = 2923, _time = 1.6548e+09)
[2022-06-09 15:28:31,678][root][INFO] - Step 19880960 @ 3069.6 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 6474.6, step = 19880960, mean_episode_return = 61.62, mean_episode_step = 2259.1, total_loss = 33.697, pg_loss = 21.693, baseline_loss = 27.557, entropy_loss = -15.553, learner_queue_size = 64, _tick = 2926, _time = 1.6548e+09)
[2022-06-09 15:28:36,682][root][INFO] - Step 19901440 @ 4092.7 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 6479.6, step = 19901440, mean_episode_return = 89.991, mean_episode_step = 2088.0, total_loss = -132.35, pg_loss = -129.98, baseline_loss = 13.055, entropy_loss = -15.419, learner_queue_size = 64, _tick = 2928, _time = 1.6548e+09)
[2022-06-09 15:28:41,686][root][INFO] - Step 19916800 @ 3069.5 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 6484.6, step = 19916800, mean_episode_return = 12.219, mean_episode_step = 2222.5, total_loss = 155.96, pg_loss = 140.86, baseline_loss = 30.356, entropy_loss = -15.255, learner_queue_size = 64, _tick = 2931, _time = 1.6548e+09)
[2022-06-09 15:28:46,690][root][INFO] - Step 19932160 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 6489.6, step = 19932160, mean_episode_return = 43.873, mean_episode_step = 2210.9, total_loss = -63.031, pg_loss = -59.929, baseline_loss = 12.136, entropy_loss = -15.238, learner_queue_size = 64, _tick = 2933, _time = 1.6548e+09)
[2022-06-09 15:28:51,694][root][INFO] - Step 19947520 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 6494.6, step = 19947520, mean_episode_return = None, mean_episode_step = 2359.8, total_loss = 366.99, pg_loss = 320.67, baseline_loss = 61.556, entropy_loss = -15.228, learner_queue_size = 64, _tick = 2934, _time = 1.6548e+09)
[2022-06-09 15:28:56,698][root][INFO] - Step 19962880 @ 3069.6 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 6499.6, step = 19962880, mean_episode_return = None, mean_episode_step = 2137.3, total_loss = 12.722, pg_loss = 10.831, baseline_loss = 17.015, entropy_loss = -15.123, learner_queue_size = 64, _tick = 2935, _time = 1.6548e+09)
[2022-06-09 15:29:01,702][root][INFO] - Step 19978240 @ 3069.5 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 6504.6, step = 19978240, mean_episode_return = 17.794, mean_episode_step = 2337.9, total_loss = -140.27, pg_loss = -140.81, baseline_loss = 15.73, entropy_loss = -15.192, learner_queue_size = 64, _tick = 2938, _time = 1.6548e+09)
[2022-06-09 15:29:06,706][root][INFO] - Step 19993600 @ 3069.6 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 6509.6, step = 19993600, mean_episode_return = 18.265, mean_episode_step = 2304.7, total_loss = -78.941, pg_loss = -81.411, baseline_loss = 17.813, entropy_loss = -15.343, learner_queue_size = 64, _tick = 2941, _time = 1.6548e+09)
[2022-06-09 15:29:11,710][root][INFO] - Step 20008960 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 6514.6, step = 20008960, mean_episode_return = 20.62, mean_episode_step = 2075.1, total_loss = -54.938, pg_loss = -48.203, baseline_loss = 8.2733, entropy_loss = -15.008, learner_queue_size = 64, _tick = 2943, _time = 1.6548e+09)
[2022-06-09 15:29:16,714][root][INFO] - Step 20024320 @ 3069.5 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 6519.6, step = 20024320, mean_episode_return = 25.316, mean_episode_step = 2208.4, total_loss = -189.17, pg_loss = -179.12, baseline_loss = 5.0373, entropy_loss = -15.083, learner_queue_size = 64, _tick = 2945, _time = 1.6548e+09)
[2022-06-09 15:29:21,718][root][INFO] - Step 20039680 @ 3069.5 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 6524.7, step = 20039680, mean_episode_return = 39.532, mean_episode_step = 2578.3, total_loss = -97.521, pg_loss = -87.92, baseline_loss = 5.4376, entropy_loss = -15.039, learner_queue_size = 64, _tick = 2947, _time = 1.6548e+09)
[2022-06-09 15:29:26,722][root][INFO] - Step 20055040 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 6529.7, step = 20055040, mean_episode_return = 40.813, mean_episode_step = 1937.9, total_loss = 187.19, pg_loss = 174.5, baseline_loss = 27.859, entropy_loss = -15.169, learner_queue_size = 64, _tick = 2949, _time = 1.6548e+09)
[2022-06-09 15:29:31,726][root][INFO] - Step 20075520 @ 4092.7 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 6534.7, step = 20075520, mean_episode_return = -34.77, mean_episode_step = 2005.7, total_loss = -22.516, pg_loss = -25.115, baseline_loss = 17.491, entropy_loss = -14.892, learner_queue_size = 64, _tick = 2953, _time = 1.6548e+09)
[2022-06-09 15:29:36,730][root][INFO] - Step 20090880 @ 3069.5 SPS. Inference batcher size: 74. Learner queue size: 64. Other stats: (train_seconds = 6539.7, step = 20090880, mean_episode_return = 24.68, mean_episode_step = 2369.2, total_loss = 234.33, pg_loss = 209.47, baseline_loss = 39.394, entropy_loss = -14.538, learner_queue_size = 64, _tick = 2955, _time = 1.6548e+09)
[2022-06-09 15:29:41,734][root][INFO] - Step 20106240 @ 3069.5 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 6544.7, step = 20106240, mean_episode_return = 20.29, mean_episode_step = 1987.9, total_loss = -141.3, pg_loss = -133.9, baseline_loss = 6.9555, entropy_loss = -14.349, learner_queue_size = 64, _tick = 2958, _time = 1.6548e+09)
[2022-06-09 15:29:46,738][root][INFO] - Step 20121600 @ 3069.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 6549.7, step = 20121600, mean_episode_return = 33.231, mean_episode_step = 2292.2, total_loss = 76.103, pg_loss = 60.599, baseline_loss = 29.639, entropy_loss = -14.135, learner_queue_size = 64, _tick = 2961, _time = 1.6548e+09)
[2022-06-09 15:29:51,742][root][INFO] - Step 20136960 @ 3069.6 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 6554.7, step = 20136960, mean_episode_return = 34.74, mean_episode_step = 2348.4, total_loss = 214.31, pg_loss = 168.08, baseline_loss = 60.422, entropy_loss = -14.193, learner_queue_size = 64, _tick = 2963, _time = 1.6548e+09)
[2022-06-09 15:29:56,746][root][INFO] - Step 20152320 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 6559.7, step = 20152320, mean_episode_return = None, mean_episode_step = 2273.9, total_loss = 220.73, pg_loss = 204.55, baseline_loss = 30.371, entropy_loss = -14.2, learner_queue_size = 64, _tick = 2965, _time = 1.6548e+09)
[2022-06-09 15:30:01,750][root][INFO] - Step 20167680 @ 3069.6 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 6564.7, step = 20167680, mean_episode_return = 90.707, mean_episode_step = 2333.4, total_loss = 376.0, pg_loss = 317.36, baseline_loss = 72.835, entropy_loss = -14.197, learner_queue_size = 64, _tick = 2968, _time = 1.6548e+09)
[2022-06-09 15:30:06,759][root][INFO] - Step 20183040 @ 3066.4 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 6569.7, step = 20183040, mean_episode_return = 30.9, mean_episode_step = 2140.0, total_loss = 41.26, pg_loss = 31.812, baseline_loss = 23.782, entropy_loss = -14.334, learner_queue_size = 64, _tick = 2970, _time = 1.6548e+09)
[2022-06-09 15:30:11,762][root][INFO] - Step 20198400 @ 3070.3 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 6574.7, step = 20198400, mean_episode_return = 56.672, mean_episode_step = 2415.2, total_loss = 99.214, pg_loss = 68.057, baseline_loss = 45.822, entropy_loss = -14.664, learner_queue_size = 64, _tick = 2972, _time = 1.6548e+09)
[2022-06-09 15:30:16,766][root][INFO] - Step 20218880 @ 4092.8 SPS. Inference batcher size: 93. Learner queue size: 64. Other stats: (train_seconds = 6579.7, step = 20218880, mean_episode_return = 13.23, mean_episode_step = 2263.9, total_loss = -131.43, pg_loss = -129.01, baseline_loss = 12.104, entropy_loss = -14.53, learner_queue_size = 64, _tick = 2975, _time = 1.6548e+09)
[2022-06-09 15:30:21,770][root][INFO] - Step 20234240 @ 3069.5 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 6584.7, step = 20234240, mean_episode_return = None, mean_episode_step = 2143.0, total_loss = 566.21, pg_loss = 424.05, baseline_loss = 157.06, entropy_loss = -14.891, learner_queue_size = 64, _tick = 2977, _time = 1.6548e+09)
[2022-06-09 15:30:26,776][root][INFO] - Step 20249600 @ 3068.3 SPS. Inference batcher size: 85. Learner queue size: 64. Other stats: (train_seconds = 6589.7, step = 20249600, mean_episode_return = 80.496, mean_episode_step = 2284.5, total_loss = 310.11, pg_loss = 266.18, baseline_loss = 58.681, entropy_loss = -14.758, learner_queue_size = 64, _tick = 2980, _time = 1.6548e+09)
[2022-06-09 15:30:31,782][root][INFO] - Step 20264960 @ 3068.4 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 6594.7, step = 20264960, mean_episode_return = 47.399, mean_episode_step = 2292.7, total_loss = 27.077, pg_loss = 8.4516, baseline_loss = 33.463, entropy_loss = -14.837, learner_queue_size = 64, _tick = 2983, _time = 1.6548e+09)
[2022-06-09 15:30:36,786][root][INFO] - Step 20280320 @ 3069.5 SPS. Inference batcher size: 75. Learner queue size: 64. Other stats: (train_seconds = 6599.7, step = 20280320, mean_episode_return = 15.5, mean_episode_step = 2545.4, total_loss = -69.582, pg_loss = -70.935, baseline_loss = 16.004, entropy_loss = -14.651, learner_queue_size = 64, _tick = 2985, _time = 1.6548e+09)
[2022-06-09 15:30:41,790][root][INFO] - Step 20295680 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 6604.7, step = 20295680, mean_episode_return = None, mean_episode_step = 2040.3, total_loss = -27.161, pg_loss = -30.899, baseline_loss = 18.561, entropy_loss = -14.823, learner_queue_size = 64, _tick = 2986, _time = 1.6548e+09)
[2022-06-09 15:30:46,794][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 15:30:47,016][root][INFO] - Step 20311040 @ 3069.5 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 6609.7, step = 20311040, mean_episode_return = 9.0102, mean_episode_step = 2171.3, total_loss = 390.51, pg_loss = 255.25, baseline_loss = 150.35, entropy_loss = -15.094, learner_queue_size = 64, _tick = 2988, _time = 1.6548e+09)
[2022-06-09 15:30:52,022][root][INFO] - Step 20326400 @ 2938.1 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 6615.0, step = 20326400, mean_episode_return = 107.55, mean_episode_step = 2401.0, total_loss = 86.757, pg_loss = 76.893, baseline_loss = 24.686, entropy_loss = -14.822, learner_queue_size = 64, _tick = 2991, _time = 1.6548e+09)
[2022-06-09 15:30:57,026][root][INFO] - Step 20341760 @ 3069.6 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 6620.0, step = 20341760, mean_episode_return = None, mean_episode_step = 2607.7, total_loss = 28.223, pg_loss = 26.696, baseline_loss = 16.118, entropy_loss = -14.591, learner_queue_size = 64, _tick = 2991, _time = 1.6548e+09)
[2022-06-09 15:31:02,030][root][INFO] - Step 20357120 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 6625.0, step = 20357120, mean_episode_return = 79.672, mean_episode_step = 2584.6, total_loss = -59.62, pg_loss = -65.462, baseline_loss = 20.093, entropy_loss = -14.251, learner_queue_size = 64, _tick = 2994, _time = 1.6548e+09)
[2022-06-09 15:31:07,034][root][INFO] - Step 20377600 @ 4092.8 SPS. Inference batcher size: 5. Learner queue size: 64. Other stats: (train_seconds = 6630.0, step = 20377600, mean_episode_return = 41.022, mean_episode_step = 2294.9, total_loss = -45.481, pg_loss = -43.796, baseline_loss = 12.629, entropy_loss = -14.314, learner_queue_size = 64, _tick = 2998, _time = 1.6548e+09)
[2022-06-09 15:31:12,038][root][INFO] - Step 20392960 @ 3069.7 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 6635.0, step = 20392960, mean_episode_return = 31.945, mean_episode_step = 2321.2, total_loss = 131.12, pg_loss = 116.08, baseline_loss = 29.458, entropy_loss = -14.418, learner_queue_size = 64, _tick = 3001, _time = 1.6548e+09)
[2022-06-09 15:31:17,042][root][INFO] - Step 20408320 @ 3069.4 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 6640.0, step = 20408320, mean_episode_return = 76.577, mean_episode_step = 2478.5, total_loss = 296.31, pg_loss = 248.68, baseline_loss = 61.868, entropy_loss = -14.235, learner_queue_size = 64, _tick = 3002, _time = 1.6548e+09)
[2022-06-09 15:31:22,046][root][INFO] - Step 20423680 @ 3069.5 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 6645.0, step = 20423680, mean_episode_return = 21.28, mean_episode_step = 2186.2, total_loss = -7.5905, pg_loss = -9.2613, baseline_loss = 15.957, entropy_loss = -14.286, learner_queue_size = 64, _tick = 3004, _time = 1.6548e+09)
[2022-06-09 15:31:27,082][root][INFO] - Step 20439040 @ 3050.0 SPS. Inference batcher size: 73. Learner queue size: 64. Other stats: (train_seconds = 6650.0, step = 20439040, mean_episode_return = 17.655, mean_episode_step = 2468.0, total_loss = -17.829, pg_loss = -22.395, baseline_loss = 19.037, entropy_loss = -14.47, learner_queue_size = 64, _tick = 3007, _time = 1.6548e+09)
[2022-06-09 15:31:32,086][root][INFO] - Step 20454400 @ 3069.6 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 6655.0, step = 20454400, mean_episode_return = None, mean_episode_step = 2719.7, total_loss = 109.76, pg_loss = 101.08, baseline_loss = 23.635, entropy_loss = -14.955, learner_queue_size = 64, _tick = 3008, _time = 1.6548e+09)
[2022-06-09 15:31:37,090][root][INFO] - Step 20469760 @ 3069.5 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 6660.0, step = 20469760, mean_episode_return = None, mean_episode_step = 1805.2, total_loss = 141.07, pg_loss = 130.8, baseline_loss = 25.391, entropy_loss = -15.118, learner_queue_size = 64, _tick = 3010, _time = 1.6548e+09)
[2022-06-09 15:31:42,094][root][INFO] - Step 20485120 @ 3069.5 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 6665.0, step = 20485120, mean_episode_return = 39.359, mean_episode_step = 2795.6, total_loss = -143.18, pg_loss = -150.82, baseline_loss = 22.648, entropy_loss = -15.001, learner_queue_size = 64, _tick = 3012, _time = 1.6548e+09)
[2022-06-09 15:31:47,098][root][INFO] - Step 20500480 @ 3069.5 SPS. Inference batcher size: 13. Learner queue size: 64. Other stats: (train_seconds = 6670.0, step = 20500480, mean_episode_return = 36.21, mean_episode_step = 2483.6, total_loss = -133.06, pg_loss = -135.83, baseline_loss = 17.486, entropy_loss = -14.719, learner_queue_size = 64, _tick = 3014, _time = 1.6548e+09)
[2022-06-09 15:31:52,102][root][INFO] - Step 20515840 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 6675.0, step = 20515840, mean_episode_return = 27.419, mean_episode_step = 2223.7, total_loss = -0.39384, pg_loss = -13.141, baseline_loss = 27.489, entropy_loss = -14.742, learner_queue_size = 64, _tick = 3017, _time = 1.6548e+09)
[2022-06-09 15:31:57,106][root][INFO] - Step 20531200 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 6680.0, step = 20531200, mean_episode_return = 23.67, mean_episode_step = 2371.5, total_loss = -64.559, pg_loss = -63.843, baseline_loss = 13.995, entropy_loss = -14.711, learner_queue_size = 64, _tick = 3020, _time = 1.6548e+09)
[2022-06-09 15:32:02,110][root][INFO] - Step 20546560 @ 3069.5 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 6685.0, step = 20546560, mean_episode_return = -12.22, mean_episode_step = 2258.9, total_loss = -58.105, pg_loss = -52.56, baseline_loss = 9.3043, entropy_loss = -14.849, learner_queue_size = 64, _tick = 3023, _time = 1.6548e+09)
[2022-06-09 15:32:07,114][root][INFO] - Step 20561920 @ 3069.6 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 6690.0, step = 20561920, mean_episode_return = 11.509, mean_episode_step = 2317.3, total_loss = 160.42, pg_loss = 139.54, baseline_loss = 35.639, entropy_loss = -14.761, learner_queue_size = 64, _tick = 3026, _time = 1.6548e+09)
[2022-06-09 15:32:12,118][root][INFO] - Step 20577280 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 6695.1, step = 20577280, mean_episode_return = 68.901, mean_episode_step = 1985.9, total_loss = -10.084, pg_loss = -21.114, baseline_loss = 25.765, entropy_loss = -14.736, learner_queue_size = 64, _tick = 3029, _time = 1.6548e+09)
[2022-06-09 15:32:17,122][root][INFO] - Step 20592640 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 6700.1, step = 20592640, mean_episode_return = 59.983, mean_episode_step = 2305.4, total_loss = 251.39, pg_loss = 227.0, baseline_loss = 39.02, entropy_loss = -14.633, learner_queue_size = 64, _tick = 3032, _time = 1.6548e+09)
[2022-06-09 15:32:22,126][root][INFO] - Step 20613120 @ 4092.6 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 6705.1, step = 20613120, mean_episode_return = 18.105, mean_episode_step = 2356.3, total_loss = 108.27, pg_loss = 81.072, baseline_loss = 42.033, entropy_loss = -14.839, learner_queue_size = 64, _tick = 3035, _time = 1.6548e+09)
[2022-06-09 15:32:27,130][root][INFO] - Step 20628480 @ 3069.6 SPS. Inference batcher size: 76. Learner queue size: 64. Other stats: (train_seconds = 6710.1, step = 20628480, mean_episode_return = 99.462, mean_episode_step = 2496.4, total_loss = 43.762, pg_loss = 28.097, baseline_loss = 30.713, entropy_loss = -15.048, learner_queue_size = 64, _tick = 3038, _time = 1.6548e+09)
[2022-06-09 15:32:32,132][root][INFO] - Step 20643840 @ 3071.0 SPS. Inference batcher size: 90. Learner queue size: 64. Other stats: (train_seconds = 6715.1, step = 20643840, mean_episode_return = 91.621, mean_episode_step = 2203.6, total_loss = 120.89, pg_loss = 107.07, baseline_loss = 28.847, entropy_loss = -15.026, learner_queue_size = 64, _tick = 3040, _time = 1.6548e+09)
[2022-06-09 15:32:37,134][root][INFO] - Step 20659200 @ 3070.6 SPS. Inference batcher size: 77. Learner queue size: 64. Other stats: (train_seconds = 6720.1, step = 20659200, mean_episode_return = 31.318, mean_episode_step = 2300.2, total_loss = -121.8, pg_loss = -115.09, baseline_loss = 8.1077, entropy_loss = -14.824, learner_queue_size = 64, _tick = 3043, _time = 1.6548e+09)
[2022-06-09 15:32:42,138][root][INFO] - Step 20674560 @ 3069.6 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 6725.1, step = 20674560, mean_episode_return = 54.928, mean_episode_step = 2610.3, total_loss = 160.72, pg_loss = 144.59, baseline_loss = 31.303, entropy_loss = -15.172, learner_queue_size = 64, _tick = 3046, _time = 1.6548e+09)
[2022-06-09 15:32:47,142][root][INFO] - Step 20689920 @ 3069.6 SPS. Inference batcher size: 11. Learner queue size: 64. Other stats: (train_seconds = 6730.1, step = 20689920, mean_episode_return = 37.48, mean_episode_step = 2198.7, total_loss = -24.709, pg_loss = -20.956, baseline_loss = 11.611, entropy_loss = -15.365, learner_queue_size = 64, _tick = 3048, _time = 1.6548e+09)
[2022-06-09 15:32:52,146][root][INFO] - Step 20705280 @ 3069.6 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 6735.1, step = 20705280, mean_episode_return = 108.1, mean_episode_step = 1941.7, total_loss = -7.3168, pg_loss = -6.8759, baseline_loss = 14.945, entropy_loss = -15.386, learner_queue_size = 64, _tick = 3051, _time = 1.6548e+09)
[2022-06-09 15:32:57,150][root][INFO] - Step 20720640 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 6740.1, step = 20720640, mean_episode_return = 55.363, mean_episode_step = 1952.3, total_loss = -162.67, pg_loss = -150.56, baseline_loss = 3.6202, entropy_loss = -15.725, learner_queue_size = 64, _tick = 3053, _time = 1.6548e+09)
[2022-06-09 15:33:02,156][root][INFO] - Step 20741120 @ 4091.1 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 6745.1, step = 20741120, mean_episode_return = 109.77, mean_episode_step = 2324.8, total_loss = 276.25, pg_loss = -44.749, baseline_loss = 13.523, entropy_loss = -15.85, learner_queue_size = 64, _tick = 3056, _time = 1.6548e+09)
[2022-06-09 15:33:07,162][root][INFO] - Step 20756480 @ 3068.3 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 6750.1, step = 20756480, mean_episode_return = 68.563, mean_episode_step = 2273.6, total_loss = 206.42, pg_loss = 187.94, baseline_loss = 34.398, entropy_loss = -15.927, learner_queue_size = 64, _tick = 3060, _time = 1.6548e+09)
[2022-06-09 15:33:12,166][root][INFO] - Step 20771840 @ 3069.5 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 6755.1, step = 20771840, mean_episode_return = 37.391, mean_episode_step = 2338.8, total_loss = 120.27, pg_loss = 109.43, baseline_loss = 26.531, entropy_loss = -15.692, learner_queue_size = 64, _tick = 3063, _time = 1.6548e+09)
[2022-06-09 15:33:17,170][root][INFO] - Step 20787200 @ 3069.6 SPS. Inference batcher size: 76. Learner queue size: 64. Other stats: (train_seconds = 6760.1, step = 20787200, mean_episode_return = 56.604, mean_episode_step = 2535.9, total_loss = 163.71, pg_loss = 145.81, baseline_loss = 33.528, entropy_loss = -15.619, learner_queue_size = 64, _tick = 3066, _time = 1.6548e+09)
[2022-06-09 15:33:22,174][root][INFO] - Step 20802560 @ 3069.5 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 6765.1, step = 20802560, mean_episode_return = 15.745, mean_episode_step = 2189.5, total_loss = 137.06, pg_loss = 124.37, baseline_loss = 28.056, entropy_loss = -15.356, learner_queue_size = 64, _tick = 3069, _time = 1.6548e+09)
[2022-06-09 15:33:27,178][root][INFO] - Step 20817920 @ 3069.6 SPS. Inference batcher size: 13. Learner queue size: 64. Other stats: (train_seconds = 6770.1, step = 20817920, mean_episode_return = 101.15, mean_episode_step = 2134.5, total_loss = -21.566, pg_loss = -34.765, baseline_loss = 28.41, entropy_loss = -15.21, learner_queue_size = 64, _tick = 3072, _time = 1.6548e+09)
[2022-06-09 15:33:32,182][root][INFO] - Step 20833280 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 6775.1, step = 20833280, mean_episode_return = 88.579, mean_episode_step = 2311.6, total_loss = 14.391, pg_loss = 9.4296, baseline_loss = 20.422, entropy_loss = -15.46, learner_queue_size = 64, _tick = 3074, _time = 1.6548e+09)
[2022-06-09 15:33:37,186][root][INFO] - Step 20848640 @ 3069.5 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 6780.1, step = 20848640, mean_episode_return = 49.481, mean_episode_step = 2284.5, total_loss = 82.778, pg_loss = 61.457, baseline_loss = 36.499, entropy_loss = -15.177, learner_queue_size = 64, _tick = 3077, _time = 1.6548e+09)
[2022-06-09 15:33:42,190][root][INFO] - Step 20864000 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 6785.1, step = 20864000, mean_episode_return = 73.832, mean_episode_step = 2453.3, total_loss = -72.458, pg_loss = -86.246, baseline_loss = 28.679, entropy_loss = -14.891, learner_queue_size = 64, _tick = 3080, _time = 1.6548e+09)
[2022-06-09 15:33:47,194][root][INFO] - Step 20884480 @ 4092.8 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 6790.1, step = 20884480, mean_episode_return = -50.845, mean_episode_step = 2102.6, total_loss = 361.77, pg_loss = 313.96, baseline_loss = 62.95, entropy_loss = -15.136, learner_queue_size = 64, _tick = 3083, _time = 1.6548e+09)
[2022-06-09 15:33:52,198][root][INFO] - Step 20899840 @ 3069.5 SPS. Inference batcher size: 76. Learner queue size: 64. Other stats: (train_seconds = 6795.1, step = 20899840, mean_episode_return = None, mean_episode_step = 2348.7, total_loss = 16.082, pg_loss = 2.9581, baseline_loss = 28.09, entropy_loss = -14.966, learner_queue_size = 64, _tick = 3084, _time = 1.6548e+09)
[2022-06-09 15:33:57,202][root][INFO] - Step 20915200 @ 3069.6 SPS. Inference batcher size: 68. Learner queue size: 64. Other stats: (train_seconds = 6800.1, step = 20915200, mean_episode_return = 85.899, mean_episode_step = 2633.8, total_loss = -107.48, pg_loss = -109.49, baseline_loss = 16.883, entropy_loss = -14.873, learner_queue_size = 64, _tick = 3087, _time = 1.6548e+09)
[2022-06-09 15:34:02,206][root][INFO] - Step 20930560 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 6805.1, step = 20930560, mean_episode_return = -32.631, mean_episode_step = 2231.5, total_loss = -9.5077, pg_loss = -20.955, baseline_loss = 26.425, entropy_loss = -14.978, learner_queue_size = 64, _tick = 3090, _time = 1.6548e+09)
[2022-06-09 15:34:07,210][root][INFO] - Step 20945920 @ 3069.6 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 6810.1, step = 20945920, mean_episode_return = None, mean_episode_step = 2012.6, total_loss = -75.207, pg_loss = -73.543, baseline_loss = 13.043, entropy_loss = -14.708, learner_queue_size = 64, _tick = 3092, _time = 1.6548e+09)
[2022-06-09 15:34:12,214][root][INFO] - Step 20961280 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 6815.1, step = 20961280, mean_episode_return = 26.183, mean_episode_step = 2168.0, total_loss = -27.482, pg_loss = -41.484, baseline_loss = 28.638, entropy_loss = -14.635, learner_queue_size = 64, _tick = 3095, _time = 1.6548e+09)
[2022-06-09 15:34:17,218][root][INFO] - Step 20976640 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 6820.2, step = 20976640, mean_episode_return = 140.86, mean_episode_step = 2473.2, total_loss = 166.22, pg_loss = 110.53, baseline_loss = 70.105, entropy_loss = -14.414, learner_queue_size = 64, _tick = 3098, _time = 1.6548e+09)
[2022-06-09 15:34:22,222][root][INFO] - Step 20992000 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 6825.2, step = 20992000, mean_episode_return = 5.09, mean_episode_step = 1993.6, total_loss = -86.734, pg_loss = -99.037, baseline_loss = 26.593, entropy_loss = -14.291, learner_queue_size = 64, _tick = 3100, _time = 1.6548e+09)
[2022-06-09 15:34:27,226][root][INFO] - Step 21012480 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 6830.2, step = 21012480, mean_episode_return = None, mean_episode_step = 1978.2, total_loss = 12.477, pg_loss = 8.6568, baseline_loss = 17.791, entropy_loss = -13.971, learner_queue_size = 64, _tick = 3102, _time = 1.6548e+09)
[2022-06-09 15:34:32,230][root][INFO] - Step 21027840 @ 3069.5 SPS. Inference batcher size: 71. Learner queue size: 64. Other stats: (train_seconds = 6835.2, step = 21027840, mean_episode_return = 10.42, mean_episode_step = 2007.8, total_loss = -96.624, pg_loss = -102.06, baseline_loss = 19.785, entropy_loss = -14.348, learner_queue_size = 64, _tick = 3104, _time = 1.6548e+09)
[2022-06-09 15:34:37,236][root][INFO] - Step 21043200 @ 3068.3 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 6840.2, step = 21043200, mean_episode_return = 10.831, mean_episode_step = 2094.7, total_loss = -175.17, pg_loss = -184.79, baseline_loss = 24.282, entropy_loss = -14.668, learner_queue_size = 64, _tick = 3107, _time = 1.6548e+09)
[2022-06-09 15:34:42,242][root][INFO] - Step 21058560 @ 3068.3 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 6845.2, step = 21058560, mean_episode_return = None, mean_episode_step = 2110.5, total_loss = -216.84, pg_loss = -203.78, baseline_loss = 1.7633, entropy_loss = -14.825, learner_queue_size = 64, _tick = 3107, _time = 1.6548e+09)
[2022-06-09 15:34:47,246][root][INFO] - Step 21073920 @ 3069.4 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 6850.2, step = 21073920, mean_episode_return = 106.71, mean_episode_step = 1919.1, total_loss = 101.28, pg_loss = 80.303, baseline_loss = 36.178, entropy_loss = -15.2, learner_queue_size = 64, _tick = 3110, _time = 1.6548e+09)
[2022-06-09 15:34:52,250][root][INFO] - Step 21089280 @ 3069.7 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 6855.2, step = 21089280, mean_episode_return = 56.02, mean_episode_step = 1958.1, total_loss = 21.801, pg_loss = 13.042, baseline_loss = 23.748, entropy_loss = -14.989, learner_queue_size = 64, _tick = 3112, _time = 1.6548e+09)
[2022-06-09 15:34:57,254][root][INFO] - Step 21104640 @ 3069.5 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 6860.2, step = 21104640, mean_episode_return = 64.197, mean_episode_step = 1991.3, total_loss = 42.735, pg_loss = 29.518, baseline_loss = 28.12, entropy_loss = -14.903, learner_queue_size = 64, _tick = 3115, _time = 1.6548e+09)
[2022-06-09 15:35:02,258][root][INFO] - Step 21120000 @ 3069.6 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 6865.2, step = 21120000, mean_episode_return = 71.979, mean_episode_step = 1924.8, total_loss = -215.81, pg_loss = -222.0, baseline_loss = 20.919, entropy_loss = -14.721, learner_queue_size = 64, _tick = 3117, _time = 1.6548e+09)
[2022-06-09 15:35:07,262][root][INFO] - Step 21135360 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 6870.2, step = 21135360, mean_episode_return = 23.032, mean_episode_step = 2226.8, total_loss = 63.556, pg_loss = 49.288, baseline_loss = 29.115, entropy_loss = -14.847, learner_queue_size = 64, _tick = 3120, _time = 1.6548e+09)
[2022-06-09 15:35:12,266][root][INFO] - Step 21150720 @ 3069.6 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 6875.2, step = 21150720, mean_episode_return = 78.091, mean_episode_step = 1934.4, total_loss = 663.12, pg_loss = 408.04, baseline_loss = 270.14, entropy_loss = -15.052, learner_queue_size = 64, _tick = 3123, _time = 1.6548e+09)
[2022-06-09 15:35:17,270][root][INFO] - Step 21166080 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 6880.2, step = 21166080, mean_episode_return = 19.53, mean_episode_step = 1896.4, total_loss = -97.93, pg_loss = -90.673, baseline_loss = 7.7728, entropy_loss = -15.029, learner_queue_size = 64, _tick = 3126, _time = 1.6548e+09)
[2022-06-09 15:35:22,274][root][INFO] - Step 21181440 @ 3069.6 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 6885.2, step = 21181440, mean_episode_return = 60.851, mean_episode_step = 1744.1, total_loss = 539.63, pg_loss = 272.04, baseline_loss = 282.85, entropy_loss = -15.261, learner_queue_size = 64, _tick = 3129, _time = 1.6548e+09)
[2022-06-09 15:35:27,278][root][INFO] - Step 21201920 @ 4092.7 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 6890.2, step = 21201920, mean_episode_return = 57.324, mean_episode_step = 1697.4, total_loss = 209.64, pg_loss = 175.32, baseline_loss = 49.338, entropy_loss = -15.019, learner_queue_size = 64, _tick = 3133, _time = 1.6548e+09)
[2022-06-09 15:35:32,282][root][INFO] - Step 21217280 @ 3069.5 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 6895.2, step = 21217280, mean_episode_return = 51.831, mean_episode_step = 1961.9, total_loss = 454.28, pg_loss = 391.24, baseline_loss = 77.797, entropy_loss = -14.759, learner_queue_size = 64, _tick = 3136, _time = 1.6548e+09)
[2022-06-09 15:35:37,286][root][INFO] - Step 21232640 @ 3069.6 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 6900.2, step = 21232640, mean_episode_return = 120.84, mean_episode_step = 1729.7, total_loss = 53.673, pg_loss = 23.836, baseline_loss = 44.639, entropy_loss = -14.802, learner_queue_size = 64, _tick = 3138, _time = 1.6548e+09)
[2022-06-09 15:35:42,290][root][INFO] - Step 21248000 @ 3069.5 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 6905.2, step = 21248000, mean_episode_return = 78.692, mean_episode_step = 1566.2, total_loss = -264.28, pg_loss = -274.01, baseline_loss = 24.678, entropy_loss = -14.943, learner_queue_size = 64, _tick = 3140, _time = 1.6548e+09)
[2022-06-09 15:35:47,294][root][INFO] - Step 21263360 @ 3069.5 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 6910.2, step = 21263360, mean_episode_return = 23.17, mean_episode_step = 1453.2, total_loss = 90.871, pg_loss = 70.741, baseline_loss = 35.137, entropy_loss = -15.008, learner_queue_size = 64, _tick = 3143, _time = 1.6548e+09)
[2022-06-09 15:35:52,298][root][INFO] - Step 21278720 @ 3069.5 SPS. Inference batcher size: 15. Learner queue size: 64. Other stats: (train_seconds = 6915.2, step = 21278720, mean_episode_return = None, mean_episode_step = 2000.2, total_loss = 280.01, pg_loss = 255.85, baseline_loss = 39.111, entropy_loss = -14.949, learner_queue_size = 64, _tick = 3145, _time = 1.6548e+09)
[2022-06-09 15:35:57,302][root][INFO] - Step 21294080 @ 3069.6 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 6920.2, step = 21294080, mean_episode_return = 25.035, mean_episode_step = 1564.4, total_loss = 165.54, pg_loss = 145.93, baseline_loss = 34.623, entropy_loss = -15.015, learner_queue_size = 64, _tick = 3148, _time = 1.6548e+09)
[2022-06-09 15:36:02,309][root][INFO] - Step 21309440 @ 3067.8 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 6925.2, step = 21309440, mean_episode_return = 63.906, mean_episode_step = 2027.8, total_loss = 74.778, pg_loss = 45.209, baseline_loss = 44.597, entropy_loss = -15.028, learner_queue_size = 64, _tick = 3151, _time = 1.6548e+09)
[2022-06-09 15:36:07,314][root][INFO] - Step 21324800 @ 3068.9 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 6930.2, step = 21324800, mean_episode_return = 11.163, mean_episode_step = 1707.4, total_loss = 337.95, pg_loss = 297.49, baseline_loss = 55.442, entropy_loss = -14.985, learner_queue_size = 64, _tick = 3153, _time = 1.6548e+09)
[2022-06-09 15:36:12,318][root][INFO] - Step 21345280 @ 4092.7 SPS. Inference batcher size: 74. Learner queue size: 64. Other stats: (train_seconds = 6935.3, step = 21345280, mean_episode_return = 52.07, mean_episode_step = 1822.8, total_loss = -70.846, pg_loss = -69.054, baseline_loss = 13.158, entropy_loss = -14.95, learner_queue_size = 64, _tick = 3157, _time = 1.6548e+09)
[2022-06-09 15:36:17,322][root][INFO] - Step 21360640 @ 3069.5 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 6940.3, step = 21360640, mean_episode_return = 27.861, mean_episode_step = 1628.7, total_loss = 50.573, pg_loss = 43.03, baseline_loss = 22.426, entropy_loss = -14.883, learner_queue_size = 64, _tick = 3160, _time = 1.6548e+09)
[2022-06-09 15:36:22,326][root][INFO] - Step 21376000 @ 3069.6 SPS. Inference batcher size: 83. Learner queue size: 64. Other stats: (train_seconds = 6945.3, step = 21376000, mean_episode_return = None, mean_episode_step = 1585.2, total_loss = 343.86, pg_loss = 282.54, baseline_loss = 76.093, entropy_loss = -14.772, learner_queue_size = 64, _tick = 3161, _time = 1.6548e+09)
[2022-06-09 15:36:27,330][root][INFO] - Step 21391360 @ 3069.5 SPS. Inference batcher size: 77. Learner queue size: 64. Other stats: (train_seconds = 6950.3, step = 21391360, mean_episode_return = 62.13, mean_episode_step = 1902.5, total_loss = -267.03, pg_loss = -266.83, baseline_loss = 14.286, entropy_loss = -14.491, learner_queue_size = 64, _tick = 3164, _time = 1.6548e+09)
[2022-06-09 15:36:32,334][root][INFO] - Step 21406720 @ 3069.5 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 6955.3, step = 21406720, mean_episode_return = 46.862, mean_episode_step = 1656.0, total_loss = -91.763, pg_loss = -100.78, baseline_loss = 23.378, entropy_loss = -14.364, learner_queue_size = 64, _tick = 3167, _time = 1.6548e+09)
[2022-06-09 15:36:37,338][root][INFO] - Step 21422080 @ 3069.5 SPS. Inference batcher size: 68. Learner queue size: 64. Other stats: (train_seconds = 6960.3, step = 21422080, mean_episode_return = 36.3, mean_episode_step = 1853.9, total_loss = -180.96, pg_loss = -172.72, baseline_loss = 6.3724, entropy_loss = -14.608, learner_queue_size = 64, _tick = 3170, _time = 1.6548e+09)
[2022-06-09 15:36:42,342][root][INFO] - Step 21437440 @ 3069.5 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 6965.3, step = 21437440, mean_episode_return = None, mean_episode_step = 1728.8, total_loss = 165.19, pg_loss = 139.92, baseline_loss = 39.885, entropy_loss = -14.623, learner_queue_size = 64, _tick = 3172, _time = 1.6548e+09)
[2022-06-09 15:36:47,346][root][INFO] - Step 21452800 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 6970.3, step = 21452800, mean_episode_return = 62.537, mean_episode_step = 1754.1, total_loss = -186.68, pg_loss = -183.76, baseline_loss = 11.67, entropy_loss = -14.595, learner_queue_size = 64, _tick = 3175, _time = 1.6548e+09)
[2022-06-09 15:36:52,350][root][INFO] - Step 21468160 @ 3069.6 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 6975.3, step = 21468160, mean_episode_return = -55.117, mean_episode_step = 2040.3, total_loss = -78.168, pg_loss = -76.794, baseline_loss = 13.675, entropy_loss = -15.049, learner_queue_size = 64, _tick = 3178, _time = 1.6548e+09)
[2022-06-09 15:36:57,354][root][INFO] - Step 21483520 @ 3069.6 SPS. Inference batcher size: 18. Learner queue size: 64. Other stats: (train_seconds = 6980.3, step = 21483520, mean_episode_return = 32.01, mean_episode_step = 1880.1, total_loss = 152.74, pg_loss = 125.59, baseline_loss = 42.299, entropy_loss = -15.15, learner_queue_size = 64, _tick = 3180, _time = 1.6548e+09)
[2022-06-09 15:37:02,358][root][INFO] - Step 21498880 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 6985.3, step = 21498880, mean_episode_return = 67.031, mean_episode_step = 1817.5, total_loss = 24.552, pg_loss = 20.993, baseline_loss = 18.938, entropy_loss = -15.379, learner_queue_size = 64, _tick = 3182, _time = 1.6548e+09)
[2022-06-09 15:37:07,364][root][INFO] - Step 21514240 @ 3068.4 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 6990.3, step = 21514240, mean_episode_return = 31.259, mean_episode_step = 1842.6, total_loss = 99.869, pg_loss = 82.855, baseline_loss = 32.277, entropy_loss = -15.264, learner_queue_size = 64, _tick = 3185, _time = 1.6548e+09)
[2022-06-09 15:37:12,370][root][INFO] - Step 21534720 @ 4090.9 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 6995.3, step = 21534720, mean_episode_return = 33.194, mean_episode_step = 2135.5, total_loss = -65.743, pg_loss = -74.693, baseline_loss = 24.192, entropy_loss = -15.242, learner_queue_size = 64, _tick = 3189, _time = 1.6548e+09)
[2022-06-09 15:37:17,374][root][INFO] - Step 21550080 @ 3069.6 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 7000.3, step = 21550080, mean_episode_return = 23.376, mean_episode_step = 1775.4, total_loss = -105.31, pg_loss = -97.552, baseline_loss = 7.4576, entropy_loss = -15.218, learner_queue_size = 64, _tick = 3191, _time = 1.6548e+09)
[2022-06-09 15:37:22,380][root][INFO] - Step 21565440 @ 3068.4 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 7005.3, step = 21565440, mean_episode_return = None, mean_episode_step = 1858.7, total_loss = 168.37, pg_loss = 148.73, baseline_loss = 35.02, entropy_loss = -15.382, learner_queue_size = 64, _tick = 3192, _time = 1.6548e+09)
[2022-06-09 15:37:27,383][root][INFO] - Step 21580800 @ 3070.3 SPS. Inference batcher size: 88. Learner queue size: 64. Other stats: (train_seconds = 7010.3, step = 21580800, mean_episode_return = None, mean_episode_step = 1822.8, total_loss = 113.84, pg_loss = 100.43, baseline_loss = 28.685, entropy_loss = -15.277, learner_queue_size = 64, _tick = 3194, _time = 1.6548e+09)
[2022-06-09 15:37:32,413][root][INFO] - Step 21596160 @ 3053.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 7015.3, step = 21596160, mean_episode_return = -33.129, mean_episode_step = 1844.5, total_loss = 3.179, pg_loss = -5.6329, baseline_loss = 24.253, entropy_loss = -15.441, learner_queue_size = 64, _tick = 3197, _time = 1.6548e+09)
[2022-06-09 15:37:37,418][root][INFO] - Step 21611520 @ 3068.9 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 7020.4, step = 21611520, mean_episode_return = 79.932, mean_episode_step = 1716.7, total_loss = 3.2117, pg_loss = -10.824, baseline_loss = 29.509, entropy_loss = -15.474, learner_queue_size = 64, _tick = 3200, _time = 1.6548e+09)
[2022-06-09 15:37:42,422][root][INFO] - Step 21626880 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 7025.4, step = 21626880, mean_episode_return = 189.37, mean_episode_step = 1790.6, total_loss = 70.664, pg_loss = 51.321, baseline_loss = 34.566, entropy_loss = -15.223, learner_queue_size = 64, _tick = 3203, _time = 1.6548e+09)
[2022-06-09 15:37:47,426][root][INFO] - Step 21642240 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 7030.4, step = 21642240, mean_episode_return = -31.491, mean_episode_step = 1997.1, total_loss = 160.12, pg_loss = 136.07, baseline_loss = 39.214, entropy_loss = -15.168, learner_queue_size = 64, _tick = 3206, _time = 1.6548e+09)
[2022-06-09 15:37:52,430][root][INFO] - Step 21657600 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 7035.4, step = 21657600, mean_episode_return = None, mean_episode_step = 1610.9, total_loss = 83.876, pg_loss = 72.606, baseline_loss = 26.664, entropy_loss = -15.394, learner_queue_size = 64, _tick = 3208, _time = 1.6548e+09)
[2022-06-09 15:37:57,434][root][INFO] - Step 21678080 @ 4092.7 SPS. Inference batcher size: 67. Learner queue size: 64. Other stats: (train_seconds = 7040.4, step = 21678080, mean_episode_return = 43.492, mean_episode_step = 2127.0, total_loss = 157.76, pg_loss = 125.88, baseline_loss = 47.152, entropy_loss = -15.273, learner_queue_size = 64, _tick = 3212, _time = 1.6548e+09)
[2022-06-09 15:38:02,438][root][INFO] - Step 21693440 @ 3069.6 SPS. Inference batcher size: 97. Learner queue size: 64. Other stats: (train_seconds = 7045.4, step = 21693440, mean_episode_return = 45.89, mean_episode_step = 1627.5, total_loss = 80.391, pg_loss = 74.483, baseline_loss = 21.128, entropy_loss = -15.22, learner_queue_size = 64, _tick = 3213, _time = 1.6548e+09)
[2022-06-09 15:38:07,442][root][INFO] - Step 21708800 @ 3069.5 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 7050.4, step = 21708800, mean_episode_return = None, mean_episode_step = 1849.1, total_loss = -55.334, pg_loss = -52.01, baseline_loss = 11.875, entropy_loss = -15.199, learner_queue_size = 64, _tick = 3215, _time = 1.6548e+09)
[2022-06-09 15:38:12,455][root][INFO] - Step 21724160 @ 3064.1 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 7055.4, step = 21724160, mean_episode_return = -2.68, mean_episode_step = 1965.1, total_loss = 157.38, pg_loss = 129.74, baseline_loss = 42.83, entropy_loss = -15.197, learner_queue_size = 64, _tick = 3218, _time = 1.6548e+09)
[2022-06-09 15:38:17,458][root][INFO] - Step 21739520 @ 3070.1 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 7060.4, step = 21739520, mean_episode_return = 32.735, mean_episode_step = 2034.2, total_loss = -92.051, pg_loss = -91.853, baseline_loss = 14.635, entropy_loss = -14.833, learner_queue_size = 64, _tick = 3221, _time = 1.6548e+09)
[2022-06-09 15:38:22,462][root][INFO] - Step 21754880 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 7065.4, step = 21754880, mean_episode_return = 43.114, mean_episode_step = 1831.0, total_loss = -26.205, pg_loss = -31.375, baseline_loss = 20.129, entropy_loss = -14.959, learner_queue_size = 64, _tick = 3223, _time = 1.6548e+09)
[2022-06-09 15:38:27,466][root][INFO] - Step 21770240 @ 3069.6 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 7070.4, step = 21770240, mean_episode_return = 74.845, mean_episode_step = 2020.7, total_loss = -134.8, pg_loss = -136.38, baseline_loss = 16.379, entropy_loss = -14.799, learner_queue_size = 64, _tick = 3226, _time = 1.6548e+09)
[2022-06-09 15:38:32,470][root][INFO] - Step 21785600 @ 3069.5 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 7075.4, step = 21785600, mean_episode_return = None, mean_episode_step = 1760.1, total_loss = 13.77, pg_loss = 9.5726, baseline_loss = 19.112, entropy_loss = -14.914, learner_queue_size = 64, _tick = 3228, _time = 1.6548e+09)
[2022-06-09 15:38:37,476][root][INFO] - Step 21800960 @ 3068.2 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 7080.4, step = 21800960, mean_episode_return = None, mean_episode_step = 1608.3, total_loss = 25.068, pg_loss = 21.978, baseline_loss = 18.136, entropy_loss = -15.046, learner_queue_size = 64, _tick = 3229, _time = 1.6548e+09)
[2022-06-09 15:38:42,482][root][INFO] - Step 21821440 @ 4091.1 SPS. Inference batcher size: 68. Learner queue size: 64. Other stats: (train_seconds = 7085.4, step = 21821440, mean_episode_return = 44.156, mean_episode_step = 1782.2, total_loss = 298.28, pg_loss = 263.02, baseline_loss = 50.139, entropy_loss = -14.885, learner_queue_size = 64, _tick = 3232, _time = 1.6548e+09)
[2022-06-09 15:38:47,486][root][INFO] - Step 21836800 @ 3069.7 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 7090.4, step = 21836800, mean_episode_return = 57.262, mean_episode_step = 1984.2, total_loss = -157.49, pg_loss = -151.84, baseline_loss = 9.0489, entropy_loss = -14.702, learner_queue_size = 64, _tick = 3234, _time = 1.6548e+09)
[2022-06-09 15:38:52,490][root][INFO] - Step 21852160 @ 3069.6 SPS. Inference batcher size: 87. Learner queue size: 64. Other stats: (train_seconds = 7095.4, step = 21852160, mean_episode_return = 50.588, mean_episode_step = 1753.4, total_loss = 43.469, pg_loss = 33.053, baseline_loss = 25.317, entropy_loss = -14.902, learner_queue_size = 64, _tick = 3236, _time = 1.6548e+09)
[2022-06-09 15:38:57,494][root][INFO] - Step 21867520 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 7100.4, step = 21867520, mean_episode_return = 3.3523, mean_episode_step = 1582.5, total_loss = -168.26, pg_loss = -161.04, baseline_loss = 7.791, entropy_loss = -15.007, learner_queue_size = 64, _tick = 3239, _time = 1.6548e+09)
[2022-06-09 15:39:02,498][root][INFO] - Step 21882880 @ 3069.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 7105.4, step = 21882880, mean_episode_return = 85.146, mean_episode_step = 1849.4, total_loss = -188.93, pg_loss = -177.88, baseline_loss = 4.1821, entropy_loss = -15.231, learner_queue_size = 64, _tick = 3241, _time = 1.6548e+09)
[2022-06-09 15:39:07,502][root][INFO] - Step 21898240 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 7110.4, step = 21898240, mean_episode_return = 26.784, mean_episode_step = 1726.2, total_loss = -50.176, pg_loss = -54.553, baseline_loss = 19.481, entropy_loss = -15.103, learner_queue_size = 64, _tick = 3244, _time = 1.6548e+09)
[2022-06-09 15:39:12,506][root][INFO] - Step 21918720 @ 4092.7 SPS. Inference batcher size: 72. Learner queue size: 64. Other stats: (train_seconds = 7115.4, step = 21918720, mean_episode_return = 56.928, mean_episode_step = 1694.0, total_loss = 80.557, pg_loss = 65.058, baseline_loss = 30.695, entropy_loss = -15.196, learner_queue_size = 64, _tick = 3248, _time = 1.6548e+09)
[2022-06-09 15:39:17,510][root][INFO] - Step 21934080 @ 3069.3 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 7120.4, step = 21934080, mean_episode_return = None, mean_episode_step = 2133.7, total_loss = -179.08, pg_loss = -167.12, baseline_loss = 3.2544, entropy_loss = -15.209, learner_queue_size = 64, _tick = 3250, _time = 1.6548e+09)
[2022-06-09 15:39:22,514][root][INFO] - Step 21949440 @ 3069.8 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 7125.4, step = 21949440, mean_episode_return = 14.86, mean_episode_step = 1594.1, total_loss = 297.72, pg_loss = 273.86, baseline_loss = 39.215, entropy_loss = -15.359, learner_queue_size = 64, _tick = 3253, _time = 1.6548e+09)
[2022-06-09 15:39:27,518][root][INFO] - Step 21964800 @ 3069.5 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 7130.5, step = 21964800, mean_episode_return = 26.832, mean_episode_step = 1870.4, total_loss = 134.58, pg_loss = 103.33, baseline_loss = 46.572, entropy_loss = -15.316, learner_queue_size = 64, _tick = 3256, _time = 1.6548e+09)
[2022-06-09 15:39:32,522][root][INFO] - Step 21980160 @ 3069.6 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 7135.5, step = 21980160, mean_episode_return = None, mean_episode_step = 1567.7, total_loss = 237.58, pg_loss = 213.87, baseline_loss = 38.84, entropy_loss = -15.126, learner_queue_size = 64, _tick = 3257, _time = 1.6548e+09)
[2022-06-09 15:39:37,526][root][INFO] - Step 21995520 @ 3069.6 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 7140.5, step = 21995520, mean_episode_return = 37.795, mean_episode_step = 1699.1, total_loss = -68.044, pg_loss = -67.743, baseline_loss = 14.925, entropy_loss = -15.227, learner_queue_size = 64, _tick = 3259, _time = 1.6548e+09)
[2022-06-09 15:39:42,530][root][INFO] - Step 22010880 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 7145.5, step = 22010880, mean_episode_return = 49.803, mean_episode_step = 2135.6, total_loss = 141.86, pg_loss = 126.04, baseline_loss = 30.979, entropy_loss = -15.154, learner_queue_size = 64, _tick = 3261, _time = 1.6548e+09)
[2022-06-09 15:39:47,534][root][INFO] - Step 22026240 @ 3069.6 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 7150.5, step = 22026240, mean_episode_return = 25.56, mean_episode_step = 1740.1, total_loss = -59.83, pg_loss = -53.587, baseline_loss = 8.8051, entropy_loss = -15.049, learner_queue_size = 64, _tick = 3263, _time = 1.6548e+09)
[2022-06-09 15:39:52,538][root][INFO] - Step 22041600 @ 3069.6 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 7155.5, step = 22041600, mean_episode_return = -1.5204, mean_episode_step = 1920.2, total_loss = 101.71, pg_loss = 86.605, baseline_loss = 30.036, entropy_loss = -14.933, learner_queue_size = 64, _tick = 3266, _time = 1.6548e+09)
[2022-06-09 15:39:57,543][root][INFO] - Step 22056960 @ 3069.1 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 7160.5, step = 22056960, mean_episode_return = None, mean_episode_step = 1843.6, total_loss = -110.67, pg_loss = -103.55, baseline_loss = 7.7284, entropy_loss = -14.85, learner_queue_size = 64, _tick = 3267, _time = 1.6548e+09)
[2022-06-09 15:40:02,546][root][INFO] - Step 22072320 @ 3070.0 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 7165.5, step = 22072320, mean_episode_return = 60.868, mean_episode_step = 2177.5, total_loss = -63.875, pg_loss = -69.212, baseline_loss = 20.341, entropy_loss = -15.004, learner_queue_size = 64, _tick = 3270, _time = 1.6548e+09)
[2022-06-09 15:40:07,550][root][INFO] - Step 22092800 @ 4092.7 SPS. Inference batcher size: 92. Learner queue size: 64. Other stats: (train_seconds = 7170.5, step = 22092800, mean_episode_return = 188.33, mean_episode_step = 1650.2, total_loss = 103.55, pg_loss = 92.54, baseline_loss = 26.023, entropy_loss = -15.011, learner_queue_size = 64, _tick = 3273, _time = 1.6548e+09)
[2022-06-09 15:40:12,554][root][INFO] - Step 22108160 @ 3069.6 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 7175.5, step = 22108160, mean_episode_return = 26.075, mean_episode_step = 2217.6, total_loss = -101.94, pg_loss = -101.11, baseline_loss = 13.764, entropy_loss = -14.591, learner_queue_size = 64, _tick = 3276, _time = 1.6548e+09)
[2022-06-09 15:40:17,558][root][INFO] - Step 22123520 @ 3069.5 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 7180.5, step = 22123520, mean_episode_return = 61.06, mean_episode_step = 1806.3, total_loss = 42.705, pg_loss = 30.054, baseline_loss = 27.603, entropy_loss = -14.951, learner_queue_size = 64, _tick = 3278, _time = 1.6548e+09)
[2022-06-09 15:40:22,562][root][INFO] - Step 22138880 @ 3069.5 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 7185.5, step = 22138880, mean_episode_return = 21.64, mean_episode_step = 2355.2, total_loss = 9.7245, pg_loss = 5.7212, baseline_loss = 18.903, entropy_loss = -14.9, learner_queue_size = 64, _tick = 3281, _time = 1.6548e+09)
[2022-06-09 15:40:27,566][root][INFO] - Step 22154240 @ 3069.6 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 7190.5, step = 22154240, mean_episode_return = None, mean_episode_step = 2313.2, total_loss = 325.72, pg_loss = 285.18, baseline_loss = 55.275, entropy_loss = -14.732, learner_queue_size = 64, _tick = 3283, _time = 1.6548e+09)
[2022-06-09 15:40:32,570][root][INFO] - Step 22169600 @ 3069.5 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 7195.5, step = 22169600, mean_episode_return = 33.605, mean_episode_step = 2026.8, total_loss = -73.646, pg_loss = -83.188, baseline_loss = 24.281, entropy_loss = -14.739, learner_queue_size = 64, _tick = 3285, _time = 1.6548e+09)
[2022-06-09 15:40:37,574][root][INFO] - Step 22184960 @ 3069.4 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 7200.5, step = 22184960, mean_episode_return = -1.4936, mean_episode_step = 2112.1, total_loss = 77.788, pg_loss = 54.849, baseline_loss = 37.672, entropy_loss = -14.733, learner_queue_size = 64, _tick = 3288, _time = 1.6548e+09)
[2022-06-09 15:40:42,580][root][INFO] - Step 22200320 @ 3068.3 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 7205.5, step = 22200320, mean_episode_return = 72.535, mean_episode_step = 2072.2, total_loss = -10.385, pg_loss = -17.384, baseline_loss = 21.54, entropy_loss = -14.54, learner_queue_size = 64, _tick = 3291, _time = 1.6548e+09)
[2022-06-09 15:40:47,587][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 15:40:47,843][root][INFO] - Step 22220800 @ 4090.8 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 7210.5, step = 22220800, mean_episode_return = None, mean_episode_step = 1907.8, total_loss = 94.215, pg_loss = 91.985, baseline_loss = 16.809, entropy_loss = -14.579, learner_queue_size = 64, _tick = 3294, _time = 1.6548e+09)
[2022-06-09 15:40:52,846][root][INFO] - Step 22236160 @ 2920.5 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 7215.8, step = 22236160, mean_episode_return = None, mean_episode_step = 2437.1, total_loss = -60.82, pg_loss = -57.134, baseline_loss = 10.906, entropy_loss = -14.592, learner_queue_size = 64, _tick = 3296, _time = 1.6548e+09)
[2022-06-09 15:40:57,850][root][INFO] - Step 22251520 @ 3069.5 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 7220.8, step = 22251520, mean_episode_return = 1.0098, mean_episode_step = 2085.6, total_loss = 85.256, pg_loss = 72.128, baseline_loss = 27.816, entropy_loss = -14.688, learner_queue_size = 64, _tick = 3299, _time = 1.6548e+09)
[2022-06-09 15:41:02,854][root][INFO] - Step 22266880 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 7225.8, step = 22266880, mean_episode_return = None, mean_episode_step = 2141.2, total_loss = 58.17, pg_loss = 43.732, baseline_loss = 29.046, entropy_loss = -14.608, learner_queue_size = 64, _tick = 3301, _time = 1.6548e+09)
[2022-06-09 15:41:07,858][root][INFO] - Step 22282240 @ 3069.6 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 7230.8, step = 22282240, mean_episode_return = 45.09, mean_episode_step = 1972.0, total_loss = -170.92, pg_loss = -174.76, baseline_loss = 18.454, entropy_loss = -14.616, learner_queue_size = 64, _tick = 3304, _time = 1.6548e+09)
[2022-06-09 15:41:12,862][root][INFO] - Step 22297600 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 7235.8, step = 22297600, mean_episode_return = 20.13, mean_episode_step = 2093.7, total_loss = -15.823, pg_loss = -24.231, baseline_loss = 22.973, entropy_loss = -14.566, learner_queue_size = 64, _tick = 3307, _time = 1.6548e+09)
[2022-06-09 15:41:17,866][root][INFO] - Step 22312960 @ 3069.4 SPS. Inference batcher size: 6. Learner queue size: 64. Other stats: (train_seconds = 7240.8, step = 22312960, mean_episode_return = 46.751, mean_episode_step = 2275.1, total_loss = 75.476, pg_loss = 67.678, baseline_loss = 22.325, entropy_loss = -14.526, learner_queue_size = 64, _tick = 3310, _time = 1.6548e+09)
[2022-06-09 15:41:22,870][root][INFO] - Step 22333440 @ 4092.9 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 7245.8, step = 22333440, mean_episode_return = -0.13384, mean_episode_step = 1976.0, total_loss = -136.97, pg_loss = -139.71, baseline_loss = 17.467, entropy_loss = -14.732, learner_queue_size = 64, _tick = 3313, _time = 1.6548e+09)
[2022-06-09 15:41:27,874][root][INFO] - Step 22348800 @ 3069.5 SPS. Inference batcher size: 72. Learner queue size: 64. Other stats: (train_seconds = 7250.8, step = 22348800, mean_episode_return = 17.129, mean_episode_step = 2397.1, total_loss = -86.08, pg_loss = -86.394, baseline_loss = 15.319, entropy_loss = -15.005, learner_queue_size = 64, _tick = 3316, _time = 1.6548e+09)
[2022-06-09 15:41:32,880][root][INFO] - Step 22364160 @ 3068.6 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 7255.8, step = 22364160, mean_episode_return = None, mean_episode_step = 2282.4, total_loss = -168.68, pg_loss = -159.37, baseline_loss = 5.6452, entropy_loss = -14.953, learner_queue_size = 64, _tick = 3317, _time = 1.6548e+09)
[2022-06-09 15:41:37,882][root][INFO] - Step 22379520 @ 3070.5 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 7260.8, step = 22379520, mean_episode_return = 71.654, mean_episode_step = 2113.7, total_loss = 205.29, pg_loss = 147.21, baseline_loss = 72.995, entropy_loss = -14.915, learner_queue_size = 64, _tick = 3320, _time = 1.6548e+09)
[2022-06-09 15:41:42,886][root][INFO] - Step 22394880 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 7265.8, step = 22394880, mean_episode_return = None, mean_episode_step = 2323.6, total_loss = -52.437, pg_loss = -59.87, baseline_loss = 22.336, entropy_loss = -14.903, learner_queue_size = 64, _tick = 3322, _time = 1.6548e+09)
[2022-06-09 15:41:47,890][root][INFO] - Step 22410240 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 7270.8, step = 22410240, mean_episode_return = 45.105, mean_episode_step = 2043.2, total_loss = 90.583, pg_loss = 72.753, baseline_loss = 32.648, entropy_loss = -14.818, learner_queue_size = 64, _tick = 3325, _time = 1.6548e+09)
[2022-06-09 15:41:52,894][root][INFO] - Step 22425600 @ 3069.6 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 7275.8, step = 22425600, mean_episode_return = 55.699, mean_episode_step = 2490.3, total_loss = 236.8, pg_loss = 205.52, baseline_loss = 46.237, entropy_loss = -14.956, learner_queue_size = 64, _tick = 3328, _time = 1.6548e+09)
[2022-06-09 15:41:57,898][root][INFO] - Step 22440960 @ 3069.5 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 7280.8, step = 22440960, mean_episode_return = 31.03, mean_episode_step = 2170.1, total_loss = 29.708, pg_loss = 26.573, baseline_loss = 18.247, entropy_loss = -15.112, learner_queue_size = 64, _tick = 3331, _time = 1.6548e+09)
[2022-06-09 15:42:02,902][root][INFO] - Step 22461440 @ 4092.7 SPS. Inference batcher size: 2. Learner queue size: 64. Other stats: (train_seconds = 7285.8, step = 22461440, mean_episode_return = 5.1401, mean_episode_step = 1810.7, total_loss = 85.625, pg_loss = 73.739, baseline_loss = 26.889, entropy_loss = -15.003, learner_queue_size = 64, _tick = 3335, _time = 1.6548e+09)
[2022-06-09 15:42:07,906][root][INFO] - Step 22476800 @ 3069.5 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 7290.8, step = 22476800, mean_episode_return = 69.259, mean_episode_step = 1921.5, total_loss = -54.048, pg_loss = -57.384, baseline_loss = 18.271, entropy_loss = -14.935, learner_queue_size = 64, _tick = 3338, _time = 1.6548e+09)
[2022-06-09 15:42:12,910][root][INFO] - Step 22492160 @ 3069.6 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 7295.8, step = 22492160, mean_episode_return = 101.66, mean_episode_step = 1855.4, total_loss = -84.11, pg_loss = -80.47, baseline_loss = 11.378, entropy_loss = -15.019, learner_queue_size = 64, _tick = 3341, _time = 1.6548e+09)
[2022-06-09 15:42:17,914][root][INFO] - Step 22507520 @ 3069.6 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 7300.8, step = 22507520, mean_episode_return = 45.63, mean_episode_step = 1756.8, total_loss = 186.82, pg_loss = 157.27, baseline_loss = 44.601, entropy_loss = -15.051, learner_queue_size = 64, _tick = 3343, _time = 1.6548e+09)
[2022-06-09 15:42:22,918][root][INFO] - Step 22522880 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 7305.9, step = 22522880, mean_episode_return = 69.03, mean_episode_step = 1945.5, total_loss = -230.57, pg_loss = -226.96, baseline_loss = 11.338, entropy_loss = -14.942, learner_queue_size = 64, _tick = 3346, _time = 1.6548e+09)
[2022-06-09 15:42:27,922][root][INFO] - Step 22538240 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 7310.9, step = 22538240, mean_episode_return = 81.438, mean_episode_step = 1827.2, total_loss = 266.21, pg_loss = 239.73, baseline_loss = 41.289, entropy_loss = -14.809, learner_queue_size = 64, _tick = 3349, _time = 1.6548e+09)
[2022-06-09 15:42:32,926][root][INFO] - Step 22553600 @ 3069.5 SPS. Inference batcher size: 5. Learner queue size: 64. Other stats: (train_seconds = 7315.9, step = 22553600, mean_episode_return = 25.993, mean_episode_step = 1891.9, total_loss = -137.64, pg_loss = -138.09, baseline_loss = 15.215, entropy_loss = -14.765, learner_queue_size = 64, _tick = 3352, _time = 1.6548e+09)
[2022-06-09 15:42:37,930][root][INFO] - Step 22568960 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 7320.9, step = 22568960, mean_episode_return = -2.1003, mean_episode_step = 2113.3, total_loss = -189.66, pg_loss = -180.32, baseline_loss = 5.4676, entropy_loss = -14.811, learner_queue_size = 64, _tick = 3354, _time = 1.6548e+09)
[2022-06-09 15:42:42,934][root][INFO] - Step 22584320 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 7325.9, step = 22584320, mean_episode_return = 63.841, mean_episode_step = 1710.3, total_loss = -214.19, pg_loss = -202.85, baseline_loss = 3.3929, entropy_loss = -14.732, learner_queue_size = 64, _tick = 3357, _time = 1.6548e+09)
[2022-06-09 15:42:47,938][root][INFO] - Step 22599680 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 7330.9, step = 22599680, mean_episode_return = 72.695, mean_episode_step = 1793.1, total_loss = -22.558, pg_loss = -37.82, baseline_loss = 29.991, entropy_loss = -14.729, learner_queue_size = 64, _tick = 3359, _time = 1.6548e+09)
[2022-06-09 15:42:52,942][root][INFO] - Step 22615040 @ 3069.5 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 7335.9, step = 22615040, mean_episode_return = None, mean_episode_step = 1826.1, total_loss = -181.01, pg_loss = -169.23, baseline_loss = 2.7028, entropy_loss = -14.48, learner_queue_size = 64, _tick = 3360, _time = 1.6548e+09)
[2022-06-09 15:42:57,946][root][INFO] - Step 22635520 @ 4092.8 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 7340.9, step = 22635520, mean_episode_return = 47.102, mean_episode_step = 1944.3, total_loss = 40.317, pg_loss = 24.002, baseline_loss = 30.807, entropy_loss = -14.492, learner_queue_size = 64, _tick = 3364, _time = 1.6548e+09)
[2022-06-09 15:43:02,950][root][INFO] - Step 22650880 @ 3069.5 SPS. Inference batcher size: 75. Learner queue size: 64. Other stats: (train_seconds = 7345.9, step = 22650880, mean_episode_return = None, mean_episode_step = 2113.1, total_loss = -8.5011, pg_loss = -12.904, baseline_loss = 18.682, entropy_loss = -14.279, learner_queue_size = 64, _tick = 3366, _time = 1.6548e+09)
[2022-06-09 15:43:07,954][root][INFO] - Step 22666240 @ 3069.6 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 7350.9, step = 22666240, mean_episode_return = -5.1203, mean_episode_step = 2045.3, total_loss = 74.65, pg_loss = 60.559, baseline_loss = 28.525, entropy_loss = -14.434, learner_queue_size = 64, _tick = 3368, _time = 1.6548e+09)
[2022-06-09 15:43:12,958][root][INFO] - Step 22681600 @ 3069.5 SPS. Inference batcher size: 71. Learner queue size: 64. Other stats: (train_seconds = 7355.9, step = 22681600, mean_episode_return = 34.6, mean_episode_step = 2179.4, total_loss = 44.688, pg_loss = 31.934, baseline_loss = 27.193, entropy_loss = -14.44, learner_queue_size = 64, _tick = 3371, _time = 1.6548e+09)
[2022-06-09 15:43:17,963][root][INFO] - Step 22696960 @ 3069.1 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 7360.9, step = 22696960, mean_episode_return = 27.75, mean_episode_step = 2033.7, total_loss = 254.32, pg_loss = 225.53, baseline_loss = 43.128, entropy_loss = -14.344, learner_queue_size = 64, _tick = 3374, _time = 1.6548e+09)
[2022-06-09 15:43:22,966][root][INFO] - Step 22712320 @ 3070.0 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 7365.9, step = 22712320, mean_episode_return = None, mean_episode_step = 1881.9, total_loss = 81.794, pg_loss = 66.503, baseline_loss = 29.866, entropy_loss = -14.575, learner_queue_size = 64, _tick = 3376, _time = 1.6548e+09)
[2022-06-09 15:43:27,970][root][INFO] - Step 22727680 @ 3069.6 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 7370.9, step = 22727680, mean_episode_return = 78.211, mean_episode_step = 1645.5, total_loss = -43.758, pg_loss = -49.449, baseline_loss = 20.446, entropy_loss = -14.755, learner_queue_size = 64, _tick = 3378, _time = 1.6548e+09)
[2022-06-09 15:43:32,974][root][INFO] - Step 22743040 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 7375.9, step = 22743040, mean_episode_return = 52.246, mean_episode_step = 1950.0, total_loss = 35.846, pg_loss = 22.939, baseline_loss = 27.541, entropy_loss = -14.634, learner_queue_size = 64, _tick = 3381, _time = 1.6548e+09)
[2022-06-09 15:43:37,978][root][INFO] - Step 22758400 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 7380.9, step = 22758400, mean_episode_return = 4.6997, mean_episode_step = 1670.3, total_loss = -0.15966, pg_loss = -8.1109, baseline_loss = 22.838, entropy_loss = -14.887, learner_queue_size = 64, _tick = 3383, _time = 1.6548e+09)
[2022-06-09 15:43:42,982][root][INFO] - Step 22778880 @ 4092.7 SPS. Inference batcher size: 84. Learner queue size: 64. Other stats: (train_seconds = 7385.9, step = 22778880, mean_episode_return = None, mean_episode_step = 2019.2, total_loss = -15.128, pg_loss = -13.231, baseline_loss = 13.013, entropy_loss = -14.911, learner_queue_size = 64, _tick = 3386, _time = 1.6548e+09)
[2022-06-09 15:43:47,988][root][INFO] - Step 22794240 @ 3068.2 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 7390.9, step = 22794240, mean_episode_return = None, mean_episode_step = 1805.5, total_loss = 38.129, pg_loss = 34.433, baseline_loss = 18.425, entropy_loss = -14.729, learner_queue_size = 64, _tick = 3387, _time = 1.6548e+09)
[2022-06-09 15:43:52,994][root][INFO] - Step 22809600 @ 3068.4 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 7395.9, step = 22809600, mean_episode_return = 10.25, mean_episode_step = 2047.8, total_loss = -170.65, pg_loss = -159.67, baseline_loss = 3.3299, entropy_loss = -14.318, learner_queue_size = 64, _tick = 3390, _time = 1.6548e+09)
[2022-06-09 15:43:57,998][root][INFO] - Step 22824960 @ 3069.6 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 7400.9, step = 22824960, mean_episode_return = 36.448, mean_episode_step = 2149.2, total_loss = -67.457, pg_loss = -78.119, baseline_loss = 24.925, entropy_loss = -14.262, learner_queue_size = 64, _tick = 3392, _time = 1.6548e+09)
[2022-06-09 15:44:03,002][root][INFO] - Step 22840320 @ 3069.6 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 7405.9, step = 22840320, mean_episode_return = None, mean_episode_step = 1780.0, total_loss = -23.662, pg_loss = -28.09, baseline_loss = 18.372, entropy_loss = -13.944, learner_queue_size = 64, _tick = 3394, _time = 1.6548e+09)
[2022-06-09 15:44:08,006][root][INFO] - Step 22855680 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 7410.9, step = 22855680, mean_episode_return = 66.7, mean_episode_step = 1697.2, total_loss = 144.63, pg_loss = 124.33, baseline_loss = 33.719, entropy_loss = -13.424, learner_queue_size = 64, _tick = 3397, _time = 1.6548e+09)
[2022-06-09 15:44:13,011][root][INFO] - Step 22871040 @ 3069.3 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 7415.9, step = 22871040, mean_episode_return = 67.961, mean_episode_step = 1945.4, total_loss = -122.56, pg_loss = -122.38, baseline_loss = 13.223, entropy_loss = -13.407, learner_queue_size = 64, _tick = 3400, _time = 1.6548e+09)
[2022-06-09 15:44:18,014][root][INFO] - Step 22886400 @ 3069.8 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 7421.0, step = 22886400, mean_episode_return = 81.54, mean_episode_step = 1895.0, total_loss = -45.374, pg_loss = -50.285, baseline_loss = 18.546, entropy_loss = -13.635, learner_queue_size = 64, _tick = 3403, _time = 1.6548e+09)
[2022-06-09 15:44:23,018][root][INFO] - Step 22901760 @ 3069.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 7426.0, step = 22901760, mean_episode_return = 50.193, mean_episode_step = 2282.4, total_loss = 6.2989, pg_loss = -8.8399, baseline_loss = 28.814, entropy_loss = -13.675, learner_queue_size = 64, _tick = 3404, _time = 1.6548e+09)
[2022-06-09 15:44:28,022][root][INFO] - Step 22922240 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 7431.0, step = 22922240, mean_episode_return = 64.8, mean_episode_step = 2290.9, total_loss = 71.013, pg_loss = 54.749, baseline_loss = 29.583, entropy_loss = -13.32, learner_queue_size = 64, _tick = 3408, _time = 1.6548e+09)
[2022-06-09 15:44:33,026][root][INFO] - Step 22937600 @ 3069.5 SPS. Inference batcher size: 77. Learner queue size: 64. Other stats: (train_seconds = 7436.0, step = 22937600, mean_episode_return = None, mean_episode_step = 2036.1, total_loss = 227.5, pg_loss = 198.95, baseline_loss = 42.063, entropy_loss = -13.509, learner_queue_size = 64, _tick = 3410, _time = 1.6548e+09)
[2022-06-09 15:44:38,030][root][INFO] - Step 22952960 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 7441.0, step = 22952960, mean_episode_return = 58.413, mean_episode_step = 2000.9, total_loss = 181.99, pg_loss = 146.66, baseline_loss = 48.994, entropy_loss = -13.672, learner_queue_size = 64, _tick = 3413, _time = 1.6548e+09)
[2022-06-09 15:44:43,034][root][INFO] - Step 22968320 @ 3069.6 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 7446.0, step = 22968320, mean_episode_return = 36.049, mean_episode_step = 2035.7, total_loss = 7.1851, pg_loss = -4.1983, baseline_loss = 25.143, entropy_loss = -13.76, learner_queue_size = 64, _tick = 3415, _time = 1.6548e+09)
[2022-06-09 15:44:48,038][root][INFO] - Step 22983680 @ 3069.6 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 7451.0, step = 22983680, mean_episode_return = 115.37, mean_episode_step = 1962.3, total_loss = 39.581, pg_loss = 19.989, baseline_loss = 32.822, entropy_loss = -13.23, learner_queue_size = 64, _tick = 3417, _time = 1.6548e+09)
[2022-06-09 15:44:53,042][root][INFO] - Step 22999040 @ 3069.5 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 7456.0, step = 22999040, mean_episode_return = 39.707, mean_episode_step = 2215.4, total_loss = -184.3, pg_loss = -185.28, baseline_loss = 14.68, entropy_loss = -13.7, learner_queue_size = 64, _tick = 3420, _time = 1.6548e+09)
[2022-06-09 15:44:58,046][root][INFO] - Step 23014400 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 7461.0, step = 23014400, mean_episode_return = None, mean_episode_step = 1979.3, total_loss = -82.125, pg_loss = -79.961, baseline_loss = 11.535, entropy_loss = -13.699, learner_queue_size = 64, _tick = 3422, _time = 1.6548e+09)
[2022-06-09 15:45:03,050][root][INFO] - Step 23029760 @ 3069.6 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 7466.0, step = 23029760, mean_episode_return = 74.601, mean_episode_step = 1839.3, total_loss = 242.28, pg_loss = 202.45, baseline_loss = 53.663, entropy_loss = -13.834, learner_queue_size = 64, _tick = 3425, _time = 1.6548e+09)
[2022-06-09 15:45:08,054][root][INFO] - Step 23045120 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 7471.0, step = 23045120, mean_episode_return = 47.922, mean_episode_step = 1940.6, total_loss = -150.61, pg_loss = -145.0, baseline_loss = 8.4186, entropy_loss = -14.03, learner_queue_size = 64, _tick = 3427, _time = 1.6548e+09)
[2022-06-09 15:45:13,058][root][INFO] - Step 23065600 @ 4092.7 SPS. Inference batcher size: 89. Learner queue size: 64. Other stats: (train_seconds = 7476.0, step = 23065600, mean_episode_return = 55.666, mean_episode_step = 2122.5, total_loss = -6.0659, pg_loss = -16.927, baseline_loss = 24.755, entropy_loss = -13.894, learner_queue_size = 64, _tick = 3430, _time = 1.6548e+09)
[2022-06-09 15:45:18,062][root][INFO] - Step 23075840 @ 2046.3 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 7481.0, step = 23075840, mean_episode_return = 78.882, mean_episode_step = 2021.4, total_loss = 211.62, pg_loss = 177.45, baseline_loss = 48.013, entropy_loss = -13.846, learner_queue_size = 64, _tick = 3432, _time = 1.6548e+09)
[2022-06-09 15:45:23,066][root][INFO] - Step 23096320 @ 4092.8 SPS. Inference batcher size: 85. Learner queue size: 64. Other stats: (train_seconds = 7486.0, step = 23096320, mean_episode_return = 29.111, mean_episode_step = 1558.3, total_loss = -75.092, pg_loss = -83.475, baseline_loss = 22.477, entropy_loss = -14.094, learner_queue_size = 64, _tick = 3436, _time = 1.6548e+09)
[2022-06-09 15:45:28,070][root][INFO] - Step 23111680 @ 3069.5 SPS. Inference batcher size: 87. Learner queue size: 64. Other stats: (train_seconds = 7491.0, step = 23111680, mean_episode_return = None, mean_episode_step = 1862.8, total_loss = 195.83, pg_loss = 160.51, baseline_loss = 49.454, entropy_loss = -14.137, learner_queue_size = 64, _tick = 3438, _time = 1.6548e+09)
[2022-06-09 15:45:33,074][root][INFO] - Step 23127040 @ 3069.6 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 7496.0, step = 23127040, mean_episode_return = None, mean_episode_step = 1817.6, total_loss = -182.55, pg_loss = -171.28, baseline_loss = 2.864, entropy_loss = -14.128, learner_queue_size = 64, _tick = 3439, _time = 1.6548e+09)
[2022-06-09 15:45:38,078][root][INFO] - Step 23142400 @ 3069.6 SPS. Inference batcher size: 6. Learner queue size: 64. Other stats: (train_seconds = 7501.0, step = 23142400, mean_episode_return = 3.3732, mean_episode_step = 1703.9, total_loss = 95.857, pg_loss = 70.925, baseline_loss = 38.761, entropy_loss = -13.829, learner_queue_size = 64, _tick = 3441, _time = 1.6548e+09)
[2022-06-09 15:45:43,082][root][INFO] - Step 23157760 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 7506.0, step = 23157760, mean_episode_return = None, mean_episode_step = 2071.7, total_loss = 94.274, pg_loss = 74.972, baseline_loss = 33.434, entropy_loss = -14.133, learner_queue_size = 64, _tick = 3443, _time = 1.6548e+09)
[2022-06-09 15:45:48,086][root][INFO] - Step 23173120 @ 3069.6 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 7511.0, step = 23173120, mean_episode_return = 79.569, mean_episode_step = 1945.9, total_loss = 38.015, pg_loss = 29.328, baseline_loss = 22.889, entropy_loss = -14.202, learner_queue_size = 64, _tick = 3446, _time = 1.6548e+09)
[2022-06-09 15:45:53,091][root][INFO] - Step 23188480 @ 3069.0 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 7516.0, step = 23188480, mean_episode_return = 35.993, mean_episode_step = 1898.5, total_loss = 92.514, pg_loss = 60.102, baseline_loss = 46.617, entropy_loss = -14.205, learner_queue_size = 64, _tick = 3448, _time = 1.6548e+09)
[2022-06-09 15:45:58,097][root][INFO] - Step 23203840 @ 3068.2 SPS. Inference batcher size: 15. Learner queue size: 64. Other stats: (train_seconds = 7521.0, step = 23203840, mean_episode_return = 1.5246, mean_episode_step = 1900.7, total_loss = -207.95, pg_loss = -209.83, baseline_loss = 16.118, entropy_loss = -14.233, learner_queue_size = 64, _tick = 3450, _time = 1.6548e+09)
[2022-06-09 15:46:03,102][root][INFO] - Step 23219200 @ 3069.0 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 7526.0, step = 23219200, mean_episode_return = -28.381, mean_episode_step = 2222.9, total_loss = 104.0, pg_loss = 86.166, baseline_loss = 32.081, entropy_loss = -14.245, learner_queue_size = 64, _tick = 3453, _time = 1.6548e+09)
[2022-06-09 15:46:08,106][root][INFO] - Step 23239680 @ 4092.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 7531.0, step = 23239680, mean_episode_return = 38.526, mean_episode_step = 1993.9, total_loss = 143.01, pg_loss = 116.97, baseline_loss = 40.629, entropy_loss = -14.591, learner_queue_size = 64, _tick = 3457, _time = 1.6548e+09)
[2022-06-09 15:46:13,110][root][INFO] - Step 23255040 @ 3069.7 SPS. Inference batcher size: 79. Learner queue size: 64. Other stats: (train_seconds = 7536.0, step = 23255040, mean_episode_return = 50.942, mean_episode_step = 1814.6, total_loss = 96.264, pg_loss = 81.124, baseline_loss = 29.674, entropy_loss = -14.534, learner_queue_size = 64, _tick = 3460, _time = 1.6548e+09)
[2022-06-09 15:46:18,114][root][INFO] - Step 23270400 @ 3069.5 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 7541.0, step = 23270400, mean_episode_return = 19.586, mean_episode_step = 1854.5, total_loss = -19.136, pg_loss = -33.826, baseline_loss = 29.123, entropy_loss = -14.433, learner_queue_size = 64, _tick = 3463, _time = 1.6548e+09)
[2022-06-09 15:46:23,118][root][INFO] - Step 23285760 @ 3069.6 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 7546.1, step = 23285760, mean_episode_return = 5.1399, mean_episode_step = 1842.1, total_loss = 69.474, pg_loss = 53.114, baseline_loss = 30.83, entropy_loss = -14.471, learner_queue_size = 64, _tick = 3466, _time = 1.6548e+09)
[2022-06-09 15:46:28,122][root][INFO] - Step 23301120 @ 3069.5 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 7551.1, step = 23301120, mean_episode_return = 0.76968, mean_episode_step = 1749.8, total_loss = 63.998, pg_loss = 55.472, baseline_loss = 22.982, entropy_loss = -14.456, learner_queue_size = 64, _tick = 3469, _time = 1.6548e+09)
[2022-06-09 15:46:33,126][root][INFO] - Step 23316480 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 7556.1, step = 23316480, mean_episode_return = 4.5095, mean_episode_step = 1966.0, total_loss = 84.581, pg_loss = 75.752, baseline_loss = 23.227, entropy_loss = -14.398, learner_queue_size = 64, _tick = 3472, _time = 1.6548e+09)
[2022-06-09 15:46:38,130][root][INFO] - Step 23331840 @ 3069.6 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 7561.1, step = 23331840, mean_episode_return = None, mean_episode_step = 2147.8, total_loss = 109.47, pg_loss = 88.857, baseline_loss = 34.864, entropy_loss = -14.249, learner_queue_size = 64, _tick = 3474, _time = 1.6548e+09)
[2022-06-09 15:46:43,134][root][INFO] - Step 23347200 @ 3069.6 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 7566.1, step = 23347200, mean_episode_return = None, mean_episode_step = 2276.8, total_loss = -48.276, pg_loss = -52.162, baseline_loss = 17.972, entropy_loss = -14.086, learner_queue_size = 64, _tick = 3475, _time = 1.6548e+09)
[2022-06-09 15:46:48,140][root][INFO] - Step 23362560 @ 3068.3 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 7571.1, step = 23362560, mean_episode_return = None, mean_episode_step = 2220.9, total_loss = -118.03, pg_loss = -112.25, baseline_loss = 8.3123, entropy_loss = -14.09, learner_queue_size = 64, _tick = 3477, _time = 1.6548e+09)
[2022-06-09 15:46:53,146][root][INFO] - Step 23377920 @ 3068.3 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 7576.1, step = 23377920, mean_episode_return = 12.754, mean_episode_step = 1785.6, total_loss = -90.451, pg_loss = -97.624, baseline_loss = 21.39, entropy_loss = -14.217, learner_queue_size = 64, _tick = 3479, _time = 1.6548e+09)
[2022-06-09 15:46:58,151][root][INFO] - Step 23393280 @ 3068.9 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 7581.1, step = 23393280, mean_episode_return = 88.774, mean_episode_step = 1768.2, total_loss = 7.3976, pg_loss = -5.3302, baseline_loss = 27.021, entropy_loss = -14.293, learner_queue_size = 64, _tick = 3482, _time = 1.6548e+09)
[2022-06-09 15:47:03,154][root][INFO] - Step 23413760 @ 4093.7 SPS. Inference batcher size: 94. Learner queue size: 64. Other stats: (train_seconds = 7586.1, step = 23413760, mean_episode_return = 29.73, mean_episode_step = 1877.9, total_loss = 115.07, pg_loss = 102.53, baseline_loss = 26.537, entropy_loss = -13.995, learner_queue_size = 64, _tick = 3484, _time = 1.6548e+09)
[2022-06-09 15:47:08,158][root][INFO] - Step 23429120 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 7591.1, step = 23429120, mean_episode_return = None, mean_episode_step = 1917.5, total_loss = -157.89, pg_loss = -151.58, baseline_loss = 7.6459, entropy_loss = -13.955, learner_queue_size = 64, _tick = 3486, _time = 1.6548e+09)
[2022-06-09 15:47:13,162][root][INFO] - Step 23444480 @ 3069.5 SPS. Inference batcher size: 97. Learner queue size: 64. Other stats: (train_seconds = 7596.1, step = 23444480, mean_episode_return = 24.34, mean_episode_step = 2364.2, total_loss = 45.367, pg_loss = 15.373, baseline_loss = 43.895, entropy_loss = -13.902, learner_queue_size = 64, _tick = 3489, _time = 1.6548e+09)
[2022-06-09 15:47:18,166][root][INFO] - Step 23459840 @ 3069.6 SPS. Inference batcher size: 82. Learner queue size: 64. Other stats: (train_seconds = 7601.1, step = 23459840, mean_episode_return = 3.6454, mean_episode_step = 2037.5, total_loss = -114.63, pg_loss = -118.15, baseline_loss = 17.592, entropy_loss = -14.074, learner_queue_size = 64, _tick = 3491, _time = 1.6548e+09)
[2022-06-09 15:47:23,176][root][INFO] - Step 23475200 @ 3065.9 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 7606.1, step = 23475200, mean_episode_return = None, mean_episode_step = 2363.3, total_loss = -113.98, pg_loss = -106.93, baseline_loss = 6.8869, entropy_loss = -13.931, learner_queue_size = 64, _tick = 3491, _time = 1.6548e+09)
[2022-06-09 15:47:28,182][root][INFO] - Step 23490560 @ 3068.3 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 7611.1, step = 23490560, mean_episode_return = 38.291, mean_episode_step = 2295.7, total_loss = -176.61, pg_loss = -173.23, baseline_loss = 10.555, entropy_loss = -13.933, learner_queue_size = 64, _tick = 3494, _time = 1.6548e+09)
[2022-06-09 15:47:33,186][root][INFO] - Step 23505920 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 7616.1, step = 23505920, mean_episode_return = 31.891, mean_episode_step = 2074.5, total_loss = 46.52, pg_loss = 29.076, baseline_loss = 31.47, entropy_loss = -14.026, learner_queue_size = 64, _tick = 3496, _time = 1.6548e+09)
[2022-06-09 15:47:38,190][root][INFO] - Step 23521280 @ 3069.6 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 7621.1, step = 23521280, mean_episode_return = None, mean_episode_step = 2329.8, total_loss = -40.605, pg_loss = -39.612, baseline_loss = 12.937, entropy_loss = -13.93, learner_queue_size = 64, _tick = 3498, _time = 1.6548e+09)
[2022-06-09 15:47:43,194][root][INFO] - Step 23536640 @ 3069.5 SPS. Inference batcher size: 14. Learner queue size: 64. Other stats: (train_seconds = 7626.1, step = 23536640, mean_episode_return = 27.63, mean_episode_step = 2129.2, total_loss = -18.099, pg_loss = -20.014, baseline_loss = 15.735, entropy_loss = -13.819, learner_queue_size = 64, _tick = 3500, _time = 1.6548e+09)
[2022-06-09 15:47:48,198][root][INFO] - Step 23557120 @ 4092.8 SPS. Inference batcher size: 86. Learner queue size: 64. Other stats: (train_seconds = 7631.1, step = 23557120, mean_episode_return = None, mean_episode_step = 2326.0, total_loss = -106.29, pg_loss = -97.148, baseline_loss = 4.9852, entropy_loss = -14.132, learner_queue_size = 64, _tick = 3502, _time = 1.6548e+09)
[2022-06-09 15:47:53,202][root][INFO] - Step 23572480 @ 3069.5 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 7636.1, step = 23572480, mean_episode_return = 39.282, mean_episode_step = 2524.9, total_loss = 408.35, pg_loss = 316.82, baseline_loss = 105.58, entropy_loss = -14.051, learner_queue_size = 64, _tick = 3505, _time = 1.6548e+09)
[2022-06-09 15:47:58,206][root][INFO] - Step 23587840 @ 3069.6 SPS. Inference batcher size: 77. Learner queue size: 64. Other stats: (train_seconds = 7641.1, step = 23587840, mean_episode_return = 81.683, mean_episode_step = 2652.9, total_loss = 55.156, pg_loss = 36.066, baseline_loss = 33.281, entropy_loss = -14.192, learner_queue_size = 64, _tick = 3507, _time = 1.6548e+09)
[2022-06-09 15:48:03,210][root][INFO] - Step 23603200 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 7646.1, step = 23603200, mean_episode_return = 65.964, mean_episode_step = 2594.0, total_loss = 297.72, pg_loss = 233.3, baseline_loss = 78.643, entropy_loss = -14.223, learner_queue_size = 64, _tick = 3509, _time = 1.6548e+09)
[2022-06-09 15:48:08,214][root][INFO] - Step 23618560 @ 3069.3 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 7651.2, step = 23618560, mean_episode_return = 56.0, mean_episode_step = 2379.3, total_loss = -98.37, pg_loss = -95.349, baseline_loss = 11.144, entropy_loss = -14.165, learner_queue_size = 64, _tick = 3511, _time = 1.6548e+09)
[2022-06-09 15:48:13,218][root][INFO] - Step 23633920 @ 3069.8 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 7656.2, step = 23633920, mean_episode_return = 50.773, mean_episode_step = 2238.6, total_loss = 69.461, pg_loss = 52.828, baseline_loss = 30.85, entropy_loss = -14.217, learner_queue_size = 64, _tick = 3513, _time = 1.6548e+09)
[2022-06-09 15:48:18,222][root][INFO] - Step 23649280 @ 3069.6 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 7661.2, step = 23649280, mean_episode_return = 16.346, mean_episode_step = 2657.5, total_loss = 5.5712, pg_loss = -12.126, baseline_loss = 32.18, entropy_loss = -14.483, learner_queue_size = 64, _tick = 3516, _time = 1.6548e+09)
[2022-06-09 15:48:23,228][root][INFO] - Step 23664640 @ 3068.3 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 7666.2, step = 23664640, mean_episode_return = 26.915, mean_episode_step = 2286.4, total_loss = 411.18, pg_loss = 363.61, baseline_loss = 62.061, entropy_loss = -14.489, learner_queue_size = 64, _tick = 3519, _time = 1.6548e+09)
[2022-06-09 15:48:28,234][root][INFO] - Step 23680000 @ 3068.4 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 7671.2, step = 23680000, mean_episode_return = 4.3857, mean_episode_step = 2427.4, total_loss = -140.25, pg_loss = -138.24, baseline_loss = 12.601, entropy_loss = -14.613, learner_queue_size = 64, _tick = 3521, _time = 1.6548e+09)
[2022-06-09 15:48:33,238][root][INFO] - Step 23695360 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 7676.2, step = 23695360, mean_episode_return = 89.897, mean_episode_step = 2186.3, total_loss = -23.183, pg_loss = -30.978, baseline_loss = 22.747, entropy_loss = -14.952, learner_queue_size = 64, _tick = 3523, _time = 1.6548e+09)
[2022-06-09 15:48:38,242][root][INFO] - Step 23715840 @ 4092.7 SPS. Inference batcher size: 95. Learner queue size: 64. Other stats: (train_seconds = 7681.2, step = 23715840, mean_episode_return = 60.121, mean_episode_step = 2431.8, total_loss = -172.8, pg_loss = -168.67, baseline_loss = 10.498, entropy_loss = -14.63, learner_queue_size = 64, _tick = 3527, _time = 1.6548e+09)
[2022-06-09 15:48:43,246][root][INFO] - Step 23731200 @ 3069.6 SPS. Inference batcher size: 78. Learner queue size: 64. Other stats: (train_seconds = 7686.2, step = 23731200, mean_episode_return = -6.5005, mean_episode_step = 2327.2, total_loss = 187.36, pg_loss = 158.44, baseline_loss = 43.522, entropy_loss = -14.603, learner_queue_size = 64, _tick = 3530, _time = 1.6548e+09)
[2022-06-09 15:48:48,250][root][INFO] - Step 23746560 @ 3069.6 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 7691.2, step = 23746560, mean_episode_return = 18.544, mean_episode_step = 2305.3, total_loss = 37.387, pg_loss = 24.86, baseline_loss = 26.746, entropy_loss = -14.219, learner_queue_size = 64, _tick = 3532, _time = 1.6548e+09)
[2022-06-09 15:48:53,254][root][INFO] - Step 23761920 @ 3069.6 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 7696.2, step = 23761920, mean_episode_return = 2.4764, mean_episode_step = 2103.5, total_loss = 183.39, pg_loss = 155.75, baseline_loss = 41.743, entropy_loss = -14.099, learner_queue_size = 64, _tick = 3535, _time = 1.6548e+09)
[2022-06-09 15:48:58,258][root][INFO] - Step 23777280 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 7701.2, step = 23777280, mean_episode_return = 44.498, mean_episode_step = 2136.7, total_loss = -160.44, pg_loss = -168.96, baseline_loss = 22.649, entropy_loss = -14.124, learner_queue_size = 64, _tick = 3537, _time = 1.6548e+09)
[2022-06-09 15:49:03,262][root][INFO] - Step 23792640 @ 3069.5 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 7706.2, step = 23792640, mean_episode_return = 25.052, mean_episode_step = 2242.4, total_loss = -126.58, pg_loss = -122.6, baseline_loss = 10.292, entropy_loss = -14.274, learner_queue_size = 64, _tick = 3540, _time = 1.6548e+09)
[2022-06-09 15:49:08,266][root][INFO] - Step 23808000 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 7711.2, step = 23808000, mean_episode_return = 72.217, mean_episode_step = 2360.8, total_loss = 487.25, pg_loss = 431.37, baseline_loss = 70.206, entropy_loss = -14.325, learner_queue_size = 64, _tick = 3543, _time = 1.6548e+09)
[2022-06-09 15:49:13,270][root][INFO] - Step 23828480 @ 4092.8 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 7716.2, step = 23828480, mean_episode_return = None, mean_episode_step = 2480.7, total_loss = 241.79, pg_loss = 205.77, baseline_loss = 50.32, entropy_loss = -14.294, learner_queue_size = 64, _tick = 3546, _time = 1.6548e+09)
[2022-06-09 15:49:18,274][root][INFO] - Step 23843840 @ 3069.6 SPS. Inference batcher size: 4. Learner queue size: 64. Other stats: (train_seconds = 7721.2, step = 23843840, mean_episode_return = 158.9, mean_episode_step = 2221.5, total_loss = -122.91, pg_loss = -117.38, baseline_loss = 8.6785, entropy_loss = -14.212, learner_queue_size = 64, _tick = 3548, _time = 1.6548e+09)
[2022-06-09 15:49:23,279][root][INFO] - Step 23859200 @ 3068.8 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 7726.2, step = 23859200, mean_episode_return = None, mean_episode_step = 2521.4, total_loss = -167.14, pg_loss = -161.65, baseline_loss = 8.8003, entropy_loss = -14.292, learner_queue_size = 64, _tick = 3550, _time = 1.6548e+09)
[2022-06-09 15:49:28,285][root][INFO] - Step 23874560 @ 3068.3 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 7731.2, step = 23874560, mean_episode_return = -17.481, mean_episode_step = 2338.6, total_loss = 989.7, pg_loss = 465.56, baseline_loss = 538.56, entropy_loss = -14.417, learner_queue_size = 64, _tick = 3553, _time = 1.6548e+09)
[2022-06-09 15:49:33,290][root][INFO] - Step 23889920 @ 3069.0 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 7736.2, step = 23889920, mean_episode_return = None, mean_episode_step = 2371.1, total_loss = 95.82, pg_loss = 83.125, baseline_loss = 27.324, entropy_loss = -14.629, learner_queue_size = 64, _tick = 3554, _time = 1.6548e+09)
[2022-06-09 15:49:38,294][root][INFO] - Step 23905280 @ 3069.6 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 7741.2, step = 23905280, mean_episode_return = None, mean_episode_step = 2597.9, total_loss = 66.748, pg_loss = 60.593, baseline_loss = 20.456, entropy_loss = -14.301, learner_queue_size = 64, _tick = 3556, _time = 1.6548e+09)
[2022-06-09 15:49:43,298][root][INFO] - Step 23920640 @ 3069.6 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 7746.2, step = 23920640, mean_episode_return = 46.607, mean_episode_step = 2010.8, total_loss = -169.73, pg_loss = -172.55, baseline_loss = 17.015, entropy_loss = -14.194, learner_queue_size = 64, _tick = 3559, _time = 1.6548e+09)
[2022-06-09 15:49:48,302][root][INFO] - Step 23936000 @ 3069.5 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 7751.2, step = 23936000, mean_episode_return = 54.775, mean_episode_step = 2653.7, total_loss = 234.26, pg_loss = 192.68, baseline_loss = 55.789, entropy_loss = -14.211, learner_queue_size = 64, _tick = 3562, _time = 1.6548e+09)
[2022-06-09 15:49:53,306][root][INFO] - Step 23956480 @ 4092.8 SPS. Inference batcher size: 78. Learner queue size: 64. Other stats: (train_seconds = 7756.2, step = 23956480, mean_episode_return = 104.13, mean_episode_step = 2511.6, total_loss = -63.018, pg_loss = -69.216, baseline_loss = 20.451, entropy_loss = -14.253, learner_queue_size = 64, _tick = 3565, _time = 1.6548e+09)
[2022-06-09 15:49:58,311][root][INFO] - Step 23971840 @ 3069.2 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 7761.2, step = 23971840, mean_episode_return = None, mean_episode_step = 2358.5, total_loss = -24.521, pg_loss = -23.319, baseline_loss = 12.871, entropy_loss = -14.074, learner_queue_size = 64, _tick = 3567, _time = 1.6548e+09)
[2022-06-09 15:50:03,314][root][INFO] - Step 23987200 @ 3069.9 SPS. Inference batcher size: 74. Learner queue size: 64. Other stats: (train_seconds = 7766.2, step = 23987200, mean_episode_return = 73.055, mean_episode_step = 2429.8, total_loss = 0.68111, pg_loss = -18.022, baseline_loss = 32.837, entropy_loss = -14.134, learner_queue_size = 64, _tick = 3570, _time = 1.6548e+09)
[2022-06-09 15:50:08,318][root][INFO] - Step 24002560 @ 3069.5 SPS. Inference batcher size: 11. Learner queue size: 64. Other stats: (train_seconds = 7771.3, step = 24002560, mean_episode_return = None, mean_episode_step = 2761.6, total_loss = -34.978, pg_loss = -29.302, baseline_loss = 8.5236, entropy_loss = -14.2, learner_queue_size = 64, _tick = 3572, _time = 1.6548e+09)
[2022-06-09 15:50:13,322][root][INFO] - Step 24017920 @ 3069.5 SPS. Inference batcher size: 2. Learner queue size: 64. Other stats: (train_seconds = 7776.3, step = 24017920, mean_episode_return = 26.6, mean_episode_step = 2278.2, total_loss = 70.462, pg_loss = 55.161, baseline_loss = 29.539, entropy_loss = -14.239, learner_queue_size = 64, _tick = 3575, _time = 1.6548e+09)
[2022-06-09 15:50:18,326][root][INFO] - Step 24033280 @ 3069.6 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 7781.3, step = 24033280, mean_episode_return = None, mean_episode_step = 2273.0, total_loss = 55.806, pg_loss = 52.045, baseline_loss = 17.931, entropy_loss = -14.17, learner_queue_size = 64, _tick = 3577, _time = 1.6548e+09)
[2022-06-09 15:50:23,330][root][INFO] - Step 24048640 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 7786.3, step = 24048640, mean_episode_return = 31.978, mean_episode_step = 2379.5, total_loss = 14.59, pg_loss = 6.2821, baseline_loss = 22.919, entropy_loss = -14.612, learner_queue_size = 64, _tick = 3580, _time = 1.6548e+09)
[2022-06-09 15:50:28,334][root][INFO] - Step 24069120 @ 4092.7 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 7791.3, step = 24069120, mean_episode_return = 107.22, mean_episode_step = 2686.7, total_loss = -276.29, pg_loss = -266.29, baseline_loss = 4.3322, entropy_loss = -14.329, learner_queue_size = 64, _tick = 3583, _time = 1.6548e+09)
[2022-06-09 15:50:33,338][root][INFO] - Step 24084480 @ 3069.5 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 7796.3, step = 24084480, mean_episode_return = 60.83, mean_episode_step = 2428.8, total_loss = 66.944, pg_loss = 57.699, baseline_loss = 23.623, entropy_loss = -14.378, learner_queue_size = 64, _tick = 3585, _time = 1.6548e+09)
[2022-06-09 15:50:38,342][root][INFO] - Step 24099840 @ 3069.6 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 7801.3, step = 24099840, mean_episode_return = 9.7648, mean_episode_step = 2327.0, total_loss = 362.1, pg_loss = 315.85, baseline_loss = 60.569, entropy_loss = -14.313, learner_queue_size = 64, _tick = 3587, _time = 1.6548e+09)
[2022-06-09 15:50:43,346][root][INFO] - Step 24115200 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 7806.3, step = 24115200, mean_episode_return = 107.07, mean_episode_step = 2122.3, total_loss = 53.804, pg_loss = 47.782, baseline_loss = 20.399, entropy_loss = -14.377, learner_queue_size = 64, _tick = 3590, _time = 1.6548e+09)
[2022-06-09 15:50:48,350][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 15:50:48,639][root][INFO] - Step 24130560 @ 3069.6 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 7811.3, step = 24130560, mean_episode_return = 28.211, mean_episode_step = 2302.9, total_loss = -134.3, pg_loss = -138.0, baseline_loss = 18.167, entropy_loss = -14.467, learner_queue_size = 64, _tick = 3592, _time = 1.6548e+09)
[2022-06-09 15:50:53,642][root][INFO] - Step 24145920 @ 2902.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 7816.6, step = 24145920, mean_episode_return = 65.188, mean_episode_step = 2457.0, total_loss = 75.746, pg_loss = 50.064, baseline_loss = 39.799, entropy_loss = -14.118, learner_queue_size = 64, _tick = 3595, _time = 1.6548e+09)
[2022-06-09 15:50:58,647][root][INFO] - Step 24161280 @ 3068.8 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 7821.6, step = 24161280, mean_episode_return = -37.22, mean_episode_step = 2489.2, total_loss = -97.951, pg_loss = -102.95, baseline_loss = 19.286, entropy_loss = -14.286, learner_queue_size = 64, _tick = 3597, _time = 1.6548e+09)
[2022-06-09 15:51:03,650][root][INFO] - Step 24176640 @ 3070.3 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 7826.6, step = 24176640, mean_episode_return = 71.396, mean_episode_step = 2411.4, total_loss = -36.17, pg_loss = -50.285, baseline_loss = 28.406, entropy_loss = -14.29, learner_queue_size = 64, _tick = 3600, _time = 1.6548e+09)
[2022-06-09 15:51:08,654][root][INFO] - Step 24197120 @ 4092.7 SPS. Inference batcher size: 80. Learner queue size: 64. Other stats: (train_seconds = 7831.6, step = 24197120, mean_episode_return = 95.527, mean_episode_step = 2410.9, total_loss = -92.771, pg_loss = -106.74, baseline_loss = 28.003, entropy_loss = -14.03, learner_queue_size = 64, _tick = 3604, _time = 1.6548e+09)
[2022-06-09 15:51:13,658][root][INFO] - Step 24212480 @ 3069.5 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 7836.6, step = 24212480, mean_episode_return = 21.89, mean_episode_step = 2126.8, total_loss = -53.262, pg_loss = -68.705, baseline_loss = 29.062, entropy_loss = -13.619, learner_queue_size = 64, _tick = 3607, _time = 1.6548e+09)
[2022-06-09 15:51:18,662][root][INFO] - Step 24227840 @ 3069.6 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 7841.6, step = 24227840, mean_episode_return = 129.84, mean_episode_step = 2342.1, total_loss = -59.731, pg_loss = -67.246, baseline_loss = 21.14, entropy_loss = -13.625, learner_queue_size = 64, _tick = 3610, _time = 1.6548e+09)
[2022-06-09 15:51:23,666][root][INFO] - Step 24243200 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 7846.6, step = 24243200, mean_episode_return = 186.92, mean_episode_step = 2499.5, total_loss = -155.41, pg_loss = -149.4, baseline_loss = 7.6408, entropy_loss = -13.648, learner_queue_size = 64, _tick = 3613, _time = 1.6548e+09)
[2022-06-09 15:51:28,670][root][INFO] - Step 24258560 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 7851.6, step = 24258560, mean_episode_return = 77.546, mean_episode_step = 1992.8, total_loss = 96.558, pg_loss = 68.606, baseline_loss = 41.703, entropy_loss = -13.75, learner_queue_size = 64, _tick = 3615, _time = 1.6548e+09)
[2022-06-09 15:51:33,674][root][INFO] - Step 24273920 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 7856.6, step = 24273920, mean_episode_return = 63.839, mean_episode_step = 2203.2, total_loss = -183.92, pg_loss = -179.22, baseline_loss = 8.8403, entropy_loss = -13.539, learner_queue_size = 64, _tick = 3617, _time = 1.6548e+09)
[2022-06-09 15:51:38,678][root][INFO] - Step 24289280 @ 3069.4 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 7861.6, step = 24289280, mean_episode_return = None, mean_episode_step = 2413.5, total_loss = 112.3, pg_loss = 91.882, baseline_loss = 33.801, entropy_loss = -13.385, learner_queue_size = 64, _tick = 3618, _time = 1.6548e+09)
[2022-06-09 15:51:43,682][root][INFO] - Step 24304640 @ 3069.7 SPS. Inference batcher size: 3. Learner queue size: 64. Other stats: (train_seconds = 7866.6, step = 24304640, mean_episode_return = None, mean_episode_step = 2417.8, total_loss = 252.68, pg_loss = 231.88, baseline_loss = 34.111, entropy_loss = -13.311, learner_queue_size = 64, _tick = 3620, _time = 1.6548e+09)
[2022-06-09 15:51:48,686][root][INFO] - Step 24325120 @ 4092.8 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 7871.6, step = 24325120, mean_episode_return = None, mean_episode_step = 2470.0, total_loss = -8.2295, pg_loss = -23.719, baseline_loss = 28.797, entropy_loss = -13.307, learner_queue_size = 64, _tick = 3623, _time = 1.6548e+09)
[2022-06-09 15:51:53,692][root][INFO] - Step 24340480 @ 3068.4 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 7876.6, step = 24340480, mean_episode_return = 34.141, mean_episode_step = 2625.2, total_loss = 120.53, pg_loss = 102.3, baseline_loss = 31.701, entropy_loss = -13.471, learner_queue_size = 64, _tick = 3626, _time = 1.6548e+09)
[2022-06-09 15:51:58,694][root][INFO] - Step 24355840 @ 3070.6 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 7881.6, step = 24355840, mean_episode_return = 23.02, mean_episode_step = 1916.5, total_loss = 155.98, pg_loss = 127.67, baseline_loss = 41.841, entropy_loss = -13.528, learner_queue_size = 64, _tick = 3628, _time = 1.6548e+09)
[2022-06-09 15:52:03,698][root][INFO] - Step 24371200 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 7886.6, step = 24371200, mean_episode_return = None, mean_episode_step = 2378.6, total_loss = 18.866, pg_loss = 17.873, baseline_loss = 14.399, entropy_loss = -13.405, learner_queue_size = 64, _tick = 3630, _time = 1.6548e+09)
[2022-06-09 15:52:08,702][root][INFO] - Step 24386560 @ 3069.6 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 7891.6, step = 24386560, mean_episode_return = None, mean_episode_step = 2083.8, total_loss = -100.88, pg_loss = -104.05, baseline_loss = 16.792, entropy_loss = -13.629, learner_queue_size = 64, _tick = 3632, _time = 1.6548e+09)
[2022-06-09 15:52:13,706][root][INFO] - Step 24401920 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 7896.6, step = 24401920, mean_episode_return = 37.0, mean_episode_step = 2471.4, total_loss = 54.042, pg_loss = 37.914, baseline_loss = 29.471, entropy_loss = -13.342, learner_queue_size = 64, _tick = 3635, _time = 1.6548e+09)
[2022-06-09 15:52:18,710][root][INFO] - Step 24417280 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 7901.6, step = 24417280, mean_episode_return = None, mean_episode_step = 2585.6, total_loss = 85.559, pg_loss = 76.397, baseline_loss = 22.548, entropy_loss = -13.385, learner_queue_size = 64, _tick = 3637, _time = 1.6548e+09)
[2022-06-09 15:52:23,714][root][INFO] - Step 24432640 @ 3069.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 7906.7, step = 24432640, mean_episode_return = None, mean_episode_step = 2248.6, total_loss = -18.759, pg_loss = -18.811, baseline_loss = 13.307, entropy_loss = -13.256, learner_queue_size = 64, _tick = 3639, _time = 1.6548e+09)
[2022-06-09 15:52:28,718][root][INFO] - Step 24453120 @ 4092.8 SPS. Inference batcher size: 76. Learner queue size: 64. Other stats: (train_seconds = 7911.7, step = 24453120, mean_episode_return = -25.864, mean_episode_step = 2182.2, total_loss = 106.75, pg_loss = 89.723, baseline_loss = 30.487, entropy_loss = -13.463, learner_queue_size = 64, _tick = 3643, _time = 1.6548e+09)
[2022-06-09 15:52:33,724][root][INFO] - Step 24468480 @ 3068.3 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 7916.7, step = 24468480, mean_episode_return = 28.511, mean_episode_step = 2129.8, total_loss = 79.158, pg_loss = 67.421, baseline_loss = 24.943, entropy_loss = -13.205, learner_queue_size = 64, _tick = 3646, _time = 1.6548e+09)
[2022-06-09 15:52:38,730][root][INFO] - Step 24483840 @ 3068.3 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 7921.7, step = 24483840, mean_episode_return = 84.965, mean_episode_step = 1904.8, total_loss = 164.4, pg_loss = 131.31, baseline_loss = 46.325, entropy_loss = -13.234, learner_queue_size = 64, _tick = 3648, _time = 1.6548e+09)
[2022-06-09 15:52:43,734][root][INFO] - Step 24499200 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 7926.7, step = 24499200, mean_episode_return = -6.9912, mean_episode_step = 1822.5, total_loss = -87.28, pg_loss = -87.157, baseline_loss = 13.077, entropy_loss = -13.199, learner_queue_size = 64, _tick = 3651, _time = 1.6548e+09)
[2022-06-09 15:52:48,738][root][INFO] - Step 24514560 @ 3069.5 SPS. Inference batcher size: 8. Learner queue size: 64. Other stats: (train_seconds = 7931.7, step = 24514560, mean_episode_return = 61.437, mean_episode_step = 2137.0, total_loss = 254.84, pg_loss = 182.04, baseline_loss = 86.372, entropy_loss = -13.574, learner_queue_size = 64, _tick = 3652, _time = 1.6548e+09)
[2022-06-09 15:52:53,742][root][INFO] - Step 24529920 @ 3069.5 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 7936.7, step = 24529920, mean_episode_return = None, mean_episode_step = 1726.3, total_loss = -119.18, pg_loss = -112.98, baseline_loss = 7.2829, entropy_loss = -13.48, learner_queue_size = 64, _tick = 3654, _time = 1.6548e+09)
[2022-06-09 15:52:58,746][root][INFO] - Step 24545280 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 7941.7, step = 24545280, mean_episode_return = -31.721, mean_episode_step = 2211.7, total_loss = -63.219, pg_loss = -67.852, baseline_loss = 18.366, entropy_loss = -13.733, learner_queue_size = 64, _tick = 3655, _time = 1.6548e+09)
[2022-06-09 15:53:03,750][root][INFO] - Step 24560640 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 7946.7, step = 24560640, mean_episode_return = 28.42, mean_episode_step = 1987.2, total_loss = -4.7674, pg_loss = -9.7624, baseline_loss = 19.129, entropy_loss = -14.135, learner_queue_size = 64, _tick = 3658, _time = 1.6548e+09)
[2022-06-09 15:53:08,754][root][INFO] - Step 24581120 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 7951.7, step = 24581120, mean_episode_return = 14.162, mean_episode_step = 2185.1, total_loss = -197.92, pg_loss = -189.84, baseline_loss = 5.535, entropy_loss = -13.618, learner_queue_size = 64, _tick = 3662, _time = 1.6548e+09)
[2022-06-09 15:53:13,758][root][INFO] - Step 24596480 @ 3069.6 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 7956.7, step = 24596480, mean_episode_return = 28.224, mean_episode_step = 2030.2, total_loss = 24.113, pg_loss = 10.576, baseline_loss = 27.05, entropy_loss = -13.512, learner_queue_size = 64, _tick = 3665, _time = 1.6548e+09)
[2022-06-09 15:53:18,762][root][INFO] - Step 24611840 @ 3069.5 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 7961.7, step = 24611840, mean_episode_return = 82.498, mean_episode_step = 2151.5, total_loss = 152.13, pg_loss = 132.74, baseline_loss = 32.965, entropy_loss = -13.572, learner_queue_size = 64, _tick = 3668, _time = 1.6548e+09)
[2022-06-09 15:53:23,766][root][INFO] - Step 24627200 @ 3069.5 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 7966.7, step = 24627200, mean_episode_return = 116.42, mean_episode_step = 1953.8, total_loss = 226.46, pg_loss = 172.34, baseline_loss = 67.771, entropy_loss = -13.657, learner_queue_size = 64, _tick = 3670, _time = 1.6548e+09)
[2022-06-09 15:53:28,770][root][INFO] - Step 24642560 @ 3069.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 7971.7, step = 24642560, mean_episode_return = 88.139, mean_episode_step = 2113.1, total_loss = -268.23, pg_loss = -261.76, baseline_loss = 7.2355, entropy_loss = -13.713, learner_queue_size = 64, _tick = 3672, _time = 1.6548e+09)
[2022-06-09 15:53:33,774][root][INFO] - Step 24657920 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 7976.7, step = 24657920, mean_episode_return = 71.969, mean_episode_step = 1741.8, total_loss = -161.09, pg_loss = -162.35, baseline_loss = 15.085, entropy_loss = -13.824, learner_queue_size = 64, _tick = 3674, _time = 1.6548e+09)
[2022-06-09 15:53:38,778][root][INFO] - Step 24673280 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 7981.7, step = 24673280, mean_episode_return = 33.08, mean_episode_step = 2144.4, total_loss = -35.254, pg_loss = -48.48, baseline_loss = 27.124, entropy_loss = -13.897, learner_queue_size = 64, _tick = 3677, _time = 1.6548e+09)
[2022-06-09 15:53:43,782][root][INFO] - Step 24693760 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 7986.7, step = 24693760, mean_episode_return = -21.891, mean_episode_step = 2139.9, total_loss = 145.42, pg_loss = 122.19, baseline_loss = 37.305, entropy_loss = -14.074, learner_queue_size = 64, _tick = 3680, _time = 1.6548e+09)
[2022-06-09 15:53:48,786][root][INFO] - Step 24709120 @ 3069.5 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 7991.7, step = 24709120, mean_episode_return = 68.152, mean_episode_step = 1889.3, total_loss = 150.14, pg_loss = 118.8, baseline_loss = 45.303, entropy_loss = -13.969, learner_queue_size = 64, _tick = 3682, _time = 1.6548e+09)
[2022-06-09 15:53:53,790][root][INFO] - Step 24724480 @ 3069.6 SPS. Inference batcher size: 72. Learner queue size: 64. Other stats: (train_seconds = 7996.7, step = 24724480, mean_episode_return = None, mean_episode_step = 1852.8, total_loss = -83.778, pg_loss = -78.15, baseline_loss = 8.5088, entropy_loss = -14.137, learner_queue_size = 64, _tick = 3684, _time = 1.6548e+09)
[2022-06-09 15:53:58,794][root][INFO] - Step 24739840 @ 3069.5 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 8001.7, step = 24739840, mean_episode_return = 61.4, mean_episode_step = 2395.8, total_loss = 19.984, pg_loss = 5.8297, baseline_loss = 28.414, entropy_loss = -14.259, learner_queue_size = 64, _tick = 3685, _time = 1.6548e+09)
[2022-06-09 15:54:03,798][root][INFO] - Step 24755200 @ 3069.6 SPS. Inference batcher size: 71. Learner queue size: 64. Other stats: (train_seconds = 8006.7, step = 24755200, mean_episode_return = 73.471, mean_episode_step = 2286.9, total_loss = 91.207, pg_loss = 74.876, baseline_loss = 30.662, entropy_loss = -14.332, learner_queue_size = 64, _tick = 3688, _time = 1.6548e+09)
[2022-06-09 15:54:08,802][root][INFO] - Step 24770560 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 8011.7, step = 24770560, mean_episode_return = None, mean_episode_step = 2014.4, total_loss = 79.991, pg_loss = 69.98, baseline_loss = 24.253, entropy_loss = -14.242, learner_queue_size = 64, _tick = 3690, _time = 1.6548e+09)
[2022-06-09 15:54:13,806][root][INFO] - Step 24785920 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 8016.7, step = 24785920, mean_episode_return = 46.463, mean_episode_step = 2695.0, total_loss = -133.14, pg_loss = -142.3, baseline_loss = 23.189, entropy_loss = -14.031, learner_queue_size = 64, _tick = 3692, _time = 1.6548e+09)
[2022-06-09 15:54:18,810][root][INFO] - Step 24801280 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 8021.7, step = 24801280, mean_episode_return = 64.183, mean_episode_step = 2523.0, total_loss = -3.0761, pg_loss = -23.895, baseline_loss = 34.885, entropy_loss = -14.066, learner_queue_size = 64, _tick = 3693, _time = 1.6548e+09)
[2022-06-09 15:54:23,814][root][INFO] - Step 24816640 @ 3069.6 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 8026.7, step = 24816640, mean_episode_return = 15.185, mean_episode_step = 2178.8, total_loss = -85.232, pg_loss = -89.003, baseline_loss = 17.899, entropy_loss = -14.129, learner_queue_size = 64, _tick = 3696, _time = 1.6548e+09)
[2022-06-09 15:54:28,818][root][INFO] - Step 24832000 @ 3069.5 SPS. Inference batcher size: 12. Learner queue size: 64. Other stats: (train_seconds = 8031.8, step = 24832000, mean_episode_return = 16.99, mean_episode_step = 2231.2, total_loss = -16.538, pg_loss = -28.416, baseline_loss = 26.197, entropy_loss = -14.319, learner_queue_size = 64, _tick = 3699, _time = 1.6548e+09)
[2022-06-09 15:54:33,824][root][INFO] - Step 24852480 @ 4091.0 SPS. Inference batcher size: 100. Learner queue size: 64. Other stats: (train_seconds = 8036.8, step = 24852480, mean_episode_return = None, mean_episode_step = 2058.3, total_loss = 321.88, pg_loss = 249.94, baseline_loss = 86.264, entropy_loss = -14.327, learner_queue_size = 64, _tick = 3701, _time = 1.6548e+09)
[2022-06-09 15:54:38,830][root][INFO] - Step 24867840 @ 3068.4 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 8041.8, step = 24867840, mean_episode_return = None, mean_episode_step = 2395.8, total_loss = -118.73, pg_loss = -111.35, baseline_loss = 6.9209, entropy_loss = -14.304, learner_queue_size = 64, _tick = 3703, _time = 1.6548e+09)
[2022-06-09 15:54:43,834][root][INFO] - Step 24883200 @ 3069.6 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 8046.8, step = 24883200, mean_episode_return = 75.219, mean_episode_step = 2188.9, total_loss = -234.45, pg_loss = -237.12, baseline_loss = 17.018, entropy_loss = -14.341, learner_queue_size = 64, _tick = 3706, _time = 1.6548e+09)
[2022-06-09 15:54:48,838][root][INFO] - Step 24898560 @ 3069.3 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 8051.8, step = 24898560, mean_episode_return = 94.004, mean_episode_step = 2502.1, total_loss = -86.977, pg_loss = -93.934, baseline_loss = 21.219, entropy_loss = -14.263, learner_queue_size = 64, _tick = 3709, _time = 1.6548e+09)
[2022-06-09 15:54:53,842][root][INFO] - Step 24913920 @ 3069.8 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 8056.8, step = 24913920, mean_episode_return = 42.44, mean_episode_step = 2098.3, total_loss = -52.016, pg_loss = -54.925, baseline_loss = 17.125, entropy_loss = -14.216, learner_queue_size = 64, _tick = 3712, _time = 1.6548e+09)
[2022-06-09 15:54:58,846][root][INFO] - Step 24929280 @ 3069.6 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 8061.8, step = 24929280, mean_episode_return = -4.2039, mean_episode_step = 1920.2, total_loss = 92.788, pg_loss = 77.032, baseline_loss = 29.601, entropy_loss = -13.845, learner_queue_size = 64, _tick = 3715, _time = 1.6548e+09)
[2022-06-09 15:55:03,850][root][INFO] - Step 24944640 @ 3069.4 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 8066.8, step = 24944640, mean_episode_return = 55.054, mean_episode_step = 1606.8, total_loss = 97.507, pg_loss = 82.84, baseline_loss = 28.675, entropy_loss = -14.008, learner_queue_size = 64, _tick = 3718, _time = 1.6548e+09)
[2022-06-09 15:55:08,854][root][INFO] - Step 24960000 @ 3069.6 SPS. Inference batcher size: 3. Learner queue size: 64. Other stats: (train_seconds = 8071.8, step = 24960000, mean_episode_return = None, mean_episode_step = 2131.7, total_loss = 338.77, pg_loss = 303.79, baseline_loss = 49.065, entropy_loss = -14.083, learner_queue_size = 64, _tick = 3720, _time = 1.6548e+09)
[2022-06-09 15:55:13,858][root][INFO] - Step 24975360 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 8076.8, step = 24975360, mean_episode_return = 30.71, mean_episode_step = 1658.7, total_loss = 106.94, pg_loss = 94.524, baseline_loss = 26.222, entropy_loss = -13.809, learner_queue_size = 64, _tick = 3723, _time = 1.6548e+09)
[2022-06-09 15:55:18,862][root][INFO] - Step 24990720 @ 3069.5 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 8081.8, step = 24990720, mean_episode_return = 23.83, mean_episode_step = 1909.4, total_loss = -21.372, pg_loss = -27.182, baseline_loss = 19.714, entropy_loss = -13.904, learner_queue_size = 64, _tick = 3726, _time = 1.6548e+09)
[2022-06-09 15:55:23,866][root][INFO] - Step 25011200 @ 4092.7 SPS. Inference batcher size: 88. Learner queue size: 64. Other stats: (train_seconds = 8086.8, step = 25011200, mean_episode_return = 50.164, mean_episode_step = 1903.6, total_loss = 78.965, pg_loss = 70.883, baseline_loss = 22.377, entropy_loss = -14.295, learner_queue_size = 64, _tick = 3729, _time = 1.6548e+09)
[2022-06-09 15:55:28,870][root][INFO] - Step 25026560 @ 3069.6 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 8091.8, step = 25026560, mean_episode_return = 19.405, mean_episode_step = 2064.0, total_loss = -169.01, pg_loss = -169.17, baseline_loss = 14.649, entropy_loss = -14.482, learner_queue_size = 64, _tick = 3732, _time = 1.6548e+09)
[2022-06-09 15:55:33,874][root][INFO] - Step 25041920 @ 3069.5 SPS. Inference batcher size: 89. Learner queue size: 64. Other stats: (train_seconds = 8096.8, step = 25041920, mean_episode_return = 18.466, mean_episode_step = 2184.4, total_loss = -130.08, pg_loss = -128.55, baseline_loss = 13.001, entropy_loss = -14.537, learner_queue_size = 64, _tick = 3735, _time = 1.6548e+09)
[2022-06-09 15:55:38,878][root][INFO] - Step 25057280 @ 3069.6 SPS. Inference batcher size: 82. Learner queue size: 64. Other stats: (train_seconds = 8101.8, step = 25057280, mean_episode_return = 80.252, mean_episode_step = 2445.2, total_loss = -136.35, pg_loss = -138.99, baseline_loss = 17.255, entropy_loss = -14.607, learner_queue_size = 64, _tick = 3738, _time = 1.6548e+09)
[2022-06-09 15:55:43,898][root][INFO] - Step 25072640 @ 3060.1 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 8106.8, step = 25072640, mean_episode_return = None, mean_episode_step = 2063.8, total_loss = -10.173, pg_loss = -11.308, baseline_loss = 16.037, entropy_loss = -14.903, learner_queue_size = 64, _tick = 3740, _time = 1.6548e+09)
[2022-06-09 15:55:48,902][root][INFO] - Step 25088000 @ 3069.3 SPS. Inference batcher size: 18. Learner queue size: 64. Other stats: (train_seconds = 8111.8, step = 25088000, mean_episode_return = 0.0082035, mean_episode_step = 1936.2, total_loss = -34.806, pg_loss = -35.519, baseline_loss = 15.492, entropy_loss = -14.778, learner_queue_size = 64, _tick = 3742, _time = 1.6548e+09)
[2022-06-09 15:55:53,906][root][INFO] - Step 25103360 @ 3069.5 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 8116.8, step = 25103360, mean_episode_return = 37.563, mean_episode_step = 1614.7, total_loss = 9.7247, pg_loss = -0.04669, baseline_loss = 24.494, entropy_loss = -14.723, learner_queue_size = 64, _tick = 3744, _time = 1.6548e+09)
[2022-06-09 15:55:58,910][root][INFO] - Step 25118720 @ 3069.5 SPS. Inference batcher size: 18. Learner queue size: 64. Other stats: (train_seconds = 8121.8, step = 25118720, mean_episode_return = 187.18, mean_episode_step = 1868.9, total_loss = 143.38, pg_loss = 119.68, baseline_loss = 38.436, entropy_loss = -14.736, learner_queue_size = 64, _tick = 3747, _time = 1.6548e+09)
[2022-06-09 15:56:03,914][root][INFO] - Step 25134080 @ 3069.6 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 8126.8, step = 25134080, mean_episode_return = 16.682, mean_episode_step = 1998.4, total_loss = -186.77, pg_loss = -182.55, baseline_loss = 10.413, entropy_loss = -14.626, learner_queue_size = 64, _tick = 3749, _time = 1.6548e+09)
[2022-06-09 15:56:08,920][root][INFO] - Step 25149440 @ 3068.3 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 8131.9, step = 25149440, mean_episode_return = 78.024, mean_episode_step = 1934.6, total_loss = 138.46, pg_loss = 105.64, baseline_loss = 47.424, entropy_loss = -14.604, learner_queue_size = 64, _tick = 3752, _time = 1.6548e+09)
[2022-06-09 15:56:13,922][root][INFO] - Step 25169920 @ 4094.3 SPS. Inference batcher size: 68. Learner queue size: 64. Other stats: (train_seconds = 8136.9, step = 25169920, mean_episode_return = 52.203, mean_episode_step = 1947.6, total_loss = -96.695, pg_loss = -92.676, baseline_loss = 10.934, entropy_loss = -14.953, learner_queue_size = 64, _tick = 3756, _time = 1.6548e+09)
[2022-06-09 15:56:18,926][root][INFO] - Step 25185280 @ 3069.5 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 8141.9, step = 25185280, mean_episode_return = 43.591, mean_episode_step = 2375.0, total_loss = 110.59, pg_loss = 98.075, baseline_loss = 27.476, entropy_loss = -14.957, learner_queue_size = 64, _tick = 3758, _time = 1.6548e+09)
[2022-06-09 15:56:23,930][root][INFO] - Step 25200640 @ 3069.6 SPS. Inference batcher size: 73. Learner queue size: 64. Other stats: (train_seconds = 8146.9, step = 25200640, mean_episode_return = 35.552, mean_episode_step = 2224.8, total_loss = 168.4, pg_loss = 134.27, baseline_loss = 48.762, entropy_loss = -14.625, learner_queue_size = 64, _tick = 3761, _time = 1.6548e+09)
[2022-06-09 15:56:28,936][root][INFO] - Step 25216000 @ 3068.5 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 8151.9, step = 25216000, mean_episode_return = None, mean_episode_step = 2062.7, total_loss = 8.462, pg_loss = -2.3645, baseline_loss = 25.45, entropy_loss = -14.623, learner_queue_size = 64, _tick = 3763, _time = 1.6548e+09)
[2022-06-09 15:56:33,938][root][INFO] - Step 25231360 @ 3070.7 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 8156.9, step = 25231360, mean_episode_return = 12.08, mean_episode_step = 2077.3, total_loss = 80.704, pg_loss = 52.247, baseline_loss = 43.476, entropy_loss = -15.019, learner_queue_size = 64, _tick = 3766, _time = 1.6548e+09)
[2022-06-09 15:56:38,942][root][INFO] - Step 25246720 @ 3069.5 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 8161.9, step = 25246720, mean_episode_return = 58.821, mean_episode_step = 2046.0, total_loss = -207.25, pg_loss = -209.5, baseline_loss = 17.11, entropy_loss = -14.863, learner_queue_size = 64, _tick = 3769, _time = 1.6548e+09)
[2022-06-09 15:56:43,946][root][INFO] - Step 25262080 @ 3069.6 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 8166.9, step = 25262080, mean_episode_return = 20.629, mean_episode_step = 1845.0, total_loss = -139.07, pg_loss = -138.82, baseline_loss = 14.408, entropy_loss = -14.664, learner_queue_size = 64, _tick = 3772, _time = 1.6548e+09)
[2022-06-09 15:56:48,950][root][INFO] - Step 25277440 @ 3069.5 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 8171.9, step = 25277440, mean_episode_return = 77.698, mean_episode_step = 2148.0, total_loss = -25.69, pg_loss = -40.288, baseline_loss = 29.367, entropy_loss = -14.768, learner_queue_size = 64, _tick = 3774, _time = 1.6548e+09)
[2022-06-09 15:56:53,953][root][INFO] - Step 25292800 @ 3070.0 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 8176.9, step = 25292800, mean_episode_return = None, mean_episode_step = 2011.8, total_loss = -97.953, pg_loss = -97.178, baseline_loss = 13.626, entropy_loss = -14.401, learner_queue_size = 64, _tick = 3776, _time = 1.6548e+09)
[2022-06-09 15:56:58,959][root][INFO] - Step 25308160 @ 3068.3 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 8181.9, step = 25308160, mean_episode_return = 0.18974, mean_episode_step = 2262.7, total_loss = -117.89, pg_loss = -113.58, baseline_loss = 10.183, entropy_loss = -14.495, learner_queue_size = 64, _tick = 3779, _time = 1.6548e+09)
[2022-06-09 15:57:03,965][root][INFO] - Step 25328640 @ 4091.0 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 8186.9, step = 25328640, mean_episode_return = 116.73, mean_episode_step = 1799.6, total_loss = 36.706, pg_loss = 25.328, baseline_loss = 26.045, entropy_loss = -14.666, learner_queue_size = 64, _tick = 3782, _time = 1.6548e+09)
[2022-06-09 15:57:08,970][root][INFO] - Step 25344000 @ 3069.2 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 8191.9, step = 25344000, mean_episode_return = None, mean_episode_step = 2366.4, total_loss = 118.19, pg_loss = 99.331, baseline_loss = 33.412, entropy_loss = -14.556, learner_queue_size = 64, _tick = 3784, _time = 1.6548e+09)
[2022-06-09 15:57:13,974][root][INFO] - Step 25359360 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 8196.9, step = 25359360, mean_episode_return = -9.9649, mean_episode_step = 2412.0, total_loss = 0.54077, pg_loss = -14.896, baseline_loss = 29.745, entropy_loss = -14.308, learner_queue_size = 64, _tick = 3786, _time = 1.6548e+09)
[2022-06-09 15:57:18,978][root][INFO] - Step 25374720 @ 3069.6 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 8201.9, step = 25374720, mean_episode_return = 46.06, mean_episode_step = 2063.2, total_loss = -114.84, pg_loss = -110.28, baseline_loss = 9.7102, entropy_loss = -14.269, learner_queue_size = 64, _tick = 3789, _time = 1.6548e+09)
[2022-06-09 15:57:23,982][root][INFO] - Step 25390080 @ 3069.6 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 8206.9, step = 25390080, mean_episode_return = 73.933, mean_episode_step = 2107.5, total_loss = -166.03, pg_loss = -175.5, baseline_loss = 23.812, entropy_loss = -14.337, learner_queue_size = 64, _tick = 3792, _time = 1.6548e+09)
[2022-06-09 15:57:28,986][root][INFO] - Step 25405440 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 8211.9, step = 25405440, mean_episode_return = 24.8, mean_episode_step = 1810.9, total_loss = 58.243, pg_loss = 41.252, baseline_loss = 31.352, entropy_loss = -14.362, learner_queue_size = 64, _tick = 3795, _time = 1.6548e+09)
[2022-06-09 15:57:33,990][root][INFO] - Step 25420800 @ 3069.6 SPS. Inference batcher size: 15. Learner queue size: 64. Other stats: (train_seconds = 8216.9, step = 25420800, mean_episode_return = 73.088, mean_episode_step = 1969.6, total_loss = -55.365, pg_loss = -56.077, baseline_loss = 14.984, entropy_loss = -14.272, learner_queue_size = 64, _tick = 3798, _time = 1.6548e+09)
[2022-06-09 15:57:38,994][root][INFO] - Step 25441280 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 8221.9, step = 25441280, mean_episode_return = 22.709, mean_episode_step = 1932.6, total_loss = -64.723, pg_loss = -69.871, baseline_loss = 19.297, entropy_loss = -14.149, learner_queue_size = 64, _tick = 3802, _time = 1.6548e+09)
[2022-06-09 15:57:43,998][root][INFO] - Step 25456640 @ 3069.6 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 8226.9, step = 25456640, mean_episode_return = None, mean_episode_step = 1761.4, total_loss = 44.406, pg_loss = 38.553, baseline_loss = 20.178, entropy_loss = -14.325, learner_queue_size = 64, _tick = 3803, _time = 1.6548e+09)
[2022-06-09 15:57:49,002][root][INFO] - Step 25472000 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 8231.9, step = 25472000, mean_episode_return = 102.18, mean_episode_step = 2119.8, total_loss = 148.73, pg_loss = 99.691, baseline_loss = 63.326, entropy_loss = -14.288, learner_queue_size = 64, _tick = 3805, _time = 1.6548e+09)
[2022-06-09 15:57:54,006][root][INFO] - Step 25487360 @ 3069.5 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 8236.9, step = 25487360, mean_episode_return = 78.49, mean_episode_step = 1792.1, total_loss = 86.306, pg_loss = 70.595, baseline_loss = 30.104, entropy_loss = -14.393, learner_queue_size = 64, _tick = 3808, _time = 1.6548e+09)
[2022-06-09 15:57:59,010][root][INFO] - Step 25502720 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 8241.9, step = 25502720, mean_episode_return = 104.18, mean_episode_step = 2317.6, total_loss = 62.396, pg_loss = 44.262, baseline_loss = 32.448, entropy_loss = -14.314, learner_queue_size = 64, _tick = 3809, _time = 1.6548e+09)
[2022-06-09 15:58:04,014][root][INFO] - Step 25518080 @ 3069.5 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 8247.0, step = 25518080, mean_episode_return = 11.16, mean_episode_step = 2215.1, total_loss = 140.96, pg_loss = 112.85, baseline_loss = 42.221, entropy_loss = -14.119, learner_queue_size = 64, _tick = 3812, _time = 1.6548e+09)
[2022-06-09 15:58:09,018][root][INFO] - Step 25533440 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 8252.0, step = 25533440, mean_episode_return = 57.275, mean_episode_step = 1868.9, total_loss = 167.5, pg_loss = 128.86, baseline_loss = 52.648, entropy_loss = -14.004, learner_queue_size = 64, _tick = 3815, _time = 1.6548e+09)
[2022-06-09 15:58:14,022][root][INFO] - Step 25548800 @ 3069.6 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 8257.0, step = 25548800, mean_episode_return = 48.622, mean_episode_step = 2218.4, total_loss = -59.482, pg_loss = -72.964, baseline_loss = 27.447, entropy_loss = -13.965, learner_queue_size = 64, _tick = 3818, _time = 1.6548e+09)
[2022-06-09 15:58:19,028][root][INFO] - Step 25564160 @ 3068.3 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 8262.0, step = 25564160, mean_episode_return = None, mean_episode_step = 1740.5, total_loss = 101.53, pg_loss = 84.785, baseline_loss = 30.66, entropy_loss = -13.916, learner_queue_size = 64, _tick = 3820, _time = 1.6548e+09)
[2022-06-09 15:58:24,034][root][INFO] - Step 25584640 @ 4091.1 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 8267.0, step = 25584640, mean_episode_return = 30.602, mean_episode_step = 2091.1, total_loss = -115.37, pg_loss = -110.55, baseline_loss = 8.917, entropy_loss = -13.744, learner_queue_size = 64, _tick = 3823, _time = 1.6548e+09)
[2022-06-09 15:58:29,038][root][INFO] - Step 25600000 @ 3069.5 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 8272.0, step = 25600000, mean_episode_return = 72.481, mean_episode_step = 2257.3, total_loss = -174.1, pg_loss = -185.98, baseline_loss = 25.713, entropy_loss = -13.834, learner_queue_size = 64, _tick = 3825, _time = 1.6548e+09)
[2022-06-09 15:58:34,042][root][INFO] - Step 25615360 @ 3069.5 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 8277.0, step = 25615360, mean_episode_return = None, mean_episode_step = 2251.4, total_loss = -60.844, pg_loss = -63.206, baseline_loss = 16.343, entropy_loss = -13.981, learner_queue_size = 64, _tick = 3827, _time = 1.6548e+09)
[2022-06-09 15:58:39,046][root][INFO] - Step 25630720 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 8282.0, step = 25630720, mean_episode_return = 23.41, mean_episode_step = 2262.7, total_loss = -77.542, pg_loss = -80.47, baseline_loss = 16.924, entropy_loss = -13.996, learner_queue_size = 64, _tick = 3830, _time = 1.6548e+09)
[2022-06-09 15:58:44,050][root][INFO] - Step 25646080 @ 3069.6 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 8287.0, step = 25646080, mean_episode_return = None, mean_episode_step = 2194.6, total_loss = 5.9344, pg_loss = 4.0995, baseline_loss = 15.946, entropy_loss = -14.111, learner_queue_size = 64, _tick = 3832, _time = 1.6548e+09)
[2022-06-09 15:58:49,054][root][INFO] - Step 25661440 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 8292.0, step = 25661440, mean_episode_return = 12.6, mean_episode_step = 2085.5, total_loss = 114.2, pg_loss = 103.0, baseline_loss = 25.162, entropy_loss = -13.961, learner_queue_size = 64, _tick = 3835, _time = 1.6548e+09)
[2022-06-09 15:58:54,058][root][INFO] - Step 25676800 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 8297.0, step = 25676800, mean_episode_return = 80.168, mean_episode_step = 2081.3, total_loss = -64.538, pg_loss = -61.174, baseline_loss = 10.724, entropy_loss = -14.087, learner_queue_size = 64, _tick = 3838, _time = 1.6548e+09)
[2022-06-09 15:58:59,064][root][INFO] - Step 25692160 @ 3068.3 SPS. Inference batcher size: 2. Learner queue size: 64. Other stats: (train_seconds = 8302.0, step = 25692160, mean_episode_return = None, mean_episode_step = 2020.1, total_loss = 11.8, pg_loss = 12.684, baseline_loss = 13.063, entropy_loss = -13.947, learner_queue_size = 64, _tick = 3840, _time = 1.6548e+09)
[2022-06-09 15:59:04,066][root][INFO] - Step 25707520 @ 3070.8 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 8307.0, step = 25707520, mean_episode_return = 64.578, mean_episode_step = 2689.6, total_loss = 49.604, pg_loss = 29.007, baseline_loss = 34.71, entropy_loss = -14.113, learner_queue_size = 64, _tick = 3843, _time = 1.6548e+09)
[2022-06-09 15:59:09,070][root][INFO] - Step 25722880 @ 3069.6 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 8312.0, step = 25722880, mean_episode_return = 86.578, mean_episode_step = 2044.8, total_loss = -166.28, pg_loss = -155.29, baseline_loss = 3.1797, entropy_loss = -14.164, learner_queue_size = 64, _tick = 3846, _time = 1.6548e+09)
[2022-06-09 15:59:14,074][root][INFO] - Step 25738240 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 8317.0, step = 25738240, mean_episode_return = 28.404, mean_episode_step = 2361.6, total_loss = -163.54, pg_loss = -163.59, baseline_loss = 14.245, entropy_loss = -14.189, learner_queue_size = 64, _tick = 3848, _time = 1.6548e+09)
[2022-06-09 15:59:19,078][root][INFO] - Step 25753600 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 8322.0, step = 25753600, mean_episode_return = 85.9, mean_episode_step = 1901.5, total_loss = 149.64, pg_loss = 89.352, baseline_loss = 74.599, entropy_loss = -14.307, learner_queue_size = 64, _tick = 3850, _time = 1.6548e+09)
[2022-06-09 15:59:24,082][root][INFO] - Step 25768960 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 8327.0, step = 25768960, mean_episode_return = 73.283, mean_episode_step = 2362.3, total_loss = 38.521, pg_loss = 21.824, baseline_loss = 30.899, entropy_loss = -14.203, learner_queue_size = 64, _tick = 3852, _time = 1.6548e+09)
[2022-06-09 15:59:29,086][root][INFO] - Step 25789440 @ 4092.7 SPS. Inference batcher size: 79. Learner queue size: 64. Other stats: (train_seconds = 8332.0, step = 25789440, mean_episode_return = 25.555, mean_episode_step = 2119.3, total_loss = 164.94, pg_loss = 129.52, baseline_loss = 49.77, entropy_loss = -14.346, learner_queue_size = 64, _tick = 3855, _time = 1.6548e+09)
[2022-06-09 15:59:34,090][root][INFO] - Step 25804800 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 8337.0, step = 25804800, mean_episode_return = 74.503, mean_episode_step = 2220.8, total_loss = -76.936, pg_loss = -75.415, baseline_loss = 12.841, entropy_loss = -14.363, learner_queue_size = 64, _tick = 3857, _time = 1.6548e+09)
[2022-06-09 15:59:39,094][root][INFO] - Step 25820160 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 8342.0, step = 25820160, mean_episode_return = 80.028, mean_episode_step = 2017.8, total_loss = -83.759, pg_loss = -81.484, baseline_loss = 12.06, entropy_loss = -14.335, learner_queue_size = 64, _tick = 3860, _time = 1.6548e+09)
[2022-06-09 15:59:44,098][root][INFO] - Step 25835520 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 8347.0, step = 25835520, mean_episode_return = 29.328, mean_episode_step = 1943.0, total_loss = -26.926, pg_loss = -38.833, baseline_loss = 26.232, entropy_loss = -14.325, learner_queue_size = 64, _tick = 3862, _time = 1.6548e+09)
[2022-06-09 15:59:49,102][root][INFO] - Step 25850880 @ 3069.5 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 8352.0, step = 25850880, mean_episode_return = None, mean_episode_step = 2343.5, total_loss = -17.619, pg_loss = -11.522, baseline_loss = 8.0553, entropy_loss = -14.152, learner_queue_size = 64, _tick = 3864, _time = 1.6548e+09)
[2022-06-09 15:59:54,108][root][INFO] - Step 25866240 @ 3068.3 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 8357.0, step = 25866240, mean_episode_return = 29.209, mean_episode_step = 2118.9, total_loss = 346.47, pg_loss = 303.27, baseline_loss = 57.448, entropy_loss = -14.248, learner_queue_size = 64, _tick = 3867, _time = 1.6548e+09)
[2022-06-09 15:59:59,114][root][INFO] - Step 25881600 @ 3068.3 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 8362.0, step = 25881600, mean_episode_return = None, mean_episode_step = 2280.7, total_loss = 25.521, pg_loss = 22.053, baseline_loss = 17.626, entropy_loss = -14.158, learner_queue_size = 64, _tick = 3869, _time = 1.6548e+09)
[2022-06-09 16:00:04,120][root][INFO] - Step 25896960 @ 3068.3 SPS. Inference batcher size: 7. Learner queue size: 64. Other stats: (train_seconds = 8367.1, step = 25896960, mean_episode_return = None, mean_episode_step = 2351.7, total_loss = 0.12202, pg_loss = -4.4789, baseline_loss = 18.894, entropy_loss = -14.293, learner_queue_size = 64, _tick = 3871, _time = 1.6548e+09)
[2022-06-09 16:00:09,126][root][INFO] - Step 25912320 @ 3068.4 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 8372.1, step = 25912320, mean_episode_return = -0.88266, mean_episode_step = 2450.5, total_loss = -289.75, pg_loss = -279.37, baseline_loss = 3.9016, entropy_loss = -14.282, learner_queue_size = 64, _tick = 3873, _time = 1.6548e+09)
[2022-06-09 16:00:14,130][root][INFO] - Step 25927680 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 8377.1, step = 25927680, mean_episode_return = 54.956, mean_episode_step = 2015.4, total_loss = 133.47, pg_loss = 112.33, baseline_loss = 35.324, entropy_loss = -14.19, learner_queue_size = 64, _tick = 3875, _time = 1.6548e+09)
[2022-06-09 16:00:19,134][root][INFO] - Step 25943040 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 8382.1, step = 25943040, mean_episode_return = None, mean_episode_step = 2203.3, total_loss = -29.027, pg_loss = -31.159, baseline_loss = 15.972, entropy_loss = -13.839, learner_queue_size = 64, _tick = 3877, _time = 1.6548e+09)
[2022-06-09 16:00:24,138][root][INFO] - Step 25958400 @ 3069.4 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 8387.1, step = 25958400, mean_episode_return = 34.435, mean_episode_step = 2283.2, total_loss = 39.307, pg_loss = 2.3894, baseline_loss = 51.333, entropy_loss = -14.415, learner_queue_size = 64, _tick = 3880, _time = 1.6548e+09)
[2022-06-09 16:00:29,142][root][INFO] - Step 25978880 @ 4092.8 SPS. Inference batcher size: 6. Learner queue size: 64. Other stats: (train_seconds = 8392.1, step = 25978880, mean_episode_return = 45.081, mean_episode_step = 2323.6, total_loss = -258.0, pg_loss = -248.2, baseline_loss = 4.7937, entropy_loss = -14.591, learner_queue_size = 64, _tick = 3883, _time = 1.6548e+09)
[2022-06-09 16:00:34,146][root][INFO] - Step 25994240 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 8397.1, step = 25994240, mean_episode_return = 47.8, mean_episode_step = 2169.9, total_loss = 550.4, pg_loss = 470.13, baseline_loss = 95.002, entropy_loss = -14.733, learner_queue_size = 64, _tick = 3885, _time = 1.6548e+09)
[2022-06-09 16:00:39,152][root][INFO] - Step 26009600 @ 3068.2 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 8402.1, step = 26009600, mean_episode_return = None, mean_episode_step = 2096.2, total_loss = 279.15, pg_loss = 228.74, baseline_loss = 65.171, entropy_loss = -14.757, learner_queue_size = 64, _tick = 3887, _time = 1.6548e+09)
[2022-06-09 16:00:44,158][root][INFO] - Step 26024960 @ 3068.6 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 8407.1, step = 26024960, mean_episode_return = 61.6, mean_episode_step = 2200.7, total_loss = 126.01, pg_loss = 93.261, baseline_loss = 47.513, entropy_loss = -14.763, learner_queue_size = 64, _tick = 3890, _time = 1.6548e+09)
[2022-06-09 16:00:49,178][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 16:00:49,424][root][INFO] - Step 26040320 @ 3059.7 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 8412.1, step = 26040320, mean_episode_return = None, mean_episode_step = 2312.3, total_loss = 142.19, pg_loss = 123.89, baseline_loss = 32.925, entropy_loss = -14.631, learner_queue_size = 64, _tick = 3892, _time = 1.6548e+09)
[2022-06-09 16:00:54,430][root][INFO] - Step 26055680 @ 2924.6 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 8417.4, step = 26055680, mean_episode_return = 44.511, mean_episode_step = 2476.1, total_loss = -68.82, pg_loss = -71.719, baseline_loss = 17.468, entropy_loss = -14.569, learner_queue_size = 64, _tick = 3894, _time = 1.6548e+09)
[2022-06-09 16:00:59,434][root][INFO] - Step 26071040 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 8422.4, step = 26071040, mean_episode_return = None, mean_episode_step = 2090.1, total_loss = -111.95, pg_loss = -105.29, baseline_loss = 8.2267, entropy_loss = -14.884, learner_queue_size = 64, _tick = 3896, _time = 1.6548e+09)
[2022-06-09 16:01:04,438][root][INFO] - Step 26086400 @ 3069.5 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 8427.4, step = 26086400, mean_episode_return = 43.291, mean_episode_step = 2376.5, total_loss = 36.927, pg_loss = 27.698, baseline_loss = 24.323, entropy_loss = -15.094, learner_queue_size = 64, _tick = 3899, _time = 1.6548e+09)
[2022-06-09 16:01:09,442][root][INFO] - Step 26101760 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 8432.4, step = 26101760, mean_episode_return = 111.9, mean_episode_step = 2559.5, total_loss = 188.92, pg_loss = 165.63, baseline_loss = 38.248, entropy_loss = -14.958, learner_queue_size = 64, _tick = 3902, _time = 1.6548e+09)
[2022-06-09 16:01:14,448][root][INFO] - Step 26122240 @ 4090.9 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 8437.4, step = 26122240, mean_episode_return = 11.88, mean_episode_step = 2076.8, total_loss = 276.18, pg_loss = 254.37, baseline_loss = 36.542, entropy_loss = -14.725, learner_queue_size = 64, _tick = 3906, _time = 1.6548e+09)
[2022-06-09 16:01:19,454][root][INFO] - Step 26137600 @ 3068.5 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 8442.4, step = 26137600, mean_episode_return = 61.593, mean_episode_step = 2365.5, total_loss = -59.082, pg_loss = -65.348, baseline_loss = 21.043, entropy_loss = -14.777, learner_queue_size = 64, _tick = 3908, _time = 1.6548e+09)
[2022-06-09 16:01:24,458][root][INFO] - Step 26152960 @ 3069.5 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 8447.4, step = 26152960, mean_episode_return = 41.523, mean_episode_step = 1980.8, total_loss = -161.26, pg_loss = -155.55, baseline_loss = 9.3023, entropy_loss = -15.007, learner_queue_size = 64, _tick = 3911, _time = 1.6548e+09)
[2022-06-09 16:01:29,462][root][INFO] - Step 26168320 @ 3069.5 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 8452.4, step = 26168320, mean_episode_return = 53.437, mean_episode_step = 2319.9, total_loss = -77.829, pg_loss = -78.936, baseline_loss = 16.239, entropy_loss = -15.132, learner_queue_size = 64, _tick = 3914, _time = 1.6548e+09)
[2022-06-09 16:01:34,468][root][INFO] - Step 26183680 @ 3068.3 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 8457.4, step = 26183680, mean_episode_return = 40.758, mean_episode_step = 2347.3, total_loss = -18.171, pg_loss = -25.843, baseline_loss = 22.935, entropy_loss = -15.264, learner_queue_size = 64, _tick = 3916, _time = 1.6548e+09)
[2022-06-09 16:01:39,474][root][INFO] - Step 26199040 @ 3068.4 SPS. Inference batcher size: 67. Learner queue size: 64. Other stats: (train_seconds = 8462.4, step = 26199040, mean_episode_return = 64.715, mean_episode_step = 2252.7, total_loss = 156.24, pg_loss = 127.81, baseline_loss = 43.459, entropy_loss = -15.028, learner_queue_size = 64, _tick = 3918, _time = 1.6548e+09)
[2022-06-09 16:01:44,478][root][INFO] - Step 26214400 @ 3069.6 SPS. Inference batcher size: 75. Learner queue size: 64. Other stats: (train_seconds = 8467.4, step = 26214400, mean_episode_return = 76.396, mean_episode_step = 2291.3, total_loss = 117.81, pg_loss = 102.2, baseline_loss = 30.474, entropy_loss = -14.86, learner_queue_size = 64, _tick = 3920, _time = 1.6548e+09)
[2022-06-09 16:01:49,482][root][INFO] - Step 26229760 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 8472.4, step = 26229760, mean_episode_return = -15.543, mean_episode_step = 2116.8, total_loss = -9.8842, pg_loss = -20.558, baseline_loss = 25.52, entropy_loss = -14.846, learner_queue_size = 64, _tick = 3923, _time = 1.6548e+09)
[2022-06-09 16:01:54,486][root][INFO] - Step 26245120 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 8477.4, step = 26245120, mean_episode_return = 28.3, mean_episode_step = 2499.3, total_loss = -16.219, pg_loss = -14.34, baseline_loss = 12.942, entropy_loss = -14.822, learner_queue_size = 64, _tick = 3926, _time = 1.6548e+09)
[2022-06-09 16:01:59,490][root][INFO] - Step 26260480 @ 3069.5 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 8482.4, step = 26260480, mean_episode_return = None, mean_episode_step = 1761.2, total_loss = 37.648, pg_loss = 28.318, baseline_loss = 24.086, entropy_loss = -14.756, learner_queue_size = 64, _tick = 3928, _time = 1.6548e+09)
[2022-06-09 16:02:04,494][root][INFO] - Step 26275840 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 8487.4, step = 26275840, mean_episode_return = 67.559, mean_episode_step = 1909.0, total_loss = -5.2495, pg_loss = -12.399, baseline_loss = 21.709, entropy_loss = -14.559, learner_queue_size = 64, _tick = 3931, _time = 1.6548e+09)
[2022-06-09 16:02:09,498][root][INFO] - Step 26291200 @ 3069.5 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 8492.4, step = 26291200, mean_episode_return = 112.45, mean_episode_step = 2220.0, total_loss = 163.96, pg_loss = 134.46, baseline_loss = 44.173, entropy_loss = -14.674, learner_queue_size = 64, _tick = 3933, _time = 1.6548e+09)
[2022-06-09 16:02:14,502][root][INFO] - Step 26306560 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 8497.4, step = 26306560, mean_episode_return = 96.729, mean_episode_step = 1978.4, total_loss = 22.626, pg_loss = 14.987, baseline_loss = 22.28, entropy_loss = -14.64, learner_queue_size = 64, _tick = 3936, _time = 1.6548e+09)
[2022-06-09 16:02:19,507][root][INFO] - Step 26321920 @ 3068.8 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 8502.4, step = 26321920, mean_episode_return = 65.753, mean_episode_step = 1990.3, total_loss = -186.36, pg_loss = -178.12, baseline_loss = 6.2847, entropy_loss = -14.523, learner_queue_size = 64, _tick = 3939, _time = 1.6548e+09)
[2022-06-09 16:02:24,510][root][INFO] - Step 26342400 @ 4093.8 SPS. Inference batcher size: 85. Learner queue size: 64. Other stats: (train_seconds = 8507.4, step = 26342400, mean_episode_return = None, mean_episode_step = 2210.5, total_loss = 22.662, pg_loss = 16.201, baseline_loss = 21.172, entropy_loss = -14.711, learner_queue_size = 64, _tick = 3941, _time = 1.6548e+09)
[2022-06-09 16:02:29,514][root][INFO] - Step 26357760 @ 3069.5 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 8512.4, step = 26357760, mean_episode_return = -11.531, mean_episode_step = 2108.9, total_loss = 16.835, pg_loss = 17.508, baseline_loss = 14.304, entropy_loss = -14.977, learner_queue_size = 64, _tick = 3944, _time = 1.6548e+09)
[2022-06-09 16:02:34,518][root][INFO] - Step 26373120 @ 3069.5 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 8517.5, step = 26373120, mean_episode_return = 37.155, mean_episode_step = 1768.6, total_loss = -63.712, pg_loss = -63.12, baseline_loss = 14.282, entropy_loss = -14.874, learner_queue_size = 64, _tick = 3945, _time = 1.6548e+09)
[2022-06-09 16:02:39,522][root][INFO] - Step 26388480 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 8522.5, step = 26388480, mean_episode_return = -4.3977, mean_episode_step = 1549.5, total_loss = 139.56, pg_loss = 125.98, baseline_loss = 28.427, entropy_loss = -14.852, learner_queue_size = 64, _tick = 3947, _time = 1.6548e+09)
[2022-06-09 16:02:44,526][root][INFO] - Step 26403840 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 8527.5, step = 26403840, mean_episode_return = None, mean_episode_step = 2164.3, total_loss = -52.753, pg_loss = -47.861, baseline_loss = 9.9702, entropy_loss = -14.862, learner_queue_size = 64, _tick = 3949, _time = 1.6548e+09)
[2022-06-09 16:02:49,530][root][INFO] - Step 26419200 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 8532.5, step = 26419200, mean_episode_return = 46.863, mean_episode_step = 2085.9, total_loss = 126.22, pg_loss = 116.5, baseline_loss = 24.833, entropy_loss = -15.112, learner_queue_size = 64, _tick = 3952, _time = 1.6548e+09)
[2022-06-09 16:02:54,534][root][INFO] - Step 26434560 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 8537.5, step = 26434560, mean_episode_return = 42.289, mean_episode_step = 1969.2, total_loss = -22.194, pg_loss = -23.463, baseline_loss = 16.365, entropy_loss = -15.097, learner_queue_size = 64, _tick = 3954, _time = 1.6548e+09)
[2022-06-09 16:02:59,540][root][INFO] - Step 26449920 @ 3068.2 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 8542.5, step = 26449920, mean_episode_return = -4.6502, mean_episode_step = 1553.0, total_loss = 281.32, pg_loss = 237.8, baseline_loss = 58.404, entropy_loss = -14.886, learner_queue_size = 64, _tick = 3956, _time = 1.6548e+09)
[2022-06-09 16:03:04,546][root][INFO] - Step 26470400 @ 4091.1 SPS. Inference batcher size: 7. Learner queue size: 64. Other stats: (train_seconds = 8547.5, step = 26470400, mean_episode_return = 18.54, mean_episode_step = 1622.8, total_loss = 332.73, pg_loss = 299.46, baseline_loss = 48.021, entropy_loss = -14.747, learner_queue_size = 64, _tick = 3960, _time = 1.6548e+09)
[2022-06-09 16:03:09,550][root][INFO] - Step 26485760 @ 3069.7 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 8552.5, step = 26485760, mean_episode_return = 94.342, mean_episode_step = 2031.9, total_loss = 14.423, pg_loss = -3.7275, baseline_loss = 32.886, entropy_loss = -14.735, learner_queue_size = 64, _tick = 3962, _time = 1.6548e+09)
[2022-06-09 16:03:14,571][root][INFO] - Step 26501120 @ 3059.3 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 8557.5, step = 26501120, mean_episode_return = 45.224, mean_episode_step = 1946.5, total_loss = -4.3693, pg_loss = -16.53, baseline_loss = 26.653, entropy_loss = -14.492, learner_queue_size = 64, _tick = 3965, _time = 1.6548e+09)
[2022-06-09 16:03:19,574][root][INFO] - Step 26516480 @ 3070.0 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 8562.5, step = 26516480, mean_episode_return = 36.656, mean_episode_step = 1848.8, total_loss = 286.09, pg_loss = 235.73, baseline_loss = 64.734, entropy_loss = -14.368, learner_queue_size = 64, _tick = 3967, _time = 1.6548e+09)
[2022-06-09 16:03:24,578][root][INFO] - Step 26531840 @ 3069.6 SPS. Inference batcher size: 8. Learner queue size: 64. Other stats: (train_seconds = 8567.5, step = 26531840, mean_episode_return = 74.008, mean_episode_step = 1727.4, total_loss = -62.992, pg_loss = -65.362, baseline_loss = 16.52, entropy_loss = -14.149, learner_queue_size = 64, _tick = 3970, _time = 1.6548e+09)
[2022-06-09 16:03:29,582][root][INFO] - Step 26547200 @ 3069.5 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 8572.5, step = 26547200, mean_episode_return = 17.305, mean_episode_step = 2217.2, total_loss = 62.069, pg_loss = 39.476, baseline_loss = 36.663, entropy_loss = -14.071, learner_queue_size = 64, _tick = 3973, _time = 1.6548e+09)
[2022-06-09 16:03:34,586][root][INFO] - Step 26562560 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 8577.5, step = 26562560, mean_episode_return = 96.259, mean_episode_step = 1766.2, total_loss = 123.58, pg_loss = 89.77, baseline_loss = 47.868, entropy_loss = -14.052, learner_queue_size = 64, _tick = 3976, _time = 1.6548e+09)
[2022-06-09 16:03:39,590][root][INFO] - Step 26577920 @ 3069.6 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 8582.5, step = 26577920, mean_episode_return = 14.704, mean_episode_step = 1878.2, total_loss = 2.387, pg_loss = -35.369, baseline_loss = 51.718, entropy_loss = -13.962, learner_queue_size = 64, _tick = 3979, _time = 1.6548e+09)
[2022-06-09 16:03:44,594][root][INFO] - Step 26598400 @ 4092.7 SPS. Inference batcher size: 83. Learner queue size: 64. Other stats: (train_seconds = 8587.5, step = 26598400, mean_episode_return = None, mean_episode_step = 1518.4, total_loss = 266.26, pg_loss = 229.6, baseline_loss = 50.507, entropy_loss = -13.845, learner_queue_size = 64, _tick = 3981, _time = 1.6548e+09)
[2022-06-09 16:03:49,598][root][INFO] - Step 26613760 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 8592.5, step = 26613760, mean_episode_return = 33.847, mean_episode_step = 1862.4, total_loss = -225.53, pg_loss = -227.11, baseline_loss = 15.591, entropy_loss = -14.006, learner_queue_size = 64, _tick = 3983, _time = 1.6548e+09)
[2022-06-09 16:03:54,602][root][INFO] - Step 26629120 @ 3069.5 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 8597.5, step = 26629120, mean_episode_return = 31.231, mean_episode_step = 1904.4, total_loss = 226.23, pg_loss = 181.4, baseline_loss = 58.895, entropy_loss = -14.063, learner_queue_size = 64, _tick = 3985, _time = 1.6548e+09)
[2022-06-09 16:03:59,606][root][INFO] - Step 26644480 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 8602.5, step = 26644480, mean_episode_return = None, mean_episode_step = 2308.4, total_loss = 167.41, pg_loss = 103.62, baseline_loss = 77.895, entropy_loss = -14.109, learner_queue_size = 64, _tick = 3986, _time = 1.6548e+09)
[2022-06-09 16:04:04,610][root][INFO] - Step 26659840 @ 3069.3 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 8607.5, step = 26659840, mean_episode_return = 79.328, mean_episode_step = 1695.5, total_loss = -10.083, pg_loss = -27.787, baseline_loss = 31.652, entropy_loss = -13.948, learner_queue_size = 64, _tick = 3989, _time = 1.6548e+09)
[2022-06-09 16:04:09,614][root][INFO] - Step 26675200 @ 3069.8 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 8612.5, step = 26675200, mean_episode_return = 20.74, mean_episode_step = 1766.2, total_loss = -146.19, pg_loss = -141.17, baseline_loss = 8.5525, entropy_loss = -13.575, learner_queue_size = 64, _tick = 3992, _time = 1.6548e+09)
[2022-06-09 16:04:14,618][root][INFO] - Step 26690560 @ 3069.6 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 8617.6, step = 26690560, mean_episode_return = -5.3204, mean_episode_step = 2106.0, total_loss = -70.67, pg_loss = -72.108, baseline_loss = 15.066, entropy_loss = -13.629, learner_queue_size = 64, _tick = 3995, _time = 1.6548e+09)
[2022-06-09 16:04:19,622][root][INFO] - Step 26705920 @ 3069.5 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 8622.6, step = 26705920, mean_episode_return = 17.02, mean_episode_step = 1896.2, total_loss = -146.04, pg_loss = -148.61, baseline_loss = 16.216, entropy_loss = -13.646, learner_queue_size = 64, _tick = 3998, _time = 1.6548e+09)
[2022-06-09 16:04:24,626][root][INFO] - Step 26721280 @ 3069.5 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 8627.6, step = 26721280, mean_episode_return = 12.977, mean_episode_step = 1802.9, total_loss = -63.352, pg_loss = -78.564, baseline_loss = 28.891, entropy_loss = -13.679, learner_queue_size = 64, _tick = 4000, _time = 1.6548e+09)
[2022-06-09 16:04:29,630][root][INFO] - Step 26741760 @ 4092.7 SPS. Inference batcher size: 97. Learner queue size: 64. Other stats: (train_seconds = 8632.6, step = 26741760, mean_episode_return = 15.62, mean_episode_step = 2210.8, total_loss = -23.107, pg_loss = -33.11, baseline_loss = 23.666, entropy_loss = -13.663, learner_queue_size = 64, _tick = 4002, _time = 1.6548e+09)
[2022-06-09 16:04:34,634][root][INFO] - Step 26757120 @ 3069.5 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 8637.6, step = 26757120, mean_episode_return = 41.452, mean_episode_step = 2080.5, total_loss = -148.6, pg_loss = -140.62, baseline_loss = 5.9615, entropy_loss = -13.939, learner_queue_size = 64, _tick = 4004, _time = 1.6548e+09)
[2022-06-09 16:04:39,638][root][INFO] - Step 26772480 @ 3069.5 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 8642.6, step = 26772480, mean_episode_return = 76.915, mean_episode_step = 2156.5, total_loss = -125.96, pg_loss = -120.67, baseline_loss = 8.4133, entropy_loss = -13.709, learner_queue_size = 64, _tick = 4006, _time = 1.6548e+09)
[2022-06-09 16:04:44,642][root][INFO] - Step 26787840 @ 3069.4 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 8647.6, step = 26787840, mean_episode_return = None, mean_episode_step = 2035.5, total_loss = -4.6829, pg_loss = -12.92, baseline_loss = 22.11, entropy_loss = -13.873, learner_queue_size = 64, _tick = 4008, _time = 1.6548e+09)
[2022-06-09 16:04:49,646][root][INFO] - Step 26803200 @ 3069.7 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 8652.6, step = 26803200, mean_episode_return = 59.742, mean_episode_step = 2195.3, total_loss = -200.32, pg_loss = -191.07, baseline_loss = 4.5781, entropy_loss = -13.825, learner_queue_size = 64, _tick = 4010, _time = 1.6548e+09)
[2022-06-09 16:04:54,650][root][INFO] - Step 26818560 @ 3069.6 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 8657.6, step = 26818560, mean_episode_return = 35.807, mean_episode_step = 2096.8, total_loss = 25.17, pg_loss = 8.9228, baseline_loss = 30.186, entropy_loss = -13.94, learner_queue_size = 64, _tick = 4011, _time = 1.6548e+09)
[2022-06-09 16:04:59,654][root][INFO] - Step 26833920 @ 3069.5 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 8662.6, step = 26833920, mean_episode_return = 67.679, mean_episode_step = 2189.5, total_loss = 138.44, pg_loss = 106.08, baseline_loss = 46.155, entropy_loss = -13.797, learner_queue_size = 64, _tick = 4013, _time = 1.6548e+09)
[2022-06-09 16:05:04,658][root][INFO] - Step 26849280 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 8667.6, step = 26849280, mean_episode_return = 72.206, mean_episode_step = 2148.2, total_loss = -190.44, pg_loss = -189.39, baseline_loss = 13.122, entropy_loss = -14.179, learner_queue_size = 64, _tick = 4016, _time = 1.6548e+09)
[2022-06-09 16:05:09,662][root][INFO] - Step 26864640 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 8672.6, step = 26864640, mean_episode_return = 31.041, mean_episode_step = 1962.2, total_loss = 207.72, pg_loss = 175.73, baseline_loss = 46.289, entropy_loss = -14.298, learner_queue_size = 64, _tick = 4018, _time = 1.6548e+09)
[2022-06-09 16:05:14,668][root][INFO] - Step 26880000 @ 3068.2 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 8677.6, step = 26880000, mean_episode_return = 78.891, mean_episode_step = 2221.6, total_loss = 42.776, pg_loss = 35.246, baseline_loss = 21.68, entropy_loss = -14.149, learner_queue_size = 64, _tick = 4021, _time = 1.6548e+09)
[2022-06-09 16:05:19,674][root][INFO] - Step 26900480 @ 4091.3 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 8682.6, step = 26900480, mean_episode_return = None, mean_episode_step = 2311.1, total_loss = -97.076, pg_loss = -97.191, baseline_loss = 14.06, entropy_loss = -13.944, learner_queue_size = 64, _tick = 4023, _time = 1.6548e+09)
[2022-06-09 16:05:24,675][root][INFO] - Step 26915840 @ 3071.3 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 8687.6, step = 26915840, mean_episode_return = 1.0774, mean_episode_step = 2190.6, total_loss = 348.34, pg_loss = 260.77, baseline_loss = 101.56, entropy_loss = -13.983, learner_queue_size = 64, _tick = 4025, _time = 1.6548e+09)
[2022-06-09 16:05:29,678][root][INFO] - Step 26931200 @ 3070.2 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 8692.6, step = 26931200, mean_episode_return = 102.74, mean_episode_step = 1979.1, total_loss = 74.806, pg_loss = 62.006, baseline_loss = 26.747, entropy_loss = -13.947, learner_queue_size = 64, _tick = 4027, _time = 1.6548e+09)
[2022-06-09 16:05:34,682][root][INFO] - Step 26946560 @ 3069.5 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 8697.6, step = 26946560, mean_episode_return = 67.297, mean_episode_step = 2251.4, total_loss = 190.84, pg_loss = 163.18, baseline_loss = 41.884, entropy_loss = -14.228, learner_queue_size = 64, _tick = 4029, _time = 1.6548e+09)
[2022-06-09 16:05:39,686][root][INFO] - Step 26961920 @ 3069.6 SPS. Inference batcher size: 12. Learner queue size: 64. Other stats: (train_seconds = 8702.6, step = 26961920, mean_episode_return = 97.511, mean_episode_step = 2118.3, total_loss = -108.74, pg_loss = -111.61, baseline_loss = 16.997, entropy_loss = -14.126, learner_queue_size = 64, _tick = 4032, _time = 1.6548e+09)
[2022-06-09 16:05:44,690][root][INFO] - Step 26977280 @ 3069.5 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 8707.6, step = 26977280, mean_episode_return = 16.81, mean_episode_step = 2339.4, total_loss = 113.46, pg_loss = 97.622, baseline_loss = 30.138, entropy_loss = -14.3, learner_queue_size = 64, _tick = 4035, _time = 1.6548e+09)
[2022-06-09 16:05:49,694][root][INFO] - Step 26992640 @ 3069.6 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 8712.6, step = 26992640, mean_episode_return = 68.789, mean_episode_step = 2240.6, total_loss = -78.321, pg_loss = -79.807, baseline_loss = 15.821, entropy_loss = -14.334, learner_queue_size = 64, _tick = 4038, _time = 1.6548e+09)
[2022-06-09 16:05:54,698][root][INFO] - Step 27008000 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 8717.6, step = 27008000, mean_episode_return = 36.14, mean_episode_step = 2043.7, total_loss = 133.48, pg_loss = 111.59, baseline_loss = 36.401, entropy_loss = -14.513, learner_queue_size = 64, _tick = 4041, _time = 1.6548e+09)
[2022-06-09 16:05:59,702][root][INFO] - Step 27023360 @ 3069.6 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 8722.6, step = 27023360, mean_episode_return = None, mean_episode_step = 2231.1, total_loss = 106.44, pg_loss = 99.764, baseline_loss = 21.188, entropy_loss = -14.515, learner_queue_size = 64, _tick = 4042, _time = 1.6548e+09)
[2022-06-09 16:06:04,706][root][INFO] - Step 27043840 @ 4092.7 SPS. Inference batcher size: 75. Learner queue size: 64. Other stats: (train_seconds = 8727.6, step = 27043840, mean_episode_return = 45.131, mean_episode_step = 2184.7, total_loss = 82.69, pg_loss = 69.051, baseline_loss = 28.451, entropy_loss = -14.812, learner_queue_size = 64, _tick = 4045, _time = 1.6548e+09)
[2022-06-09 16:06:09,710][root][INFO] - Step 27059200 @ 3069.5 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 8732.6, step = 27059200, mean_episode_return = 59.181, mean_episode_step = 2166.7, total_loss = 195.67, pg_loss = 164.8, baseline_loss = 45.575, entropy_loss = -14.713, learner_queue_size = 64, _tick = 4048, _time = 1.6548e+09)
[2022-06-09 16:06:14,714][root][INFO] - Step 27074560 @ 3069.5 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 8737.7, step = 27074560, mean_episode_return = None, mean_episode_step = 2456.4, total_loss = -158.47, pg_loss = -151.76, baseline_loss = 7.855, entropy_loss = -14.562, learner_queue_size = 64, _tick = 4049, _time = 1.6548e+09)
[2022-06-09 16:06:19,718][root][INFO] - Step 27089920 @ 3069.6 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 8742.7, step = 27089920, mean_episode_return = 107.41, mean_episode_step = 2083.4, total_loss = -34.922, pg_loss = -41.314, baseline_loss = 21.035, entropy_loss = -14.643, learner_queue_size = 64, _tick = 4052, _time = 1.6548e+09)
[2022-06-09 16:06:24,722][root][INFO] - Step 27105280 @ 3069.5 SPS. Inference batcher size: 4. Learner queue size: 64. Other stats: (train_seconds = 8747.7, step = 27105280, mean_episode_return = 106.38, mean_episode_step = 2452.9, total_loss = 74.326, pg_loss = 60.322, baseline_loss = 28.464, entropy_loss = -14.46, learner_queue_size = 64, _tick = 4054, _time = 1.6548e+09)
[2022-06-09 16:06:29,728][root][INFO] - Step 27120640 @ 3068.1 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 8752.7, step = 27120640, mean_episode_return = 73.387, mean_episode_step = 2196.5, total_loss = -126.82, pg_loss = -129.23, baseline_loss = 16.951, entropy_loss = -14.537, learner_queue_size = 64, _tick = 4057, _time = 1.6548e+09)
[2022-06-09 16:06:34,734][root][INFO] - Step 27136000 @ 3068.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 8757.7, step = 27136000, mean_episode_return = 71.12, mean_episode_step = 2202.6, total_loss = -25.095, pg_loss = -28.874, baseline_loss = 18.18, entropy_loss = -14.401, learner_queue_size = 64, _tick = 4060, _time = 1.6548e+09)
[2022-06-09 16:06:39,738][root][INFO] - Step 27156480 @ 4092.7 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 8762.7, step = 27156480, mean_episode_return = 53.609, mean_episode_step = 2312.1, total_loss = 38.27, pg_loss = 25.445, baseline_loss = 26.734, entropy_loss = -13.909, learner_queue_size = 64, _tick = 4064, _time = 1.6548e+09)
[2022-06-09 16:06:44,742][root][INFO] - Step 27171840 @ 3069.6 SPS. Inference batcher size: 100. Learner queue size: 64. Other stats: (train_seconds = 8767.7, step = 27171840, mean_episode_return = 74.712, mean_episode_step = 2209.2, total_loss = 184.36, pg_loss = 159.69, baseline_loss = 38.098, entropy_loss = -13.422, learner_queue_size = 64, _tick = 4067, _time = 1.6548e+09)
[2022-06-09 16:06:49,746][root][INFO] - Step 27187200 @ 3069.6 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 8772.7, step = 27187200, mean_episode_return = 2.4746, mean_episode_step = 2010.5, total_loss = -49.035, pg_loss = -60.016, baseline_loss = 24.573, entropy_loss = -13.592, learner_queue_size = 64, _tick = 4069, _time = 1.6548e+09)
[2022-06-09 16:06:54,750][root][INFO] - Step 27202560 @ 3069.6 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 8777.7, step = 27202560, mean_episode_return = 14.18, mean_episode_step = 2129.8, total_loss = 5.382, pg_loss = -4.047, baseline_loss = 23.065, entropy_loss = -13.636, learner_queue_size = 64, _tick = 4072, _time = 1.6548e+09)
[2022-06-09 16:06:59,754][root][INFO] - Step 27217920 @ 3069.5 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 8782.7, step = 27217920, mean_episode_return = None, mean_episode_step = 2139.1, total_loss = -48.697, pg_loss = -46.36, baseline_loss = 11.61, entropy_loss = -13.946, learner_queue_size = 64, _tick = 4073, _time = 1.6548e+09)
[2022-06-09 16:07:04,758][root][INFO] - Step 27233280 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 8787.7, step = 27233280, mean_episode_return = 34.594, mean_episode_step = 2385.7, total_loss = -246.88, pg_loss = -244.44, baseline_loss = 11.564, entropy_loss = -14.002, learner_queue_size = 64, _tick = 4076, _time = 1.6548e+09)
[2022-06-09 16:07:09,763][root][INFO] - Step 27248640 @ 3068.7 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 8792.7, step = 27248640, mean_episode_return = 55.091, mean_episode_step = 2439.1, total_loss = 212.34, pg_loss = 168.35, baseline_loss = 57.959, entropy_loss = -13.969, learner_queue_size = 64, _tick = 4078, _time = 1.6548e+09)
[2022-06-09 16:07:14,766][root][INFO] - Step 27269120 @ 4093.9 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 8797.7, step = 27269120, mean_episode_return = 27.41, mean_episode_step = 2557.5, total_loss = 114.65, pg_loss = 84.852, baseline_loss = 43.764, entropy_loss = -13.965, learner_queue_size = 64, _tick = 4082, _time = 1.6548e+09)
[2022-06-09 16:07:19,770][root][INFO] - Step 27284480 @ 3069.5 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 8802.7, step = 27284480, mean_episode_return = 7.712, mean_episode_step = 2389.7, total_loss = -16.682, pg_loss = -28.841, baseline_loss = 25.952, entropy_loss = -13.793, learner_queue_size = 64, _tick = 4085, _time = 1.6548e+09)
[2022-06-09 16:07:24,774][root][INFO] - Step 27299840 @ 3069.5 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 8807.7, step = 27299840, mean_episode_return = 15.185, mean_episode_step = 2214.8, total_loss = -215.66, pg_loss = -215.15, baseline_loss = 13.497, entropy_loss = -14.011, learner_queue_size = 64, _tick = 4087, _time = 1.6548e+09)
[2022-06-09 16:07:29,778][root][INFO] - Step 27315200 @ 3069.5 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 8812.7, step = 27315200, mean_episode_return = None, mean_episode_step = 2427.6, total_loss = 73.233, pg_loss = 47.753, baseline_loss = 39.539, entropy_loss = -14.058, learner_queue_size = 64, _tick = 4088, _time = 1.6548e+09)
[2022-06-09 16:07:34,782][root][INFO] - Step 27330560 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 8817.7, step = 27330560, mean_episode_return = None, mean_episode_step = 2213.7, total_loss = 84.666, pg_loss = 72.087, baseline_loss = 26.796, entropy_loss = -14.218, learner_queue_size = 64, _tick = 4090, _time = 1.6548e+09)
[2022-06-09 16:07:39,786][root][INFO] - Step 27345920 @ 3069.5 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 8822.7, step = 27345920, mean_episode_return = 59.112, mean_episode_step = 2083.1, total_loss = -124.3, pg_loss = -123.43, baseline_loss = 13.241, entropy_loss = -14.109, learner_queue_size = 64, _tick = 4093, _time = 1.6548e+09)
[2022-06-09 16:07:44,790][root][INFO] - Step 27361280 @ 3069.6 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 8827.7, step = 27361280, mean_episode_return = 41.29, mean_episode_step = 1986.0, total_loss = -57.91, pg_loss = -61.818, baseline_loss = 18.068, entropy_loss = -14.16, learner_queue_size = 64, _tick = 4096, _time = 1.6548e+09)
[2022-06-09 16:07:49,794][root][INFO] - Step 27376640 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 8832.7, step = 27376640, mean_episode_return = None, mean_episode_step = 2717.5, total_loss = -22.634, pg_loss = -22.518, baseline_loss = 13.766, entropy_loss = -13.882, learner_queue_size = 64, _tick = 4098, _time = 1.6548e+09)
[2022-06-09 16:07:54,798][root][INFO] - Step 27397120 @ 4092.6 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 8837.7, step = 27397120, mean_episode_return = 139.22, mean_episode_step = 2781.5, total_loss = 43.42, pg_loss = 18.54, baseline_loss = 39.034, entropy_loss = -14.154, learner_queue_size = 64, _tick = 4102, _time = 1.6548e+09)
[2022-06-09 16:07:59,802][root][INFO] - Step 27412480 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 8842.7, step = 27412480, mean_episode_return = None, mean_episode_step = 2308.5, total_loss = 11.032, pg_loss = 5.8636, baseline_loss = 19.147, entropy_loss = -13.979, learner_queue_size = 64, _tick = 4104, _time = 1.6548e+09)
[2022-06-09 16:08:04,806][root][INFO] - Step 27427840 @ 3069.6 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 8847.7, step = 27427840, mean_episode_return = 25.595, mean_episode_step = 2434.0, total_loss = -134.26, pg_loss = -131.01, baseline_loss = 10.8, entropy_loss = -14.049, learner_queue_size = 64, _tick = 4105, _time = 1.6548e+09)
[2022-06-09 16:08:09,810][root][INFO] - Step 27443200 @ 3069.5 SPS. Inference batcher size: 68. Learner queue size: 64. Other stats: (train_seconds = 8852.7, step = 27443200, mean_episode_return = 65.732, mean_episode_step = 2243.7, total_loss = -6.5183, pg_loss = -14.204, baseline_loss = 21.747, entropy_loss = -14.062, learner_queue_size = 64, _tick = 4107, _time = 1.6548e+09)
[2022-06-09 16:08:14,814][root][INFO] - Step 27458560 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 8857.7, step = 27458560, mean_episode_return = 26.308, mean_episode_step = 2412.4, total_loss = -29.478, pg_loss = -41.577, baseline_loss = 26.43, entropy_loss = -14.331, learner_queue_size = 64, _tick = 4109, _time = 1.6548e+09)
[2022-06-09 16:08:19,818][root][INFO] - Step 27473920 @ 3069.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 8862.8, step = 27473920, mean_episode_return = None, mean_episode_step = 2136.6, total_loss = 129.08, pg_loss = 105.43, baseline_loss = 38.021, entropy_loss = -14.376, learner_queue_size = 64, _tick = 4111, _time = 1.6548e+09)
[2022-06-09 16:08:24,822][root][INFO] - Step 27489280 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 8867.8, step = 27489280, mean_episode_return = 11.469, mean_episode_step = 2331.7, total_loss = 64.081, pg_loss = 42.777, baseline_loss = 35.584, entropy_loss = -14.28, learner_queue_size = 64, _tick = 4114, _time = 1.6548e+09)
[2022-06-09 16:08:29,826][root][INFO] - Step 27504640 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 8872.8, step = 27504640, mean_episode_return = 94.447, mean_episode_step = 2328.1, total_loss = -124.67, pg_loss = -115.48, baseline_loss = 5.0874, entropy_loss = -14.275, learner_queue_size = 64, _tick = 4117, _time = 1.6548e+09)
[2022-06-09 16:08:34,830][root][INFO] - Step 27520000 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 8877.8, step = 27520000, mean_episode_return = 59.19, mean_episode_step = 2260.8, total_loss = 1.6342, pg_loss = -8.922, baseline_loss = 24.812, entropy_loss = -14.256, learner_queue_size = 64, _tick = 4120, _time = 1.6548e+09)
[2022-06-09 16:08:39,834][root][INFO] - Step 27540480 @ 4092.6 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 8882.8, step = 27540480, mean_episode_return = 94.278, mean_episode_step = 2288.1, total_loss = 146.17, pg_loss = 111.4, baseline_loss = 48.986, entropy_loss = -14.215, learner_queue_size = 64, _tick = 4123, _time = 1.6548e+09)
[2022-06-09 16:08:44,838][root][INFO] - Step 27555840 @ 3069.6 SPS. Inference batcher size: 75. Learner queue size: 64. Other stats: (train_seconds = 8887.8, step = 27555840, mean_episode_return = 15.592, mean_episode_step = 2064.1, total_loss = 174.09, pg_loss = 153.8, baseline_loss = 34.433, entropy_loss = -14.146, learner_queue_size = 64, _tick = 4126, _time = 1.6548e+09)
[2022-06-09 16:08:49,842][root][INFO] - Step 27571200 @ 3069.6 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 8892.8, step = 27571200, mean_episode_return = 23.831, mean_episode_step = 2508.2, total_loss = -125.7, pg_loss = -149.97, baseline_loss = 38.412, entropy_loss = -14.143, learner_queue_size = 64, _tick = 4129, _time = 1.6548e+09)
[2022-06-09 16:08:54,846][root][INFO] - Step 27586560 @ 3069.6 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 8897.8, step = 27586560, mean_episode_return = 39.833, mean_episode_step = 2238.9, total_loss = 19.983, pg_loss = 0.22587, baseline_loss = 33.583, entropy_loss = -13.825, learner_queue_size = 64, _tick = 4132, _time = 1.6548e+09)
[2022-06-09 16:08:59,850][root][INFO] - Step 27601920 @ 3069.5 SPS. Inference batcher size: 12. Learner queue size: 64. Other stats: (train_seconds = 8902.8, step = 27601920, mean_episode_return = 35.004, mean_episode_step = 2186.8, total_loss = 28.649, pg_loss = 15.551, baseline_loss = 26.773, entropy_loss = -13.675, learner_queue_size = 64, _tick = 4135, _time = 1.6548e+09)
[2022-06-09 16:09:04,854][root][INFO] - Step 27617280 @ 3069.6 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 8907.8, step = 27617280, mean_episode_return = None, mean_episode_step = 2164.0, total_loss = 126.39, pg_loss = 103.38, baseline_loss = 36.747, entropy_loss = -13.741, learner_queue_size = 64, _tick = 4136, _time = 1.6548e+09)
[2022-06-09 16:09:09,858][root][INFO] - Step 27632640 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 8912.8, step = 27632640, mean_episode_return = 151.71, mean_episode_step = 2322.3, total_loss = -161.19, pg_loss = -163.66, baseline_loss = 16.065, entropy_loss = -13.601, learner_queue_size = 64, _tick = 4138, _time = 1.6548e+09)
[2022-06-09 16:09:14,862][root][INFO] - Step 27648000 @ 3069.5 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 8917.8, step = 27648000, mean_episode_return = 35.544, mean_episode_step = 2411.8, total_loss = -12.262, pg_loss = -30.084, baseline_loss = 31.23, entropy_loss = -13.408, learner_queue_size = 64, _tick = 4140, _time = 1.6548e+09)
[2022-06-09 16:09:19,866][root][INFO] - Step 27663360 @ 3069.6 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 8922.8, step = 27663360, mean_episode_return = 48.18, mean_episode_step = 2267.0, total_loss = -63.868, pg_loss = -65.768, baseline_loss = 15.286, entropy_loss = -13.386, learner_queue_size = 64, _tick = 4143, _time = 1.6548e+09)
[2022-06-09 16:09:24,870][root][INFO] - Step 27678720 @ 3069.6 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 8927.8, step = 27678720, mean_episode_return = 22.811, mean_episode_step = 2312.1, total_loss = 136.73, pg_loss = 101.27, baseline_loss = 48.75, entropy_loss = -13.291, learner_queue_size = 64, _tick = 4144, _time = 1.6548e+09)
[2022-06-09 16:09:29,874][root][INFO] - Step 27699200 @ 4092.6 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 8932.8, step = 27699200, mean_episode_return = 37.825, mean_episode_step = 2145.4, total_loss = -24.043, pg_loss = -41.898, baseline_loss = 31.01, entropy_loss = -13.155, learner_queue_size = 64, _tick = 4148, _time = 1.6548e+09)
[2022-06-09 16:09:34,878][root][INFO] - Step 27714560 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 8937.8, step = 27714560, mean_episode_return = 1.0692, mean_episode_step = 2143.5, total_loss = 52.578, pg_loss = 45.904, baseline_loss = 20.005, entropy_loss = -13.331, learner_queue_size = 64, _tick = 4150, _time = 1.6548e+09)
[2022-06-09 16:09:39,882][root][INFO] - Step 27729920 @ 3069.5 SPS. Inference batcher size: 73. Learner queue size: 64. Other stats: (train_seconds = 8942.8, step = 27729920, mean_episode_return = None, mean_episode_step = 2064.2, total_loss = -131.47, pg_loss = -121.19, baseline_loss = 3.0485, entropy_loss = -13.322, learner_queue_size = 64, _tick = 4152, _time = 1.6548e+09)
[2022-06-09 16:09:44,886][root][INFO] - Step 27745280 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 8947.8, step = 27745280, mean_episode_return = 102.76, mean_episode_step = 2444.8, total_loss = -69.929, pg_loss = -75.472, baseline_loss = 18.724, entropy_loss = -13.18, learner_queue_size = 64, _tick = 4154, _time = 1.6548e+09)
[2022-06-09 16:09:49,890][root][INFO] - Step 27760640 @ 3069.6 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 8952.8, step = 27760640, mean_episode_return = 35.46, mean_episode_step = 2021.3, total_loss = -162.17, pg_loss = -159.79, baseline_loss = 11.154, entropy_loss = -13.533, learner_queue_size = 64, _tick = 4157, _time = 1.6548e+09)
[2022-06-09 16:09:54,894][root][INFO] - Step 27776000 @ 3069.6 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 8957.8, step = 27776000, mean_episode_return = 12.765, mean_episode_step = 1907.7, total_loss = 53.622, pg_loss = 28.949, baseline_loss = 38.27, entropy_loss = -13.597, learner_queue_size = 64, _tick = 4160, _time = 1.6548e+09)
[2022-06-09 16:09:59,898][root][INFO] - Step 27791360 @ 3069.5 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 8962.8, step = 27791360, mean_episode_return = None, mean_episode_step = 2363.0, total_loss = 274.19, pg_loss = 247.13, baseline_loss = 40.635, entropy_loss = -13.584, learner_queue_size = 64, _tick = 4162, _time = 1.6548e+09)
[2022-06-09 16:10:04,902][root][INFO] - Step 27806720 @ 3069.6 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 8967.8, step = 27806720, mean_episode_return = None, mean_episode_step = 1999.5, total_loss = 123.2, pg_loss = 112.25, baseline_loss = 24.597, entropy_loss = -13.644, learner_queue_size = 64, _tick = 4164, _time = 1.6548e+09)
[2022-06-09 16:10:09,908][root][INFO] - Step 27822080 @ 3068.1 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 8972.8, step = 27822080, mean_episode_return = 71.31, mean_episode_step = 2166.2, total_loss = 24.839, pg_loss = 20.648, baseline_loss = 17.871, entropy_loss = -13.679, learner_queue_size = 64, _tick = 4167, _time = 1.6548e+09)
[2022-06-09 16:10:14,914][root][INFO] - Step 27842560 @ 4091.4 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 8977.8, step = 27842560, mean_episode_return = None, mean_episode_step = 2333.1, total_loss = 96.691, pg_loss = 82.692, baseline_loss = 27.745, entropy_loss = -13.746, learner_queue_size = 64, _tick = 4170, _time = 1.6548e+09)
[2022-06-09 16:10:19,920][root][INFO] - Step 27857920 @ 3068.2 SPS. Inference batcher size: 73. Learner queue size: 64. Other stats: (train_seconds = 8982.9, step = 27857920, mean_episode_return = 15.053, mean_episode_step = 2345.9, total_loss = -104.48, pg_loss = -110.74, baseline_loss = 19.943, entropy_loss = -13.683, learner_queue_size = 64, _tick = 4172, _time = 1.6548e+09)
[2022-06-09 16:10:24,926][root][INFO] - Step 27873280 @ 3068.4 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 8987.9, step = 27873280, mean_episode_return = 49.575, mean_episode_step = 2076.6, total_loss = 86.535, pg_loss = 55.539, baseline_loss = 44.812, entropy_loss = -13.816, learner_queue_size = 64, _tick = 4174, _time = 1.6548e+09)
[2022-06-09 16:10:29,930][root][INFO] - Step 27888640 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 8992.9, step = 27888640, mean_episode_return = 29.831, mean_episode_step = 1947.3, total_loss = 116.58, pg_loss = 92.15, baseline_loss = 38.043, entropy_loss = -13.608, learner_queue_size = 64, _tick = 4177, _time = 1.6548e+09)
[2022-06-09 16:10:34,934][root][INFO] - Step 27904000 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 8997.9, step = 27904000, mean_episode_return = 10.839, mean_episode_step = 2387.5, total_loss = 236.5, pg_loss = 204.62, baseline_loss = 45.414, entropy_loss = -13.542, learner_queue_size = 64, _tick = 4180, _time = 1.6548e+09)
[2022-06-09 16:10:39,938][root][INFO] - Step 27919360 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 9002.9, step = 27919360, mean_episode_return = 4.4394, mean_episode_step = 2071.7, total_loss = -21.44, pg_loss = -32.045, baseline_loss = 24.105, entropy_loss = -13.5, learner_queue_size = 64, _tick = 4183, _time = 1.6548e+09)
[2022-06-09 16:10:44,942][root][INFO] - Step 27934720 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 9007.9, step = 27934720, mean_episode_return = None, mean_episode_step = 1943.2, total_loss = 37.75, pg_loss = 28.143, baseline_loss = 23.147, entropy_loss = -13.54, learner_queue_size = 64, _tick = 4184, _time = 1.6548e+09)
[2022-06-09 16:10:49,946][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 16:10:50,445][root][INFO] - Step 27950080 @ 3069.5 SPS. Inference batcher size: 71. Learner queue size: 64. Other stats: (train_seconds = 9012.9, step = 27955200, mean_episode_return = 32.705, mean_episode_step = 1984.1, total_loss = 229.43, pg_loss = 196.27, baseline_loss = 46.769, entropy_loss = -13.613, learner_queue_size = 64, _tick = 4188, _time = 1.6548e+09)
[2022-06-09 16:10:55,450][root][INFO] - Step 27970560 @ 3720.9 SPS. Inference batcher size: 83. Learner queue size: 64. Other stats: (train_seconds = 9018.4, step = 27970560, mean_episode_return = None, mean_episode_step = 2325.9, total_loss = 260.68, pg_loss = 235.04, baseline_loss = 39.34, entropy_loss = -13.703, learner_queue_size = 64, _tick = 4189, _time = 1.6548e+09)
[2022-06-09 16:11:00,454][root][INFO] - Step 27985920 @ 3069.5 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 9023.4, step = 27985920, mean_episode_return = 83.3, mean_episode_step = 2151.6, total_loss = 9.9081, pg_loss = -1.9309, baseline_loss = 25.847, entropy_loss = -14.008, learner_queue_size = 64, _tick = 4191, _time = 1.6548e+09)
[2022-06-09 16:11:05,458][root][INFO] - Step 28001280 @ 3069.6 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 9028.4, step = 28001280, mean_episode_return = 26.723, mean_episode_step = 2087.2, total_loss = 23.054, pg_loss = 17.596, baseline_loss = 19.337, entropy_loss = -13.88, learner_queue_size = 64, _tick = 4194, _time = 1.6548e+09)
[2022-06-09 16:11:10,462][root][INFO] - Step 28016640 @ 3069.6 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 9033.4, step = 28016640, mean_episode_return = None, mean_episode_step = 2319.2, total_loss = -84.637, pg_loss = -83.142, baseline_loss = 12.485, entropy_loss = -13.98, learner_queue_size = 64, _tick = 4196, _time = 1.6548e+09)
[2022-06-09 16:11:15,466][root][INFO] - Step 28032000 @ 3069.5 SPS. Inference batcher size: 6. Learner queue size: 64. Other stats: (train_seconds = 9038.4, step = 28032000, mean_episode_return = None, mean_episode_step = 2304.4, total_loss = 448.01, pg_loss = 272.57, baseline_loss = 189.47, entropy_loss = -14.024, learner_queue_size = 64, _tick = 4198, _time = 1.6548e+09)
[2022-06-09 16:11:20,470][root][INFO] - Step 28047360 @ 3069.6 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 9043.4, step = 28047360, mean_episode_return = 25.39, mean_episode_step = 2328.9, total_loss = 58.656, pg_loss = 41.645, baseline_loss = 31.044, entropy_loss = -14.032, learner_queue_size = 64, _tick = 4201, _time = 1.6548e+09)
[2022-06-09 16:11:25,474][root][INFO] - Step 28062720 @ 3069.6 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 9048.4, step = 28062720, mean_episode_return = 38.573, mean_episode_step = 2182.7, total_loss = 16.051, pg_loss = -0.09119, baseline_loss = 30.047, entropy_loss = -13.905, learner_queue_size = 64, _tick = 4204, _time = 1.6548e+09)
[2022-06-09 16:11:30,478][root][INFO] - Step 28078080 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 9053.4, step = 28078080, mean_episode_return = 71.954, mean_episode_step = 2394.9, total_loss = -127.9, pg_loss = -125.72, baseline_loss = 11.673, entropy_loss = -13.852, learner_queue_size = 64, _tick = 4207, _time = 1.6548e+09)
[2022-06-09 16:11:35,482][root][INFO] - Step 28093440 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 9058.4, step = 28093440, mean_episode_return = -6.2454, mean_episode_step = 2740.7, total_loss = 83.338, pg_loss = 70.102, baseline_loss = 26.997, entropy_loss = -13.761, learner_queue_size = 64, _tick = 4210, _time = 1.6548e+09)
[2022-06-09 16:11:40,486][root][INFO] - Step 28108800 @ 3069.5 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 9063.4, step = 28108800, mean_episode_return = None, mean_episode_step = 2376.2, total_loss = 80.903, pg_loss = 71.64, baseline_loss = 22.931, entropy_loss = -13.668, learner_queue_size = 64, _tick = 4212, _time = 1.6548e+09)
[2022-06-09 16:11:45,490][root][INFO] - Step 28124160 @ 3069.6 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 9068.4, step = 28124160, mean_episode_return = 56.49, mean_episode_step = 2509.0, total_loss = 94.849, pg_loss = 68.913, baseline_loss = 39.588, entropy_loss = -13.652, learner_queue_size = 64, _tick = 4214, _time = 1.6548e+09)
[2022-06-09 16:11:50,496][root][INFO] - Step 28139520 @ 3068.3 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 9073.4, step = 28139520, mean_episode_return = 192.9, mean_episode_step = 2205.3, total_loss = 111.04, pg_loss = 92.869, baseline_loss = 31.793, entropy_loss = -13.621, learner_queue_size = 64, _tick = 4217, _time = 1.6548e+09)
[2022-06-09 16:11:55,502][root][INFO] - Step 28160000 @ 4091.1 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 9078.4, step = 28160000, mean_episode_return = 7.3104, mean_episode_step = 2565.8, total_loss = -100.09, pg_loss = -111.94, baseline_loss = 25.579, entropy_loss = -13.727, learner_queue_size = 64, _tick = 4219, _time = 1.6548e+09)
[2022-06-09 16:12:00,506][root][INFO] - Step 28175360 @ 3069.6 SPS. Inference batcher size: 73. Learner queue size: 64. Other stats: (train_seconds = 9083.4, step = 28175360, mean_episode_return = 65.115, mean_episode_step = 2095.5, total_loss = -46.854, pg_loss = -68.214, baseline_loss = 35.27, entropy_loss = -13.909, learner_queue_size = 64, _tick = 4221, _time = 1.6548e+09)
[2022-06-09 16:12:05,510][root][INFO] - Step 28190720 @ 3069.5 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 9088.4, step = 28190720, mean_episode_return = 23.176, mean_episode_step = 2579.6, total_loss = -169.0, pg_loss = -173.82, baseline_loss = 18.598, entropy_loss = -13.772, learner_queue_size = 64, _tick = 4224, _time = 1.6548e+09)
[2022-06-09 16:12:10,515][root][INFO] - Step 28206080 @ 3069.0 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 9093.5, step = 28206080, mean_episode_return = 50.471, mean_episode_step = 2192.5, total_loss = 34.464, pg_loss = 18.653, baseline_loss = 29.508, entropy_loss = -13.697, learner_queue_size = 64, _tick = 4227, _time = 1.6548e+09)
[2022-06-09 16:12:15,519][root][INFO] - Step 28221440 @ 3069.6 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 9098.5, step = 28221440, mean_episode_return = None, mean_episode_step = 2190.0, total_loss = -159.24, pg_loss = -154.66, baseline_loss = 9.0609, entropy_loss = -13.641, learner_queue_size = 64, _tick = 4229, _time = 1.6548e+09)
[2022-06-09 16:12:20,522][root][INFO] - Step 28236800 @ 3070.1 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 9103.5, step = 28236800, mean_episode_return = 44.9, mean_episode_step = 2234.0, total_loss = -236.49, pg_loss = -236.65, baseline_loss = 13.646, entropy_loss = -13.487, learner_queue_size = 64, _tick = 4232, _time = 1.6548e+09)
[2022-06-09 16:12:25,528][root][INFO] - Step 28252160 @ 3068.3 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 9108.5, step = 28252160, mean_episode_return = -3.8752, mean_episode_step = 2750.0, total_loss = -154.37, pg_loss = -157.45, baseline_loss = 16.87, entropy_loss = -13.792, learner_queue_size = 64, _tick = 4234, _time = 1.6548e+09)
[2022-06-09 16:12:30,534][root][INFO] - Step 28267520 @ 3068.3 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 9113.5, step = 28267520, mean_episode_return = 29.521, mean_episode_step = 2370.5, total_loss = -128.24, pg_loss = -136.46, baseline_loss = 21.911, entropy_loss = -13.693, learner_queue_size = 64, _tick = 4237, _time = 1.6548e+09)
[2022-06-09 16:12:35,538][root][INFO] - Step 28282880 @ 3069.6 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 9118.5, step = 28282880, mean_episode_return = 32.717, mean_episode_step = 2098.5, total_loss = -102.29, pg_loss = -116.32, baseline_loss = 27.808, entropy_loss = -13.776, learner_queue_size = 64, _tick = 4239, _time = 1.6548e+09)
[2022-06-09 16:12:40,542][root][INFO] - Step 28298240 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 9123.5, step = 28298240, mean_episode_return = 15.58, mean_episode_step = 1841.3, total_loss = 123.06, pg_loss = 98.844, baseline_loss = 37.714, entropy_loss = -13.499, learner_queue_size = 64, _tick = 4241, _time = 1.6548e+09)
[2022-06-09 16:12:45,546][root][INFO] - Step 28318720 @ 4092.8 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 9128.5, step = 28318720, mean_episode_return = 46.798, mean_episode_step = 2225.9, total_loss = -50.03, pg_loss = -64.029, baseline_loss = 27.341, entropy_loss = -13.343, learner_queue_size = 64, _tick = 4244, _time = 1.6548e+09)
[2022-06-09 16:12:50,550][root][INFO] - Step 28334080 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 9133.5, step = 28334080, mean_episode_return = 44.407, mean_episode_step = 2249.5, total_loss = 138.23, pg_loss = 115.43, baseline_loss = 36.222, entropy_loss = -13.423, learner_queue_size = 64, _tick = 4247, _time = 1.6548e+09)
[2022-06-09 16:12:55,554][root][INFO] - Step 28349440 @ 3069.5 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 9138.5, step = 28349440, mean_episode_return = 31.122, mean_episode_step = 2392.2, total_loss = -59.4, pg_loss = -68.582, baseline_loss = 22.752, entropy_loss = -13.57, learner_queue_size = 64, _tick = 4250, _time = 1.6548e+09)
[2022-06-09 16:13:00,558][root][INFO] - Step 28364800 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 9143.5, step = 28364800, mean_episode_return = 115.59, mean_episode_step = 2311.3, total_loss = 263.52, pg_loss = 212.29, baseline_loss = 64.72, entropy_loss = -13.488, learner_queue_size = 64, _tick = 4253, _time = 1.6548e+09)
[2022-06-09 16:13:05,562][root][INFO] - Step 28380160 @ 3069.5 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 9148.5, step = 28380160, mean_episode_return = 117.39, mean_episode_step = 2776.9, total_loss = -98.803, pg_loss = -102.52, baseline_loss = 17.342, entropy_loss = -13.621, learner_queue_size = 64, _tick = 4256, _time = 1.6548e+09)
[2022-06-09 16:13:10,566][root][INFO] - Step 28395520 @ 3069.6 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 9153.5, step = 28395520, mean_episode_return = 6.0609, mean_episode_step = 2463.3, total_loss = 234.11, pg_loss = 202.81, baseline_loss = 44.804, entropy_loss = -13.502, learner_queue_size = 64, _tick = 4259, _time = 1.6548e+09)
[2022-06-09 16:13:15,570][root][INFO] - Step 28410880 @ 3069.5 SPS. Inference batcher size: 5. Learner queue size: 64. Other stats: (train_seconds = 9158.5, step = 28410880, mean_episode_return = 54.172, mean_episode_step = 2144.6, total_loss = 164.2, pg_loss = 135.54, baseline_loss = 42.279, entropy_loss = -13.619, learner_queue_size = 64, _tick = 4262, _time = 1.6548e+09)
[2022-06-09 16:13:20,575][root][INFO] - Step 28426240 @ 3069.1 SPS. Inference batcher size: 3. Learner queue size: 64. Other stats: (train_seconds = 9163.5, step = 28426240, mean_episode_return = None, mean_episode_step = 2574.5, total_loss = 415.92, pg_loss = 367.62, baseline_loss = 61.755, entropy_loss = -13.454, learner_queue_size = 64, _tick = 4264, _time = 1.6548e+09)
[2022-06-09 16:13:25,578][root][INFO] - Step 28441600 @ 3070.0 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 9168.5, step = 28441600, mean_episode_return = 102.42, mean_episode_step = 2413.7, total_loss = 1.7566, pg_loss = -7.7063, baseline_loss = 23.03, entropy_loss = -13.567, learner_queue_size = 64, _tick = 4266, _time = 1.6548e+09)
[2022-06-09 16:13:30,582][root][INFO] - Step 28462080 @ 4092.7 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 9173.5, step = 28462080, mean_episode_return = None, mean_episode_step = 2496.0, total_loss = -0.79642, pg_loss = -8.3017, baseline_loss = 21.314, entropy_loss = -13.809, learner_queue_size = 64, _tick = 4268, _time = 1.6548e+09)
[2022-06-09 16:13:35,586][root][INFO] - Step 28477440 @ 3069.6 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 9178.5, step = 28477440, mean_episode_return = 44.265, mean_episode_step = 2199.4, total_loss = 26.268, pg_loss = 3.5361, baseline_loss = 36.691, entropy_loss = -13.959, learner_queue_size = 64, _tick = 4271, _time = 1.6548e+09)
[2022-06-09 16:13:40,590][root][INFO] - Step 28492800 @ 3069.5 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 9183.5, step = 28492800, mean_episode_return = 23.286, mean_episode_step = 2445.2, total_loss = -37.422, pg_loss = -46.277, baseline_loss = 22.99, entropy_loss = -14.135, learner_queue_size = 64, _tick = 4274, _time = 1.6548e+09)
[2022-06-09 16:13:45,594][root][INFO] - Step 28508160 @ 3069.5 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 9188.5, step = 28508160, mean_episode_return = None, mean_episode_step = 2060.1, total_loss = 311.07, pg_loss = 267.63, baseline_loss = 57.507, entropy_loss = -14.064, learner_queue_size = 64, _tick = 4276, _time = 1.6548e+09)
[2022-06-09 16:13:50,598][root][INFO] - Step 28523520 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 9193.5, step = 28523520, mean_episode_return = 10.24, mean_episode_step = 2369.9, total_loss = -100.79, pg_loss = -96.949, baseline_loss = 10.013, entropy_loss = -13.858, learner_queue_size = 64, _tick = 4279, _time = 1.6548e+09)
[2022-06-09 16:13:55,602][root][INFO] - Step 28538880 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 9198.5, step = 28538880, mean_episode_return = 46.802, mean_episode_step = 2618.1, total_loss = -91.193, pg_loss = -86.404, baseline_loss = 8.8771, entropy_loss = -13.666, learner_queue_size = 64, _tick = 4281, _time = 1.6548e+09)
[2022-06-09 16:14:00,606][root][INFO] - Step 28554240 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 9203.5, step = 28554240, mean_episode_return = None, mean_episode_step = 2505.7, total_loss = -18.114, pg_loss = -19.321, baseline_loss = 14.794, entropy_loss = -13.587, learner_queue_size = 64, _tick = 4283, _time = 1.6548e+09)
[2022-06-09 16:14:05,610][root][INFO] - Step 28574720 @ 4092.8 SPS. Inference batcher size: 105. Learner queue size: 64. Other stats: (train_seconds = 9208.5, step = 28574720, mean_episode_return = 92.064, mean_episode_step = 2363.9, total_loss = 7.0144, pg_loss = -8.7498, baseline_loss = 29.805, entropy_loss = -14.041, learner_queue_size = 64, _tick = 4287, _time = 1.6548e+09)
[2022-06-09 16:14:10,614][root][INFO] - Step 28590080 @ 3069.6 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 9213.5, step = 28590080, mean_episode_return = 51.221, mean_episode_step = 1932.8, total_loss = -8.0101, pg_loss = -23.263, baseline_loss = 29.206, entropy_loss = -13.953, learner_queue_size = 64, _tick = 4290, _time = 1.6548e+09)
[2022-06-09 16:14:15,618][root][INFO] - Step 28605440 @ 3069.5 SPS. Inference batcher size: 73. Learner queue size: 64. Other stats: (train_seconds = 9218.6, step = 28605440, mean_episode_return = None, mean_episode_step = 1897.3, total_loss = 32.641, pg_loss = 24.368, baseline_loss = 22.074, entropy_loss = -13.802, learner_queue_size = 64, _tick = 4292, _time = 1.6548e+09)
[2022-06-09 16:14:20,622][root][INFO] - Step 28620800 @ 3069.5 SPS. Inference batcher size: 71. Learner queue size: 64. Other stats: (train_seconds = 9223.6, step = 28620800, mean_episode_return = 2.5295, mean_episode_step = 1752.5, total_loss = -3.1492, pg_loss = -9.7497, baseline_loss = 20.497, entropy_loss = -13.897, learner_queue_size = 64, _tick = 4294, _time = 1.6548e+09)
[2022-06-09 16:14:25,642][root][INFO] - Step 28636160 @ 3059.6 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 9228.6, step = 28636160, mean_episode_return = None, mean_episode_step = 2403.5, total_loss = 168.13, pg_loss = 145.38, baseline_loss = 36.423, entropy_loss = -13.668, learner_queue_size = 64, _tick = 4295, _time = 1.6548e+09)
[2022-06-09 16:14:30,646][root][INFO] - Step 28651520 @ 3069.7 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 9233.6, step = 28651520, mean_episode_return = None, mean_episode_step = 2437.3, total_loss = 130.09, pg_loss = 115.54, baseline_loss = 28.461, entropy_loss = -13.918, learner_queue_size = 64, _tick = 4296, _time = 1.6548e+09)
[2022-06-09 16:14:35,650][root][INFO] - Step 28666880 @ 3069.6 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 9238.6, step = 28666880, mean_episode_return = None, mean_episode_step = 1976.5, total_loss = 211.21, pg_loss = 180.02, baseline_loss = 44.987, entropy_loss = -13.796, learner_queue_size = 64, _tick = 4298, _time = 1.6548e+09)
[2022-06-09 16:14:40,654][root][INFO] - Step 28682240 @ 3069.6 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 9243.6, step = 28682240, mean_episode_return = 35.132, mean_episode_step = 2034.1, total_loss = -60.255, pg_loss = -69.786, baseline_loss = 23.416, entropy_loss = -13.885, learner_queue_size = 64, _tick = 4300, _time = 1.6548e+09)
[2022-06-09 16:14:45,658][root][INFO] - Step 28697600 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 9248.6, step = 28697600, mean_episode_return = 12.955, mean_episode_step = 2324.1, total_loss = -117.89, pg_loss = -120.35, baseline_loss = 16.361, entropy_loss = -13.9, learner_queue_size = 64, _tick = 4303, _time = 1.6548e+09)
[2022-06-09 16:14:50,662][root][INFO] - Step 28718080 @ 4092.8 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 9253.6, step = 28718080, mean_episode_return = 55.88, mean_episode_step = 2310.5, total_loss = -37.733, pg_loss = -39.454, baseline_loss = 15.584, entropy_loss = -13.863, learner_queue_size = 64, _tick = 4306, _time = 1.6548e+09)
[2022-06-09 16:14:55,668][root][INFO] - Step 28733440 @ 3068.3 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 9258.6, step = 28733440, mean_episode_return = 137.11, mean_episode_step = 2182.2, total_loss = 243.38, pg_loss = 205.71, baseline_loss = 51.613, entropy_loss = -13.94, learner_queue_size = 64, _tick = 4309, _time = 1.6548e+09)
[2022-06-09 16:15:00,674][root][INFO] - Step 28748800 @ 3068.3 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 9263.6, step = 28748800, mean_episode_return = 71.71, mean_episode_step = 2341.4, total_loss = 73.683, pg_loss = 57.355, baseline_loss = 30.231, entropy_loss = -13.903, learner_queue_size = 64, _tick = 4312, _time = 1.6548e+09)
[2022-06-09 16:15:05,678][root][INFO] - Step 28764160 @ 3069.5 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 9268.6, step = 28764160, mean_episode_return = None, mean_episode_step = 2205.0, total_loss = 362.27, pg_loss = 310.08, baseline_loss = 66.101, entropy_loss = -13.916, learner_queue_size = 64, _tick = 4313, _time = 1.6548e+09)
[2022-06-09 16:15:10,688][root][INFO] - Step 28779520 @ 3065.9 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 9273.6, step = 28779520, mean_episode_return = 117.48, mean_episode_step = 1927.0, total_loss = -80.916, pg_loss = -100.84, baseline_loss = 33.791, entropy_loss = -13.87, learner_queue_size = 64, _tick = 4315, _time = 1.6548e+09)
[2022-06-09 16:15:15,694][root][INFO] - Step 28794880 @ 3068.3 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 9278.6, step = 28794880, mean_episode_return = 54.283, mean_episode_step = 2220.7, total_loss = -63.37, pg_loss = -80.727, baseline_loss = 31.274, entropy_loss = -13.916, learner_queue_size = 64, _tick = 4317, _time = 1.6548e+09)
[2022-06-09 16:15:20,698][root][INFO] - Step 28810240 @ 3069.5 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 9283.6, step = 28810240, mean_episode_return = 41.201, mean_episode_step = 2405.8, total_loss = -244.55, pg_loss = -250.14, baseline_loss = 19.431, entropy_loss = -13.843, learner_queue_size = 64, _tick = 4319, _time = 1.6548e+09)
[2022-06-09 16:15:25,702][root][INFO] - Step 28825600 @ 3069.6 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 9288.6, step = 28825600, mean_episode_return = 6.729, mean_episode_step = 1868.2, total_loss = -67.082, pg_loss = -66.005, baseline_loss = 12.886, entropy_loss = -13.963, learner_queue_size = 64, _tick = 4321, _time = 1.6548e+09)
[2022-06-09 16:15:30,706][root][INFO] - Step 28840960 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 9293.6, step = 28840960, mean_episode_return = 0.79, mean_episode_step = 2309.7, total_loss = 293.12, pg_loss = 215.17, baseline_loss = 91.669, entropy_loss = -13.714, learner_queue_size = 64, _tick = 4323, _time = 1.6548e+09)
[2022-06-09 16:15:35,712][root][INFO] - Step 28856320 @ 3068.4 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 9298.6, step = 28856320, mean_episode_return = 31.726, mean_episode_step = 2556.3, total_loss = 167.95, pg_loss = 143.3, baseline_loss = 38.389, entropy_loss = -13.736, learner_queue_size = 64, _tick = 4326, _time = 1.6548e+09)
[2022-06-09 16:15:40,719][root][INFO] - Step 28876800 @ 4090.5 SPS. Inference batcher size: 10. Learner queue size: 35. Other stats: (train_seconds = 9303.7, step = 28876800, mean_episode_return = 80.907, mean_episode_step = 2632.8, total_loss = 16.151, pg_loss = 4.2672, baseline_loss = 25.857, entropy_loss = -13.974, learner_queue_size = 64, _tick = 4329, _time = 1.6548e+09)
[2022-06-09 16:15:45,722][root][INFO] - Step 28892160 @ 3069.9 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 9308.7, step = 28892160, mean_episode_return = None, mean_episode_step = 2539.6, total_loss = 97.936, pg_loss = 80.782, baseline_loss = 31.022, entropy_loss = -13.868, learner_queue_size = 64, _tick = 4330, _time = 1.6548e+09)
[2022-06-09 16:15:50,728][root][INFO] - Step 28907520 @ 3068.3 SPS. Inference batcher size: 81. Learner queue size: 64. Other stats: (train_seconds = 9313.7, step = 28907520, mean_episode_return = 77.051, mean_episode_step = 2088.6, total_loss = 10.901, pg_loss = -9.3415, baseline_loss = 34.087, entropy_loss = -13.844, learner_queue_size = 64, _tick = 4332, _time = 1.6548e+09)
[2022-06-09 16:15:55,734][root][INFO] - Step 28922880 @ 3068.3 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 9318.7, step = 28922880, mean_episode_return = None, mean_episode_step = 2334.7, total_loss = -52.029, pg_loss = -47.674, baseline_loss = 9.9215, entropy_loss = -14.277, learner_queue_size = 64, _tick = 4333, _time = 1.6548e+09)
[2022-06-09 16:16:00,738][root][INFO] - Step 28938240 @ 3069.5 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 9323.7, step = 28938240, mean_episode_return = 94.994, mean_episode_step = 2086.4, total_loss = 421.67, pg_loss = 358.05, baseline_loss = 77.785, entropy_loss = -14.167, learner_queue_size = 64, _tick = 4336, _time = 1.6548e+09)
[2022-06-09 16:16:05,742][root][INFO] - Step 28953600 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 9328.7, step = 28953600, mean_episode_return = None, mean_episode_step = 2775.2, total_loss = 17.094, pg_loss = 11.663, baseline_loss = 19.622, entropy_loss = -14.192, learner_queue_size = 64, _tick = 4338, _time = 1.6548e+09)
[2022-06-09 16:16:10,746][root][INFO] - Step 28968960 @ 3069.6 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 9333.7, step = 28968960, mean_episode_return = 88.777, mean_episode_step = 2616.8, total_loss = -96.601, pg_loss = -99.044, baseline_loss = 16.866, entropy_loss = -14.423, learner_queue_size = 64, _tick = 4341, _time = 1.6548e+09)
[2022-06-09 16:16:15,750][root][INFO] - Step 28984320 @ 3069.4 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 9338.7, step = 28984320, mean_episode_return = 89.616, mean_episode_step = 2071.2, total_loss = 30.178, pg_loss = 17.453, baseline_loss = 27.148, entropy_loss = -14.423, learner_queue_size = 64, _tick = 4344, _time = 1.6548e+09)
[2022-06-09 16:16:20,754][root][INFO] - Step 28999680 @ 3069.7 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 9343.7, step = 28999680, mean_episode_return = 59.167, mean_episode_step = 2377.1, total_loss = -340.58, pg_loss = -333.76, baseline_loss = 7.4697, entropy_loss = -14.295, learner_queue_size = 64, _tick = 4347, _time = 1.6548e+09)
[2022-06-09 16:16:25,758][root][INFO] - Step 29015040 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 9348.7, step = 29015040, mean_episode_return = None, mean_episode_step = 1845.0, total_loss = 61.154, pg_loss = 48.749, baseline_loss = 26.735, entropy_loss = -14.33, learner_queue_size = 64, _tick = 4349, _time = 1.6548e+09)
[2022-06-09 16:16:30,762][root][INFO] - Step 29030400 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 9353.7, step = 29030400, mean_episode_return = 132.46, mean_episode_step = 2551.9, total_loss = 137.93, pg_loss = 98.074, baseline_loss = 54.033, entropy_loss = -14.172, learner_queue_size = 64, _tick = 4352, _time = 1.6548e+09)
[2022-06-09 16:16:35,766][root][INFO] - Step 29045760 @ 3069.6 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 9358.7, step = 29045760, mean_episode_return = 47.407, mean_episode_step = 1898.2, total_loss = 330.19, pg_loss = 277.64, baseline_loss = 66.778, entropy_loss = -14.233, learner_queue_size = 64, _tick = 4355, _time = 1.6548e+09)
[2022-06-09 16:16:40,767][root][INFO] - Step 29061120 @ 3071.3 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 9363.7, step = 29061120, mean_episode_return = None, mean_episode_step = 2349.0, total_loss = -48.838, pg_loss = -52.746, baseline_loss = 17.993, entropy_loss = -14.085, learner_queue_size = 64, _tick = 4355, _time = 1.6548e+09)
[2022-06-09 16:16:45,770][root][INFO] - Step 29076480 @ 3070.3 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 9368.7, step = 29076480, mean_episode_return = 59.51, mean_episode_step = 2231.7, total_loss = -138.94, pg_loss = -148.53, baseline_loss = 23.762, entropy_loss = -14.17, learner_queue_size = 64, _tick = 4358, _time = 1.6548e+09)
[2022-06-09 16:16:50,774][root][INFO] - Step 29096960 @ 4092.7 SPS. Inference batcher size: 83. Learner queue size: 64. Other stats: (train_seconds = 9373.7, step = 29096960, mean_episode_return = None, mean_episode_step = 2344.5, total_loss = -69.317, pg_loss = -68.061, baseline_loss = 12.664, entropy_loss = -13.92, learner_queue_size = 64, _tick = 4361, _time = 1.6548e+09)
[2022-06-09 16:16:55,778][root][INFO] - Step 29112320 @ 3069.4 SPS. Inference batcher size: 93. Learner queue size: 64. Other stats: (train_seconds = 9378.7, step = 29112320, mean_episode_return = None, mean_episode_step = 2244.9, total_loss = -24.606, pg_loss = -26.933, baseline_loss = 16.478, entropy_loss = -14.151, learner_queue_size = 64, _tick = 4363, _time = 1.6548e+09)
[2022-06-09 16:17:00,782][root][INFO] - Step 29127680 @ 3069.6 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 9383.7, step = 29127680, mean_episode_return = 17.105, mean_episode_step = 2572.7, total_loss = -119.25, pg_loss = -116.9, baseline_loss = 11.843, entropy_loss = -14.187, learner_queue_size = 64, _tick = 4366, _time = 1.6548e+09)
[2022-06-09 16:17:05,786][root][INFO] - Step 29143040 @ 3069.6 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 9388.7, step = 29143040, mean_episode_return = 62.011, mean_episode_step = 2326.2, total_loss = 186.88, pg_loss = 147.44, baseline_loss = 53.478, entropy_loss = -14.045, learner_queue_size = 64, _tick = 4369, _time = 1.6548e+09)
[2022-06-09 16:17:10,790][root][INFO] - Step 29158400 @ 3069.5 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 9393.7, step = 29158400, mean_episode_return = None, mean_episode_step = 2565.1, total_loss = -95.441, pg_loss = -93.956, baseline_loss = 12.608, entropy_loss = -14.093, learner_queue_size = 64, _tick = 4371, _time = 1.6548e+09)
[2022-06-09 16:17:15,808][root][INFO] - Step 29173760 @ 3061.0 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 9398.7, step = 29173760, mean_episode_return = 44.045, mean_episode_step = 2427.2, total_loss = -196.11, pg_loss = -195.74, baseline_loss = 13.608, entropy_loss = -13.974, learner_queue_size = 64, _tick = 4374, _time = 1.6548e+09)
[2022-06-09 16:17:20,814][root][INFO] - Step 29189120 @ 3068.4 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 9403.7, step = 29189120, mean_episode_return = 35.881, mean_episode_step = 2244.0, total_loss = -33.19, pg_loss = -50.958, baseline_loss = 31.821, entropy_loss = -14.053, learner_queue_size = 64, _tick = 4376, _time = 1.6548e+09)
[2022-06-09 16:17:25,818][root][INFO] - Step 29204480 @ 3069.5 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 9408.8, step = 29204480, mean_episode_return = 44.328, mean_episode_step = 2353.9, total_loss = -57.197, pg_loss = -62.008, baseline_loss = 19.023, entropy_loss = -14.212, learner_queue_size = 64, _tick = 4379, _time = 1.6548e+09)
[2022-06-09 16:17:30,824][root][INFO] - Step 29219840 @ 3068.3 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 9413.8, step = 29219840, mean_episode_return = -0.57033, mean_episode_step = 2213.4, total_loss = -9.648, pg_loss = -12.983, baseline_loss = 17.562, entropy_loss = -14.227, learner_queue_size = 64, _tick = 4382, _time = 1.6548e+09)
[2022-06-09 16:17:35,828][root][INFO] - Step 29235200 @ 3069.4 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 9418.8, step = 29235200, mean_episode_return = 63.885, mean_episode_step = 1976.4, total_loss = 13.463, pg_loss = -1.9552, baseline_loss = 29.657, entropy_loss = -14.239, learner_queue_size = 64, _tick = 4384, _time = 1.6548e+09)
[2022-06-09 16:17:40,834][root][INFO] - Step 29250560 @ 3068.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 9423.8, step = 29250560, mean_episode_return = 20.04, mean_episode_step = 1974.1, total_loss = 45.574, pg_loss = 34.502, baseline_loss = 25.34, entropy_loss = -14.268, learner_queue_size = 64, _tick = 4387, _time = 1.6548e+09)
[2022-06-09 16:17:45,838][root][INFO] - Step 29271040 @ 4092.6 SPS. Inference batcher size: 87. Learner queue size: 64. Other stats: (train_seconds = 9428.8, step = 29271040, mean_episode_return = None, mean_episode_step = 1992.7, total_loss = -73.693, pg_loss = -71.429, baseline_loss = 12.099, entropy_loss = -14.362, learner_queue_size = 64, _tick = 4390, _time = 1.6548e+09)
[2022-06-09 16:17:50,842][root][INFO] - Step 29286400 @ 3069.6 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 9433.8, step = 29286400, mean_episode_return = 16.872, mean_episode_step = 2384.6, total_loss = 47.911, pg_loss = 29.613, baseline_loss = 32.832, entropy_loss = -14.534, learner_queue_size = 64, _tick = 4391, _time = 1.6548e+09)
[2022-06-09 16:17:55,846][root][INFO] - Step 29301760 @ 3069.5 SPS. Inference batcher size: 67. Learner queue size: 64. Other stats: (train_seconds = 9438.8, step = 29301760, mean_episode_return = None, mean_episode_step = 1989.3, total_loss = -86.419, pg_loss = -81.727, baseline_loss = 9.8174, entropy_loss = -14.509, learner_queue_size = 64, _tick = 4393, _time = 1.6548e+09)
[2022-06-09 16:18:00,852][root][INFO] - Step 29317120 @ 3068.3 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 9443.8, step = 29317120, mean_episode_return = 59.818, mean_episode_step = 1852.4, total_loss = -89.525, pg_loss = -98.979, baseline_loss = 24.249, entropy_loss = -14.796, learner_queue_size = 64, _tick = 4395, _time = 1.6548e+09)
[2022-06-09 16:18:05,858][root][INFO] - Step 29332480 @ 3068.4 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 9448.8, step = 29332480, mean_episode_return = 8.8455, mean_episode_step = 2100.4, total_loss = 177.69, pg_loss = 149.76, baseline_loss = 42.598, entropy_loss = -14.664, learner_queue_size = 64, _tick = 4398, _time = 1.6548e+09)
[2022-06-09 16:18:10,862][root][INFO] - Step 29347840 @ 3069.5 SPS. Inference batcher size: 18. Learner queue size: 64. Other stats: (train_seconds = 9453.8, step = 29347840, mean_episode_return = None, mean_episode_step = 2577.7, total_loss = -181.86, pg_loss = -169.11, baseline_loss = 1.7296, entropy_loss = -14.479, learner_queue_size = 64, _tick = 4400, _time = 1.6548e+09)
[2022-06-09 16:18:15,866][root][INFO] - Step 29363200 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 9458.8, step = 29363200, mean_episode_return = None, mean_episode_step = 2381.3, total_loss = -18.52, pg_loss = -21.116, baseline_loss = 17.065, entropy_loss = -14.469, learner_queue_size = 64, _tick = 4401, _time = 1.6548e+09)
[2022-06-09 16:18:20,870][root][INFO] - Step 29378560 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 9463.8, step = 29378560, mean_episode_return = 56.859, mean_episode_step = 2189.3, total_loss = 224.86, pg_loss = 197.7, baseline_loss = 41.609, entropy_loss = -14.444, learner_queue_size = 64, _tick = 4403, _time = 1.6548e+09)
[2022-06-09 16:18:25,874][root][INFO] - Step 29393920 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 9468.8, step = 29393920, mean_episode_return = -4.0404, mean_episode_step = 2356.2, total_loss = -7.1896, pg_loss = -17.807, baseline_loss = 25.006, entropy_loss = -14.389, learner_queue_size = 64, _tick = 4405, _time = 1.6548e+09)
[2022-06-09 16:18:30,878][root][INFO] - Step 29409280 @ 3069.5 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 9473.8, step = 29409280, mean_episode_return = None, mean_episode_step = 2051.9, total_loss = -84.128, pg_loss = -79.51, baseline_loss = 9.8095, entropy_loss = -14.428, learner_queue_size = 64, _tick = 4407, _time = 1.6548e+09)
[2022-06-09 16:18:35,882][root][INFO] - Step 29424640 @ 3069.6 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 9478.8, step = 29424640, mean_episode_return = None, mean_episode_step = 2123.5, total_loss = 85.842, pg_loss = 80.766, baseline_loss = 19.546, entropy_loss = -14.471, learner_queue_size = 64, _tick = 4409, _time = 1.6548e+09)
[2022-06-09 16:18:40,886][root][INFO] - Step 29440000 @ 3069.6 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 9483.8, step = 29440000, mean_episode_return = None, mean_episode_step = 2400.0, total_loss = 2.5948, pg_loss = -0.6759, baseline_loss = 17.821, entropy_loss = -14.55, learner_queue_size = 64, _tick = 4410, _time = 1.6548e+09)
[2022-06-09 16:18:45,890][root][INFO] - Step 29455360 @ 3069.5 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 9488.8, step = 29455360, mean_episode_return = 22.945, mean_episode_step = 2227.9, total_loss = 173.34, pg_loss = 147.87, baseline_loss = 40.234, entropy_loss = -14.767, learner_queue_size = 64, _tick = 4413, _time = 1.6548e+09)
[2022-06-09 16:18:50,894][root][INFO] - Step 29470720 @ 3069.5 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 9493.8, step = 29470720, mean_episode_return = 4.9748, mean_episode_step = 2264.5, total_loss = 246.22, pg_loss = 213.99, baseline_loss = 46.753, entropy_loss = -14.528, learner_queue_size = 64, _tick = 4415, _time = 1.6548e+09)
[2022-06-09 16:18:55,898][root][INFO] - Step 29491200 @ 4092.8 SPS. Inference batcher size: 93. Learner queue size: 64. Other stats: (train_seconds = 9498.8, step = 29491200, mean_episode_return = None, mean_episode_step = 2341.8, total_loss = -62.989, pg_loss = -62.43, baseline_loss = 14.001, entropy_loss = -14.56, learner_queue_size = 64, _tick = 4418, _time = 1.6548e+09)
[2022-06-09 16:19:00,902][root][INFO] - Step 29506560 @ 3069.5 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 9503.8, step = 29506560, mean_episode_return = None, mean_episode_step = 2429.9, total_loss = 152.14, pg_loss = 131.61, baseline_loss = 35.336, entropy_loss = -14.802, learner_queue_size = 64, _tick = 4420, _time = 1.6548e+09)
[2022-06-09 16:19:05,909][root][INFO] - Step 29521920 @ 3068.0 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 9508.8, step = 29521920, mean_episode_return = None, mean_episode_step = 2984.0, total_loss = 93.69, pg_loss = 79.975, baseline_loss = 28.605, entropy_loss = -14.89, learner_queue_size = 64, _tick = 4421, _time = 1.6548e+09)
[2022-06-09 16:19:10,914][root][INFO] - Step 29537280 @ 3068.6 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 9513.9, step = 29537280, mean_episode_return = 11.029, mean_episode_step = 2508.2, total_loss = 61.299, pg_loss = 54.414, baseline_loss = 21.613, entropy_loss = -14.728, learner_queue_size = 64, _tick = 4424, _time = 1.6548e+09)
[2022-06-09 16:19:15,918][root][INFO] - Step 29552640 @ 3069.6 SPS. Inference batcher size: 67. Learner queue size: 64. Other stats: (train_seconds = 9518.9, step = 29552640, mean_episode_return = 36.439, mean_episode_step = 2489.0, total_loss = 55.19, pg_loss = 29.627, baseline_loss = 40.104, entropy_loss = -14.541, learner_queue_size = 64, _tick = 4427, _time = 1.6548e+09)
[2022-06-09 16:19:20,922][root][INFO] - Step 29568000 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 9523.9, step = 29568000, mean_episode_return = 6.8797, mean_episode_step = 2388.3, total_loss = -0.60824, pg_loss = -5.4495, baseline_loss = 19.268, entropy_loss = -14.427, learner_queue_size = 64, _tick = 4430, _time = 1.6548e+09)
[2022-06-09 16:19:25,926][root][INFO] - Step 29583360 @ 3069.6 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 9528.9, step = 29583360, mean_episode_return = 45.937, mean_episode_step = 2554.1, total_loss = 59.338, pg_loss = 45.285, baseline_loss = 28.217, entropy_loss = -14.164, learner_queue_size = 64, _tick = 4433, _time = 1.6548e+09)
[2022-06-09 16:19:30,930][root][INFO] - Step 29598720 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 9533.9, step = 29598720, mean_episode_return = 43.373, mean_episode_step = 2187.5, total_loss = -6.1944, pg_loss = -17.245, baseline_loss = 25.091, entropy_loss = -14.041, learner_queue_size = 64, _tick = 4435, _time = 1.6548e+09)
[2022-06-09 16:19:35,934][root][INFO] - Step 29614080 @ 3069.5 SPS. Inference batcher size: 14. Learner queue size: 64. Other stats: (train_seconds = 9538.9, step = 29614080, mean_episode_return = 55.72, mean_episode_step = 2122.0, total_loss = 38.667, pg_loss = 22.509, baseline_loss = 30.137, entropy_loss = -13.978, learner_queue_size = 64, _tick = 4438, _time = 1.6548e+09)
[2022-06-09 16:19:40,938][root][INFO] - Step 29629440 @ 3069.6 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 9543.9, step = 29629440, mean_episode_return = 64.744, mean_episode_step = 2599.6, total_loss = 4.8353, pg_loss = 2.7718, baseline_loss = 16.228, entropy_loss = -14.164, learner_queue_size = 64, _tick = 4441, _time = 1.6548e+09)
[2022-06-09 16:19:45,943][root][INFO] - Step 29649920 @ 4092.6 SPS. Inference batcher size: 93. Learner queue size: 64. Other stats: (train_seconds = 9548.9, step = 29649920, mean_episode_return = 26.051, mean_episode_step = 2033.8, total_loss = -135.1, pg_loss = -133.36, baseline_loss = 12.593, entropy_loss = -14.33, learner_queue_size = 64, _tick = 4445, _time = 1.6548e+09)
[2022-06-09 16:19:50,946][root][INFO] - Step 29665280 @ 3069.6 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 9553.9, step = 29665280, mean_episode_return = 60.004, mean_episode_step = 1995.0, total_loss = 38.962, pg_loss = 24.087, baseline_loss = 29.311, entropy_loss = -14.436, learner_queue_size = 64, _tick = 4447, _time = 1.6548e+09)
[2022-06-09 16:19:55,950][root][INFO] - Step 29680640 @ 3069.5 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 9558.9, step = 29680640, mean_episode_return = 23.827, mean_episode_step = 2064.0, total_loss = -36.994, pg_loss = -52.402, baseline_loss = 30.141, entropy_loss = -14.732, learner_queue_size = 64, _tick = 4449, _time = 1.6548e+09)
[2022-06-09 16:20:00,954][root][INFO] - Step 29696000 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 9563.9, step = 29696000, mean_episode_return = 63.972, mean_episode_step = 2337.2, total_loss = 269.01, pg_loss = 245.01, baseline_loss = 38.914, entropy_loss = -14.91, learner_queue_size = 64, _tick = 4451, _time = 1.6548e+09)
[2022-06-09 16:20:05,958][root][INFO] - Step 29711360 @ 3069.5 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 9568.9, step = 29711360, mean_episode_return = None, mean_episode_step = 1949.2, total_loss = -57.874, pg_loss = -54.585, baseline_loss = 11.591, entropy_loss = -14.879, learner_queue_size = 64, _tick = 4452, _time = 1.6548e+09)
[2022-06-09 16:20:10,962][root][INFO] - Step 29726720 @ 3069.6 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 9573.9, step = 29726720, mean_episode_return = 6.0352, mean_episode_step = 2011.1, total_loss = -49.194, pg_loss = -49.587, baseline_loss = 15.257, entropy_loss = -14.864, learner_queue_size = 64, _tick = 4455, _time = 1.6548e+09)
[2022-06-09 16:20:15,966][root][INFO] - Step 29742080 @ 3069.6 SPS. Inference batcher size: 76. Learner queue size: 64. Other stats: (train_seconds = 9578.9, step = 29742080, mean_episode_return = 36.271, mean_episode_step = 2043.1, total_loss = 207.16, pg_loss = 187.25, baseline_loss = 34.87, entropy_loss = -14.961, learner_queue_size = 64, _tick = 4458, _time = 1.6548e+09)
[2022-06-09 16:20:20,984][root][INFO] - Step 29757440 @ 3060.9 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 9583.9, step = 29757440, mean_episode_return = 71.813, mean_episode_step = 2066.7, total_loss = 17.62, pg_loss = 5.5932, baseline_loss = 26.939, entropy_loss = -14.912, learner_queue_size = 64, _tick = 4460, _time = 1.6548e+09)
[2022-06-09 16:20:25,990][root][INFO] - Step 29772800 @ 3068.4 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 9588.9, step = 29772800, mean_episode_return = 53.106, mean_episode_step = 1981.7, total_loss = -154.82, pg_loss = -147.35, baseline_loss = 7.0468, entropy_loss = -14.51, learner_queue_size = 64, _tick = 4463, _time = 1.6548e+09)
[2022-06-09 16:20:30,994][root][INFO] - Step 29788160 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 9593.9, step = 29788160, mean_episode_return = 33.377, mean_episode_step = 1821.2, total_loss = 23.758, pg_loss = 17.648, baseline_loss = 20.637, entropy_loss = -14.527, learner_queue_size = 64, _tick = 4466, _time = 1.6548e+09)
[2022-06-09 16:20:35,998][root][INFO] - Step 29803520 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 9598.9, step = 29803520, mean_episode_return = 31.216, mean_episode_step = 1979.3, total_loss = -6.8417, pg_loss = -12.504, baseline_loss = 20.271, entropy_loss = -14.609, learner_queue_size = 64, _tick = 4468, _time = 1.6548e+09)
[2022-06-09 16:20:41,002][root][INFO] - Step 29818880 @ 3069.6 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 9603.9, step = 29818880, mean_episode_return = 42.735, mean_episode_step = 1840.0, total_loss = 16.591, pg_loss = 20.802, baseline_loss = 10.117, entropy_loss = -14.327, learner_queue_size = 64, _tick = 4471, _time = 1.6548e+09)
[2022-06-09 16:20:46,006][root][INFO] - Step 29839360 @ 4092.7 SPS. Inference batcher size: 28. Learner queue size: 31. Other stats: (train_seconds = 9608.9, step = 29839360, mean_episode_return = None, mean_episode_step = 2077.2, total_loss = 2.2863, pg_loss = 7.7076, baseline_loss = 8.9947, entropy_loss = -14.416, learner_queue_size = 64, _tick = 4473, _time = 1.6548e+09)
[2022-06-09 16:20:51,014][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 16:20:51,243][root][INFO] - Step 29854720 @ 3067.0 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 9614.0, step = 29854720, mean_episode_return = 45.234, mean_episode_step = 2154.9, total_loss = 13.783, pg_loss = 9.5098, baseline_loss = 18.366, entropy_loss = -14.093, learner_queue_size = 64, _tick = 4476, _time = 1.6548e+09)
[2022-06-09 16:20:56,246][root][INFO] - Step 29870080 @ 2935.8 SPS. Inference batcher size: 81. Learner queue size: 64. Other stats: (train_seconds = 9619.2, step = 29870080, mean_episode_return = 22.86, mean_episode_step = 1953.7, total_loss = 267.52, pg_loss = 233.18, baseline_loss = 48.591, entropy_loss = -14.258, learner_queue_size = 64, _tick = 4479, _time = 1.6548e+09)
[2022-06-09 16:21:01,250][root][INFO] - Step 29885440 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 9624.2, step = 29885440, mean_episode_return = -12.68, mean_episode_step = 2347.4, total_loss = 106.58, pg_loss = 91.622, baseline_loss = 29.242, entropy_loss = -14.281, learner_queue_size = 64, _tick = 4482, _time = 1.6548e+09)
[2022-06-09 16:21:06,254][root][INFO] - Step 29900800 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 9629.2, step = 29900800, mean_episode_return = 2.3691, mean_episode_step = 1988.7, total_loss = 189.22, pg_loss = 169.75, baseline_loss = 34.029, entropy_loss = -14.562, learner_queue_size = 64, _tick = 4485, _time = 1.6548e+09)
[2022-06-09 16:21:11,258][root][INFO] - Step 29916160 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 9634.2, step = 29916160, mean_episode_return = None, mean_episode_step = 1937.6, total_loss = 160.68, pg_loss = 142.58, baseline_loss = 32.69, entropy_loss = -14.596, learner_queue_size = 64, _tick = 4486, _time = 1.6548e+09)
[2022-06-09 16:21:16,262][root][INFO] - Step 29931520 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 9639.2, step = 29931520, mean_episode_return = -41.091, mean_episode_step = 2078.2, total_loss = 94.422, pg_loss = 62.928, baseline_loss = 46.244, entropy_loss = -14.751, learner_queue_size = 64, _tick = 4488, _time = 1.6548e+09)
[2022-06-09 16:21:21,266][root][INFO] - Step 29946880 @ 3069.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 9644.2, step = 29946880, mean_episode_return = 36.435, mean_episode_step = 1780.8, total_loss = 1.1468, pg_loss = -4.6974, baseline_loss = 20.741, entropy_loss = -14.897, learner_queue_size = 64, _tick = 4490, _time = 1.6548e+09)
[2022-06-09 16:21:26,270][root][INFO] - Step 29962240 @ 3069.5 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 9649.2, step = 29962240, mean_episode_return = 44.63, mean_episode_step = 2101.7, total_loss = -60.4, pg_loss = -58.661, baseline_loss = 13.386, entropy_loss = -15.124, learner_queue_size = 64, _tick = 4492, _time = 1.6548e+09)
[2022-06-09 16:21:31,274][root][INFO] - Step 29977600 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 9654.2, step = 29977600, mean_episode_return = 39.262, mean_episode_step = 2058.8, total_loss = -23.111, pg_loss = -30.593, baseline_loss = 22.764, entropy_loss = -15.282, learner_queue_size = 64, _tick = 4495, _time = 1.6548e+09)
[2022-06-09 16:21:36,278][root][INFO] - Step 29992960 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 9659.2, step = 29992960, mean_episode_return = 73.0, mean_episode_step = 1903.1, total_loss = 20.287, pg_loss = 16.214, baseline_loss = 19.343, entropy_loss = -15.27, learner_queue_size = 64, _tick = 4498, _time = 1.6548e+09)
[2022-06-09 16:21:41,282][root][INFO] - Step 30008320 @ 3069.6 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 9664.2, step = 30008320, mean_episode_return = None, mean_episode_step = 2419.9, total_loss = -28.552, pg_loss = -22.402, baseline_loss = 9.1274, entropy_loss = -15.278, learner_queue_size = 64, _tick = 4500, _time = 1.6548e+09)
[2022-06-09 16:21:46,286][root][INFO] - Step 30028800 @ 4092.8 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 9669.2, step = 30028800, mean_episode_return = None, mean_episode_step = 2031.5, total_loss = -20.731, pg_loss = -14.133, baseline_loss = 8.47, entropy_loss = -15.068, learner_queue_size = 64, _tick = 4501, _time = 1.6548e+09)
[2022-06-09 16:21:51,290][root][INFO] - Step 30044160 @ 3069.5 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 9674.2, step = 30044160, mean_episode_return = 27.23, mean_episode_step = 2176.3, total_loss = -21.388, pg_loss = -27.718, baseline_loss = 21.286, entropy_loss = -14.956, learner_queue_size = 64, _tick = 4504, _time = 1.6548e+09)
[2022-06-09 16:21:56,294][root][INFO] - Step 30059520 @ 3069.6 SPS. Inference batcher size: 77. Learner queue size: 64. Other stats: (train_seconds = 9679.2, step = 30059520, mean_episode_return = 16.42, mean_episode_step = 1831.2, total_loss = -152.57, pg_loss = -145.21, baseline_loss = 7.5784, entropy_loss = -14.942, learner_queue_size = 64, _tick = 4507, _time = 1.6548e+09)
[2022-06-09 16:22:01,298][root][INFO] - Step 30074880 @ 3069.4 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 9684.2, step = 30074880, mean_episode_return = 33.67, mean_episode_step = 2307.0, total_loss = 129.07, pg_loss = 116.83, baseline_loss = 27.289, entropy_loss = -15.049, learner_queue_size = 64, _tick = 4510, _time = 1.6548e+09)
[2022-06-09 16:22:06,302][root][INFO] - Step 30090240 @ 3069.7 SPS. Inference batcher size: 67. Learner queue size: 64. Other stats: (train_seconds = 9689.2, step = 30090240, mean_episode_return = 0.89429, mean_episode_step = 2015.7, total_loss = 246.0, pg_loss = 215.24, baseline_loss = 45.712, entropy_loss = -14.954, learner_queue_size = 64, _tick = 4513, _time = 1.6548e+09)
[2022-06-09 16:22:11,306][root][INFO] - Step 30105600 @ 3069.4 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 9694.2, step = 30105600, mean_episode_return = None, mean_episode_step = 2234.2, total_loss = -11.767, pg_loss = -9.8435, baseline_loss = 12.948, entropy_loss = -14.872, learner_queue_size = 64, _tick = 4515, _time = 1.6548e+09)
[2022-06-09 16:22:16,310][root][INFO] - Step 30120960 @ 3069.7 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 9699.2, step = 30120960, mean_episode_return = None, mean_episode_step = 2187.1, total_loss = 377.24, pg_loss = 304.48, baseline_loss = 87.913, entropy_loss = -15.155, learner_queue_size = 64, _tick = 4515, _time = 1.6548e+09)
[2022-06-09 16:22:21,314][root][INFO] - Step 30136320 @ 3069.5 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 9704.3, step = 30136320, mean_episode_return = -44.349, mean_episode_step = 2209.3, total_loss = -69.071, pg_loss = -66.238, baseline_loss = 12.462, entropy_loss = -15.295, learner_queue_size = 64, _tick = 4517, _time = 1.6548e+09)
[2022-06-09 16:22:26,318][root][INFO] - Step 30151680 @ 3069.6 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 9709.3, step = 30151680, mean_episode_return = 39.18, mean_episode_step = 2302.2, total_loss = 207.0, pg_loss = 186.18, baseline_loss = 36.234, entropy_loss = -15.414, learner_queue_size = 64, _tick = 4520, _time = 1.6548e+09)
[2022-06-09 16:22:31,322][root][INFO] - Step 30167040 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 9714.3, step = 30167040, mean_episode_return = 28.435, mean_episode_step = 2312.2, total_loss = 42.179, pg_loss = 36.432, baseline_loss = 20.949, entropy_loss = -15.202, learner_queue_size = 64, _tick = 4523, _time = 1.6548e+09)
[2022-06-09 16:22:36,326][root][INFO] - Step 30182400 @ 3069.5 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 9719.3, step = 30182400, mean_episode_return = 29.52, mean_episode_step = 1907.0, total_loss = -28.31, pg_loss = -22.943, baseline_loss = 9.8293, entropy_loss = -15.196, learner_queue_size = 64, _tick = 4525, _time = 1.6548e+09)
[2022-06-09 16:22:41,330][root][INFO] - Step 30197760 @ 3069.5 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 9724.3, step = 30197760, mean_episode_return = 55.076, mean_episode_step = 2510.6, total_loss = 61.264, pg_loss = 53.504, baseline_loss = 23.143, entropy_loss = -15.383, learner_queue_size = 64, _tick = 4528, _time = 1.6548e+09)
[2022-06-09 16:22:46,334][root][INFO] - Step 30213120 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 9729.3, step = 30213120, mean_episode_return = -8.5775, mean_episode_step = 2064.0, total_loss = 180.24, pg_loss = 162.95, baseline_loss = 32.636, entropy_loss = -15.346, learner_queue_size = 64, _tick = 4531, _time = 1.6548e+09)
[2022-06-09 16:22:51,338][root][INFO] - Step 30228480 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 9734.3, step = 30228480, mean_episode_return = 119.24, mean_episode_step = 2082.9, total_loss = -111.08, pg_loss = -105.3, baseline_loss = 9.5738, entropy_loss = -15.352, learner_queue_size = 64, _tick = 4534, _time = 1.6548e+09)
[2022-06-09 16:22:56,342][root][INFO] - Step 30243840 @ 3069.5 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 9739.3, step = 30243840, mean_episode_return = 33.45, mean_episode_step = 1869.6, total_loss = 192.44, pg_loss = 177.63, baseline_loss = 30.07, entropy_loss = -15.264, learner_queue_size = 64, _tick = 4537, _time = 1.6548e+09)
[2022-06-09 16:23:01,346][root][INFO] - Step 30259200 @ 3069.6 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 9744.3, step = 30259200, mean_episode_return = 27.698, mean_episode_step = 2133.6, total_loss = -179.75, pg_loss = -179.57, baseline_loss = 15.087, entropy_loss = -15.269, learner_queue_size = 64, _tick = 4539, _time = 1.6548e+09)
[2022-06-09 16:23:06,352][root][INFO] - Step 30274560 @ 3068.1 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 9749.3, step = 30274560, mean_episode_return = 63.654, mean_episode_step = 2158.2, total_loss = -140.48, pg_loss = -133.11, baseline_loss = 7.9319, entropy_loss = -15.301, learner_queue_size = 64, _tick = 4542, _time = 1.6548e+09)
[2022-06-09 16:23:11,358][root][INFO] - Step 30295040 @ 4091.3 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 9754.3, step = 30295040, mean_episode_return = None, mean_episode_step = 1995.3, total_loss = 375.83, pg_loss = 340.04, baseline_loss = 51.264, entropy_loss = -15.472, learner_queue_size = 64, _tick = 4545, _time = 1.6548e+09)
[2022-06-09 16:23:16,362][root][INFO] - Step 30310400 @ 3069.6 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 9759.3, step = 30310400, mean_episode_return = 39.551, mean_episode_step = 2066.1, total_loss = -124.27, pg_loss = -122.04, baseline_loss = 13.286, entropy_loss = -15.513, learner_queue_size = 64, _tick = 4548, _time = 1.6548e+09)
[2022-06-09 16:23:21,366][root][INFO] - Step 30325760 @ 3069.6 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 9764.3, step = 30325760, mean_episode_return = 100.31, mean_episode_step = 1834.9, total_loss = -192.03, pg_loss = -183.96, baseline_loss = 7.3586, entropy_loss = -15.422, learner_queue_size = 64, _tick = 4551, _time = 1.6548e+09)
[2022-06-09 16:23:26,370][root][INFO] - Step 30341120 @ 3069.3 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 9769.3, step = 30341120, mean_episode_return = 7.9997, mean_episode_step = 2264.0, total_loss = -113.27, pg_loss = -108.34, baseline_loss = 10.668, entropy_loss = -15.594, learner_queue_size = 64, _tick = 4553, _time = 1.6548e+09)
[2022-06-09 16:23:31,374][root][INFO] - Step 30356480 @ 3069.8 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 9774.3, step = 30356480, mean_episode_return = 13.035, mean_episode_step = 1893.9, total_loss = 41.468, pg_loss = 32.384, baseline_loss = 24.558, entropy_loss = -15.474, learner_queue_size = 64, _tick = 4555, _time = 1.6548e+09)
[2022-06-09 16:23:36,378][root][INFO] - Step 30371840 @ 3069.5 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 9779.3, step = 30371840, mean_episode_return = None, mean_episode_step = 2183.0, total_loss = 280.93, pg_loss = 254.1, baseline_loss = 42.1, entropy_loss = -15.27, learner_queue_size = 64, _tick = 4556, _time = 1.6548e+09)
[2022-06-09 16:23:41,383][root][INFO] - Step 30387200 @ 3069.0 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 9784.3, step = 30387200, mean_episode_return = None, mean_episode_step = 2104.0, total_loss = 239.54, pg_loss = 218.66, baseline_loss = 36.162, entropy_loss = -15.284, learner_queue_size = 64, _tick = 4558, _time = 1.6548e+09)
[2022-06-09 16:23:46,386][root][INFO] - Step 30402560 @ 3070.2 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 9789.3, step = 30402560, mean_episode_return = 23.15, mean_episode_step = 2424.7, total_loss = 165.18, pg_loss = 139.67, baseline_loss = 40.72, entropy_loss = -15.207, learner_queue_size = 64, _tick = 4560, _time = 1.6548e+09)
[2022-06-09 16:23:51,390][root][INFO] - Step 30417920 @ 3069.5 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 9794.3, step = 30417920, mean_episode_return = 50.752, mean_episode_step = 2033.8, total_loss = -136.07, pg_loss = -129.54, baseline_loss = 8.6675, entropy_loss = -15.198, learner_queue_size = 64, _tick = 4563, _time = 1.6548e+09)
[2022-06-09 16:23:56,394][root][INFO] - Step 30433280 @ 3069.6 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 9799.3, step = 30433280, mean_episode_return = 32.32, mean_episode_step = 1969.4, total_loss = 40.156, pg_loss = 37.175, baseline_loss = 18.184, entropy_loss = -15.203, learner_queue_size = 64, _tick = 4566, _time = 1.6548e+09)
[2022-06-09 16:24:01,398][root][INFO] - Step 30448640 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 9804.3, step = 30448640, mean_episode_return = None, mean_episode_step = 2303.3, total_loss = -63.973, pg_loss = -65.224, baseline_loss = 16.354, entropy_loss = -15.104, learner_queue_size = 64, _tick = 4566, _time = 1.6548e+09)
[2022-06-09 16:24:06,404][root][INFO] - Step 30464000 @ 3068.5 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 9809.3, step = 30464000, mean_episode_return = 93.416, mean_episode_step = 2421.4, total_loss = 226.14, pg_loss = 189.26, baseline_loss = 51.945, entropy_loss = -15.065, learner_queue_size = 64, _tick = 4569, _time = 1.6548e+09)
[2022-06-09 16:24:11,406][root][INFO] - Step 30479360 @ 3070.6 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 9814.3, step = 30479360, mean_episode_return = None, mean_episode_step = 2129.9, total_loss = 378.63, pg_loss = 331.12, baseline_loss = 62.47, entropy_loss = -14.954, learner_queue_size = 64, _tick = 4570, _time = 1.6548e+09)
[2022-06-09 16:24:16,410][root][INFO] - Step 30499840 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 9819.3, step = 30499840, mean_episode_return = 74.808, mean_episode_step = 2337.6, total_loss = -8.3271, pg_loss = -11.279, baseline_loss = 17.727, entropy_loss = -14.775, learner_queue_size = 64, _tick = 4573, _time = 1.6548e+09)
[2022-06-09 16:24:21,416][root][INFO] - Step 30515200 @ 3068.1 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 9824.4, step = 30515200, mean_episode_return = -5.8539, mean_episode_step = 2429.2, total_loss = 70.71, pg_loss = 56.665, baseline_loss = 28.874, entropy_loss = -14.829, learner_queue_size = 64, _tick = 4575, _time = 1.6548e+09)
[2022-06-09 16:24:26,422][root][INFO] - Step 30530560 @ 3068.5 SPS. Inference batcher size: 3. Learner queue size: 64. Other stats: (train_seconds = 9829.4, step = 30530560, mean_episode_return = 85.083, mean_episode_step = 1998.4, total_loss = 20.795, pg_loss = 0.63209, baseline_loss = 34.597, entropy_loss = -14.434, learner_queue_size = 64, _tick = 4578, _time = 1.6548e+09)
[2022-06-09 16:24:31,427][root][INFO] - Step 30545920 @ 3068.9 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 9834.4, step = 30545920, mean_episode_return = None, mean_episode_step = 2001.7, total_loss = 125.96, pg_loss = 98.229, baseline_loss = 42.049, entropy_loss = -14.313, learner_queue_size = 64, _tick = 4579, _time = 1.6548e+09)
[2022-06-09 16:24:36,430][root][INFO] - Step 30561280 @ 3070.2 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 9839.4, step = 30561280, mean_episode_return = None, mean_episode_step = 2179.8, total_loss = -18.158, pg_loss = -26.094, baseline_loss = 22.327, entropy_loss = -14.39, learner_queue_size = 64, _tick = 4580, _time = 1.6548e+09)
[2022-06-09 16:24:41,434][root][INFO] - Step 30576640 @ 3069.5 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 9844.4, step = 30576640, mean_episode_return = 98.887, mean_episode_step = 2553.0, total_loss = 51.246, pg_loss = 35.027, baseline_loss = 30.481, entropy_loss = -14.262, learner_queue_size = 64, _tick = 4583, _time = 1.6548e+09)
[2022-06-09 16:24:46,438][root][INFO] - Step 30592000 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 9849.4, step = 30592000, mean_episode_return = None, mean_episode_step = 2459.8, total_loss = 24.242, pg_loss = 19.884, baseline_loss = 18.516, entropy_loss = -14.158, learner_queue_size = 64, _tick = 4584, _time = 1.6548e+09)
[2022-06-09 16:24:51,442][root][INFO] - Step 30607360 @ 3069.6 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 9854.4, step = 30607360, mean_episode_return = 27.64, mean_episode_step = 2320.8, total_loss = -10.241, pg_loss = -27.388, baseline_loss = 31.228, entropy_loss = -14.081, learner_queue_size = 64, _tick = 4587, _time = 1.6548e+09)
[2022-06-09 16:24:56,446][root][INFO] - Step 30622720 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 9859.4, step = 30622720, mean_episode_return = 50.492, mean_episode_step = 2169.7, total_loss = 32.372, pg_loss = 22.624, baseline_loss = 24.17, entropy_loss = -14.422, learner_queue_size = 64, _tick = 4590, _time = 1.6548e+09)
[2022-06-09 16:25:01,450][root][INFO] - Step 30643200 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 9864.4, step = 30643200, mean_episode_return = 5.6494, mean_episode_step = 2334.5, total_loss = 120.78, pg_loss = 105.57, baseline_loss = 29.639, entropy_loss = -14.432, learner_queue_size = 64, _tick = 4593, _time = 1.6548e+09)
[2022-06-09 16:25:06,454][root][INFO] - Step 30658560 @ 3069.6 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 9869.4, step = 30658560, mean_episode_return = 5.1697, mean_episode_step = 2177.9, total_loss = -29.144, pg_loss = -39.898, baseline_loss = 25.21, entropy_loss = -14.456, learner_queue_size = 64, _tick = 4595, _time = 1.6548e+09)
[2022-06-09 16:25:11,458][root][INFO] - Step 30673920 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 9874.4, step = 30673920, mean_episode_return = None, mean_episode_step = 2202.0, total_loss = 863.86, pg_loss = 425.81, baseline_loss = 452.73, entropy_loss = -14.677, learner_queue_size = 64, _tick = 4596, _time = 1.6548e+09)
[2022-06-09 16:25:16,462][root][INFO] - Step 30689280 @ 3069.6 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 9879.4, step = 30689280, mean_episode_return = 13.62, mean_episode_step = 2354.6, total_loss = -8.8766, pg_loss = -23.807, baseline_loss = 29.652, entropy_loss = -14.722, learner_queue_size = 64, _tick = 4599, _time = 1.6548e+09)
[2022-06-09 16:25:21,466][root][INFO] - Step 30704640 @ 3069.5 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 9884.4, step = 30704640, mean_episode_return = None, mean_episode_step = 2390.5, total_loss = -14.956, pg_loss = -20.711, baseline_loss = 20.424, entropy_loss = -14.669, learner_queue_size = 64, _tick = 4601, _time = 1.6548e+09)
[2022-06-09 16:25:26,470][root][INFO] - Step 30725120 @ 4092.8 SPS. Inference batcher size: 76. Learner queue size: 64. Other stats: (train_seconds = 9889.4, step = 30725120, mean_episode_return = None, mean_episode_step = 2416.3, total_loss = -47.172, pg_loss = -49.399, baseline_loss = 17.052, entropy_loss = -14.826, learner_queue_size = 64, _tick = 4603, _time = 1.6548e+09)
[2022-06-09 16:25:31,474][root][INFO] - Step 30740480 @ 3069.5 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 9894.4, step = 30740480, mean_episode_return = 19.216, mean_episode_step = 2648.8, total_loss = -108.74, pg_loss = -112.37, baseline_loss = 18.585, entropy_loss = -14.948, learner_queue_size = 64, _tick = 4606, _time = 1.6548e+09)
[2022-06-09 16:25:36,478][root][INFO] - Step 30755840 @ 3069.6 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 9899.4, step = 30755840, mean_episode_return = 18.666, mean_episode_step = 2804.1, total_loss = -71.286, pg_loss = -71.642, baseline_loss = 15.578, entropy_loss = -15.222, learner_queue_size = 64, _tick = 4609, _time = 1.6548e+09)
[2022-06-09 16:25:41,482][root][INFO] - Step 30771200 @ 3069.3 SPS. Inference batcher size: 10. Learner queue size: 64. Other stats: (train_seconds = 9904.4, step = 30771200, mean_episode_return = None, mean_episode_step = 2432.5, total_loss = 85.533, pg_loss = 75.113, baseline_loss = 25.695, entropy_loss = -15.275, learner_queue_size = 64, _tick = 4610, _time = 1.6548e+09)
[2022-06-09 16:25:46,486][root][INFO] - Step 30786560 @ 3069.7 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 9909.4, step = 30786560, mean_episode_return = 56.3, mean_episode_step = 2531.7, total_loss = -69.845, pg_loss = -69.853, baseline_loss = 15.288, entropy_loss = -15.279, learner_queue_size = 64, _tick = 4613, _time = 1.6548e+09)
[2022-06-09 16:25:51,490][root][INFO] - Step 30807040 @ 4092.6 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 9914.4, step = 30807040, mean_episode_return = None, mean_episode_step = 2190.0, total_loss = 195.75, pg_loss = 176.79, baseline_loss = 34.233, entropy_loss = -15.273, learner_queue_size = 64, _tick = 4616, _time = 1.6548e+09)
[2022-06-09 16:25:56,498][root][INFO] - Step 30822400 @ 3067.2 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 9919.4, step = 30822400, mean_episode_return = 0.0097329, mean_episode_step = 2301.8, total_loss = 121.29, pg_loss = 113.09, baseline_loss = 23.386, entropy_loss = -15.186, learner_queue_size = 64, _tick = 4618, _time = 1.6548e+09)
[2022-06-09 16:26:01,502][root][INFO] - Step 30837760 @ 3069.5 SPS. Inference batcher size: 15. Learner queue size: 64. Other stats: (train_seconds = 9924.4, step = 30837760, mean_episode_return = None, mean_episode_step = 2342.7, total_loss = 118.58, pg_loss = 106.33, baseline_loss = 27.519, entropy_loss = -15.27, learner_queue_size = 64, _tick = 4620, _time = 1.6548e+09)
[2022-06-09 16:26:06,506][root][INFO] - Step 30853120 @ 3069.6 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 9929.4, step = 30853120, mean_episode_return = None, mean_episode_step = 2326.5, total_loss = 250.73, pg_loss = 231.8, baseline_loss = 34.076, entropy_loss = -15.148, learner_queue_size = 64, _tick = 4622, _time = 1.6548e+09)
[2022-06-09 16:26:11,510][root][INFO] - Step 30868480 @ 3069.5 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 9934.4, step = 30868480, mean_episode_return = 21.359, mean_episode_step = 2096.4, total_loss = 0.77234, pg_loss = -1.0335, baseline_loss = 16.856, entropy_loss = -15.051, learner_queue_size = 64, _tick = 4625, _time = 1.6548e+09)
[2022-06-09 16:26:16,514][root][INFO] - Step 30888960 @ 4092.7 SPS. Inference batcher size: 78. Learner queue size: 64. Other stats: (train_seconds = 9939.4, step = 30888960, mean_episode_return = 49.875, mean_episode_step = 2201.9, total_loss = -26.944, pg_loss = -39.409, baseline_loss = 27.469, entropy_loss = -15.004, learner_queue_size = 64, _tick = 4629, _time = 1.6548e+09)
[2022-06-09 16:26:21,518][root][INFO] - Step 30904320 @ 3069.6 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 9944.5, step = 30904320, mean_episode_return = 143.16, mean_episode_step = 2170.1, total_loss = 41.896, pg_loss = 35.139, baseline_loss = 21.895, entropy_loss = -15.138, learner_queue_size = 64, _tick = 4632, _time = 1.6548e+09)
[2022-06-09 16:26:26,522][root][INFO] - Step 30919680 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 9949.5, step = 30919680, mean_episode_return = 110.26, mean_episode_step = 2895.6, total_loss = -177.25, pg_loss = -174.03, baseline_loss = 12.016, entropy_loss = -15.232, learner_queue_size = 64, _tick = 4635, _time = 1.6548e+09)
[2022-06-09 16:26:31,526][root][INFO] - Step 30935040 @ 3069.5 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 9954.5, step = 30935040, mean_episode_return = 39.983, mean_episode_step = 2162.7, total_loss = 193.05, pg_loss = 157.63, baseline_loss = 50.587, entropy_loss = -15.159, learner_queue_size = 64, _tick = 4638, _time = 1.6548e+09)
[2022-06-09 16:26:36,530][root][INFO] - Step 30950400 @ 3069.6 SPS. Inference batcher size: 6. Learner queue size: 64. Other stats: (train_seconds = 9959.5, step = 30950400, mean_episode_return = None, mean_episode_step = 2576.7, total_loss = 218.15, pg_loss = 201.03, baseline_loss = 32.212, entropy_loss = -15.095, learner_queue_size = 64, _tick = 4640, _time = 1.6548e+09)
[2022-06-09 16:26:41,534][root][INFO] - Step 30965760 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 9964.5, step = 30965760, mean_episode_return = 39.439, mean_episode_step = 2254.6, total_loss = -30.149, pg_loss = -44.582, baseline_loss = 29.504, entropy_loss = -15.071, learner_queue_size = 64, _tick = 4643, _time = 1.6548e+09)
[2022-06-09 16:26:46,538][root][INFO] - Step 30986240 @ 4092.7 SPS. Inference batcher size: 76. Learner queue size: 64. Other stats: (train_seconds = 9969.5, step = 30986240, mean_episode_return = 42.192, mean_episode_step = 2018.4, total_loss = -1.0141, pg_loss = -10.851, baseline_loss = 24.751, entropy_loss = -14.914, learner_queue_size = 64, _tick = 4647, _time = 1.6548e+09)
[2022-06-09 16:26:51,542][root][INFO] - Step 31001600 @ 3069.6 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 9974.5, step = 31001600, mean_episode_return = 49.753, mean_episode_step = 2163.7, total_loss = 338.34, pg_loss = 299.08, baseline_loss = 53.985, entropy_loss = -14.725, learner_queue_size = 64, _tick = 4650, _time = 1.6548e+09)
[2022-06-09 16:26:56,546][root][INFO] - Step 31016960 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 9979.5, step = 31016960, mean_episode_return = 60.643, mean_episode_step = 2404.9, total_loss = -166.47, pg_loss = -168.56, baseline_loss = 16.549, entropy_loss = -14.456, learner_queue_size = 64, _tick = 4653, _time = 1.6548e+09)
[2022-06-09 16:27:01,550][root][INFO] - Step 31032320 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 9984.5, step = 31032320, mean_episode_return = 56.593, mean_episode_step = 2753.3, total_loss = -201.07, pg_loss = -199.62, baseline_loss = 12.944, entropy_loss = -14.392, learner_queue_size = 64, _tick = 4656, _time = 1.6548e+09)
[2022-06-09 16:27:06,554][root][INFO] - Step 31047680 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 9989.5, step = 31047680, mean_episode_return = 3.07, mean_episode_step = 1831.4, total_loss = 100.0, pg_loss = 78.842, baseline_loss = 35.542, entropy_loss = -14.379, learner_queue_size = 64, _tick = 4659, _time = 1.6548e+09)
[2022-06-09 16:27:11,558][root][INFO] - Step 31068160 @ 4092.7 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 9994.5, step = 31068160, mean_episode_return = 24.623, mean_episode_step = 2335.4, total_loss = -254.18, pg_loss = -265.65, baseline_loss = 25.978, entropy_loss = -14.5, learner_queue_size = 64, _tick = 4661, _time = 1.6548e+09)
[2022-06-09 16:27:16,562][root][INFO] - Step 31083520 @ 3069.4 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 9999.5, step = 31083520, mean_episode_return = 30.43, mean_episode_step = 2158.4, total_loss = 83.336, pg_loss = 69.072, baseline_loss = 28.737, entropy_loss = -14.473, learner_queue_size = 64, _tick = 4663, _time = 1.6548e+09)
[2022-06-09 16:27:21,566][root][INFO] - Step 31098880 @ 3069.7 SPS. Inference batcher size: 15. Learner queue size: 64. Other stats: (train_seconds = 1.0004e+04, step = 31098880, mean_episode_return = 67.503, mean_episode_step = 2132.9, total_loss = 17.833, pg_loss = -2.7873, baseline_loss = 35.215, entropy_loss = -14.595, learner_queue_size = 64, _tick = 4666, _time = 1.6548e+09)
[2022-06-09 16:27:26,570][root][INFO] - Step 31114240 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.001e+04, step = 31114240, mean_episode_return = 26.94, mean_episode_step = 2461.9, total_loss = -45.102, pg_loss = -47.137, baseline_loss = 16.555, entropy_loss = -14.52, learner_queue_size = 64, _tick = 4668, _time = 1.6548e+09)
[2022-06-09 16:27:31,574][root][INFO] - Step 31129600 @ 3069.5 SPS. Inference batcher size: 18. Learner queue size: 64. Other stats: (train_seconds = 1.0014e+04, step = 31129600, mean_episode_return = None, mean_episode_step = 2254.6, total_loss = 185.81, pg_loss = 144.7, baseline_loss = 55.921, entropy_loss = -14.811, learner_queue_size = 64, _tick = 4670, _time = 1.6548e+09)
[2022-06-09 16:27:36,578][root][INFO] - Step 31150080 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.002e+04, step = 31150080, mean_episode_return = 98.256, mean_episode_step = 2047.7, total_loss = -194.08, pg_loss = -182.2, baseline_loss = 2.8863, entropy_loss = -14.759, learner_queue_size = 64, _tick = 4674, _time = 1.6548e+09)
[2022-06-09 16:27:41,582][root][INFO] - Step 31165440 @ 3069.6 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 1.0024e+04, step = 31165440, mean_episode_return = None, mean_episode_step = 2185.9, total_loss = 69.801, pg_loss = 64.3, baseline_loss = 20.38, entropy_loss = -14.879, learner_queue_size = 64, _tick = 4676, _time = 1.6548e+09)
[2022-06-09 16:27:46,586][root][INFO] - Step 31180800 @ 3069.6 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.003e+04, step = 31180800, mean_episode_return = None, mean_episode_step = 2456.0, total_loss = 192.11, pg_loss = 163.72, baseline_loss = 43.24, entropy_loss = -14.85, learner_queue_size = 64, _tick = 4678, _time = 1.6548e+09)
[2022-06-09 16:27:51,590][root][INFO] - Step 31196160 @ 3069.5 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 1.0034e+04, step = 31196160, mean_episode_return = 59.509, mean_episode_step = 2037.2, total_loss = -22.193, pg_loss = -23.331, baseline_loss = 15.765, entropy_loss = -14.627, learner_queue_size = 64, _tick = 4681, _time = 1.6548e+09)
[2022-06-09 16:27:56,594][root][INFO] - Step 31216640 @ 4092.8 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 1.004e+04, step = 31216640, mean_episode_return = None, mean_episode_step = 2003.9, total_loss = -141.16, pg_loss = -133.8, baseline_loss = 7.38, entropy_loss = -14.734, learner_queue_size = 64, _tick = 4684, _time = 1.6548e+09)
[2022-06-09 16:28:01,598][root][INFO] - Step 31232000 @ 3069.5 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1.0044e+04, step = 31232000, mean_episode_return = 51.327, mean_episode_step = 1724.5, total_loss = -108.33, pg_loss = -134.96, baseline_loss = 41.331, entropy_loss = -14.698, learner_queue_size = 64, _tick = 4687, _time = 1.6548e+09)
[2022-06-09 16:28:06,602][root][INFO] - Step 31247360 @ 3069.5 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.005e+04, step = 31247360, mean_episode_return = 186.63, mean_episode_step = 2067.4, total_loss = 84.896, pg_loss = 72.789, baseline_loss = 26.776, entropy_loss = -14.668, learner_queue_size = 64, _tick = 4690, _time = 1.6548e+09)
[2022-06-09 16:28:11,606][root][INFO] - Step 31262720 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.0054e+04, step = 31262720, mean_episode_return = 32.98, mean_episode_step = 1952.5, total_loss = -49.473, pg_loss = -50.335, baseline_loss = 15.648, entropy_loss = -14.786, learner_queue_size = 64, _tick = 4693, _time = 1.6548e+09)
[2022-06-09 16:28:16,610][root][INFO] - Step 31278080 @ 3069.6 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 1.006e+04, step = 31278080, mean_episode_return = -1.9907, mean_episode_step = 2160.8, total_loss = -22.397, pg_loss = -47.177, baseline_loss = 39.667, entropy_loss = -14.888, learner_queue_size = 64, _tick = 4694, _time = 1.6548e+09)
[2022-06-09 16:28:21,614][root][INFO] - Step 31298560 @ 4092.7 SPS. Inference batcher size: 72. Learner queue size: 64. Other stats: (train_seconds = 1.0064e+04, step = 31298560, mean_episode_return = None, mean_episode_step = 2111.0, total_loss = 452.53, pg_loss = 377.31, baseline_loss = 90.057, entropy_loss = -14.843, learner_queue_size = 64, _tick = 4696, _time = 1.6548e+09)
[2022-06-09 16:28:26,618][root][INFO] - Step 31313920 @ 3069.5 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 1.007e+04, step = 31313920, mean_episode_return = 40.169, mean_episode_step = 2163.2, total_loss = -44.563, pg_loss = -49.717, baseline_loss = 20.179, entropy_loss = -15.025, learner_queue_size = 64, _tick = 4699, _time = 1.6548e+09)
[2022-06-09 16:28:31,622][root][INFO] - Step 31329280 @ 3069.6 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 1.0075e+04, step = 31329280, mean_episode_return = 77.218, mean_episode_step = 1620.4, total_loss = 266.85, pg_loss = 241.4, baseline_loss = 40.683, entropy_loss = -15.239, learner_queue_size = 64, _tick = 4702, _time = 1.6548e+09)
[2022-06-09 16:28:36,626][root][INFO] - Step 31344640 @ 3069.5 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.008e+04, step = 31344640, mean_episode_return = 52.978, mean_episode_step = 2093.1, total_loss = -322.48, pg_loss = -313.85, baseline_loss = 6.665, entropy_loss = -15.3, learner_queue_size = 64, _tick = 4704, _time = 1.6548e+09)
[2022-06-09 16:28:41,630][root][INFO] - Step 31360000 @ 3069.5 SPS. Inference batcher size: 14. Learner queue size: 64. Other stats: (train_seconds = 1.0085e+04, step = 31360000, mean_episode_return = 96.779, mean_episode_step = 2356.9, total_loss = -164.67, pg_loss = -155.04, baseline_loss = 5.8112, entropy_loss = -15.44, learner_queue_size = 64, _tick = 4706, _time = 1.6548e+09)
[2022-06-09 16:28:46,634][root][INFO] - Step 31375360 @ 3069.6 SPS. Inference batcher size: 13. Learner queue size: 64. Other stats: (train_seconds = 1.009e+04, step = 31375360, mean_episode_return = 36.872, mean_episode_step = 2152.6, total_loss = -114.59, pg_loss = -114.19, baseline_loss = 15.022, entropy_loss = -15.42, learner_queue_size = 64, _tick = 4707, _time = 1.6548e+09)
[2022-06-09 16:28:51,638][root][INFO] - Step 31395840 @ 4092.7 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 1.0095e+04, step = 31395840, mean_episode_return = 53.36, mean_episode_step = 2145.3, total_loss = -147.24, pg_loss = -150.57, baseline_loss = 18.603, entropy_loss = -15.273, learner_queue_size = 64, _tick = 4711, _time = 1.6548e+09)
[2022-06-09 16:28:56,642][root][INFO] - Step 31411200 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.01e+04, step = 31411200, mean_episode_return = -4.49, mean_episode_step = 2433.5, total_loss = 64.648, pg_loss = 48.214, baseline_loss = 31.583, entropy_loss = -15.149, learner_queue_size = 64, _tick = 4714, _time = 1.6548e+09)
[2022-06-09 16:29:01,646][root][INFO] - Step 31426560 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.0105e+04, step = 31426560, mean_episode_return = 68.161, mean_episode_step = 2032.2, total_loss = -259.32, pg_loss = -250.71, baseline_loss = 6.4192, entropy_loss = -15.028, learner_queue_size = 64, _tick = 4717, _time = 1.6548e+09)
[2022-06-09 16:29:06,650][root][INFO] - Step 31441920 @ 3069.5 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 1.011e+04, step = 31441920, mean_episode_return = 18.16, mean_episode_step = 2063.2, total_loss = 263.7, pg_loss = 237.36, baseline_loss = 41.237, entropy_loss = -14.896, learner_queue_size = 64, _tick = 4720, _time = 1.6548e+09)
[2022-06-09 16:29:11,656][root][INFO] - Step 31462400 @ 4092.8 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.0115e+04, step = 31462400, mean_episode_return = None, mean_episode_step = 2333.1, total_loss = -92.264, pg_loss = -89.836, baseline_loss = 12.715, entropy_loss = -15.143, learner_queue_size = 64, _tick = 4722, _time = 1.6548e+09)
[2022-06-09 16:29:16,658][root][INFO] - Step 31477760 @ 3069.5 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 1.012e+04, step = 31477760, mean_episode_return = 10.56, mean_episode_step = 2167.0, total_loss = 204.98, pg_loss = 180.16, baseline_loss = 40.057, entropy_loss = -15.239, learner_queue_size = 64, _tick = 4724, _time = 1.6548e+09)
[2022-06-09 16:29:21,662][root][INFO] - Step 31493120 @ 3069.6 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.0125e+04, step = 31493120, mean_episode_return = 33.372, mean_episode_step = 1956.9, total_loss = 69.146, pg_loss = 43.449, baseline_loss = 40.873, entropy_loss = -15.176, learner_queue_size = 64, _tick = 4727, _time = 1.6548e+09)
[2022-06-09 16:29:26,666][root][INFO] - Step 31508480 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.013e+04, step = 31508480, mean_episode_return = 60.331, mean_episode_step = 2176.6, total_loss = 136.89, pg_loss = 125.22, baseline_loss = 26.947, entropy_loss = -15.277, learner_queue_size = 64, _tick = 4729, _time = 1.6548e+09)
[2022-06-09 16:29:31,670][root][INFO] - Step 31523840 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.0135e+04, step = 31523840, mean_episode_return = 41.073, mean_episode_step = 2333.3, total_loss = -261.62, pg_loss = -261.0, baseline_loss = 14.59, entropy_loss = -15.211, learner_queue_size = 64, _tick = 4732, _time = 1.6548e+09)
[2022-06-09 16:29:36,674][root][INFO] - Step 31544320 @ 4092.7 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.014e+04, step = 31544320, mean_episode_return = None, mean_episode_step = 1892.3, total_loss = 131.74, pg_loss = 118.01, baseline_loss = 28.69, entropy_loss = -14.957, learner_queue_size = 64, _tick = 4735, _time = 1.6548e+09)
[2022-06-09 16:29:41,678][root][INFO] - Step 31559680 @ 3069.5 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.0145e+04, step = 31559680, mean_episode_return = None, mean_episode_step = 1934.3, total_loss = -47.178, pg_loss = -44.111, baseline_loss = 11.77, entropy_loss = -14.837, learner_queue_size = 64, _tick = 4737, _time = 1.6548e+09)
[2022-06-09 16:29:46,682][root][INFO] - Step 31575040 @ 3069.6 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.015e+04, step = 31575040, mean_episode_return = None, mean_episode_step = 2181.2, total_loss = 27.871, pg_loss = 25.736, baseline_loss = 16.913, entropy_loss = -14.778, learner_queue_size = 64, _tick = 4739, _time = 1.6548e+09)
[2022-06-09 16:29:51,686][root][INFO] - Step 31590400 @ 3069.4 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1.0155e+04, step = 31590400, mean_episode_return = 106.1, mean_episode_step = 2004.1, total_loss = -246.52, pg_loss = -235.69, baseline_loss = 4.0075, entropy_loss = -14.84, learner_queue_size = 64, _tick = 4742, _time = 1.6548e+09)
[2022-06-09 16:29:56,690][root][INFO] - Step 31610880 @ 4092.9 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.016e+04, step = 31610880, mean_episode_return = 15.43, mean_episode_step = 2110.0, total_loss = -122.88, pg_loss = -119.24, baseline_loss = 11.356, entropy_loss = -15.002, learner_queue_size = 64, _tick = 4745, _time = 1.6548e+09)
[2022-06-09 16:30:01,694][root][INFO] - Step 31621120 @ 2046.3 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1.0165e+04, step = 31621120, mean_episode_return = 136.55, mean_episode_step = 2226.2, total_loss = 61.816, pg_loss = 46.844, baseline_loss = 29.921, entropy_loss = -14.948, learner_queue_size = 64, _tick = 4746, _time = 1.6548e+09)
[2022-06-09 16:30:06,698][root][INFO] - Step 31641600 @ 4092.7 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.017e+04, step = 31641600, mean_episode_return = 27.283, mean_episode_step = 2088.4, total_loss = 139.67, pg_loss = 117.01, baseline_loss = 37.602, entropy_loss = -14.939, learner_queue_size = 64, _tick = 4749, _time = 1.6548e+09)
[2022-06-09 16:30:11,702][root][INFO] - Step 31656960 @ 3069.5 SPS. Inference batcher size: 71. Learner queue size: 64. Other stats: (train_seconds = 1.0175e+04, step = 31656960, mean_episode_return = 46.202, mean_episode_step = 2082.7, total_loss = 72.179, pg_loss = 66.894, baseline_loss = 20.203, entropy_loss = -14.918, learner_queue_size = 64, _tick = 4752, _time = 1.6548e+09)
[2022-06-09 16:30:16,706][root][INFO] - Step 31672320 @ 3069.6 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 1.018e+04, step = 31672320, mean_episode_return = 169.22, mean_episode_step = 2104.3, total_loss = -78.518, pg_loss = -77.34, baseline_loss = 13.875, entropy_loss = -15.053, learner_queue_size = 64, _tick = 4755, _time = 1.6548e+09)
[2022-06-09 16:30:21,710][root][INFO] - Step 31687680 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.0185e+04, step = 31687680, mean_episode_return = 49.793, mean_episode_step = 2299.9, total_loss = -24.448, pg_loss = -34.972, baseline_loss = 25.653, entropy_loss = -15.13, learner_queue_size = 64, _tick = 4758, _time = 1.6548e+09)
[2022-06-09 16:30:26,714][root][INFO] - Step 31703040 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.019e+04, step = 31703040, mean_episode_return = 77.933, mean_episode_step = 2095.9, total_loss = 912.76, pg_loss = 633.61, baseline_loss = 294.32, entropy_loss = -15.169, learner_queue_size = 64, _tick = 4761, _time = 1.6548e+09)
[2022-06-09 16:30:31,718][root][INFO] - Step 31723520 @ 4092.6 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 1.0195e+04, step = 31723520, mean_episode_return = 3.4895, mean_episode_step = 2020.5, total_loss = 13.768, pg_loss = 14.419, baseline_loss = 14.158, entropy_loss = -14.809, learner_queue_size = 64, _tick = 4765, _time = 1.6548e+09)
[2022-06-09 16:30:36,722][root][INFO] - Step 31738880 @ 3069.6 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 1.02e+04, step = 31738880, mean_episode_return = 101.25, mean_episode_step = 1948.8, total_loss = 600.26, pg_loss = 344.51, baseline_loss = 270.77, entropy_loss = -15.025, learner_queue_size = 64, _tick = 4768, _time = 1.6548e+09)
[2022-06-09 16:30:41,726][root][INFO] - Step 31754240 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.0205e+04, step = 31754240, mean_episode_return = -21.049, mean_episode_step = 1874.3, total_loss = -65.875, pg_loss = -74.582, baseline_loss = 23.483, entropy_loss = -14.777, learner_queue_size = 64, _tick = 4771, _time = 1.6548e+09)
[2022-06-09 16:30:46,730][root][INFO] - Step 31774720 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.021e+04, step = 31774720, mean_episode_return = 8.386, mean_episode_step = 1905.4, total_loss = 6.9877, pg_loss = -1.6033, baseline_loss = 23.42, entropy_loss = -14.829, learner_queue_size = 64, _tick = 4775, _time = 1.6548e+09)
[2022-06-09 16:30:51,734][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 16:30:51,927][root][INFO] - Step 31790080 @ 3069.5 SPS. Inference batcher size: 14. Learner queue size: 64. Other stats: (train_seconds = 1.0215e+04, step = 31790080, mean_episode_return = -22.78, mean_episode_step = 1882.9, total_loss = -7.432, pg_loss = -9.9174, baseline_loss = 17.28, entropy_loss = -14.795, learner_queue_size = 64, _tick = 4777, _time = 1.6548e+09)
[2022-06-09 16:30:56,930][root][INFO] - Step 31805440 @ 2956.2 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.022e+04, step = 31805440, mean_episode_return = None, mean_episode_step = 1779.7, total_loss = -131.7, pg_loss = -122.97, baseline_loss = 6.0222, entropy_loss = -14.746, learner_queue_size = 64, _tick = 4778, _time = 1.6548e+09)
[2022-06-09 16:31:01,934][root][INFO] - Step 31820800 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.0225e+04, step = 31820800, mean_episode_return = 73.993, mean_episode_step = 1749.3, total_loss = 20.786, pg_loss = 14.682, baseline_loss = 20.856, entropy_loss = -14.751, learner_queue_size = 64, _tick = 4781, _time = 1.6548e+09)
[2022-06-09 16:31:06,938][root][INFO] - Step 31836160 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.023e+04, step = 31836160, mean_episode_return = 83.073, mean_episode_step = 1963.6, total_loss = -70.449, pg_loss = -69.429, baseline_loss = 13.8, entropy_loss = -14.82, learner_queue_size = 64, _tick = 4784, _time = 1.6548e+09)
[2022-06-09 16:31:11,942][root][INFO] - Step 31856640 @ 4092.7 SPS. Inference batcher size: 15. Learner queue size: 64. Other stats: (train_seconds = 1.0235e+04, step = 31856640, mean_episode_return = None, mean_episode_step = 1997.0, total_loss = 57.048, pg_loss = 48.88, baseline_loss = 22.973, entropy_loss = -14.804, learner_queue_size = 64, _tick = 4786, _time = 1.6548e+09)
[2022-06-09 16:31:16,946][root][INFO] - Step 31872000 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.024e+04, step = 31872000, mean_episode_return = 53.353, mean_episode_step = 1943.5, total_loss = -46.657, pg_loss = -49.221, baseline_loss = 17.478, entropy_loss = -14.914, learner_queue_size = 64, _tick = 4789, _time = 1.6548e+09)
[2022-06-09 16:31:21,950][root][INFO] - Step 31887360 @ 3069.6 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.0245e+04, step = 31887360, mean_episode_return = None, mean_episode_step = 2318.0, total_loss = -173.09, pg_loss = -162.51, baseline_loss = 4.2756, entropy_loss = -14.856, learner_queue_size = 64, _tick = 4791, _time = 1.6548e+09)
[2022-06-09 16:31:26,954][root][INFO] - Step 31902720 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.025e+04, step = 31902720, mean_episode_return = None, mean_episode_step = 2183.1, total_loss = 186.57, pg_loss = 146.76, baseline_loss = 54.599, entropy_loss = -14.782, learner_queue_size = 64, _tick = 4792, _time = 1.6548e+09)
[2022-06-09 16:31:31,960][root][INFO] - Step 31923200 @ 4091.3 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 1.0255e+04, step = 31923200, mean_episode_return = 16.64, mean_episode_step = 1989.4, total_loss = -124.29, pg_loss = -120.05, baseline_loss = 10.558, entropy_loss = -14.795, learner_queue_size = 64, _tick = 4796, _time = 1.6548e+09)
[2022-06-09 16:31:36,962][root][INFO] - Step 31938560 @ 3070.6 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 1.026e+04, step = 31938560, mean_episode_return = 15.259, mean_episode_step = 2132.8, total_loss = -118.95, pg_loss = -116.55, baseline_loss = 12.497, entropy_loss = -14.896, learner_queue_size = 64, _tick = 4799, _time = 1.6548e+09)
[2022-06-09 16:31:41,966][root][INFO] - Step 31953920 @ 3069.4 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 1.0265e+04, step = 31953920, mean_episode_return = 78.522, mean_episode_step = 1958.9, total_loss = -108.21, pg_loss = -108.02, baseline_loss = 14.543, entropy_loss = -14.736, learner_queue_size = 64, _tick = 4801, _time = 1.6548e+09)
[2022-06-09 16:31:46,970][root][INFO] - Step 31969280 @ 3069.7 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.027e+04, step = 31969280, mean_episode_return = 52.518, mean_episode_step = 2006.1, total_loss = -209.48, pg_loss = -200.7, baseline_loss = 6.0749, entropy_loss = -14.855, learner_queue_size = 64, _tick = 4803, _time = 1.6548e+09)
[2022-06-09 16:31:51,974][root][INFO] - Step 31984640 @ 3069.5 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 1.0275e+04, step = 31984640, mean_episode_return = 17.45, mean_episode_step = 2018.1, total_loss = 425.25, pg_loss = 353.71, baseline_loss = 86.312, entropy_loss = -14.773, learner_queue_size = 64, _tick = 4806, _time = 1.6548e+09)
[2022-06-09 16:31:56,978][root][INFO] - Step 32005120 @ 4092.7 SPS. Inference batcher size: 74. Learner queue size: 64. Other stats: (train_seconds = 1.028e+04, step = 32005120, mean_episode_return = None, mean_episode_step = 1961.7, total_loss = 201.13, pg_loss = 174.28, baseline_loss = 41.546, entropy_loss = -14.693, learner_queue_size = 64, _tick = 4809, _time = 1.6548e+09)
[2022-06-09 16:32:01,982][root][INFO] - Step 32020480 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.0285e+04, step = 32020480, mean_episode_return = 55.975, mean_episode_step = 1513.4, total_loss = 231.2, pg_loss = 203.83, baseline_loss = 42.077, entropy_loss = -14.713, learner_queue_size = 64, _tick = 4812, _time = 1.6548e+09)
[2022-06-09 16:32:06,986][root][INFO] - Step 32035840 @ 3069.6 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 1.029e+04, step = 32035840, mean_episode_return = 19.136, mean_episode_step = 1814.4, total_loss = 79.375, pg_loss = 59.73, baseline_loss = 34.361, entropy_loss = -14.717, learner_queue_size = 64, _tick = 4815, _time = 1.6548e+09)
[2022-06-09 16:32:11,990][root][INFO] - Step 32051200 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.0295e+04, step = 32051200, mean_episode_return = 10.19, mean_episode_step = 1802.1, total_loss = 186.36, pg_loss = 166.93, baseline_loss = 34.156, entropy_loss = -14.724, learner_queue_size = 64, _tick = 4818, _time = 1.6548e+09)
[2022-06-09 16:32:16,994][root][INFO] - Step 32066560 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.03e+04, step = 32066560, mean_episode_return = 50.888, mean_episode_step = 1920.9, total_loss = 371.49, pg_loss = 303.24, baseline_loss = 82.885, entropy_loss = -14.64, learner_queue_size = 64, _tick = 4821, _time = 1.6548e+09)
[2022-06-09 16:32:21,998][root][INFO] - Step 32087040 @ 4092.7 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.0305e+04, step = 32087040, mean_episode_return = None, mean_episode_step = 2072.0, total_loss = -70.724, pg_loss = -73.737, baseline_loss = 17.404, entropy_loss = -14.39, learner_queue_size = 64, _tick = 4823, _time = 1.6548e+09)
[2022-06-09 16:32:27,002][root][INFO] - Step 32102400 @ 3069.5 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 1.031e+04, step = 32102400, mean_episode_return = 89.269, mean_episode_step = 1893.0, total_loss = -115.01, pg_loss = -117.22, baseline_loss = 16.716, entropy_loss = -14.497, learner_queue_size = 64, _tick = 4825, _time = 1.6548e+09)
[2022-06-09 16:32:32,006][root][INFO] - Step 32117760 @ 3069.6 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.0315e+04, step = 32117760, mean_episode_return = 59.91, mean_episode_step = 1747.5, total_loss = 54.814, pg_loss = 44.416, baseline_loss = 25.097, entropy_loss = -14.699, learner_queue_size = 64, _tick = 4828, _time = 1.6548e+09)
[2022-06-09 16:32:37,012][root][INFO] - Step 32133120 @ 3068.5 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 1.032e+04, step = 32133120, mean_episode_return = 42.977, mean_episode_step = 2135.3, total_loss = -10.045, pg_loss = -25.131, baseline_loss = 29.836, entropy_loss = -14.75, learner_queue_size = 64, _tick = 4830, _time = 1.6548e+09)
[2022-06-09 16:32:42,017][root][INFO] - Step 32153600 @ 4091.3 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.0325e+04, step = 32153600, mean_episode_return = -15.28, mean_episode_step = 1793.0, total_loss = 214.66, pg_loss = 196.92, baseline_loss = 32.751, entropy_loss = -15.005, learner_queue_size = 64, _tick = 4834, _time = 1.6548e+09)
[2022-06-09 16:32:47,022][root][INFO] - Step 32168960 @ 3069.1 SPS. Inference batcher size: 71. Learner queue size: 64. Other stats: (train_seconds = 1.033e+04, step = 32168960, mean_episode_return = 112.43, mean_episode_step = 1735.7, total_loss = 16.448, pg_loss = 5.9402, baseline_loss = 25.677, entropy_loss = -15.168, learner_queue_size = 64, _tick = 4837, _time = 1.6548e+09)
[2022-06-09 16:32:52,026][root][INFO] - Step 32184320 @ 3069.5 SPS. Inference batcher size: 15. Learner queue size: 64. Other stats: (train_seconds = 1.0335e+04, step = 32184320, mean_episode_return = None, mean_episode_step = 1842.3, total_loss = 82.226, pg_loss = 70.452, baseline_loss = 26.836, entropy_loss = -15.062, learner_queue_size = 64, _tick = 4839, _time = 1.6548e+09)
[2022-06-09 16:32:57,030][root][INFO] - Step 32199680 @ 3069.6 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.034e+04, step = 32199680, mean_episode_return = 20.09, mean_episode_step = 1637.0, total_loss = 73.115, pg_loss = 56.315, baseline_loss = 31.744, entropy_loss = -14.944, learner_queue_size = 64, _tick = 4842, _time = 1.6548e+09)
[2022-06-09 16:33:02,034][root][INFO] - Step 32215040 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.0345e+04, step = 32215040, mean_episode_return = 77.681, mean_episode_step = 1717.0, total_loss = 114.93, pg_loss = 89.447, baseline_loss = 40.559, entropy_loss = -15.079, learner_queue_size = 64, _tick = 4845, _time = 1.6548e+09)
[2022-06-09 16:33:07,038][root][INFO] - Step 32235520 @ 4092.8 SPS. Inference batcher size: 6. Learner queue size: 64. Other stats: (train_seconds = 1.035e+04, step = 32235520, mean_episode_return = 57.465, mean_episode_step = 1785.1, total_loss = 202.67, pg_loss = 179.16, baseline_loss = 38.492, entropy_loss = -14.983, learner_queue_size = 64, _tick = 4849, _time = 1.6548e+09)
[2022-06-09 16:33:12,042][root][INFO] - Step 32250880 @ 3069.4 SPS. Inference batcher size: 9. Learner queue size: 64. Other stats: (train_seconds = 1.0355e+04, step = 32250880, mean_episode_return = 30.22, mean_episode_step = 1852.7, total_loss = 21.88, pg_loss = 2.0404, baseline_loss = 34.752, entropy_loss = -14.912, learner_queue_size = 64, _tick = 4852, _time = 1.6548e+09)
[2022-06-09 16:33:17,046][root][INFO] - Step 32266240 @ 3069.6 SPS. Inference batcher size: 14. Learner queue size: 64. Other stats: (train_seconds = 1.036e+04, step = 32266240, mean_episode_return = -12.41, mean_episode_step = 1753.0, total_loss = -154.93, pg_loss = -175.76, baseline_loss = 35.687, entropy_loss = -14.85, learner_queue_size = 64, _tick = 4855, _time = 1.6548e+09)
[2022-06-09 16:33:22,050][root][INFO] - Step 32281600 @ 3069.6 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.0365e+04, step = 32281600, mean_episode_return = None, mean_episode_step = 1874.8, total_loss = -46.531, pg_loss = -51.794, baseline_loss = 20.289, entropy_loss = -15.026, learner_queue_size = 64, _tick = 4857, _time = 1.6548e+09)
[2022-06-09 16:33:27,054][root][INFO] - Step 32296960 @ 3069.5 SPS. Inference batcher size: 12. Learner queue size: 64. Other stats: (train_seconds = 1.037e+04, step = 32296960, mean_episode_return = 93.0, mean_episode_step = 1900.4, total_loss = -47.346, pg_loss = -52.216, baseline_loss = 19.876, entropy_loss = -15.005, learner_queue_size = 64, _tick = 4860, _time = 1.6548e+09)
[2022-06-09 16:33:32,058][root][INFO] - Step 32317440 @ 4092.6 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.0375e+04, step = 32317440, mean_episode_return = 61.978, mean_episode_step = 1813.8, total_loss = 30.629, pg_loss = 22.186, baseline_loss = 23.267, entropy_loss = -14.824, learner_queue_size = 64, _tick = 4864, _time = 1.6548e+09)
[2022-06-09 16:33:37,062][root][INFO] - Step 32332800 @ 3069.6 SPS. Inference batcher size: 87. Learner queue size: 64. Other stats: (train_seconds = 1.038e+04, step = 32332800, mean_episode_return = 39.564, mean_episode_step = 2074.8, total_loss = -263.55, pg_loss = -263.12, baseline_loss = 14.17, entropy_loss = -14.598, learner_queue_size = 64, _tick = 4866, _time = 1.6548e+09)
[2022-06-09 16:33:42,066][root][INFO] - Step 32348160 @ 3069.6 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 1.0385e+04, step = 32348160, mean_episode_return = -10.331, mean_episode_step = 1803.5, total_loss = 36.667, pg_loss = 18.699, baseline_loss = 32.515, entropy_loss = -14.548, learner_queue_size = 64, _tick = 4869, _time = 1.6548e+09)
[2022-06-09 16:33:47,070][root][INFO] - Step 32363520 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.039e+04, step = 32363520, mean_episode_return = -3.1011, mean_episode_step = 2118.4, total_loss = 128.47, pg_loss = 99.823, baseline_loss = 43.26, entropy_loss = -14.614, learner_queue_size = 64, _tick = 4871, _time = 1.6548e+09)
[2022-06-09 16:33:52,074][root][INFO] - Step 32378880 @ 3069.6 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1.0395e+04, step = 32378880, mean_episode_return = 18.91, mean_episode_step = 2077.7, total_loss = -25.988, pg_loss = -33.542, baseline_loss = 22.046, entropy_loss = -14.491, learner_queue_size = 64, _tick = 4874, _time = 1.6548e+09)
[2022-06-09 16:33:57,078][root][INFO] - Step 32399360 @ 4092.7 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 1.04e+04, step = 32399360, mean_episode_return = 47.552, mean_episode_step = 1732.6, total_loss = 320.02, pg_loss = 269.72, baseline_loss = 65.11, entropy_loss = -14.812, learner_queue_size = 64, _tick = 4877, _time = 1.6548e+09)
[2022-06-09 16:34:02,082][root][INFO] - Step 32414720 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.0405e+04, step = 32414720, mean_episode_return = 39.394, mean_episode_step = 1840.3, total_loss = -9.9519, pg_loss = -18.342, baseline_loss = 23.261, entropy_loss = -14.871, learner_queue_size = 64, _tick = 4880, _time = 1.6548e+09)
[2022-06-09 16:34:07,086][root][INFO] - Step 32430080 @ 3069.5 SPS. Inference batcher size: 18. Learner queue size: 64. Other stats: (train_seconds = 1.041e+04, step = 32430080, mean_episode_return = None, mean_episode_step = 1923.7, total_loss = 49.992, pg_loss = 44.249, baseline_loss = 20.605, entropy_loss = -14.862, learner_queue_size = 64, _tick = 4881, _time = 1.6548e+09)
[2022-06-09 16:34:12,090][root][INFO] - Step 32445440 @ 3069.6 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 1.0415e+04, step = 32445440, mean_episode_return = -33.13, mean_episode_step = 1931.5, total_loss = -20.552, pg_loss = -32.204, baseline_loss = 26.46, entropy_loss = -14.808, learner_queue_size = 64, _tick = 4884, _time = 1.6548e+09)
[2022-06-09 16:34:17,094][root][INFO] - Step 32460800 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.042e+04, step = 32460800, mean_episode_return = 83.289, mean_episode_step = 2101.1, total_loss = -59.126, pg_loss = -66.453, baseline_loss = 22.024, entropy_loss = -14.697, learner_queue_size = 64, _tick = 4885, _time = 1.6548e+09)
[2022-06-09 16:34:22,098][root][INFO] - Step 32481280 @ 4092.7 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 1.0425e+04, step = 32481280, mean_episode_return = 41.025, mean_episode_step = 1706.1, total_loss = -45.967, pg_loss = -60.409, baseline_loss = 29.005, entropy_loss = -14.563, learner_queue_size = 64, _tick = 4889, _time = 1.6548e+09)
[2022-06-09 16:34:27,102][root][INFO] - Step 32496640 @ 3069.5 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 1.043e+04, step = 32496640, mean_episode_return = 26.085, mean_episode_step = 2115.2, total_loss = -60.444, pg_loss = -70.278, baseline_loss = 24.564, entropy_loss = -14.731, learner_queue_size = 64, _tick = 4891, _time = 1.6548e+09)
[2022-06-09 16:34:32,106][root][INFO] - Step 32512000 @ 3069.5 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1.0435e+04, step = 32512000, mean_episode_return = None, mean_episode_step = 1720.8, total_loss = 252.86, pg_loss = 211.26, baseline_loss = 56.064, entropy_loss = -14.467, learner_queue_size = 64, _tick = 4893, _time = 1.6548e+09)
[2022-06-09 16:34:37,110][root][INFO] - Step 32527360 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.044e+04, step = 32527360, mean_episode_return = None, mean_episode_step = 2125.4, total_loss = -142.36, pg_loss = -142.01, baseline_loss = 14.102, entropy_loss = -14.455, learner_queue_size = 64, _tick = 4895, _time = 1.6548e+09)
[2022-06-09 16:34:42,114][root][INFO] - Step 32547840 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.0445e+04, step = 32547840, mean_episode_return = -17.233, mean_episode_step = 2014.2, total_loss = -114.71, pg_loss = -126.19, baseline_loss = 25.817, entropy_loss = -14.333, learner_queue_size = 64, _tick = 4898, _time = 1.6548e+09)
[2022-06-09 16:34:47,118][root][INFO] - Step 32563200 @ 3069.6 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 1.045e+04, step = 32563200, mean_episode_return = 62.402, mean_episode_step = 2111.6, total_loss = -238.01, pg_loss = -233.64, baseline_loss = 9.8558, entropy_loss = -14.228, learner_queue_size = 64, _tick = 4900, _time = 1.6548e+09)
[2022-06-09 16:34:52,122][root][INFO] - Step 32578560 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.0455e+04, step = 32578560, mean_episode_return = None, mean_episode_step = 1894.2, total_loss = 127.48, pg_loss = 108.97, baseline_loss = 32.676, entropy_loss = -14.164, learner_queue_size = 64, _tick = 4902, _time = 1.6548e+09)
[2022-06-09 16:34:57,126][root][INFO] - Step 32593920 @ 3069.6 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.046e+04, step = 32593920, mean_episode_return = 45.24, mean_episode_step = 2203.2, total_loss = -129.54, pg_loss = -139.22, baseline_loss = 23.815, entropy_loss = -14.136, learner_queue_size = 64, _tick = 4905, _time = 1.6548e+09)
[2022-06-09 16:35:02,130][root][INFO] - Step 32614400 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 1.0465e+04, step = 32614400, mean_episode_return = 99.226, mean_episode_step = 1967.5, total_loss = -123.05, pg_loss = -119.11, baseline_loss = 10.085, entropy_loss = -14.031, learner_queue_size = 64, _tick = 4909, _time = 1.6548e+09)
[2022-06-09 16:35:07,134][root][INFO] - Step 32629760 @ 3069.5 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 1.047e+04, step = 32629760, mean_episode_return = 68.045, mean_episode_step = 2357.4, total_loss = 144.64, pg_loss = 101.54, baseline_loss = 57.257, entropy_loss = -14.152, learner_queue_size = 64, _tick = 4912, _time = 1.6548e+09)
[2022-06-09 16:35:12,138][root][INFO] - Step 32645120 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.0475e+04, step = 32645120, mean_episode_return = 34.567, mean_episode_step = 1973.4, total_loss = 244.64, pg_loss = 99.567, baseline_loss = 159.15, entropy_loss = -14.075, learner_queue_size = 64, _tick = 4914, _time = 1.6548e+09)
[2022-06-09 16:35:17,142][root][INFO] - Step 32660480 @ 3069.6 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.048e+04, step = 32660480, mean_episode_return = -6.2704, mean_episode_step = 1986.0, total_loss = -79.969, pg_loss = -91.895, baseline_loss = 26.202, entropy_loss = -14.276, learner_queue_size = 64, _tick = 4917, _time = 1.6548e+09)
[2022-06-09 16:35:22,146][root][INFO] - Step 32675840 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.0485e+04, step = 32675840, mean_episode_return = 28.518, mean_episode_step = 2023.5, total_loss = -29.488, pg_loss = -57.35, baseline_loss = 42.121, entropy_loss = -14.259, learner_queue_size = 64, _tick = 4920, _time = 1.6548e+09)
[2022-06-09 16:35:27,150][root][INFO] - Step 32691200 @ 3069.5 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.049e+04, step = 32691200, mean_episode_return = 15.504, mean_episode_step = 1809.2, total_loss = 130.59, pg_loss = 93.236, baseline_loss = 51.607, entropy_loss = -14.249, learner_queue_size = 64, _tick = 4923, _time = 1.6548e+09)
[2022-06-09 16:35:32,154][root][INFO] - Step 32711680 @ 4092.7 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 1.0495e+04, step = 32711680, mean_episode_return = 89.671, mean_episode_step = 2320.7, total_loss = 266.68, pg_loss = 209.46, baseline_loss = 71.375, entropy_loss = -14.154, learner_queue_size = 64, _tick = 4926, _time = 1.6548e+09)
[2022-06-09 16:35:37,158][root][INFO] - Step 32727040 @ 3069.6 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 1.05e+04, step = 32727040, mean_episode_return = 131.62, mean_episode_step = 1841.0, total_loss = 74.386, pg_loss = 49.076, baseline_loss = 39.455, entropy_loss = -14.144, learner_queue_size = 64, _tick = 4929, _time = 1.6548e+09)
[2022-06-09 16:35:42,162][root][INFO] - Step 32742400 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.0505e+04, step = 32742400, mean_episode_return = 26.27, mean_episode_step = 1804.2, total_loss = -120.21, pg_loss = -131.52, baseline_loss = 25.357, entropy_loss = -14.052, learner_queue_size = 64, _tick = 4931, _time = 1.6548e+09)
[2022-06-09 16:35:47,166][root][INFO] - Step 32757760 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.051e+04, step = 32757760, mean_episode_return = 56.354, mean_episode_step = 2392.0, total_loss = 133.69, pg_loss = 96.838, baseline_loss = 50.722, entropy_loss = -13.865, learner_queue_size = 64, _tick = 4934, _time = 1.6548e+09)
[2022-06-09 16:35:52,170][root][INFO] - Step 32773120 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.0515e+04, step = 32773120, mean_episode_return = 59.196, mean_episode_step = 1931.8, total_loss = -117.78, pg_loss = -136.47, baseline_loss = 32.605, entropy_loss = -13.912, learner_queue_size = 64, _tick = 4937, _time = 1.6548e+09)
[2022-06-09 16:35:57,174][root][INFO] - Step 32788480 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.052e+04, step = 32788480, mean_episode_return = 50.584, mean_episode_step = 1676.2, total_loss = -150.98, pg_loss = -154.81, baseline_loss = 17.639, entropy_loss = -13.804, learner_queue_size = 64, _tick = 4940, _time = 1.6548e+09)
[2022-06-09 16:36:02,180][root][INFO] - Step 32803840 @ 3068.3 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.0525e+04, step = 32803840, mean_episode_return = 16.454, mean_episode_step = 2000.3, total_loss = 31.419, pg_loss = 1.6486, baseline_loss = 43.554, entropy_loss = -13.783, learner_queue_size = 64, _tick = 4943, _time = 1.6548e+09)
[2022-06-09 16:36:07,182][root][INFO] - Step 32819200 @ 3070.7 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.053e+04, step = 32819200, mean_episode_return = -17.381, mean_episode_step = 1963.4, total_loss = 63.744, pg_loss = 56.306, baseline_loss = 21.564, entropy_loss = -14.126, learner_queue_size = 64, _tick = 4946, _time = 1.6548e+09)
[2022-06-09 16:36:12,186][root][INFO] - Step 32839680 @ 4092.8 SPS. Inference batcher size: 12. Learner queue size: 64. Other stats: (train_seconds = 1.0535e+04, step = 32839680, mean_episode_return = 20.26, mean_episode_step = 1848.7, total_loss = 45.045, pg_loss = 23.327, baseline_loss = 35.771, entropy_loss = -14.052, learner_queue_size = 64, _tick = 4950, _time = 1.6548e+09)
[2022-06-09 16:36:17,190][root][INFO] - Step 32855040 @ 3069.6 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 1.054e+04, step = 32855040, mean_episode_return = 57.015, mean_episode_step = 1909.2, total_loss = -15.356, pg_loss = -30.988, baseline_loss = 29.691, entropy_loss = -14.059, learner_queue_size = 64, _tick = 4952, _time = 1.6548e+09)
[2022-06-09 16:36:22,194][root][INFO] - Step 32870400 @ 3069.5 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 1.0545e+04, step = 32870400, mean_episode_return = 7.6693, mean_episode_step = 1892.8, total_loss = -129.38, pg_loss = -127.93, baseline_loss = 12.402, entropy_loss = -13.848, learner_queue_size = 64, _tick = 4955, _time = 1.6548e+09)
[2022-06-09 16:36:27,199][root][INFO] - Step 32885760 @ 3068.9 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.055e+04, step = 32885760, mean_episode_return = 72.159, mean_episode_step = 2127.0, total_loss = 13.338, pg_loss = -8.4814, baseline_loss = 35.78, entropy_loss = -13.961, learner_queue_size = 64, _tick = 4958, _time = 1.6548e+09)
[2022-06-09 16:36:32,202][root][INFO] - Step 32901120 @ 3070.2 SPS. Inference batcher size: 15. Learner queue size: 64. Other stats: (train_seconds = 1.0555e+04, step = 32901120, mean_episode_return = 13.763, mean_episode_step = 1999.2, total_loss = -67.335, pg_loss = -78.181, baseline_loss = 24.98, entropy_loss = -14.135, learner_queue_size = 64, _tick = 4961, _time = 1.6548e+09)
[2022-06-09 16:36:37,206][root][INFO] - Step 32916480 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.056e+04, step = 32916480, mean_episode_return = 18.843, mean_episode_step = 2094.9, total_loss = 55.393, pg_loss = 25.977, baseline_loss = 43.625, entropy_loss = -14.208, learner_queue_size = 64, _tick = 4963, _time = 1.6548e+09)
[2022-06-09 16:36:42,210][root][INFO] - Step 32931840 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.0565e+04, step = 32931840, mean_episode_return = 56.515, mean_episode_step = 2069.4, total_loss = -174.11, pg_loss = -171.01, baseline_loss = 11.15, entropy_loss = -14.242, learner_queue_size = 64, _tick = 4965, _time = 1.6548e+09)
[2022-06-09 16:36:47,214][root][INFO] - Step 32947200 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.057e+04, step = 32947200, mean_episode_return = 124.97, mean_episode_step = 1793.7, total_loss = -47.651, pg_loss = -49.182, baseline_loss = 15.674, entropy_loss = -14.143, learner_queue_size = 64, _tick = 4968, _time = 1.6548e+09)
[2022-06-09 16:36:52,218][root][INFO] - Step 32962560 @ 3069.6 SPS. Inference batcher size: 10. Learner queue size: 64. Other stats: (train_seconds = 1.0575e+04, step = 32962560, mean_episode_return = 116.31, mean_episode_step = 1771.2, total_loss = -120.84, pg_loss = -119.88, baseline_loss = 13.225, entropy_loss = -14.18, learner_queue_size = 64, _tick = 4971, _time = 1.6548e+09)
[2022-06-09 16:36:57,222][root][INFO] - Step 32977920 @ 3069.5 SPS. Inference batcher size: 7. Learner queue size: 64. Other stats: (train_seconds = 1.058e+04, step = 32977920, mean_episode_return = -27.071, mean_episode_step = 1881.4, total_loss = 187.95, pg_loss = 168.22, baseline_loss = 34.02, entropy_loss = -14.288, learner_queue_size = 64, _tick = 4974, _time = 1.6548e+09)
[2022-06-09 16:37:02,226][root][INFO] - Step 32993280 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.0585e+04, step = 32993280, mean_episode_return = None, mean_episode_step = 1634.5, total_loss = -13.901, pg_loss = -14.997, baseline_loss = 15.306, entropy_loss = -14.21, learner_queue_size = 64, _tick = 4976, _time = 1.6548e+09)
[2022-06-09 16:37:07,230][root][INFO] - Step 33008640 @ 3069.6 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 1.059e+04, step = 33008640, mean_episode_return = None, mean_episode_step = 1862.8, total_loss = 264.18, pg_loss = 233.16, baseline_loss = 45.094, entropy_loss = -14.081, learner_queue_size = 64, _tick = 4977, _time = 1.6548e+09)
[2022-06-09 16:37:12,234][root][INFO] - Step 33029120 @ 4092.7 SPS. Inference batcher size: 75. Learner queue size: 64. Other stats: (train_seconds = 1.0595e+04, step = 33029120, mean_episode_return = None, mean_episode_step = 1892.0, total_loss = 115.37, pg_loss = 103.56, baseline_loss = 25.514, entropy_loss = -13.704, learner_queue_size = 64, _tick = 4980, _time = 1.6548e+09)
[2022-06-09 16:37:17,238][root][INFO] - Step 33044480 @ 3069.6 SPS. Inference batcher size: 89. Learner queue size: 64. Other stats: (train_seconds = 1.06e+04, step = 33044480, mean_episode_return = None, mean_episode_step = 1806.9, total_loss = 74.497, pg_loss = 62.277, baseline_loss = 26.065, entropy_loss = -13.845, learner_queue_size = 64, _tick = 4982, _time = 1.6548e+09)
[2022-06-09 16:37:22,242][root][INFO] - Step 33059840 @ 3069.5 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 1.0605e+04, step = 33059840, mean_episode_return = 44.96, mean_episode_step = 1928.2, total_loss = -37.369, pg_loss = -40.372, baseline_loss = 16.889, entropy_loss = -13.886, learner_queue_size = 64, _tick = 4983, _time = 1.6548e+09)
[2022-06-09 16:37:27,253][root][INFO] - Step 33075200 @ 3065.3 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 1.061e+04, step = 33075200, mean_episode_return = 42.39, mean_episode_step = 2078.5, total_loss = -50.707, pg_loss = -76.6, baseline_loss = 39.745, entropy_loss = -13.853, learner_queue_size = 64, _tick = 4985, _time = 1.6548e+09)
[2022-06-09 16:37:32,258][root][INFO] - Step 33090560 @ 3068.9 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 1.0615e+04, step = 33090560, mean_episode_return = 30.3, mean_episode_step = 2239.3, total_loss = -98.08, pg_loss = -102.17, baseline_loss = 18.068, entropy_loss = -13.976, learner_queue_size = 64, _tick = 4988, _time = 1.6548e+09)
[2022-06-09 16:37:37,262][root][INFO] - Step 33105920 @ 3069.5 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.062e+04, step = 33105920, mean_episode_return = 1.4897, mean_episode_step = 1889.8, total_loss = -142.56, pg_loss = -135.17, baseline_loss = 6.5021, entropy_loss = -13.892, learner_queue_size = 64, _tick = 4991, _time = 1.6548e+09)
[2022-06-09 16:37:42,266][root][INFO] - Step 33121280 @ 3069.5 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.0625e+04, step = 33121280, mean_episode_return = 100.78, mean_episode_step = 1692.3, total_loss = -237.49, pg_loss = -229.36, baseline_loss = 5.6567, entropy_loss = -13.786, learner_queue_size = 64, _tick = 4994, _time = 1.6548e+09)
[2022-06-09 16:37:47,270][root][INFO] - Step 33141760 @ 4092.8 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.063e+04, step = 33141760, mean_episode_return = 59.639, mean_episode_step = 2073.0, total_loss = -9.9746, pg_loss = -36.993, baseline_loss = 40.644, entropy_loss = -13.626, learner_queue_size = 64, _tick = 4998, _time = 1.6548e+09)
[2022-06-09 16:37:52,274][root][INFO] - Step 33157120 @ 3069.5 SPS. Inference batcher size: 86. Learner queue size: 64. Other stats: (train_seconds = 1.0635e+04, step = 33157120, mean_episode_return = 11.76, mean_episode_step = 1986.5, total_loss = -50.705, pg_loss = -48.583, baseline_loss = 11.403, entropy_loss = -13.525, learner_queue_size = 64, _tick = 5000, _time = 1.6548e+09)
[2022-06-09 16:37:57,278][root][INFO] - Step 33172480 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.064e+04, step = 33172480, mean_episode_return = 9.2146, mean_episode_step = 1979.1, total_loss = 65.609, pg_loss = 40.662, baseline_loss = 38.723, entropy_loss = -13.775, learner_queue_size = 64, _tick = 5003, _time = 1.6548e+09)
[2022-06-09 16:38:02,282][root][INFO] - Step 33187840 @ 3069.5 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 1.0645e+04, step = 33187840, mean_episode_return = 23.5, mean_episode_step = 1890.5, total_loss = 64.851, pg_loss = 43.543, baseline_loss = 35.131, entropy_loss = -13.823, learner_queue_size = 64, _tick = 5006, _time = 1.6548e+09)
[2022-06-09 16:38:07,286][root][INFO] - Step 33203200 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.065e+04, step = 33203200, mean_episode_return = -44.259, mean_episode_step = 2099.3, total_loss = 71.309, pg_loss = 46.116, baseline_loss = 38.949, entropy_loss = -13.756, learner_queue_size = 64, _tick = 5008, _time = 1.6548e+09)
[2022-06-09 16:38:12,290][root][INFO] - Step 33218560 @ 3069.6 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.0655e+04, step = 33218560, mean_episode_return = 20.38, mean_episode_step = 1890.8, total_loss = 882.18, pg_loss = 760.0, baseline_loss = 135.92, entropy_loss = -13.737, learner_queue_size = 64, _tick = 5010, _time = 1.6548e+09)
[2022-06-09 16:38:17,294][root][INFO] - Step 33233920 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.066e+04, step = 33233920, mean_episode_return = 73.059, mean_episode_step = 1893.7, total_loss = 1.9677, pg_loss = -4.1989, baseline_loss = 20.145, entropy_loss = -13.978, learner_queue_size = 64, _tick = 5013, _time = 1.6548e+09)
[2022-06-09 16:38:22,298][root][INFO] - Step 33254400 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 1.0665e+04, step = 33254400, mean_episode_return = 33.877, mean_episode_step = 2022.2, total_loss = 90.98, pg_loss = 69.093, baseline_loss = 35.59, entropy_loss = -13.703, learner_queue_size = 64, _tick = 5017, _time = 1.6548e+09)
[2022-06-09 16:38:27,302][root][INFO] - Step 33269760 @ 3069.6 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 1.067e+04, step = 33269760, mean_episode_return = 58.351, mean_episode_step = 1989.7, total_loss = 107.29, pg_loss = 93.988, baseline_loss = 27.096, entropy_loss = -13.793, learner_queue_size = 64, _tick = 5020, _time = 1.6548e+09)
[2022-06-09 16:38:32,306][root][INFO] - Step 33285120 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.0675e+04, step = 33285120, mean_episode_return = None, mean_episode_step = 2133.0, total_loss = -63.869, pg_loss = -65.63, baseline_loss = 15.579, entropy_loss = -13.819, learner_queue_size = 64, _tick = 5022, _time = 1.6548e+09)
[2022-06-09 16:38:37,310][root][INFO] - Step 33300480 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.068e+04, step = 33300480, mean_episode_return = None, mean_episode_step = 1801.6, total_loss = -134.4, pg_loss = -130.82, baseline_loss = 10.277, entropy_loss = -13.86, learner_queue_size = 64, _tick = 5023, _time = 1.6548e+09)
[2022-06-09 16:38:42,314][root][INFO] - Step 33315840 @ 3069.6 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.0685e+04, step = 33315840, mean_episode_return = None, mean_episode_step = 1939.5, total_loss = -39.041, pg_loss = -39.81, baseline_loss = 14.59, entropy_loss = -13.821, learner_queue_size = 64, _tick = 5025, _time = 1.6548e+09)
[2022-06-09 16:38:47,318][root][INFO] - Step 33331200 @ 3069.6 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1.069e+04, step = 33331200, mean_episode_return = None, mean_episode_step = 1969.8, total_loss = -117.62, pg_loss = -109.43, baseline_loss = 5.7331, entropy_loss = -13.921, learner_queue_size = 64, _tick = 5025, _time = 1.6548e+09)
[2022-06-09 16:38:52,322][root][INFO] - Step 33346560 @ 3069.5 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.0695e+04, step = 33346560, mean_episode_return = 61.806, mean_episode_step = 2203.6, total_loss = -115.4, pg_loss = -114.24, baseline_loss = 12.715, entropy_loss = -13.874, learner_queue_size = 64, _tick = 5028, _time = 1.6548e+09)
[2022-06-09 16:38:57,326][root][INFO] - Step 33361920 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.07e+04, step = 33361920, mean_episode_return = 58.021, mean_episode_step = 1882.2, total_loss = 241.48, pg_loss = 214.06, baseline_loss = 41.363, entropy_loss = -13.942, learner_queue_size = 64, _tick = 5030, _time = 1.6548e+09)
[2022-06-09 16:39:02,330][root][INFO] - Step 33377280 @ 3069.6 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.0705e+04, step = 33377280, mean_episode_return = 50.419, mean_episode_step = 2322.4, total_loss = -116.53, pg_loss = -118.65, baseline_loss = 16.025, entropy_loss = -13.911, learner_queue_size = 64, _tick = 5033, _time = 1.6548e+09)
[2022-06-09 16:39:07,334][root][INFO] - Step 33392640 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.071e+04, step = 33392640, mean_episode_return = None, mean_episode_step = 1899.7, total_loss = -151.61, pg_loss = -142.95, baseline_loss = 5.2916, entropy_loss = -13.95, learner_queue_size = 64, _tick = 5034, _time = 1.6548e+09)
[2022-06-09 16:39:12,338][root][INFO] - Step 33408000 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.0715e+04, step = 33408000, mean_episode_return = 35.581, mean_episode_step = 1634.9, total_loss = 226.77, pg_loss = 193.04, baseline_loss = 47.733, entropy_loss = -14.002, learner_queue_size = 64, _tick = 5037, _time = 1.6548e+09)
[2022-06-09 16:39:17,342][root][INFO] - Step 33423360 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.072e+04, step = 33423360, mean_episode_return = 60.265, mean_episode_step = 1900.3, total_loss = -165.53, pg_loss = -163.0, baseline_loss = 11.374, entropy_loss = -13.907, learner_queue_size = 64, _tick = 5040, _time = 1.6548e+09)
[2022-06-09 16:39:22,346][root][INFO] - Step 33443840 @ 4092.8 SPS. Inference batcher size: 80. Learner queue size: 64. Other stats: (train_seconds = 1.0725e+04, step = 33443840, mean_episode_return = 37.943, mean_episode_step = 1975.9, total_loss = 13.734, pg_loss = -3.2759, baseline_loss = 30.794, entropy_loss = -13.784, learner_queue_size = 64, _tick = 5042, _time = 1.6548e+09)
[2022-06-09 16:39:27,350][root][INFO] - Step 33459200 @ 3069.5 SPS. Inference batcher size: 71. Learner queue size: 64. Other stats: (train_seconds = 1.073e+04, step = 33459200, mean_episode_return = 35.123, mean_episode_step = 1890.0, total_loss = -119.36, pg_loss = -115.98, baseline_loss = 10.475, entropy_loss = -13.856, learner_queue_size = 64, _tick = 5045, _time = 1.6548e+09)
[2022-06-09 16:39:32,356][root][INFO] - Step 33474560 @ 3068.3 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 1.0735e+04, step = 33474560, mean_episode_return = 82.698, mean_episode_step = 1734.6, total_loss = 274.53, pg_loss = 220.27, baseline_loss = 68.17, entropy_loss = -13.904, learner_queue_size = 64, _tick = 5048, _time = 1.6548e+09)
[2022-06-09 16:39:37,362][root][INFO] - Step 33489920 @ 3068.3 SPS. Inference batcher size: 9. Learner queue size: 64. Other stats: (train_seconds = 1.074e+04, step = 33489920, mean_episode_return = None, mean_episode_step = 2133.7, total_loss = -102.02, pg_loss = -98.718, baseline_loss = 10.553, entropy_loss = -13.851, learner_queue_size = 64, _tick = 5049, _time = 1.6548e+09)
[2022-06-09 16:39:42,366][root][INFO] - Step 33505280 @ 3069.6 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.0745e+04, step = 33505280, mean_episode_return = 51.624, mean_episode_step = 2197.3, total_loss = -78.078, pg_loss = -84.806, baseline_loss = 20.5, entropy_loss = -13.773, learner_queue_size = 64, _tick = 5052, _time = 1.6548e+09)
[2022-06-09 16:39:47,376][root][INFO] - Step 33520640 @ 3065.9 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 1.075e+04, step = 33520640, mean_episode_return = -60.626, mean_episode_step = 2030.8, total_loss = 199.13, pg_loss = 171.27, baseline_loss = 41.761, entropy_loss = -13.902, learner_queue_size = 64, _tick = 5055, _time = 1.6548e+09)
[2022-06-09 16:39:52,382][root][INFO] - Step 33536000 @ 3068.2 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.0755e+04, step = 33536000, mean_episode_return = 17.59, mean_episode_step = 2041.4, total_loss = 214.73, pg_loss = 178.38, baseline_loss = 50.179, entropy_loss = -13.828, learner_queue_size = 64, _tick = 5057, _time = 1.6548e+09)
[2022-06-09 16:39:57,386][root][INFO] - Step 33551360 @ 3069.6 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.076e+04, step = 33551360, mean_episode_return = 73.211, mean_episode_step = 2064.0, total_loss = -57.071, pg_loss = -76.905, baseline_loss = 33.609, entropy_loss = -13.774, learner_queue_size = 64, _tick = 5059, _time = 1.6548e+09)
[2022-06-09 16:40:02,392][root][INFO] - Step 33566720 @ 3068.3 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 1.0765e+04, step = 33566720, mean_episode_return = 46.124, mean_episode_step = 1931.3, total_loss = -76.845, pg_loss = -88.408, baseline_loss = 25.154, entropy_loss = -13.592, learner_queue_size = 64, _tick = 5062, _time = 1.6548e+09)
[2022-06-09 16:40:07,394][root][INFO] - Step 33582080 @ 3070.7 SPS. Inference batcher size: 18. Learner queue size: 64. Other stats: (train_seconds = 1.077e+04, step = 33582080, mean_episode_return = 111.91, mean_episode_step = 1958.6, total_loss = 23.405, pg_loss = 4.8301, baseline_loss = 32.116, entropy_loss = -13.541, learner_queue_size = 64, _tick = 5065, _time = 1.6548e+09)
[2022-06-09 16:40:12,399][root][INFO] - Step 33602560 @ 4092.1 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 1.0775e+04, step = 33602560, mean_episode_return = None, mean_episode_step = 2196.5, total_loss = 16.474, pg_loss = 5.0799, baseline_loss = 25.108, entropy_loss = -13.714, learner_queue_size = 64, _tick = 5067, _time = 1.6548e+09)
[2022-06-09 16:40:17,402][root][INFO] - Step 33617920 @ 3070.0 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 1.078e+04, step = 33617920, mean_episode_return = 62.445, mean_episode_step = 2057.2, total_loss = -137.3, pg_loss = -133.5, baseline_loss = 9.6165, entropy_loss = -13.42, learner_queue_size = 64, _tick = 5070, _time = 1.6548e+09)
[2022-06-09 16:40:22,406][root][INFO] - Step 33633280 @ 3069.6 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1.0785e+04, step = 33633280, mean_episode_return = 27.499, mean_episode_step = 1842.3, total_loss = 121.86, pg_loss = 84.591, baseline_loss = 50.72, entropy_loss = -13.454, learner_queue_size = 64, _tick = 5072, _time = 1.6548e+09)
[2022-06-09 16:40:27,410][root][INFO] - Step 33648640 @ 3069.4 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.079e+04, step = 33648640, mean_episode_return = 60.88, mean_episode_step = 2079.9, total_loss = 26.607, pg_loss = -1.8044, baseline_loss = 41.874, entropy_loss = -13.462, learner_queue_size = 64, _tick = 5074, _time = 1.6548e+09)
[2022-06-09 16:40:32,414][root][INFO] - Step 33664000 @ 3069.7 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 1.0795e+04, step = 33664000, mean_episode_return = 17.997, mean_episode_step = 2050.7, total_loss = -183.76, pg_loss = -180.04, baseline_loss = 9.9815, entropy_loss = -13.701, learner_queue_size = 64, _tick = 5077, _time = 1.6548e+09)
[2022-06-09 16:40:37,418][root][INFO] - Step 33679360 @ 3069.6 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.08e+04, step = 33679360, mean_episode_return = 48.182, mean_episode_step = 1972.7, total_loss = 76.128, pg_loss = 66.392, baseline_loss = 23.357, entropy_loss = -13.622, learner_queue_size = 64, _tick = 5080, _time = 1.6548e+09)
[2022-06-09 16:40:42,422][root][INFO] - Step 33699840 @ 4092.7 SPS. Inference batcher size: 102. Learner queue size: 64. Other stats: (train_seconds = 1.0805e+04, step = 33699840, mean_episode_return = 12.765, mean_episode_step = 2154.7, total_loss = 232.83, pg_loss = 206.47, baseline_loss = 39.873, entropy_loss = -13.508, learner_queue_size = 64, _tick = 5084, _time = 1.6548e+09)
[2022-06-09 16:40:47,426][root][INFO] - Step 33715200 @ 3069.5 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 1.081e+04, step = 33715200, mean_episode_return = 65.274, mean_episode_step = 1905.0, total_loss = 184.08, pg_loss = 148.05, baseline_loss = 49.485, entropy_loss = -13.449, learner_queue_size = 64, _tick = 5087, _time = 1.6548e+09)
[2022-06-09 16:40:52,430][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 16:40:52,650][root][INFO] - Step 33730560 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.0815e+04, step = 33730560, mean_episode_return = 72.515, mean_episode_step = 2234.1, total_loss = 159.52, pg_loss = 121.22, baseline_loss = 51.946, entropy_loss = -13.639, learner_queue_size = 64, _tick = 5090, _time = 1.6548e+09)
[2022-06-09 16:40:57,654][root][INFO] - Step 33745920 @ 2940.3 SPS. Inference batcher size: 82. Learner queue size: 64. Other stats: (train_seconds = 1.0821e+04, step = 33745920, mean_episode_return = 21.02, mean_episode_step = 2163.7, total_loss = -51.265, pg_loss = -69.049, baseline_loss = 31.378, entropy_loss = -13.594, learner_queue_size = 64, _tick = 5093, _time = 1.6548e+09)
[2022-06-09 16:41:02,658][root][INFO] - Step 33761280 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.0826e+04, step = 33761280, mean_episode_return = 122.67, mean_episode_step = 2246.1, total_loss = 17.801, pg_loss = -2.439, baseline_loss = 33.928, entropy_loss = -13.689, learner_queue_size = 64, _tick = 5096, _time = 1.6548e+09)
[2022-06-09 16:41:07,662][root][INFO] - Step 33776640 @ 3069.4 SPS. Inference batcher size: 2. Learner queue size: 64. Other stats: (train_seconds = 1.0831e+04, step = 33776640, mean_episode_return = 24.555, mean_episode_step = 2171.2, total_loss = -25.31, pg_loss = -47.637, baseline_loss = 35.848, entropy_loss = -13.521, learner_queue_size = 64, _tick = 5099, _time = 1.6548e+09)
[2022-06-09 16:41:12,666][root][INFO] - Step 33792000 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.0836e+04, step = 33792000, mean_episode_return = 33.443, mean_episode_step = 1975.2, total_loss = 263.08, pg_loss = 222.57, baseline_loss = 54.235, entropy_loss = -13.725, learner_queue_size = 64, _tick = 5102, _time = 1.6548e+09)
[2022-06-09 16:41:17,670][root][INFO] - Step 33807360 @ 3069.6 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 1.0841e+04, step = 33807360, mean_episode_return = 41.24, mean_episode_step = 2229.0, total_loss = -121.95, pg_loss = -122.62, baseline_loss = 14.421, entropy_loss = -13.746, learner_queue_size = 64, _tick = 5104, _time = 1.6548e+09)
[2022-06-09 16:41:22,674][root][INFO] - Step 33822720 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.0846e+04, step = 33822720, mean_episode_return = 53.516, mean_episode_step = 2532.6, total_loss = -83.6, pg_loss = -86.143, baseline_loss = 16.38, entropy_loss = -13.838, learner_queue_size = 64, _tick = 5106, _time = 1.6548e+09)
[2022-06-09 16:41:27,678][root][INFO] - Step 33838080 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.0851e+04, step = 33838080, mean_episode_return = 45.77, mean_episode_step = 1983.9, total_loss = -73.902, pg_loss = -94.401, baseline_loss = 34.237, entropy_loss = -13.738, learner_queue_size = 64, _tick = 5109, _time = 1.6548e+09)
[2022-06-09 16:41:32,682][root][INFO] - Step 33853440 @ 3069.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.0856e+04, step = 33853440, mean_episode_return = 55.736, mean_episode_step = 2017.0, total_loss = 19.515, pg_loss = 0.31653, baseline_loss = 32.815, entropy_loss = -13.616, learner_queue_size = 64, _tick = 5111, _time = 1.6548e+09)
[2022-06-09 16:41:37,686][root][INFO] - Step 33873920 @ 4092.7 SPS. Inference batcher size: 77. Learner queue size: 64. Other stats: (train_seconds = 1.0861e+04, step = 33873920, mean_episode_return = 8.1499, mean_episode_step = 2227.7, total_loss = -172.47, pg_loss = -168.34, baseline_loss = 9.6323, entropy_loss = -13.766, learner_queue_size = 64, _tick = 5115, _time = 1.6548e+09)
[2022-06-09 16:41:42,694][root][INFO] - Step 33889280 @ 3067.1 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.0866e+04, step = 33889280, mean_episode_return = None, mean_episode_step = 2417.7, total_loss = -138.28, pg_loss = -127.29, baseline_loss = 2.792, entropy_loss = -13.788, learner_queue_size = 64, _tick = 5117, _time = 1.6548e+09)
[2022-06-09 16:41:47,698][root][INFO] - Step 33904640 @ 3069.6 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 1.0871e+04, step = 33904640, mean_episode_return = 80.353, mean_episode_step = 2310.0, total_loss = -82.936, pg_loss = -86.12, baseline_loss = 17.136, entropy_loss = -13.951, learner_queue_size = 64, _tick = 5120, _time = 1.6548e+09)
[2022-06-09 16:41:52,702][root][INFO] - Step 33920000 @ 3069.5 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 1.0876e+04, step = 33920000, mean_episode_return = 18.66, mean_episode_step = 2140.5, total_loss = -84.277, pg_loss = -93.147, baseline_loss = 22.928, entropy_loss = -14.058, learner_queue_size = 64, _tick = 5122, _time = 1.6548e+09)
[2022-06-09 16:41:57,706][root][INFO] - Step 33935360 @ 3069.5 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 1.0881e+04, step = 33935360, mean_episode_return = 8.4399, mean_episode_step = 2199.7, total_loss = 109.08, pg_loss = 96.985, baseline_loss = 26.188, entropy_loss = -14.093, learner_queue_size = 64, _tick = 5125, _time = 1.6548e+09)
[2022-06-09 16:42:02,710][root][INFO] - Step 33950720 @ 3069.6 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 1.0886e+04, step = 33950720, mean_episode_return = 37.635, mean_episode_step = 2251.5, total_loss = -78.46, pg_loss = -86.914, baseline_loss = 22.514, entropy_loss = -14.059, learner_queue_size = 64, _tick = 5127, _time = 1.6548e+09)
[2022-06-09 16:42:07,716][root][INFO] - Step 33966080 @ 3068.3 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.0891e+04, step = 33966080, mean_episode_return = 25.064, mean_episode_step = 2548.7, total_loss = 298.71, pg_loss = 255.72, baseline_loss = 57.055, entropy_loss = -14.068, learner_queue_size = 64, _tick = 5130, _time = 1.6548e+09)
[2022-06-09 16:42:12,722][root][INFO] - Step 33981440 @ 3068.3 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.0896e+04, step = 33981440, mean_episode_return = 62.57, mean_episode_step = 2546.1, total_loss = -133.55, pg_loss = -132.71, baseline_loss = 13.166, entropy_loss = -13.998, learner_queue_size = 64, _tick = 5133, _time = 1.6548e+09)
[2022-06-09 16:42:17,726][root][INFO] - Step 33996800 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.0901e+04, step = 33996800, mean_episode_return = 19.821, mean_episode_step = 1986.9, total_loss = 191.93, pg_loss = 158.67, baseline_loss = 47.436, entropy_loss = -14.172, learner_queue_size = 64, _tick = 5136, _time = 1.6548e+09)
[2022-06-09 16:42:22,732][root][INFO] - Step 34012160 @ 3068.3 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.0906e+04, step = 34012160, mean_episode_return = 89.348, mean_episode_step = 2463.8, total_loss = -107.88, pg_loss = -118.35, baseline_loss = 24.514, entropy_loss = -14.044, learner_queue_size = 64, _tick = 5138, _time = 1.6548e+09)
[2022-06-09 16:42:27,738][root][INFO] - Step 34032640 @ 4091.2 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 1.0911e+04, step = 34032640, mean_episode_return = -12.31, mean_episode_step = 2287.0, total_loss = 60.573, pg_loss = 45.006, baseline_loss = 29.574, entropy_loss = -14.007, learner_queue_size = 64, _tick = 5142, _time = 1.6548e+09)
[2022-06-09 16:42:32,742][root][INFO] - Step 34048000 @ 3069.6 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 1.0916e+04, step = 34048000, mean_episode_return = 45.871, mean_episode_step = 2135.8, total_loss = -100.36, pg_loss = -99.169, baseline_loss = 12.747, entropy_loss = -13.939, learner_queue_size = 64, _tick = 5145, _time = 1.6548e+09)
[2022-06-09 16:42:37,746][root][INFO] - Step 34063360 @ 3069.4 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.0921e+04, step = 34063360, mean_episode_return = None, mean_episode_step = 1620.8, total_loss = -110.1, pg_loss = -106.76, baseline_loss = 10.587, entropy_loss = -13.933, learner_queue_size = 64, _tick = 5147, _time = 1.6548e+09)
[2022-06-09 16:42:42,750][root][INFO] - Step 34078720 @ 3069.7 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 1.0926e+04, step = 34078720, mean_episode_return = 65.925, mean_episode_step = 2243.2, total_loss = 423.57, pg_loss = 246.99, baseline_loss = 190.82, entropy_loss = -14.237, learner_queue_size = 64, _tick = 5150, _time = 1.6548e+09)
[2022-06-09 16:42:47,754][root][INFO] - Step 34094080 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.0931e+04, step = 34094080, mean_episode_return = None, mean_episode_step = 2164.9, total_loss = -20.688, pg_loss = -30.637, baseline_loss = 24.154, entropy_loss = -14.205, learner_queue_size = 64, _tick = 5152, _time = 1.6548e+09)
[2022-06-09 16:42:52,758][root][INFO] - Step 34109440 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 1.0936e+04, step = 34109440, mean_episode_return = 26.59, mean_episode_step = 2299.6, total_loss = -59.483, pg_loss = -66.198, baseline_loss = 20.823, entropy_loss = -14.108, learner_queue_size = 64, _tick = 5155, _time = 1.6548e+09)
[2022-06-09 16:42:57,762][root][INFO] - Step 34124800 @ 3069.5 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 1.0941e+04, step = 34124800, mean_episode_return = 17.02, mean_episode_step = 2327.5, total_loss = 74.255, pg_loss = 57.306, baseline_loss = 30.917, entropy_loss = -13.968, learner_queue_size = 64, _tick = 5158, _time = 1.6548e+09)
[2022-06-09 16:43:02,766][root][INFO] - Step 34140160 @ 3069.6 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 1.0946e+04, step = 34140160, mean_episode_return = None, mean_episode_step = 1854.5, total_loss = 208.93, pg_loss = 187.65, baseline_loss = 35.278, entropy_loss = -13.999, learner_queue_size = 64, _tick = 5160, _time = 1.6548e+09)
[2022-06-09 16:43:07,770][root][INFO] - Step 34155520 @ 3069.5 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 1.0951e+04, step = 34155520, mean_episode_return = 116.08, mean_episode_step = 1915.1, total_loss = 26.812, pg_loss = 19.822, baseline_loss = 21.137, entropy_loss = -14.147, learner_queue_size = 64, _tick = 5163, _time = 1.6548e+09)
[2022-06-09 16:43:12,774][root][INFO] - Step 34176000 @ 4092.8 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.0956e+04, step = 34176000, mean_episode_return = 125.96, mean_episode_step = 1963.7, total_loss = -2.4377, pg_loss = -10.349, baseline_loss = 21.988, entropy_loss = -14.077, learner_queue_size = 64, _tick = 5165, _time = 1.6548e+09)
[2022-06-09 16:43:17,778][root][INFO] - Step 34191360 @ 3069.5 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 1.0961e+04, step = 34191360, mean_episode_return = 96.141, mean_episode_step = 2236.7, total_loss = -26.53, pg_loss = -35.885, baseline_loss = 23.557, entropy_loss = -14.201, learner_queue_size = 64, _tick = 5168, _time = 1.6548e+09)
[2022-06-09 16:43:22,782][root][INFO] - Step 34206720 @ 3069.5 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1.0966e+04, step = 34206720, mean_episode_return = 52.825, mean_episode_step = 2018.6, total_loss = 98.262, pg_loss = 64.812, baseline_loss = 47.492, entropy_loss = -14.042, learner_queue_size = 64, _tick = 5171, _time = 1.6548e+09)
[2022-06-09 16:43:27,788][root][INFO] - Step 34222080 @ 3068.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.0971e+04, step = 34222080, mean_episode_return = 25.33, mean_episode_step = 2375.7, total_loss = 43.872, pg_loss = 36.104, baseline_loss = 21.921, entropy_loss = -14.153, learner_queue_size = 64, _tick = 5173, _time = 1.6548e+09)
[2022-06-09 16:43:32,790][root][INFO] - Step 34237440 @ 3070.6 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.0976e+04, step = 34237440, mean_episode_return = 43.292, mean_episode_step = 2105.0, total_loss = -84.993, pg_loss = -84.345, baseline_loss = 13.678, entropy_loss = -14.326, learner_queue_size = 64, _tick = 5175, _time = 1.6548e+09)
[2022-06-09 16:43:37,794][root][INFO] - Step 34252800 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.0981e+04, step = 34252800, mean_episode_return = 14.19, mean_episode_step = 2243.4, total_loss = -173.65, pg_loss = -167.0, baseline_loss = 7.6533, entropy_loss = -14.298, learner_queue_size = 64, _tick = 5178, _time = 1.6548e+09)
[2022-06-09 16:43:42,798][root][INFO] - Step 34268160 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.0986e+04, step = 34268160, mean_episode_return = 52.09, mean_episode_step = 1976.2, total_loss = 420.3, pg_loss = 279.52, baseline_loss = 154.94, entropy_loss = -14.161, learner_queue_size = 64, _tick = 5181, _time = 1.6548e+09)
[2022-06-09 16:43:47,802][root][INFO] - Step 34283520 @ 3069.6 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 1.0991e+04, step = 34283520, mean_episode_return = 9.1597, mean_episode_step = 1795.6, total_loss = 391.34, pg_loss = 342.93, baseline_loss = 62.627, entropy_loss = -14.215, learner_queue_size = 64, _tick = 5184, _time = 1.6548e+09)
[2022-06-09 16:43:52,806][root][INFO] - Step 34298880 @ 3069.6 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 1.0996e+04, step = 34298880, mean_episode_return = 9.4048, mean_episode_step = 1862.9, total_loss = -85.28, pg_loss = -91.791, baseline_loss = 20.724, entropy_loss = -14.213, learner_queue_size = 64, _tick = 5186, _time = 1.6548e+09)
[2022-06-09 16:43:57,810][root][INFO] - Step 34319360 @ 4092.6 SPS. Inference batcher size: 76. Learner queue size: 64. Other stats: (train_seconds = 1.1001e+04, step = 34319360, mean_episode_return = None, mean_episode_step = 2241.0, total_loss = 181.17, pg_loss = 160.75, baseline_loss = 34.691, entropy_loss = -14.27, learner_queue_size = 64, _tick = 5188, _time = 1.6548e+09)
[2022-06-09 16:44:02,814][root][INFO] - Step 34334720 @ 3069.6 SPS. Inference batcher size: 67. Learner queue size: 64. Other stats: (train_seconds = 1.1006e+04, step = 34334720, mean_episode_return = 62.48, mean_episode_step = 1894.3, total_loss = 239.66, pg_loss = 192.93, baseline_loss = 60.798, entropy_loss = -14.069, learner_queue_size = 64, _tick = 5189, _time = 1.6548e+09)
[2022-06-09 16:44:07,818][root][INFO] - Step 34350080 @ 3069.5 SPS. Inference batcher size: 71. Learner queue size: 64. Other stats: (train_seconds = 1.1011e+04, step = 34350080, mean_episode_return = None, mean_episode_step = 1947.6, total_loss = 53.578, pg_loss = 42.75, baseline_loss = 24.719, entropy_loss = -13.891, learner_queue_size = 64, _tick = 5191, _time = 1.6548e+09)
[2022-06-09 16:44:12,822][root][INFO] - Step 34365440 @ 3069.5 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 1.1016e+04, step = 34365440, mean_episode_return = 65.687, mean_episode_step = 2145.5, total_loss = -79.712, pg_loss = -86.939, baseline_loss = 21.157, entropy_loss = -13.93, learner_queue_size = 64, _tick = 5194, _time = 1.6548e+09)
[2022-06-09 16:44:17,826][root][INFO] - Step 34380800 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.1021e+04, step = 34380800, mean_episode_return = None, mean_episode_step = 2153.7, total_loss = -96.077, pg_loss = -96.411, baseline_loss = 14.173, entropy_loss = -13.838, learner_queue_size = 64, _tick = 5195, _time = 1.6548e+09)
[2022-06-09 16:44:22,830][root][INFO] - Step 34396160 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.1026e+04, step = 34396160, mean_episode_return = None, mean_episode_step = 2239.9, total_loss = 24.932, pg_loss = 15.155, baseline_loss = 23.737, entropy_loss = -13.96, learner_queue_size = 64, _tick = 5197, _time = 1.6548e+09)
[2022-06-09 16:44:27,836][root][INFO] - Step 34411520 @ 3068.4 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.1031e+04, step = 34411520, mean_episode_return = 39.189, mean_episode_step = 2090.0, total_loss = 101.37, pg_loss = 66.798, baseline_loss = 48.474, entropy_loss = -13.904, learner_queue_size = 64, _tick = 5199, _time = 1.6548e+09)
[2022-06-09 16:44:32,838][root][INFO] - Step 34432000 @ 4094.2 SPS. Inference batcher size: 75. Learner queue size: 64. Other stats: (train_seconds = 1.1036e+04, step = 34432000, mean_episode_return = 83.233, mean_episode_step = 1955.0, total_loss = -67.14, pg_loss = -79.613, baseline_loss = 26.329, entropy_loss = -13.856, learner_queue_size = 64, _tick = 5203, _time = 1.6548e+09)
[2022-06-09 16:44:37,842][root][INFO] - Step 34447360 @ 3069.5 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 1.1041e+04, step = 34447360, mean_episode_return = 24.52, mean_episode_step = 2303.1, total_loss = -253.82, pg_loss = -244.9, baseline_loss = 4.904, entropy_loss = -13.829, learner_queue_size = 64, _tick = 5206, _time = 1.6548e+09)
[2022-06-09 16:44:42,846][root][INFO] - Step 34462720 @ 3069.6 SPS. Inference batcher size: 89. Learner queue size: 64. Other stats: (train_seconds = 1.1046e+04, step = 34462720, mean_episode_return = 60.93, mean_episode_step = 1892.7, total_loss = -31.902, pg_loss = -52.107, baseline_loss = 34.016, entropy_loss = -13.811, learner_queue_size = 64, _tick = 5209, _time = 1.6548e+09)
[2022-06-09 16:44:47,850][root][INFO] - Step 34478080 @ 3069.6 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 1.1051e+04, step = 34478080, mean_episode_return = 75.862, mean_episode_step = 2131.9, total_loss = -91.0, pg_loss = -95.429, baseline_loss = 18.068, entropy_loss = -13.639, learner_queue_size = 64, _tick = 5212, _time = 1.6548e+09)
[2022-06-09 16:44:52,854][root][INFO] - Step 34493440 @ 3069.5 SPS. Inference batcher size: 7. Learner queue size: 64. Other stats: (train_seconds = 1.1056e+04, step = 34493440, mean_episode_return = 68.018, mean_episode_step = 2126.7, total_loss = -11.251, pg_loss = -23.972, baseline_loss = 26.393, entropy_loss = -13.672, learner_queue_size = 64, _tick = 5214, _time = 1.6548e+09)
[2022-06-09 16:44:57,858][root][INFO] - Step 34508800 @ 3069.6 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 1.1061e+04, step = 34508800, mean_episode_return = 52.852, mean_episode_step = 2151.4, total_loss = -78.327, pg_loss = -79.077, baseline_loss = 14.735, entropy_loss = -13.986, learner_queue_size = 64, _tick = 5216, _time = 1.6548e+09)
[2022-06-09 16:45:02,862][root][INFO] - Step 34524160 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.1066e+04, step = 34524160, mean_episode_return = None, mean_episode_step = 1962.3, total_loss = -107.53, pg_loss = -99.856, baseline_loss = 6.4288, entropy_loss = -14.103, learner_queue_size = 64, _tick = 5218, _time = 1.6548e+09)
[2022-06-09 16:45:07,866][root][INFO] - Step 34539520 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.1071e+04, step = 34539520, mean_episode_return = 36.911, mean_episode_step = 2196.2, total_loss = -35.414, pg_loss = -43.069, baseline_loss = 21.582, entropy_loss = -13.928, learner_queue_size = 64, _tick = 5221, _time = 1.6548e+09)
[2022-06-09 16:45:12,870][root][INFO] - Step 34554880 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.1076e+04, step = 34554880, mean_episode_return = 17.135, mean_episode_step = 1790.7, total_loss = -140.56, pg_loss = -137.06, baseline_loss = 10.631, entropy_loss = -14.132, learner_queue_size = 64, _tick = 5223, _time = 1.6548e+09)
[2022-06-09 16:45:17,874][root][INFO] - Step 34570240 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 1.1081e+04, step = 34570240, mean_episode_return = 29.553, mean_episode_step = 2246.7, total_loss = -75.33, pg_loss = -78.701, baseline_loss = 17.604, entropy_loss = -14.233, learner_queue_size = 64, _tick = 5224, _time = 1.6548e+09)
[2022-06-09 16:45:22,878][root][INFO] - Step 34590720 @ 4092.8 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.1086e+04, step = 34590720, mean_episode_return = 31.692, mean_episode_step = 2138.9, total_loss = 2.2737, pg_loss = -6.4094, baseline_loss = 23.06, entropy_loss = -14.377, learner_queue_size = 64, _tick = 5227, _time = 1.6548e+09)
[2022-06-09 16:45:27,882][root][INFO] - Step 34606080 @ 3069.6 SPS. Inference batcher size: 81. Learner queue size: 64. Other stats: (train_seconds = 1.1091e+04, step = 34606080, mean_episode_return = 24.555, mean_episode_step = 2085.1, total_loss = 29.504, pg_loss = 22.022, baseline_loss = 21.938, entropy_loss = -14.455, learner_queue_size = 64, _tick = 5229, _time = 1.6548e+09)
[2022-06-09 16:45:32,886][root][INFO] - Step 34621440 @ 3069.5 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 1.1096e+04, step = 34621440, mean_episode_return = None, mean_episode_step = 2343.7, total_loss = -200.43, pg_loss = -186.89, baseline_loss = 0.95373, entropy_loss = -14.489, learner_queue_size = 64, _tick = 5231, _time = 1.6548e+09)
[2022-06-09 16:45:37,890][root][INFO] - Step 34636800 @ 3069.6 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 1.1101e+04, step = 34636800, mean_episode_return = 21.481, mean_episode_step = 1872.8, total_loss = 70.421, pg_loss = 52.183, baseline_loss = 32.814, entropy_loss = -14.576, learner_queue_size = 64, _tick = 5233, _time = 1.6548e+09)
[2022-06-09 16:45:42,894][root][INFO] - Step 34652160 @ 3069.6 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 1.1106e+04, step = 34652160, mean_episode_return = 55.36, mean_episode_step = 1894.2, total_loss = 216.31, pg_loss = 194.56, baseline_loss = 36.277, entropy_loss = -14.526, learner_queue_size = 64, _tick = 5236, _time = 1.6548e+09)
[2022-06-09 16:45:47,898][root][INFO] - Step 34667520 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.1111e+04, step = 34667520, mean_episode_return = 72.244, mean_episode_step = 2313.6, total_loss = 244.83, pg_loss = 216.6, baseline_loss = 42.728, entropy_loss = -14.491, learner_queue_size = 64, _tick = 5239, _time = 1.6548e+09)
[2022-06-09 16:45:52,902][root][INFO] - Step 34682880 @ 3069.5 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.1116e+04, step = 34682880, mean_episode_return = 54.775, mean_episode_step = 2230.1, total_loss = 84.217, pg_loss = 71.487, baseline_loss = 27.235, entropy_loss = -14.505, learner_queue_size = 64, _tick = 5242, _time = 1.6548e+09)
[2022-06-09 16:45:57,906][root][INFO] - Step 34698240 @ 3069.6 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.1121e+04, step = 34698240, mean_episode_return = 39.781, mean_episode_step = 2224.8, total_loss = 73.24, pg_loss = 72.265, baseline_loss = 15.547, entropy_loss = -14.571, learner_queue_size = 64, _tick = 5245, _time = 1.6548e+09)
[2022-06-09 16:46:02,910][root][INFO] - Step 34713600 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.1126e+04, step = 34713600, mean_episode_return = 57.501, mean_episode_step = 2439.9, total_loss = -182.73, pg_loss = -187.1, baseline_loss = 18.768, entropy_loss = -14.396, learner_queue_size = 64, _tick = 5247, _time = 1.6548e+09)
[2022-06-09 16:46:07,916][root][INFO] - Step 34728960 @ 3068.2 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.1131e+04, step = 34728960, mean_episode_return = 38.34, mean_episode_step = 2072.6, total_loss = 312.59, pg_loss = 264.82, baseline_loss = 62.085, entropy_loss = -14.308, learner_queue_size = 64, _tick = 5250, _time = 1.6548e+09)
[2022-06-09 16:46:12,922][root][INFO] - Step 34749440 @ 4091.3 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.1136e+04, step = 34749440, mean_episode_return = 23.92, mean_episode_step = 2239.0, total_loss = 73.714, pg_loss = 53.59, baseline_loss = 34.432, entropy_loss = -14.307, learner_queue_size = 64, _tick = 5253, _time = 1.6548e+09)
[2022-06-09 16:46:17,926][root][INFO] - Step 34764800 @ 3069.5 SPS. Inference batcher size: 71. Learner queue size: 64. Other stats: (train_seconds = 1.1141e+04, step = 34764800, mean_episode_return = -12.433, mean_episode_step = 2060.1, total_loss = -21.109, pg_loss = -35.325, baseline_loss = 28.406, entropy_loss = -14.19, learner_queue_size = 64, _tick = 5256, _time = 1.6548e+09)
[2022-06-09 16:46:22,930][root][INFO] - Step 34780160 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.1146e+04, step = 34780160, mean_episode_return = 108.66, mean_episode_step = 2322.9, total_loss = 32.847, pg_loss = 22.141, baseline_loss = 25.023, entropy_loss = -14.316, learner_queue_size = 64, _tick = 5259, _time = 1.6548e+09)
[2022-06-09 16:46:27,934][root][INFO] - Step 34795520 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.1151e+04, step = 34795520, mean_episode_return = None, mean_episode_step = 2227.5, total_loss = -156.48, pg_loss = -148.39, baseline_loss = 6.1878, entropy_loss = -14.278, learner_queue_size = 64, _tick = 5261, _time = 1.6548e+09)
[2022-06-09 16:46:32,938][root][INFO] - Step 34810880 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.1156e+04, step = 34810880, mean_episode_return = 36.281, mean_episode_step = 1819.4, total_loss = 57.383, pg_loss = 48.212, baseline_loss = 23.583, entropy_loss = -14.412, learner_queue_size = 64, _tick = 5263, _time = 1.6548e+09)
[2022-06-09 16:46:37,942][root][INFO] - Step 34826240 @ 3069.5 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.1161e+04, step = 34826240, mean_episode_return = 13.281, mean_episode_step = 2136.5, total_loss = 14.094, pg_loss = -8.2502, baseline_loss = 36.7, entropy_loss = -14.356, learner_queue_size = 64, _tick = 5264, _time = 1.6548e+09)
[2022-06-09 16:46:42,946][root][INFO] - Step 34841600 @ 3069.6 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 1.1166e+04, step = 34841600, mean_episode_return = 60.69, mean_episode_step = 2198.0, total_loss = -150.65, pg_loss = -146.44, baseline_loss = 9.9703, entropy_loss = -14.181, learner_queue_size = 64, _tick = 5266, _time = 1.6548e+09)
[2022-06-09 16:46:47,950][root][INFO] - Step 34856960 @ 3069.5 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 1.1171e+04, step = 34856960, mean_episode_return = 54.882, mean_episode_step = 1980.4, total_loss = 221.39, pg_loss = 186.6, baseline_loss = 48.984, entropy_loss = -14.193, learner_queue_size = 64, _tick = 5268, _time = 1.6548e+09)
[2022-06-09 16:46:52,954][root][INFO] - Step 34877440 @ 4092.7 SPS. Inference batcher size: 71. Learner queue size: 64. Other stats: (train_seconds = 1.1176e+04, step = 34877440, mean_episode_return = None, mean_episode_step = 2174.1, total_loss = 134.05, pg_loss = 122.11, baseline_loss = 25.987, entropy_loss = -14.043, learner_queue_size = 64, _tick = 5271, _time = 1.6548e+09)
[2022-06-09 16:46:57,958][root][INFO] - Step 34892800 @ 3069.5 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 1.1181e+04, step = 34892800, mean_episode_return = 43.135, mean_episode_step = 2064.4, total_loss = 74.536, pg_loss = 53.216, baseline_loss = 35.464, entropy_loss = -14.144, learner_queue_size = 64, _tick = 5272, _time = 1.6548e+09)
[2022-06-09 16:47:02,962][root][INFO] - Step 34908160 @ 3069.6 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 1.1186e+04, step = 34908160, mean_episode_return = 67.998, mean_episode_step = 2315.9, total_loss = 60.769, pg_loss = 51.239, baseline_loss = 23.655, entropy_loss = -14.125, learner_queue_size = 64, _tick = 5275, _time = 1.6548e+09)
[2022-06-09 16:47:07,966][root][INFO] - Step 34923520 @ 3069.5 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.1191e+04, step = 34923520, mean_episode_return = 47.161, mean_episode_step = 2151.8, total_loss = -30.41, pg_loss = -38.247, baseline_loss = 21.798, entropy_loss = -13.961, learner_queue_size = 64, _tick = 5278, _time = 1.6548e+09)
[2022-06-09 16:47:12,970][root][INFO] - Step 34938880 @ 3069.3 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.1196e+04, step = 34938880, mean_episode_return = 17.89, mean_episode_step = 2209.1, total_loss = -35.015, pg_loss = -40.403, baseline_loss = 19.458, entropy_loss = -14.07, learner_queue_size = 64, _tick = 5280, _time = 1.6548e+09)
[2022-06-09 16:47:17,974][root][INFO] - Step 34954240 @ 3069.9 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.1201e+04, step = 34954240, mean_episode_return = 65.5, mean_episode_step = 2400.7, total_loss = -3.3067, pg_loss = -8.9243, baseline_loss = 19.921, entropy_loss = -14.303, learner_queue_size = 64, _tick = 5283, _time = 1.6548e+09)
[2022-06-09 16:47:22,978][root][INFO] - Step 34969600 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.1206e+04, step = 34969600, mean_episode_return = 29.993, mean_episode_step = 2199.7, total_loss = -3.168, pg_loss = -28.61, baseline_loss = 39.849, entropy_loss = -14.407, learner_queue_size = 64, _tick = 5286, _time = 1.6548e+09)
[2022-06-09 16:47:27,982][root][INFO] - Step 34984960 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.1211e+04, step = 34984960, mean_episode_return = None, mean_episode_step = 2277.4, total_loss = -24.16, pg_loss = -25.069, baseline_loss = 15.227, entropy_loss = -14.317, learner_queue_size = 64, _tick = 5287, _time = 1.6548e+09)
[2022-06-09 16:47:32,986][root][INFO] - Step 35000320 @ 3069.5 SPS. Inference batcher size: 15. Learner queue size: 64. Other stats: (train_seconds = 1.1216e+04, step = 35000320, mean_episode_return = 8.7609, mean_episode_step = 2418.0, total_loss = -130.33, pg_loss = -123.71, baseline_loss = 7.4564, entropy_loss = -14.081, learner_queue_size = 64, _tick = 5290, _time = 1.6548e+09)
[2022-06-09 16:47:37,993][root][INFO] - Step 35015680 @ 3067.6 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 1.1221e+04, step = 35015680, mean_episode_return = 14.766, mean_episode_step = 2032.2, total_loss = 99.913, pg_loss = 78.399, baseline_loss = 35.536, entropy_loss = -14.022, learner_queue_size = 64, _tick = 5293, _time = 1.6548e+09)
[2022-06-09 16:47:42,998][root][INFO] - Step 35036160 @ 4092.1 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 1.1226e+04, step = 35036160, mean_episode_return = None, mean_episode_step = 2158.5, total_loss = -9.2817, pg_loss = -13.557, baseline_loss = 18.239, entropy_loss = -13.964, learner_queue_size = 64, _tick = 5296, _time = 1.6548e+09)
[2022-06-09 16:47:48,002][root][INFO] - Step 35051520 @ 3069.5 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 1.1231e+04, step = 35051520, mean_episode_return = 49.716, mean_episode_step = 1879.7, total_loss = -55.501, pg_loss = -59.964, baseline_loss = 18.381, entropy_loss = -13.918, learner_queue_size = 64, _tick = 5299, _time = 1.6548e+09)
[2022-06-09 16:47:53,006][root][INFO] - Step 35066880 @ 3069.5 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 1.1236e+04, step = 35066880, mean_episode_return = None, mean_episode_step = 2318.4, total_loss = 138.56, pg_loss = 113.55, baseline_loss = 39.138, entropy_loss = -14.137, learner_queue_size = 64, _tick = 5300, _time = 1.6548e+09)
[2022-06-09 16:47:58,010][root][INFO] - Step 35082240 @ 3069.7 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1.1241e+04, step = 35082240, mean_episode_return = 43.28, mean_episode_step = 2305.4, total_loss = -14.769, pg_loss = -34.383, baseline_loss = 33.68, entropy_loss = -14.066, learner_queue_size = 64, _tick = 5303, _time = 1.6548e+09)
[2022-06-09 16:48:03,014][root][INFO] - Step 35097600 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.1246e+04, step = 35097600, mean_episode_return = 29.837, mean_episode_step = 2551.4, total_loss = -33.067, pg_loss = -37.738, baseline_loss = 18.616, entropy_loss = -13.945, learner_queue_size = 64, _tick = 5304, _time = 1.6548e+09)
[2022-06-09 16:48:08,020][root][INFO] - Step 35112960 @ 3068.3 SPS. Inference batcher size: 9. Learner queue size: 64. Other stats: (train_seconds = 1.1251e+04, step = 35112960, mean_episode_return = None, mean_episode_step = 2264.0, total_loss = 168.11, pg_loss = 147.66, baseline_loss = 34.413, entropy_loss = -13.964, learner_queue_size = 64, _tick = 5306, _time = 1.6548e+09)
[2022-06-09 16:48:13,026][root][INFO] - Step 35128320 @ 3068.3 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.1256e+04, step = 35128320, mean_episode_return = 110.4, mean_episode_step = 2554.4, total_loss = 74.638, pg_loss = 54.389, baseline_loss = 34.184, entropy_loss = -13.935, learner_queue_size = 64, _tick = 5308, _time = 1.6548e+09)
[2022-06-09 16:48:18,030][root][INFO] - Step 35148800 @ 4092.6 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1.1261e+04, step = 35148800, mean_episode_return = 89.914, mean_episode_step = 2334.7, total_loss = -83.915, pg_loss = -87.594, baseline_loss = 17.594, entropy_loss = -13.915, learner_queue_size = 64, _tick = 5311, _time = 1.6548e+09)
[2022-06-09 16:48:23,034][root][INFO] - Step 35164160 @ 3069.6 SPS. Inference batcher size: 79. Learner queue size: 64. Other stats: (train_seconds = 1.1266e+04, step = 35164160, mean_episode_return = -1.23, mean_episode_step = 2028.6, total_loss = -11.382, pg_loss = -11.87, baseline_loss = 14.44, entropy_loss = -13.952, learner_queue_size = 64, _tick = 5314, _time = 1.6548e+09)
[2022-06-09 16:48:28,038][root][INFO] - Step 35179520 @ 3069.6 SPS. Inference batcher size: 78. Learner queue size: 64. Other stats: (train_seconds = 1.1271e+04, step = 35179520, mean_episode_return = 27.921, mean_episode_step = 2503.4, total_loss = -71.927, pg_loss = -68.043, baseline_loss = 10.111, entropy_loss = -13.995, learner_queue_size = 64, _tick = 5317, _time = 1.6548e+09)
[2022-06-09 16:48:33,042][root][INFO] - Step 35194880 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.1276e+04, step = 35194880, mean_episode_return = 5.0152, mean_episode_step = 1977.5, total_loss = 16.704, pg_loss = 13.143, baseline_loss = 17.777, entropy_loss = -14.215, learner_queue_size = 64, _tick = 5320, _time = 1.6548e+09)
[2022-06-09 16:48:38,046][root][INFO] - Step 35210240 @ 3069.5 SPS. Inference batcher size: 18. Learner queue size: 64. Other stats: (train_seconds = 1.1281e+04, step = 35210240, mean_episode_return = 58.261, mean_episode_step = 2242.8, total_loss = -80.082, pg_loss = -76.253, baseline_loss = 10.355, entropy_loss = -14.184, learner_queue_size = 64, _tick = 5323, _time = 1.6548e+09)
[2022-06-09 16:48:43,050][root][INFO] - Step 35225600 @ 3069.5 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 1.1286e+04, step = 35225600, mean_episode_return = 49.646, mean_episode_step = 2854.1, total_loss = 24.483, pg_loss = 19.03, baseline_loss = 19.725, entropy_loss = -14.272, learner_queue_size = 64, _tick = 5326, _time = 1.6548e+09)
[2022-06-09 16:48:48,054][root][INFO] - Step 35240960 @ 3069.6 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.1291e+04, step = 35240960, mean_episode_return = 44.539, mean_episode_step = 2225.7, total_loss = -26.159, pg_loss = -33.044, baseline_loss = 21.224, entropy_loss = -14.339, learner_queue_size = 64, _tick = 5329, _time = 1.6548e+09)
[2022-06-09 16:48:53,058][root][INFO] - Step 35256320 @ 3069.6 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 1.1296e+04, step = 35256320, mean_episode_return = 65.51, mean_episode_step = 2394.8, total_loss = -13.574, pg_loss = -16.676, baseline_loss = 17.457, entropy_loss = -14.355, learner_queue_size = 64, _tick = 5331, _time = 1.6548e+09)
[2022-06-09 16:48:58,062][root][INFO] - Step 35276800 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.1301e+04, step = 35276800, mean_episode_return = 9.4499, mean_episode_step = 2556.8, total_loss = -79.887, pg_loss = -74.494, baseline_loss = 9.1056, entropy_loss = -14.499, learner_queue_size = 64, _tick = 5334, _time = 1.6548e+09)
[2022-06-09 16:49:03,066][root][INFO] - Step 35292160 @ 3069.5 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 1.1306e+04, step = 35292160, mean_episode_return = 85.06, mean_episode_step = 2487.5, total_loss = -123.96, pg_loss = -114.04, baseline_loss = 4.7426, entropy_loss = -14.671, learner_queue_size = 64, _tick = 5337, _time = 1.6548e+09)
[2022-06-09 16:49:08,070][root][INFO] - Step 35307520 @ 3069.5 SPS. Inference batcher size: 78. Learner queue size: 64. Other stats: (train_seconds = 1.1311e+04, step = 35307520, mean_episode_return = 21.35, mean_episode_step = 2261.1, total_loss = -1.3653, pg_loss = -7.1321, baseline_loss = 20.344, entropy_loss = -14.577, learner_queue_size = 64, _tick = 5340, _time = 1.6548e+09)
[2022-06-09 16:49:13,076][root][INFO] - Step 35322880 @ 3068.2 SPS. Inference batcher size: 4. Learner queue size: 64. Other stats: (train_seconds = 1.1316e+04, step = 35322880, mean_episode_return = 61.603, mean_episode_step = 2550.4, total_loss = -132.06, pg_loss = -126.24, baseline_loss = 8.8391, entropy_loss = -14.662, learner_queue_size = 64, _tick = 5343, _time = 1.6548e+09)
[2022-06-09 16:49:18,082][root][INFO] - Step 35338240 @ 3068.5 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 1.1321e+04, step = 35338240, mean_episode_return = 39.983, mean_episode_step = 2138.6, total_loss = 215.59, pg_loss = 195.29, baseline_loss = 35.184, entropy_loss = -14.878, learner_queue_size = 64, _tick = 5346, _time = 1.6548e+09)
[2022-06-09 16:49:23,086][root][INFO] - Step 35353600 @ 3069.5 SPS. Inference batcher size: 10. Learner queue size: 64. Other stats: (train_seconds = 1.1326e+04, step = 35353600, mean_episode_return = 4.5195, mean_episode_step = 2235.2, total_loss = 55.027, pg_loss = 52.074, baseline_loss = 17.577, entropy_loss = -14.624, learner_queue_size = 64, _tick = 5349, _time = 1.6548e+09)
[2022-06-09 16:49:28,092][root][INFO] - Step 35368960 @ 3068.5 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 1.1331e+04, step = 35368960, mean_episode_return = 44.831, mean_episode_step = 2608.4, total_loss = 240.73, pg_loss = 208.83, baseline_loss = 46.606, entropy_loss = -14.706, learner_queue_size = 64, _tick = 5352, _time = 1.6548e+09)
[2022-06-09 16:49:33,094][root][INFO] - Step 35384320 @ 3070.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.1336e+04, step = 35384320, mean_episode_return = 51.716, mean_episode_step = 2403.9, total_loss = 124.19, pg_loss = 110.3, baseline_loss = 28.611, entropy_loss = -14.713, learner_queue_size = 64, _tick = 5355, _time = 1.6548e+09)
[2022-06-09 16:49:38,098][root][INFO] - Step 35399680 @ 3069.6 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.1341e+04, step = 35399680, mean_episode_return = -7.3321, mean_episode_step = 2341.0, total_loss = 63.134, pg_loss = 43.089, baseline_loss = 34.657, entropy_loss = -14.612, learner_queue_size = 64, _tick = 5358, _time = 1.6548e+09)
[2022-06-09 16:49:43,102][root][INFO] - Step 35420160 @ 4092.8 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 1.1346e+04, step = 35420160, mean_episode_return = 26.136, mean_episode_step = 1878.1, total_loss = -28.205, pg_loss = -33.534, baseline_loss = 20.014, entropy_loss = -14.685, learner_queue_size = 64, _tick = 5362, _time = 1.6548e+09)
[2022-06-09 16:49:48,106][root][INFO] - Step 35435520 @ 3069.5 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 1.1351e+04, step = 35435520, mean_episode_return = 35.372, mean_episode_step = 2197.2, total_loss = 151.26, pg_loss = 138.85, baseline_loss = 27.235, entropy_loss = -14.825, learner_queue_size = 64, _tick = 5365, _time = 1.6548e+09)
[2022-06-09 16:49:53,110][root][INFO] - Step 35450880 @ 3069.5 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 1.1356e+04, step = 35450880, mean_episode_return = -18.416, mean_episode_step = 2157.6, total_loss = 104.51, pg_loss = 92.649, baseline_loss = 26.951, entropy_loss = -15.089, learner_queue_size = 64, _tick = 5366, _time = 1.6548e+09)
[2022-06-09 16:49:58,114][root][INFO] - Step 35466240 @ 3069.5 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 1.1361e+04, step = 35466240, mean_episode_return = -38.059, mean_episode_step = 2321.2, total_loss = -54.689, pg_loss = -51.752, baseline_loss = 11.977, entropy_loss = -14.914, learner_queue_size = 64, _tick = 5369, _time = 1.6548e+09)
[2022-06-09 16:50:03,118][root][INFO] - Step 35481600 @ 3069.6 SPS. Inference batcher size: 71. Learner queue size: 64. Other stats: (train_seconds = 1.1366e+04, step = 35481600, mean_episode_return = 70.738, mean_episode_step = 2023.7, total_loss = 389.15, pg_loss = 342.62, baseline_loss = 61.374, entropy_loss = -14.837, learner_queue_size = 64, _tick = 5372, _time = 1.6548e+09)
[2022-06-09 16:50:08,122][root][INFO] - Step 35496960 @ 3069.6 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 1.1371e+04, step = 35496960, mean_episode_return = 34.75, mean_episode_step = 1861.2, total_loss = 369.36, pg_loss = 296.49, baseline_loss = 87.656, entropy_loss = -14.782, learner_queue_size = 64, _tick = 5375, _time = 1.6548e+09)
[2022-06-09 16:50:13,126][root][INFO] - Step 35512320 @ 3069.6 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.1376e+04, step = 35512320, mean_episode_return = 39.611, mean_episode_step = 2141.2, total_loss = 150.42, pg_loss = 128.62, baseline_loss = 36.592, entropy_loss = -14.789, learner_queue_size = 64, _tick = 5378, _time = 1.6548e+09)
[2022-06-09 16:50:18,132][root][INFO] - Step 35527680 @ 3068.3 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 1.1381e+04, step = 35527680, mean_episode_return = 71.53, mean_episode_step = 2189.6, total_loss = 96.609, pg_loss = 69.367, baseline_loss = 41.864, entropy_loss = -14.623, learner_queue_size = 64, _tick = 5380, _time = 1.6548e+09)
[2022-06-09 16:50:23,138][root][INFO] - Step 35543040 @ 3068.3 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 1.1386e+04, step = 35543040, mean_episode_return = -3.7903, mean_episode_step = 2149.2, total_loss = 158.27, pg_loss = 129.78, baseline_loss = 43.038, entropy_loss = -14.552, learner_queue_size = 64, _tick = 5383, _time = 1.6548e+09)
[2022-06-09 16:50:28,142][root][INFO] - Step 35558400 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.1391e+04, step = 35558400, mean_episode_return = None, mean_episode_step = 2013.1, total_loss = -33.652, pg_loss = -37.323, baseline_loss = 18.267, entropy_loss = -14.596, learner_queue_size = 64, _tick = 5385, _time = 1.6548e+09)
[2022-06-09 16:50:33,146][root][INFO] - Step 35573760 @ 3069.6 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 1.1396e+04, step = 35573760, mean_episode_return = None, mean_episode_step = 2177.6, total_loss = -111.31, pg_loss = -110.81, baseline_loss = 14.311, entropy_loss = -14.81, learner_queue_size = 64, _tick = 5387, _time = 1.6548e+09)
[2022-06-09 16:50:38,154][root][INFO] - Step 35594240 @ 4089.4 SPS. Inference batcher size: 68. Learner queue size: 64. Other stats: (train_seconds = 1.1401e+04, step = 35594240, mean_episode_return = 106.78, mean_episode_step = 2470.6, total_loss = -8.5736, pg_loss = -18.272, baseline_loss = 24.68, entropy_loss = -14.981, learner_queue_size = 64, _tick = 5390, _time = 1.6548e+09)
[2022-06-09 16:50:43,162][root][INFO] - Step 35609600 @ 3067.1 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.1406e+04, step = 35609600, mean_episode_return = 45.028, mean_episode_step = 1889.9, total_loss = 101.67, pg_loss = 78.873, baseline_loss = 37.55, entropy_loss = -14.756, learner_queue_size = 64, _tick = 5392, _time = 1.6548e+09)
[2022-06-09 16:50:48,166][root][INFO] - Step 35624960 @ 3069.6 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 1.1411e+04, step = 35624960, mean_episode_return = 38.5, mean_episode_step = 2332.5, total_loss = -110.91, pg_loss = -124.69, baseline_loss = 28.435, entropy_loss = -14.655, learner_queue_size = 64, _tick = 5395, _time = 1.6548e+09)
[2022-06-09 16:50:53,170][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 16:50:53,431][root][INFO] - Step 35640320 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.1416e+04, step = 35640320, mean_episode_return = -1.32, mean_episode_step = 2185.5, total_loss = 45.613, pg_loss = 39.11, baseline_loss = 21.263, entropy_loss = -14.759, learner_queue_size = 64, _tick = 5398, _time = 1.6548e+09)
[2022-06-09 16:50:58,434][root][INFO] - Step 35655680 @ 2917.9 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 1.1421e+04, step = 35655680, mean_episode_return = 34.057, mean_episode_step = 1733.4, total_loss = 93.315, pg_loss = 68.616, baseline_loss = 39.692, entropy_loss = -14.993, learner_queue_size = 64, _tick = 5401, _time = 1.6548e+09)
[2022-06-09 16:51:03,438][root][INFO] - Step 35671040 @ 3069.6 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.1426e+04, step = 35671040, mean_episode_return = 60.9, mean_episode_step = 2064.2, total_loss = 128.29, pg_loss = 101.72, baseline_loss = 41.392, entropy_loss = -14.826, learner_queue_size = 64, _tick = 5404, _time = 1.6548e+09)
[2022-06-09 16:51:08,442][root][INFO] - Step 35686400 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.1431e+04, step = 35686400, mean_episode_return = 4.4644, mean_episode_step = 2059.1, total_loss = -145.25, pg_loss = -149.86, baseline_loss = 19.502, entropy_loss = -14.893, learner_queue_size = 64, _tick = 5407, _time = 1.6548e+09)
[2022-06-09 16:51:13,446][root][INFO] - Step 35701760 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.1436e+04, step = 35701760, mean_episode_return = None, mean_episode_step = 2179.7, total_loss = 156.46, pg_loss = 148.93, baseline_loss = 22.648, entropy_loss = -15.119, learner_queue_size = 64, _tick = 5408, _time = 1.6548e+09)
[2022-06-09 16:51:18,450][root][INFO] - Step 35717120 @ 3069.5 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.1441e+04, step = 35717120, mean_episode_return = 82.357, mean_episode_step = 2283.8, total_loss = 129.29, pg_loss = 106.44, baseline_loss = 38.06, entropy_loss = -15.208, learner_queue_size = 64, _tick = 5410, _time = 1.6548e+09)
[2022-06-09 16:51:23,454][root][INFO] - Step 35732480 @ 3069.6 SPS. Inference batcher size: 10. Learner queue size: 64. Other stats: (train_seconds = 1.1446e+04, step = 35732480, mean_episode_return = 42.975, mean_episode_step = 1834.4, total_loss = 245.0, pg_loss = 197.78, baseline_loss = 62.39, entropy_loss = -15.164, learner_queue_size = 64, _tick = 5413, _time = 1.6548e+09)
[2022-06-09 16:51:28,458][root][INFO] - Step 35747840 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.1451e+04, step = 35747840, mean_episode_return = 72.567, mean_episode_step = 1977.2, total_loss = 184.84, pg_loss = 157.34, baseline_loss = 42.818, entropy_loss = -15.318, learner_queue_size = 64, _tick = 5416, _time = 1.6548e+09)
[2022-06-09 16:51:33,462][root][INFO] - Step 35763200 @ 3069.6 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.1456e+04, step = 35763200, mean_episode_return = None, mean_episode_step = 1939.4, total_loss = 101.07, pg_loss = 94.448, baseline_loss = 21.674, entropy_loss = -15.048, learner_queue_size = 64, _tick = 5417, _time = 1.6548e+09)
[2022-06-09 16:51:38,468][root][INFO] - Step 35778560 @ 3068.4 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.1461e+04, step = 35778560, mean_episode_return = 21.976, mean_episode_step = 2150.1, total_loss = -241.56, pg_loss = -233.78, baseline_loss = 7.2188, entropy_loss = -15.006, learner_queue_size = 64, _tick = 5419, _time = 1.6548e+09)
[2022-06-09 16:51:43,470][root][INFO] - Step 35793920 @ 3070.7 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.1466e+04, step = 35793920, mean_episode_return = -71.687, mean_episode_step = 1977.7, total_loss = 295.33, pg_loss = 258.68, baseline_loss = 51.678, entropy_loss = -15.027, learner_queue_size = 64, _tick = 5421, _time = 1.6548e+09)
[2022-06-09 16:51:48,474][root][INFO] - Step 35814400 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 1.1471e+04, step = 35814400, mean_episode_return = 34.9, mean_episode_step = 1944.7, total_loss = -120.67, pg_loss = -116.65, baseline_loss = 11.17, entropy_loss = -15.191, learner_queue_size = 64, _tick = 5425, _time = 1.6548e+09)
[2022-06-09 16:51:53,478][root][INFO] - Step 35829760 @ 3069.6 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 1.1476e+04, step = 35829760, mean_episode_return = 57.905, mean_episode_step = 1796.4, total_loss = -265.34, pg_loss = -275.2, baseline_loss = 25.031, entropy_loss = -15.17, learner_queue_size = 64, _tick = 5426, _time = 1.6548e+09)
[2022-06-09 16:51:58,482][root][INFO] - Step 35845120 @ 3069.6 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 1.1481e+04, step = 35845120, mean_episode_return = 41.566, mean_episode_step = 1861.1, total_loss = 15.275, pg_loss = -10.564, baseline_loss = 41.006, entropy_loss = -15.167, learner_queue_size = 64, _tick = 5429, _time = 1.6548e+09)
[2022-06-09 16:52:03,486][root][INFO] - Step 35860480 @ 3069.6 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 1.1486e+04, step = 35860480, mean_episode_return = None, mean_episode_step = 2299.1, total_loss = -72.94, pg_loss = -69.414, baseline_loss = 11.549, entropy_loss = -15.075, learner_queue_size = 64, _tick = 5430, _time = 1.6548e+09)
[2022-06-09 16:52:08,490][root][INFO] - Step 35875840 @ 3069.6 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.1491e+04, step = 35875840, mean_episode_return = None, mean_episode_step = 1906.4, total_loss = -36.628, pg_loss = -32.682, baseline_loss = 11.04, entropy_loss = -14.986, learner_queue_size = 64, _tick = 5432, _time = 1.6548e+09)
[2022-06-09 16:52:13,494][root][INFO] - Step 35891200 @ 3069.5 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 1.1496e+04, step = 35891200, mean_episode_return = -35.62, mean_episode_step = 2037.0, total_loss = -98.291, pg_loss = -94.396, baseline_loss = 11.207, entropy_loss = -15.101, learner_queue_size = 64, _tick = 5435, _time = 1.6548e+09)
[2022-06-09 16:52:18,498][root][INFO] - Step 35906560 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.1501e+04, step = 35906560, mean_episode_return = 85.186, mean_episode_step = 1988.6, total_loss = 121.52, pg_loss = 99.127, baseline_loss = 37.474, entropy_loss = -15.078, learner_queue_size = 64, _tick = 5437, _time = 1.6548e+09)
[2022-06-09 16:52:23,504][root][INFO] - Step 35921920 @ 3068.3 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.1506e+04, step = 35921920, mean_episode_return = 40.575, mean_episode_step = 1865.4, total_loss = 4.732, pg_loss = -9.1567, baseline_loss = 28.983, entropy_loss = -15.094, learner_queue_size = 64, _tick = 5440, _time = 1.6548e+09)
[2022-06-09 16:52:28,510][root][INFO] - Step 35942400 @ 4091.1 SPS. Inference batcher size: 73. Learner queue size: 64. Other stats: (train_seconds = 1.1511e+04, step = 35942400, mean_episode_return = 30.48, mean_episode_step = 2067.5, total_loss = -50.414, pg_loss = -48.865, baseline_loss = 13.546, entropy_loss = -15.096, learner_queue_size = 64, _tick = 5443, _time = 1.6548e+09)
[2022-06-09 16:52:33,516][root][INFO] - Step 35957760 @ 3068.2 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 1.1516e+04, step = 35957760, mean_episode_return = 3.0832, mean_episode_step = 1964.6, total_loss = -158.14, pg_loss = -155.21, baseline_loss = 12.193, entropy_loss = -15.122, learner_queue_size = 64, _tick = 5445, _time = 1.6548e+09)
[2022-06-09 16:52:38,522][root][INFO] - Step 35973120 @ 3068.5 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 1.1522e+04, step = 35973120, mean_episode_return = 50.967, mean_episode_step = 1742.8, total_loss = 207.52, pg_loss = 178.77, baseline_loss = 43.928, entropy_loss = -15.175, learner_queue_size = 64, _tick = 5448, _time = 1.6548e+09)
[2022-06-09 16:52:43,526][root][INFO] - Step 35988480 @ 3069.6 SPS. Inference batcher size: 86. Learner queue size: 64. Other stats: (train_seconds = 1.1526e+04, step = 35988480, mean_episode_return = 46.051, mean_episode_step = 1697.8, total_loss = 88.589, pg_loss = 63.602, baseline_loss = 40.391, entropy_loss = -15.404, learner_queue_size = 64, _tick = 5451, _time = 1.6548e+09)
[2022-06-09 16:52:48,530][root][INFO] - Step 36003840 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.1532e+04, step = 36003840, mean_episode_return = 22.52, mean_episode_step = 2178.0, total_loss = -192.62, pg_loss = -185.14, baseline_loss = 7.9167, entropy_loss = -15.398, learner_queue_size = 64, _tick = 5454, _time = 1.6548e+09)
[2022-06-09 16:52:53,536][root][INFO] - Step 36019200 @ 3068.3 SPS. Inference batcher size: 2. Learner queue size: 64. Other stats: (train_seconds = 1.1536e+04, step = 36019200, mean_episode_return = 9.4597, mean_episode_step = 2102.1, total_loss = -89.936, pg_loss = -91.173, baseline_loss = 16.587, entropy_loss = -15.349, learner_queue_size = 64, _tick = 5457, _time = 1.6548e+09)
[2022-06-09 16:52:58,542][root][INFO] - Step 36034560 @ 3068.3 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.1542e+04, step = 36034560, mean_episode_return = -2.8604, mean_episode_step = 2169.6, total_loss = -42.559, pg_loss = -44.45, baseline_loss = 17.032, entropy_loss = -15.141, learner_queue_size = 64, _tick = 5460, _time = 1.6548e+09)
[2022-06-09 16:53:03,546][root][INFO] - Step 36049920 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.1546e+04, step = 36049920, mean_episode_return = 59.155, mean_episode_step = 2196.6, total_loss = 360.78, pg_loss = 297.25, baseline_loss = 78.396, entropy_loss = -14.867, learner_queue_size = 64, _tick = 5463, _time = 1.6548e+09)
[2022-06-09 16:53:08,550][root][INFO] - Step 36065280 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.1552e+04, step = 36065280, mean_episode_return = 25.958, mean_episode_step = 1720.7, total_loss = -200.54, pg_loss = -198.85, baseline_loss = 13.185, entropy_loss = -14.877, learner_queue_size = 64, _tick = 5466, _time = 1.6548e+09)
[2022-06-09 16:53:13,554][root][INFO] - Step 36080640 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.1556e+04, step = 36080640, mean_episode_return = 24.631, mean_episode_step = 2025.6, total_loss = -68.144, pg_loss = -69.477, baseline_loss = 16.139, entropy_loss = -14.806, learner_queue_size = 64, _tick = 5469, _time = 1.6548e+09)
[2022-06-09 16:53:18,558][root][INFO] - Step 36101120 @ 4092.8 SPS. Inference batcher size: 73. Learner queue size: 64. Other stats: (train_seconds = 1.1562e+04, step = 36101120, mean_episode_return = 26.001, mean_episode_step = 1979.3, total_loss = 171.77, pg_loss = 127.35, baseline_loss = 59.045, entropy_loss = -14.622, learner_queue_size = 64, _tick = 5473, _time = 1.6548e+09)
[2022-06-09 16:53:23,562][root][INFO] - Step 36116480 @ 3069.5 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 1.1566e+04, step = 36116480, mean_episode_return = 99.005, mean_episode_step = 2233.0, total_loss = -194.57, pg_loss = -199.83, baseline_loss = 19.847, entropy_loss = -14.591, learner_queue_size = 64, _tick = 5474, _time = 1.6548e+09)
[2022-06-09 16:53:28,566][root][INFO] - Step 36131840 @ 3069.6 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 1.1572e+04, step = 36131840, mean_episode_return = 38.694, mean_episode_step = 1875.1, total_loss = -88.449, pg_loss = -97.865, baseline_loss = 23.943, entropy_loss = -14.528, learner_queue_size = 64, _tick = 5476, _time = 1.6548e+09)
[2022-06-09 16:53:33,573][root][INFO] - Step 36147200 @ 3068.0 SPS. Inference batcher size: 13. Learner queue size: 64. Other stats: (train_seconds = 1.1576e+04, step = 36147200, mean_episode_return = None, mean_episode_step = 2010.8, total_loss = 136.31, pg_loss = 120.2, baseline_loss = 30.751, entropy_loss = -14.643, learner_queue_size = 64, _tick = 5477, _time = 1.6548e+09)
[2022-06-09 16:53:38,578][root][INFO] - Step 36162560 @ 3068.6 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 1.1582e+04, step = 36162560, mean_episode_return = 11.32, mean_episode_step = 1956.7, total_loss = 155.1, pg_loss = 127.31, baseline_loss = 42.49, entropy_loss = -14.705, learner_queue_size = 64, _tick = 5480, _time = 1.6548e+09)
[2022-06-09 16:53:43,582][root][INFO] - Step 36177920 @ 3069.6 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 1.1586e+04, step = 36177920, mean_episode_return = 29.71, mean_episode_step = 1848.4, total_loss = 155.92, pg_loss = 133.46, baseline_loss = 37.15, entropy_loss = -14.695, learner_queue_size = 64, _tick = 5482, _time = 1.6548e+09)
[2022-06-09 16:53:48,586][root][INFO] - Step 36193280 @ 3069.5 SPS. Inference batcher size: 4. Learner queue size: 64. Other stats: (train_seconds = 1.1592e+04, step = 36193280, mean_episode_return = 36.311, mean_episode_step = 1906.6, total_loss = 34.484, pg_loss = 10.221, baseline_loss = 38.826, entropy_loss = -14.563, learner_queue_size = 64, _tick = 5485, _time = 1.6548e+09)
[2022-06-09 16:53:53,590][root][INFO] - Step 36208640 @ 3069.6 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 1.1596e+04, step = 36208640, mean_episode_return = -20.97, mean_episode_step = 1544.3, total_loss = 65.689, pg_loss = 37.617, baseline_loss = 42.438, entropy_loss = -14.365, learner_queue_size = 64, _tick = 5487, _time = 1.6548e+09)
[2022-06-09 16:53:58,596][root][INFO] - Step 36224000 @ 3068.4 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 1.1602e+04, step = 36224000, mean_episode_return = 5.2294, mean_episode_step = 1832.7, total_loss = 31.093, pg_loss = 17.098, baseline_loss = 28.325, entropy_loss = -14.329, learner_queue_size = 64, _tick = 5490, _time = 1.6548e+09)
[2022-06-09 16:54:03,598][root][INFO] - Step 36239360 @ 3070.7 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.1606e+04, step = 36239360, mean_episode_return = 59.755, mean_episode_step = 2044.3, total_loss = -75.108, pg_loss = -77.912, baseline_loss = 17.167, entropy_loss = -14.363, learner_queue_size = 64, _tick = 5492, _time = 1.6548e+09)
[2022-06-09 16:54:08,602][root][INFO] - Step 36259840 @ 4092.7 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.1612e+04, step = 36259840, mean_episode_return = 13.75, mean_episode_step = 2015.7, total_loss = -194.28, pg_loss = -191.12, baseline_loss = 11.231, entropy_loss = -14.389, learner_queue_size = 64, _tick = 5495, _time = 1.6548e+09)
[2022-06-09 16:54:13,606][root][INFO] - Step 36275200 @ 3069.5 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 1.1616e+04, step = 36275200, mean_episode_return = 43.959, mean_episode_step = 1991.3, total_loss = -236.42, pg_loss = -239.93, baseline_loss = 18.064, entropy_loss = -14.551, learner_queue_size = 64, _tick = 5497, _time = 1.6548e+09)
[2022-06-09 16:54:18,610][root][INFO] - Step 36290560 @ 3069.6 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.1622e+04, step = 36290560, mean_episode_return = None, mean_episode_step = 2035.8, total_loss = -40.862, pg_loss = -47.432, baseline_loss = 20.872, entropy_loss = -14.302, learner_queue_size = 64, _tick = 5499, _time = 1.6548e+09)
[2022-06-09 16:54:23,614][root][INFO] - Step 36305920 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.1626e+04, step = 36305920, mean_episode_return = 96.347, mean_episode_step = 1772.0, total_loss = 243.42, pg_loss = 201.52, baseline_loss = 56.325, entropy_loss = -14.432, learner_queue_size = 64, _tick = 5502, _time = 1.6548e+09)
[2022-06-09 16:54:28,618][root][INFO] - Step 36321280 @ 3069.5 SPS. Inference batcher size: 3. Learner queue size: 64. Other stats: (train_seconds = 1.1632e+04, step = 36321280, mean_episode_return = None, mean_episode_step = 2073.7, total_loss = 13.38, pg_loss = 3.3815, baseline_loss = 24.48, entropy_loss = -14.482, learner_queue_size = 64, _tick = 5504, _time = 1.6548e+09)
[2022-06-09 16:54:33,622][root][INFO] - Step 36341760 @ 4092.7 SPS. Inference batcher size: 76. Learner queue size: 64. Other stats: (train_seconds = 1.1637e+04, step = 36341760, mean_episode_return = None, mean_episode_step = 2360.0, total_loss = -24.673, pg_loss = -25.027, baseline_loss = 14.902, entropy_loss = -14.548, learner_queue_size = 64, _tick = 5507, _time = 1.6548e+09)
[2022-06-09 16:54:38,626][root][INFO] - Step 36357120 @ 3069.5 SPS. Inference batcher size: 76. Learner queue size: 64. Other stats: (train_seconds = 1.1642e+04, step = 36357120, mean_episode_return = 66.739, mean_episode_step = 1686.6, total_loss = -8.939, pg_loss = -15.366, baseline_loss = 21.18, entropy_loss = -14.752, learner_queue_size = 64, _tick = 5509, _time = 1.6548e+09)
[2022-06-09 16:54:43,630][root][INFO] - Step 36372480 @ 3069.6 SPS. Inference batcher size: 87. Learner queue size: 64. Other stats: (train_seconds = 1.1647e+04, step = 36372480, mean_episode_return = None, mean_episode_step = 2028.5, total_loss = -81.506, pg_loss = -76.851, baseline_loss = 10.101, entropy_loss = -14.756, learner_queue_size = 64, _tick = 5511, _time = 1.6548e+09)
[2022-06-09 16:54:48,634][root][INFO] - Step 36387840 @ 3069.5 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 1.1652e+04, step = 36387840, mean_episode_return = 53.501, mean_episode_step = 2370.1, total_loss = 190.57, pg_loss = 152.44, baseline_loss = 52.899, entropy_loss = -14.765, learner_queue_size = 64, _tick = 5514, _time = 1.6548e+09)
[2022-06-09 16:54:53,638][root][INFO] - Step 36403200 @ 3069.6 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 1.1657e+04, step = 36403200, mean_episode_return = 43.307, mean_episode_step = 1883.8, total_loss = 78.762, pg_loss = 46.775, baseline_loss = 46.638, entropy_loss = -14.651, learner_queue_size = 64, _tick = 5515, _time = 1.6548e+09)
[2022-06-09 16:54:58,642][root][INFO] - Step 36418560 @ 3069.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.1662e+04, step = 36418560, mean_episode_return = None, mean_episode_step = 2077.0, total_loss = 57.101, pg_loss = 18.285, baseline_loss = 53.378, entropy_loss = -14.562, learner_queue_size = 64, _tick = 5516, _time = 1.6548e+09)
[2022-06-09 16:55:03,646][root][INFO] - Step 36433920 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.1667e+04, step = 36433920, mean_episode_return = None, mean_episode_step = 2373.9, total_loss = 101.38, pg_loss = 70.334, baseline_loss = 45.729, entropy_loss = -14.686, learner_queue_size = 64, _tick = 5517, _time = 1.6548e+09)
[2022-06-09 16:55:08,650][root][INFO] - Step 36449280 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.1672e+04, step = 36449280, mean_episode_return = None, mean_episode_step = 2161.4, total_loss = 145.86, pg_loss = 136.51, baseline_loss = 24.111, entropy_loss = -14.758, learner_queue_size = 64, _tick = 5518, _time = 1.6548e+09)
[2022-06-09 16:55:13,654][root][INFO] - Step 36464640 @ 3069.5 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 1.1677e+04, step = 36464640, mean_episode_return = 30.914, mean_episode_step = 2235.6, total_loss = -137.58, pg_loss = -132.71, baseline_loss = 10.003, entropy_loss = -14.873, learner_queue_size = 64, _tick = 5520, _time = 1.6548e+09)
[2022-06-09 16:55:18,658][root][INFO] - Step 36480000 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.1682e+04, step = 36480000, mean_episode_return = 44.445, mean_episode_step = 2133.5, total_loss = 268.84, pg_loss = 235.0, baseline_loss = 48.749, entropy_loss = -14.913, learner_queue_size = 64, _tick = 5523, _time = 1.6548e+09)
[2022-06-09 16:55:23,662][root][INFO] - Step 36500480 @ 4092.8 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 1.1687e+04, step = 36500480, mean_episode_return = 48.528, mean_episode_step = 2425.2, total_loss = 32.109, pg_loss = 17.588, baseline_loss = 29.257, entropy_loss = -14.737, learner_queue_size = 64, _tick = 5527, _time = 1.6548e+09)
[2022-06-09 16:55:28,666][root][INFO] - Step 36515840 @ 3069.5 SPS. Inference batcher size: 93. Learner queue size: 64. Other stats: (train_seconds = 1.1692e+04, step = 36515840, mean_episode_return = 37.061, mean_episode_step = 1914.2, total_loss = 826.26, pg_loss = 570.89, baseline_loss = 269.86, entropy_loss = -14.493, learner_queue_size = 64, _tick = 5530, _time = 1.6548e+09)
[2022-06-09 16:55:33,670][root][INFO] - Step 36531200 @ 3069.5 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 1.1697e+04, step = 36531200, mean_episode_return = 44.141, mean_episode_step = 1611.8, total_loss = -13.514, pg_loss = -25.572, baseline_loss = 26.493, entropy_loss = -14.435, learner_queue_size = 64, _tick = 5533, _time = 1.6548e+09)
[2022-06-09 16:55:38,674][root][INFO] - Step 36546560 @ 3069.6 SPS. Inference batcher size: 12. Learner queue size: 64. Other stats: (train_seconds = 1.1702e+04, step = 36546560, mean_episode_return = None, mean_episode_step = 2231.6, total_loss = 5.7438, pg_loss = -3.1894, baseline_loss = 23.46, entropy_loss = -14.526, learner_queue_size = 64, _tick = 5535, _time = 1.6548e+09)
[2022-06-09 16:55:43,678][root][INFO] - Step 36561920 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.1707e+04, step = 36561920, mean_episode_return = 87.356, mean_episode_step = 2018.1, total_loss = 76.188, pg_loss = 55.17, baseline_loss = 35.699, entropy_loss = -14.681, learner_queue_size = 64, _tick = 5537, _time = 1.6548e+09)
[2022-06-09 16:55:48,682][root][INFO] - Step 36577280 @ 3069.6 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 1.1712e+04, step = 36577280, mean_episode_return = 15.33, mean_episode_step = 2135.3, total_loss = 135.83, pg_loss = 128.22, baseline_loss = 22.326, entropy_loss = -14.718, learner_queue_size = 64, _tick = 5540, _time = 1.6548e+09)
[2022-06-09 16:55:53,686][root][INFO] - Step 36592640 @ 3069.5 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 1.1717e+04, step = 36592640, mean_episode_return = None, mean_episode_step = 2061.9, total_loss = 116.59, pg_loss = 104.15, baseline_loss = 27.147, entropy_loss = -14.716, learner_queue_size = 64, _tick = 5542, _time = 1.6548e+09)
[2022-06-09 16:55:58,690][root][INFO] - Step 36608000 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.1722e+04, step = 36608000, mean_episode_return = None, mean_episode_step = 2080.1, total_loss = 62.077, pg_loss = 45.782, baseline_loss = 30.959, entropy_loss = -14.664, learner_queue_size = 64, _tick = 5544, _time = 1.6548e+09)
[2022-06-09 16:56:03,694][root][INFO] - Step 36623360 @ 3069.6 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.1727e+04, step = 36623360, mean_episode_return = 29.719, mean_episode_step = 2093.6, total_loss = 92.301, pg_loss = 58.46, baseline_loss = 48.445, entropy_loss = -14.603, learner_queue_size = 64, _tick = 5547, _time = 1.6548e+09)
[2022-06-09 16:56:08,698][root][INFO] - Step 36643840 @ 4092.7 SPS. Inference batcher size: 4. Learner queue size: 64. Other stats: (train_seconds = 1.1732e+04, step = 36643840, mean_episode_return = 36.242, mean_episode_step = 1727.6, total_loss = 295.6, pg_loss = 257.43, baseline_loss = 52.818, entropy_loss = -14.651, learner_queue_size = 64, _tick = 5549, _time = 1.6548e+09)
[2022-06-09 16:56:13,702][root][INFO] - Step 36659200 @ 3069.5 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 1.1737e+04, step = 36659200, mean_episode_return = 54.607, mean_episode_step = 2123.5, total_loss = -3.4084, pg_loss = -29.395, baseline_loss = 40.573, entropy_loss = -14.586, learner_queue_size = 64, _tick = 5552, _time = 1.6548e+09)
[2022-06-09 16:56:18,706][root][INFO] - Step 36674560 @ 3069.6 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 1.1742e+04, step = 36674560, mean_episode_return = 11.779, mean_episode_step = 2064.6, total_loss = -104.13, pg_loss = -105.61, baseline_loss = 16.087, entropy_loss = -14.605, learner_queue_size = 64, _tick = 5554, _time = 1.6548e+09)
[2022-06-09 16:56:23,710][root][INFO] - Step 36689920 @ 3069.6 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.1747e+04, step = 36689920, mean_episode_return = 15.565, mean_episode_step = 1867.2, total_loss = 71.325, pg_loss = 55.094, baseline_loss = 30.951, entropy_loss = -14.72, learner_queue_size = 64, _tick = 5557, _time = 1.6548e+09)
[2022-06-09 16:56:28,714][root][INFO] - Step 36705280 @ 3069.6 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.1752e+04, step = 36705280, mean_episode_return = 15.51, mean_episode_step = 2145.4, total_loss = -38.147, pg_loss = -46.329, baseline_loss = 22.887, entropy_loss = -14.705, learner_queue_size = 64, _tick = 5559, _time = 1.6548e+09)
[2022-06-09 16:56:33,718][root][INFO] - Step 36720640 @ 3069.6 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 1.1757e+04, step = 36720640, mean_episode_return = 29.59, mean_episode_step = 2143.8, total_loss = -12.992, pg_loss = -16.711, baseline_loss = 18.268, entropy_loss = -14.549, learner_queue_size = 64, _tick = 5562, _time = 1.6548e+09)
[2022-06-09 16:56:38,722][root][INFO] - Step 36736000 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.1762e+04, step = 36736000, mean_episode_return = 59.684, mean_episode_step = 2047.6, total_loss = 22.304, pg_loss = 12.715, baseline_loss = 24.125, entropy_loss = -14.535, learner_queue_size = 64, _tick = 5565, _time = 1.6548e+09)
[2022-06-09 16:56:43,726][root][INFO] - Step 36751360 @ 3069.6 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.1767e+04, step = 36751360, mean_episode_return = 65.421, mean_episode_step = 2091.5, total_loss = 100.92, pg_loss = 77.978, baseline_loss = 37.687, entropy_loss = -14.75, learner_queue_size = 64, _tick = 5568, _time = 1.6548e+09)
[2022-06-09 16:56:48,731][root][INFO] - Step 36771840 @ 4092.3 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 1.1772e+04, step = 36771840, mean_episode_return = 46.15, mean_episode_step = 2347.9, total_loss = -167.76, pg_loss = -166.19, baseline_loss = 13.262, entropy_loss = -14.828, learner_queue_size = 64, _tick = 5570, _time = 1.6548e+09)
[2022-06-09 16:56:53,734][root][INFO] - Step 36787200 @ 3069.8 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.1777e+04, step = 36787200, mean_episode_return = 42.206, mean_episode_step = 2498.9, total_loss = -102.6, pg_loss = -119.33, baseline_loss = 31.657, entropy_loss = -14.933, learner_queue_size = 64, _tick = 5573, _time = 1.6548e+09)
[2022-06-09 16:56:58,738][root][INFO] - Step 36802560 @ 3069.6 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 1.1782e+04, step = 36802560, mean_episode_return = 13.485, mean_episode_step = 2211.3, total_loss = -178.14, pg_loss = -178.33, baseline_loss = 14.954, entropy_loss = -14.759, learner_queue_size = 64, _tick = 5575, _time = 1.6548e+09)
[2022-06-09 16:57:03,742][root][INFO] - Step 36817920 @ 3069.5 SPS. Inference batcher size: 2. Learner queue size: 64. Other stats: (train_seconds = 1.1787e+04, step = 36817920, mean_episode_return = 71.593, mean_episode_step = 1831.0, total_loss = 50.794, pg_loss = 27.71, baseline_loss = 37.726, entropy_loss = -14.642, learner_queue_size = 64, _tick = 5578, _time = 1.6548e+09)
[2022-06-09 16:57:08,746][root][INFO] - Step 36833280 @ 3069.5 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 1.1792e+04, step = 36833280, mean_episode_return = 56.541, mean_episode_step = 2020.0, total_loss = 248.16, pg_loss = 215.86, baseline_loss = 46.878, entropy_loss = -14.57, learner_queue_size = 64, _tick = 5580, _time = 1.6548e+09)
[2022-06-09 16:57:13,750][root][INFO] - Step 36848640 @ 3069.6 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 1.1797e+04, step = 36848640, mean_episode_return = 23.9, mean_episode_step = 2454.9, total_loss = -133.26, pg_loss = -135.68, baseline_loss = 16.948, entropy_loss = -14.53, learner_queue_size = 64, _tick = 5583, _time = 1.6548e+09)
[2022-06-09 16:57:18,754][root][INFO] - Step 36864000 @ 3069.5 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 1.1802e+04, step = 36864000, mean_episode_return = None, mean_episode_step = 2450.5, total_loss = -109.43, pg_loss = -103.21, baseline_loss = 8.3574, entropy_loss = -14.583, learner_queue_size = 64, _tick = 5585, _time = 1.6548e+09)
[2022-06-09 16:57:23,758][root][INFO] - Step 36879360 @ 3069.6 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 1.1807e+04, step = 36879360, mean_episode_return = 39.237, mean_episode_step = 2428.6, total_loss = 144.96, pg_loss = 103.73, baseline_loss = 55.801, entropy_loss = -14.57, learner_queue_size = 64, _tick = 5588, _time = 1.6548e+09)
[2022-06-09 16:57:28,762][root][INFO] - Step 36894720 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.1812e+04, step = 36894720, mean_episode_return = 23.65, mean_episode_step = 2168.8, total_loss = 383.15, pg_loss = 323.64, baseline_loss = 74.052, entropy_loss = -14.534, learner_queue_size = 64, _tick = 5591, _time = 1.6548e+09)
[2022-06-09 16:57:33,766][root][INFO] - Step 36910080 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 1.1817e+04, step = 36910080, mean_episode_return = 20.165, mean_episode_step = 2285.0, total_loss = 81.675, pg_loss = 65.966, baseline_loss = 30.175, entropy_loss = -14.467, learner_queue_size = 64, _tick = 5593, _time = 1.6548e+09)
[2022-06-09 16:57:38,770][root][INFO] - Step 36925440 @ 3069.6 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1.1822e+04, step = 36925440, mean_episode_return = -5.3616, mean_episode_step = 2463.1, total_loss = -221.28, pg_loss = -227.72, baseline_loss = 20.539, entropy_loss = -14.102, learner_queue_size = 64, _tick = 5596, _time = 1.6548e+09)
[2022-06-09 16:57:43,774][root][INFO] - Step 36945920 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 1.1827e+04, step = 36945920, mean_episode_return = 58.381, mean_episode_step = 2645.5, total_loss = 198.07, pg_loss = 162.27, baseline_loss = 49.998, entropy_loss = -14.201, learner_queue_size = 64, _tick = 5599, _time = 1.6548e+09)
[2022-06-09 16:57:48,778][root][INFO] - Step 36961280 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.1832e+04, step = 36961280, mean_episode_return = 43.482, mean_episode_step = 2312.1, total_loss = 0.7109, pg_loss = -20.093, baseline_loss = 34.863, entropy_loss = -14.059, learner_queue_size = 64, _tick = 5602, _time = 1.6548e+09)
[2022-06-09 16:57:53,784][root][INFO] - Step 36976640 @ 3068.3 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 1.1837e+04, step = 36976640, mean_episode_return = 24.258, mean_episode_step = 2002.2, total_loss = 146.39, pg_loss = 86.279, baseline_loss = 74.202, entropy_loss = -14.092, learner_queue_size = 64, _tick = 5604, _time = 1.6548e+09)
[2022-06-09 16:57:58,790][root][INFO] - Step 36992000 @ 3068.4 SPS. Inference batcher size: 8. Learner queue size: 64. Other stats: (train_seconds = 1.1842e+04, step = 36992000, mean_episode_return = 62.141, mean_episode_step = 2545.7, total_loss = -218.72, pg_loss = -213.55, baseline_loss = 8.8469, entropy_loss = -14.018, learner_queue_size = 64, _tick = 5606, _time = 1.6548e+09)
[2022-06-09 16:58:03,794][root][INFO] - Step 37007360 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.1847e+04, step = 37007360, mean_episode_return = 7.4638, mean_episode_step = 2074.0, total_loss = 263.29, pg_loss = 213.52, baseline_loss = 63.909, entropy_loss = -14.142, learner_queue_size = 64, _tick = 5609, _time = 1.6548e+09)
[2022-06-09 16:58:08,798][root][INFO] - Step 37022720 @ 3069.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.1852e+04, step = 37022720, mean_episode_return = 124.13, mean_episode_step = 2233.1, total_loss = -84.193, pg_loss = -91.925, baseline_loss = 21.772, entropy_loss = -14.04, learner_queue_size = 64, _tick = 5612, _time = 1.6548e+09)
[2022-06-09 16:58:13,802][root][INFO] - Step 37038080 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.1857e+04, step = 37038080, mean_episode_return = 67.668, mean_episode_step = 1965.8, total_loss = -122.25, pg_loss = -124.24, baseline_loss = 16.019, entropy_loss = -14.034, learner_queue_size = 64, _tick = 5615, _time = 1.6548e+09)
[2022-06-09 16:58:18,806][root][INFO] - Step 37053440 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.1862e+04, step = 37053440, mean_episode_return = 51.812, mean_episode_step = 2650.7, total_loss = -24.269, pg_loss = -37.929, baseline_loss = 27.603, entropy_loss = -13.943, learner_queue_size = 64, _tick = 5616, _time = 1.6548e+09)
[2022-06-09 16:58:23,810][root][INFO] - Step 37068800 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.1867e+04, step = 37068800, mean_episode_return = None, mean_episode_step = 2190.3, total_loss = -100.3, pg_loss = -97.457, baseline_loss = 11.214, entropy_loss = -14.055, learner_queue_size = 64, _tick = 5616, _time = 1.6548e+09)
[2022-06-09 16:58:28,814][root][INFO] - Step 37084160 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.1872e+04, step = 37084160, mean_episode_return = 96.99, mean_episode_step = 2141.7, total_loss = 235.94, pg_loss = 162.35, baseline_loss = 87.654, entropy_loss = -14.067, learner_queue_size = 64, _tick = 5619, _time = 1.6548e+09)
[2022-06-09 16:58:33,818][root][INFO] - Step 37099520 @ 3069.6 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 1.1877e+04, step = 37099520, mean_episode_return = None, mean_episode_step = 1896.4, total_loss = 54.207, pg_loss = 47.544, baseline_loss = 20.889, entropy_loss = -14.226, learner_queue_size = 64, _tick = 5620, _time = 1.6548e+09)
[2022-06-09 16:58:38,822][root][INFO] - Step 37114880 @ 3069.5 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.1882e+04, step = 37114880, mean_episode_return = 37.795, mean_episode_step = 2384.6, total_loss = -124.05, pg_loss = -116.14, baseline_loss = 6.5412, entropy_loss = -14.458, learner_queue_size = 64, _tick = 5622, _time = 1.6548e+09)
[2022-06-09 16:58:43,826][root][INFO] - Step 37130240 @ 3069.4 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.1887e+04, step = 37130240, mean_episode_return = 81.293, mean_episode_step = 1826.6, total_loss = 118.08, pg_loss = 94.199, baseline_loss = 38.577, entropy_loss = -14.692, learner_queue_size = 64, _tick = 5625, _time = 1.6548e+09)
[2022-06-09 16:58:48,830][root][INFO] - Step 37150720 @ 4092.9 SPS. Inference batcher size: 82. Learner queue size: 64. Other stats: (train_seconds = 1.1892e+04, step = 37150720, mean_episode_return = 14.31, mean_episode_step = 2370.5, total_loss = 55.381, pg_loss = 42.879, baseline_loss = 27.155, entropy_loss = -14.653, learner_queue_size = 64, _tick = 5629, _time = 1.6548e+09)
[2022-06-09 16:58:53,834][root][INFO] - Step 37166080 @ 3069.5 SPS. Inference batcher size: 77. Learner queue size: 64. Other stats: (train_seconds = 1.1897e+04, step = 37166080, mean_episode_return = 82.41, mean_episode_step = 2296.5, total_loss = 130.46, pg_loss = 107.83, baseline_loss = 37.293, entropy_loss = -14.66, learner_queue_size = 64, _tick = 5631, _time = 1.6548e+09)
[2022-06-09 16:58:58,838][root][INFO] - Step 37181440 @ 3069.3 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.1902e+04, step = 37181440, mean_episode_return = None, mean_episode_step = 1884.7, total_loss = 51.179, pg_loss = 36.239, baseline_loss = 29.537, entropy_loss = -14.597, learner_queue_size = 64, _tick = 5631, _time = 1.6548e+09)
[2022-06-09 16:59:03,842][root][INFO] - Step 37196800 @ 3069.7 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.1907e+04, step = 37196800, mean_episode_return = -17.481, mean_episode_step = 2532.6, total_loss = 35.981, pg_loss = 18.103, baseline_loss = 32.398, entropy_loss = -14.52, learner_queue_size = 64, _tick = 5634, _time = 1.6548e+09)
[2022-06-09 16:59:08,846][root][INFO] - Step 37212160 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.1912e+04, step = 37212160, mean_episode_return = 22.944, mean_episode_step = 2100.1, total_loss = 178.71, pg_loss = 139.83, baseline_loss = 53.364, entropy_loss = -14.484, learner_queue_size = 64, _tick = 5636, _time = 1.6548e+09)
[2022-06-09 16:59:13,850][root][INFO] - Step 37227520 @ 3069.5 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 1.1917e+04, step = 37227520, mean_episode_return = 28.6, mean_episode_step = 2231.3, total_loss = -154.9, pg_loss = -155.63, baseline_loss = 15.292, entropy_loss = -14.562, learner_queue_size = 64, _tick = 5637, _time = 1.6548e+09)
[2022-06-09 16:59:18,854][root][INFO] - Step 37242880 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.1922e+04, step = 37242880, mean_episode_return = 13.865, mean_episode_step = 2196.8, total_loss = 73.675, pg_loss = 58.562, baseline_loss = 29.686, entropy_loss = -14.573, learner_queue_size = 64, _tick = 5639, _time = 1.6548e+09)
[2022-06-09 16:59:23,858][root][INFO] - Step 37258240 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.1927e+04, step = 37258240, mean_episode_return = 44.243, mean_episode_step = 2091.0, total_loss = -84.846, pg_loss = -95.386, baseline_loss = 25.145, entropy_loss = -14.606, learner_queue_size = 64, _tick = 5642, _time = 1.6548e+09)
[2022-06-09 16:59:28,862][root][INFO] - Step 37273600 @ 3069.5 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 1.1932e+04, step = 37273600, mean_episode_return = 37.745, mean_episode_step = 2127.5, total_loss = -5.7582, pg_loss = -13.661, baseline_loss = 22.568, entropy_loss = -14.666, learner_queue_size = 64, _tick = 5643, _time = 1.6548e+09)
[2022-06-09 16:59:33,866][root][INFO] - Step 37288960 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.1937e+04, step = 37288960, mean_episode_return = 58.316, mean_episode_step = 2211.8, total_loss = 333.63, pg_loss = 280.79, baseline_loss = 67.416, entropy_loss = -14.576, learner_queue_size = 64, _tick = 5645, _time = 1.6548e+09)
[2022-06-09 16:59:38,870][root][INFO] - Step 37304320 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.1942e+04, step = 37304320, mean_episode_return = 28.81, mean_episode_step = 2077.9, total_loss = -15.25, pg_loss = -30.348, baseline_loss = 29.625, entropy_loss = -14.527, learner_queue_size = 64, _tick = 5648, _time = 1.6548e+09)
[2022-06-09 16:59:43,874][root][INFO] - Step 37319680 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.1947e+04, step = 37319680, mean_episode_return = 83.312, mean_episode_step = 2196.6, total_loss = 260.78, pg_loss = 220.13, baseline_loss = 55.304, entropy_loss = -14.66, learner_queue_size = 64, _tick = 5651, _time = 1.6548e+09)
[2022-06-09 16:59:48,880][root][INFO] - Step 37340160 @ 4091.0 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 1.1952e+04, step = 37340160, mean_episode_return = None, mean_episode_step = 2140.2, total_loss = 86.164, pg_loss = 66.745, baseline_loss = 33.978, entropy_loss = -14.56, learner_queue_size = 64, _tick = 5654, _time = 1.6548e+09)
[2022-06-09 16:59:53,882][root][INFO] - Step 37355520 @ 3070.8 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.1957e+04, step = 37355520, mean_episode_return = 56.339, mean_episode_step = 2166.2, total_loss = 322.72, pg_loss = 269.42, baseline_loss = 67.853, entropy_loss = -14.559, learner_queue_size = 64, _tick = 5657, _time = 1.6548e+09)
[2022-06-09 16:59:58,938][root][INFO] - Step 37370880 @ 3037.7 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 1.1962e+04, step = 37370880, mean_episode_return = 86.279, mean_episode_step = 2069.9, total_loss = -206.36, pg_loss = -199.29, baseline_loss = 7.4802, entropy_loss = -14.552, learner_queue_size = 64, _tick = 5660, _time = 1.6548e+09)
[2022-06-09 17:00:03,942][root][INFO] - Step 37386240 @ 3069.8 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 1.1967e+04, step = 37386240, mean_episode_return = 33.741, mean_episode_step = 2315.9, total_loss = -333.71, pg_loss = -328.29, baseline_loss = 9.2303, entropy_loss = -14.649, learner_queue_size = 64, _tick = 5663, _time = 1.6548e+09)
[2022-06-09 17:00:08,946][root][INFO] - Step 37401600 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.1972e+04, step = 37401600, mean_episode_return = None, mean_episode_step = 2077.4, total_loss = 184.76, pg_loss = 172.33, baseline_loss = 27.138, entropy_loss = -14.703, learner_queue_size = 64, _tick = 5665, _time = 1.6548e+09)
[2022-06-09 17:00:13,950][root][INFO] - Step 37416960 @ 3069.5 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 1.1977e+04, step = 37416960, mean_episode_return = 57.393, mean_episode_step = 2028.1, total_loss = 22.918, pg_loss = -2.7427, baseline_loss = 40.27, entropy_loss = -14.61, learner_queue_size = 64, _tick = 5667, _time = 1.6548e+09)
[2022-06-09 17:00:18,954][root][INFO] - Step 37432320 @ 3069.5 SPS. Inference batcher size: 71. Learner queue size: 64. Other stats: (train_seconds = 1.1982e+04, step = 37432320, mean_episode_return = 78.52, mean_episode_step = 2280.0, total_loss = -210.01, pg_loss = -205.49, baseline_loss = 10.027, entropy_loss = -14.544, learner_queue_size = 64, _tick = 5670, _time = 1.6548e+09)
[2022-06-09 17:00:23,958][root][INFO] - Step 37447680 @ 3069.6 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.1987e+04, step = 37447680, mean_episode_return = 22.5, mean_episode_step = 1922.6, total_loss = -26.875, pg_loss = -48.808, baseline_loss = 36.367, entropy_loss = -14.433, learner_queue_size = 64, _tick = 5672, _time = 1.6548e+09)
[2022-06-09 17:00:28,962][root][INFO] - Step 37463040 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.1992e+04, step = 37463040, mean_episode_return = 10.623, mean_episode_step = 1908.1, total_loss = 26.509, pg_loss = 10.4, baseline_loss = 30.467, entropy_loss = -14.358, learner_queue_size = 64, _tick = 5675, _time = 1.6548e+09)
[2022-06-09 17:00:33,966][root][INFO] - Step 37478400 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.1997e+04, step = 37478400, mean_episode_return = 64.582, mean_episode_step = 1976.8, total_loss = 265.1, pg_loss = 217.78, baseline_loss = 61.906, entropy_loss = -14.59, learner_queue_size = 64, _tick = 5678, _time = 1.6548e+09)
[2022-06-09 17:00:38,970][root][INFO] - Step 37493760 @ 3069.6 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.2002e+04, step = 37493760, mean_episode_return = 79.118, mean_episode_step = 2221.7, total_loss = -70.01, pg_loss = -79.827, baseline_loss = 24.317, entropy_loss = -14.5, learner_queue_size = 64, _tick = 5681, _time = 1.6548e+09)
[2022-06-09 17:00:43,974][root][INFO] - Step 37509120 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.2007e+04, step = 37509120, mean_episode_return = 55.851, mean_episode_step = 2192.5, total_loss = -25.277, pg_loss = -54.138, baseline_loss = 43.427, entropy_loss = -14.565, learner_queue_size = 64, _tick = 5684, _time = 1.6548e+09)
[2022-06-09 17:00:48,980][root][INFO] - Step 37524480 @ 3068.4 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.2012e+04, step = 37524480, mean_episode_return = 24.543, mean_episode_step = 2340.8, total_loss = -2.7622, pg_loss = -14.949, baseline_loss = 26.336, entropy_loss = -14.149, learner_queue_size = 64, _tick = 5686, _time = 1.6548e+09)
[2022-06-09 17:00:53,982][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 17:00:54,310][root][INFO] - Step 37544960 @ 4094.3 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.2017e+04, step = 37544960, mean_episode_return = 104.6, mean_episode_step = 2090.2, total_loss = 124.29, pg_loss = 97.206, baseline_loss = 41.186, entropy_loss = -14.098, learner_queue_size = 64, _tick = 5690, _time = 1.6548e+09)
[2022-06-09 17:00:59,314][root][INFO] - Step 37560320 @ 2880.7 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.2022e+04, step = 37560320, mean_episode_return = None, mean_episode_step = 2255.3, total_loss = 359.28, pg_loss = 307.76, baseline_loss = 65.597, entropy_loss = -14.08, learner_queue_size = 64, _tick = 5691, _time = 1.6548e+09)
[2022-06-09 17:01:04,318][root][INFO] - Step 37575680 @ 3069.5 SPS. Inference batcher size: 85. Learner queue size: 64. Other stats: (train_seconds = 1.2027e+04, step = 37575680, mean_episode_return = None, mean_episode_step = 2080.4, total_loss = 11.133, pg_loss = 5.8127, baseline_loss = 19.271, entropy_loss = -13.95, learner_queue_size = 64, _tick = 5692, _time = 1.6548e+09)
[2022-06-09 17:01:09,322][root][INFO] - Step 37591040 @ 3069.5 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 1.2032e+04, step = 37591040, mean_episode_return = None, mean_episode_step = 2030.4, total_loss = 82.952, pg_loss = 72.94, baseline_loss = 24.189, entropy_loss = -14.177, learner_queue_size = 64, _tick = 5694, _time = 1.6548e+09)
[2022-06-09 17:01:14,326][root][INFO] - Step 37606400 @ 3069.5 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 1.2037e+04, step = 37606400, mean_episode_return = 34.486, mean_episode_step = 2242.5, total_loss = -46.148, pg_loss = -49.625, baseline_loss = 17.569, entropy_loss = -14.092, learner_queue_size = 64, _tick = 5697, _time = 1.6548e+09)
[2022-06-09 17:01:19,330][root][INFO] - Step 37621760 @ 3069.6 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 1.2042e+04, step = 37621760, mean_episode_return = None, mean_episode_step = 2044.3, total_loss = 215.72, pg_loss = 191.62, baseline_loss = 38.299, entropy_loss = -14.203, learner_queue_size = 64, _tick = 5698, _time = 1.6548e+09)
[2022-06-09 17:01:24,334][root][INFO] - Step 37637120 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.2047e+04, step = 37637120, mean_episode_return = None, mean_episode_step = 2159.6, total_loss = 122.3, pg_loss = 100.16, baseline_loss = 36.33, entropy_loss = -14.187, learner_queue_size = 64, _tick = 5699, _time = 1.6548e+09)
[2022-06-09 17:01:29,338][root][INFO] - Step 37652480 @ 3069.5 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 1.2052e+04, step = 37652480, mean_episode_return = 44.682, mean_episode_step = 2045.4, total_loss = -20.843, pg_loss = -44.29, baseline_loss = 37.69, entropy_loss = -14.243, learner_queue_size = 64, _tick = 5702, _time = 1.6548e+09)
[2022-06-09 17:01:34,346][root][INFO] - Step 37667840 @ 3067.1 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.2057e+04, step = 37667840, mean_episode_return = 67.239, mean_episode_step = 2366.2, total_loss = -181.02, pg_loss = -185.87, baseline_loss = 18.953, entropy_loss = -14.103, learner_queue_size = 64, _tick = 5705, _time = 1.6548e+09)
[2022-06-09 17:01:39,350][root][INFO] - Step 37683200 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.2062e+04, step = 37683200, mean_episode_return = 41.76, mean_episode_step = 1897.1, total_loss = -166.58, pg_loss = -172.41, baseline_loss = 19.975, entropy_loss = -14.14, learner_queue_size = 64, _tick = 5708, _time = 1.6548e+09)
[2022-06-09 17:01:44,354][root][INFO] - Step 37698560 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.2067e+04, step = 37698560, mean_episode_return = 98.996, mean_episode_step = 2036.8, total_loss = -32.842, pg_loss = -36.819, baseline_loss = 18.116, entropy_loss = -14.139, learner_queue_size = 64, _tick = 5711, _time = 1.6548e+09)
[2022-06-09 17:01:49,358][root][INFO] - Step 37713920 @ 3069.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.2072e+04, step = 37713920, mean_episode_return = -5.3703, mean_episode_step = 2011.6, total_loss = 225.41, pg_loss = 164.97, baseline_loss = 74.867, entropy_loss = -14.428, learner_queue_size = 64, _tick = 5714, _time = 1.6548e+09)
[2022-06-09 17:01:54,362][root][INFO] - Step 37729280 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.2077e+04, step = 37729280, mean_episode_return = None, mean_episode_step = 2445.5, total_loss = -209.96, pg_loss = -196.79, baseline_loss = 1.5224, entropy_loss = -14.696, learner_queue_size = 64, _tick = 5716, _time = 1.6548e+09)
[2022-06-09 17:01:59,367][root][INFO] - Step 37744640 @ 3068.9 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.2082e+04, step = 37744640, mean_episode_return = -4.8203, mean_episode_step = 2072.5, total_loss = -102.92, pg_loss = -101.65, baseline_loss = 13.45, entropy_loss = -14.722, learner_queue_size = 64, _tick = 5719, _time = 1.6548e+09)
[2022-06-09 17:02:04,370][root][INFO] - Step 37765120 @ 4093.6 SPS. Inference batcher size: 85. Learner queue size: 64. Other stats: (train_seconds = 1.2087e+04, step = 37765120, mean_episode_return = 6.6772, mean_episode_step = 2320.1, total_loss = -140.14, pg_loss = -147.18, baseline_loss = 21.806, entropy_loss = -14.764, learner_queue_size = 64, _tick = 5722, _time = 1.6548e+09)
[2022-06-09 17:02:09,374][root][INFO] - Step 37780480 @ 3069.6 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.2092e+04, step = 37780480, mean_episode_return = 99.695, mean_episode_step = 2314.5, total_loss = -57.185, pg_loss = -69.327, baseline_loss = 26.707, entropy_loss = -14.565, learner_queue_size = 64, _tick = 5725, _time = 1.6548e+09)
[2022-06-09 17:02:14,378][root][INFO] - Step 37795840 @ 3069.5 SPS. Inference batcher size: 68. Learner queue size: 64. Other stats: (train_seconds = 1.2097e+04, step = 37795840, mean_episode_return = 44.5, mean_episode_step = 1941.0, total_loss = 96.882, pg_loss = 64.705, baseline_loss = 46.777, entropy_loss = -14.6, learner_queue_size = 64, _tick = 5728, _time = 1.6548e+09)
[2022-06-09 17:02:19,382][root][INFO] - Step 37811200 @ 3069.6 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.2102e+04, step = 37811200, mean_episode_return = 83.437, mean_episode_step = 1881.3, total_loss = -144.97, pg_loss = -147.25, baseline_loss = 16.892, entropy_loss = -14.61, learner_queue_size = 64, _tick = 5731, _time = 1.6548e+09)
[2022-06-09 17:02:24,386][root][INFO] - Step 37826560 @ 3069.6 SPS. Inference batcher size: 9. Learner queue size: 64. Other stats: (train_seconds = 1.2107e+04, step = 37826560, mean_episode_return = 72.681, mean_episode_step = 1944.5, total_loss = 19.506, pg_loss = 10.339, baseline_loss = 23.832, entropy_loss = -14.665, learner_queue_size = 64, _tick = 5733, _time = 1.6548e+09)
[2022-06-09 17:02:29,390][root][INFO] - Step 37841920 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.2112e+04, step = 37841920, mean_episode_return = 91.735, mean_episode_step = 2077.2, total_loss = 47.637, pg_loss = 31.539, baseline_loss = 30.616, entropy_loss = -14.519, learner_queue_size = 64, _tick = 5736, _time = 1.6548e+09)
[2022-06-09 17:02:34,394][root][INFO] - Step 37857280 @ 3069.6 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 1.2117e+04, step = 37857280, mean_episode_return = 80.979, mean_episode_step = 2180.7, total_loss = -158.31, pg_loss = -155.29, baseline_loss = 11.492, entropy_loss = -14.513, learner_queue_size = 64, _tick = 5739, _time = 1.6548e+09)
[2022-06-09 17:02:39,398][root][INFO] - Step 37872640 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.2122e+04, step = 37872640, mean_episode_return = None, mean_episode_step = 1916.8, total_loss = -47.187, pg_loss = -45.767, baseline_loss = 13.278, entropy_loss = -14.698, learner_queue_size = 64, _tick = 5741, _time = 1.6548e+09)
[2022-06-09 17:02:44,402][root][INFO] - Step 37888000 @ 3069.5 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.2127e+04, step = 37888000, mean_episode_return = 76.625, mean_episode_step = 2284.5, total_loss = -93.375, pg_loss = -99.373, baseline_loss = 20.528, entropy_loss = -14.531, learner_queue_size = 64, _tick = 5744, _time = 1.6548e+09)
[2022-06-09 17:02:49,406][root][INFO] - Step 37908480 @ 4092.8 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.2132e+04, step = 37908480, mean_episode_return = 37.341, mean_episode_step = 1981.1, total_loss = -118.14, pg_loss = -126.17, baseline_loss = 22.512, entropy_loss = -14.482, learner_queue_size = 64, _tick = 5748, _time = 1.6548e+09)
[2022-06-09 17:02:54,410][root][INFO] - Step 37923840 @ 3069.5 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 1.2137e+04, step = 37923840, mean_episode_return = 73.699, mean_episode_step = 1928.6, total_loss = -232.03, pg_loss = -235.99, baseline_loss = 18.518, entropy_loss = -14.56, learner_queue_size = 64, _tick = 5750, _time = 1.6548e+09)
[2022-06-09 17:02:59,414][root][INFO] - Step 37939200 @ 3069.6 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.2142e+04, step = 37939200, mean_episode_return = 153.68, mean_episode_step = 2122.8, total_loss = 137.8, pg_loss = 110.5, baseline_loss = 41.925, entropy_loss = -14.624, learner_queue_size = 64, _tick = 5753, _time = 1.6548e+09)
[2022-06-09 17:03:04,418][root][INFO] - Step 37954560 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.2147e+04, step = 37954560, mean_episode_return = 28.147, mean_episode_step = 1780.2, total_loss = 393.75, pg_loss = 347.29, baseline_loss = 61.179, entropy_loss = -14.716, learner_queue_size = 64, _tick = 5756, _time = 1.6548e+09)
[2022-06-09 17:03:09,422][root][INFO] - Step 37969920 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.2152e+04, step = 37969920, mean_episode_return = 20.636, mean_episode_step = 2278.9, total_loss = -105.78, pg_loss = -117.24, baseline_loss = 26.074, entropy_loss = -14.612, learner_queue_size = 64, _tick = 5759, _time = 1.6548e+09)
[2022-06-09 17:03:14,426][root][INFO] - Step 37985280 @ 3069.5 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 1.2157e+04, step = 37985280, mean_episode_return = 44.732, mean_episode_step = 2240.4, total_loss = -20.318, pg_loss = -31.586, baseline_loss = 25.816, entropy_loss = -14.547, learner_queue_size = 64, _tick = 5762, _time = 1.6548e+09)
[2022-06-09 17:03:19,430][root][INFO] - Step 38000640 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.2162e+04, step = 38000640, mean_episode_return = 40.502, mean_episode_step = 1768.7, total_loss = 17.79, pg_loss = 6.3277, baseline_loss = 25.987, entropy_loss = -14.526, learner_queue_size = 64, _tick = 5765, _time = 1.6548e+09)
[2022-06-09 17:03:24,434][root][INFO] - Step 38016000 @ 3069.3 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.2167e+04, step = 38016000, mean_episode_return = 104.45, mean_episode_step = 1969.0, total_loss = 108.77, pg_loss = 87.782, baseline_loss = 35.339, entropy_loss = -14.352, learner_queue_size = 64, _tick = 5767, _time = 1.6548e+09)
[2022-06-09 17:03:29,438][root][INFO] - Step 38036480 @ 4093.1 SPS. Inference batcher size: 81. Learner queue size: 64. Other stats: (train_seconds = 1.2172e+04, step = 38036480, mean_episode_return = 20.91, mean_episode_step = 1644.5, total_loss = 37.753, pg_loss = 15.172, baseline_loss = 36.744, entropy_loss = -14.162, learner_queue_size = 64, _tick = 5771, _time = 1.6548e+09)
[2022-06-09 17:03:34,442][root][INFO] - Step 38051840 @ 3069.5 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 1.2177e+04, step = 38051840, mean_episode_return = 71.579, mean_episode_step = 1763.4, total_loss = 67.956, pg_loss = 27.287, baseline_loss = 54.909, entropy_loss = -14.24, learner_queue_size = 64, _tick = 5772, _time = 1.6548e+09)
[2022-06-09 17:03:39,446][root][INFO] - Step 38067200 @ 3069.6 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 1.2182e+04, step = 38067200, mean_episode_return = 102.63, mean_episode_step = 1912.6, total_loss = -80.185, pg_loss = -86.974, baseline_loss = 21.061, entropy_loss = -14.271, learner_queue_size = 64, _tick = 5774, _time = 1.6548e+09)
[2022-06-09 17:03:44,450][root][INFO] - Step 38082560 @ 3069.5 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 1.2187e+04, step = 38082560, mean_episode_return = 27.72, mean_episode_step = 1897.0, total_loss = 70.739, pg_loss = 65.401, baseline_loss = 19.386, entropy_loss = -14.048, learner_queue_size = 64, _tick = 5776, _time = 1.6548e+09)
[2022-06-09 17:03:49,454][root][INFO] - Step 38097920 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.2192e+04, step = 38097920, mean_episode_return = None, mean_episode_step = 2150.0, total_loss = 188.86, pg_loss = 172.06, baseline_loss = 30.966, entropy_loss = -14.158, learner_queue_size = 64, _tick = 5776, _time = 1.6548e+09)
[2022-06-09 17:03:54,458][root][INFO] - Step 38113280 @ 3069.6 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.2197e+04, step = 38113280, mean_episode_return = 61.086, mean_episode_step = 1952.7, total_loss = 45.185, pg_loss = 27.214, baseline_loss = 32.283, entropy_loss = -14.312, learner_queue_size = 64, _tick = 5779, _time = 1.6548e+09)
[2022-06-09 17:03:59,462][root][INFO] - Step 38128640 @ 3069.3 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.2202e+04, step = 38128640, mean_episode_return = 25.201, mean_episode_step = 1874.1, total_loss = 42.518, pg_loss = 21.981, baseline_loss = 34.751, entropy_loss = -14.214, learner_queue_size = 64, _tick = 5782, _time = 1.6548e+09)
[2022-06-09 17:04:04,466][root][INFO] - Step 38144000 @ 3069.7 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.2207e+04, step = 38144000, mean_episode_return = 65.767, mean_episode_step = 2064.9, total_loss = 61.857, pg_loss = 27.32, baseline_loss = 48.71, entropy_loss = -14.173, learner_queue_size = 64, _tick = 5785, _time = 1.6548e+09)
[2022-06-09 17:04:09,470][root][INFO] - Step 38164480 @ 4092.8 SPS. Inference batcher size: 94. Learner queue size: 64. Other stats: (train_seconds = 1.2212e+04, step = 38164480, mean_episode_return = 137.38, mean_episode_step = 2107.4, total_loss = 25.297, pg_loss = 4.1034, baseline_loss = 35.448, entropy_loss = -14.254, learner_queue_size = 64, _tick = 5788, _time = 1.6548e+09)
[2022-06-09 17:04:14,475][root][INFO] - Step 38179840 @ 3068.8 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 1.2217e+04, step = 38179840, mean_episode_return = 15.138, mean_episode_step = 2278.2, total_loss = -14.045, pg_loss = -25.098, baseline_loss = 25.214, entropy_loss = -14.161, learner_queue_size = 64, _tick = 5790, _time = 1.6548e+09)
[2022-06-09 17:04:19,480][root][INFO] - Step 38195200 @ 3069.3 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 1.2222e+04, step = 38195200, mean_episode_return = 97.047, mean_episode_step = 1926.1, total_loss = -1.7273, pg_loss = -19.37, baseline_loss = 31.924, entropy_loss = -14.281, learner_queue_size = 64, _tick = 5793, _time = 1.6548e+09)
[2022-06-09 17:04:24,486][root][INFO] - Step 38210560 @ 3068.2 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 1.2227e+04, step = 38210560, mean_episode_return = 68.489, mean_episode_step = 1902.0, total_loss = -80.256, pg_loss = -84.164, baseline_loss = 18.192, entropy_loss = -14.284, learner_queue_size = 64, _tick = 5795, _time = 1.6548e+09)
[2022-06-09 17:04:29,490][root][INFO] - Step 38225920 @ 3069.4 SPS. Inference batcher size: 75. Learner queue size: 64. Other stats: (train_seconds = 1.2232e+04, step = 38225920, mean_episode_return = 112.96, mean_episode_step = 2052.1, total_loss = -86.035, pg_loss = -85.386, baseline_loss = 13.597, entropy_loss = -14.247, learner_queue_size = 64, _tick = 5798, _time = 1.6548e+09)
[2022-06-09 17:04:34,494][root][INFO] - Step 38241280 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.2237e+04, step = 38241280, mean_episode_return = 26.77, mean_episode_step = 1826.4, total_loss = -8.5712, pg_loss = -19.022, baseline_loss = 24.816, entropy_loss = -14.365, learner_queue_size = 64, _tick = 5800, _time = 1.6548e+09)
[2022-06-09 17:04:39,498][root][INFO] - Step 38256640 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.2242e+04, step = 38256640, mean_episode_return = None, mean_episode_step = 2060.3, total_loss = 173.37, pg_loss = 155.79, baseline_loss = 31.976, entropy_loss = -14.397, learner_queue_size = 64, _tick = 5802, _time = 1.6548e+09)
[2022-06-09 17:04:44,502][root][INFO] - Step 38272000 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.2247e+04, step = 38272000, mean_episode_return = 39.771, mean_episode_step = 1971.6, total_loss = 291.48, pg_loss = 248.55, baseline_loss = 57.209, entropy_loss = -14.281, learner_queue_size = 64, _tick = 5804, _time = 1.6548e+09)
[2022-06-09 17:04:49,506][root][INFO] - Step 38287360 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.2252e+04, step = 38287360, mean_episode_return = 21.09, mean_episode_step = 1857.0, total_loss = 188.47, pg_loss = 155.99, baseline_loss = 46.731, entropy_loss = -14.243, learner_queue_size = 64, _tick = 5807, _time = 1.6548e+09)
[2022-06-09 17:04:54,509][root][INFO] - Step 38307840 @ 4093.4 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 1.2257e+04, step = 38307840, mean_episode_return = 74.063, mean_episode_step = 1920.7, total_loss = -97.616, pg_loss = -119.27, baseline_loss = 35.788, entropy_loss = -14.134, learner_queue_size = 64, _tick = 5810, _time = 1.6548e+09)
[2022-06-09 17:04:59,514][root][INFO] - Step 38323200 @ 3069.1 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 1.2262e+04, step = 38323200, mean_episode_return = 37.591, mean_episode_step = 1758.9, total_loss = -51.743, pg_loss = -70.524, baseline_loss = 32.91, entropy_loss = -14.129, learner_queue_size = 64, _tick = 5813, _time = 1.6548e+09)
[2022-06-09 17:05:04,519][root][INFO] - Step 38338560 @ 3069.1 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 1.2268e+04, step = 38338560, mean_episode_return = -3.4453, mean_episode_step = 1969.8, total_loss = 75.948, pg_loss = 60.397, baseline_loss = 29.713, entropy_loss = -14.162, learner_queue_size = 64, _tick = 5816, _time = 1.6548e+09)
[2022-06-09 17:05:09,522][root][INFO] - Step 38353920 @ 3069.9 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.2272e+04, step = 38353920, mean_episode_return = 38.575, mean_episode_step = 1807.2, total_loss = 30.651, pg_loss = -13.223, baseline_loss = 57.959, entropy_loss = -14.086, learner_queue_size = 64, _tick = 5819, _time = 1.6548e+09)
[2022-06-09 17:05:14,526][root][INFO] - Step 38369280 @ 3069.5 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 1.2278e+04, step = 38369280, mean_episode_return = 48.036, mean_episode_step = 2036.0, total_loss = 30.036, pg_loss = 18.546, baseline_loss = 25.582, entropy_loss = -14.093, learner_queue_size = 64, _tick = 5822, _time = 1.6548e+09)
[2022-06-09 17:05:19,530][root][INFO] - Step 38384640 @ 3069.6 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.2282e+04, step = 38384640, mean_episode_return = 79.117, mean_episode_step = 1958.8, total_loss = 265.02, pg_loss = 220.35, baseline_loss = 58.759, entropy_loss = -14.088, learner_queue_size = 64, _tick = 5825, _time = 1.6548e+09)
[2022-06-09 17:05:24,534][root][INFO] - Step 38400000 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.2288e+04, step = 38400000, mean_episode_return = None, mean_episode_step = 1985.7, total_loss = -14.972, pg_loss = -16.676, baseline_loss = 15.75, entropy_loss = -14.045, learner_queue_size = 64, _tick = 5827, _time = 1.6548e+09)
[2022-06-09 17:05:29,538][root][INFO] - Step 38415360 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.2292e+04, step = 38415360, mean_episode_return = None, mean_episode_step = 1959.4, total_loss = 71.692, pg_loss = 57.806, baseline_loss = 28.225, entropy_loss = -14.339, learner_queue_size = 64, _tick = 5829, _time = 1.6548e+09)
[2022-06-09 17:05:34,542][root][INFO] - Step 38430720 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.2298e+04, step = 38430720, mean_episode_return = 79.312, mean_episode_step = 2176.2, total_loss = -59.715, pg_loss = -65.978, baseline_loss = 20.83, entropy_loss = -14.567, learner_queue_size = 64, _tick = 5832, _time = 1.6548e+09)
[2022-06-09 17:05:39,546][root][INFO] - Step 38446080 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.2302e+04, step = 38446080, mean_episode_return = 13.52, mean_episode_step = 1941.7, total_loss = -11.619, pg_loss = -23.97, baseline_loss = 27.095, entropy_loss = -14.745, learner_queue_size = 64, _tick = 5834, _time = 1.6548e+09)
[2022-06-09 17:05:44,552][root][INFO] - Step 38461440 @ 3068.2 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.2308e+04, step = 38461440, mean_episode_return = 30.651, mean_episode_step = 1894.5, total_loss = -266.82, pg_loss = -261.96, baseline_loss = 9.6748, entropy_loss = -14.531, learner_queue_size = 64, _tick = 5837, _time = 1.6548e+09)
[2022-06-09 17:05:49,558][root][INFO] - Step 38481920 @ 4091.2 SPS. Inference batcher size: 18. Learner queue size: 64. Other stats: (train_seconds = 1.2312e+04, step = 38481920, mean_episode_return = 118.52, mean_episode_step = 1811.6, total_loss = 53.526, pg_loss = 28.96, baseline_loss = 39.138, entropy_loss = -14.571, learner_queue_size = 64, _tick = 5841, _time = 1.6548e+09)
[2022-06-09 17:05:54,562][root][INFO] - Step 38497280 @ 3069.6 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.2318e+04, step = 38497280, mean_episode_return = None, mean_episode_step = 1776.2, total_loss = -30.583, pg_loss = -33.904, baseline_loss = 18.016, entropy_loss = -14.695, learner_queue_size = 64, _tick = 5843, _time = 1.6548e+09)
[2022-06-09 17:05:59,566][root][INFO] - Step 38512640 @ 3069.5 SPS. Inference batcher size: 71. Learner queue size: 64. Other stats: (train_seconds = 1.2322e+04, step = 38512640, mean_episode_return = 55.374, mean_episode_step = 1568.8, total_loss = 16.866, pg_loss = 5.9067, baseline_loss = 25.591, entropy_loss = -14.632, learner_queue_size = 64, _tick = 5846, _time = 1.6548e+09)
[2022-06-09 17:06:04,570][root][INFO] - Step 38528000 @ 3069.6 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 1.2328e+04, step = 38528000, mean_episode_return = 47.425, mean_episode_step = 1621.2, total_loss = -56.32, pg_loss = -63.573, baseline_loss = 21.926, entropy_loss = -14.673, learner_queue_size = 64, _tick = 5849, _time = 1.6548e+09)
[2022-06-09 17:06:09,574][root][INFO] - Step 38543360 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.2332e+04, step = 38543360, mean_episode_return = 48.038, mean_episode_step = 1851.6, total_loss = -51.836, pg_loss = -70.186, baseline_loss = 33.116, entropy_loss = -14.765, learner_queue_size = 64, _tick = 5851, _time = 1.6548e+09)
[2022-06-09 17:06:14,578][root][INFO] - Step 38558720 @ 3069.6 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.2338e+04, step = 38558720, mean_episode_return = 85.788, mean_episode_step = 1547.9, total_loss = -50.551, pg_loss = -55.839, baseline_loss = 19.864, entropy_loss = -14.577, learner_queue_size = 64, _tick = 5854, _time = 1.6548e+09)
[2022-06-09 17:06:19,582][root][INFO] - Step 38574080 @ 3069.6 SPS. Inference batcher size: 6. Learner queue size: 64. Other stats: (train_seconds = 1.2342e+04, step = 38574080, mean_episode_return = -23.69, mean_episode_step = 1658.0, total_loss = 476.58, pg_loss = 411.69, baseline_loss = 79.474, entropy_loss = -14.591, learner_queue_size = 64, _tick = 5857, _time = 1.6548e+09)
[2022-06-09 17:06:24,588][root][INFO] - Step 38589440 @ 3068.1 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.2348e+04, step = 38589440, mean_episode_return = 56.493, mean_episode_step = 1554.3, total_loss = 65.716, pg_loss = 39.553, baseline_loss = 40.796, entropy_loss = -14.634, learner_queue_size = 64, _tick = 5860, _time = 1.6548e+09)
[2022-06-09 17:06:29,594][root][INFO] - Step 38609920 @ 4091.3 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 1.2352e+04, step = 38609920, mean_episode_return = 24.53, mean_episode_step = 1811.1, total_loss = 72.675, pg_loss = 43.605, baseline_loss = 43.481, entropy_loss = -14.411, learner_queue_size = 64, _tick = 5863, _time = 1.6548e+09)
[2022-06-09 17:06:34,598][root][INFO] - Step 38625280 @ 3069.6 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.2358e+04, step = 38625280, mean_episode_return = 24.531, mean_episode_step = 1961.4, total_loss = 540.2, pg_loss = 470.63, baseline_loss = 83.92, entropy_loss = -14.354, learner_queue_size = 64, _tick = 5865, _time = 1.6548e+09)
[2022-06-09 17:06:39,604][root][INFO] - Step 38640640 @ 3068.2 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.2362e+04, step = 38640640, mean_episode_return = 23.0, mean_episode_step = 1758.8, total_loss = -200.97, pg_loss = -191.77, baseline_loss = 5.0136, entropy_loss = -14.216, learner_queue_size = 64, _tick = 5868, _time = 1.6548e+09)
[2022-06-09 17:06:44,610][root][INFO] - Step 38656000 @ 3068.4 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.2368e+04, step = 38656000, mean_episode_return = 54.478, mean_episode_step = 2062.7, total_loss = -150.34, pg_loss = -146.81, baseline_loss = 10.738, entropy_loss = -14.268, learner_queue_size = 64, _tick = 5871, _time = 1.6548e+09)
[2022-06-09 17:06:49,614][root][INFO] - Step 38671360 @ 3069.6 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 1.2372e+04, step = 38671360, mean_episode_return = None, mean_episode_step = 1915.3, total_loss = 66.433, pg_loss = 54.553, baseline_loss = 26.396, entropy_loss = -14.516, learner_queue_size = 64, _tick = 5872, _time = 1.6548e+09)
[2022-06-09 17:06:54,618][root][INFO] - Step 38686720 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.2378e+04, step = 38686720, mean_episode_return = None, mean_episode_step = 1918.2, total_loss = 257.58, pg_loss = 231.32, baseline_loss = 40.864, entropy_loss = -14.598, learner_queue_size = 64, _tick = 5873, _time = 1.6548e+09)
[2022-06-09 17:06:59,625][root][INFO] - Step 38702080 @ 3067.6 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.2383e+04, step = 38702080, mean_episode_return = 25.72, mean_episode_step = 2321.1, total_loss = -75.224, pg_loss = -82.028, baseline_loss = 21.353, entropy_loss = -14.549, learner_queue_size = 64, _tick = 5874, _time = 1.6548e+09)
[2022-06-09 17:07:04,630][root][INFO] - Step 38722560 @ 4092.1 SPS. Inference batcher size: 72. Learner queue size: 64. Other stats: (train_seconds = 1.2388e+04, step = 38722560, mean_episode_return = -3.9107, mean_episode_step = 2103.3, total_loss = -10.733, pg_loss = -24.603, baseline_loss = 28.461, entropy_loss = -14.591, learner_queue_size = 64, _tick = 5878, _time = 1.6548e+09)
[2022-06-09 17:07:09,636][root][INFO] - Step 38737920 @ 3068.5 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 1.2393e+04, step = 38737920, mean_episode_return = 48.188, mean_episode_step = 2005.4, total_loss = -121.22, pg_loss = -126.97, baseline_loss = 20.133, entropy_loss = -14.389, learner_queue_size = 64, _tick = 5881, _time = 1.6548e+09)
[2022-06-09 17:07:14,638][root][INFO] - Step 38753280 @ 3070.4 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 1.2398e+04, step = 38753280, mean_episode_return = 63.183, mean_episode_step = 1971.1, total_loss = 534.43, pg_loss = 459.12, baseline_loss = 89.67, entropy_loss = -14.356, learner_queue_size = 64, _tick = 5883, _time = 1.6548e+09)
[2022-06-09 17:07:19,642][root][INFO] - Step 38768640 @ 3069.7 SPS. Inference batcher size: 94. Learner queue size: 64. Other stats: (train_seconds = 1.2403e+04, step = 38768640, mean_episode_return = 55.741, mean_episode_step = 1917.9, total_loss = 285.49, pg_loss = 234.67, baseline_loss = 65.052, entropy_loss = -14.229, learner_queue_size = 64, _tick = 5886, _time = 1.6548e+09)
[2022-06-09 17:07:24,649][root][INFO] - Step 38784000 @ 3067.4 SPS. Inference batcher size: 120. Learner queue size: 64. Other stats: (train_seconds = 1.2408e+04, step = 38784000, mean_episode_return = 13.166, mean_episode_step = 2135.9, total_loss = 87.669, pg_loss = 68.408, baseline_loss = 33.392, entropy_loss = -14.13, learner_queue_size = 64, _tick = 5889, _time = 1.6548e+09)
[2022-06-09 17:07:29,654][root][INFO] - Step 38799360 @ 3069.1 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 1.2413e+04, step = 38799360, mean_episode_return = 31.934, mean_episode_step = 1824.8, total_loss = -236.97, pg_loss = -235.4, baseline_loss = 12.538, entropy_loss = -14.107, learner_queue_size = 64, _tick = 5891, _time = 1.6548e+09)
[2022-06-09 17:07:34,658][root][INFO] - Step 38814720 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.2418e+04, step = 38814720, mean_episode_return = None, mean_episode_step = 2032.6, total_loss = 459.37, pg_loss = 408.47, baseline_loss = 65.086, entropy_loss = -14.188, learner_queue_size = 64, _tick = 5891, _time = 1.6548e+09)
[2022-06-09 17:07:39,662][root][INFO] - Step 38830080 @ 3069.5 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.2423e+04, step = 38830080, mean_episode_return = 69.24, mean_episode_step = 1870.0, total_loss = 441.06, pg_loss = 376.13, baseline_loss = 79.086, entropy_loss = -14.159, learner_queue_size = 64, _tick = 5894, _time = 1.6548e+09)
[2022-06-09 17:07:44,666][root][INFO] - Step 38845440 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.2428e+04, step = 38845440, mean_episode_return = None, mean_episode_step = 2168.1, total_loss = -217.36, pg_loss = -207.85, baseline_loss = 4.5384, entropy_loss = -14.054, learner_queue_size = 64, _tick = 5896, _time = 1.6548e+09)
[2022-06-09 17:07:49,670][root][INFO] - Step 38860800 @ 3069.6 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.2433e+04, step = 38860800, mean_episode_return = 90.18, mean_episode_step = 2183.8, total_loss = 49.917, pg_loss = 39.899, baseline_loss = 24.313, entropy_loss = -14.296, learner_queue_size = 64, _tick = 5899, _time = 1.6548e+09)
[2022-06-09 17:07:54,675][root][INFO] - Step 38881280 @ 4091.5 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 1.2438e+04, step = 38881280, mean_episode_return = None, mean_episode_step = 2241.9, total_loss = -49.454, pg_loss = -46.655, baseline_loss = 11.278, entropy_loss = -14.078, learner_queue_size = 64, _tick = 5900, _time = 1.6548e+09)
[2022-06-09 17:07:59,678][root][INFO] - Step 38896640 @ 3070.4 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 1.2443e+04, step = 38896640, mean_episode_return = 54.91, mean_episode_step = 2211.5, total_loss = 33.212, pg_loss = 9.9181, baseline_loss = 37.565, entropy_loss = -14.271, learner_queue_size = 64, _tick = 5903, _time = 1.6548e+09)
[2022-06-09 17:08:04,682][root][INFO] - Step 38912000 @ 3069.6 SPS. Inference batcher size: 76. Learner queue size: 64. Other stats: (train_seconds = 1.2448e+04, step = 38912000, mean_episode_return = None, mean_episode_step = 2452.0, total_loss = 70.695, pg_loss = 48.962, baseline_loss = 36.058, entropy_loss = -14.324, learner_queue_size = 64, _tick = 5905, _time = 1.6548e+09)
[2022-06-09 17:08:09,697][root][INFO] - Step 38927360 @ 3063.1 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.2453e+04, step = 38927360, mean_episode_return = -2.9105, mean_episode_step = 2153.4, total_loss = -16.095, pg_loss = -27.591, baseline_loss = 25.971, entropy_loss = -14.475, learner_queue_size = 64, _tick = 5908, _time = 1.6548e+09)
[2022-06-09 17:08:14,702][root][INFO] - Step 38942720 @ 3068.7 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.2458e+04, step = 38942720, mean_episode_return = 55.381, mean_episode_step = 2356.6, total_loss = -157.1, pg_loss = -155.95, baseline_loss = 13.498, entropy_loss = -14.647, learner_queue_size = 64, _tick = 5911, _time = 1.6548e+09)
[2022-06-09 17:08:19,706][root][INFO] - Step 38958080 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.2463e+04, step = 38958080, mean_episode_return = 52.361, mean_episode_step = 2087.2, total_loss = 36.671, pg_loss = 21.606, baseline_loss = 29.551, entropy_loss = -14.485, learner_queue_size = 64, _tick = 5913, _time = 1.6548e+09)
[2022-06-09 17:08:24,710][root][INFO] - Step 38973440 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.2468e+04, step = 38973440, mean_episode_return = None, mean_episode_step = 2408.2, total_loss = -201.09, pg_loss = -190.58, baseline_loss = 4.1864, entropy_loss = -14.693, learner_queue_size = 64, _tick = 5914, _time = 1.6548e+09)
[2022-06-09 17:08:29,714][root][INFO] - Step 38988800 @ 3069.5 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 1.2473e+04, step = 38988800, mean_episode_return = None, mean_episode_step = 2642.8, total_loss = -3.9641, pg_loss = -5.6093, baseline_loss = 16.235, entropy_loss = -14.59, learner_queue_size = 64, _tick = 5916, _time = 1.6548e+09)
[2022-06-09 17:08:34,718][root][INFO] - Step 39009280 @ 4092.7 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 1.2478e+04, step = 39009280, mean_episode_return = 22.507, mean_episode_step = 1993.0, total_loss = -16.23, pg_loss = -30.787, baseline_loss = 29.078, entropy_loss = -14.521, learner_queue_size = 64, _tick = 5919, _time = 1.6548e+09)
[2022-06-09 17:08:39,724][root][INFO] - Step 39024640 @ 3068.3 SPS. Inference batcher size: 72. Learner queue size: 64. Other stats: (train_seconds = 1.2483e+04, step = 39024640, mean_episode_return = 22.686, mean_episode_step = 2359.3, total_loss = -196.01, pg_loss = -194.11, baseline_loss = 12.574, entropy_loss = -14.473, learner_queue_size = 64, _tick = 5922, _time = 1.6548e+09)
[2022-06-09 17:08:44,730][root][INFO] - Step 39040000 @ 3068.4 SPS. Inference batcher size: 10. Learner queue size: 64. Other stats: (train_seconds = 1.2488e+04, step = 39040000, mean_episode_return = -34.098, mean_episode_step = 2607.7, total_loss = -186.25, pg_loss = -177.6, baseline_loss = 5.5013, entropy_loss = -14.154, learner_queue_size = 64, _tick = 5925, _time = 1.6548e+09)
[2022-06-09 17:08:49,734][root][INFO] - Step 39055360 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.2493e+04, step = 39055360, mean_episode_return = 12.806, mean_episode_step = 2344.5, total_loss = -127.9, pg_loss = -127.79, baseline_loss = 14.329, entropy_loss = -14.436, learner_queue_size = 64, _tick = 5927, _time = 1.6548e+09)
[2022-06-09 17:08:54,738][root][INFO] - Step 39070720 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.2498e+04, step = 39070720, mean_episode_return = 97.129, mean_episode_step = 2356.3, total_loss = 80.463, pg_loss = 68.76, baseline_loss = 26.24, entropy_loss = -14.536, learner_queue_size = 64, _tick = 5930, _time = 1.6548e+09)
[2022-06-09 17:08:59,742][root][INFO] - Step 39086080 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.2503e+04, step = 39086080, mean_episode_return = None, mean_episode_step = 2203.9, total_loss = 76.754, pg_loss = 67.744, baseline_loss = 23.497, entropy_loss = -14.487, learner_queue_size = 64, _tick = 5932, _time = 1.6548e+09)
[2022-06-09 17:09:04,746][root][INFO] - Step 39101440 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.2508e+04, step = 39101440, mean_episode_return = 21.348, mean_episode_step = 2215.1, total_loss = -242.35, pg_loss = -242.17, baseline_loss = 14.098, entropy_loss = -14.282, learner_queue_size = 64, _tick = 5934, _time = 1.6548e+09)
[2022-06-09 17:09:09,752][root][INFO] - Step 39116800 @ 3068.3 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.2513e+04, step = 39116800, mean_episode_return = 52.291, mean_episode_step = 2599.4, total_loss = 193.57, pg_loss = 162.97, baseline_loss = 45.19, entropy_loss = -14.593, learner_queue_size = 64, _tick = 5937, _time = 1.6548e+09)
[2022-06-09 17:09:14,758][root][INFO] - Step 39132160 @ 3068.4 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 1.2518e+04, step = 39132160, mean_episode_return = 31.842, mean_episode_step = 2081.8, total_loss = -146.62, pg_loss = -140.33, baseline_loss = 8.3865, entropy_loss = -14.676, learner_queue_size = 64, _tick = 5938, _time = 1.6548e+09)
[2022-06-09 17:09:19,762][root][INFO] - Step 39152640 @ 4092.7 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.2523e+04, step = 39152640, mean_episode_return = -0.62035, mean_episode_step = 2277.2, total_loss = -71.217, pg_loss = -70.525, baseline_loss = 14.208, entropy_loss = -14.9, learner_queue_size = 64, _tick = 5942, _time = 1.6548e+09)
[2022-06-09 17:09:24,768][root][INFO] - Step 39168000 @ 3068.3 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.2528e+04, step = 39168000, mean_episode_return = None, mean_episode_step = 2441.1, total_loss = 40.912, pg_loss = 36.224, baseline_loss = 19.662, entropy_loss = -14.974, learner_queue_size = 64, _tick = 5944, _time = 1.6548e+09)
[2022-06-09 17:09:29,774][root][INFO] - Step 39183360 @ 3068.3 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.2533e+04, step = 39183360, mean_episode_return = 53.475, mean_episode_step = 2560.5, total_loss = 191.15, pg_loss = 158.77, baseline_loss = 47.424, entropy_loss = -15.04, learner_queue_size = 64, _tick = 5947, _time = 1.6548e+09)
[2022-06-09 17:09:34,778][root][INFO] - Step 39198720 @ 3069.5 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1.2538e+04, step = 39198720, mean_episode_return = 35.505, mean_episode_step = 1898.0, total_loss = 204.78, pg_loss = 166.07, baseline_loss = 53.641, entropy_loss = -14.925, learner_queue_size = 64, _tick = 5950, _time = 1.6548e+09)
[2022-06-09 17:09:39,782][root][INFO] - Step 39214080 @ 3069.6 SPS. Inference batcher size: 2. Learner queue size: 64. Other stats: (train_seconds = 1.2543e+04, step = 39214080, mean_episode_return = None, mean_episode_step = 2313.9, total_loss = 125.92, pg_loss = 108.16, baseline_loss = 32.435, entropy_loss = -14.676, learner_queue_size = 64, _tick = 5952, _time = 1.6548e+09)
[2022-06-09 17:09:44,786][root][INFO] - Step 39229440 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.2548e+04, step = 39229440, mean_episode_return = None, mean_episode_step = 2405.3, total_loss = -9.344, pg_loss = -14.817, baseline_loss = 20.277, entropy_loss = -14.804, learner_queue_size = 64, _tick = 5954, _time = 1.6548e+09)
[2022-06-09 17:09:49,790][root][INFO] - Step 39244800 @ 3069.5 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.2553e+04, step = 39244800, mean_episode_return = 89.388, mean_episode_step = 2407.6, total_loss = 60.636, pg_loss = 50.024, baseline_loss = 25.047, entropy_loss = -14.434, learner_queue_size = 64, _tick = 5957, _time = 1.6548e+09)
[2022-06-09 17:09:54,794][root][INFO] - Step 39265280 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 1.2558e+04, step = 39265280, mean_episode_return = -2.0068, mean_episode_step = 2302.1, total_loss = 188.55, pg_loss = 158.98, baseline_loss = 44.113, entropy_loss = -14.541, learner_queue_size = 64, _tick = 5960, _time = 1.6548e+09)
[2022-06-09 17:09:59,798][root][INFO] - Step 39280640 @ 3069.4 SPS. Inference batcher size: 68. Learner queue size: 64. Other stats: (train_seconds = 1.2563e+04, step = 39280640, mean_episode_return = 60.172, mean_episode_step = 2010.5, total_loss = 223.33, pg_loss = 191.6, baseline_loss = 45.99, entropy_loss = -14.256, learner_queue_size = 64, _tick = 5962, _time = 1.6548e+09)
[2022-06-09 17:10:04,805][root][INFO] - Step 39296000 @ 3068.0 SPS. Inference batcher size: 9. Learner queue size: 64. Other stats: (train_seconds = 1.2568e+04, step = 39296000, mean_episode_return = None, mean_episode_step = 2317.4, total_loss = -77.711, pg_loss = -88.997, baseline_loss = 25.492, entropy_loss = -14.205, learner_queue_size = 64, _tick = 5964, _time = 1.6548e+09)
[2022-06-09 17:10:09,810][root][INFO] - Step 39311360 @ 3068.8 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1.2573e+04, step = 39311360, mean_episode_return = 63.911, mean_episode_step = 2162.3, total_loss = -159.06, pg_loss = -179.54, baseline_loss = 34.646, entropy_loss = -14.164, learner_queue_size = 64, _tick = 5965, _time = 1.6548e+09)
[2022-06-09 17:10:14,814][root][INFO] - Step 39326720 @ 3069.6 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.2578e+04, step = 39326720, mean_episode_return = None, mean_episode_step = 2069.5, total_loss = -8.6368, pg_loss = -16.004, baseline_loss = 21.369, entropy_loss = -14.002, learner_queue_size = 64, _tick = 5966, _time = 1.6548e+09)
[2022-06-09 17:10:19,818][root][INFO] - Step 39342080 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.2583e+04, step = 39342080, mean_episode_return = 79.047, mean_episode_step = 2235.4, total_loss = -226.21, pg_loss = -214.69, baseline_loss = 2.7297, entropy_loss = -14.248, learner_queue_size = 64, _tick = 5968, _time = 1.6548e+09)
[2022-06-09 17:10:24,822][root][INFO] - Step 39357440 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.2588e+04, step = 39357440, mean_episode_return = 75.082, mean_episode_step = 2169.2, total_loss = -55.337, pg_loss = -55.009, baseline_loss = 13.982, entropy_loss = -14.31, learner_queue_size = 64, _tick = 5971, _time = 1.6548e+09)
[2022-06-09 17:10:29,826][root][INFO] - Step 39372800 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.2593e+04, step = 39372800, mean_episode_return = 27.22, mean_episode_step = 1979.1, total_loss = 68.006, pg_loss = 37.369, baseline_loss = 44.904, entropy_loss = -14.268, learner_queue_size = 64, _tick = 5974, _time = 1.6548e+09)
[2022-06-09 17:10:34,830][root][INFO] - Step 39393280 @ 4092.7 SPS. Inference batcher size: 5. Learner queue size: 64. Other stats: (train_seconds = 1.2598e+04, step = 39393280, mean_episode_return = None, mean_episode_step = 2165.4, total_loss = 144.2, pg_loss = 117.06, baseline_loss = 41.39, entropy_loss = -14.251, learner_queue_size = 64, _tick = 5976, _time = 1.6548e+09)
[2022-06-09 17:10:39,834][root][INFO] - Step 39408640 @ 3069.5 SPS. Inference batcher size: 15. Learner queue size: 64. Other stats: (train_seconds = 1.2603e+04, step = 39408640, mean_episode_return = None, mean_episode_step = 2178.7, total_loss = 9.7499, pg_loss = -0.70844, baseline_loss = 24.83, entropy_loss = -14.372, learner_queue_size = 64, _tick = 5977, _time = 1.6548e+09)
[2022-06-09 17:10:44,838][root][INFO] - Step 39424000 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.2608e+04, step = 39424000, mean_episode_return = 11.495, mean_episode_step = 2112.8, total_loss = 5.1259, pg_loss = -37.244, baseline_loss = 56.812, entropy_loss = -14.441, learner_queue_size = 64, _tick = 5980, _time = 1.6548e+09)
[2022-06-09 17:10:49,842][root][INFO] - Step 39439360 @ 3069.6 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 1.2613e+04, step = 39439360, mean_episode_return = 37.183, mean_episode_step = 2163.3, total_loss = 498.17, pg_loss = 328.31, baseline_loss = 184.34, entropy_loss = -14.476, learner_queue_size = 64, _tick = 5982, _time = 1.6548e+09)
[2022-06-09 17:10:54,846][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 17:10:55,058][root][INFO] - Step 39454720 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.2618e+04, step = 39454720, mean_episode_return = 21.867, mean_episode_step = 2168.5, total_loss = -113.87, pg_loss = -117.24, baseline_loss = 17.807, entropy_loss = -14.443, learner_queue_size = 64, _tick = 5985, _time = 1.6548e+09)
[2022-06-09 17:11:00,062][root][INFO] - Step 39470080 @ 2944.8 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 1.2623e+04, step = 39470080, mean_episode_return = -15.081, mean_episode_step = 2193.2, total_loss = -166.98, pg_loss = -164.46, baseline_loss = 11.858, entropy_loss = -14.38, learner_queue_size = 64, _tick = 5987, _time = 1.6548e+09)
[2022-06-09 17:11:05,066][root][INFO] - Step 39485440 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.2628e+04, step = 39485440, mean_episode_return = 105.48, mean_episode_step = 2221.3, total_loss = 75.089, pg_loss = 61.289, baseline_loss = 28.098, entropy_loss = -14.298, learner_queue_size = 64, _tick = 5990, _time = 1.6548e+09)
[2022-06-09 17:11:10,070][root][INFO] - Step 39500800 @ 3069.6 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.2633e+04, step = 39500800, mean_episode_return = 51.25, mean_episode_step = 2096.9, total_loss = 156.32, pg_loss = 126.59, baseline_loss = 43.905, entropy_loss = -14.173, learner_queue_size = 64, _tick = 5993, _time = 1.6548e+09)
[2022-06-09 17:11:15,074][root][INFO] - Step 39516160 @ 3069.6 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.2638e+04, step = 39516160, mean_episode_return = 66.415, mean_episode_step = 2041.4, total_loss = -126.62, pg_loss = -129.57, baseline_loss = 17.371, entropy_loss = -14.42, learner_queue_size = 64, _tick = 5995, _time = 1.6548e+09)
[2022-06-09 17:11:20,080][root][INFO] - Step 39531520 @ 3068.4 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 1.2643e+04, step = 39531520, mean_episode_return = None, mean_episode_step = 1919.5, total_loss = -0.97213, pg_loss = 0.63259, baseline_loss = 13.171, entropy_loss = -14.776, learner_queue_size = 64, _tick = 5997, _time = 1.6548e+09)
[2022-06-09 17:11:25,086][root][INFO] - Step 39546880 @ 3068.3 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1.2648e+04, step = 39546880, mean_episode_return = None, mean_episode_step = 2038.9, total_loss = 65.699, pg_loss = 55.303, baseline_loss = 25.115, entropy_loss = -14.719, learner_queue_size = 64, _tick = 5998, _time = 1.6548e+09)
[2022-06-09 17:11:30,092][root][INFO] - Step 39562240 @ 3068.3 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 1.2653e+04, step = 39562240, mean_episode_return = 2.6095, mean_episode_step = 1905.6, total_loss = 300.05, pg_loss = 238.43, baseline_loss = 76.336, entropy_loss = -14.714, learner_queue_size = 64, _tick = 6001, _time = 1.6548e+09)
[2022-06-09 17:11:35,098][root][INFO] - Step 39577600 @ 3068.3 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.2658e+04, step = 39577600, mean_episode_return = 96.292, mean_episode_step = 1973.9, total_loss = 80.275, pg_loss = 55.921, baseline_loss = 38.737, entropy_loss = -14.383, learner_queue_size = 64, _tick = 6004, _time = 1.6548e+09)
[2022-06-09 17:11:40,102][root][INFO] - Step 39598080 @ 4092.7 SPS. Inference batcher size: 78. Learner queue size: 64. Other stats: (train_seconds = 1.2663e+04, step = 39598080, mean_episode_return = None, mean_episode_step = 2087.5, total_loss = -51.772, pg_loss = -60.1, baseline_loss = 22.727, entropy_loss = -14.399, learner_queue_size = 64, _tick = 6007, _time = 1.6548e+09)
[2022-06-09 17:11:45,106][root][INFO] - Step 39613440 @ 3069.6 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 1.2668e+04, step = 39613440, mean_episode_return = None, mean_episode_step = 1839.6, total_loss = 95.388, pg_loss = 80.117, baseline_loss = 29.689, entropy_loss = -14.419, learner_queue_size = 64, _tick = 6009, _time = 1.6548e+09)
[2022-06-09 17:11:50,112][root][INFO] - Step 39628800 @ 3068.4 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 1.2673e+04, step = 39628800, mean_episode_return = None, mean_episode_step = 1890.2, total_loss = 499.15, pg_loss = 415.86, baseline_loss = 97.588, entropy_loss = -14.298, learner_queue_size = 64, _tick = 6011, _time = 1.6548e+09)
[2022-06-09 17:11:55,114][root][INFO] - Step 39644160 @ 3070.7 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 1.2678e+04, step = 39644160, mean_episode_return = 39.016, mean_episode_step = 1985.1, total_loss = 19.279, pg_loss = -0.25887, baseline_loss = 33.755, entropy_loss = -14.217, learner_queue_size = 64, _tick = 6013, _time = 1.6548e+09)
[2022-06-09 17:12:00,118][root][INFO] - Step 39659520 @ 3069.5 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 1.2683e+04, step = 39659520, mean_episode_return = 69.679, mean_episode_step = 1869.7, total_loss = -126.93, pg_loss = -151.51, baseline_loss = 38.611, entropy_loss = -14.036, learner_queue_size = 64, _tick = 6016, _time = 1.6548e+09)
[2022-06-09 17:12:05,122][root][INFO] - Step 39674880 @ 3069.6 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.2688e+04, step = 39674880, mean_episode_return = -1.64, mean_episode_step = 1814.0, total_loss = 229.3, pg_loss = 194.85, baseline_loss = 48.389, entropy_loss = -13.932, learner_queue_size = 64, _tick = 6017, _time = 1.6548e+09)
[2022-06-09 17:12:10,126][root][INFO] - Step 39690240 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.2693e+04, step = 39690240, mean_episode_return = None, mean_episode_step = 1978.3, total_loss = -210.64, pg_loss = -212.76, baseline_loss = 15.896, entropy_loss = -13.776, learner_queue_size = 64, _tick = 6019, _time = 1.6548e+09)
[2022-06-09 17:12:15,132][root][INFO] - Step 39705600 @ 3068.5 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 1.2698e+04, step = 39705600, mean_episode_return = None, mean_episode_step = 1988.0, total_loss = 103.26, pg_loss = 86.452, baseline_loss = 30.453, entropy_loss = -13.645, learner_queue_size = 64, _tick = 6021, _time = 1.6548e+09)
[2022-06-09 17:12:20,134][root][INFO] - Step 39720960 @ 3070.6 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.2703e+04, step = 39720960, mean_episode_return = 69.059, mean_episode_step = 2047.5, total_loss = 102.71, pg_loss = 80.463, baseline_loss = 35.912, entropy_loss = -13.665, learner_queue_size = 64, _tick = 6022, _time = 1.6548e+09)
[2022-06-09 17:12:25,138][root][INFO] - Step 39736320 @ 3069.5 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 1.2708e+04, step = 39736320, mean_episode_return = 59.982, mean_episode_step = 2096.3, total_loss = -118.77, pg_loss = -139.14, baseline_loss = 34.02, entropy_loss = -13.65, learner_queue_size = 64, _tick = 6025, _time = 1.6548e+09)
[2022-06-09 17:12:30,142][root][INFO] - Step 39751680 @ 3069.6 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.2713e+04, step = 39751680, mean_episode_return = None, mean_episode_step = 1599.8, total_loss = 408.86, pg_loss = 364.29, baseline_loss = 58.438, entropy_loss = -13.865, learner_queue_size = 64, _tick = 6027, _time = 1.6548e+09)
[2022-06-09 17:12:35,146][root][INFO] - Step 39767040 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.2718e+04, step = 39767040, mean_episode_return = None, mean_episode_step = 2413.9, total_loss = 14.931, pg_loss = 16.356, baseline_loss = 12.591, entropy_loss = -14.017, learner_queue_size = 64, _tick = 6028, _time = 1.6548e+09)
[2022-06-09 17:12:40,150][root][INFO] - Step 39787520 @ 4092.6 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.2723e+04, step = 39787520, mean_episode_return = 29.299, mean_episode_step = 1769.6, total_loss = 242.42, pg_loss = 196.74, baseline_loss = 59.831, entropy_loss = -14.153, learner_queue_size = 64, _tick = 6031, _time = 1.6548e+09)
[2022-06-09 17:12:45,154][root][INFO] - Step 39802880 @ 3069.6 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 1.2728e+04, step = 39802880, mean_episode_return = 53.56, mean_episode_step = 1649.8, total_loss = -29.027, pg_loss = -50.216, baseline_loss = 35.262, entropy_loss = -14.073, learner_queue_size = 64, _tick = 6034, _time = 1.6548e+09)
[2022-06-09 17:12:50,158][root][INFO] - Step 39818240 @ 3069.6 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 1.2733e+04, step = 39818240, mean_episode_return = 18.53, mean_episode_step = 1783.2, total_loss = -3.2648, pg_loss = -12.301, baseline_loss = 23.012, entropy_loss = -13.976, learner_queue_size = 64, _tick = 6037, _time = 1.6548e+09)
[2022-06-09 17:12:55,162][root][INFO] - Step 39833600 @ 3069.5 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 1.2738e+04, step = 39833600, mean_episode_return = 34.112, mean_episode_step = 2237.0, total_loss = -54.102, pg_loss = -72.253, baseline_loss = 32.028, entropy_loss = -13.877, learner_queue_size = 64, _tick = 6040, _time = 1.6548e+09)
[2022-06-09 17:13:00,166][root][INFO] - Step 39848960 @ 3069.5 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 1.2743e+04, step = 39848960, mean_episode_return = -9.1959, mean_episode_step = 1877.1, total_loss = 44.526, pg_loss = 6.0332, baseline_loss = 52.49, entropy_loss = -13.998, learner_queue_size = 64, _tick = 6043, _time = 1.6548e+09)
[2022-06-09 17:13:05,171][root][INFO] - Step 39864320 @ 3069.0 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.2748e+04, step = 39864320, mean_episode_return = 36.992, mean_episode_step = 1676.3, total_loss = 566.86, pg_loss = 456.93, baseline_loss = 124.12, entropy_loss = -14.191, learner_queue_size = 64, _tick = 6046, _time = 1.6548e+09)
[2022-06-09 17:13:10,174][root][INFO] - Step 39879680 @ 3070.1 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.2753e+04, step = 39879680, mean_episode_return = 19.96, mean_episode_step = 1670.7, total_loss = 194.48, pg_loss = 162.73, baseline_loss = 45.98, entropy_loss = -14.229, learner_queue_size = 64, _tick = 6049, _time = 1.6548e+09)
[2022-06-09 17:13:15,178][root][INFO] - Step 39895040 @ 3069.6 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.2758e+04, step = 39895040, mean_episode_return = 68.846, mean_episode_step = 1997.3, total_loss = 145.47, pg_loss = 108.55, baseline_loss = 51.229, entropy_loss = -14.312, learner_queue_size = 64, _tick = 6052, _time = 1.6548e+09)
[2022-06-09 17:13:20,182][root][INFO] - Step 39910400 @ 3069.6 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.2763e+04, step = 39910400, mean_episode_return = 27.184, mean_episode_step = 1963.4, total_loss = -416.85, pg_loss = -415.67, baseline_loss = 13.025, entropy_loss = -14.2, learner_queue_size = 64, _tick = 6055, _time = 1.6548e+09)
[2022-06-09 17:13:25,186][root][INFO] - Step 39925760 @ 3069.5 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 1.2768e+04, step = 39925760, mean_episode_return = 14.164, mean_episode_step = 1698.3, total_loss = 78.675, pg_loss = 52.942, baseline_loss = 39.925, entropy_loss = -14.192, learner_queue_size = 64, _tick = 6058, _time = 1.6548e+09)
[2022-06-09 17:13:30,190][root][INFO] - Step 39946240 @ 4092.8 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 1.2773e+04, step = 39946240, mean_episode_return = 88.884, mean_episode_step = 1821.6, total_loss = 879.63, pg_loss = 636.51, baseline_loss = 257.47, entropy_loss = -14.351, learner_queue_size = 64, _tick = 6061, _time = 1.6548e+09)
[2022-06-09 17:13:35,194][root][INFO] - Step 39961600 @ 3069.5 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.2778e+04, step = 39961600, mean_episode_return = 43.09, mean_episode_step = 1898.2, total_loss = 170.04, pg_loss = 125.34, baseline_loss = 59.155, entropy_loss = -14.448, learner_queue_size = 64, _tick = 6064, _time = 1.6548e+09)
[2022-06-09 17:13:40,198][root][INFO] - Step 39976960 @ 3069.6 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 1.2783e+04, step = 39976960, mean_episode_return = 26.61, mean_episode_step = 1994.3, total_loss = 155.56, pg_loss = 131.24, baseline_loss = 38.932, entropy_loss = -14.61, learner_queue_size = 64, _tick = 6067, _time = 1.6548e+09)
[2022-06-09 17:13:45,202][root][INFO] - Step 39992320 @ 3069.5 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 1.2788e+04, step = 39992320, mean_episode_return = 62.389, mean_episode_step = 1877.3, total_loss = -64.385, pg_loss = -82.663, baseline_loss = 32.896, entropy_loss = -14.618, learner_queue_size = 64, _tick = 6070, _time = 1.6548e+09)
[2022-06-09 17:13:50,206][root][INFO] - Step 40007680 @ 3069.5 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 1.2793e+04, step = 40007680, mean_episode_return = 41.138, mean_episode_step = 1648.3, total_loss = -279.63, pg_loss = -300.18, baseline_loss = 35.015, entropy_loss = -14.467, learner_queue_size = 64, _tick = 6073, _time = 1.6548e+09)
[2022-06-09 17:13:55,228][root][INFO] - Step 40023040 @ 3058.8 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 1.2798e+04, step = 40023040, mean_episode_return = -4.3346, mean_episode_step = 1667.9, total_loss = -217.95, pg_loss = -211.47, baseline_loss = 8.1638, entropy_loss = -14.649, learner_queue_size = 64, _tick = 6076, _time = 1.6548e+09)
[2022-06-09 17:14:00,230][root][INFO] - Step 40038400 @ 3070.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.2803e+04, step = 40038400, mean_episode_return = None, mean_episode_step = 1672.7, total_loss = 507.38, pg_loss = 440.14, baseline_loss = 81.918, entropy_loss = -14.684, learner_queue_size = 64, _tick = 6077, _time = 1.6548e+09)
[2022-06-09 17:14:05,234][root][INFO] - Step 40053760 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.2808e+04, step = 40053760, mean_episode_return = 41.541, mean_episode_step = 1860.0, total_loss = -122.14, pg_loss = -132.02, baseline_loss = 24.556, entropy_loss = -14.674, learner_queue_size = 64, _tick = 6079, _time = 1.6548e+09)
[2022-06-09 17:14:10,238][root][INFO] - Step 40069120 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.2813e+04, step = 40069120, mean_episode_return = 76.838, mean_episode_step = 1835.8, total_loss = -84.599, pg_loss = -96.706, baseline_loss = 26.804, entropy_loss = -14.697, learner_queue_size = 64, _tick = 6082, _time = 1.6548e+09)
[2022-06-09 17:14:15,242][root][INFO] - Step 40084480 @ 3069.5 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 1.2818e+04, step = 40084480, mean_episode_return = 52.892, mean_episode_step = 1859.9, total_loss = 69.784, pg_loss = 31.872, baseline_loss = 52.611, entropy_loss = -14.699, learner_queue_size = 64, _tick = 6085, _time = 1.6548e+09)
[2022-06-09 17:14:20,246][root][INFO] - Step 40104960 @ 4092.8 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 1.2823e+04, step = 40104960, mean_episode_return = 98.577, mean_episode_step = 2144.1, total_loss = -9.8397, pg_loss = -16.44, baseline_loss = 21.521, entropy_loss = -14.92, learner_queue_size = 64, _tick = 6089, _time = 1.6548e+09)
[2022-06-09 17:14:25,250][root][INFO] - Step 40120320 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.2828e+04, step = 40120320, mean_episode_return = 33.091, mean_episode_step = 1761.5, total_loss = 388.4, pg_loss = 347.58, baseline_loss = 55.808, entropy_loss = -14.987, learner_queue_size = 64, _tick = 6092, _time = 1.6548e+09)
[2022-06-09 17:14:30,254][root][INFO] - Step 40135680 @ 3069.6 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 1.2833e+04, step = 40135680, mean_episode_return = 141.27, mean_episode_step = 1601.7, total_loss = -182.87, pg_loss = -176.28, baseline_loss = 8.2517, entropy_loss = -14.834, learner_queue_size = 64, _tick = 6095, _time = 1.6548e+09)
[2022-06-09 17:14:35,260][root][INFO] - Step 40151040 @ 3068.1 SPS. Inference batcher size: 68. Learner queue size: 64. Other stats: (train_seconds = 1.2838e+04, step = 40151040, mean_episode_return = 38.36, mean_episode_step = 1915.9, total_loss = 218.34, pg_loss = 191.35, baseline_loss = 41.827, entropy_loss = -14.841, learner_queue_size = 64, _tick = 6098, _time = 1.6548e+09)
[2022-06-09 17:14:40,266][root][INFO] - Step 40166400 @ 3068.5 SPS. Inference batcher size: 18. Learner queue size: 64. Other stats: (train_seconds = 1.2843e+04, step = 40166400, mean_episode_return = -4.74, mean_episode_step = 1874.2, total_loss = -136.55, pg_loss = -138.17, baseline_loss = 16.313, entropy_loss = -14.688, learner_queue_size = 64, _tick = 6100, _time = 1.6548e+09)
[2022-06-09 17:14:45,270][root][INFO] - Step 40181760 @ 3069.6 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 1.2848e+04, step = 40181760, mean_episode_return = None, mean_episode_step = 1930.3, total_loss = -22.874, pg_loss = -28.03, baseline_loss = 19.862, entropy_loss = -14.706, learner_queue_size = 64, _tick = 6102, _time = 1.6548e+09)
[2022-06-09 17:14:50,274][root][INFO] - Step 40197120 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.2853e+04, step = 40197120, mean_episode_return = 30.036, mean_episode_step = 1670.5, total_loss = -128.51, pg_loss = -140.41, baseline_loss = 26.555, entropy_loss = -14.662, learner_queue_size = 64, _tick = 6104, _time = 1.6548e+09)
[2022-06-09 17:14:55,278][root][INFO] - Step 40212480 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.2858e+04, step = 40212480, mean_episode_return = 31.193, mean_episode_step = 1955.9, total_loss = -83.618, pg_loss = -103.71, baseline_loss = 34.614, entropy_loss = -14.519, learner_queue_size = 64, _tick = 6107, _time = 1.6548e+09)
[2022-06-09 17:15:00,282][root][INFO] - Step 40232960 @ 4092.7 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 1.2863e+04, step = 40232960, mean_episode_return = 42.863, mean_episode_step = 1924.6, total_loss = 107.91, pg_loss = 90.121, baseline_loss = 32.212, entropy_loss = -14.419, learner_queue_size = 64, _tick = 6111, _time = 1.6548e+09)
[2022-06-09 17:15:05,288][root][INFO] - Step 40248320 @ 3068.4 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 1.2868e+04, step = 40248320, mean_episode_return = 9.3294, mean_episode_step = 1822.2, total_loss = -67.548, pg_loss = -87.018, baseline_loss = 33.81, entropy_loss = -14.339, learner_queue_size = 64, _tick = 6114, _time = 1.6548e+09)
[2022-06-09 17:15:10,294][root][INFO] - Step 40263680 @ 3068.2 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 1.2873e+04, step = 40263680, mean_episode_return = None, mean_episode_step = 1847.5, total_loss = 44.551, pg_loss = 31.142, baseline_loss = 27.687, entropy_loss = -14.278, learner_queue_size = 64, _tick = 6116, _time = 1.6548e+09)
[2022-06-09 17:15:15,298][root][INFO] - Step 40279040 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.2878e+04, step = 40279040, mean_episode_return = 36.87, mean_episode_step = 1744.7, total_loss = -160.0, pg_loss = -155.66, baseline_loss = 9.9804, entropy_loss = -14.32, learner_queue_size = 64, _tick = 6119, _time = 1.6548e+09)
[2022-06-09 17:15:20,302][root][INFO] - Step 40294400 @ 3069.6 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.2883e+04, step = 40294400, mean_episode_return = 43.895, mean_episode_step = 1703.4, total_loss = 65.203, pg_loss = 47.974, baseline_loss = 31.541, entropy_loss = -14.312, learner_queue_size = 64, _tick = 6122, _time = 1.6548e+09)
[2022-06-09 17:15:25,306][root][INFO] - Step 40309760 @ 3069.5 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.2888e+04, step = 40309760, mean_episode_return = None, mean_episode_step = 1427.2, total_loss = -135.18, pg_loss = -128.22, baseline_loss = 7.2723, entropy_loss = -14.236, learner_queue_size = 64, _tick = 6122, _time = 1.6548e+09)
[2022-06-09 17:15:30,312][root][INFO] - Step 40325120 @ 3068.1 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 1.2893e+04, step = 40325120, mean_episode_return = 36.881, mean_episode_step = 1759.9, total_loss = -79.455, pg_loss = -87.389, baseline_loss = 22.227, entropy_loss = -14.293, learner_queue_size = 64, _tick = 6125, _time = 1.6548e+09)
[2022-06-09 17:15:35,318][root][INFO] - Step 40345600 @ 4091.4 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 1.2898e+04, step = 40345600, mean_episode_return = 41.31, mean_episode_step = 1719.1, total_loss = -15.493, pg_loss = -30.027, baseline_loss = 28.66, entropy_loss = -14.126, learner_queue_size = 64, _tick = 6129, _time = 1.6548e+09)
[2022-06-09 17:15:40,322][root][INFO] - Step 40360960 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.2903e+04, step = 40360960, mean_episode_return = 78.108, mean_episode_step = 1801.4, total_loss = -194.62, pg_loss = -187.29, baseline_loss = 7.0033, entropy_loss = -14.332, learner_queue_size = 64, _tick = 6132, _time = 1.6548e+09)
[2022-06-09 17:15:45,326][root][INFO] - Step 40376320 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.2908e+04, step = 40376320, mean_episode_return = 70.55, mean_episode_step = 2049.4, total_loss = 62.185, pg_loss = 53.28, baseline_loss = 23.29, entropy_loss = -14.385, learner_queue_size = 64, _tick = 6135, _time = 1.6548e+09)
[2022-06-09 17:15:50,330][root][INFO] - Step 40391680 @ 3069.5 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 1.2913e+04, step = 40391680, mean_episode_return = 47.145, mean_episode_step = 1804.5, total_loss = -8.7366, pg_loss = -18.47, baseline_loss = 24.124, entropy_loss = -14.39, learner_queue_size = 64, _tick = 6137, _time = 1.6548e+09)
[2022-06-09 17:15:55,334][root][INFO] - Step 40407040 @ 3069.6 SPS. Inference batcher size: 18. Learner queue size: 64. Other stats: (train_seconds = 1.2918e+04, step = 40407040, mean_episode_return = None, mean_episode_step = 1959.2, total_loss = 205.67, pg_loss = 181.3, baseline_loss = 38.491, entropy_loss = -14.119, learner_queue_size = 64, _tick = 6139, _time = 1.6548e+09)
[2022-06-09 17:16:00,338][root][INFO] - Step 40422400 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.2923e+04, step = 40422400, mean_episode_return = 33.268, mean_episode_step = 1640.6, total_loss = 255.81, pg_loss = 213.86, baseline_loss = 56.239, entropy_loss = -14.285, learner_queue_size = 64, _tick = 6142, _time = 1.6548e+09)
[2022-06-09 17:16:05,342][root][INFO] - Step 40437760 @ 3069.5 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 1.2928e+04, step = 40437760, mean_episode_return = None, mean_episode_step = 1886.2, total_loss = 68.985, pg_loss = 53.457, baseline_loss = 29.998, entropy_loss = -14.47, learner_queue_size = 64, _tick = 6144, _time = 1.6548e+09)
[2022-06-09 17:16:10,346][root][INFO] - Step 40453120 @ 3069.6 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 1.2933e+04, step = 40453120, mean_episode_return = 21.321, mean_episode_step = 1686.7, total_loss = -99.938, pg_loss = -109.46, baseline_loss = 24.057, entropy_loss = -14.541, learner_queue_size = 64, _tick = 6147, _time = 1.6548e+09)
[2022-06-09 17:16:15,350][root][INFO] - Step 40468480 @ 3069.5 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.2938e+04, step = 40468480, mean_episode_return = 130.42, mean_episode_step = 1790.0, total_loss = 54.591, pg_loss = 31.94, baseline_loss = 37.145, entropy_loss = -14.494, learner_queue_size = 64, _tick = 6150, _time = 1.6548e+09)
[2022-06-09 17:16:20,353][root][INFO] - Step 40483840 @ 3070.2 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.2943e+04, step = 40483840, mean_episode_return = 48.435, mean_episode_step = 1640.8, total_loss = 6.5499, pg_loss = -20.272, baseline_loss = 41.292, entropy_loss = -14.471, learner_queue_size = 64, _tick = 6153, _time = 1.6548e+09)
[2022-06-09 17:16:25,358][root][INFO] - Step 40504320 @ 4092.0 SPS. Inference batcher size: 79. Learner queue size: 64. Other stats: (train_seconds = 1.2948e+04, step = 40504320, mean_episode_return = 23.09, mean_episode_step = 1790.8, total_loss = 505.93, pg_loss = 430.32, baseline_loss = 89.81, entropy_loss = -14.207, learner_queue_size = 64, _tick = 6156, _time = 1.6548e+09)
[2022-06-09 17:16:30,362][root][INFO] - Step 40519680 @ 3069.5 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 1.2953e+04, step = 40519680, mean_episode_return = 26.011, mean_episode_step = 1671.4, total_loss = 79.735, pg_loss = 52.426, baseline_loss = 41.496, entropy_loss = -14.187, learner_queue_size = 64, _tick = 6158, _time = 1.6548e+09)
[2022-06-09 17:16:35,366][root][INFO] - Step 40535040 @ 3069.6 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 1.2958e+04, step = 40535040, mean_episode_return = 33.06, mean_episode_step = 2035.7, total_loss = -58.662, pg_loss = -72.328, baseline_loss = 27.927, entropy_loss = -14.261, learner_queue_size = 64, _tick = 6161, _time = 1.6548e+09)
[2022-06-09 17:16:40,370][root][INFO] - Step 40550400 @ 3069.6 SPS. Inference batcher size: 79. Learner queue size: 64. Other stats: (train_seconds = 1.2963e+04, step = 40550400, mean_episode_return = None, mean_episode_step = 1633.2, total_loss = 321.63, pg_loss = 284.22, baseline_loss = 51.68, entropy_loss = -14.264, learner_queue_size = 64, _tick = 6163, _time = 1.6548e+09)
[2022-06-09 17:16:45,374][root][INFO] - Step 40565760 @ 3069.5 SPS. Inference batcher size: 75. Learner queue size: 64. Other stats: (train_seconds = 1.2968e+04, step = 40565760, mean_episode_return = 21.035, mean_episode_step = 1878.8, total_loss = -288.98, pg_loss = -279.41, baseline_loss = 4.7164, entropy_loss = -14.28, learner_queue_size = 64, _tick = 6166, _time = 1.6548e+09)
[2022-06-09 17:16:50,378][root][INFO] - Step 40581120 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.2973e+04, step = 40581120, mean_episode_return = -7.0451, mean_episode_step = 1945.0, total_loss = -209.85, pg_loss = -208.51, baseline_loss = 12.836, entropy_loss = -14.169, learner_queue_size = 64, _tick = 6169, _time = 1.6548e+09)
[2022-06-09 17:16:55,382][root][INFO] - Step 40596480 @ 3069.5 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 1.2978e+04, step = 40596480, mean_episode_return = 19.111, mean_episode_step = 1772.4, total_loss = -204.12, pg_loss = -210.37, baseline_loss = 20.504, entropy_loss = -14.253, learner_queue_size = 64, _tick = 6171, _time = 1.6548e+09)
[2022-06-09 17:17:00,386][root][INFO] - Step 40611840 @ 3069.6 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.2983e+04, step = 40611840, mean_episode_return = 80.757, mean_episode_step = 1959.5, total_loss = 155.37, pg_loss = 125.43, baseline_loss = 44.244, entropy_loss = -14.298, learner_queue_size = 64, _tick = 6173, _time = 1.6548e+09)
[2022-06-09 17:17:05,390][root][INFO] - Step 40627200 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.2988e+04, step = 40627200, mean_episode_return = 34.726, mean_episode_step = 1697.5, total_loss = -14.124, pg_loss = -33.293, baseline_loss = 33.358, entropy_loss = -14.189, learner_queue_size = 64, _tick = 6175, _time = 1.6548e+09)
[2022-06-09 17:17:10,394][root][INFO] - Step 40642560 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.2993e+04, step = 40642560, mean_episode_return = 46.971, mean_episode_step = 1964.8, total_loss = -102.59, pg_loss = -113.77, baseline_loss = 25.426, entropy_loss = -14.243, learner_queue_size = 64, _tick = 6178, _time = 1.6548e+09)
[2022-06-09 17:17:15,398][root][INFO] - Step 40663040 @ 4092.8 SPS. Inference batcher size: 77. Learner queue size: 64. Other stats: (train_seconds = 1.2998e+04, step = 40663040, mean_episode_return = 26.612, mean_episode_step = 2001.1, total_loss = 310.19, pg_loss = 267.2, baseline_loss = 57.245, entropy_loss = -14.254, learner_queue_size = 64, _tick = 6180, _time = 1.6548e+09)
[2022-06-09 17:17:20,402][root][INFO] - Step 40678400 @ 3069.5 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 1.3003e+04, step = 40678400, mean_episode_return = -7.7601, mean_episode_step = 1954.6, total_loss = 69.017, pg_loss = 41.775, baseline_loss = 41.448, entropy_loss = -14.207, learner_queue_size = 64, _tick = 6182, _time = 1.6548e+09)
[2022-06-09 17:17:25,406][root][INFO] - Step 40693760 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.3008e+04, step = 40693760, mean_episode_return = 67.244, mean_episode_step = 1993.9, total_loss = -203.98, pg_loss = -204.87, baseline_loss = 15.016, entropy_loss = -14.126, learner_queue_size = 64, _tick = 6184, _time = 1.6548e+09)
[2022-06-09 17:17:30,410][root][INFO] - Step 40709120 @ 3069.6 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.3013e+04, step = 40709120, mean_episode_return = None, mean_episode_step = 2236.2, total_loss = -8.0232, pg_loss = -8.3823, baseline_loss = 14.306, entropy_loss = -13.947, learner_queue_size = 64, _tick = 6186, _time = 1.6548e+09)
[2022-06-09 17:17:35,414][root][INFO] - Step 40724480 @ 3069.6 SPS. Inference batcher size: 14. Learner queue size: 64. Other stats: (train_seconds = 1.3018e+04, step = 40724480, mean_episode_return = None, mean_episode_step = 1695.9, total_loss = 285.29, pg_loss = 252.36, baseline_loss = 46.872, entropy_loss = -13.935, learner_queue_size = 64, _tick = 6188, _time = 1.6548e+09)
[2022-06-09 17:17:40,418][root][INFO] - Step 40739840 @ 3069.5 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1.3023e+04, step = 40739840, mean_episode_return = 51.592, mean_episode_step = 1814.9, total_loss = 122.58, pg_loss = 101.64, baseline_loss = 34.721, entropy_loss = -13.778, learner_queue_size = 64, _tick = 6190, _time = 1.6548e+09)
[2022-06-09 17:17:45,422][root][INFO] - Step 40755200 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.3028e+04, step = 40755200, mean_episode_return = -2.1906, mean_episode_step = 2004.7, total_loss = 61.965, pg_loss = 41.062, baseline_loss = 34.523, entropy_loss = -13.619, learner_queue_size = 64, _tick = 6192, _time = 1.6548e+09)
[2022-06-09 17:17:50,427][root][INFO] - Step 40775680 @ 4092.3 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 1.3033e+04, step = 40775680, mean_episode_return = 103.49, mean_episode_step = 1788.7, total_loss = -52.585, pg_loss = -71.758, baseline_loss = 32.747, entropy_loss = -13.574, learner_queue_size = 64, _tick = 6196, _time = 1.6548e+09)
[2022-06-09 17:17:55,430][root][INFO] - Step 40791040 @ 3069.9 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.3038e+04, step = 40791040, mean_episode_return = 15.165, mean_episode_step = 2044.9, total_loss = 111.97, pg_loss = 64.437, baseline_loss = 61.015, entropy_loss = -13.478, learner_queue_size = 64, _tick = 6199, _time = 1.6548e+09)
[2022-06-09 17:18:00,436][root][INFO] - Step 40806400 @ 3068.2 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 1.3043e+04, step = 40806400, mean_episode_return = 73.727, mean_episode_step = 2008.9, total_loss = 257.45, pg_loss = 225.58, baseline_loss = 45.246, entropy_loss = -13.373, learner_queue_size = 64, _tick = 6202, _time = 1.6548e+09)
[2022-06-09 17:18:05,442][root][INFO] - Step 40821760 @ 3068.4 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 1.3048e+04, step = 40821760, mean_episode_return = 34.586, mean_episode_step = 1976.6, total_loss = 37.083, pg_loss = 12.449, baseline_loss = 37.951, entropy_loss = -13.317, learner_queue_size = 64, _tick = 6204, _time = 1.6548e+09)
[2022-06-09 17:18:10,446][root][INFO] - Step 40837120 @ 3069.5 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 1.3053e+04, step = 40837120, mean_episode_return = None, mean_episode_step = 1931.9, total_loss = -37.679, pg_loss = -55.845, baseline_loss = 31.642, entropy_loss = -13.476, learner_queue_size = 64, _tick = 6206, _time = 1.6548e+09)
[2022-06-09 17:18:15,450][root][INFO] - Step 40852480 @ 3069.6 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 1.3058e+04, step = 40852480, mean_episode_return = None, mean_episode_step = 2143.6, total_loss = -184.72, pg_loss = -176.76, baseline_loss = 5.5044, entropy_loss = -13.461, learner_queue_size = 64, _tick = 6208, _time = 1.6548e+09)
[2022-06-09 17:18:20,454][root][INFO] - Step 40867840 @ 3069.6 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 1.3063e+04, step = 40867840, mean_episode_return = 40.62, mean_episode_step = 1956.2, total_loss = 159.96, pg_loss = 136.82, baseline_loss = 36.534, entropy_loss = -13.402, learner_queue_size = 64, _tick = 6210, _time = 1.6548e+09)
[2022-06-09 17:18:25,458][root][INFO] - Step 40883200 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.3068e+04, step = 40883200, mean_episode_return = 6.3002, mean_episode_step = 2052.9, total_loss = 9.3495, pg_loss = -5.3495, baseline_loss = 28.176, entropy_loss = -13.477, learner_queue_size = 64, _tick = 6213, _time = 1.6548e+09)
[2022-06-09 17:18:30,464][root][INFO] - Step 40898560 @ 3068.3 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.3073e+04, step = 40898560, mean_episode_return = 67.835, mean_episode_step = 2168.9, total_loss = 486.61, pg_loss = 417.46, baseline_loss = 82.688, entropy_loss = -13.54, learner_queue_size = 64, _tick = 6216, _time = 1.6548e+09)
[2022-06-09 17:18:35,470][root][INFO] - Step 40919040 @ 4091.1 SPS. Inference batcher size: 71. Learner queue size: 64. Other stats: (train_seconds = 1.3078e+04, step = 40919040, mean_episode_return = 16.87, mean_episode_step = 2001.6, total_loss = -101.21, pg_loss = -101.98, baseline_loss = 14.058, entropy_loss = -13.296, learner_queue_size = 64, _tick = 6219, _time = 1.6548e+09)
[2022-06-09 17:18:40,474][root][INFO] - Step 40934400 @ 3069.5 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 1.3083e+04, step = 40934400, mean_episode_return = 13.987, mean_episode_step = 2226.4, total_loss = -168.25, pg_loss = -173.15, baseline_loss = 18.026, entropy_loss = -13.132, learner_queue_size = 64, _tick = 6222, _time = 1.6548e+09)
[2022-06-09 17:18:45,478][root][INFO] - Step 40949760 @ 3069.5 SPS. Inference batcher size: 77. Learner queue size: 64. Other stats: (train_seconds = 1.3088e+04, step = 40949760, mean_episode_return = 38.652, mean_episode_step = 2075.1, total_loss = -5.7829, pg_loss = -16.605, baseline_loss = 24.071, entropy_loss = -13.249, learner_queue_size = 64, _tick = 6225, _time = 1.6548e+09)
[2022-06-09 17:18:50,482][root][INFO] - Step 40965120 @ 3069.6 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.3093e+04, step = 40965120, mean_episode_return = 4.4494, mean_episode_step = 2300.6, total_loss = -163.51, pg_loss = -155.47, baseline_loss = 5.3976, entropy_loss = -13.441, learner_queue_size = 64, _tick = 6227, _time = 1.6548e+09)
[2022-06-09 17:18:55,486][root][INFO] - Step 40980480 @ 3069.5 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.3098e+04, step = 40980480, mean_episode_return = 7.1397, mean_episode_step = 2071.3, total_loss = 53.152, pg_loss = 39.527, baseline_loss = 27.169, entropy_loss = -13.544, learner_queue_size = 64, _tick = 6230, _time = 1.6548e+09)
[2022-06-09 17:19:00,492][root][INFO] - Step 40995840 @ 3068.1 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.3103e+04, step = 40995840, mean_episode_return = 49.781, mean_episode_step = 2205.4, total_loss = 30.626, pg_loss = 18.52, baseline_loss = 25.745, entropy_loss = -13.639, learner_queue_size = 64, _tick = 6232, _time = 1.6548e+09)
[2022-06-09 17:19:05,498][root][INFO] - Step 41016320 @ 4091.5 SPS. Inference batcher size: 84. Learner queue size: 64. Other stats: (train_seconds = 1.3108e+04, step = 41016320, mean_episode_return = 39.17, mean_episode_step = 2109.0, total_loss = 238.4, pg_loss = 202.24, baseline_loss = 50.142, entropy_loss = -13.988, learner_queue_size = 64, _tick = 6235, _time = 1.6548e+09)
[2022-06-09 17:19:10,502][root][INFO] - Step 41031680 @ 3069.4 SPS. Inference batcher size: 79. Learner queue size: 64. Other stats: (train_seconds = 1.3113e+04, step = 41031680, mean_episode_return = None, mean_episode_step = 2026.8, total_loss = -30.263, pg_loss = -33.741, baseline_loss = 17.526, entropy_loss = -14.049, learner_queue_size = 64, _tick = 6237, _time = 1.6548e+09)
[2022-06-09 17:19:15,514][root][INFO] - Step 41047040 @ 3064.7 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.3118e+04, step = 41047040, mean_episode_return = None, mean_episode_step = 2304.0, total_loss = -85.833, pg_loss = -83.651, baseline_loss = 11.841, entropy_loss = -14.023, learner_queue_size = 64, _tick = 6239, _time = 1.6548e+09)
[2022-06-09 17:19:20,518][root][INFO] - Step 41062400 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.3124e+04, step = 41062400, mean_episode_return = 89.555, mean_episode_step = 2224.2, total_loss = -59.665, pg_loss = -62.194, baseline_loss = 16.585, entropy_loss = -14.056, learner_queue_size = 64, _tick = 6242, _time = 1.6548e+09)
[2022-06-09 17:19:25,522][root][INFO] - Step 41077760 @ 3069.6 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.3128e+04, step = 41077760, mean_episode_return = 34.261, mean_episode_step = 1891.4, total_loss = -103.09, pg_loss = -99.072, baseline_loss = 10.263, entropy_loss = -14.278, learner_queue_size = 64, _tick = 6245, _time = 1.6548e+09)
[2022-06-09 17:19:30,526][root][INFO] - Step 41093120 @ 3069.6 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.3134e+04, step = 41093120, mean_episode_return = 13.298, mean_episode_step = 2239.2, total_loss = -109.28, pg_loss = -107.94, baseline_loss = 13.104, entropy_loss = -14.441, learner_queue_size = 64, _tick = 6247, _time = 1.6548e+09)
[2022-06-09 17:19:35,530][root][INFO] - Step 41108480 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.3138e+04, step = 41108480, mean_episode_return = 132.23, mean_episode_step = 2340.6, total_loss = 14.146, pg_loss = 8.338, baseline_loss = 20.138, entropy_loss = -14.33, learner_queue_size = 64, _tick = 6250, _time = 1.6548e+09)
[2022-06-09 17:19:40,534][root][INFO] - Step 41123840 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.3144e+04, step = 41123840, mean_episode_return = 74.545, mean_episode_step = 2294.3, total_loss = 241.63, pg_loss = 205.23, baseline_loss = 50.741, entropy_loss = -14.337, learner_queue_size = 64, _tick = 6253, _time = 1.6548e+09)
[2022-06-09 17:19:45,538][root][INFO] - Step 41139200 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.3148e+04, step = 41139200, mean_episode_return = 26.487, mean_episode_step = 2106.3, total_loss = -16.535, pg_loss = -20.232, baseline_loss = 18.037, entropy_loss = -14.34, learner_queue_size = 64, _tick = 6256, _time = 1.6548e+09)
[2022-06-09 17:19:50,542][root][INFO] - Step 41154560 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.3154e+04, step = 41154560, mean_episode_return = None, mean_episode_step = 2031.8, total_loss = 408.07, pg_loss = 364.34, baseline_loss = 58.104, entropy_loss = -14.374, learner_queue_size = 64, _tick = 6258, _time = 1.6548e+09)
[2022-06-09 17:19:55,546][root][INFO] - Step 41169920 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.3158e+04, step = 41169920, mean_episode_return = 33.249, mean_episode_step = 2149.0, total_loss = 311.72, pg_loss = 259.73, baseline_loss = 66.377, entropy_loss = -14.391, learner_queue_size = 64, _tick = 6260, _time = 1.6548e+09)
[2022-06-09 17:20:00,550][root][INFO] - Step 41190400 @ 4092.8 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.3164e+04, step = 41190400, mean_episode_return = 44.077, mean_episode_step = 2025.8, total_loss = 31.999, pg_loss = 3.7566, baseline_loss = 42.574, entropy_loss = -14.331, learner_queue_size = 64, _tick = 6263, _time = 1.6548e+09)
[2022-06-09 17:20:05,554][root][INFO] - Step 41205760 @ 3069.5 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 1.3168e+04, step = 41205760, mean_episode_return = None, mean_episode_step = 1993.6, total_loss = -9.5612, pg_loss = -13.904, baseline_loss = 18.739, entropy_loss = -14.396, learner_queue_size = 64, _tick = 6265, _time = 1.6548e+09)
[2022-06-09 17:20:10,560][root][INFO] - Step 41221120 @ 3068.3 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.3174e+04, step = 41221120, mean_episode_return = 21.676, mean_episode_step = 1792.2, total_loss = 69.786, pg_loss = 51.549, baseline_loss = 32.817, entropy_loss = -14.58, learner_queue_size = 64, _tick = 6268, _time = 1.6548e+09)
[2022-06-09 17:20:15,562][root][INFO] - Step 41236480 @ 3070.7 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 1.3178e+04, step = 41236480, mean_episode_return = 42.983, mean_episode_step = 1970.8, total_loss = 11.479, pg_loss = -5.7461, baseline_loss = 31.865, entropy_loss = -14.64, learner_queue_size = 64, _tick = 6271, _time = 1.6548e+09)
[2022-06-09 17:20:20,566][root][INFO] - Step 41251840 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.3184e+04, step = 41251840, mean_episode_return = 63.946, mean_episode_step = 2219.4, total_loss = 379.7, pg_loss = 326.36, baseline_loss = 68.228, entropy_loss = -14.882, learner_queue_size = 64, _tick = 6274, _time = 1.6548e+09)
[2022-06-09 17:20:25,570][root][INFO] - Step 41267200 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.3188e+04, step = 41267200, mean_episode_return = 11.701, mean_episode_step = 2400.6, total_loss = -121.07, pg_loss = -129.18, baseline_loss = 22.922, entropy_loss = -14.812, learner_queue_size = 64, _tick = 6275, _time = 1.6548e+09)
[2022-06-09 17:20:30,574][root][INFO] - Step 41282560 @ 3069.6 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.3194e+04, step = 41282560, mean_episode_return = None, mean_episode_step = 2163.0, total_loss = -58.299, pg_loss = -59.253, baseline_loss = 15.572, entropy_loss = -14.617, learner_queue_size = 64, _tick = 6277, _time = 1.6548e+09)
[2022-06-09 17:20:35,578][root][INFO] - Step 41303040 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 1.3198e+04, step = 41303040, mean_episode_return = 20.64, mean_episode_step = 2003.8, total_loss = 7.1238, pg_loss = -9.1561, baseline_loss = 30.927, entropy_loss = -14.647, learner_queue_size = 64, _tick = 6280, _time = 1.6548e+09)
[2022-06-09 17:20:40,582][root][INFO] - Step 41318400 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.3204e+04, step = 41318400, mean_episode_return = 45.145, mean_episode_step = 2045.5, total_loss = 417.84, pg_loss = 353.73, baseline_loss = 78.896, entropy_loss = -14.794, learner_queue_size = 64, _tick = 6283, _time = 1.6548e+09)
[2022-06-09 17:20:45,586][root][INFO] - Step 41333760 @ 3069.5 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 1.3208e+04, step = 41333760, mean_episode_return = None, mean_episode_step = 2098.4, total_loss = 5.5548, pg_loss = -1.4804, baseline_loss = 21.789, entropy_loss = -14.754, learner_queue_size = 64, _tick = 6284, _time = 1.6548e+09)
[2022-06-09 17:20:50,590][root][INFO] - Step 41349120 @ 3069.5 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 1.3214e+04, step = 41349120, mean_episode_return = 48.474, mean_episode_step = 2000.9, total_loss = 21.06, pg_loss = 2.5498, baseline_loss = 33.13, entropy_loss = -14.62, learner_queue_size = 64, _tick = 6287, _time = 1.6548e+09)
[2022-06-09 17:20:55,596][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 17:20:55,903][root][INFO] - Step 41364480 @ 3068.3 SPS. Inference batcher size: 15. Learner queue size: 64. Other stats: (train_seconds = 1.3218e+04, step = 41364480, mean_episode_return = -8.8259, mean_episode_step = 2312.7, total_loss = -133.21, pg_loss = -141.23, baseline_loss = 22.46, entropy_loss = -14.444, learner_queue_size = 64, _tick = 6290, _time = 1.6548e+09)
[2022-06-09 17:21:00,906][root][INFO] - Step 41379840 @ 2892.7 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.3224e+04, step = 41379840, mean_episode_return = None, mean_episode_step = 2111.5, total_loss = 8.077, pg_loss = -1.3947, baseline_loss = 23.885, entropy_loss = -14.413, learner_queue_size = 64, _tick = 6292, _time = 1.6548e+09)
[2022-06-09 17:21:05,910][root][INFO] - Step 41395200 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.3229e+04, step = 41395200, mean_episode_return = 94.539, mean_episode_step = 1860.4, total_loss = 209.23, pg_loss = 158.96, baseline_loss = 64.575, entropy_loss = -14.306, learner_queue_size = 64, _tick = 6293, _time = 1.6548e+09)
[2022-06-09 17:21:10,914][root][INFO] - Step 41410560 @ 3069.4 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.3234e+04, step = 41410560, mean_episode_return = 93.479, mean_episode_step = 1817.2, total_loss = 87.995, pg_loss = 52.59, baseline_loss = 49.822, entropy_loss = -14.417, learner_queue_size = 64, _tick = 6296, _time = 1.6548e+09)
[2022-06-09 17:21:15,918][root][INFO] - Step 41425920 @ 3069.6 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.3239e+04, step = 41425920, mean_episode_return = 25.141, mean_episode_step = 2406.0, total_loss = 323.29, pg_loss = 242.29, baseline_loss = 95.203, entropy_loss = -14.207, learner_queue_size = 64, _tick = 6299, _time = 1.6548e+09)
[2022-06-09 17:21:20,922][root][INFO] - Step 41441280 @ 3069.6 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 1.3244e+04, step = 41441280, mean_episode_return = 54.257, mean_episode_step = 2030.5, total_loss = 177.11, pg_loss = 129.55, baseline_loss = 61.846, entropy_loss = -14.289, learner_queue_size = 64, _tick = 6302, _time = 1.6548e+09)
[2022-06-09 17:21:25,926][root][INFO] - Step 41456640 @ 3069.6 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 1.3249e+04, step = 41456640, mean_episode_return = 29.564, mean_episode_step = 1872.5, total_loss = -28.865, pg_loss = -42.447, baseline_loss = 27.892, entropy_loss = -14.309, learner_queue_size = 64, _tick = 6305, _time = 1.6548e+09)
[2022-06-09 17:21:30,930][root][INFO] - Step 41472000 @ 3069.5 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 1.3254e+04, step = 41472000, mean_episode_return = 27.602, mean_episode_step = 1895.4, total_loss = -68.562, pg_loss = -77.154, baseline_loss = 23.004, entropy_loss = -14.412, learner_queue_size = 64, _tick = 6308, _time = 1.6548e+09)
[2022-06-09 17:21:35,934][root][INFO] - Step 41492480 @ 4092.8 SPS. Inference batcher size: 75. Learner queue size: 64. Other stats: (train_seconds = 1.3259e+04, step = 41492480, mean_episode_return = 112.9, mean_episode_step = 1963.2, total_loss = 2.108, pg_loss = -10.939, baseline_loss = 27.615, entropy_loss = -14.568, learner_queue_size = 64, _tick = 6312, _time = 1.6548e+09)
[2022-06-09 17:21:40,937][root][INFO] - Step 41507840 @ 3070.4 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 1.3264e+04, step = 41507840, mean_episode_return = 38.918, mean_episode_step = 2146.3, total_loss = -100.12, pg_loss = -131.97, baseline_loss = 46.238, entropy_loss = -14.393, learner_queue_size = 64, _tick = 6315, _time = 1.6548e+09)
[2022-06-09 17:21:45,942][root][INFO] - Step 41523200 @ 3068.6 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 1.3269e+04, step = 41523200, mean_episode_return = 13.81, mean_episode_step = 2119.1, total_loss = -122.07, pg_loss = -122.53, baseline_loss = 14.921, entropy_loss = -14.465, learner_queue_size = 64, _tick = 6318, _time = 1.6548e+09)
[2022-06-09 17:21:50,946][root][INFO] - Step 41538560 @ 3069.6 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 1.3274e+04, step = 41538560, mean_episode_return = 13.868, mean_episode_step = 1723.7, total_loss = 218.72, pg_loss = 186.56, baseline_loss = 46.753, entropy_loss = -14.589, learner_queue_size = 64, _tick = 6321, _time = 1.6548e+09)
[2022-06-09 17:21:55,950][root][INFO] - Step 41553920 @ 3069.5 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 1.3279e+04, step = 41553920, mean_episode_return = 65.79, mean_episode_step = 2112.5, total_loss = -271.91, pg_loss = -268.65, baseline_loss = 11.381, entropy_loss = -14.642, learner_queue_size = 64, _tick = 6323, _time = 1.6548e+09)
[2022-06-09 17:22:00,957][root][INFO] - Step 41569280 @ 3068.1 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 1.3284e+04, step = 41569280, mean_episode_return = None, mean_episode_step = 1827.9, total_loss = 196.65, pg_loss = 173.67, baseline_loss = 37.652, entropy_loss = -14.665, learner_queue_size = 64, _tick = 6325, _time = 1.6548e+09)
[2022-06-09 17:22:05,962][root][INFO] - Step 41584640 @ 3068.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.3289e+04, step = 41584640, mean_episode_return = 46.814, mean_episode_step = 2080.1, total_loss = 110.89, pg_loss = 67.627, baseline_loss = 57.952, entropy_loss = -14.687, learner_queue_size = 64, _tick = 6328, _time = 1.6548e+09)
[2022-06-09 17:22:10,966][root][INFO] - Step 41600000 @ 3069.6 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 1.3294e+04, step = 41600000, mean_episode_return = 46.26, mean_episode_step = 1894.1, total_loss = -202.32, pg_loss = -212.53, baseline_loss = 24.836, entropy_loss = -14.625, learner_queue_size = 64, _tick = 6330, _time = 1.6548e+09)
[2022-06-09 17:22:15,970][root][INFO] - Step 41615360 @ 3069.2 SPS. Inference batcher size: 18. Learner queue size: 64. Other stats: (train_seconds = 1.3299e+04, step = 41615360, mean_episode_return = 36.756, mean_episode_step = 1942.4, total_loss = 183.79, pg_loss = 160.45, baseline_loss = 37.735, entropy_loss = -14.396, learner_queue_size = 64, _tick = 6332, _time = 1.6548e+09)
[2022-06-09 17:22:20,974][root][INFO] - Step 41630720 @ 3069.9 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.3304e+04, step = 41630720, mean_episode_return = 51.05, mean_episode_step = 1833.8, total_loss = -144.04, pg_loss = -138.34, baseline_loss = 8.782, entropy_loss = -14.482, learner_queue_size = 64, _tick = 6334, _time = 1.6548e+09)
[2022-06-09 17:22:25,980][root][INFO] - Step 41646080 @ 3068.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.3309e+04, step = 41646080, mean_episode_return = -1.44, mean_episode_step = 2103.3, total_loss = 72.412, pg_loss = 50.187, baseline_loss = 36.735, entropy_loss = -14.51, learner_queue_size = 64, _tick = 6336, _time = 1.6548e+09)
[2022-06-09 17:22:30,982][root][INFO] - Step 41666560 @ 4094.1 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.3314e+04, step = 41666560, mean_episode_return = 23.3, mean_episode_step = 1783.5, total_loss = 43.675, pg_loss = 27.516, baseline_loss = 30.394, entropy_loss = -14.235, learner_queue_size = 64, _tick = 6338, _time = 1.6548e+09)
[2022-06-09 17:22:35,986][root][INFO] - Step 41681920 @ 3069.5 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 1.3319e+04, step = 41681920, mean_episode_return = 12.37, mean_episode_step = 2328.4, total_loss = -122.32, pg_loss = -121.5, baseline_loss = 13.36, entropy_loss = -14.183, learner_queue_size = 64, _tick = 6341, _time = 1.6548e+09)
[2022-06-09 17:22:40,990][root][INFO] - Step 41697280 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.3324e+04, step = 41697280, mean_episode_return = -1.2338, mean_episode_step = 2031.9, total_loss = -8.7783, pg_loss = -29.995, baseline_loss = 35.352, entropy_loss = -14.136, learner_queue_size = 64, _tick = 6344, _time = 1.6548e+09)
[2022-06-09 17:22:46,004][root][INFO] - Step 41712640 @ 3063.4 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.3329e+04, step = 41712640, mean_episode_return = 127.1, mean_episode_step = 1668.0, total_loss = 193.7, pg_loss = 155.68, baseline_loss = 52.319, entropy_loss = -14.3, learner_queue_size = 64, _tick = 6346, _time = 1.6548e+09)
[2022-06-09 17:22:51,010][root][INFO] - Step 41728000 @ 3068.4 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.3334e+04, step = 41728000, mean_episode_return = 50.073, mean_episode_step = 2058.1, total_loss = 1.1885e+04, pg_loss = 3110.3, baseline_loss = 8789.2, entropy_loss = -14.131, learner_queue_size = 64, _tick = 6348, _time = 1.6548e+09)
[2022-06-09 17:22:56,014][root][INFO] - Step 41743360 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.3339e+04, step = 41743360, mean_episode_return = 96.02, mean_episode_step = 2016.6, total_loss = 279.6, pg_loss = 226.64, baseline_loss = 67.005, entropy_loss = -14.047, learner_queue_size = 64, _tick = 6350, _time = 1.6548e+09)
[2022-06-09 17:23:01,018][root][INFO] - Step 41758720 @ 3069.6 SPS. Inference batcher size: 18. Learner queue size: 64. Other stats: (train_seconds = 1.3344e+04, step = 41758720, mean_episode_return = 34.74, mean_episode_step = 1879.2, total_loss = -136.05, pg_loss = -141.18, baseline_loss = 19.035, entropy_loss = -13.906, learner_queue_size = 64, _tick = 6353, _time = 1.6548e+09)
[2022-06-09 17:23:06,022][root][INFO] - Step 41774080 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.3349e+04, step = 41774080, mean_episode_return = 60.957, mean_episode_step = 1832.6, total_loss = 61.648, pg_loss = 26.713, baseline_loss = 48.978, entropy_loss = -14.042, learner_queue_size = 64, _tick = 6355, _time = 1.6548e+09)
[2022-06-09 17:23:11,028][root][INFO] - Step 41794560 @ 4090.8 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 1.3354e+04, step = 41794560, mean_episode_return = None, mean_episode_step = 2209.9, total_loss = 5.6712, pg_loss = -5.4882, baseline_loss = 25.275, entropy_loss = -14.116, learner_queue_size = 64, _tick = 6358, _time = 1.6548e+09)
[2022-06-09 17:23:16,030][root][INFO] - Step 41809920 @ 3070.9 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 1.3359e+04, step = 41809920, mean_episode_return = 77.029, mean_episode_step = 1825.4, total_loss = -64.833, pg_loss = -79.283, baseline_loss = 28.727, entropy_loss = -14.277, learner_queue_size = 64, _tick = 6361, _time = 1.6548e+09)
[2022-06-09 17:23:21,034][root][INFO] - Step 41825280 @ 3069.6 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.3364e+04, step = 41825280, mean_episode_return = 45.482, mean_episode_step = 2316.8, total_loss = 159.2, pg_loss = 113.38, baseline_loss = 60.287, entropy_loss = -14.467, learner_queue_size = 64, _tick = 6364, _time = 1.6548e+09)
[2022-06-09 17:23:26,038][root][INFO] - Step 41840640 @ 3069.6 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.3369e+04, step = 41840640, mean_episode_return = 80.574, mean_episode_step = 2316.1, total_loss = -95.295, pg_loss = -111.32, baseline_loss = 30.595, entropy_loss = -14.566, learner_queue_size = 64, _tick = 6366, _time = 1.6548e+09)
[2022-06-09 17:23:31,042][root][INFO] - Step 41856000 @ 3069.6 SPS. Inference batcher size: 3. Learner queue size: 64. Other stats: (train_seconds = 1.3374e+04, step = 41856000, mean_episode_return = 76.791, mean_episode_step = 2034.8, total_loss = -74.465, pg_loss = -81.545, baseline_loss = 21.815, entropy_loss = -14.735, learner_queue_size = 64, _tick = 6369, _time = 1.6548e+09)
[2022-06-09 17:23:36,046][root][INFO] - Step 41871360 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.3379e+04, step = 41871360, mean_episode_return = None, mean_episode_step = 2139.4, total_loss = 24.409, pg_loss = 13.96, baseline_loss = 25.226, entropy_loss = -14.777, learner_queue_size = 64, _tick = 6371, _time = 1.6548e+09)
[2022-06-09 17:23:41,051][root][INFO] - Step 41886720 @ 3069.2 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.3384e+04, step = 41886720, mean_episode_return = -10.521, mean_episode_step = 2241.4, total_loss = -244.18, pg_loss = -238.08, baseline_loss = 8.7168, entropy_loss = -14.814, learner_queue_size = 64, _tick = 6373, _time = 1.6548e+09)
[2022-06-09 17:23:46,057][root][INFO] - Step 41902080 @ 3068.1 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.3389e+04, step = 41902080, mean_episode_return = 43.626, mean_episode_step = 2180.4, total_loss = 81.966, pg_loss = 27.61, baseline_loss = 69.253, entropy_loss = -14.898, learner_queue_size = 64, _tick = 6376, _time = 1.6548e+09)
[2022-06-09 17:23:51,062][root][INFO] - Step 41922560 @ 4091.9 SPS. Inference batcher size: 91. Learner queue size: 64. Other stats: (train_seconds = 1.3394e+04, step = 41922560, mean_episode_return = -9.4105, mean_episode_step = 2030.4, total_loss = 198.13, pg_loss = 163.28, baseline_loss = 49.937, entropy_loss = -15.085, learner_queue_size = 64, _tick = 6378, _time = 1.6548e+09)
[2022-06-09 17:23:56,066][root][INFO] - Step 41932800 @ 2046.4 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.3399e+04, step = 41932800, mean_episode_return = 68.78, mean_episode_step = 2156.8, total_loss = -15.532, pg_loss = -19.54, baseline_loss = 18.926, entropy_loss = -14.918, learner_queue_size = 64, _tick = 6379, _time = 1.6548e+09)
[2022-06-09 17:24:01,070][root][INFO] - Step 41953280 @ 4092.8 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.3404e+04, step = 41953280, mean_episode_return = 27.852, mean_episode_step = 2268.0, total_loss = -97.556, pg_loss = -103.38, baseline_loss = 20.648, entropy_loss = -14.825, learner_queue_size = 64, _tick = 6382, _time = 1.6548e+09)
[2022-06-09 17:24:06,074][root][INFO] - Step 41968640 @ 3069.5 SPS. Inference batcher size: 85. Learner queue size: 64. Other stats: (train_seconds = 1.3409e+04, step = 41968640, mean_episode_return = 21.001, mean_episode_step = 2164.9, total_loss = -236.1, pg_loss = -230.45, baseline_loss = 9.3101, entropy_loss = -14.952, learner_queue_size = 64, _tick = 6385, _time = 1.6548e+09)
[2022-06-09 17:24:11,078][root][INFO] - Step 41984000 @ 3069.5 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 1.3414e+04, step = 41984000, mean_episode_return = None, mean_episode_step = 2167.4, total_loss = -100.97, pg_loss = -98.445, baseline_loss = 12.485, entropy_loss = -15.009, learner_queue_size = 64, _tick = 6385, _time = 1.6548e+09)
[2022-06-09 17:24:16,086][root][INFO] - Step 41999360 @ 3067.1 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.3419e+04, step = 41999360, mean_episode_return = 51.944, mean_episode_step = 2311.5, total_loss = -16.098, pg_loss = -40.629, baseline_loss = 39.62, entropy_loss = -15.089, learner_queue_size = 64, _tick = 6388, _time = 1.6548e+09)
[2022-06-09 17:24:21,090][root][INFO] - Step 42014720 @ 3069.6 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.3424e+04, step = 42014720, mean_episode_return = 9.7365, mean_episode_step = 2654.0, total_loss = 207.61, pg_loss = 137.71, baseline_loss = 85.133, entropy_loss = -15.233, learner_queue_size = 64, _tick = 6391, _time = 1.6548e+09)
[2022-06-09 17:24:26,094][root][INFO] - Step 42030080 @ 3069.5 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.3429e+04, step = 42030080, mean_episode_return = None, mean_episode_step = 2044.8, total_loss = -65.505, pg_loss = -60.923, baseline_loss = 10.764, entropy_loss = -15.346, learner_queue_size = 64, _tick = 6392, _time = 1.6548e+09)
[2022-06-09 17:24:31,098][root][INFO] - Step 42045440 @ 3069.5 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1.3434e+04, step = 42045440, mean_episode_return = 48.406, mean_episode_step = 2145.7, total_loss = -40.439, pg_loss = -46.123, baseline_loss = 21.151, entropy_loss = -15.466, learner_queue_size = 64, _tick = 6395, _time = 1.6548e+09)
[2022-06-09 17:24:36,102][root][INFO] - Step 42060800 @ 3069.6 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.3439e+04, step = 42060800, mean_episode_return = 70.691, mean_episode_step = 2233.3, total_loss = -112.67, pg_loss = -106.9, baseline_loss = 9.7988, entropy_loss = -15.563, learner_queue_size = 64, _tick = 6398, _time = 1.6548e+09)
[2022-06-09 17:24:41,106][root][INFO] - Step 42076160 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.3444e+04, step = 42076160, mean_episode_return = 85.343, mean_episode_step = 2270.9, total_loss = 84.999, pg_loss = 73.293, baseline_loss = 27.048, entropy_loss = -15.343, learner_queue_size = 64, _tick = 6400, _time = 1.6548e+09)
[2022-06-09 17:24:46,110][root][INFO] - Step 42091520 @ 3069.2 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 1.3449e+04, step = 42091520, mean_episode_return = 23.542, mean_episode_step = 2379.5, total_loss = 80.93, pg_loss = 68.709, baseline_loss = 27.54, entropy_loss = -15.32, learner_queue_size = 64, _tick = 6403, _time = 1.6548e+09)
[2022-06-09 17:24:51,115][root][INFO] - Step 42106880 @ 3069.3 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1.3454e+04, step = 42106880, mean_episode_return = None, mean_episode_step = 2393.7, total_loss = 275.02, pg_loss = 238.33, baseline_loss = 52.064, entropy_loss = -15.373, learner_queue_size = 64, _tick = 6405, _time = 1.6548e+09)
[2022-06-09 17:24:56,118][root][INFO] - Step 42127360 @ 4093.4 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.3459e+04, step = 42127360, mean_episode_return = -3.3588, mean_episode_step = 2087.2, total_loss = 100.21, pg_loss = 89.618, baseline_loss = 25.694, entropy_loss = -15.098, learner_queue_size = 64, _tick = 6409, _time = 1.6548e+09)
[2022-06-09 17:25:01,122][root][INFO] - Step 42142720 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.3464e+04, step = 42142720, mean_episode_return = None, mean_episode_step = 1936.4, total_loss = 5.4957, pg_loss = -4.0427, baseline_loss = 24.523, entropy_loss = -14.984, learner_queue_size = 64, _tick = 6411, _time = 1.6548e+09)
[2022-06-09 17:25:06,126][root][INFO] - Step 42158080 @ 3069.5 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 1.3469e+04, step = 42158080, mean_episode_return = 117.31, mean_episode_step = 2237.5, total_loss = 187.47, pg_loss = 164.36, baseline_loss = 38.176, entropy_loss = -15.067, learner_queue_size = 64, _tick = 6414, _time = 1.6548e+09)
[2022-06-09 17:25:11,130][root][INFO] - Step 42173440 @ 3069.6 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 1.3474e+04, step = 42173440, mean_episode_return = 84.143, mean_episode_step = 2111.5, total_loss = -72.922, pg_loss = -75.251, baseline_loss = 17.257, entropy_loss = -14.927, learner_queue_size = 64, _tick = 6417, _time = 1.6548e+09)
[2022-06-09 17:25:16,134][root][INFO] - Step 42188800 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.3479e+04, step = 42188800, mean_episode_return = 65.219, mean_episode_step = 2038.2, total_loss = 314.85, pg_loss = 244.37, baseline_loss = 85.208, entropy_loss = -14.726, learner_queue_size = 64, _tick = 6420, _time = 1.6548e+09)
[2022-06-09 17:25:21,138][root][INFO] - Step 42204160 @ 3069.6 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 1.3484e+04, step = 42204160, mean_episode_return = 80.26, mean_episode_step = 1882.2, total_loss = 390.52, pg_loss = 326.71, baseline_loss = 78.606, entropy_loss = -14.79, learner_queue_size = 64, _tick = 6423, _time = 1.6548e+09)
[2022-06-09 17:25:26,144][root][INFO] - Step 42219520 @ 3068.4 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.3489e+04, step = 42219520, mean_episode_return = 26.872, mean_episode_step = 1699.2, total_loss = 49.191, pg_loss = 19.815, baseline_loss = 44.134, entropy_loss = -14.758, learner_queue_size = 64, _tick = 6426, _time = 1.6548e+09)
[2022-06-09 17:25:31,146][root][INFO] - Step 42234880 @ 3070.7 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.3494e+04, step = 42234880, mean_episode_return = None, mean_episode_step = 1858.5, total_loss = 84.266, pg_loss = 74.601, baseline_loss = 24.138, entropy_loss = -14.472, learner_queue_size = 64, _tick = 6427, _time = 1.6548e+09)
[2022-06-09 17:25:36,150][root][INFO] - Step 42250240 @ 3069.6 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.3499e+04, step = 42250240, mean_episode_return = 63.743, mean_episode_step = 1960.3, total_loss = 104.99, pg_loss = 82.113, baseline_loss = 37.384, entropy_loss = -14.508, learner_queue_size = 64, _tick = 6430, _time = 1.6548e+09)
[2022-06-09 17:25:41,156][root][INFO] - Step 42265600 @ 3068.1 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.3504e+04, step = 42265600, mean_episode_return = 160.28, mean_episode_step = 1726.4, total_loss = 495.14, pg_loss = 422.02, baseline_loss = 87.662, entropy_loss = -14.534, learner_queue_size = 64, _tick = 6433, _time = 1.6548e+09)
[2022-06-09 17:25:46,164][root][INFO] - Step 42286080 @ 4090.0 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.3509e+04, step = 42286080, mean_episode_return = 60.292, mean_episode_step = 1672.0, total_loss = 170.23, pg_loss = 124.48, baseline_loss = 60.239, entropy_loss = -14.488, learner_queue_size = 64, _tick = 6437, _time = 1.6548e+09)
[2022-06-09 17:25:51,166][root][INFO] - Step 42301440 @ 3070.6 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 1.3514e+04, step = 42301440, mean_episode_return = 71.45, mean_episode_step = 1916.0, total_loss = 28.007, pg_loss = 7.8577, baseline_loss = 34.682, entropy_loss = -14.533, learner_queue_size = 64, _tick = 6440, _time = 1.6548e+09)
[2022-06-09 17:25:56,170][root][INFO] - Step 42316800 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.3519e+04, step = 42316800, mean_episode_return = 31.532, mean_episode_step = 2119.3, total_loss = 48.773, pg_loss = 31.341, baseline_loss = 31.863, entropy_loss = -14.431, learner_queue_size = 64, _tick = 6441, _time = 1.6548e+09)
[2022-06-09 17:26:01,174][root][INFO] - Step 42332160 @ 3069.6 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.3524e+04, step = 42332160, mean_episode_return = 91.769, mean_episode_step = 1605.8, total_loss = -78.456, pg_loss = -89.365, baseline_loss = 25.403, entropy_loss = -14.494, learner_queue_size = 64, _tick = 6444, _time = 1.6548e+09)
[2022-06-09 17:26:06,178][root][INFO] - Step 42347520 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.3529e+04, step = 42347520, mean_episode_return = 34.861, mean_episode_step = 1742.9, total_loss = -67.363, pg_loss = -67.747, baseline_loss = 14.904, entropy_loss = -14.52, learner_queue_size = 64, _tick = 6447, _time = 1.6548e+09)
[2022-06-09 17:26:11,182][root][INFO] - Step 42362880 @ 3069.5 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.3534e+04, step = 42362880, mean_episode_return = None, mean_episode_step = 1683.8, total_loss = 248.74, pg_loss = 208.42, baseline_loss = 54.698, entropy_loss = -14.372, learner_queue_size = 64, _tick = 6448, _time = 1.6548e+09)
[2022-06-09 17:26:16,188][root][INFO] - Step 42378240 @ 3068.2 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 1.3539e+04, step = 42378240, mean_episode_return = 91.328, mean_episode_step = 1335.2, total_loss = 305.56, pg_loss = 254.13, baseline_loss = 65.894, entropy_loss = -14.464, learner_queue_size = 64, _tick = 6451, _time = 1.6548e+09)
[2022-06-09 17:26:21,194][root][INFO] - Step 42398720 @ 4091.3 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 1.3544e+04, step = 42398720, mean_episode_return = 76.96, mean_episode_step = 2005.1, total_loss = 101.88, pg_loss = 54.712, baseline_loss = 61.275, entropy_loss = -14.109, learner_queue_size = 64, _tick = 6454, _time = 1.6548e+09)
[2022-06-09 17:26:26,198][root][INFO] - Step 42414080 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.3549e+04, step = 42414080, mean_episode_return = 12.05, mean_episode_step = 2018.9, total_loss = -64.253, pg_loss = -70.54, baseline_loss = 20.316, entropy_loss = -14.03, learner_queue_size = 64, _tick = 6456, _time = 1.6548e+09)
[2022-06-09 17:26:31,202][root][INFO] - Step 42429440 @ 3069.5 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.3554e+04, step = 42429440, mean_episode_return = 8.5196, mean_episode_step = 1998.6, total_loss = -19.185, pg_loss = -27.102, baseline_loss = 22.088, entropy_loss = -14.171, learner_queue_size = 64, _tick = 6459, _time = 1.6548e+09)
[2022-06-09 17:26:36,206][root][INFO] - Step 42444800 @ 3069.6 SPS. Inference batcher size: 71. Learner queue size: 64. Other stats: (train_seconds = 1.3559e+04, step = 42444800, mean_episode_return = 7.3796, mean_episode_step = 1841.2, total_loss = -194.92, pg_loss = -198.03, baseline_loss = 17.448, entropy_loss = -14.338, learner_queue_size = 64, _tick = 6462, _time = 1.6548e+09)
[2022-06-09 17:26:41,210][root][INFO] - Step 42460160 @ 3069.4 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1.3564e+04, step = 42460160, mean_episode_return = 172.07, mean_episode_step = 1713.2, total_loss = 66.745, pg_loss = 34.661, baseline_loss = 46.429, entropy_loss = -14.344, learner_queue_size = 64, _tick = 6464, _time = 1.6548e+09)
[2022-06-09 17:26:46,214][root][INFO] - Step 42475520 @ 3069.6 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.3569e+04, step = 42475520, mean_episode_return = None, mean_episode_step = 1771.3, total_loss = -11.255, pg_loss = -28.395, baseline_loss = 31.096, entropy_loss = -13.956, learner_queue_size = 64, _tick = 6466, _time = 1.6548e+09)
[2022-06-09 17:26:51,218][root][INFO] - Step 42490880 @ 3069.6 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.3574e+04, step = 42490880, mean_episode_return = 34.267, mean_episode_step = 1832.0, total_loss = -126.4, pg_loss = -131.59, baseline_loss = 19.272, entropy_loss = -14.084, learner_queue_size = 64, _tick = 6469, _time = 1.6548e+09)
[2022-06-09 17:26:56,222][root][INFO] - Step 42506240 @ 3069.6 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.3579e+04, step = 42506240, mean_episode_return = None, mean_episode_step = 1863.8, total_loss = 0.5266, pg_loss = -4.9031, baseline_loss = 19.487, entropy_loss = -14.057, learner_queue_size = 64, _tick = 6471, _time = 1.6548e+09)
[2022-06-09 17:27:01,226][root][INFO] - Step 42526720 @ 4092.7 SPS. Inference batcher size: 78. Learner queue size: 64. Other stats: (train_seconds = 1.3584e+04, step = 42526720, mean_episode_return = 37.381, mean_episode_step = 1671.9, total_loss = 182.11, pg_loss = 152.17, baseline_loss = 44.052, entropy_loss = -14.113, learner_queue_size = 64, _tick = 6474, _time = 1.6548e+09)
[2022-06-09 17:27:06,230][root][INFO] - Step 42542080 @ 3069.5 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 1.3589e+04, step = 42542080, mean_episode_return = None, mean_episode_step = 1715.1, total_loss = 274.21, pg_loss = 233.2, baseline_loss = 55.129, entropy_loss = -14.115, learner_queue_size = 64, _tick = 6476, _time = 1.6548e+09)
[2022-06-09 17:27:11,234][root][INFO] - Step 42557440 @ 3069.5 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 1.3594e+04, step = 42557440, mean_episode_return = -26.681, mean_episode_step = 2042.8, total_loss = -10.485, pg_loss = -18.049, baseline_loss = 21.611, entropy_loss = -14.047, learner_queue_size = 64, _tick = 6479, _time = 1.6548e+09)
[2022-06-09 17:27:16,238][root][INFO] - Step 42572800 @ 3069.6 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 1.3599e+04, step = 42572800, mean_episode_return = 69.107, mean_episode_step = 2206.8, total_loss = 298.7, pg_loss = 233.24, baseline_loss = 79.656, entropy_loss = -14.2, learner_queue_size = 64, _tick = 6482, _time = 1.6548e+09)
[2022-06-09 17:27:21,242][root][INFO] - Step 42588160 @ 3069.6 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.3604e+04, step = 42588160, mean_episode_return = 111.46, mean_episode_step = 2125.9, total_loss = -169.7, pg_loss = -184.86, baseline_loss = 29.332, entropy_loss = -14.172, learner_queue_size = 64, _tick = 6484, _time = 1.6548e+09)
[2022-06-09 17:27:26,246][root][INFO] - Step 42603520 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.3609e+04, step = 42603520, mean_episode_return = 27.39, mean_episode_step = 1949.1, total_loss = 26.194, pg_loss = 13.429, baseline_loss = 27.007, entropy_loss = -14.241, learner_queue_size = 64, _tick = 6487, _time = 1.6548e+09)
[2022-06-09 17:27:31,250][root][INFO] - Step 42618880 @ 3069.5 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 1.3614e+04, step = 42618880, mean_episode_return = 47.916, mean_episode_step = 2169.6, total_loss = -186.92, pg_loss = -193.95, baseline_loss = 20.978, entropy_loss = -13.947, learner_queue_size = 64, _tick = 6490, _time = 1.6548e+09)
[2022-06-09 17:27:36,254][root][INFO] - Step 42634240 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.3619e+04, step = 42634240, mean_episode_return = 14.08, mean_episode_step = 2072.8, total_loss = 247.53, pg_loss = 212.15, baseline_loss = 49.507, entropy_loss = -14.123, learner_queue_size = 64, _tick = 6493, _time = 1.6548e+09)
[2022-06-09 17:27:41,258][root][INFO] - Step 42649600 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.3624e+04, step = 42649600, mean_episode_return = 51.88, mean_episode_step = 1995.9, total_loss = 205.3, pg_loss = 147.7, baseline_loss = 71.67, entropy_loss = -14.069, learner_queue_size = 64, _tick = 6496, _time = 1.6548e+09)
[2022-06-09 17:27:46,262][root][INFO] - Step 42664960 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.3629e+04, step = 42664960, mean_episode_return = 93.319, mean_episode_step = 1996.4, total_loss = 143.76, pg_loss = 119.24, baseline_loss = 38.562, entropy_loss = -14.044, learner_queue_size = 64, _tick = 6499, _time = 1.6548e+09)
[2022-06-09 17:27:51,266][root][INFO] - Step 42680320 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.3634e+04, step = 42680320, mean_episode_return = 25.92, mean_episode_step = 1983.3, total_loss = -104.28, pg_loss = -126.52, baseline_loss = 36.274, entropy_loss = -14.032, learner_queue_size = 64, _tick = 6501, _time = 1.6548e+09)
[2022-06-09 17:27:56,270][root][INFO] - Step 42695680 @ 3069.6 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.3639e+04, step = 42695680, mean_episode_return = None, mean_episode_step = 1919.6, total_loss = -251.27, pg_loss = -238.8, baseline_loss = 1.7002, entropy_loss = -14.17, learner_queue_size = 64, _tick = 6503, _time = 1.6548e+09)
[2022-06-09 17:28:01,275][root][INFO] - Step 42716160 @ 4092.2 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.3644e+04, step = 42716160, mean_episode_return = 45.365, mean_episode_step = 2050.7, total_loss = -64.348, pg_loss = -84.829, baseline_loss = 34.719, entropy_loss = -14.237, learner_queue_size = 64, _tick = 6507, _time = 1.6548e+09)
[2022-06-09 17:28:06,278][root][INFO] - Step 42731520 @ 3069.9 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 1.3649e+04, step = 42731520, mean_episode_return = None, mean_episode_step = 1928.0, total_loss = 93.72, pg_loss = 83.252, baseline_loss = 24.77, entropy_loss = -14.302, learner_queue_size = 64, _tick = 6509, _time = 1.6548e+09)
[2022-06-09 17:28:11,284][root][INFO] - Step 42746880 @ 3068.3 SPS. Inference batcher size: 18. Learner queue size: 64. Other stats: (train_seconds = 1.3654e+04, step = 42746880, mean_episode_return = 67.656, mean_episode_step = 1717.2, total_loss = 57.768, pg_loss = 31.654, baseline_loss = 40.579, entropy_loss = -14.465, learner_queue_size = 64, _tick = 6511, _time = 1.6548e+09)
[2022-06-09 17:28:16,290][root][INFO] - Step 42762240 @ 3068.3 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 1.3659e+04, step = 42762240, mean_episode_return = 34.146, mean_episode_step = 1897.5, total_loss = 76.855, pg_loss = 34.978, baseline_loss = 56.508, entropy_loss = -14.631, learner_queue_size = 64, _tick = 6514, _time = 1.6548e+09)
[2022-06-09 17:28:21,294][root][INFO] - Step 42777600 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.3664e+04, step = 42777600, mean_episode_return = 101.01, mean_episode_step = 1822.6, total_loss = 138.8, pg_loss = 107.63, baseline_loss = 45.765, entropy_loss = -14.593, learner_queue_size = 64, _tick = 6516, _time = 1.6548e+09)
[2022-06-09 17:28:26,298][root][INFO] - Step 42792960 @ 3069.5 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 1.3669e+04, step = 42792960, mean_episode_return = -4.6451, mean_episode_step = 1802.8, total_loss = -240.57, pg_loss = -246.53, baseline_loss = 20.757, entropy_loss = -14.796, learner_queue_size = 64, _tick = 6519, _time = 1.6548e+09)
[2022-06-09 17:28:31,302][root][INFO] - Step 42808320 @ 3069.7 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 1.3674e+04, step = 42808320, mean_episode_return = 54.054, mean_episode_step = 1958.4, total_loss = 275.53, pg_loss = 224.7, baseline_loss = 65.653, entropy_loss = -14.826, learner_queue_size = 64, _tick = 6522, _time = 1.6548e+09)
[2022-06-09 17:28:36,306][root][INFO] - Step 42823680 @ 3069.5 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 1.3679e+04, step = 42823680, mean_episode_return = 66.42, mean_episode_step = 2114.5, total_loss = 6.3396, pg_loss = -1.3645, baseline_loss = 22.651, entropy_loss = -14.947, learner_queue_size = 64, _tick = 6525, _time = 1.6548e+09)
[2022-06-09 17:28:41,312][root][INFO] - Step 42839040 @ 3068.3 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.3684e+04, step = 42839040, mean_episode_return = 89.108, mean_episode_step = 1589.9, total_loss = 164.74, pg_loss = 113.54, baseline_loss = 66.36, entropy_loss = -15.16, learner_queue_size = 64, _tick = 6528, _time = 1.6548e+09)
[2022-06-09 17:28:46,318][root][INFO] - Step 42854400 @ 3068.5 SPS. Inference batcher size: 13. Learner queue size: 64. Other stats: (train_seconds = 1.3689e+04, step = 42854400, mean_episode_return = 59.14, mean_episode_step = 1649.6, total_loss = 686.06, pg_loss = 429.02, baseline_loss = 272.05, entropy_loss = -15.024, learner_queue_size = 64, _tick = 6531, _time = 1.6548e+09)
[2022-06-09 17:28:51,322][root][INFO] - Step 42874880 @ 4092.6 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 1.3694e+04, step = 42874880, mean_episode_return = 11.869, mean_episode_step = 1700.4, total_loss = 185.75, pg_loss = 149.23, baseline_loss = 51.402, entropy_loss = -14.881, learner_queue_size = 64, _tick = 6535, _time = 1.6548e+09)
[2022-06-09 17:28:56,326][root][INFO] - Step 42890240 @ 3069.5 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 1.3699e+04, step = 42890240, mean_episode_return = 6.5321, mean_episode_step = 1979.5, total_loss = -201.01, pg_loss = -210.23, baseline_loss = 24.064, entropy_loss = -14.845, learner_queue_size = 64, _tick = 6538, _time = 1.6548e+09)
[2022-06-09 17:29:01,332][root][INFO] - Step 42905600 @ 3068.2 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 1.3704e+04, step = 42905600, mean_episode_return = 19.83, mean_episode_step = 1855.8, total_loss = 41.617, pg_loss = 14.944, baseline_loss = 41.387, entropy_loss = -14.714, learner_queue_size = 64, _tick = 6541, _time = 1.6548e+09)
[2022-06-09 17:29:06,338][root][INFO] - Step 42920960 @ 3068.4 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.3709e+04, step = 42920960, mean_episode_return = 78.718, mean_episode_step = 1501.8, total_loss = -83.844, pg_loss = -79.184, baseline_loss = 9.8018, entropy_loss = -14.462, learner_queue_size = 64, _tick = 6544, _time = 1.6548e+09)
[2022-06-09 17:29:11,342][root][INFO] - Step 42936320 @ 3069.5 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.3714e+04, step = 42936320, mean_episode_return = None, mean_episode_step = 1635.5, total_loss = 22.51, pg_loss = 12.732, baseline_loss = 24.337, entropy_loss = -14.559, learner_queue_size = 64, _tick = 6546, _time = 1.6548e+09)
[2022-06-09 17:29:16,346][root][INFO] - Step 42951680 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.3719e+04, step = 42951680, mean_episode_return = None, mean_episode_step = 1767.7, total_loss = 30.506, pg_loss = 20.866, baseline_loss = 24.436, entropy_loss = -14.797, learner_queue_size = 64, _tick = 6547, _time = 1.6548e+09)
[2022-06-09 17:29:21,350][root][INFO] - Step 42967040 @ 3069.5 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.3724e+04, step = 42967040, mean_episode_return = 1.8195, mean_episode_step = 1646.7, total_loss = -287.99, pg_loss = -282.05, baseline_loss = 8.9171, entropy_loss = -14.862, learner_queue_size = 64, _tick = 6550, _time = 1.6548e+09)
[2022-06-09 17:29:26,354][root][INFO] - Step 42982400 @ 3069.5 SPS. Inference batcher size: 15. Learner queue size: 64. Other stats: (train_seconds = 1.3729e+04, step = 42982400, mean_episode_return = -3.8604, mean_episode_step = 1509.1, total_loss = -77.003, pg_loss = -80.606, baseline_loss = 18.641, entropy_loss = -15.037, learner_queue_size = 64, _tick = 6552, _time = 1.6548e+09)
[2022-06-09 17:29:31,361][root][INFO] - Step 43002880 @ 4090.3 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 1.3734e+04, step = 43002880, mean_episode_return = 33.491, mean_episode_step = 1740.9, total_loss = -134.66, pg_loss = -146.89, baseline_loss = 27.122, entropy_loss = -14.9, learner_queue_size = 64, _tick = 6555, _time = 1.6548e+09)
[2022-06-09 17:29:36,366][root][INFO] - Step 43018240 @ 3069.0 SPS. Inference batcher size: 74. Learner queue size: 64. Other stats: (train_seconds = 1.3739e+04, step = 43018240, mean_episode_return = 48.91, mean_episode_step = 1723.7, total_loss = 48.414, pg_loss = 17.443, baseline_loss = 46.06, entropy_loss = -15.089, learner_queue_size = 64, _tick = 6558, _time = 1.6548e+09)
[2022-06-09 17:29:41,372][root][INFO] - Step 43033600 @ 3068.3 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 1.3744e+04, step = 43033600, mean_episode_return = None, mean_episode_step = 1889.7, total_loss = -79.798, pg_loss = -75.715, baseline_loss = 10.76, entropy_loss = -14.843, learner_queue_size = 64, _tick = 6560, _time = 1.6548e+09)
[2022-06-09 17:29:46,378][root][INFO] - Step 43048960 @ 3068.3 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.3749e+04, step = 43048960, mean_episode_return = 41.615, mean_episode_step = 1671.4, total_loss = 118.5, pg_loss = 95.083, baseline_loss = 38.257, entropy_loss = -14.836, learner_queue_size = 64, _tick = 6563, _time = 1.6548e+09)
[2022-06-09 17:29:51,382][root][INFO] - Step 43064320 @ 3069.3 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.3754e+04, step = 43064320, mean_episode_return = 45.289, mean_episode_step = 1676.8, total_loss = -136.69, pg_loss = -137.79, baseline_loss = 15.938, entropy_loss = -14.836, learner_queue_size = 64, _tick = 6566, _time = 1.6548e+09)
[2022-06-09 17:29:56,386][root][INFO] - Step 43079680 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.3759e+04, step = 43079680, mean_episode_return = 46.595, mean_episode_step = 1883.5, total_loss = -68.193, pg_loss = -82.681, baseline_loss = 29.267, entropy_loss = -14.778, learner_queue_size = 64, _tick = 6569, _time = 1.6548e+09)
[2022-06-09 17:30:01,390][root][INFO] - Step 43095040 @ 3069.8 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.3764e+04, step = 43095040, mean_episode_return = 79.16, mean_episode_step = 1883.5, total_loss = -114.48, pg_loss = -125.49, baseline_loss = 25.7, entropy_loss = -14.695, learner_queue_size = 64, _tick = 6571, _time = 1.6548e+09)
[2022-06-09 17:30:06,394][root][INFO] - Step 43110400 @ 3069.5 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.3769e+04, step = 43110400, mean_episode_return = None, mean_episode_step = 1382.3, total_loss = 465.28, pg_loss = 424.15, baseline_loss = 55.931, entropy_loss = -14.804, learner_queue_size = 64, _tick = 6572, _time = 1.6548e+09)
[2022-06-09 17:30:11,398][root][INFO] - Step 43125760 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.3774e+04, step = 43125760, mean_episode_return = 65.862, mean_episode_step = 1691.6, total_loss = 620.09, pg_loss = 525.92, baseline_loss = 109.08, entropy_loss = -14.91, learner_queue_size = 64, _tick = 6575, _time = 1.6548e+09)
[2022-06-09 17:30:16,402][root][INFO] - Step 43141120 @ 3069.6 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.3779e+04, step = 43141120, mean_episode_return = None, mean_episode_step = 1642.3, total_loss = 151.47, pg_loss = 135.24, baseline_loss = 31.021, entropy_loss = -14.79, learner_queue_size = 64, _tick = 6577, _time = 1.6548e+09)
[2022-06-09 17:30:21,406][root][INFO] - Step 43156480 @ 3069.6 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.3784e+04, step = 43156480, mean_episode_return = 82.512, mean_episode_step = 2046.6, total_loss = 352.8, pg_loss = 307.12, baseline_loss = 60.48, entropy_loss = -14.805, learner_queue_size = 64, _tick = 6580, _time = 1.6548e+09)
[2022-06-09 17:30:26,410][root][INFO] - Step 43176960 @ 4092.7 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.3789e+04, step = 43176960, mean_episode_return = 4.8815, mean_episode_step = 1599.3, total_loss = 138.7, pg_loss = 94.217, baseline_loss = 59.213, entropy_loss = -14.728, learner_queue_size = 64, _tick = 6584, _time = 1.6548e+09)
[2022-06-09 17:30:31,414][root][INFO] - Step 43192320 @ 3069.5 SPS. Inference batcher size: 81. Learner queue size: 64. Other stats: (train_seconds = 1.3794e+04, step = 43192320, mean_episode_return = 37.792, mean_episode_step = 1399.2, total_loss = -6.0279, pg_loss = -32.783, baseline_loss = 41.377, entropy_loss = -14.622, learner_queue_size = 64, _tick = 6586, _time = 1.6548e+09)
[2022-06-09 17:30:36,418][root][INFO] - Step 43207680 @ 3069.4 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 1.3799e+04, step = 43207680, mean_episode_return = None, mean_episode_step = 1981.0, total_loss = 232.87, pg_loss = 206.65, baseline_loss = 40.65, entropy_loss = -14.438, learner_queue_size = 64, _tick = 6587, _time = 1.6548e+09)
[2022-06-09 17:30:41,430][root][INFO] - Step 43223040 @ 3064.6 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.3804e+04, step = 43223040, mean_episode_return = 68.143, mean_episode_step = 1832.5, total_loss = -310.35, pg_loss = -307.23, baseline_loss = 11.38, entropy_loss = -14.505, learner_queue_size = 64, _tick = 6589, _time = 1.6548e+09)
[2022-06-09 17:30:46,434][root][INFO] - Step 43238400 @ 3069.7 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.3809e+04, step = 43238400, mean_episode_return = None, mean_episode_step = 1774.4, total_loss = 707.81, pg_loss = 565.34, baseline_loss = 157.02, entropy_loss = -14.56, learner_queue_size = 64, _tick = 6591, _time = 1.6548e+09)
[2022-06-09 17:30:51,438][root][INFO] - Step 43253760 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.3814e+04, step = 43253760, mean_episode_return = None, mean_episode_step = 1818.1, total_loss = 167.54, pg_loss = 139.42, baseline_loss = 42.562, entropy_loss = -14.436, learner_queue_size = 64, _tick = 6593, _time = 1.6548e+09)
[2022-06-09 17:30:56,442][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 17:30:56,644][root][INFO] - Step 43269120 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.3819e+04, step = 43269120, mean_episode_return = 52.115, mean_episode_step = 1758.0, total_loss = 112.73, pg_loss = 53.479, baseline_loss = 73.497, entropy_loss = -14.246, learner_queue_size = 64, _tick = 6596, _time = 1.6548e+09)
[2022-06-09 17:31:01,646][root][INFO] - Step 43289600 @ 3935.5 SPS. Inference batcher size: 78. Learner queue size: 64. Other stats: (train_seconds = 1.3825e+04, step = 43289600, mean_episode_return = None, mean_episode_step = 1749.8, total_loss = 107.04, pg_loss = 93.131, baseline_loss = 28.132, entropy_loss = -14.225, learner_queue_size = 64, _tick = 6598, _time = 1.6548e+09)
[2022-06-09 17:31:06,650][root][INFO] - Step 43304960 @ 3069.5 SPS. Inference batcher size: 74. Learner queue size: 64. Other stats: (train_seconds = 1.383e+04, step = 43304960, mean_episode_return = None, mean_episode_step = 1641.9, total_loss = 13.197, pg_loss = 1.6196, baseline_loss = 25.635, entropy_loss = -14.058, learner_queue_size = 64, _tick = 6600, _time = 1.6548e+09)
[2022-06-09 17:31:11,654][root][INFO] - Step 43320320 @ 3069.5 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 1.3835e+04, step = 43320320, mean_episode_return = None, mean_episode_step = 1668.4, total_loss = 16.858, pg_loss = -12.749, baseline_loss = 43.622, entropy_loss = -14.015, learner_queue_size = 64, _tick = 6600, _time = 1.6548e+09)
[2022-06-09 17:31:16,658][root][INFO] - Step 43335680 @ 3069.5 SPS. Inference batcher size: 88. Learner queue size: 64. Other stats: (train_seconds = 1.384e+04, step = 43335680, mean_episode_return = 80.649, mean_episode_step = 1725.0, total_loss = -46.29, pg_loss = -70.458, baseline_loss = 38.342, entropy_loss = -14.174, learner_queue_size = 64, _tick = 6601, _time = 1.6548e+09)
[2022-06-09 17:31:21,662][root][INFO] - Step 43351040 @ 3069.6 SPS. Inference batcher size: 67. Learner queue size: 64. Other stats: (train_seconds = 1.3845e+04, step = 43351040, mean_episode_return = 21.14, mean_episode_step = 1799.6, total_loss = -290.31, pg_loss = -295.43, baseline_loss = 19.405, entropy_loss = -14.28, learner_queue_size = 64, _tick = 6603, _time = 1.6548e+09)
[2022-06-09 17:31:26,666][root][INFO] - Step 43366400 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.385e+04, step = 43366400, mean_episode_return = 32.86, mean_episode_step = 1723.8, total_loss = 365.55, pg_loss = 321.53, baseline_loss = 58.344, entropy_loss = -14.324, learner_queue_size = 64, _tick = 6606, _time = 1.6548e+09)
[2022-06-09 17:31:31,670][root][INFO] - Step 43381760 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.3855e+04, step = 43381760, mean_episode_return = 46.846, mean_episode_step = 1778.1, total_loss = 190.11, pg_loss = 154.78, baseline_loss = 49.615, entropy_loss = -14.284, learner_queue_size = 64, _tick = 6608, _time = 1.6548e+09)
[2022-06-09 17:31:36,674][root][INFO] - Step 43397120 @ 3069.6 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.386e+04, step = 43397120, mean_episode_return = None, mean_episode_step = 1978.1, total_loss = 3.349, pg_loss = -14.528, baseline_loss = 32.033, entropy_loss = -14.156, learner_queue_size = 64, _tick = 6610, _time = 1.6548e+09)
[2022-06-09 17:31:41,678][root][INFO] - Step 43412480 @ 3069.4 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.3865e+04, step = 43412480, mean_episode_return = None, mean_episode_step = 1970.2, total_loss = -101.41, pg_loss = -102.36, baseline_loss = 15.182, entropy_loss = -14.231, learner_queue_size = 64, _tick = 6611, _time = 1.6548e+09)
[2022-06-09 17:31:46,682][root][INFO] - Step 43427840 @ 3069.6 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.387e+04, step = 43427840, mean_episode_return = 88.08, mean_episode_step = 1911.0, total_loss = -105.46, pg_loss = -112.73, baseline_loss = 21.716, entropy_loss = -14.443, learner_queue_size = 64, _tick = 6614, _time = 1.6548e+09)
[2022-06-09 17:31:51,686][root][INFO] - Step 43443200 @ 3069.5 SPS. Inference batcher size: 10. Learner queue size: 64. Other stats: (train_seconds = 1.3875e+04, step = 43443200, mean_episode_return = 144.51, mean_episode_step = 1689.9, total_loss = 44.779, pg_loss = 31.901, baseline_loss = 27.382, entropy_loss = -14.505, learner_queue_size = 64, _tick = 6617, _time = 1.6548e+09)
[2022-06-09 17:31:56,690][root][INFO] - Step 43458560 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.388e+04, step = 43458560, mean_episode_return = 72.059, mean_episode_step = 1702.7, total_loss = -30.1, pg_loss = -66.489, baseline_loss = 50.599, entropy_loss = -14.209, learner_queue_size = 64, _tick = 6620, _time = 1.6548e+09)
[2022-06-09 17:32:01,696][root][INFO] - Step 43479040 @ 4091.0 SPS. Inference batcher size: 79. Learner queue size: 64. Other stats: (train_seconds = 1.3885e+04, step = 43479040, mean_episode_return = 142.21, mean_episode_step = 1714.1, total_loss = 192.15, pg_loss = 167.94, baseline_loss = 38.336, entropy_loss = -14.12, learner_queue_size = 64, _tick = 6624, _time = 1.6548e+09)
[2022-06-09 17:32:06,702][root][INFO] - Step 43494400 @ 3068.4 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 1.389e+04, step = 43494400, mean_episode_return = 52.783, mean_episode_step = 1857.0, total_loss = -133.23, pg_loss = -135.32, baseline_loss = 16.272, entropy_loss = -14.181, learner_queue_size = 64, _tick = 6627, _time = 1.6548e+09)
[2022-06-09 17:32:11,706][root][INFO] - Step 43509760 @ 3069.5 SPS. Inference batcher size: 13. Learner queue size: 64. Other stats: (train_seconds = 1.3895e+04, step = 43509760, mean_episode_return = 46.658, mean_episode_step = 1770.4, total_loss = 40.518, pg_loss = 16.468, baseline_loss = 38.118, entropy_loss = -14.068, learner_queue_size = 64, _tick = 6629, _time = 1.6548e+09)
[2022-06-09 17:32:16,710][root][INFO] - Step 43525120 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.39e+04, step = 43525120, mean_episode_return = None, mean_episode_step = 1797.7, total_loss = -110.23, pg_loss = -104.93, baseline_loss = 8.543, entropy_loss = -13.844, learner_queue_size = 64, _tick = 6631, _time = 1.6548e+09)
[2022-06-09 17:32:21,714][root][INFO] - Step 43540480 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.3905e+04, step = 43540480, mean_episode_return = 79.542, mean_episode_step = 1942.8, total_loss = -24.712, pg_loss = -69.377, baseline_loss = 58.58, entropy_loss = -13.915, learner_queue_size = 64, _tick = 6633, _time = 1.6548e+09)
[2022-06-09 17:32:26,718][root][INFO] - Step 43555840 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.391e+04, step = 43555840, mean_episode_return = 23.999, mean_episode_step = 1856.0, total_loss = -235.56, pg_loss = -231.56, baseline_loss = 10.087, entropy_loss = -14.094, learner_queue_size = 64, _tick = 6635, _time = 1.6548e+09)
[2022-06-09 17:32:31,722][root][INFO] - Step 43571200 @ 3069.6 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.3915e+04, step = 43571200, mean_episode_return = 50.66, mean_episode_step = 1773.4, total_loss = 44.213, pg_loss = 26.575, baseline_loss = 31.774, entropy_loss = -14.136, learner_queue_size = 64, _tick = 6637, _time = 1.6548e+09)
[2022-06-09 17:32:36,726][root][INFO] - Step 43586560 @ 3069.4 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.392e+04, step = 43586560, mean_episode_return = -1.69, mean_episode_step = 1996.0, total_loss = -73.77, pg_loss = -79.572, baseline_loss = 19.854, entropy_loss = -14.051, learner_queue_size = 64, _tick = 6639, _time = 1.6548e+09)
[2022-06-09 17:32:41,731][root][INFO] - Step 43601920 @ 3069.1 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.3925e+04, step = 43601920, mean_episode_return = None, mean_episode_step = 1941.3, total_loss = -67.085, pg_loss = -65.171, baseline_loss = 12.276, entropy_loss = -14.19, learner_queue_size = 64, _tick = 6641, _time = 1.6548e+09)
[2022-06-09 17:32:46,734][root][INFO] - Step 43622400 @ 4093.4 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 1.393e+04, step = 43622400, mean_episode_return = None, mean_episode_step = 1840.8, total_loss = 290.87, pg_loss = 258.75, baseline_loss = 46.563, entropy_loss = -14.444, learner_queue_size = 64, _tick = 6643, _time = 1.6548e+09)
[2022-06-09 17:32:51,738][root][INFO] - Step 43637760 @ 3069.6 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 1.3935e+04, step = 43637760, mean_episode_return = 25.179, mean_episode_step = 2279.4, total_loss = -246.4, pg_loss = -239.98, baseline_loss = 7.9277, entropy_loss = -14.344, learner_queue_size = 64, _tick = 6646, _time = 1.6548e+09)
[2022-06-09 17:32:56,742][root][INFO] - Step 43653120 @ 3069.4 SPS. Inference batcher size: 74. Learner queue size: 64. Other stats: (train_seconds = 1.394e+04, step = 43653120, mean_episode_return = None, mean_episode_step = 2079.0, total_loss = 122.17, pg_loss = 99.314, baseline_loss = 37.299, entropy_loss = -14.444, learner_queue_size = 64, _tick = 6647, _time = 1.6548e+09)
[2022-06-09 17:33:01,746][root][INFO] - Step 43668480 @ 3069.6 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 1.3945e+04, step = 43668480, mean_episode_return = 62.192, mean_episode_step = 1957.6, total_loss = -169.64, pg_loss = -185.06, baseline_loss = 29.958, entropy_loss = -14.539, learner_queue_size = 64, _tick = 6649, _time = 1.6548e+09)
[2022-06-09 17:33:06,750][root][INFO] - Step 43683840 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.395e+04, step = 43683840, mean_episode_return = None, mean_episode_step = 2087.3, total_loss = 38.725, pg_loss = 37.203, baseline_loss = 16.311, entropy_loss = -14.788, learner_queue_size = 64, _tick = 6650, _time = 1.6548e+09)
[2022-06-09 17:33:11,754][root][INFO] - Step 43699200 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.3955e+04, step = 43699200, mean_episode_return = None, mean_episode_step = 2060.1, total_loss = 121.01, pg_loss = 85.582, baseline_loss = 50.137, entropy_loss = -14.706, learner_queue_size = 64, _tick = 6652, _time = 1.6548e+09)
[2022-06-09 17:33:16,758][root][INFO] - Step 43714560 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.396e+04, step = 43714560, mean_episode_return = 66.7, mean_episode_step = 2031.9, total_loss = 262.17, pg_loss = 221.31, baseline_loss = 55.767, entropy_loss = -14.908, learner_queue_size = 64, _tick = 6655, _time = 1.6548e+09)
[2022-06-09 17:33:21,762][root][INFO] - Step 43729920 @ 3069.5 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.3965e+04, step = 43729920, mean_episode_return = 127.94, mean_episode_step = 1948.0, total_loss = -39.794, pg_loss = -44.991, baseline_loss = 20.155, entropy_loss = -14.958, learner_queue_size = 64, _tick = 6658, _time = 1.6548e+09)
[2022-06-09 17:33:26,766][root][INFO] - Step 43745280 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.397e+04, step = 43745280, mean_episode_return = 53.696, mean_episode_step = 1930.0, total_loss = -153.24, pg_loss = -153.66, baseline_loss = 15.424, entropy_loss = -15.003, learner_queue_size = 64, _tick = 6661, _time = 1.6548e+09)
[2022-06-09 17:33:31,770][root][INFO] - Step 43765760 @ 4092.7 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 1.3975e+04, step = 43765760, mean_episode_return = 97.786, mean_episode_step = 1893.5, total_loss = 218.28, pg_loss = 184.65, baseline_loss = 48.535, entropy_loss = -14.897, learner_queue_size = 64, _tick = 6665, _time = 1.6548e+09)
[2022-06-09 17:33:36,776][root][INFO] - Step 43781120 @ 3068.2 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.398e+04, step = 43781120, mean_episode_return = 6.7647, mean_episode_step = 2099.5, total_loss = 166.74, pg_loss = 134.25, baseline_loss = 47.439, entropy_loss = -14.947, learner_queue_size = 64, _tick = 6668, _time = 1.6548e+09)
[2022-06-09 17:33:41,782][root][INFO] - Step 43796480 @ 3068.4 SPS. Inference batcher size: 76. Learner queue size: 64. Other stats: (train_seconds = 1.3985e+04, step = 43796480, mean_episode_return = 0.70971, mean_episode_step = 1807.3, total_loss = 179.94, pg_loss = 155.97, baseline_loss = 38.904, entropy_loss = -14.936, learner_queue_size = 64, _tick = 6671, _time = 1.6548e+09)
[2022-06-09 17:33:46,786][root][INFO] - Step 43811840 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.399e+04, step = 43811840, mean_episode_return = 73.259, mean_episode_step = 1590.8, total_loss = -59.529, pg_loss = -68.276, baseline_loss = 23.538, entropy_loss = -14.791, learner_queue_size = 64, _tick = 6674, _time = 1.6548e+09)
[2022-06-09 17:33:51,790][root][INFO] - Step 43827200 @ 3069.6 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1.3995e+04, step = 43827200, mean_episode_return = None, mean_episode_step = 1663.0, total_loss = 203.23, pg_loss = 176.42, baseline_loss = 41.454, entropy_loss = -14.644, learner_queue_size = 64, _tick = 6676, _time = 1.6548e+09)
[2022-06-09 17:33:56,794][root][INFO] - Step 43842560 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.4e+04, step = 43842560, mean_episode_return = 55.286, mean_episode_step = 1781.8, total_loss = -75.386, pg_loss = -94.567, baseline_loss = 33.753, entropy_loss = -14.572, learner_queue_size = 64, _tick = 6679, _time = 1.6548e+09)
[2022-06-09 17:34:01,798][root][INFO] - Step 43857920 @ 3069.5 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.4005e+04, step = 43857920, mean_episode_return = 42.535, mean_episode_step = 1814.5, total_loss = -52.898, pg_loss = -71.532, baseline_loss = 33.227, entropy_loss = -14.592, learner_queue_size = 64, _tick = 6681, _time = 1.6548e+09)
[2022-06-09 17:34:06,802][root][INFO] - Step 43873280 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.401e+04, step = 43873280, mean_episode_return = 9.8796, mean_episode_step = 2011.9, total_loss = -26.04, pg_loss = -38.131, baseline_loss = 26.758, entropy_loss = -14.667, learner_queue_size = 64, _tick = 6684, _time = 1.6548e+09)
[2022-06-09 17:34:11,806][root][INFO] - Step 43893760 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.4015e+04, step = 43893760, mean_episode_return = 2.0, mean_episode_step = 1574.9, total_loss = 10.653, pg_loss = -0.091888, baseline_loss = 25.58, entropy_loss = -14.835, learner_queue_size = 64, _tick = 6688, _time = 1.6548e+09)
[2022-06-09 17:34:16,810][root][INFO] - Step 43909120 @ 3069.5 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 1.402e+04, step = 43909120, mean_episode_return = 133.28, mean_episode_step = 1715.8, total_loss = -5.8251, pg_loss = -5.9667, baseline_loss = 14.963, entropy_loss = -14.821, learner_queue_size = 64, _tick = 6690, _time = 1.6548e+09)
[2022-06-09 17:34:21,814][root][INFO] - Step 43924480 @ 3069.5 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 1.4025e+04, step = 43924480, mean_episode_return = 106.69, mean_episode_step = 1682.0, total_loss = 78.479, pg_loss = 65.429, baseline_loss = 27.847, entropy_loss = -14.797, learner_queue_size = 64, _tick = 6693, _time = 1.6548e+09)
[2022-06-09 17:34:26,818][root][INFO] - Step 43939840 @ 3069.6 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 1.403e+04, step = 43939840, mean_episode_return = 82.262, mean_episode_step = 1710.1, total_loss = 74.084, pg_loss = 55.614, baseline_loss = 33.15, entropy_loss = -14.68, learner_queue_size = 64, _tick = 6695, _time = 1.6548e+09)
[2022-06-09 17:34:31,822][root][INFO] - Step 43955200 @ 3069.6 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.4035e+04, step = 43955200, mean_episode_return = 64.452, mean_episode_step = 2054.0, total_loss = 11.823, pg_loss = -12.628, baseline_loss = 39.14, entropy_loss = -14.689, learner_queue_size = 64, _tick = 6697, _time = 1.6548e+09)
[2022-06-09 17:34:36,826][root][INFO] - Step 43970560 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.404e+04, step = 43970560, mean_episode_return = 61.96, mean_episode_step = 1873.5, total_loss = 15.288, pg_loss = -7.8148, baseline_loss = 37.781, entropy_loss = -14.678, learner_queue_size = 64, _tick = 6700, _time = 1.6548e+09)
[2022-06-09 17:34:41,830][root][INFO] - Step 43985920 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.4045e+04, step = 43985920, mean_episode_return = 46.966, mean_episode_step = 1779.2, total_loss = 318.8, pg_loss = 269.75, baseline_loss = 63.77, entropy_loss = -14.716, learner_queue_size = 64, _tick = 6701, _time = 1.6548e+09)
[2022-06-09 17:34:46,834][root][INFO] - Step 44001280 @ 3069.6 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 1.405e+04, step = 44001280, mean_episode_return = None, mean_episode_step = 1947.7, total_loss = -26.714, pg_loss = -42.065, baseline_loss = 30.06, entropy_loss = -14.709, learner_queue_size = 64, _tick = 6703, _time = 1.6548e+09)
[2022-06-09 17:34:51,838][root][INFO] - Step 44021760 @ 4092.8 SPS. Inference batcher size: 104. Learner queue size: 64. Other stats: (train_seconds = 1.4055e+04, step = 44021760, mean_episode_return = 16.51, mean_episode_step = 2049.4, total_loss = -79.418, pg_loss = -92.694, baseline_loss = 27.756, entropy_loss = -14.481, learner_queue_size = 64, _tick = 6707, _time = 1.6548e+09)
[2022-06-09 17:34:56,842][root][INFO] - Step 44037120 @ 3069.5 SPS. Inference batcher size: 67. Learner queue size: 64. Other stats: (train_seconds = 1.406e+04, step = 44037120, mean_episode_return = None, mean_episode_step = 1914.7, total_loss = 30.246, pg_loss = 21.91, baseline_loss = 22.898, entropy_loss = -14.561, learner_queue_size = 64, _tick = 6709, _time = 1.6548e+09)
[2022-06-09 17:35:01,846][root][INFO] - Step 44052480 @ 3069.5 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 1.4065e+04, step = 44052480, mean_episode_return = 31.591, mean_episode_step = 2095.5, total_loss = -195.3, pg_loss = -193.97, baseline_loss = 13.283, entropy_loss = -14.604, learner_queue_size = 64, _tick = 6712, _time = 1.6548e+09)
[2022-06-09 17:35:06,850][root][INFO] - Step 44067840 @ 3069.6 SPS. Inference batcher size: 78. Learner queue size: 64. Other stats: (train_seconds = 1.407e+04, step = 44067840, mean_episode_return = 5.6896, mean_episode_step = 1761.1, total_loss = -2.7807, pg_loss = -16.967, baseline_loss = 28.752, entropy_loss = -14.566, learner_queue_size = 64, _tick = 6715, _time = 1.6548e+09)
[2022-06-09 17:35:11,854][root][INFO] - Step 44083200 @ 3069.5 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 1.4075e+04, step = 44083200, mean_episode_return = 40.422, mean_episode_step = 1953.0, total_loss = 860.1, pg_loss = 661.97, baseline_loss = 212.8, entropy_loss = -14.669, learner_queue_size = 64, _tick = 6718, _time = 1.6548e+09)
[2022-06-09 17:35:16,858][root][INFO] - Step 44098560 @ 3069.6 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.408e+04, step = 44098560, mean_episode_return = 32.63, mean_episode_step = 1996.0, total_loss = -27.035, pg_loss = -31.991, baseline_loss = 19.621, entropy_loss = -14.664, learner_queue_size = 64, _tick = 6721, _time = 1.6548e+09)
[2022-06-09 17:35:21,862][root][INFO] - Step 44113920 @ 3069.6 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.4085e+04, step = 44113920, mean_episode_return = 126.75, mean_episode_step = 1828.1, total_loss = -110.92, pg_loss = -120.49, baseline_loss = 24.233, entropy_loss = -14.66, learner_queue_size = 64, _tick = 6723, _time = 1.6548e+09)
[2022-06-09 17:35:26,866][root][INFO] - Step 44129280 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.409e+04, step = 44129280, mean_episode_return = 24.718, mean_episode_step = 1769.5, total_loss = -112.16, pg_loss = -125.16, baseline_loss = 27.677, entropy_loss = -14.673, learner_queue_size = 64, _tick = 6726, _time = 1.6548e+09)
[2022-06-09 17:35:31,870][root][INFO] - Step 44144640 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.4095e+04, step = 44144640, mean_episode_return = None, mean_episode_step = 1992.5, total_loss = -118.47, pg_loss = -110.07, baseline_loss = 6.2802, entropy_loss = -14.683, learner_queue_size = 64, _tick = 6728, _time = 1.6548e+09)
[2022-06-09 17:35:36,874][root][INFO] - Step 44160000 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.41e+04, step = 44160000, mean_episode_return = 60.831, mean_episode_step = 2176.8, total_loss = 75.746, pg_loss = 49.077, baseline_loss = 41.451, entropy_loss = -14.781, learner_queue_size = 64, _tick = 6731, _time = 1.6548e+09)
[2022-06-09 17:35:41,878][root][INFO] - Step 44175360 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.4105e+04, step = 44175360, mean_episode_return = 19.511, mean_episode_step = 2171.9, total_loss = 193.34, pg_loss = 166.26, baseline_loss = 41.714, entropy_loss = -14.638, learner_queue_size = 64, _tick = 6734, _time = 1.6548e+09)
[2022-06-09 17:35:46,882][root][INFO] - Step 44195840 @ 4092.8 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 1.411e+04, step = 44195840, mean_episode_return = None, mean_episode_step = 1936.9, total_loss = 2.3243, pg_loss = 3.2837, baseline_loss = 13.491, entropy_loss = -14.45, learner_queue_size = 64, _tick = 6737, _time = 1.6548e+09)
[2022-06-09 17:35:51,886][root][INFO] - Step 44211200 @ 3069.5 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 1.4115e+04, step = 44211200, mean_episode_return = 38.26, mean_episode_step = 2007.6, total_loss = 32.441, pg_loss = 23.61, baseline_loss = 23.432, entropy_loss = -14.601, learner_queue_size = 64, _tick = 6740, _time = 1.6548e+09)
[2022-06-09 17:35:56,890][root][INFO] - Step 44226560 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.412e+04, step = 44226560, mean_episode_return = 18.426, mean_episode_step = 2058.2, total_loss = -177.08, pg_loss = -176.33, baseline_loss = 13.81, entropy_loss = -14.559, learner_queue_size = 64, _tick = 6742, _time = 1.6548e+09)
[2022-06-09 17:36:01,894][root][INFO] - Step 44241920 @ 3069.6 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 1.4125e+04, step = 44241920, mean_episode_return = 49.803, mean_episode_step = 1885.4, total_loss = 13.362, pg_loss = -11.391, baseline_loss = 39.28, entropy_loss = -14.527, learner_queue_size = 64, _tick = 6744, _time = 1.6548e+09)
[2022-06-09 17:36:06,898][root][INFO] - Step 44257280 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.413e+04, step = 44257280, mean_episode_return = None, mean_episode_step = 2011.2, total_loss = -44.374, pg_loss = -45.971, baseline_loss = 15.966, entropy_loss = -14.37, learner_queue_size = 64, _tick = 6745, _time = 1.6548e+09)
[2022-06-09 17:36:11,902][root][INFO] - Step 44272640 @ 3069.5 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.4135e+04, step = 44272640, mean_episode_return = -0.19499, mean_episode_step = 1751.5, total_loss = 37.608, pg_loss = 20.424, baseline_loss = 31.54, entropy_loss = -14.355, learner_queue_size = 64, _tick = 6748, _time = 1.6548e+09)
[2022-06-09 17:36:16,906][root][INFO] - Step 44288000 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.414e+04, step = 44288000, mean_episode_return = 27.99, mean_episode_step = 1745.5, total_loss = 260.77, pg_loss = 228.22, baseline_loss = 46.863, entropy_loss = -14.311, learner_queue_size = 64, _tick = 6751, _time = 1.6548e+09)
[2022-06-09 17:36:21,910][root][INFO] - Step 44303360 @ 3069.6 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.4145e+04, step = 44303360, mean_episode_return = 26.906, mean_episode_step = 1997.2, total_loss = -128.11, pg_loss = -123.67, baseline_loss = 9.8317, entropy_loss = -14.268, learner_queue_size = 64, _tick = 6754, _time = 1.6548e+09)
[2022-06-09 17:36:26,914][root][INFO] - Step 44318720 @ 3069.6 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 1.415e+04, step = 44318720, mean_episode_return = 16.95, mean_episode_step = 2007.8, total_loss = 190.97, pg_loss = 160.83, baseline_loss = 44.415, entropy_loss = -14.272, learner_queue_size = 64, _tick = 6756, _time = 1.6548e+09)
[2022-06-09 17:36:31,920][root][INFO] - Step 44339200 @ 4091.2 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.4155e+04, step = 44339200, mean_episode_return = 92.68, mean_episode_step = 1825.4, total_loss = -148.86, pg_loss = -147.11, baseline_loss = 12.408, entropy_loss = -14.157, learner_queue_size = 64, _tick = 6759, _time = 1.6548e+09)
[2022-06-09 17:36:36,926][root][INFO] - Step 44354560 @ 3070.2 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 1.416e+04, step = 44354560, mean_episode_return = 1.2997, mean_episode_step = 1917.1, total_loss = 44.403, pg_loss = 30.613, baseline_loss = 28.008, entropy_loss = -14.219, learner_queue_size = 64, _tick = 6762, _time = 1.6548e+09)
[2022-06-09 17:36:41,930][root][INFO] - Step 44369920 @ 3067.6 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 1.4165e+04, step = 44369920, mean_episode_return = 73.15, mean_episode_step = 1653.2, total_loss = 111.48, pg_loss = 80.355, baseline_loss = 45.216, entropy_loss = -14.089, learner_queue_size = 64, _tick = 6765, _time = 1.6548e+09)
[2022-06-09 17:36:46,934][root][INFO] - Step 44385280 @ 3069.6 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.417e+04, step = 44385280, mean_episode_return = 13.75, mean_episode_step = 2098.3, total_loss = 39.72, pg_loss = 14.635, baseline_loss = 39.161, entropy_loss = -14.076, learner_queue_size = 64, _tick = 6767, _time = 1.6548e+09)
[2022-06-09 17:36:51,938][root][INFO] - Step 44400640 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.4175e+04, step = 44400640, mean_episode_return = 94.135, mean_episode_step = 1718.2, total_loss = -110.58, pg_loss = -119.78, baseline_loss = 23.336, entropy_loss = -14.131, learner_queue_size = 64, _tick = 6768, _time = 1.6548e+09)
[2022-06-09 17:36:56,942][root][INFO] - Step 44416000 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.418e+04, step = 44416000, mean_episode_return = 62.0, mean_episode_step = 1904.6, total_loss = -207.72, pg_loss = -209.0, baseline_loss = 15.414, entropy_loss = -14.132, learner_queue_size = 64, _tick = 6771, _time = 1.6548e+09)
[2022-06-09 17:37:01,946][root][INFO] - Step 44431360 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.4185e+04, step = 44431360, mean_episode_return = None, mean_episode_step = 2158.0, total_loss = 151.03, pg_loss = 132.33, baseline_loss = 32.676, entropy_loss = -13.976, learner_queue_size = 64, _tick = 6773, _time = 1.6548e+09)
[2022-06-09 17:37:06,950][root][INFO] - Step 44446720 @ 3069.5 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 1.419e+04, step = 44446720, mean_episode_return = 105.0, mean_episode_step = 2068.3, total_loss = 242.34, pg_loss = 212.53, baseline_loss = 43.605, entropy_loss = -13.789, learner_queue_size = 64, _tick = 6776, _time = 1.6548e+09)
[2022-06-09 17:37:11,954][root][INFO] - Step 44467200 @ 4092.7 SPS. Inference batcher size: 75. Learner queue size: 64. Other stats: (train_seconds = 1.4195e+04, step = 44467200, mean_episode_return = 14.149, mean_episode_step = 1935.9, total_loss = -167.32, pg_loss = -178.58, baseline_loss = 24.707, entropy_loss = -13.442, learner_queue_size = 64, _tick = 6779, _time = 1.6548e+09)
[2022-06-09 17:37:16,960][root][INFO] - Step 44482560 @ 3068.2 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 1.42e+04, step = 44482560, mean_episode_return = 24.902, mean_episode_step = 2138.4, total_loss = 36.376, pg_loss = 12.409, baseline_loss = 37.275, entropy_loss = -13.308, learner_queue_size = 64, _tick = 6781, _time = 1.6548e+09)
[2022-06-09 17:37:21,966][root][INFO] - Step 44497920 @ 3068.4 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.4205e+04, step = 44497920, mean_episode_return = 17.886, mean_episode_step = 1987.0, total_loss = -194.7, pg_loss = -199.2, baseline_loss = 17.94, entropy_loss = -13.448, learner_queue_size = 64, _tick = 6784, _time = 1.6548e+09)
[2022-06-09 17:37:26,970][root][INFO] - Step 44513280 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.421e+04, step = 44513280, mean_episode_return = 52.91, mean_episode_step = 2194.4, total_loss = -136.3, pg_loss = -148.49, baseline_loss = 25.825, entropy_loss = -13.63, learner_queue_size = 64, _tick = 6786, _time = 1.6548e+09)
[2022-06-09 17:37:31,974][root][INFO] - Step 44528640 @ 3069.7 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.4215e+04, step = 44528640, mean_episode_return = 83.056, mean_episode_step = 1944.0, total_loss = -88.242, pg_loss = -90.707, baseline_loss = 15.993, entropy_loss = -13.528, learner_queue_size = 64, _tick = 6789, _time = 1.6548e+09)
[2022-06-09 17:37:36,978][root][INFO] - Step 44544000 @ 3069.5 SPS. Inference batcher size: 18. Learner queue size: 64. Other stats: (train_seconds = 1.422e+04, step = 44544000, mean_episode_return = None, mean_episode_step = 1918.9, total_loss = 440.49, pg_loss = 392.63, baseline_loss = 61.387, entropy_loss = -13.52, learner_queue_size = 64, _tick = 6791, _time = 1.6548e+09)
[2022-06-09 17:37:41,982][root][INFO] - Step 44559360 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.4225e+04, step = 44559360, mean_episode_return = 103.99, mean_episode_step = 2179.9, total_loss = -53.951, pg_loss = -61.444, baseline_loss = 21.066, entropy_loss = -13.573, learner_queue_size = 64, _tick = 6793, _time = 1.6548e+09)
[2022-06-09 17:37:46,986][root][INFO] - Step 44574720 @ 3069.5 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 1.423e+04, step = 44574720, mean_episode_return = 84.727, mean_episode_step = 2243.2, total_loss = -203.79, pg_loss = -204.9, baseline_loss = 14.704, entropy_loss = -13.599, learner_queue_size = 64, _tick = 6795, _time = 1.6548e+09)
[2022-06-09 17:37:51,990][root][INFO] - Step 44595200 @ 4092.8 SPS. Inference batcher size: 67. Learner queue size: 64. Other stats: (train_seconds = 1.4235e+04, step = 44595200, mean_episode_return = 25.051, mean_episode_step = 1948.3, total_loss = -76.824, pg_loss = -90.979, baseline_loss = 27.834, entropy_loss = -13.679, learner_queue_size = 64, _tick = 6799, _time = 1.6548e+09)
[2022-06-09 17:37:56,994][root][INFO] - Step 44610560 @ 3069.5 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 1.424e+04, step = 44610560, mean_episode_return = None, mean_episode_step = 2265.1, total_loss = 149.39, pg_loss = 127.11, baseline_loss = 36.028, entropy_loss = -13.752, learner_queue_size = 64, _tick = 6800, _time = 1.6548e+09)
[2022-06-09 17:38:01,998][root][INFO] - Step 44625920 @ 3069.6 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.4245e+04, step = 44625920, mean_episode_return = None, mean_episode_step = 2173.0, total_loss = -84.507, pg_loss = -80.839, baseline_loss = 10.119, entropy_loss = -13.787, learner_queue_size = 64, _tick = 6801, _time = 1.6548e+09)
[2022-06-09 17:38:07,003][root][INFO] - Step 44641280 @ 3069.0 SPS. Inference batcher size: 18. Learner queue size: 64. Other stats: (train_seconds = 1.425e+04, step = 44641280, mean_episode_return = 0.27956, mean_episode_step = 2126.6, total_loss = -59.206, pg_loss = -59.974, baseline_loss = 14.614, entropy_loss = -13.846, learner_queue_size = 64, _tick = 6803, _time = 1.6548e+09)
[2022-06-09 17:38:12,006][root][INFO] - Step 44656640 @ 3070.0 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.4255e+04, step = 44656640, mean_episode_return = 24.001, mean_episode_step = 2218.5, total_loss = 407.38, pg_loss = 356.25, baseline_loss = 64.931, entropy_loss = -13.793, learner_queue_size = 64, _tick = 6806, _time = 1.6548e+09)
[2022-06-09 17:38:17,012][root][INFO] - Step 44672000 @ 3068.3 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 1.426e+04, step = 44672000, mean_episode_return = -16.661, mean_episode_step = 2351.1, total_loss = 139.92, pg_loss = 98.956, baseline_loss = 54.759, entropy_loss = -13.797, learner_queue_size = 64, _tick = 6808, _time = 1.6548e+09)
[2022-06-09 17:38:22,018][root][INFO] - Step 44687360 @ 3068.3 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.4265e+04, step = 44687360, mean_episode_return = 89.806, mean_episode_step = 2077.5, total_loss = 71.065, pg_loss = 46.838, baseline_loss = 38.014, entropy_loss = -13.786, learner_queue_size = 64, _tick = 6811, _time = 1.6548e+09)
[2022-06-09 17:38:27,022][root][INFO] - Step 44702720 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.427e+04, step = 44702720, mean_episode_return = None, mean_episode_step = 2018.8, total_loss = -117.34, pg_loss = -118.36, baseline_loss = 14.996, entropy_loss = -13.973, learner_queue_size = 64, _tick = 6813, _time = 1.6548e+09)
[2022-06-09 17:38:32,026][root][INFO] - Step 44723200 @ 4092.7 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.4275e+04, step = 44723200, mean_episode_return = 31.78, mean_episode_step = 2194.4, total_loss = 322.6, pg_loss = 264.38, baseline_loss = 72.503, entropy_loss = -14.284, learner_queue_size = 64, _tick = 6817, _time = 1.6548e+09)
[2022-06-09 17:38:37,030][root][INFO] - Step 44738560 @ 3069.6 SPS. Inference batcher size: 76. Learner queue size: 64. Other stats: (train_seconds = 1.428e+04, step = 44738560, mean_episode_return = 13.733, mean_episode_step = 2121.0, total_loss = -176.55, pg_loss = -172.22, baseline_loss = 9.9365, entropy_loss = -14.258, learner_queue_size = 64, _tick = 6820, _time = 1.6548e+09)
[2022-06-09 17:38:42,034][root][INFO] - Step 44753920 @ 3069.5 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 1.4285e+04, step = 44753920, mean_episode_return = 32.964, mean_episode_step = 2126.7, total_loss = 62.723, pg_loss = 52.166, baseline_loss = 24.942, entropy_loss = -14.385, learner_queue_size = 64, _tick = 6822, _time = 1.6548e+09)
[2022-06-09 17:38:47,038][root][INFO] - Step 44769280 @ 3069.5 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 1.429e+04, step = 44769280, mean_episode_return = None, mean_episode_step = 1841.7, total_loss = 13.092, pg_loss = 11.792, baseline_loss = 15.9, entropy_loss = -14.6, learner_queue_size = 64, _tick = 6823, _time = 1.6548e+09)
[2022-06-09 17:38:52,042][root][INFO] - Step 44784640 @ 3069.6 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.4295e+04, step = 44784640, mean_episode_return = 116.82, mean_episode_step = 2212.3, total_loss = -109.08, pg_loss = -110.12, baseline_loss = 15.497, entropy_loss = -14.464, learner_queue_size = 64, _tick = 6825, _time = 1.6548e+09)
[2022-06-09 17:38:57,046][root][INFO] - Step 44800000 @ 3069.5 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 1.43e+04, step = 44800000, mean_episode_return = 73.551, mean_episode_step = 1934.5, total_loss = 27.26, pg_loss = 16.213, baseline_loss = 25.418, entropy_loss = -14.371, learner_queue_size = 64, _tick = 6828, _time = 1.6548e+09)
[2022-06-09 17:39:02,050][root][INFO] - Step 44815360 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.4305e+04, step = 44815360, mean_episode_return = 53.076, mean_episode_step = 1843.7, total_loss = 100.86, pg_loss = 81.855, baseline_loss = 33.149, entropy_loss = -14.14, learner_queue_size = 64, _tick = 6831, _time = 1.6548e+09)
[2022-06-09 17:39:07,054][root][INFO] - Step 44830720 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.431e+04, step = 44830720, mean_episode_return = 87.809, mean_episode_step = 2100.4, total_loss = 61.216, pg_loss = 52.289, baseline_loss = 22.952, entropy_loss = -14.025, learner_queue_size = 64, _tick = 6834, _time = 1.6548e+09)
[2022-06-09 17:39:12,058][root][INFO] - Step 44846080 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.4315e+04, step = 44846080, mean_episode_return = 66.424, mean_episode_step = 2233.2, total_loss = -8.9964, pg_loss = -32.378, baseline_loss = 37.54, entropy_loss = -14.158, learner_queue_size = 64, _tick = 6837, _time = 1.6548e+09)
[2022-06-09 17:39:17,062][root][INFO] - Step 44866560 @ 4092.7 SPS. Inference batcher size: 77. Learner queue size: 64. Other stats: (train_seconds = 1.432e+04, step = 44866560, mean_episode_return = -45.938, mean_episode_step = 2135.8, total_loss = 90.44, pg_loss = 78.0, baseline_loss = 26.673, entropy_loss = -14.232, learner_queue_size = 64, _tick = 6841, _time = 1.6548e+09)
[2022-06-09 17:39:22,066][root][INFO] - Step 44881920 @ 3069.5 SPS. Inference batcher size: 86. Learner queue size: 64. Other stats: (train_seconds = 1.4325e+04, step = 44881920, mean_episode_return = 39.539, mean_episode_step = 2005.6, total_loss = 135.82, pg_loss = 112.49, baseline_loss = 37.636, entropy_loss = -14.301, learner_queue_size = 64, _tick = 6844, _time = 1.6548e+09)
[2022-06-09 17:39:27,070][root][INFO] - Step 44897280 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.433e+04, step = 44897280, mean_episode_return = 15.825, mean_episode_step = 2207.5, total_loss = 95.816, pg_loss = 71.587, baseline_loss = 38.537, entropy_loss = -14.308, learner_queue_size = 64, _tick = 6846, _time = 1.6548e+09)
[2022-06-09 17:39:32,074][root][INFO] - Step 44912640 @ 3069.7 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.4335e+04, step = 44912640, mean_episode_return = 56.341, mean_episode_step = 2478.2, total_loss = 83.397, pg_loss = 43.393, baseline_loss = 54.309, entropy_loss = -14.305, learner_queue_size = 64, _tick = 6848, _time = 1.6548e+09)
[2022-06-09 17:39:37,078][root][INFO] - Step 44928000 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.434e+04, step = 44928000, mean_episode_return = 0.09243, mean_episode_step = 2366.3, total_loss = 69.339, pg_loss = 53.507, baseline_loss = 30.15, entropy_loss = -14.318, learner_queue_size = 64, _tick = 6851, _time = 1.6548e+09)
[2022-06-09 17:39:42,082][root][INFO] - Step 44943360 @ 3069.5 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.4345e+04, step = 44943360, mean_episode_return = 133.23, mean_episode_step = 2022.6, total_loss = -105.52, pg_loss = -116.63, baseline_loss = 25.424, entropy_loss = -14.316, learner_queue_size = 64, _tick = 6854, _time = 1.6548e+09)
[2022-06-09 17:39:47,086][root][INFO] - Step 44958720 @ 3069.6 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.435e+04, step = 44958720, mean_episode_return = 7.6396, mean_episode_step = 1904.5, total_loss = 359.68, pg_loss = 302.74, baseline_loss = 71.167, entropy_loss = -14.221, learner_queue_size = 64, _tick = 6857, _time = 1.6548e+09)
[2022-06-09 17:39:52,090][root][INFO] - Step 44979200 @ 4092.8 SPS. Inference batcher size: 86. Learner queue size: 64. Other stats: (train_seconds = 1.4355e+04, step = 44979200, mean_episode_return = 51.601, mean_episode_step = 1978.4, total_loss = 110.66, pg_loss = 90.959, baseline_loss = 34.132, entropy_loss = -14.432, learner_queue_size = 64, _tick = 6860, _time = 1.6548e+09)
[2022-06-09 17:39:57,092][root][INFO] - Step 44994560 @ 3071.0 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 1.436e+04, step = 44994560, mean_episode_return = 34.736, mean_episode_step = 1961.3, total_loss = -18.741, pg_loss = -27.083, baseline_loss = 22.816, entropy_loss = -14.474, learner_queue_size = 64, _tick = 6863, _time = 1.6548e+09)
[2022-06-09 17:40:02,094][root][INFO] - Step 45009920 @ 3070.5 SPS. Inference batcher size: 68. Learner queue size: 64. Other stats: (train_seconds = 1.4365e+04, step = 45009920, mean_episode_return = 59.002, mean_episode_step = 2120.0, total_loss = -1.0956, pg_loss = -14.844, baseline_loss = 28.395, entropy_loss = -14.647, learner_queue_size = 64, _tick = 6866, _time = 1.6548e+09)
[2022-06-09 17:40:07,098][root][INFO] - Step 45025280 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.437e+04, step = 45025280, mean_episode_return = -3.69, mean_episode_step = 2139.5, total_loss = 336.97, pg_loss = 287.73, baseline_loss = 63.924, entropy_loss = -14.689, learner_queue_size = 64, _tick = 6869, _time = 1.6548e+09)
[2022-06-09 17:40:12,104][root][INFO] - Step 45040640 @ 3068.2 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.4375e+04, step = 45040640, mean_episode_return = 53.378, mean_episode_step = 2169.8, total_loss = -88.329, pg_loss = -99.809, baseline_loss = 26.214, entropy_loss = -14.734, learner_queue_size = 64, _tick = 6871, _time = 1.6548e+09)
[2022-06-09 17:40:17,110][root][INFO] - Step 45056000 @ 3068.5 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 1.438e+04, step = 45056000, mean_episode_return = None, mean_episode_step = 2271.6, total_loss = -253.39, pg_loss = -239.8, baseline_loss = 1.1326, entropy_loss = -14.713, learner_queue_size = 64, _tick = 6873, _time = 1.6548e+09)
[2022-06-09 17:40:22,114][root][INFO] - Step 45071360 @ 3069.6 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.4385e+04, step = 45071360, mean_episode_return = 21.256, mean_episode_step = 2065.0, total_loss = -63.235, pg_loss = -69.615, baseline_loss = 21.292, entropy_loss = -14.912, learner_queue_size = 64, _tick = 6876, _time = 1.6548e+09)
[2022-06-09 17:40:27,118][root][INFO] - Step 45086720 @ 3069.5 SPS. Inference batcher size: 12. Learner queue size: 64. Other stats: (train_seconds = 1.439e+04, step = 45086720, mean_episode_return = 34.426, mean_episode_step = 2045.2, total_loss = -222.4, pg_loss = -211.94, baseline_loss = 4.6166, entropy_loss = -15.084, learner_queue_size = 64, _tick = 6879, _time = 1.6548e+09)
[2022-06-09 17:40:32,122][root][INFO] - Step 45107200 @ 4092.7 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 1.4395e+04, step = 45107200, mean_episode_return = None, mean_episode_step = 1829.0, total_loss = -91.14, pg_loss = -87.529, baseline_loss = 11.542, entropy_loss = -15.153, learner_queue_size = 64, _tick = 6882, _time = 1.6548e+09)
[2022-06-09 17:40:37,126][root][INFO] - Step 45122560 @ 3069.6 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 1.44e+04, step = 45122560, mean_episode_return = 46.342, mean_episode_step = 1986.4, total_loss = 58.633, pg_loss = 38.315, baseline_loss = 35.471, entropy_loss = -15.152, learner_queue_size = 64, _tick = 6885, _time = 1.6548e+09)
[2022-06-09 17:40:42,130][root][INFO] - Step 45137920 @ 3069.5 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 1.4405e+04, step = 45137920, mean_episode_return = 61.67, mean_episode_step = 1868.2, total_loss = -4.1519, pg_loss = -10.037, baseline_loss = 21.027, entropy_loss = -15.142, learner_queue_size = 64, _tick = 6887, _time = 1.6548e+09)
[2022-06-09 17:40:47,134][root][INFO] - Step 45153280 @ 3069.5 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 1.441e+04, step = 45153280, mean_episode_return = 53.394, mean_episode_step = 1968.5, total_loss = -94.636, pg_loss = -86.088, baseline_loss = 6.5246, entropy_loss = -15.073, learner_queue_size = 64, _tick = 6890, _time = 1.6548e+09)
[2022-06-09 17:40:52,146][root][INFO] - Step 45168640 @ 3064.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.4415e+04, step = 45168640, mean_episode_return = 3.8508, mean_episode_step = 1479.8, total_loss = 78.062, pg_loss = 67.777, baseline_loss = 25.515, entropy_loss = -15.23, learner_queue_size = 64, _tick = 6893, _time = 1.6548e+09)
[2022-06-09 17:40:57,150][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 17:40:57,398][root][INFO] - Step 45184000 @ 3069.8 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.442e+04, step = 45184000, mean_episode_return = 12.355, mean_episode_step = 2059.9, total_loss = 201.83, pg_loss = 178.43, baseline_loss = 38.511, entropy_loss = -15.108, learner_queue_size = 64, _tick = 6896, _time = 1.6548e+09)
[2022-06-09 17:41:02,402][root][INFO] - Step 45199360 @ 2924.6 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.4425e+04, step = 45199360, mean_episode_return = 82.719, mean_episode_step = 1553.4, total_loss = 129.52, pg_loss = 115.88, baseline_loss = 28.601, entropy_loss = -14.968, learner_queue_size = 64, _tick = 6899, _time = 1.6548e+09)
[2022-06-09 17:41:07,406][root][INFO] - Step 45214720 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.443e+04, step = 45214720, mean_episode_return = 17.32, mean_episode_step = 1764.1, total_loss = 239.26, pg_loss = 208.01, baseline_loss = 46.228, entropy_loss = -14.981, learner_queue_size = 64, _tick = 6902, _time = 1.6548e+09)
[2022-06-09 17:41:12,410][root][INFO] - Step 45230080 @ 3069.6 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.4435e+04, step = 45230080, mean_episode_return = 4.4995, mean_episode_step = 1701.5, total_loss = 254.37, pg_loss = 232.69, baseline_loss = 36.575, entropy_loss = -14.892, learner_queue_size = 64, _tick = 6903, _time = 1.6548e+09)
[2022-06-09 17:41:17,414][root][INFO] - Step 45245440 @ 3069.6 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.444e+04, step = 45245440, mean_episode_return = 108.72, mean_episode_step = 1702.1, total_loss = 99.628, pg_loss = 83.143, baseline_loss = 31.442, entropy_loss = -14.957, learner_queue_size = 64, _tick = 6906, _time = 1.6548e+09)
[2022-06-09 17:41:22,418][root][INFO] - Step 45265920 @ 4092.6 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 1.4445e+04, step = 45265920, mean_episode_return = 66.09, mean_episode_step = 1924.7, total_loss = 117.23, pg_loss = 97.0, baseline_loss = 35.083, entropy_loss = -14.854, learner_queue_size = 64, _tick = 6909, _time = 1.6548e+09)
[2022-06-09 17:41:27,422][root][INFO] - Step 45281280 @ 3069.6 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 1.445e+04, step = 45281280, mean_episode_return = 51.306, mean_episode_step = 1695.6, total_loss = 232.63, pg_loss = 210.29, baseline_loss = 37.155, entropy_loss = -14.812, learner_queue_size = 64, _tick = 6911, _time = 1.6548e+09)
[2022-06-09 17:41:32,426][root][INFO] - Step 45296640 @ 3069.5 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 1.4455e+04, step = 45296640, mean_episode_return = 24.8, mean_episode_step = 1830.1, total_loss = 94.591, pg_loss = 73.863, baseline_loss = 35.799, entropy_loss = -15.071, learner_queue_size = 64, _tick = 6913, _time = 1.6548e+09)
[2022-06-09 17:41:37,430][root][INFO] - Step 45312000 @ 3069.6 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 1.446e+04, step = 45312000, mean_episode_return = 71.8, mean_episode_step = 1830.0, total_loss = 8.0747, pg_loss = -8.9438, baseline_loss = 32.192, entropy_loss = -15.173, learner_queue_size = 64, _tick = 6916, _time = 1.6548e+09)
[2022-06-09 17:41:42,434][root][INFO] - Step 45327360 @ 3069.5 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 1.4465e+04, step = 45327360, mean_episode_return = 72.049, mean_episode_step = 2007.8, total_loss = -109.45, pg_loss = -109.47, baseline_loss = 15.17, entropy_loss = -15.15, learner_queue_size = 64, _tick = 6918, _time = 1.6548e+09)
[2022-06-09 17:41:47,438][root][INFO] - Step 45342720 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.447e+04, step = 45342720, mean_episode_return = 8.5397, mean_episode_step = 1916.4, total_loss = -28.51, pg_loss = -37.684, baseline_loss = 24.347, entropy_loss = -15.173, learner_queue_size = 64, _tick = 6920, _time = 1.6548e+09)
[2022-06-09 17:41:52,442][root][INFO] - Step 45358080 @ 3069.5 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.4475e+04, step = 45358080, mean_episode_return = 32.785, mean_episode_step = 2130.3, total_loss = -173.19, pg_loss = -190.21, baseline_loss = 32.176, entropy_loss = -15.155, learner_queue_size = 64, _tick = 6923, _time = 1.6548e+09)
[2022-06-09 17:41:57,446][root][INFO] - Step 45373440 @ 3069.6 SPS. Inference batcher size: 15. Learner queue size: 64. Other stats: (train_seconds = 1.448e+04, step = 45373440, mean_episode_return = -3.8006, mean_episode_step = 1943.5, total_loss = 413.62, pg_loss = 308.9, baseline_loss = 119.84, entropy_loss = -15.123, learner_queue_size = 64, _tick = 6925, _time = 1.6548e+09)
[2022-06-09 17:42:02,450][root][INFO] - Step 45388800 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.4485e+04, step = 45388800, mean_episode_return = 21.74, mean_episode_step = 1997.9, total_loss = -197.62, pg_loss = -201.26, baseline_loss = 18.659, entropy_loss = -15.02, learner_queue_size = 64, _tick = 6926, _time = 1.6548e+09)
[2022-06-09 17:42:07,454][root][INFO] - Step 45404160 @ 3069.6 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.449e+04, step = 45404160, mean_episode_return = 6.3995, mean_episode_step = 1977.8, total_loss = -79.545, pg_loss = -83.7, baseline_loss = 19.282, entropy_loss = -15.126, learner_queue_size = 64, _tick = 6929, _time = 1.6548e+09)
[2022-06-09 17:42:12,458][root][INFO] - Step 45419520 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.4495e+04, step = 45419520, mean_episode_return = 36.843, mean_episode_step = 2005.9, total_loss = -127.1, pg_loss = -133.56, baseline_loss = 21.779, entropy_loss = -15.319, learner_queue_size = 64, _tick = 6932, _time = 1.6548e+09)
[2022-06-09 17:42:17,462][root][INFO] - Step 45440000 @ 4092.6 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 1.45e+04, step = 45440000, mean_episode_return = 22.923, mean_episode_step = 2103.6, total_loss = 146.68, pg_loss = 131.0, baseline_loss = 31.15, entropy_loss = -15.465, learner_queue_size = 64, _tick = 6934, _time = 1.6548e+09)
[2022-06-09 17:42:22,466][root][INFO] - Step 45455360 @ 3069.6 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 1.4505e+04, step = 45455360, mean_episode_return = None, mean_episode_step = 2053.3, total_loss = 25.987, pg_loss = 18.278, baseline_loss = 23.112, entropy_loss = -15.403, learner_queue_size = 64, _tick = 6935, _time = 1.6548e+09)
[2022-06-09 17:42:27,470][root][INFO] - Step 45470720 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.451e+04, step = 45470720, mean_episode_return = 63.732, mean_episode_step = 2204.5, total_loss = -149.18, pg_loss = -142.64, baseline_loss = 9.0033, entropy_loss = -15.538, learner_queue_size = 64, _tick = 6937, _time = 1.6548e+09)
[2022-06-09 17:42:32,474][root][INFO] - Step 45486080 @ 3069.5 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 1.4515e+04, step = 45486080, mean_episode_return = 4.8096, mean_episode_step = 1944.3, total_loss = 93.287, pg_loss = 76.216, baseline_loss = 32.774, entropy_loss = -15.704, learner_queue_size = 64, _tick = 6940, _time = 1.6548e+09)
[2022-06-09 17:42:37,478][root][INFO] - Step 45501440 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.452e+04, step = 45501440, mean_episode_return = 115.52, mean_episode_step = 2063.9, total_loss = 85.476, pg_loss = 68.975, baseline_loss = 32.039, entropy_loss = -15.537, learner_queue_size = 64, _tick = 6942, _time = 1.6548e+09)
[2022-06-09 17:42:42,482][root][INFO] - Step 45516800 @ 3069.6 SPS. Inference batcher size: 7. Learner queue size: 64. Other stats: (train_seconds = 1.4525e+04, step = 45516800, mean_episode_return = 38.192, mean_episode_step = 2243.5, total_loss = 253.43, pg_loss = 215.17, baseline_loss = 53.575, entropy_loss = -15.318, learner_queue_size = 64, _tick = 6945, _time = 1.6548e+09)
[2022-06-09 17:42:47,486][root][INFO] - Step 45532160 @ 3069.6 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.453e+04, step = 45532160, mean_episode_return = 116.36, mean_episode_step = 2155.9, total_loss = -37.134, pg_loss = -59.747, baseline_loss = 37.787, entropy_loss = -15.174, learner_queue_size = 64, _tick = 6948, _time = 1.6548e+09)
[2022-06-09 17:42:52,490][root][INFO] - Step 45547520 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.4535e+04, step = 45547520, mean_episode_return = None, mean_episode_step = 1920.0, total_loss = 228.7, pg_loss = 195.9, baseline_loss = 47.743, entropy_loss = -14.948, learner_queue_size = 64, _tick = 6950, _time = 1.6548e+09)
[2022-06-09 17:42:57,494][root][INFO] - Step 45562880 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.454e+04, step = 45562880, mean_episode_return = 40.19, mean_episode_step = 2148.7, total_loss = -2.637, pg_loss = -11.169, baseline_loss = 23.326, entropy_loss = -14.794, learner_queue_size = 64, _tick = 6953, _time = 1.6548e+09)
[2022-06-09 17:43:02,498][root][INFO] - Step 45578240 @ 3069.5 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1.4545e+04, step = 45578240, mean_episode_return = None, mean_episode_step = 2194.0, total_loss = 41.099, pg_loss = 29.867, baseline_loss = 25.719, entropy_loss = -14.487, learner_queue_size = 64, _tick = 6955, _time = 1.6548e+09)
[2022-06-09 17:43:07,502][root][INFO] - Step 45598720 @ 4092.7 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 1.455e+04, step = 45598720, mean_episode_return = 75.023, mean_episode_step = 1796.5, total_loss = -48.59, pg_loss = -59.519, baseline_loss = 25.39, entropy_loss = -14.461, learner_queue_size = 64, _tick = 6959, _time = 1.6548e+09)
[2022-06-09 17:43:12,506][root][INFO] - Step 45614080 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.4555e+04, step = 45614080, mean_episode_return = None, mean_episode_step = 2029.3, total_loss = 149.91, pg_loss = 133.71, baseline_loss = 30.67, entropy_loss = -14.478, learner_queue_size = 64, _tick = 6961, _time = 1.6548e+09)
[2022-06-09 17:43:17,510][root][INFO] - Step 45629440 @ 3069.6 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 1.456e+04, step = 45629440, mean_episode_return = 67.768, mean_episode_step = 2048.9, total_loss = -134.93, pg_loss = -137.44, baseline_loss = 16.966, entropy_loss = -14.449, learner_queue_size = 64, _tick = 6963, _time = 1.6548e+09)
[2022-06-09 17:43:22,514][root][INFO] - Step 45644800 @ 3069.5 SPS. Inference batcher size: 4. Learner queue size: 64. Other stats: (train_seconds = 1.4566e+04, step = 45644800, mean_episode_return = 23.871, mean_episode_step = 1866.1, total_loss = -42.01, pg_loss = -50.666, baseline_loss = 23.134, entropy_loss = -14.478, learner_queue_size = 64, _tick = 6966, _time = 1.6548e+09)
[2022-06-09 17:43:27,518][root][INFO] - Step 45660160 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.457e+04, step = 45660160, mean_episode_return = None, mean_episode_step = 1715.9, total_loss = 472.57, pg_loss = 415.79, baseline_loss = 71.384, entropy_loss = -14.604, learner_queue_size = 64, _tick = 6968, _time = 1.6548e+09)
[2022-06-09 17:43:32,522][root][INFO] - Step 45675520 @ 3069.6 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 1.4576e+04, step = 45675520, mean_episode_return = None, mean_episode_step = 2192.4, total_loss = -107.18, pg_loss = -106.57, baseline_loss = 14.047, entropy_loss = -14.652, learner_queue_size = 64, _tick = 6969, _time = 1.6548e+09)
[2022-06-09 17:43:37,526][root][INFO] - Step 45690880 @ 3069.5 SPS. Inference batcher size: 4. Learner queue size: 64. Other stats: (train_seconds = 1.458e+04, step = 45690880, mean_episode_return = 68.271, mean_episode_step = 2060.5, total_loss = -112.98, pg_loss = -110.98, baseline_loss = 12.835, entropy_loss = -14.834, learner_queue_size = 64, _tick = 6972, _time = 1.6548e+09)
[2022-06-09 17:43:42,532][root][INFO] - Step 45706240 @ 3068.4 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.4586e+04, step = 45706240, mean_episode_return = 44.095, mean_episode_step = 2252.0, total_loss = 214.35, pg_loss = 160.72, baseline_loss = 68.525, entropy_loss = -14.893, learner_queue_size = 64, _tick = 6974, _time = 1.6548e+09)
[2022-06-09 17:43:47,538][root][INFO] - Step 45721600 @ 3068.3 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 1.459e+04, step = 45721600, mean_episode_return = 30.161, mean_episode_step = 2252.1, total_loss = 60.589, pg_loss = 40.545, baseline_loss = 35.0, entropy_loss = -14.956, learner_queue_size = 64, _tick = 6977, _time = 1.6548e+09)
[2022-06-09 17:43:52,542][root][INFO] - Step 45736960 @ 3069.6 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.4596e+04, step = 45736960, mean_episode_return = 69.95, mean_episode_step = 2187.0, total_loss = -55.248, pg_loss = -63.244, baseline_loss = 22.962, entropy_loss = -14.967, learner_queue_size = 64, _tick = 6979, _time = 1.6548e+09)
[2022-06-09 17:43:57,546][root][INFO] - Step 45757440 @ 4092.7 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.46e+04, step = 45757440, mean_episode_return = 80.802, mean_episode_step = 2002.8, total_loss = 435.38, pg_loss = 362.04, baseline_loss = 88.387, entropy_loss = -15.054, learner_queue_size = 64, _tick = 6983, _time = 1.6548e+09)
[2022-06-09 17:44:02,550][root][INFO] - Step 45772800 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.4606e+04, step = 45772800, mean_episode_return = None, mean_episode_step = 2088.8, total_loss = -103.34, pg_loss = -101.59, baseline_loss = 13.088, entropy_loss = -14.836, learner_queue_size = 64, _tick = 6985, _time = 1.6548e+09)
[2022-06-09 17:44:07,554][root][INFO] - Step 45788160 @ 3069.5 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 1.461e+04, step = 45788160, mean_episode_return = None, mean_episode_step = 1960.1, total_loss = -95.631, pg_loss = -92.398, baseline_loss = 11.612, entropy_loss = -14.845, learner_queue_size = 64, _tick = 6986, _time = 1.6548e+09)
[2022-06-09 17:44:12,560][root][INFO] - Step 45803520 @ 3068.3 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 1.4616e+04, step = 45803520, mean_episode_return = 62.42, mean_episode_step = 1958.9, total_loss = 121.43, pg_loss = 106.13, baseline_loss = 30.136, entropy_loss = -14.831, learner_queue_size = 64, _tick = 6989, _time = 1.6548e+09)
[2022-06-09 17:44:17,566][root][INFO] - Step 45818880 @ 3068.3 SPS. Inference batcher size: 14. Learner queue size: 64. Other stats: (train_seconds = 1.462e+04, step = 45818880, mean_episode_return = None, mean_episode_step = 1732.4, total_loss = 64.589, pg_loss = 53.478, baseline_loss = 25.888, entropy_loss = -14.777, learner_queue_size = 64, _tick = 6991, _time = 1.6548e+09)
[2022-06-09 17:44:22,570][root][INFO] - Step 45834240 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.4626e+04, step = 45834240, mean_episode_return = 18.335, mean_episode_step = 1646.7, total_loss = -77.778, pg_loss = -84.621, baseline_loss = 21.61, entropy_loss = -14.767, learner_queue_size = 64, _tick = 6994, _time = 1.6548e+09)
[2022-06-09 17:44:27,574][root][INFO] - Step 45849600 @ 3069.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.463e+04, step = 45849600, mean_episode_return = 39.687, mean_episode_step = 1944.2, total_loss = -97.048, pg_loss = -104.45, baseline_loss = 22.184, entropy_loss = -14.782, learner_queue_size = 64, _tick = 6997, _time = 1.6548e+09)
[2022-06-09 17:44:32,578][root][INFO] - Step 45864960 @ 3069.5 SPS. Inference batcher size: 9. Learner queue size: 64. Other stats: (train_seconds = 1.4636e+04, step = 45864960, mean_episode_return = 26.115, mean_episode_step = 1904.1, total_loss = -105.67, pg_loss = -109.2, baseline_loss = 18.393, entropy_loss = -14.862, learner_queue_size = 64, _tick = 7000, _time = 1.6548e+09)
[2022-06-09 17:44:37,582][root][INFO] - Step 45880320 @ 3069.6 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 1.464e+04, step = 45880320, mean_episode_return = 31.602, mean_episode_step = 2059.4, total_loss = -3.4177, pg_loss = -29.766, baseline_loss = 41.095, entropy_loss = -14.746, learner_queue_size = 64, _tick = 7003, _time = 1.6548e+09)
[2022-06-09 17:44:42,586][root][INFO] - Step 45895680 @ 3069.5 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1.4646e+04, step = 45895680, mean_episode_return = 42.647, mean_episode_step = 2267.7, total_loss = 134.17, pg_loss = 106.58, baseline_loss = 42.549, entropy_loss = -14.961, learner_queue_size = 64, _tick = 7005, _time = 1.6548e+09)
[2022-06-09 17:44:47,590][root][INFO] - Step 45911040 @ 3069.6 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.465e+04, step = 45911040, mean_episode_return = 42.452, mean_episode_step = 1814.9, total_loss = 283.55, pg_loss = 237.88, baseline_loss = 60.499, entropy_loss = -14.828, learner_queue_size = 64, _tick = 7007, _time = 1.6548e+09)
[2022-06-09 17:44:52,594][root][INFO] - Step 45931520 @ 4092.7 SPS. Inference batcher size: 94. Learner queue size: 64. Other stats: (train_seconds = 1.4656e+04, step = 45931520, mean_episode_return = 40.116, mean_episode_step = 1879.5, total_loss = -15.912, pg_loss = -27.936, baseline_loss = 26.774, entropy_loss = -14.749, learner_queue_size = 64, _tick = 7010, _time = 1.6548e+09)
[2022-06-09 17:44:57,598][root][INFO] - Step 45946880 @ 3069.6 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 1.466e+04, step = 45946880, mean_episode_return = 36.156, mean_episode_step = 2005.9, total_loss = -90.375, pg_loss = -92.536, baseline_loss = 17.028, entropy_loss = -14.867, learner_queue_size = 64, _tick = 7013, _time = 1.6548e+09)
[2022-06-09 17:45:02,603][root][INFO] - Step 45962240 @ 3069.6 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 1.4666e+04, step = 45962240, mean_episode_return = 90.553, mean_episode_step = 1760.4, total_loss = 105.46, pg_loss = 79.16, baseline_loss = 41.1, entropy_loss = -14.8, learner_queue_size = 64, _tick = 7015, _time = 1.6548e+09)
[2022-06-09 17:45:07,606][root][INFO] - Step 45977600 @ 3069.6 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 1.467e+04, step = 45977600, mean_episode_return = 14.161, mean_episode_step = 1659.0, total_loss = -2.1699, pg_loss = -20.581, baseline_loss = 33.363, entropy_loss = -14.953, learner_queue_size = 64, _tick = 7017, _time = 1.6548e+09)
[2022-06-09 17:45:12,610][root][INFO] - Step 45992960 @ 3069.5 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 1.4676e+04, step = 45992960, mean_episode_return = 31.832, mean_episode_step = 1981.3, total_loss = 217.52, pg_loss = 190.44, baseline_loss = 41.877, entropy_loss = -14.795, learner_queue_size = 64, _tick = 7019, _time = 1.6548e+09)
[2022-06-09 17:45:17,614][root][INFO] - Step 46008320 @ 3069.6 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 1.468e+04, step = 46008320, mean_episode_return = 33.729, mean_episode_step = 1839.5, total_loss = -71.032, pg_loss = -83.405, baseline_loss = 27.121, entropy_loss = -14.748, learner_queue_size = 64, _tick = 7022, _time = 1.6548e+09)
[2022-06-09 17:45:22,618][root][INFO] - Step 46023680 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.4686e+04, step = 46023680, mean_episode_return = 56.95, mean_episode_step = 1970.6, total_loss = 61.634, pg_loss = 42.788, baseline_loss = 33.421, entropy_loss = -14.575, learner_queue_size = 64, _tick = 7024, _time = 1.6548e+09)
[2022-06-09 17:45:27,622][root][INFO] - Step 46039040 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.4691e+04, step = 46039040, mean_episode_return = 30.768, mean_episode_step = 2128.0, total_loss = -54.204, pg_loss = -62.782, baseline_loss = 23.162, entropy_loss = -14.584, learner_queue_size = 64, _tick = 7027, _time = 1.6548e+09)
[2022-06-09 17:45:32,626][root][INFO] - Step 46054400 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.4696e+04, step = 46054400, mean_episode_return = -7.4204, mean_episode_step = 1937.5, total_loss = 82.296, pg_loss = 75.539, baseline_loss = 21.328, entropy_loss = -14.572, learner_queue_size = 64, _tick = 7029, _time = 1.6548e+09)
[2022-06-09 17:45:37,632][root][INFO] - Step 46069760 @ 3068.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 1.4701e+04, step = 46069760, mean_episode_return = None, mean_episode_step = 1904.6, total_loss = 153.83, pg_loss = 126.69, baseline_loss = 41.815, entropy_loss = -14.675, learner_queue_size = 64, _tick = 7030, _time = 1.6548e+09)
[2022-06-09 17:45:42,634][root][INFO] - Step 46090240 @ 4094.1 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 1.4706e+04, step = 46090240, mean_episode_return = 31.833, mean_episode_step = 2112.3, total_loss = 17.564, pg_loss = 6.0906, baseline_loss = 25.922, entropy_loss = -14.449, learner_queue_size = 64, _tick = 7033, _time = 1.6548e+09)
[2022-06-09 17:45:47,638][root][INFO] - Step 46105600 @ 3069.5 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 1.4711e+04, step = 46105600, mean_episode_return = None, mean_episode_step = 2029.9, total_loss = 131.74, pg_loss = 113.94, baseline_loss = 32.313, entropy_loss = -14.516, learner_queue_size = 64, _tick = 7035, _time = 1.6548e+09)
[2022-06-09 17:45:52,642][root][INFO] - Step 46120960 @ 3069.6 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 1.4716e+04, step = 46120960, mean_episode_return = 13.3, mean_episode_step = 2208.8, total_loss = -226.75, pg_loss = -222.5, baseline_loss = 10.159, entropy_loss = -14.406, learner_queue_size = 64, _tick = 7038, _time = 1.6548e+09)
[2022-06-09 17:45:57,646][root][INFO] - Step 46136320 @ 3069.6 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 1.4721e+04, step = 46136320, mean_episode_return = 57.962, mean_episode_step = 1716.3, total_loss = 100.03, pg_loss = 56.703, baseline_loss = 57.805, entropy_loss = -14.476, learner_queue_size = 64, _tick = 7040, _time = 1.6548e+09)
[2022-06-09 17:46:02,650][root][INFO] - Step 46151680 @ 3069.5 SPS. Inference batcher size: 15. Learner queue size: 64. Other stats: (train_seconds = 1.4726e+04, step = 46151680, mean_episode_return = 22.571, mean_episode_step = 2275.0, total_loss = -85.791, pg_loss = -92.247, baseline_loss = 20.773, entropy_loss = -14.317, learner_queue_size = 64, _tick = 7043, _time = 1.6548e+09)
[2022-06-09 17:46:07,654][root][INFO] - Step 46167040 @ 3069.6 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 1.4731e+04, step = 46167040, mean_episode_return = 46.552, mean_episode_step = 2058.3, total_loss = -68.247, pg_loss = -66.823, baseline_loss = 12.905, entropy_loss = -14.329, learner_queue_size = 64, _tick = 7046, _time = 1.6548e+09)
[2022-06-09 17:46:12,658][root][INFO] - Step 46182400 @ 3069.6 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.4736e+04, step = 46182400, mean_episode_return = -11.374, mean_episode_step = 2205.1, total_loss = 162.75, pg_loss = 118.89, baseline_loss = 58.438, entropy_loss = -14.577, learner_queue_size = 64, _tick = 7048, _time = 1.6548e+09)
[2022-06-09 17:46:17,662][root][INFO] - Step 46202880 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.4741e+04, step = 46202880, mean_episode_return = None, mean_episode_step = 1983.2, total_loss = -30.586, pg_loss = -31.398, baseline_loss = 15.503, entropy_loss = -14.691, learner_queue_size = 64, _tick = 7050, _time = 1.6548e+09)
[2022-06-09 17:46:22,666][root][INFO] - Step 46218240 @ 3069.6 SPS. Inference batcher size: 79. Learner queue size: 64. Other stats: (train_seconds = 1.4746e+04, step = 46218240, mean_episode_return = 142.11, mean_episode_step = 2069.4, total_loss = 14.047, pg_loss = 3.4972, baseline_loss = 25.262, entropy_loss = -14.713, learner_queue_size = 64, _tick = 7053, _time = 1.6548e+09)
[2022-06-09 17:46:27,670][root][INFO] - Step 46233600 @ 3069.5 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 1.4751e+04, step = 46233600, mean_episode_return = 12.12, mean_episode_step = 2327.7, total_loss = 116.4, pg_loss = 96.153, baseline_loss = 34.644, entropy_loss = -14.401, learner_queue_size = 64, _tick = 7055, _time = 1.6548e+09)
[2022-06-09 17:46:32,674][root][INFO] - Step 46248960 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.4756e+04, step = 46248960, mean_episode_return = None, mean_episode_step = 2301.3, total_loss = 220.19, pg_loss = 197.09, baseline_loss = 37.069, entropy_loss = -13.968, learner_queue_size = 64, _tick = 7056, _time = 1.6548e+09)
[2022-06-09 17:46:37,678][root][INFO] - Step 46264320 @ 3069.5 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 1.4761e+04, step = 46264320, mean_episode_return = 25.526, mean_episode_step = 2007.3, total_loss = -155.26, pg_loss = -166.22, baseline_loss = 24.903, entropy_loss = -13.943, learner_queue_size = 64, _tick = 7058, _time = 1.6548e+09)
[2022-06-09 17:46:42,684][root][INFO] - Step 46279680 @ 3068.3 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 1.4766e+04, step = 46279680, mean_episode_return = None, mean_episode_step = 2006.8, total_loss = -182.65, pg_loss = -176.03, baseline_loss = 7.1795, entropy_loss = -13.796, learner_queue_size = 64, _tick = 7060, _time = 1.6548e+09)
[2022-06-09 17:46:47,690][root][INFO] - Step 46295040 @ 3068.3 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 1.4771e+04, step = 46295040, mean_episode_return = 20.65, mean_episode_step = 2063.1, total_loss = 59.011, pg_loss = 43.938, baseline_loss = 28.816, entropy_loss = -13.744, learner_queue_size = 64, _tick = 7063, _time = 1.6548e+09)
[2022-06-09 17:46:52,694][root][INFO] - Step 46310400 @ 3069.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.4776e+04, step = 46310400, mean_episode_return = 100.31, mean_episode_step = 1744.9, total_loss = -93.602, pg_loss = -94.984, baseline_loss = 15.22, entropy_loss = -13.838, learner_queue_size = 64, _tick = 7066, _time = 1.6548e+09)
[2022-06-09 17:46:57,698][root][INFO] - Step 46325760 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.4781e+04, step = 46325760, mean_episode_return = 99.029, mean_episode_step = 2275.2, total_loss = 80.629, pg_loss = 54.603, baseline_loss = 40.038, entropy_loss = -14.012, learner_queue_size = 64, _tick = 7069, _time = 1.6548e+09)
[2022-06-09 17:47:02,702][root][INFO] - Step 46341120 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.4786e+04, step = 46341120, mean_episode_return = 16.93, mean_episode_step = 2159.6, total_loss = 591.8, pg_loss = 408.33, baseline_loss = 197.51, entropy_loss = -14.046, learner_queue_size = 64, _tick = 7071, _time = 1.6548e+09)
[2022-06-09 17:47:07,706][root][INFO] - Step 46356480 @ 3069.5 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 1.4791e+04, step = 46356480, mean_episode_return = -5.8204, mean_episode_step = 2482.2, total_loss = -265.42, pg_loss = -254.75, baseline_loss = 3.198, entropy_loss = -13.863, learner_queue_size = 64, _tick = 7073, _time = 1.6548e+09)
[2022-06-09 17:47:12,710][root][INFO] - Step 46376960 @ 4092.7 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.4796e+04, step = 46376960, mean_episode_return = -5.51, mean_episode_step = 1990.3, total_loss = -201.47, pg_loss = -195.68, baseline_loss = 7.9261, entropy_loss = -13.716, learner_queue_size = 64, _tick = 7077, _time = 1.6548e+09)
[2022-06-09 17:47:17,714][root][INFO] - Step 46392320 @ 3069.5 SPS. Inference batcher size: 98. Learner queue size: 64. Other stats: (train_seconds = 1.4801e+04, step = 46392320, mean_episode_return = 36.529, mean_episode_step = 1984.6, total_loss = -267.88, pg_loss = -262.04, baseline_loss = 8.0222, entropy_loss = -13.855, learner_queue_size = 64, _tick = 7080, _time = 1.6548e+09)
[2022-06-09 17:47:22,718][root][INFO] - Step 46407680 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.4806e+04, step = 46407680, mean_episode_return = 85.594, mean_episode_step = 1953.6, total_loss = -169.26, pg_loss = -175.52, baseline_loss = 19.953, entropy_loss = -13.691, learner_queue_size = 64, _tick = 7082, _time = 1.6548e+09)
[2022-06-09 17:47:27,722][root][INFO] - Step 46423040 @ 3069.6 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.4811e+04, step = 46423040, mean_episode_return = 28.995, mean_episode_step = 2244.9, total_loss = 14.625, pg_loss = -14.296, baseline_loss = 42.752, entropy_loss = -13.831, learner_queue_size = 64, _tick = 7085, _time = 1.6548e+09)
[2022-06-09 17:47:32,726][root][INFO] - Step 46438400 @ 3069.5 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 1.4816e+04, step = 46438400, mean_episode_return = 9.3021, mean_episode_step = 2196.5, total_loss = -90.659, pg_loss = -105.81, baseline_loss = 28.924, entropy_loss = -13.775, learner_queue_size = 64, _tick = 7088, _time = 1.6548e+09)
[2022-06-09 17:47:37,730][root][INFO] - Step 46453760 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.4821e+04, step = 46453760, mean_episode_return = 89.705, mean_episode_step = 2145.9, total_loss = -118.37, pg_loss = -115.37, baseline_loss = 10.864, entropy_loss = -13.863, learner_queue_size = 64, _tick = 7091, _time = 1.6548e+09)
[2022-06-09 17:47:42,734][root][INFO] - Step 46469120 @ 3069.5 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 1.4826e+04, step = 46469120, mean_episode_return = 65.344, mean_episode_step = 2127.7, total_loss = 289.7, pg_loss = 242.7, baseline_loss = 60.803, entropy_loss = -13.801, learner_queue_size = 64, _tick = 7094, _time = 1.6548e+09)
[2022-06-09 17:47:47,738][root][INFO] - Step 46484480 @ 3069.5 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 1.4831e+04, step = 46484480, mean_episode_return = None, mean_episode_step = 2555.0, total_loss = 297.04, pg_loss = 243.01, baseline_loss = 67.706, entropy_loss = -13.676, learner_queue_size = 64, _tick = 7095, _time = 1.6548e+09)
[2022-06-09 17:47:52,742][root][INFO] - Step 46499840 @ 3069.6 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 1.4836e+04, step = 46499840, mean_episode_return = 94.966, mean_episode_step = 2102.6, total_loss = -46.036, pg_loss = -61.863, baseline_loss = 29.476, entropy_loss = -13.65, learner_queue_size = 64, _tick = 7098, _time = 1.6548e+09)
[2022-06-09 17:47:57,746][root][INFO] - Step 46520320 @ 4092.5 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 1.4841e+04, step = 46520320, mean_episode_return = None, mean_episode_step = 2013.0, total_loss = -51.29, pg_loss = -58.922, baseline_loss = 21.58, entropy_loss = -13.948, learner_queue_size = 64, _tick = 7100, _time = 1.6548e+09)
[2022-06-09 17:48:02,750][root][INFO] - Step 46535680 @ 3069.5 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 1.4846e+04, step = 46535680, mean_episode_return = None, mean_episode_step = 2286.7, total_loss = -1.612, pg_loss = -10.596, baseline_loss = 22.883, entropy_loss = -13.899, learner_queue_size = 64, _tick = 7102, _time = 1.6548e+09)
[2022-06-09 17:48:07,754][root][INFO] - Step 46551040 @ 3069.7 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.4851e+04, step = 46551040, mean_episode_return = 30.951, mean_episode_step = 2114.8, total_loss = -99.473, pg_loss = -107.46, baseline_loss = 21.871, entropy_loss = -13.881, learner_queue_size = 64, _tick = 7105, _time = 1.6548e+09)
[2022-06-09 17:48:12,758][root][INFO] - Step 46566400 @ 3069.6 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 1.4856e+04, step = 46566400, mean_episode_return = 25.679, mean_episode_step = 2294.2, total_loss = 184.24, pg_loss = 154.53, baseline_loss = 43.772, entropy_loss = -14.062, learner_queue_size = 64, _tick = 7108, _time = 1.6548e+09)
[2022-06-09 17:48:17,762][root][INFO] - Step 46581760 @ 3069.6 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 1.4861e+04, step = 46581760, mean_episode_return = 15.471, mean_episode_step = 2107.3, total_loss = -293.75, pg_loss = -289.87, baseline_loss = 10.112, entropy_loss = -13.996, learner_queue_size = 64, _tick = 7111, _time = 1.6548e+09)
[2022-06-09 17:48:22,766][root][INFO] - Step 46597120 @ 3069.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.4866e+04, step = 46597120, mean_episode_return = None, mean_episode_step = 2054.6, total_loss = 151.7, pg_loss = 126.06, baseline_loss = 39.573, entropy_loss = -13.935, learner_queue_size = 64, _tick = 7113, _time = 1.6548e+09)
[2022-06-09 17:48:27,770][root][INFO] - Step 46612480 @ 3069.5 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 1.4871e+04, step = 46612480, mean_episode_return = 118.59, mean_episode_step = 2418.4, total_loss = 3.0794, pg_loss = 1.3154, baseline_loss = 15.543, entropy_loss = -13.779, learner_queue_size = 64, _tick = 7116, _time = 1.6548e+09)
[2022-06-09 17:48:32,774][root][INFO] - Step 46627840 @ 3069.6 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 1.4876e+04, step = 46627840, mean_episode_return = None, mean_episode_step = 2241.0, total_loss = -9.4939, pg_loss = -10.674, baseline_loss = 15.228, entropy_loss = -14.048, learner_queue_size = 64, _tick = 7116, _time = 1.6548e+09)
[2022-06-09 17:48:37,778][root][INFO] - Step 46648320 @ 4092.7 SPS. Inference batcher size: 77. Learner queue size: 64. Other stats: (train_seconds = 1.4881e+04, step = 46648320, mean_episode_return = None, mean_episode_step = 2057.0, total_loss = 104.12, pg_loss = 96.357, baseline_loss = 21.885, entropy_loss = -14.125, learner_queue_size = 64, _tick = 7118, _time = 1.6548e+09)
[2022-06-09 17:48:42,782][root][INFO] - Step 46663680 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.4886e+04, step = 46663680, mean_episode_return = 13.06, mean_episode_step = 1877.5, total_loss = 167.92, pg_loss = 144.83, baseline_loss = 37.276, entropy_loss = -14.186, learner_queue_size = 64, _tick = 7121, _time = 1.6548e+09)
[2022-06-09 17:48:47,786][root][INFO] - Step 46679040 @ 3069.5 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 1.4891e+04, step = 46679040, mean_episode_return = 54.922, mean_episode_step = 2235.9, total_loss = 37.943, pg_loss = 21.274, baseline_loss = 30.961, entropy_loss = -14.291, learner_queue_size = 64, _tick = 7123, _time = 1.6548e+09)
[2022-06-09 17:48:52,790][root][INFO] - Step 46694400 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.4896e+04, step = 46694400, mean_episode_return = 121.45, mean_episode_step = 1999.0, total_loss = -53.735, pg_loss = -64.661, baseline_loss = 25.386, entropy_loss = -14.459, learner_queue_size = 64, _tick = 7126, _time = 1.6548e+09)
[2022-06-09 17:48:57,794][root][INFO] - Step 46709760 @ 3069.6 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 1.4901e+04, step = 46709760, mean_episode_return = None, mean_episode_step = 2032.9, total_loss = -24.392, pg_loss = -32.747, baseline_loss = 22.865, entropy_loss = -14.51, learner_queue_size = 64, _tick = 7127, _time = 1.6548e+09)
[2022-06-09 17:49:02,798][root][INFO] - Step 46725120 @ 3069.5 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 1.4906e+04, step = 46725120, mean_episode_return = 0.73452, mean_episode_step = 2111.8, total_loss = -209.11, pg_loss = -203.07, baseline_loss = 8.4765, entropy_loss = -14.517, learner_queue_size = 64, _tick = 7129, _time = 1.6548e+09)
[2022-06-09 17:49:07,802][root][INFO] - Step 46740480 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 1.4911e+04, step = 46740480, mean_episode_return = 1.4496, mean_episode_step = 2258.9, total_loss = 81.221, pg_loss = 62.793, baseline_loss = 32.917, entropy_loss = -14.489, learner_queue_size = 64, _tick = 7132, _time = 1.6548e+09)
[2022-06-09 17:49:12,806][root][INFO] - Step 46755840 @ 3069.5 SPS. Inference batcher size: 18. Learner queue size: 64. Other stats: (train_seconds = 1.4916e+04, step = 46755840, mean_episode_return = 66.795, mean_episode_step = 2294.6, total_loss = -204.25, pg_loss = -195.38, baseline_loss = 5.8316, entropy_loss = -14.708, learner_queue_size = 64, _tick = 7134, _time = 1.6548e+09)
[2022-06-09 17:49:17,809][root][INFO] - Step 46771200 @ 3070.3 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.4921e+04, step = 46771200, mean_episode_return = 26.551, mean_episode_step = 2198.9, total_loss = -137.17, pg_loss = -128.83, baseline_loss = 6.4541, entropy_loss = -14.799, learner_queue_size = 64, _tick = 7136, _time = 1.6548e+09)
[2022-06-09 17:49:22,814][root][INFO] - Step 46791680 @ 4091.8 SPS. Inference batcher size: 8. Learner queue size: 64. Other stats: (train_seconds = 1.4926e+04, step = 46791680, mean_episode_return = 90.345, mean_episode_step = 2032.4, total_loss = -198.42, pg_loss = -196.93, baseline_loss = 13.193, entropy_loss = -14.674, learner_queue_size = 64, _tick = 7139, _time = 1.6548e+09)
[2022-06-09 17:49:27,818][root][INFO] - Step 46807040 @ 3069.5 SPS. Inference batcher size: 68. Learner queue size: 64. Other stats: (train_seconds = 1.4931e+04, step = 46807040, mean_episode_return = -14.39, mean_episode_step = 2144.3, total_loss = 84.879, pg_loss = 68.722, baseline_loss = 30.874, entropy_loss = -14.717, learner_queue_size = 64, _tick = 7142, _time = 1.6548e+09)
[2022-06-09 17:49:32,822][root][INFO] - Step 46822400 @ 3069.5 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 1.4936e+04, step = 46822400, mean_episode_return = 60.291, mean_episode_step = 2562.2, total_loss = 312.52, pg_loss = 277.59, baseline_loss = 49.724, entropy_loss = -14.793, learner_queue_size = 64, _tick = 7145, _time = 1.6548e+09)
[2022-06-09 17:49:37,826][root][INFO] - Step 46837760 @ 3069.6 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 1.4941e+04, step = 46837760, mean_episode_return = 14.619, mean_episode_step = 2116.9, total_loss = 118.04, pg_loss = 103.42, baseline_loss = 29.373, entropy_loss = -14.744, learner_queue_size = 64, _tick = 7148, _time = 1.6548e+09)
[2022-06-09 17:49:42,830][root][INFO] - Step 46853120 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.4946e+04, step = 46853120, mean_episode_return = -26.05, mean_episode_step = 2016.0, total_loss = 98.905, pg_loss = 87.306, baseline_loss = 26.056, entropy_loss = -14.457, learner_queue_size = 64, _tick = 7151, _time = 1.6548e+09)
[2022-06-09 17:49:47,834][root][INFO] - Step 46868480 @ 3069.6 SPS. Inference batcher size: 5. Learner queue size: 64. Other stats: (train_seconds = 1.4951e+04, step = 46868480, mean_episode_return = 106.72, mean_episode_step = 2177.4, total_loss = -5.9584, pg_loss = -18.253, baseline_loss = 26.779, entropy_loss = -14.484, learner_queue_size = 64, _tick = 7154, _time = 1.6548e+09)
[2022-06-09 17:49:52,838][root][INFO] - Step 46883840 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.4956e+04, step = 46883840, mean_episode_return = 67.814, mean_episode_step = 1677.4, total_loss = 178.49, pg_loss = 162.85, baseline_loss = 30.51, entropy_loss = -14.871, learner_queue_size = 64, _tick = 7157, _time = 1.6548e+09)
[2022-06-09 17:49:57,845][root][INFO] - Step 46899200 @ 3068.1 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1.4961e+04, step = 46899200, mean_episode_return = -0.55, mean_episode_step = 2187.7, total_loss = -131.57, pg_loss = -129.92, baseline_loss = 13.236, entropy_loss = -14.887, learner_queue_size = 64, _tick = 7160, _time = 1.6548e+09)
[2022-06-09 17:50:02,850][root][INFO] - Step 46919680 @ 4091.4 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.4966e+04, step = 46919680, mean_episode_return = -1.8601, mean_episode_step = 1961.9, total_loss = -24.058, pg_loss = -36.088, baseline_loss = 26.762, entropy_loss = -14.732, learner_queue_size = 64, _tick = 7164, _time = 1.6548e+09)
[2022-06-09 17:50:07,854][root][INFO] - Step 46935040 @ 3069.5 SPS. Inference batcher size: 96. Learner queue size: 64. Other stats: (train_seconds = 1.4971e+04, step = 46935040, mean_episode_return = 57.637, mean_episode_step = 1860.2, total_loss = 335.88, pg_loss = 290.11, baseline_loss = 60.643, entropy_loss = -14.875, learner_queue_size = 64, _tick = 7166, _time = 1.6548e+09)
[2022-06-09 17:50:12,858][root][INFO] - Step 46950400 @ 3069.6 SPS. Inference batcher size: 89. Learner queue size: 64. Other stats: (train_seconds = 1.4976e+04, step = 46950400, mean_episode_return = 35.706, mean_episode_step = 1865.0, total_loss = -68.379, pg_loss = -76.167, baseline_loss = 22.497, entropy_loss = -14.709, learner_queue_size = 64, _tick = 7169, _time = 1.6548e+09)
[2022-06-09 17:50:17,862][root][INFO] - Step 46965760 @ 3069.4 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 1.4981e+04, step = 46965760, mean_episode_return = 86.643, mean_episode_step = 1814.4, total_loss = -182.44, pg_loss = -174.69, baseline_loss = 7.015, entropy_loss = -14.766, learner_queue_size = 64, _tick = 7172, _time = 1.6548e+09)
[2022-06-09 17:50:22,866][root][INFO] - Step 46981120 @ 3069.8 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.4986e+04, step = 46981120, mean_episode_return = 30.056, mean_episode_step = 1651.4, total_loss = -80.542, pg_loss = -87.23, baseline_loss = 21.292, entropy_loss = -14.604, learner_queue_size = 64, _tick = 7175, _time = 1.6548e+09)
[2022-06-09 17:50:27,870][root][INFO] - Step 46996480 @ 3069.5 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 1.4991e+04, step = 46996480, mean_episode_return = 58.68, mean_episode_step = 2337.9, total_loss = 29.055, pg_loss = 5.8015, baseline_loss = 37.817, entropy_loss = -14.564, learner_queue_size = 64, _tick = 7177, _time = 1.6548e+09)
[2022-06-09 17:50:32,875][root][INFO] - Step 47011840 @ 3068.5 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.4996e+04, step = 47011840, mean_episode_return = 44.193, mean_episode_step = 1414.9, total_loss = 132.48, pg_loss = 104.13, baseline_loss = 42.889, entropy_loss = -14.544, learner_queue_size = 64, _tick = 7180, _time = 1.6548e+09)
[2022-06-09 17:50:37,878][root][INFO] - Step 47027200 @ 3070.6 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 1.5001e+04, step = 47027200, mean_episode_return = None, mean_episode_step = 1940.8, total_loss = 296.57, pg_loss = 248.83, baseline_loss = 62.12, entropy_loss = -14.379, learner_queue_size = 64, _tick = 7182, _time = 1.6548e+09)
[2022-06-09 17:50:42,882][root][INFO] - Step 47042560 @ 3069.5 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1.5006e+04, step = 47042560, mean_episode_return = 61.926, mean_episode_step = 1729.0, total_loss = -39.456, pg_loss = -53.762, baseline_loss = 28.58, entropy_loss = -14.274, learner_queue_size = 64, _tick = 7185, _time = 1.6548e+09)
[2022-06-09 17:50:47,886][root][INFO] - Step 47057920 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.5011e+04, step = 47057920, mean_episode_return = None, mean_episode_step = 1942.1, total_loss = 208.25, pg_loss = 175.71, baseline_loss = 46.768, entropy_loss = -14.223, learner_queue_size = 64, _tick = 7186, _time = 1.6548e+09)
[2022-06-09 17:50:52,890][root][INFO] - Step 47073280 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.5016e+04, step = 47073280, mean_episode_return = 39.483, mean_episode_step = 1863.5, total_loss = 76.414, pg_loss = 54.452, baseline_loss = 36.199, entropy_loss = -14.237, learner_queue_size = 64, _tick = 7189, _time = 1.6548e+09)
[2022-06-09 17:50:57,894][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 17:50:58,148][root][INFO] - Step 47093760 @ 4092.8 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 1.5021e+04, step = 47093760, mean_episode_return = 48.003, mean_episode_step = 1866.8, total_loss = 639.73, pg_loss = 457.62, baseline_loss = 196.41, entropy_loss = -14.299, learner_queue_size = 64, _tick = 7193, _time = 1.6548e+09)
[2022-06-09 17:51:03,153][root][INFO] - Step 47109120 @ 2920.5 SPS. Inference batcher size: 67. Learner queue size: 64. Other stats: (train_seconds = 1.5026e+04, step = 47109120, mean_episode_return = 34.007, mean_episode_step = 1784.3, total_loss = -52.45, pg_loss = -75.157, baseline_loss = 36.852, entropy_loss = -14.144, learner_queue_size = 64, _tick = 7195, _time = 1.6548e+09)
[2022-06-09 17:51:08,158][root][INFO] - Step 47124480 @ 3069.1 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 1.5031e+04, step = 47124480, mean_episode_return = 7.221, mean_episode_step = 1544.3, total_loss = 135.91, pg_loss = 95.22, baseline_loss = 54.724, entropy_loss = -14.037, learner_queue_size = 64, _tick = 7198, _time = 1.6548e+09)
[2022-06-09 17:51:13,162][root][INFO] - Step 47139840 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.5036e+04, step = 47139840, mean_episode_return = 54.04, mean_episode_step = 1618.7, total_loss = -110.61, pg_loss = -115.28, baseline_loss = 18.488, entropy_loss = -13.817, learner_queue_size = 64, _tick = 7201, _time = 1.6548e+09)
[2022-06-09 17:51:18,166][root][INFO] - Step 47155200 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.5041e+04, step = 47155200, mean_episode_return = 121.02, mean_episode_step = 1900.2, total_loss = 68.691, pg_loss = 44.177, baseline_loss = 38.388, entropy_loss = -13.874, learner_queue_size = 64, _tick = 7203, _time = 1.6548e+09)
[2022-06-09 17:51:23,170][root][INFO] - Step 47170560 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.5046e+04, step = 47170560, mean_episode_return = 34.324, mean_episode_step = 1788.9, total_loss = 140.05, pg_loss = 100.77, baseline_loss = 52.997, entropy_loss = -13.718, learner_queue_size = 64, _tick = 7206, _time = 1.6548e+09)
[2022-06-09 17:51:28,174][root][INFO] - Step 47185920 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.5051e+04, step = 47185920, mean_episode_return = 42.565, mean_episode_step = 1976.6, total_loss = 65.257, pg_loss = 26.161, baseline_loss = 52.669, entropy_loss = -13.573, learner_queue_size = 64, _tick = 7209, _time = 1.6548e+09)
[2022-06-09 17:51:33,178][root][INFO] - Step 47201280 @ 3069.6 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 1.5056e+04, step = 47201280, mean_episode_return = 45.292, mean_episode_step = 1627.8, total_loss = -249.52, pg_loss = -242.89, baseline_loss = 6.9981, entropy_loss = -13.629, learner_queue_size = 64, _tick = 7211, _time = 1.6548e+09)
[2022-06-09 17:51:38,184][root][INFO] - Step 47216640 @ 3068.3 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.5061e+04, step = 47216640, mean_episode_return = None, mean_episode_step = 1828.3, total_loss = 60.554, pg_loss = 41.224, baseline_loss = 32.948, entropy_loss = -13.618, learner_queue_size = 64, _tick = 7211, _time = 1.6548e+09)
[2022-06-09 17:51:43,190][root][INFO] - Step 47237120 @ 4091.2 SPS. Inference batcher size: 91. Learner queue size: 64. Other stats: (train_seconds = 1.5066e+04, step = 47237120, mean_episode_return = None, mean_episode_step = 1853.1, total_loss = 66.992, pg_loss = 51.629, baseline_loss = 28.899, entropy_loss = -13.536, learner_queue_size = 64, _tick = 7213, _time = 1.6548e+09)
[2022-06-09 17:51:48,194][root][INFO] - Step 47252480 @ 3069.5 SPS. Inference batcher size: 79. Learner queue size: 64. Other stats: (train_seconds = 1.5071e+04, step = 47252480, mean_episode_return = -2.17, mean_episode_step = 2085.4, total_loss = -148.76, pg_loss = -144.82, baseline_loss = 9.4918, entropy_loss = -13.431, learner_queue_size = 64, _tick = 7216, _time = 1.6548e+09)
[2022-06-09 17:51:53,198][root][INFO] - Step 47267840 @ 3069.6 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.5076e+04, step = 47267840, mean_episode_return = 54.811, mean_episode_step = 2276.8, total_loss = 25.788, pg_loss = -0.626, baseline_loss = 40.014, entropy_loss = -13.6, learner_queue_size = 64, _tick = 7219, _time = 1.6548e+09)
[2022-06-09 17:51:58,202][root][INFO] - Step 47283200 @ 3069.5 SPS. Inference batcher size: 67. Learner queue size: 64. Other stats: (train_seconds = 1.5081e+04, step = 47283200, mean_episode_return = None, mean_episode_step = 1959.6, total_loss = 506.28, pg_loss = 448.9, baseline_loss = 70.896, entropy_loss = -13.518, learner_queue_size = 64, _tick = 7220, _time = 1.6548e+09)
[2022-06-09 17:52:03,206][root][INFO] - Step 47298560 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.5086e+04, step = 47298560, mean_episode_return = 68.58, mean_episode_step = 1905.1, total_loss = -139.41, pg_loss = -140.7, baseline_loss = 14.611, entropy_loss = -13.317, learner_queue_size = 64, _tick = 7223, _time = 1.6548e+09)
[2022-06-09 17:52:08,210][root][INFO] - Step 47313920 @ 3069.4 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.5091e+04, step = 47313920, mean_episode_return = 56.789, mean_episode_step = 2110.5, total_loss = -48.768, pg_loss = -76.704, baseline_loss = 41.237, entropy_loss = -13.302, learner_queue_size = 64, _tick = 7225, _time = 1.6548e+09)
[2022-06-09 17:52:13,216][root][INFO] - Step 47329280 @ 3068.2 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 1.5096e+04, step = 47329280, mean_episode_return = 14.757, mean_episode_step = 1904.5, total_loss = 216.72, pg_loss = 182.37, baseline_loss = 47.709, entropy_loss = -13.351, learner_queue_size = 64, _tick = 7227, _time = 1.6548e+09)
[2022-06-09 17:52:18,222][root][INFO] - Step 47349760 @ 4091.4 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 1.5101e+04, step = 47349760, mean_episode_return = 94.12, mean_episode_step = 2164.4, total_loss = -72.206, pg_loss = -85.52, baseline_loss = 26.627, entropy_loss = -13.313, learner_queue_size = 64, _tick = 7231, _time = 1.6548e+09)
[2022-06-09 17:52:23,226][root][INFO] - Step 47365120 @ 3069.3 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 1.5106e+04, step = 47365120, mean_episode_return = 44.183, mean_episode_step = 1909.2, total_loss = -51.579, pg_loss = -68.98, baseline_loss = 30.79, entropy_loss = -13.389, learner_queue_size = 64, _tick = 7234, _time = 1.6548e+09)
[2022-06-09 17:52:28,230][root][INFO] - Step 47375360 @ 2046.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.5111e+04, step = 47375360, mean_episode_return = 86.871, mean_episode_step = 1945.9, total_loss = -198.86, pg_loss = -212.97, baseline_loss = 27.358, entropy_loss = -13.248, learner_queue_size = 64, _tick = 7236, _time = 1.6548e+09)
[2022-06-09 17:52:33,234][root][INFO] - Step 47395840 @ 4092.8 SPS. Inference batcher size: 75. Learner queue size: 64. Other stats: (train_seconds = 1.5116e+04, step = 47395840, mean_episode_return = 64.428, mean_episode_step = 1732.7, total_loss = 38.009, pg_loss = 6.9028, baseline_loss = 44.36, entropy_loss = -13.254, learner_queue_size = 64, _tick = 7240, _time = 1.6548e+09)
[2022-06-09 17:52:38,238][root][INFO] - Step 47411200 @ 3069.5 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 1.5121e+04, step = 47411200, mean_episode_return = 45.074, mean_episode_step = 2019.8, total_loss = 470.77, pg_loss = 376.38, baseline_loss = 107.71, entropy_loss = -13.316, learner_queue_size = 64, _tick = 7242, _time = 1.6548e+09)
[2022-06-09 17:52:43,242][root][INFO] - Step 47426560 @ 3069.6 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 1.5126e+04, step = 47426560, mean_episode_return = 21.378, mean_episode_step = 2222.1, total_loss = -127.19, pg_loss = -136.66, baseline_loss = 22.863, entropy_loss = -13.387, learner_queue_size = 64, _tick = 7245, _time = 1.6548e+09)
[2022-06-09 17:52:48,246][root][INFO] - Step 47441920 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.5131e+04, step = 47441920, mean_episode_return = 37.78, mean_episode_step = 2102.6, total_loss = -179.99, pg_loss = -183.26, baseline_loss = 16.899, entropy_loss = -13.623, learner_queue_size = 64, _tick = 7248, _time = 1.6548e+09)
[2022-06-09 17:52:53,250][root][INFO] - Step 47457280 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.5136e+04, step = 47457280, mean_episode_return = None, mean_episode_step = 2247.9, total_loss = 161.43, pg_loss = 145.37, baseline_loss = 29.818, entropy_loss = -13.761, learner_queue_size = 64, _tick = 7250, _time = 1.6548e+09)
[2022-06-09 17:52:58,254][root][INFO] - Step 47472640 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.5141e+04, step = 47472640, mean_episode_return = 54.635, mean_episode_step = 1762.9, total_loss = -39.98, pg_loss = -57.6, baseline_loss = 31.296, entropy_loss = -13.676, learner_queue_size = 64, _tick = 7252, _time = 1.6548e+09)
[2022-06-09 17:53:03,258][root][INFO] - Step 47488000 @ 3069.6 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.5146e+04, step = 47488000, mean_episode_return = None, mean_episode_step = 1902.0, total_loss = 48.393, pg_loss = 39.957, baseline_loss = 22.042, entropy_loss = -13.606, learner_queue_size = 64, _tick = 7253, _time = 1.6548e+09)
[2022-06-09 17:53:08,264][root][INFO] - Step 47503360 @ 3068.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.5151e+04, step = 47503360, mean_episode_return = 74.237, mean_episode_step = 2341.3, total_loss = -54.904, pg_loss = -64.094, baseline_loss = 22.868, entropy_loss = -13.679, learner_queue_size = 64, _tick = 7256, _time = 1.6548e+09)
[2022-06-09 17:53:13,266][root][INFO] - Step 47523840 @ 4094.1 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 1.5156e+04, step = 47523840, mean_episode_return = 32.35, mean_episode_step = 1922.7, total_loss = 88.899, pg_loss = 58.189, baseline_loss = 44.461, entropy_loss = -13.751, learner_queue_size = 64, _tick = 7260, _time = 1.6548e+09)
[2022-06-09 17:53:18,270][root][INFO] - Step 47539200 @ 3069.5 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 1.5161e+04, step = 47539200, mean_episode_return = 149.49, mean_episode_step = 1996.4, total_loss = 301.91, pg_loss = 255.87, baseline_loss = 59.435, entropy_loss = -13.393, learner_queue_size = 64, _tick = 7263, _time = 1.6548e+09)
[2022-06-09 17:53:23,274][root][INFO] - Step 47554560 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.5166e+04, step = 47554560, mean_episode_return = None, mean_episode_step = 1988.2, total_loss = 249.41, pg_loss = 216.33, baseline_loss = 46.334, entropy_loss = -13.253, learner_queue_size = 64, _tick = 7264, _time = 1.6548e+09)
[2022-06-09 17:53:28,278][root][INFO] - Step 47569920 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.5171e+04, step = 47569920, mean_episode_return = 25.92, mean_episode_step = 1899.9, total_loss = 16.732, pg_loss = 1.4361, baseline_loss = 28.581, entropy_loss = -13.284, learner_queue_size = 64, _tick = 7266, _time = 1.6548e+09)
[2022-06-09 17:53:33,282][root][INFO] - Step 47585280 @ 3069.5 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.5176e+04, step = 47585280, mean_episode_return = 101.24, mean_episode_step = 2267.7, total_loss = -222.29, pg_loss = -216.25, baseline_loss = 7.3565, entropy_loss = -13.395, learner_queue_size = 64, _tick = 7268, _time = 1.6548e+09)
[2022-06-09 17:53:38,286][root][INFO] - Step 47600640 @ 3069.6 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.5181e+04, step = 47600640, mean_episode_return = 36.858, mean_episode_step = 2180.0, total_loss = -223.46, pg_loss = -219.77, baseline_loss = 9.8622, entropy_loss = -13.556, learner_queue_size = 64, _tick = 7271, _time = 1.6548e+09)
[2022-06-09 17:53:43,290][root][INFO] - Step 47616000 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.5186e+04, step = 47616000, mean_episode_return = None, mean_episode_step = 2162.8, total_loss = 57.044, pg_loss = 38.136, baseline_loss = 32.449, entropy_loss = -13.542, learner_queue_size = 64, _tick = 7272, _time = 1.6548e+09)
[2022-06-09 17:53:48,294][root][INFO] - Step 47631360 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.5191e+04, step = 47631360, mean_episode_return = None, mean_episode_step = 1902.1, total_loss = 66.448, pg_loss = 45.813, baseline_loss = 34.059, entropy_loss = -13.423, learner_queue_size = 64, _tick = 7274, _time = 1.6548e+09)
[2022-06-09 17:53:53,298][root][INFO] - Step 47651840 @ 4092.7 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 1.5196e+04, step = 47651840, mean_episode_return = None, mean_episode_step = 2321.8, total_loss = -8.4223, pg_loss = -28.198, baseline_loss = 33.492, entropy_loss = -13.716, learner_queue_size = 64, _tick = 7276, _time = 1.6548e+09)
[2022-06-09 17:53:58,302][root][INFO] - Step 47667200 @ 3069.5 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 1.5201e+04, step = 47667200, mean_episode_return = 16.39, mean_episode_step = 1875.5, total_loss = -61.495, pg_loss = -60.653, baseline_loss = 12.859, entropy_loss = -13.7, learner_queue_size = 64, _tick = 7279, _time = 1.6548e+09)
[2022-06-09 17:54:03,306][root][INFO] - Step 47682560 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.5206e+04, step = 47682560, mean_episode_return = 5.2282, mean_episode_step = 2102.2, total_loss = -123.79, pg_loss = -140.49, baseline_loss = 30.439, entropy_loss = -13.736, learner_queue_size = 64, _tick = 7281, _time = 1.6548e+09)
[2022-06-09 17:54:08,308][root][INFO] - Step 47697920 @ 3070.7 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 1.5211e+04, step = 47697920, mean_episode_return = 37.311, mean_episode_step = 2058.6, total_loss = 117.28, pg_loss = 99.043, baseline_loss = 32.047, entropy_loss = -13.815, learner_queue_size = 64, _tick = 7284, _time = 1.6548e+09)
[2022-06-09 17:54:13,314][root][INFO] - Step 47713280 @ 3068.3 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 1.5216e+04, step = 47713280, mean_episode_return = 47.98, mean_episode_step = 2100.8, total_loss = -182.64, pg_loss = -172.46, baseline_loss = 3.5341, entropy_loss = -13.712, learner_queue_size = 64, _tick = 7287, _time = 1.6548e+09)
[2022-06-09 17:54:18,318][root][INFO] - Step 47728640 @ 3069.5 SPS. Inference batcher size: 18. Learner queue size: 64. Other stats: (train_seconds = 1.5221e+04, step = 47728640, mean_episode_return = None, mean_episode_step = 2259.5, total_loss = 9.2326, pg_loss = -2.7002, baseline_loss = 25.661, entropy_loss = -13.728, learner_queue_size = 64, _tick = 7289, _time = 1.6548e+09)
[2022-06-09 17:54:23,322][root][INFO] - Step 47744000 @ 3069.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.5226e+04, step = 47744000, mean_episode_return = 135.32, mean_episode_step = 2607.5, total_loss = -66.23, pg_loss = -68.308, baseline_loss = 15.778, entropy_loss = -13.7, learner_queue_size = 64, _tick = 7291, _time = 1.6548e+09)
[2022-06-09 17:54:28,326][root][INFO] - Step 47759360 @ 3069.6 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.5231e+04, step = 47759360, mean_episode_return = 16.95, mean_episode_step = 2253.9, total_loss = 233.0, pg_loss = 207.77, baseline_loss = 38.94, entropy_loss = -13.713, learner_queue_size = 64, _tick = 7293, _time = 1.6548e+09)
[2022-06-09 17:54:33,332][root][INFO] - Step 47774720 @ 3068.3 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.5236e+04, step = 47774720, mean_episode_return = 2.7002, mean_episode_step = 2256.3, total_loss = 31.138, pg_loss = 11.889, baseline_loss = 32.956, entropy_loss = -13.707, learner_queue_size = 64, _tick = 7296, _time = 1.6548e+09)
[2022-06-09 17:54:38,338][root][INFO] - Step 47790080 @ 3068.3 SPS. Inference batcher size: 7. Learner queue size: 64. Other stats: (train_seconds = 1.5241e+04, step = 47790080, mean_episode_return = 71.922, mean_episode_step = 2132.7, total_loss = -91.774, pg_loss = -96.316, baseline_loss = 18.076, entropy_loss = -13.534, learner_queue_size = 64, _tick = 7299, _time = 1.6548e+09)
[2022-06-09 17:54:43,342][root][INFO] - Step 47810560 @ 4092.6 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 1.5246e+04, step = 47810560, mean_episode_return = 67.377, mean_episode_step = 2241.9, total_loss = -110.42, pg_loss = -126.12, baseline_loss = 29.43, entropy_loss = -13.725, learner_queue_size = 64, _tick = 7303, _time = 1.6548e+09)
[2022-06-09 17:54:48,346][root][INFO] - Step 47825920 @ 3069.4 SPS. Inference batcher size: 72. Learner queue size: 64. Other stats: (train_seconds = 1.5251e+04, step = 47825920, mean_episode_return = 75.356, mean_episode_step = 2095.4, total_loss = -59.359, pg_loss = -61.062, baseline_loss = 15.385, entropy_loss = -13.681, learner_queue_size = 64, _tick = 7306, _time = 1.6548e+09)
[2022-06-09 17:54:53,350][root][INFO] - Step 47841280 @ 3069.8 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 1.5256e+04, step = 47841280, mean_episode_return = 25.02, mean_episode_step = 2026.3, total_loss = -24.869, pg_loss = -31.929, baseline_loss = 20.802, entropy_loss = -13.742, learner_queue_size = 64, _tick = 7309, _time = 1.6548e+09)
[2022-06-09 17:54:58,354][root][INFO] - Step 47856640 @ 3069.5 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 1.5261e+04, step = 47856640, mean_episode_return = None, mean_episode_step = 2031.1, total_loss = 64.808, pg_loss = 39.435, baseline_loss = 39.195, entropy_loss = -13.822, learner_queue_size = 64, _tick = 7311, _time = 1.6548e+09)
[2022-06-09 17:55:03,358][root][INFO] - Step 47872000 @ 3069.6 SPS. Inference batcher size: 7. Learner queue size: 64. Other stats: (train_seconds = 1.5266e+04, step = 47872000, mean_episode_return = -1.3905, mean_episode_step = 2148.9, total_loss = 157.44, pg_loss = 132.59, baseline_loss = 38.691, entropy_loss = -13.838, learner_queue_size = 64, _tick = 7314, _time = 1.6548e+09)
[2022-06-09 17:55:08,362][root][INFO] - Step 47887360 @ 3069.6 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 1.5271e+04, step = 47887360, mean_episode_return = 160.41, mean_episode_step = 1954.2, total_loss = 37.987, pg_loss = 25.515, baseline_loss = 26.37, entropy_loss = -13.898, learner_queue_size = 64, _tick = 7317, _time = 1.6548e+09)
[2022-06-09 17:55:13,366][root][INFO] - Step 47902720 @ 3069.5 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 1.5276e+04, step = 47902720, mean_episode_return = None, mean_episode_step = 2196.6, total_loss = 116.01, pg_loss = 107.98, baseline_loss = 21.958, entropy_loss = -13.93, learner_queue_size = 64, _tick = 7319, _time = 1.6548e+09)
[2022-06-09 17:55:18,370][root][INFO] - Step 47918080 @ 3069.4 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 1.5281e+04, step = 47918080, mean_episode_return = 38.231, mean_episode_step = 2518.3, total_loss = -4.9391, pg_loss = -18.703, baseline_loss = 27.748, entropy_loss = -13.984, learner_queue_size = 64, _tick = 7321, _time = 1.6548e+09)
[2022-06-09 17:55:23,374][root][INFO] - Step 47933440 @ 3069.6 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.5286e+04, step = 47933440, mean_episode_return = 70.607, mean_episode_step = 2223.2, total_loss = 110.35, pg_loss = 92.144, baseline_loss = 32.386, entropy_loss = -14.181, learner_queue_size = 64, _tick = 7324, _time = 1.6548e+09)
[2022-06-09 17:55:28,378][root][INFO] - Step 47948800 @ 3069.6 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.5291e+04, step = 47948800, mean_episode_return = 68.066, mean_episode_step = 2173.3, total_loss = -18.016, pg_loss = -36.914, baseline_loss = 33.013, entropy_loss = -14.115, learner_queue_size = 64, _tick = 7326, _time = 1.6548e+09)
[2022-06-09 17:55:33,382][root][INFO] - Step 47969280 @ 4092.6 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.5296e+04, step = 47969280, mean_episode_return = 68.785, mean_episode_step = 1942.9, total_loss = -84.031, pg_loss = -86.007, baseline_loss = 15.983, entropy_loss = -14.007, learner_queue_size = 64, _tick = 7330, _time = 1.6548e+09)
[2022-06-09 17:55:38,386][root][INFO] - Step 47984640 @ 3069.6 SPS. Inference batcher size: 81. Learner queue size: 64. Other stats: (train_seconds = 1.5301e+04, step = 47984640, mean_episode_return = 40.113, mean_episode_step = 2489.6, total_loss = -66.082, pg_loss = -80.679, baseline_loss = 28.732, entropy_loss = -14.135, learner_queue_size = 64, _tick = 7333, _time = 1.6548e+09)
[2022-06-09 17:55:43,390][root][INFO] - Step 48000000 @ 3069.5 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 1.5306e+04, step = 48000000, mean_episode_return = 42.025, mean_episode_step = 2205.1, total_loss = -174.32, pg_loss = -174.59, baseline_loss = 14.556, entropy_loss = -14.285, learner_queue_size = 64, _tick = 7335, _time = 1.6548e+09)
[2022-06-09 17:55:48,394][root][INFO] - Step 48015360 @ 3069.5 SPS. Inference batcher size: 81. Learner queue size: 64. Other stats: (train_seconds = 1.5311e+04, step = 48015360, mean_episode_return = None, mean_episode_step = 2647.0, total_loss = 191.24, pg_loss = 159.25, baseline_loss = 46.165, entropy_loss = -14.169, learner_queue_size = 64, _tick = 7336, _time = 1.6548e+09)
[2022-06-09 17:55:53,398][root][INFO] - Step 48030720 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.5316e+04, step = 48030720, mean_episode_return = 54.659, mean_episode_step = 2108.5, total_loss = -5.6829, pg_loss = -16.615, baseline_loss = 25.148, entropy_loss = -14.216, learner_queue_size = 64, _tick = 7338, _time = 1.6548e+09)
[2022-06-09 17:55:58,402][root][INFO] - Step 48046080 @ 3069.6 SPS. Inference batcher size: 5. Learner queue size: 64. Other stats: (train_seconds = 1.5321e+04, step = 48046080, mean_episode_return = 5.0997, mean_episode_step = 2119.2, total_loss = -31.45, pg_loss = -53.12, baseline_loss = 35.955, entropy_loss = -14.285, learner_queue_size = 64, _tick = 7340, _time = 1.6548e+09)
[2022-06-09 17:56:03,408][root][INFO] - Step 48061440 @ 3068.2 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 1.5326e+04, step = 48061440, mean_episode_return = None, mean_episode_step = 2273.6, total_loss = -205.93, pg_loss = -195.8, baseline_loss = 4.0997, entropy_loss = -14.225, learner_queue_size = 64, _tick = 7342, _time = 1.6548e+09)
[2022-06-09 17:56:08,414][root][INFO] - Step 48076800 @ 3068.5 SPS. Inference batcher size: 14. Learner queue size: 64. Other stats: (train_seconds = 1.5331e+04, step = 48076800, mean_episode_return = 58.672, mean_episode_step = 2136.5, total_loss = -200.92, pg_loss = -196.54, baseline_loss = 9.9662, entropy_loss = -14.343, learner_queue_size = 64, _tick = 7345, _time = 1.6548e+09)
[2022-06-09 17:56:13,418][root][INFO] - Step 48092160 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.5336e+04, step = 48092160, mean_episode_return = None, mean_episode_step = 2279.7, total_loss = 69.234, pg_loss = 54.628, baseline_loss = 28.803, entropy_loss = -14.196, learner_queue_size = 64, _tick = 7347, _time = 1.6548e+09)
[2022-06-09 17:56:18,422][root][INFO] - Step 48107520 @ 3069.6 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.5341e+04, step = 48107520, mean_episode_return = None, mean_episode_step = 2431.7, total_loss = 107.97, pg_loss = 94.071, baseline_loss = 27.853, entropy_loss = -13.954, learner_queue_size = 64, _tick = 7349, _time = 1.6548e+09)
[2022-06-09 17:56:23,426][root][INFO] - Step 48122880 @ 3069.4 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.5346e+04, step = 48122880, mean_episode_return = None, mean_episode_step = 2216.7, total_loss = 438.57, pg_loss = 382.08, baseline_loss = 70.347, entropy_loss = -13.857, learner_queue_size = 64, _tick = 7351, _time = 1.6548e+09)
[2022-06-09 17:56:28,430][root][INFO] - Step 48138240 @ 3069.6 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.5351e+04, step = 48138240, mean_episode_return = None, mean_episode_step = 2195.0, total_loss = -52.354, pg_loss = -59.964, baseline_loss = 21.653, entropy_loss = -14.043, learner_queue_size = 64, _tick = 7352, _time = 1.6548e+09)
[2022-06-09 17:56:33,434][root][INFO] - Step 48158720 @ 4092.8 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.5356e+04, step = 48158720, mean_episode_return = 44.59, mean_episode_step = 2257.9, total_loss = -84.514, pg_loss = -91.808, baseline_loss = 21.159, entropy_loss = -13.864, learner_queue_size = 64, _tick = 7356, _time = 1.6548e+09)
[2022-06-09 17:56:38,440][root][INFO] - Step 48174080 @ 3068.2 SPS. Inference batcher size: 74. Learner queue size: 64. Other stats: (train_seconds = 1.5361e+04, step = 48174080, mean_episode_return = 10.715, mean_episode_step = 2639.2, total_loss = 28.408, pg_loss = 13.696, baseline_loss = 28.468, entropy_loss = -13.756, learner_queue_size = 64, _tick = 7358, _time = 1.6548e+09)
[2022-06-09 17:56:43,446][root][INFO] - Step 48189440 @ 3068.4 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.5366e+04, step = 48189440, mean_episode_return = -1.7665, mean_episode_step = 2249.5, total_loss = -5.589, pg_loss = -21.975, baseline_loss = 30.142, entropy_loss = -13.756, learner_queue_size = 64, _tick = 7360, _time = 1.6548e+09)
[2022-06-09 17:56:48,450][root][INFO] - Step 48204800 @ 3069.6 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 1.5371e+04, step = 48204800, mean_episode_return = 42.191, mean_episode_step = 2637.4, total_loss = -5.9739, pg_loss = -23.053, baseline_loss = 30.868, entropy_loss = -13.789, learner_queue_size = 64, _tick = 7363, _time = 1.6548e+09)
[2022-06-09 17:56:53,454][root][INFO] - Step 48220160 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.5376e+04, step = 48220160, mean_episode_return = None, mean_episode_step = 2339.7, total_loss = -111.49, pg_loss = -109.59, baseline_loss = 12.076, entropy_loss = -13.974, learner_queue_size = 64, _tick = 7364, _time = 1.6548e+09)
[2022-06-09 17:56:58,458][root][INFO] - Step 48235520 @ 3069.6 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.5381e+04, step = 48235520, mean_episode_return = 191.96, mean_episode_step = 2212.7, total_loss = -119.91, pg_loss = -120.83, baseline_loss = 14.883, entropy_loss = -13.969, learner_queue_size = 64, _tick = 7367, _time = 1.6548e+09)
[2022-06-09 17:57:03,462][root][INFO] - Step 48250880 @ 3069.5 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 1.5386e+04, step = 48250880, mean_episode_return = 98.668, mean_episode_step = 2342.0, total_loss = 192.0, pg_loss = 158.25, baseline_loss = 47.788, entropy_loss = -14.039, learner_queue_size = 64, _tick = 7370, _time = 1.6548e+09)
[2022-06-09 17:57:08,466][root][INFO] - Step 48266240 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 1.5391e+04, step = 48266240, mean_episode_return = 51.251, mean_episode_step = 2407.8, total_loss = 26.686, pg_loss = -1.4442, baseline_loss = 42.146, entropy_loss = -14.016, learner_queue_size = 64, _tick = 7372, _time = 1.6548e+09)
[2022-06-09 17:57:13,470][root][INFO] - Step 48281600 @ 3069.6 SPS. Inference batcher size: 5. Learner queue size: 64. Other stats: (train_seconds = 1.5396e+04, step = 48281600, mean_episode_return = 66.004, mean_episode_step = 2212.6, total_loss = 126.32, pg_loss = 99.138, baseline_loss = 41.046, entropy_loss = -13.867, learner_queue_size = 64, _tick = 7374, _time = 1.6548e+09)
[2022-06-09 17:57:18,474][root][INFO] - Step 48296960 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.5401e+04, step = 48296960, mean_episode_return = 33.857, mean_episode_step = 2224.6, total_loss = -159.53, pg_loss = -157.59, baseline_loss = 11.735, entropy_loss = -13.678, learner_queue_size = 64, _tick = 7377, _time = 1.6548e+09)
[2022-06-09 17:57:23,478][root][INFO] - Step 48317440 @ 4092.8 SPS. Inference batcher size: 76. Learner queue size: 64. Other stats: (train_seconds = 1.5406e+04, step = 48317440, mean_episode_return = 99.144, mean_episode_step = 2165.9, total_loss = 95.05, pg_loss = 78.629, baseline_loss = 29.969, entropy_loss = -13.548, learner_queue_size = 64, _tick = 7380, _time = 1.6548e+09)
[2022-06-09 17:57:28,482][root][INFO] - Step 48332800 @ 3069.5 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 1.5411e+04, step = 48332800, mean_episode_return = 34.863, mean_episode_step = 2285.1, total_loss = -148.6, pg_loss = -154.79, baseline_loss = 19.719, entropy_loss = -13.536, learner_queue_size = 64, _tick = 7383, _time = 1.6548e+09)
[2022-06-09 17:57:33,489][root][INFO] - Step 48348160 @ 3068.0 SPS. Inference batcher size: 8. Learner queue size: 64. Other stats: (train_seconds = 1.5416e+04, step = 48348160, mean_episode_return = -1.97, mean_episode_step = 1866.6, total_loss = 436.75, pg_loss = 373.54, baseline_loss = 76.839, entropy_loss = -13.628, learner_queue_size = 64, _tick = 7386, _time = 1.6548e+09)
[2022-06-09 17:57:38,494][root][INFO] - Step 48363520 @ 3068.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.5421e+04, step = 48363520, mean_episode_return = 12.789, mean_episode_step = 2237.9, total_loss = 48.983, pg_loss = 38.655, baseline_loss = 23.984, entropy_loss = -13.656, learner_queue_size = 64, _tick = 7387, _time = 1.6548e+09)
[2022-06-09 17:57:43,498][root][INFO] - Step 48378880 @ 3069.6 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.5426e+04, step = 48378880, mean_episode_return = 61.033, mean_episode_step = 2316.3, total_loss = -58.301, pg_loss = -63.918, baseline_loss = 19.477, entropy_loss = -13.861, learner_queue_size = 64, _tick = 7389, _time = 1.6548e+09)
[2022-06-09 17:57:48,502][root][INFO] - Step 48394240 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.5431e+04, step = 48394240, mean_episode_return = 63.089, mean_episode_step = 2568.5, total_loss = 20.363, pg_loss = 9.0555, baseline_loss = 25.23, entropy_loss = -13.922, learner_queue_size = 64, _tick = 7391, _time = 1.6548e+09)
[2022-06-09 17:57:53,506][root][INFO] - Step 48409600 @ 3069.6 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 1.5436e+04, step = 48409600, mean_episode_return = 3.3242, mean_episode_step = 2458.6, total_loss = -29.095, pg_loss = -38.416, baseline_loss = 23.372, entropy_loss = -14.05, learner_queue_size = 64, _tick = 7394, _time = 1.6548e+09)
[2022-06-09 17:57:58,510][root][INFO] - Step 48424960 @ 3069.5 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.5441e+04, step = 48424960, mean_episode_return = 68.401, mean_episode_step = 1605.4, total_loss = 8.9922, pg_loss = -24.164, baseline_loss = 47.214, entropy_loss = -14.057, learner_queue_size = 64, _tick = 7397, _time = 1.6548e+09)
[2022-06-09 17:58:03,514][root][INFO] - Step 48440320 @ 3069.6 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.5446e+04, step = 48440320, mean_episode_return = 81.032, mean_episode_step = 2107.8, total_loss = -36.43, pg_loss = -44.175, baseline_loss = 21.736, entropy_loss = -13.99, learner_queue_size = 64, _tick = 7400, _time = 1.6548e+09)
[2022-06-09 17:58:08,518][root][INFO] - Step 48460800 @ 4092.7 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 1.5452e+04, step = 48460800, mean_episode_return = 60.822, mean_episode_step = 2012.4, total_loss = 137.46, pg_loss = 112.53, baseline_loss = 38.947, entropy_loss = -14.011, learner_queue_size = 64, _tick = 7404, _time = 1.6548e+09)
[2022-06-09 17:58:13,522][root][INFO] - Step 48476160 @ 3069.5 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 1.5456e+04, step = 48476160, mean_episode_return = None, mean_episode_step = 2238.5, total_loss = -101.87, pg_loss = -100.33, baseline_loss = 12.481, entropy_loss = -14.018, learner_queue_size = 64, _tick = 7406, _time = 1.6548e+09)
[2022-06-09 17:58:18,526][root][INFO] - Step 48491520 @ 3069.6 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 1.5462e+04, step = 48491520, mean_episode_return = 42.603, mean_episode_step = 2238.6, total_loss = 120.32, pg_loss = 78.901, baseline_loss = 55.465, entropy_loss = -14.042, learner_queue_size = 64, _tick = 7409, _time = 1.6548e+09)
[2022-06-09 17:58:23,530][root][INFO] - Step 48506880 @ 3069.5 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 1.5466e+04, step = 48506880, mean_episode_return = None, mean_episode_step = 2088.9, total_loss = 18.288, pg_loss = 9.4726, baseline_loss = 22.881, entropy_loss = -14.066, learner_queue_size = 64, _tick = 7410, _time = 1.6548e+09)
[2022-06-09 17:58:28,534][root][INFO] - Step 48522240 @ 3069.6 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 1.5472e+04, step = 48522240, mean_episode_return = 19.251, mean_episode_step = 2144.0, total_loss = -58.749, pg_loss = -83.383, baseline_loss = 38.585, entropy_loss = -13.952, learner_queue_size = 64, _tick = 7413, _time = 1.6548e+09)
[2022-06-09 17:58:33,538][root][INFO] - Step 48537600 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.5476e+04, step = 48537600, mean_episode_return = 12.756, mean_episode_step = 2127.4, total_loss = 285.93, pg_loss = 219.78, baseline_loss = 80.033, entropy_loss = -13.874, learner_queue_size = 64, _tick = 7415, _time = 1.6548e+09)
[2022-06-09 17:58:38,542][root][INFO] - Step 48552960 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.5482e+04, step = 48552960, mean_episode_return = 45.948, mean_episode_step = 2060.6, total_loss = -75.094, pg_loss = -95.275, baseline_loss = 34.123, entropy_loss = -13.941, learner_queue_size = 64, _tick = 7418, _time = 1.6548e+09)
[2022-06-09 17:58:43,546][root][INFO] - Step 48568320 @ 3069.6 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.5486e+04, step = 48568320, mean_episode_return = None, mean_episode_step = 2173.9, total_loss = 225.87, pg_loss = 195.33, baseline_loss = 44.492, entropy_loss = -13.957, learner_queue_size = 64, _tick = 7420, _time = 1.6548e+09)
[2022-06-09 17:58:48,552][root][INFO] - Step 48583680 @ 3068.3 SPS. Inference batcher size: 11. Learner queue size: 64. Other stats: (train_seconds = 1.5492e+04, step = 48583680, mean_episode_return = 121.45, mean_episode_step = 2138.4, total_loss = -152.75, pg_loss = -154.64, baseline_loss = 15.809, entropy_loss = -13.921, learner_queue_size = 64, _tick = 7422, _time = 1.6548e+09)
[2022-06-09 17:58:53,558][root][INFO] - Step 48604160 @ 4091.0 SPS. Inference batcher size: 91. Learner queue size: 64. Other stats: (train_seconds = 1.5496e+04, step = 48604160, mean_episode_return = 60.59, mean_episode_step = 2196.1, total_loss = 138.5, pg_loss = 81.514, baseline_loss = 71.024, entropy_loss = -14.042, learner_queue_size = 64, _tick = 7426, _time = 1.6548e+09)
[2022-06-09 17:58:58,562][root][INFO] - Step 48619520 @ 3069.4 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 1.5502e+04, step = 48619520, mean_episode_return = 73.791, mean_episode_step = 2187.2, total_loss = 244.38, pg_loss = 218.51, baseline_loss = 39.99, entropy_loss = -14.111, learner_queue_size = 64, _tick = 7429, _time = 1.6548e+09)
[2022-06-09 17:59:03,568][root][INFO] - Step 48634880 @ 3068.4 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 1.5506e+04, step = 48634880, mean_episode_return = 44.748, mean_episode_step = 2063.5, total_loss = -62.115, pg_loss = -79.359, baseline_loss = 31.299, entropy_loss = -14.055, learner_queue_size = 64, _tick = 7432, _time = 1.6548e+09)
[2022-06-09 17:59:08,574][root][INFO] - Step 48650240 @ 3068.4 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.5512e+04, step = 48650240, mean_episode_return = 95.367, mean_episode_step = 1694.0, total_loss = 3649.7, pg_loss = 1422.8, baseline_loss = 2241.0, entropy_loss = -14.095, learner_queue_size = 64, _tick = 7435, _time = 1.6548e+09)
[2022-06-09 17:59:13,578][root][INFO] - Step 48665600 @ 3069.6 SPS. Inference batcher size: 71. Learner queue size: 64. Other stats: (train_seconds = 1.5516e+04, step = 48665600, mean_episode_return = None, mean_episode_step = 2178.7, total_loss = -172.42, pg_loss = -173.01, baseline_loss = 14.566, entropy_loss = -13.975, learner_queue_size = 64, _tick = 7437, _time = 1.6548e+09)
[2022-06-09 17:59:18,582][root][INFO] - Step 48680960 @ 3069.4 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 1.5522e+04, step = 48680960, mean_episode_return = 32.825, mean_episode_step = 2090.9, total_loss = 69.799, pg_loss = 34.382, baseline_loss = 49.367, entropy_loss = -13.949, learner_queue_size = 64, _tick = 7440, _time = 1.6548e+09)
[2022-06-09 17:59:23,586][root][INFO] - Step 48696320 @ 3069.8 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.5526e+04, step = 48696320, mean_episode_return = 53.029, mean_episode_step = 1953.4, total_loss = -9.3773, pg_loss = -19.233, baseline_loss = 23.926, entropy_loss = -14.07, learner_queue_size = 64, _tick = 7443, _time = 1.6548e+09)
[2022-06-09 17:59:28,590][root][INFO] - Step 48711680 @ 3069.5 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 1.5532e+04, step = 48711680, mean_episode_return = 27.041, mean_episode_step = 1704.4, total_loss = 242.37, pg_loss = 209.18, baseline_loss = 47.296, entropy_loss = -14.106, learner_queue_size = 64, _tick = 7446, _time = 1.6548e+09)
[2022-06-09 17:59:33,594][root][INFO] - Step 48727040 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.5536e+04, step = 48727040, mean_episode_return = 77.569, mean_episode_step = 2132.7, total_loss = 96.831, pg_loss = 75.992, baseline_loss = 34.998, entropy_loss = -14.159, learner_queue_size = 64, _tick = 7448, _time = 1.6548e+09)
[2022-06-09 17:59:38,598][root][INFO] - Step 48747520 @ 4092.8 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 1.5542e+04, step = 48747520, mean_episode_return = 93.006, mean_episode_step = 1917.6, total_loss = 75.218, pg_loss = 54.716, baseline_loss = 34.518, entropy_loss = -14.016, learner_queue_size = 64, _tick = 7452, _time = 1.6548e+09)
[2022-06-09 17:59:43,602][root][INFO] - Step 48762880 @ 3069.5 SPS. Inference batcher size: 67. Learner queue size: 64. Other stats: (train_seconds = 1.5546e+04, step = 48762880, mean_episode_return = 196.51, mean_episode_step = 1839.1, total_loss = -117.07, pg_loss = -132.87, baseline_loss = 29.793, entropy_loss = -13.99, learner_queue_size = 64, _tick = 7454, _time = 1.6548e+09)
[2022-06-09 17:59:48,606][root][INFO] - Step 48778240 @ 3069.5 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 1.5552e+04, step = 48778240, mean_episode_return = 47.267, mean_episode_step = 1884.5, total_loss = 89.53, pg_loss = 53.333, baseline_loss = 50.156, entropy_loss = -13.959, learner_queue_size = 64, _tick = 7456, _time = 1.6548e+09)
[2022-06-09 17:59:53,610][root][INFO] - Step 48793600 @ 3069.6 SPS. Inference batcher size: 84. Learner queue size: 64. Other stats: (train_seconds = 1.5556e+04, step = 48793600, mean_episode_return = 60.851, mean_episode_step = 2105.1, total_loss = 129.14, pg_loss = 101.11, baseline_loss = 41.892, entropy_loss = -13.861, learner_queue_size = 64, _tick = 7458, _time = 1.6548e+09)
[2022-06-09 17:59:58,618][root][INFO] - Step 48808960 @ 3067.3 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.5562e+04, step = 48808960, mean_episode_return = 72.302, mean_episode_step = 1924.7, total_loss = 165.49, pg_loss = 125.75, baseline_loss = 53.706, entropy_loss = -13.969, learner_queue_size = 64, _tick = 7461, _time = 1.6548e+09)
[2022-06-09 18:00:03,622][root][INFO] - Step 48824320 @ 3069.3 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.5567e+04, step = 48824320, mean_episode_return = 95.507, mean_episode_step = 1891.0, total_loss = -44.397, pg_loss = -63.781, baseline_loss = 33.292, entropy_loss = -13.909, learner_queue_size = 64, _tick = 7463, _time = 1.6548e+09)
[2022-06-09 18:00:08,626][root][INFO] - Step 48839680 @ 3069.5 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.5572e+04, step = 48839680, mean_episode_return = 70.789, mean_episode_step = 1922.6, total_loss = 150.36, pg_loss = 118.41, baseline_loss = 45.675, entropy_loss = -13.732, learner_queue_size = 64, _tick = 7465, _time = 1.6548e+09)
[2022-06-09 18:00:13,630][root][INFO] - Step 48855040 @ 3069.6 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.5577e+04, step = 48855040, mean_episode_return = None, mean_episode_step = 2019.0, total_loss = -86.194, pg_loss = -89.439, baseline_loss = 16.808, entropy_loss = -13.564, learner_queue_size = 64, _tick = 7466, _time = 1.6548e+09)
[2022-06-09 18:00:18,634][root][INFO] - Step 48870400 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.5582e+04, step = 48870400, mean_episode_return = 64.051, mean_episode_step = 2001.6, total_loss = -129.88, pg_loss = -153.64, baseline_loss = 37.513, entropy_loss = -13.753, learner_queue_size = 64, _tick = 7468, _time = 1.6548e+09)
[2022-06-09 18:00:23,638][root][INFO] - Step 48885760 @ 3069.6 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1.5587e+04, step = 48885760, mean_episode_return = -5.59, mean_episode_step = 2017.7, total_loss = -21.949, pg_loss = -35.168, baseline_loss = 26.716, entropy_loss = -13.497, learner_queue_size = 64, _tick = 7470, _time = 1.6548e+09)
[2022-06-09 18:00:28,642][root][INFO] - Step 48906240 @ 4092.7 SPS. Inference batcher size: 89. Learner queue size: 64. Other stats: (train_seconds = 1.5592e+04, step = 48906240, mean_episode_return = 88.49, mean_episode_step = 2209.5, total_loss = 266.73, pg_loss = 200.3, baseline_loss = 79.838, entropy_loss = -13.416, learner_queue_size = 64, _tick = 7474, _time = 1.6548e+09)
[2022-06-09 18:00:33,646][root][INFO] - Step 48921600 @ 3069.5 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 1.5597e+04, step = 48921600, mean_episode_return = 49.68, mean_episode_step = 2395.0, total_loss = 33.062, pg_loss = 5.3024, baseline_loss = 41.217, entropy_loss = -13.458, learner_queue_size = 64, _tick = 7477, _time = 1.6548e+09)
[2022-06-09 18:00:38,650][root][INFO] - Step 48936960 @ 3069.6 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 1.5602e+04, step = 48936960, mean_episode_return = 57.928, mean_episode_step = 1875.4, total_loss = -6.8444, pg_loss = -16.438, baseline_loss = 23.042, entropy_loss = -13.448, learner_queue_size = 64, _tick = 7480, _time = 1.6548e+09)
[2022-06-09 18:00:43,654][root][INFO] - Step 48952320 @ 3069.5 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 1.5607e+04, step = 48952320, mean_episode_return = None, mean_episode_step = 2106.4, total_loss = 29.992, pg_loss = 21.278, baseline_loss = 21.919, entropy_loss = -13.205, learner_queue_size = 64, _tick = 7482, _time = 1.6548e+09)
[2022-06-09 18:00:48,658][root][INFO] - Step 48967680 @ 3069.6 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.5612e+04, step = 48967680, mean_episode_return = 10.96, mean_episode_step = 2166.9, total_loss = 329.59, pg_loss = 296.32, baseline_loss = 46.658, entropy_loss = -13.393, learner_queue_size = 64, _tick = 7485, _time = 1.6548e+09)
[2022-06-09 18:00:53,662][root][INFO] - Step 48983040 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.5617e+04, step = 48983040, mean_episode_return = 51.28, mean_episode_step = 1933.8, total_loss = 166.97, pg_loss = 135.76, baseline_loss = 44.511, entropy_loss = -13.301, learner_queue_size = 64, _tick = 7488, _time = 1.6548e+09)
[2022-06-09 18:00:58,666][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 18:00:58,906][root][INFO] - Step 48998400 @ 3069.5 SPS. Inference batcher size: 11. Learner queue size: 64. Other stats: (train_seconds = 1.5622e+04, step = 48998400, mean_episode_return = 58.993, mean_episode_step = 2420.4, total_loss = -175.9, pg_loss = -187.2, baseline_loss = 24.47, entropy_loss = -13.169, learner_queue_size = 64, _tick = 7490, _time = 1.6548e+09)
[2022-06-09 18:01:03,911][root][INFO] - Step 49013760 @ 2928.3 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.5627e+04, step = 49013760, mean_episode_return = 3.2147, mean_episode_step = 2002.1, total_loss = 364.68, pg_loss = 307.86, baseline_loss = 70.04, entropy_loss = -13.214, learner_queue_size = 64, _tick = 7493, _time = 1.6548e+09)
[2022-06-09 18:01:08,914][root][INFO] - Step 49034240 @ 4093.9 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.5632e+04, step = 49034240, mean_episode_return = 48.066, mean_episode_step = 2088.5, total_loss = 93.276, pg_loss = 52.758, baseline_loss = 53.614, entropy_loss = -13.096, learner_queue_size = 64, _tick = 7497, _time = 1.6548e+09)
[2022-06-09 18:01:13,918][root][INFO] - Step 49049600 @ 3069.5 SPS. Inference batcher size: 90. Learner queue size: 64. Other stats: (train_seconds = 1.5637e+04, step = 49049600, mean_episode_return = 36.398, mean_episode_step = 2403.7, total_loss = -114.44, pg_loss = -149.72, baseline_loss = 48.33, entropy_loss = -13.042, learner_queue_size = 64, _tick = 7499, _time = 1.6548e+09)
[2022-06-09 18:01:18,922][root][INFO] - Step 49064960 @ 3069.5 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 1.5642e+04, step = 49064960, mean_episode_return = 78.347, mean_episode_step = 2225.0, total_loss = -162.34, pg_loss = -164.67, baseline_loss = 15.338, entropy_loss = -13.003, learner_queue_size = 64, _tick = 7501, _time = 1.6548e+09)
[2022-06-09 18:01:23,926][root][INFO] - Step 49080320 @ 3069.5 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 1.5647e+04, step = 49080320, mean_episode_return = -1.7303, mean_episode_step = 1968.5, total_loss = -53.862, pg_loss = -69.572, baseline_loss = 28.92, entropy_loss = -13.21, learner_queue_size = 64, _tick = 7504, _time = 1.6548e+09)
[2022-06-09 18:01:28,930][root][INFO] - Step 49095680 @ 3069.6 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 1.5652e+04, step = 49095680, mean_episode_return = 53.43, mean_episode_step = 1853.3, total_loss = -131.1, pg_loss = -134.27, baseline_loss = 16.661, entropy_loss = -13.491, learner_queue_size = 64, _tick = 7507, _time = 1.6548e+09)
[2022-06-09 18:01:33,934][root][INFO] - Step 49111040 @ 3069.6 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.5657e+04, step = 49111040, mean_episode_return = None, mean_episode_step = 1845.0, total_loss = -45.051, pg_loss = -50.949, baseline_loss = 19.425, entropy_loss = -13.527, learner_queue_size = 64, _tick = 7509, _time = 1.6548e+09)
[2022-06-09 18:01:38,938][root][INFO] - Step 49126400 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.5662e+04, step = 49126400, mean_episode_return = 43.191, mean_episode_step = 1771.8, total_loss = -58.141, pg_loss = -71.535, baseline_loss = 26.692, entropy_loss = -13.297, learner_queue_size = 64, _tick = 7512, _time = 1.6548e+09)
[2022-06-09 18:01:43,942][root][INFO] - Step 49141760 @ 3069.5 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 1.5667e+04, step = 49141760, mean_episode_return = 47.442, mean_episode_step = 1862.0, total_loss = 87.719, pg_loss = 78.217, baseline_loss = 23.06, entropy_loss = -13.557, learner_queue_size = 64, _tick = 7515, _time = 1.6548e+09)
[2022-06-09 18:01:48,946][root][INFO] - Step 49157120 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.5672e+04, step = 49157120, mean_episode_return = 76.478, mean_episode_step = 2038.7, total_loss = 184.34, pg_loss = 142.53, baseline_loss = 55.532, entropy_loss = -13.724, learner_queue_size = 64, _tick = 7517, _time = 1.6548e+09)
[2022-06-09 18:01:53,950][root][INFO] - Step 49172480 @ 3069.6 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 1.5677e+04, step = 49172480, mean_episode_return = 42.085, mean_episode_step = 1853.8, total_loss = -196.72, pg_loss = -215.23, baseline_loss = 32.255, entropy_loss = -13.749, learner_queue_size = 64, _tick = 7520, _time = 1.6548e+09)
[2022-06-09 18:01:58,954][root][INFO] - Step 49187840 @ 3069.5 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.5682e+04, step = 49187840, mean_episode_return = 55.528, mean_episode_step = 1921.2, total_loss = -109.37, pg_loss = -124.79, baseline_loss = 29.162, entropy_loss = -13.743, learner_queue_size = 64, _tick = 7523, _time = 1.6548e+09)
[2022-06-09 18:02:03,958][root][INFO] - Step 49203200 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.5687e+04, step = 49203200, mean_episode_return = 98.677, mean_episode_step = 1860.0, total_loss = 107.37, pg_loss = 87.973, baseline_loss = 33.316, entropy_loss = -13.919, learner_queue_size = 64, _tick = 7526, _time = 1.6548e+09)
[2022-06-09 18:02:08,962][root][INFO] - Step 49223680 @ 4092.7 SPS. Inference batcher size: 87. Learner queue size: 64. Other stats: (train_seconds = 1.5692e+04, step = 49223680, mean_episode_return = 67.004, mean_episode_step = 1596.0, total_loss = 618.96, pg_loss = 534.14, baseline_loss = 98.464, entropy_loss = -13.643, learner_queue_size = 64, _tick = 7530, _time = 1.6548e+09)
[2022-06-09 18:02:13,966][root][INFO] - Step 49239040 @ 3069.6 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 1.5697e+04, step = 49239040, mean_episode_return = 73.735, mean_episode_step = 1581.5, total_loss = 286.28, pg_loss = 251.31, baseline_loss = 48.442, entropy_loss = -13.474, learner_queue_size = 64, _tick = 7533, _time = 1.6548e+09)
[2022-06-09 18:02:18,970][root][INFO] - Step 49254400 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.5702e+04, step = 49254400, mean_episode_return = 57.608, mean_episode_step = 1675.2, total_loss = 115.97, pg_loss = 88.297, baseline_loss = 41.111, entropy_loss = -13.435, learner_queue_size = 64, _tick = 7536, _time = 1.6548e+09)
[2022-06-09 18:02:23,974][root][INFO] - Step 49269760 @ 3069.5 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 1.5707e+04, step = 49269760, mean_episode_return = 7.5746, mean_episode_step = 1859.3, total_loss = 198.9, pg_loss = 157.53, baseline_loss = 54.794, entropy_loss = -13.418, learner_queue_size = 64, _tick = 7538, _time = 1.6548e+09)
[2022-06-09 18:02:28,978][root][INFO] - Step 49285120 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.5712e+04, step = 49285120, mean_episode_return = 5.3496, mean_episode_step = 1518.5, total_loss = 262.41, pg_loss = 206.34, baseline_loss = 69.229, entropy_loss = -13.158, learner_queue_size = 64, _tick = 7541, _time = 1.6548e+09)
[2022-06-09 18:02:33,982][root][INFO] - Step 49300480 @ 3069.5 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 1.5717e+04, step = 49300480, mean_episode_return = 79.496, mean_episode_step = 1705.6, total_loss = -256.94, pg_loss = -260.73, baseline_loss = 16.978, entropy_loss = -13.18, learner_queue_size = 64, _tick = 7544, _time = 1.6548e+09)
[2022-06-09 18:02:38,986][root][INFO] - Step 49315840 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.5722e+04, step = 49315840, mean_episode_return = 36.391, mean_episode_step = 1253.5, total_loss = 5.1956, pg_loss = -10.471, baseline_loss = 28.75, entropy_loss = -13.084, learner_queue_size = 64, _tick = 7547, _time = 1.6548e+09)
[2022-06-09 18:02:43,990][root][INFO] - Step 49331200 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.5727e+04, step = 49331200, mean_episode_return = None, mean_episode_step = 1625.2, total_loss = 162.25, pg_loss = 133.61, baseline_loss = 41.67, entropy_loss = -13.029, learner_queue_size = 64, _tick = 7549, _time = 1.6548e+09)
[2022-06-09 18:02:48,994][root][INFO] - Step 49346560 @ 3069.9 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 1.5732e+04, step = 49346560, mean_episode_return = 9.1751, mean_episode_step = 1603.8, total_loss = 347.15, pg_loss = 185.78, baseline_loss = 174.37, entropy_loss = -12.997, learner_queue_size = 64, _tick = 7551, _time = 1.6548e+09)
[2022-06-09 18:02:53,998][root][INFO] - Step 49367040 @ 4092.0 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 1.5737e+04, step = 49367040, mean_episode_return = 41.628, mean_episode_step = 1793.9, total_loss = -30.464, pg_loss = -55.031, baseline_loss = 37.595, entropy_loss = -13.028, learner_queue_size = 64, _tick = 7554, _time = 1.6548e+09)
[2022-06-09 18:02:59,002][root][INFO] - Step 49382400 @ 3069.8 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 1.5742e+04, step = 49382400, mean_episode_return = 69.32, mean_episode_step = 1741.1, total_loss = -222.4, pg_loss = -221.68, baseline_loss = 12.242, entropy_loss = -12.972, learner_queue_size = 64, _tick = 7557, _time = 1.6548e+09)
[2022-06-09 18:03:04,006][root][INFO] - Step 49397760 @ 3069.6 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.5747e+04, step = 49397760, mean_episode_return = None, mean_episode_step = 1720.4, total_loss = 35.714, pg_loss = 9.6599, baseline_loss = 38.999, entropy_loss = -12.945, learner_queue_size = 64, _tick = 7558, _time = 1.6548e+09)
[2022-06-09 18:03:09,010][root][INFO] - Step 49413120 @ 3069.5 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 1.5752e+04, step = 49413120, mean_episode_return = 12.073, mean_episode_step = 1786.5, total_loss = -161.62, pg_loss = -183.7, baseline_loss = 35.072, entropy_loss = -12.992, learner_queue_size = 64, _tick = 7561, _time = 1.6548e+09)
[2022-06-09 18:03:14,031][root][INFO] - Step 49428480 @ 3059.3 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 1.5757e+04, step = 49428480, mean_episode_return = 85.838, mean_episode_step = 1780.5, total_loss = 188.5, pg_loss = 153.44, baseline_loss = 48.073, entropy_loss = -13.007, learner_queue_size = 64, _tick = 7564, _time = 1.6548e+09)
[2022-06-09 18:03:19,034][root][INFO] - Step 49443840 @ 3069.9 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.5762e+04, step = 49443840, mean_episode_return = None, mean_episode_step = 1761.1, total_loss = -65.987, pg_loss = -71.913, baseline_loss = 18.959, entropy_loss = -13.033, learner_queue_size = 64, _tick = 7566, _time = 1.6548e+09)
[2022-06-09 18:03:24,038][root][INFO] - Step 49459200 @ 3069.6 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.5767e+04, step = 49459200, mean_episode_return = 88.342, mean_episode_step = 2192.1, total_loss = -233.08, pg_loss = -246.02, baseline_loss = 26.0, entropy_loss = -13.053, learner_queue_size = 64, _tick = 7568, _time = 1.6548e+09)
[2022-06-09 18:03:29,042][root][INFO] - Step 49474560 @ 3069.5 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 1.5772e+04, step = 49474560, mean_episode_return = None, mean_episode_step = 1828.2, total_loss = 91.11, pg_loss = 72.817, baseline_loss = 31.497, entropy_loss = -13.204, learner_queue_size = 64, _tick = 7569, _time = 1.6548e+09)
[2022-06-09 18:03:34,046][root][INFO] - Step 49489920 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.5777e+04, step = 49489920, mean_episode_return = 116.14, mean_episode_step = 1778.5, total_loss = 139.72, pg_loss = 109.75, baseline_loss = 42.886, entropy_loss = -12.92, learner_queue_size = 64, _tick = 7572, _time = 1.6548e+09)
[2022-06-09 18:03:39,052][root][INFO] - Step 49505280 @ 3068.3 SPS. Inference batcher size: 5. Learner queue size: 64. Other stats: (train_seconds = 1.5782e+04, step = 49505280, mean_episode_return = None, mean_episode_step = 1802.0, total_loss = -55.808, pg_loss = -59.516, baseline_loss = 16.606, entropy_loss = -12.898, learner_queue_size = 64, _tick = 7572, _time = 1.6548e+09)
[2022-06-09 18:03:44,058][root][INFO] - Step 49525760 @ 4091.2 SPS. Inference batcher size: 94. Learner queue size: 64. Other stats: (train_seconds = 1.5787e+04, step = 49525760, mean_episode_return = None, mean_episode_step = 2026.5, total_loss = -52.457, pg_loss = -51.579, baseline_loss = 12.148, entropy_loss = -13.026, learner_queue_size = 64, _tick = 7575, _time = 1.6548e+09)
[2022-06-09 18:03:49,062][root][INFO] - Step 49541120 @ 3069.5 SPS. Inference batcher size: 75. Learner queue size: 64. Other stats: (train_seconds = 1.5792e+04, step = 49541120, mean_episode_return = 23.06, mean_episode_step = 1489.0, total_loss = 113.98, pg_loss = 90.744, baseline_loss = 36.3, entropy_loss = -13.064, learner_queue_size = 64, _tick = 7578, _time = 1.6548e+09)
[2022-06-09 18:03:54,066][root][INFO] - Step 49556480 @ 3069.6 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 1.5797e+04, step = 49556480, mean_episode_return = 65.43, mean_episode_step = 2127.1, total_loss = -97.778, pg_loss = -108.46, baseline_loss = 23.507, entropy_loss = -12.826, learner_queue_size = 64, _tick = 7581, _time = 1.6548e+09)
[2022-06-09 18:03:59,070][root][INFO] - Step 49571840 @ 3069.6 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 1.5802e+04, step = 49571840, mean_episode_return = 43.515, mean_episode_step = 1902.3, total_loss = -112.1, pg_loss = -124.62, baseline_loss = 25.428, entropy_loss = -12.911, learner_queue_size = 64, _tick = 7583, _time = 1.6548e+09)
[2022-06-09 18:04:04,074][root][INFO] - Step 49587200 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.5807e+04, step = 49587200, mean_episode_return = 21.03, mean_episode_step = 2172.5, total_loss = 47.711, pg_loss = 13.601, baseline_loss = 47.08, entropy_loss = -12.969, learner_queue_size = 64, _tick = 7585, _time = 1.6548e+09)
[2022-06-09 18:04:09,078][root][INFO] - Step 49602560 @ 3069.6 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 1.5812e+04, step = 49602560, mean_episode_return = None, mean_episode_step = 2068.0, total_loss = 64.605, pg_loss = 55.303, baseline_loss = 22.493, entropy_loss = -13.191, learner_queue_size = 64, _tick = 7587, _time = 1.6548e+09)
[2022-06-09 18:04:14,082][root][INFO] - Step 49617920 @ 3069.5 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.5817e+04, step = 49617920, mean_episode_return = 24.804, mean_episode_step = 2072.7, total_loss = -270.52, pg_loss = -268.14, baseline_loss = 10.81, entropy_loss = -13.191, learner_queue_size = 64, _tick = 7590, _time = 1.6548e+09)
[2022-06-09 18:04:19,086][root][INFO] - Step 49633280 @ 3069.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.5822e+04, step = 49633280, mean_episode_return = 67.719, mean_episode_step = 1953.2, total_loss = -196.04, pg_loss = -190.97, baseline_loss = 8.0805, entropy_loss = -13.145, learner_queue_size = 64, _tick = 7592, _time = 1.6548e+09)
[2022-06-09 18:04:24,090][root][INFO] - Step 49648640 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.5827e+04, step = 49648640, mean_episode_return = None, mean_episode_step = 1963.4, total_loss = -236.84, pg_loss = -225.63, baseline_loss = 1.9188, entropy_loss = -13.125, learner_queue_size = 64, _tick = 7594, _time = 1.6548e+09)
[2022-06-09 18:04:29,094][root][INFO] - Step 49664000 @ 3069.5 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 1.5832e+04, step = 49664000, mean_episode_return = 30.12, mean_episode_step = 2095.9, total_loss = -71.488, pg_loss = -79.603, baseline_loss = 21.25, entropy_loss = -13.134, learner_queue_size = 64, _tick = 7597, _time = 1.6548e+09)
[2022-06-09 18:04:34,098][root][INFO] - Step 49679360 @ 3069.6 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 1.5837e+04, step = 49679360, mean_episode_return = 4.4896, mean_episode_step = 1995.3, total_loss = 143.0, pg_loss = 88.39, baseline_loss = 67.893, entropy_loss = -13.281, learner_queue_size = 64, _tick = 7599, _time = 1.6548e+09)
[2022-06-09 18:04:39,102][root][INFO] - Step 49699840 @ 4092.7 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 1.5842e+04, step = 49699840, mean_episode_return = 73.022, mean_episode_step = 1590.9, total_loss = 49.825, pg_loss = 26.049, baseline_loss = 37.069, entropy_loss = -13.293, learner_queue_size = 64, _tick = 7602, _time = 1.6548e+09)
[2022-06-09 18:04:44,106][root][INFO] - Step 49715200 @ 3069.5 SPS. Inference batcher size: 9. Learner queue size: 64. Other stats: (train_seconds = 1.5847e+04, step = 49715200, mean_episode_return = 116.09, mean_episode_step = 1854.1, total_loss = 703.9, pg_loss = 602.62, baseline_loss = 114.36, entropy_loss = -13.083, learner_queue_size = 64, _tick = 7605, _time = 1.6548e+09)
[2022-06-09 18:04:49,110][root][INFO] - Step 49730560 @ 3069.6 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 1.5852e+04, step = 49730560, mean_episode_return = 63.207, mean_episode_step = 2020.9, total_loss = 8.5898, pg_loss = -13.843, baseline_loss = 35.484, entropy_loss = -13.051, learner_queue_size = 64, _tick = 7608, _time = 1.6548e+09)
[2022-06-09 18:04:54,114][root][INFO] - Step 49745920 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.5857e+04, step = 49745920, mean_episode_return = 58.281, mean_episode_step = 1932.1, total_loss = -15.803, pg_loss = -29.481, baseline_loss = 26.623, entropy_loss = -12.944, learner_queue_size = 64, _tick = 7611, _time = 1.6548e+09)
[2022-06-09 18:04:59,118][root][INFO] - Step 49761280 @ 3069.5 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 1.5862e+04, step = 49761280, mean_episode_return = 70.89, mean_episode_step = 1810.5, total_loss = 113.75, pg_loss = 72.89, baseline_loss = 53.911, entropy_loss = -13.053, learner_queue_size = 64, _tick = 7614, _time = 1.6548e+09)
[2022-06-09 18:05:04,124][root][INFO] - Step 49776640 @ 3068.3 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.5867e+04, step = 49776640, mean_episode_return = None, mean_episode_step = 2021.2, total_loss = -249.41, pg_loss = -238.98, baseline_loss = 2.5655, entropy_loss = -13.0, learner_queue_size = 64, _tick = 7616, _time = 1.6548e+09)
[2022-06-09 18:05:09,130][root][INFO] - Step 49792000 @ 3068.3 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.5872e+04, step = 49792000, mean_episode_return = 53.889, mean_episode_step = 1603.5, total_loss = 205.52, pg_loss = 151.06, baseline_loss = 67.423, entropy_loss = -12.97, learner_queue_size = 64, _tick = 7619, _time = 1.6548e+09)
[2022-06-09 18:05:14,134][root][INFO] - Step 49807360 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.5877e+04, step = 49807360, mean_episode_return = 45.321, mean_episode_step = 1977.0, total_loss = -183.37, pg_loss = -180.01, baseline_loss = 9.514, entropy_loss = -12.87, learner_queue_size = 64, _tick = 7621, _time = 1.6548e+09)
[2022-06-09 18:05:19,138][root][INFO] - Step 49822720 @ 3069.6 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.5882e+04, step = 49822720, mean_episode_return = None, mean_episode_step = 2168.9, total_loss = -84.312, pg_loss = -87.035, baseline_loss = 15.613, entropy_loss = -12.89, learner_queue_size = 64, _tick = 7622, _time = 1.6548e+09)
[2022-06-09 18:05:24,142][root][INFO] - Step 49843200 @ 4092.7 SPS. Inference batcher size: 94. Learner queue size: 64. Other stats: (train_seconds = 1.5887e+04, step = 49843200, mean_episode_return = None, mean_episode_step = 1702.5, total_loss = 77.52, pg_loss = 52.253, baseline_loss = 38.134, entropy_loss = -12.867, learner_queue_size = 64, _tick = 7624, _time = 1.6548e+09)
[2022-06-09 18:05:29,146][root][INFO] - Step 49858560 @ 3069.6 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 1.5892e+04, step = 49858560, mean_episode_return = 16.43, mean_episode_step = 2080.9, total_loss = -3.6948, pg_loss = -22.074, baseline_loss = 31.455, entropy_loss = -13.075, learner_queue_size = 64, _tick = 7627, _time = 1.6548e+09)
[2022-06-09 18:05:34,150][root][INFO] - Step 49873920 @ 3069.5 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 1.5897e+04, step = 49873920, mean_episode_return = 7.5497, mean_episode_step = 1898.5, total_loss = 152.02, pg_loss = 104.88, baseline_loss = 59.977, entropy_loss = -12.841, learner_queue_size = 64, _tick = 7630, _time = 1.6548e+09)
[2022-06-09 18:05:39,154][root][INFO] - Step 49889280 @ 3069.5 SPS. Inference batcher size: 71. Learner queue size: 64. Other stats: (train_seconds = 1.5902e+04, step = 49889280, mean_episode_return = 67.421, mean_episode_step = 1929.7, total_loss = 34.521, pg_loss = 12.343, baseline_loss = 35.199, entropy_loss = -13.021, learner_queue_size = 64, _tick = 7632, _time = 1.6548e+09)
[2022-06-09 18:05:44,158][root][INFO] - Step 49904640 @ 3069.6 SPS. Inference batcher size: 8. Learner queue size: 64. Other stats: (train_seconds = 1.5907e+04, step = 49904640, mean_episode_return = 83.148, mean_episode_step = 1904.2, total_loss = 44.678, pg_loss = 24.576, baseline_loss = 32.984, entropy_loss = -12.882, learner_queue_size = 64, _tick = 7635, _time = 1.6548e+09)
[2022-06-09 18:05:49,162][root][INFO] - Step 49920000 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.5912e+04, step = 49920000, mean_episode_return = 97.308, mean_episode_step = 2048.2, total_loss = 52.546, pg_loss = 29.314, baseline_loss = 36.231, entropy_loss = -12.999, learner_queue_size = 64, _tick = 7637, _time = 1.6548e+09)
[2022-06-09 18:05:54,166][root][INFO] - Step 49935360 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.5917e+04, step = 49935360, mean_episode_return = 51.744, mean_episode_step = 1873.8, total_loss = -126.52, pg_loss = -144.71, baseline_loss = 31.382, entropy_loss = -13.193, learner_queue_size = 64, _tick = 7639, _time = 1.6548e+09)
[2022-06-09 18:05:59,170][root][INFO] - Step 49950720 @ 3069.6 SPS. Inference batcher size: 11. Learner queue size: 64. Other stats: (train_seconds = 1.5922e+04, step = 49950720, mean_episode_return = None, mean_episode_step = 1781.3, total_loss = -258.99, pg_loss = -247.65, baseline_loss = 1.8292, entropy_loss = -13.166, learner_queue_size = 64, _tick = 7641, _time = 1.6548e+09)
[2022-06-09 18:06:04,174][root][INFO] - Step 49966080 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.5927e+04, step = 49966080, mean_episode_return = 39.305, mean_episode_step = 1958.8, total_loss = 98.684, pg_loss = 54.261, baseline_loss = 57.799, entropy_loss = -13.377, learner_queue_size = 64, _tick = 7643, _time = 1.6548e+09)
[2022-06-09 18:06:09,178][root][INFO] - Step 49981440 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.5932e+04, step = 49981440, mean_episode_return = 19.71, mean_episode_step = 2207.5, total_loss = -109.7, pg_loss = -115.85, baseline_loss = 19.706, entropy_loss = -13.552, learner_queue_size = 64, _tick = 7644, _time = 1.6548e+09)
[2022-06-09 18:06:14,182][root][INFO] - Step 49996800 @ 3069.5 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.5937e+04, step = 49996800, mean_episode_return = 1.5743, mean_episode_step = 2130.3, total_loss = 18.831, pg_loss = 6.2948, baseline_loss = 26.015, entropy_loss = -13.479, learner_queue_size = 64, _tick = 7646, _time = 1.6548e+09)
[2022-06-09 18:06:19,186][root][INFO] - Step 50017280 @ 4092.8 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 1.5942e+04, step = 50017280, mean_episode_return = 83.094, mean_episode_step = 2193.4, total_loss = -211.07, pg_loss = -210.65, baseline_loss = 13.075, entropy_loss = -13.493, learner_queue_size = 64, _tick = 7650, _time = 1.6548e+09)
[2022-06-09 18:06:24,190][root][INFO] - Step 50032640 @ 3069.5 SPS. Inference batcher size: 75. Learner queue size: 64. Other stats: (train_seconds = 1.5947e+04, step = 50032640, mean_episode_return = 56.29, mean_episode_step = 1841.5, total_loss = 386.45, pg_loss = 346.65, baseline_loss = 53.426, entropy_loss = -13.627, learner_queue_size = 64, _tick = 7653, _time = 1.6548e+09)
[2022-06-09 18:06:29,194][root][INFO] - Step 50048000 @ 3069.4 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.5952e+04, step = 50048000, mean_episode_return = -3.5956, mean_episode_step = 2129.2, total_loss = -57.127, pg_loss = -68.082, baseline_loss = 24.578, entropy_loss = -13.623, learner_queue_size = 64, _tick = 7656, _time = 1.6548e+09)
[2022-06-09 18:06:34,198][root][INFO] - Step 50063360 @ 3069.7 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.5957e+04, step = 50063360, mean_episode_return = 2.7945, mean_episode_step = 1949.6, total_loss = -42.742, pg_loss = -55.079, baseline_loss = 25.989, entropy_loss = -13.652, learner_queue_size = 64, _tick = 7659, _time = 1.6548e+09)
[2022-06-09 18:06:39,202][root][INFO] - Step 50078720 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.5962e+04, step = 50078720, mean_episode_return = None, mean_episode_step = 2029.0, total_loss = 72.386, pg_loss = 58.815, baseline_loss = 27.369, entropy_loss = -13.798, learner_queue_size = 64, _tick = 7660, _time = 1.6548e+09)
[2022-06-09 18:06:44,206][root][INFO] - Step 50094080 @ 3069.6 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 1.5967e+04, step = 50094080, mean_episode_return = 23.926, mean_episode_step = 2141.2, total_loss = -52.223, pg_loss = -63.867, baseline_loss = 25.436, entropy_loss = -13.793, learner_queue_size = 64, _tick = 7663, _time = 1.6548e+09)
[2022-06-09 18:06:49,210][root][INFO] - Step 50114560 @ 4092.7 SPS. Inference batcher size: 93. Learner queue size: 64. Other stats: (train_seconds = 1.5972e+04, step = 50114560, mean_episode_return = 25.732, mean_episode_step = 2293.2, total_loss = -54.942, pg_loss = -56.875, baseline_loss = 15.676, entropy_loss = -13.743, learner_queue_size = 64, _tick = 7667, _time = 1.6548e+09)
[2022-06-09 18:06:54,214][root][INFO] - Step 50129920 @ 3069.5 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 1.5977e+04, step = 50129920, mean_episode_return = None, mean_episode_step = 1986.0, total_loss = 252.09, pg_loss = 230.23, baseline_loss = 35.716, entropy_loss = -13.853, learner_queue_size = 64, _tick = 7669, _time = 1.6548e+09)
[2022-06-09 18:06:59,218][root][INFO] - Step 50145280 @ 3069.6 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 1.5982e+04, step = 50145280, mean_episode_return = 38.341, mean_episode_step = 2021.9, total_loss = -82.637, pg_loss = -80.284, baseline_loss = 11.653, entropy_loss = -14.006, learner_queue_size = 64, _tick = 7672, _time = 1.6548e+09)
[2022-06-09 18:07:04,222][root][INFO] - Step 50160640 @ 3069.5 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 1.5987e+04, step = 50160640, mean_episode_return = 25.525, mean_episode_step = 2275.7, total_loss = 195.02, pg_loss = 171.21, baseline_loss = 38.081, entropy_loss = -14.265, learner_queue_size = 64, _tick = 7674, _time = 1.6548e+09)
[2022-06-09 18:07:09,226][root][INFO] - Step 50176000 @ 3069.5 SPS. Inference batcher size: 75. Learner queue size: 64. Other stats: (train_seconds = 1.5992e+04, step = 50176000, mean_episode_return = 10.1, mean_episode_step = 2194.7, total_loss = 99.533, pg_loss = 81.038, baseline_loss = 32.534, entropy_loss = -14.04, learner_queue_size = 64, _tick = 7676, _time = 1.6548e+09)
[2022-06-09 18:07:14,230][root][INFO] - Step 50191360 @ 3069.5 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 1.5997e+04, step = 50191360, mean_episode_return = 39.326, mean_episode_step = 1807.7, total_loss = 434.46, pg_loss = 373.04, baseline_loss = 75.423, entropy_loss = -14.007, learner_queue_size = 64, _tick = 7679, _time = 1.6548e+09)
[2022-06-09 18:07:19,234][root][INFO] - Step 50206720 @ 3069.6 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 1.6002e+04, step = 50206720, mean_episode_return = 76.449, mean_episode_step = 1827.7, total_loss = 2.9393, pg_loss = -9.4251, baseline_loss = 26.6, entropy_loss = -14.236, learner_queue_size = 64, _tick = 7681, _time = 1.6548e+09)
[2022-06-09 18:07:24,238][root][INFO] - Step 50222080 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.6007e+04, step = 50222080, mean_episode_return = 9.7297, mean_episode_step = 1911.1, total_loss = -74.247, pg_loss = -72.349, baseline_loss = 12.224, entropy_loss = -14.122, learner_queue_size = 64, _tick = 7682, _time = 1.6548e+09)
[2022-06-09 18:07:29,242][root][INFO] - Step 50237440 @ 3069.6 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.6012e+04, step = 50237440, mean_episode_return = 1.01, mean_episode_step = 1746.8, total_loss = 7.7864, pg_loss = 1.4243, baseline_loss = 20.548, entropy_loss = -14.186, learner_queue_size = 64, _tick = 7684, _time = 1.6548e+09)
[2022-06-09 18:07:34,246][root][INFO] - Step 50252800 @ 3069.5 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 1.6017e+04, step = 50252800, mean_episode_return = 64.423, mean_episode_step = 2089.8, total_loss = 224.97, pg_loss = 197.28, baseline_loss = 42.0, entropy_loss = -14.305, learner_queue_size = 64, _tick = 7687, _time = 1.6548e+09)
[2022-06-09 18:07:39,250][root][INFO] - Step 50268160 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.6022e+04, step = 50268160, mean_episode_return = 13.29, mean_episode_step = 1809.7, total_loss = 343.37, pg_loss = 296.89, baseline_loss = 60.775, entropy_loss = -14.298, learner_queue_size = 64, _tick = 7690, _time = 1.6548e+09)
[2022-06-09 18:07:44,254][root][INFO] - Step 50288640 @ 4092.8 SPS. Inference batcher size: 86. Learner queue size: 64. Other stats: (train_seconds = 1.6027e+04, step = 50288640, mean_episode_return = 3.4529, mean_episode_step = 1936.0, total_loss = 2.6576, pg_loss = -8.4766, baseline_loss = 25.15, entropy_loss = -14.015, learner_queue_size = 64, _tick = 7693, _time = 1.6548e+09)
[2022-06-09 18:07:49,258][root][INFO] - Step 50304000 @ 3069.5 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 1.6032e+04, step = 50304000, mean_episode_return = 93.479, mean_episode_step = 1651.8, total_loss = 391.53, pg_loss = 344.2, baseline_loss = 61.472, entropy_loss = -14.145, learner_queue_size = 64, _tick = 7696, _time = 1.6548e+09)
[2022-06-09 18:07:54,262][root][INFO] - Step 50319360 @ 3069.6 SPS. Inference batcher size: 71. Learner queue size: 64. Other stats: (train_seconds = 1.6037e+04, step = 50319360, mean_episode_return = 85.303, mean_episode_step = 1878.4, total_loss = 136.56, pg_loss = 108.38, baseline_loss = 42.204, entropy_loss = -14.023, learner_queue_size = 64, _tick = 7699, _time = 1.6548e+09)
[2022-06-09 18:07:59,266][root][INFO] - Step 50334720 @ 3069.4 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 1.6042e+04, step = 50334720, mean_episode_return = 39.02, mean_episode_step = 1782.0, total_loss = -50.402, pg_loss = -68.696, baseline_loss = 32.379, entropy_loss = -14.085, learner_queue_size = 64, _tick = 7702, _time = 1.6548e+09)
[2022-06-09 18:08:04,270][root][INFO] - Step 50350080 @ 3069.6 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 1.6047e+04, step = 50350080, mean_episode_return = 204.06, mean_episode_step = 2027.5, total_loss = -129.59, pg_loss = -127.67, baseline_loss = 12.019, entropy_loss = -13.931, learner_queue_size = 64, _tick = 7705, _time = 1.6548e+09)
[2022-06-09 18:08:09,274][root][INFO] - Step 50365440 @ 3069.6 SPS. Inference batcher size: 2. Learner queue size: 64. Other stats: (train_seconds = 1.6052e+04, step = 50365440, mean_episode_return = 15.5, mean_episode_step = 1973.7, total_loss = 319.55, pg_loss = 268.05, baseline_loss = 65.338, entropy_loss = -13.837, learner_queue_size = 64, _tick = 7708, _time = 1.6548e+09)
[2022-06-09 18:08:14,278][root][INFO] - Step 50380800 @ 3069.5 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.6057e+04, step = 50380800, mean_episode_return = 68.695, mean_episode_step = 1859.7, total_loss = -67.687, pg_loss = -94.023, baseline_loss = 40.028, entropy_loss = -13.693, learner_queue_size = 64, _tick = 7711, _time = 1.6548e+09)
[2022-06-09 18:08:19,282][root][INFO] - Step 50396160 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.6062e+04, step = 50396160, mean_episode_return = 88.323, mean_episode_step = 1972.3, total_loss = -116.84, pg_loss = -140.8, baseline_loss = 37.482, entropy_loss = -13.524, learner_queue_size = 64, _tick = 7714, _time = 1.6548e+09)
[2022-06-09 18:08:24,286][root][INFO] - Step 50411520 @ 3069.6 SPS. Inference batcher size: 2. Learner queue size: 64. Other stats: (train_seconds = 1.6067e+04, step = 50411520, mean_episode_return = 66.529, mean_episode_step = 1476.3, total_loss = 459.14, pg_loss = 367.13, baseline_loss = 105.63, entropy_loss = -13.623, learner_queue_size = 64, _tick = 7717, _time = 1.6548e+09)
[2022-06-09 18:08:29,290][root][INFO] - Step 50426880 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.6072e+04, step = 50426880, mean_episode_return = -5.1504, mean_episode_step = 1729.1, total_loss = -332.99, pg_loss = -323.3, baseline_loss = 3.9013, entropy_loss = -13.596, learner_queue_size = 64, _tick = 7720, _time = 1.6548e+09)
[2022-06-09 18:08:34,294][root][INFO] - Step 50442240 @ 3069.6 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.6077e+04, step = 50442240, mean_episode_return = 95.848, mean_episode_step = 1749.1, total_loss = 196.56, pg_loss = 161.47, baseline_loss = 48.797, entropy_loss = -13.707, learner_queue_size = 64, _tick = 7723, _time = 1.6548e+09)
[2022-06-09 18:08:39,298][root][INFO] - Step 50462720 @ 4092.6 SPS. Inference batcher size: 71. Learner queue size: 64. Other stats: (train_seconds = 1.6082e+04, step = 50462720, mean_episode_return = 52.597, mean_episode_step = 1934.8, total_loss = -250.87, pg_loss = -258.13, baseline_loss = 20.827, entropy_loss = -13.574, learner_queue_size = 64, _tick = 7724, _time = 1.6548e+09)
[2022-06-09 18:08:44,302][root][INFO] - Step 50478080 @ 3069.6 SPS. Inference batcher size: 95. Learner queue size: 64. Other stats: (train_seconds = 1.6087e+04, step = 50478080, mean_episode_return = None, mean_episode_step = 2165.4, total_loss = -256.82, pg_loss = -245.19, baseline_loss = 1.9115, entropy_loss = -13.543, learner_queue_size = 64, _tick = 7726, _time = 1.6548e+09)
[2022-06-09 18:08:49,306][root][INFO] - Step 50493440 @ 3069.5 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 1.6092e+04, step = 50493440, mean_episode_return = 42.626, mean_episode_step = 1934.7, total_loss = 194.59, pg_loss = 148.97, baseline_loss = 59.264, entropy_loss = -13.641, learner_queue_size = 64, _tick = 7728, _time = 1.6548e+09)
[2022-06-09 18:08:54,310][root][INFO] - Step 50508800 @ 3069.6 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 1.6097e+04, step = 50508800, mean_episode_return = None, mean_episode_step = 1860.8, total_loss = 81.945, pg_loss = 57.554, baseline_loss = 38.134, entropy_loss = -13.743, learner_queue_size = 64, _tick = 7730, _time = 1.6548e+09)
[2022-06-09 18:08:59,314][root][INFO] - Step 50524160 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.6102e+04, step = 50524160, mean_episode_return = 47.169, mean_episode_step = 2143.6, total_loss = 117.43, pg_loss = 82.434, baseline_loss = 48.74, entropy_loss = -13.744, learner_queue_size = 64, _tick = 7732, _time = 1.6548e+09)
[2022-06-09 18:09:04,318][root][INFO] - Step 50539520 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.6107e+04, step = 50539520, mean_episode_return = None, mean_episode_step = 2089.1, total_loss = -70.187, pg_loss = -72.346, baseline_loss = 15.92, entropy_loss = -13.762, learner_queue_size = 64, _tick = 7733, _time = 1.6548e+09)
[2022-06-09 18:09:09,322][root][INFO] - Step 50554880 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.6112e+04, step = 50554880, mean_episode_return = 57.381, mean_episode_step = 1911.7, total_loss = 194.49, pg_loss = 155.14, baseline_loss = 53.017, entropy_loss = -13.666, learner_queue_size = 64, _tick = 7735, _time = 1.6548e+09)
[2022-06-09 18:09:14,326][root][INFO] - Step 50570240 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.6117e+04, step = 50570240, mean_episode_return = 78.074, mean_episode_step = 2240.0, total_loss = -192.99, pg_loss = -203.55, baseline_loss = 24.308, entropy_loss = -13.741, learner_queue_size = 64, _tick = 7736, _time = 1.6548e+09)
[2022-06-09 18:09:19,330][root][INFO] - Step 50585600 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.6122e+04, step = 50585600, mean_episode_return = -40.289, mean_episode_step = 1941.5, total_loss = 182.21, pg_loss = 143.41, baseline_loss = 52.568, entropy_loss = -13.767, learner_queue_size = 64, _tick = 7739, _time = 1.6548e+09)
[2022-06-09 18:09:24,334][root][INFO] - Step 50600960 @ 3069.6 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.6127e+04, step = 50600960, mean_episode_return = 76.978, mean_episode_step = 2294.8, total_loss = -16.507, pg_loss = -40.493, baseline_loss = 37.954, entropy_loss = -13.969, learner_queue_size = 64, _tick = 7741, _time = 1.6548e+09)
[2022-06-09 18:09:29,338][root][INFO] - Step 50616320 @ 3069.5 SPS. Inference batcher size: 18. Learner queue size: 64. Other stats: (train_seconds = 1.6132e+04, step = 50616320, mean_episode_return = 48.927, mean_episode_step = 2166.7, total_loss = -155.02, pg_loss = -154.98, baseline_loss = 14.095, entropy_loss = -14.134, learner_queue_size = 64, _tick = 7744, _time = 1.6548e+09)
[2022-06-09 18:09:34,342][root][INFO] - Step 50631680 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.6137e+04, step = 50631680, mean_episode_return = 12.73, mean_episode_step = 1950.9, total_loss = 232.26, pg_loss = 195.06, baseline_loss = 51.462, entropy_loss = -14.267, learner_queue_size = 64, _tick = 7747, _time = 1.6548e+09)
[2022-06-09 18:09:39,348][root][INFO] - Step 50647040 @ 3068.3 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.6142e+04, step = 50647040, mean_episode_return = 26.89, mean_episode_step = 2166.8, total_loss = 13.0, pg_loss = -4.1301, baseline_loss = 31.353, entropy_loss = -14.223, learner_queue_size = 64, _tick = 7750, _time = 1.6548e+09)
[2022-06-09 18:09:44,354][root][INFO] - Step 50662400 @ 3068.4 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.6147e+04, step = 50662400, mean_episode_return = 45.817, mean_episode_step = 2019.7, total_loss = -60.48, pg_loss = -113.78, baseline_loss = 67.464, entropy_loss = -14.162, learner_queue_size = 64, _tick = 7753, _time = 1.6548e+09)
[2022-06-09 18:09:49,358][root][INFO] - Step 50682880 @ 4092.7 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.6152e+04, step = 50682880, mean_episode_return = None, mean_episode_step = 2117.7, total_loss = -87.98, pg_loss = -96.923, baseline_loss = 23.082, entropy_loss = -14.139, learner_queue_size = 64, _tick = 7756, _time = 1.6548e+09)
[2022-06-09 18:09:54,362][root][INFO] - Step 50698240 @ 3069.5 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 1.6157e+04, step = 50698240, mean_episode_return = 21.44, mean_episode_step = 1845.7, total_loss = -4.5353, pg_loss = -14.116, baseline_loss = 23.725, entropy_loss = -14.144, learner_queue_size = 64, _tick = 7759, _time = 1.6548e+09)
[2022-06-09 18:09:59,366][root][INFO] - Step 50713600 @ 3069.6 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 1.6162e+04, step = 50713600, mean_episode_return = 73.231, mean_episode_step = 2186.8, total_loss = -34.491, pg_loss = -41.201, baseline_loss = 20.705, entropy_loss = -13.995, learner_queue_size = 64, _tick = 7762, _time = 1.6548e+09)
[2022-06-09 18:10:04,370][root][INFO] - Step 50728960 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.6167e+04, step = 50728960, mean_episode_return = 87.974, mean_episode_step = 2047.1, total_loss = -59.68, pg_loss = -69.663, baseline_loss = 23.869, entropy_loss = -13.886, learner_queue_size = 64, _tick = 7765, _time = 1.6548e+09)
[2022-06-09 18:10:09,374][root][INFO] - Step 50744320 @ 3069.6 SPS. Inference batcher size: 80. Learner queue size: 64. Other stats: (train_seconds = 1.6172e+04, step = 50744320, mean_episode_return = None, mean_episode_step = 1951.9, total_loss = -179.28, pg_loss = -175.84, baseline_loss = 10.578, entropy_loss = -14.02, learner_queue_size = 64, _tick = 7765, _time = 1.6548e+09)
[2022-06-09 18:10:14,378][root][INFO] - Step 50759680 @ 3069.5 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.6177e+04, step = 50759680, mean_episode_return = 46.158, mean_episode_step = 2020.8, total_loss = -142.2, pg_loss = -146.2, baseline_loss = 18.041, entropy_loss = -14.035, learner_queue_size = 64, _tick = 7768, _time = 1.6548e+09)
[2022-06-09 18:10:19,382][root][INFO] - Step 50775040 @ 3069.6 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.6182e+04, step = 50775040, mean_episode_return = 31.322, mean_episode_step = 1894.4, total_loss = -62.486, pg_loss = -74.632, baseline_loss = 26.206, entropy_loss = -14.06, learner_queue_size = 64, _tick = 7771, _time = 1.6548e+09)
[2022-06-09 18:10:24,386][root][INFO] - Step 50790400 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.6187e+04, step = 50790400, mean_episode_return = 31.231, mean_episode_step = 1925.0, total_loss = -153.65, pg_loss = -150.97, baseline_loss = 11.108, entropy_loss = -13.788, learner_queue_size = 64, _tick = 7774, _time = 1.6548e+09)
[2022-06-09 18:10:29,390][root][INFO] - Step 50805760 @ 3069.5 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.6192e+04, step = 50805760, mean_episode_return = 43.79, mean_episode_step = 1951.8, total_loss = -47.159, pg_loss = -77.359, baseline_loss = 44.119, entropy_loss = -13.919, learner_queue_size = 64, _tick = 7776, _time = 1.6548e+09)
[2022-06-09 18:10:34,396][root][INFO] - Step 50821120 @ 3068.1 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.6197e+04, step = 50821120, mean_episode_return = 134.58, mean_episode_step = 2015.0, total_loss = -133.5, pg_loss = -130.59, baseline_loss = 10.959, entropy_loss = -13.866, learner_queue_size = 64, _tick = 7779, _time = 1.6548e+09)
[2022-06-09 18:10:39,402][root][INFO] - Step 50836480 @ 3068.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.6202e+04, step = 50836480, mean_episode_return = 43.634, mean_episode_step = 2093.5, total_loss = 151.12, pg_loss = 116.16, baseline_loss = 48.849, entropy_loss = -13.897, learner_queue_size = 64, _tick = 7782, _time = 1.6548e+09)
[2022-06-09 18:10:44,406][root][INFO] - Step 50856960 @ 4092.7 SPS. Inference batcher size: 87. Learner queue size: 64. Other stats: (train_seconds = 1.6207e+04, step = 50856960, mean_episode_return = None, mean_episode_step = 1887.6, total_loss = -47.189, pg_loss = -53.903, baseline_loss = 20.719, entropy_loss = -14.005, learner_queue_size = 64, _tick = 7784, _time = 1.6548e+09)
[2022-06-09 18:10:49,410][root][INFO] - Step 50872320 @ 3069.5 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 1.6212e+04, step = 50872320, mean_episode_return = 44.951, mean_episode_step = 2018.3, total_loss = -50.702, pg_loss = -54.131, baseline_loss = 17.524, entropy_loss = -14.096, learner_queue_size = 64, _tick = 7787, _time = 1.6548e+09)
[2022-06-09 18:10:54,414][root][INFO] - Step 50887680 @ 3069.6 SPS. Inference batcher size: 86. Learner queue size: 64. Other stats: (train_seconds = 1.6217e+04, step = 50887680, mean_episode_return = None, mean_episode_step = 1789.5, total_loss = 33.161, pg_loss = 28.923, baseline_loss = 18.112, entropy_loss = -13.874, learner_queue_size = 64, _tick = 7789, _time = 1.6548e+09)
[2022-06-09 18:10:59,418][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 18:10:59,667][root][INFO] - Step 50903040 @ 3069.5 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1.6222e+04, step = 50903040, mean_episode_return = 10.055, mean_episode_step = 1702.1, total_loss = 471.04, pg_loss = 405.63, baseline_loss = 79.417, entropy_loss = -14.012, learner_queue_size = 64, _tick = 7792, _time = 1.6548e+09)
[2022-06-09 18:11:04,670][root][INFO] - Step 50918400 @ 2924.6 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 1.6228e+04, step = 50918400, mean_episode_return = -4.2383, mean_episode_step = 1860.0, total_loss = -43.892, pg_loss = -47.832, baseline_loss = 17.913, entropy_loss = -13.973, learner_queue_size = 64, _tick = 7795, _time = 1.6548e+09)
[2022-06-09 18:11:09,674][root][INFO] - Step 50933760 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.6233e+04, step = 50933760, mean_episode_return = 44.865, mean_episode_step = 2078.4, total_loss = -120.9, pg_loss = -123.75, baseline_loss = 16.98, entropy_loss = -14.136, learner_queue_size = 64, _tick = 7797, _time = 1.6548e+09)
[2022-06-09 18:11:14,680][root][INFO] - Step 50949120 @ 3068.3 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.6238e+04, step = 50949120, mean_episode_return = 47.935, mean_episode_step = 2046.7, total_loss = -134.1, pg_loss = -131.35, baseline_loss = 11.261, entropy_loss = -14.021, learner_queue_size = 64, _tick = 7800, _time = 1.6548e+09)
[2022-06-09 18:11:19,686][root][INFO] - Step 50964480 @ 3068.2 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.6243e+04, step = 50964480, mean_episode_return = 105.89, mean_episode_step = 1992.4, total_loss = 530.17, pg_loss = 262.58, baseline_loss = 281.79, entropy_loss = -14.2, learner_queue_size = 64, _tick = 7803, _time = 1.6548e+09)
[2022-06-09 18:11:24,690][root][INFO] - Step 50979840 @ 3069.6 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.6248e+04, step = 50979840, mean_episode_return = 47.397, mean_episode_step = 2196.3, total_loss = 266.7, pg_loss = 214.24, baseline_loss = 66.656, entropy_loss = -14.191, learner_queue_size = 64, _tick = 7806, _time = 1.6548e+09)
[2022-06-09 18:11:29,694][root][INFO] - Step 51000320 @ 4092.8 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 1.6253e+04, step = 51000320, mean_episode_return = None, mean_episode_step = 1813.7, total_loss = -25.51, pg_loss = -20.985, baseline_loss = 9.5645, entropy_loss = -14.09, learner_queue_size = 64, _tick = 7809, _time = 1.6548e+09)
[2022-06-09 18:11:34,698][root][INFO] - Step 51015680 @ 3069.5 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 1.6258e+04, step = 51015680, mean_episode_return = 42.95, mean_episode_step = 2001.9, total_loss = 30.239, pg_loss = 19.678, baseline_loss = 24.861, entropy_loss = -14.301, learner_queue_size = 64, _tick = 7812, _time = 1.6548e+09)
[2022-06-09 18:11:39,702][root][INFO] - Step 51031040 @ 3069.5 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 1.6263e+04, step = 51031040, mean_episode_return = 43.231, mean_episode_step = 1856.5, total_loss = -71.199, pg_loss = -91.887, baseline_loss = 34.932, entropy_loss = -14.243, learner_queue_size = 64, _tick = 7814, _time = 1.6548e+09)
[2022-06-09 18:11:44,706][root][INFO] - Step 51046400 @ 3069.5 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 1.6268e+04, step = 51046400, mean_episode_return = 70.219, mean_episode_step = 2130.4, total_loss = 113.9, pg_loss = 95.779, baseline_loss = 32.513, entropy_loss = -14.393, learner_queue_size = 64, _tick = 7816, _time = 1.6548e+09)
[2022-06-09 18:11:49,710][root][INFO] - Step 51061760 @ 3069.5 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 1.6273e+04, step = 51061760, mean_episode_return = 84.402, mean_episode_step = 1985.5, total_loss = 338.87, pg_loss = 287.57, baseline_loss = 65.584, entropy_loss = -14.281, learner_queue_size = 64, _tick = 7819, _time = 1.6548e+09)
[2022-06-09 18:11:54,714][root][INFO] - Step 51077120 @ 3069.7 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.6278e+04, step = 51077120, mean_episode_return = 23.66, mean_episode_step = 1957.4, total_loss = -185.41, pg_loss = -180.76, baseline_loss = 9.6367, entropy_loss = -14.285, learner_queue_size = 64, _tick = 7822, _time = 1.6548e+09)
[2022-06-09 18:11:59,718][root][INFO] - Step 51092480 @ 3069.5 SPS. Inference batcher size: 14. Learner queue size: 64. Other stats: (train_seconds = 1.6283e+04, step = 51092480, mean_episode_return = 54.315, mean_episode_step = 2042.8, total_loss = -269.91, pg_loss = -273.09, baseline_loss = 17.442, entropy_loss = -14.263, learner_queue_size = 64, _tick = 7825, _time = 1.6548e+09)
[2022-06-09 18:12:04,723][root][INFO] - Step 51107840 @ 3069.2 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.6288e+04, step = 51107840, mean_episode_return = 70.249, mean_episode_step = 2054.3, total_loss = -83.691, pg_loss = -93.138, baseline_loss = 23.58, entropy_loss = -14.134, learner_queue_size = 64, _tick = 7828, _time = 1.6548e+09)
[2022-06-09 18:12:09,729][root][INFO] - Step 51123200 @ 3068.3 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.6293e+04, step = 51123200, mean_episode_return = None, mean_episode_step = 1892.2, total_loss = -89.344, pg_loss = -86.464, baseline_loss = 11.308, entropy_loss = -14.187, learner_queue_size = 64, _tick = 7830, _time = 1.6548e+09)
[2022-06-09 18:12:14,735][root][INFO] - Step 51143680 @ 4090.8 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 1.6298e+04, step = 51143680, mean_episode_return = 45.268, mean_episode_step = 1793.7, total_loss = 225.98, pg_loss = 182.83, baseline_loss = 57.521, entropy_loss = -14.376, learner_queue_size = 64, _tick = 7833, _time = 1.6548e+09)
[2022-06-09 18:12:19,738][root][INFO] - Step 51159040 @ 3070.1 SPS. Inference batcher size: 78. Learner queue size: 64. Other stats: (train_seconds = 1.6303e+04, step = 51159040, mean_episode_return = None, mean_episode_step = 2226.6, total_loss = 246.62, pg_loss = 167.08, baseline_loss = 93.88, entropy_loss = -14.347, learner_queue_size = 64, _tick = 7835, _time = 1.6548e+09)
[2022-06-09 18:12:24,742][root][INFO] - Step 51174400 @ 3069.6 SPS. Inference batcher size: 78. Learner queue size: 64. Other stats: (train_seconds = 1.6308e+04, step = 51174400, mean_episode_return = 33.087, mean_episode_step = 1865.5, total_loss = 121.16, pg_loss = 88.651, baseline_loss = 46.882, entropy_loss = -14.368, learner_queue_size = 64, _tick = 7838, _time = 1.6548e+09)
[2022-06-09 18:12:29,746][root][INFO] - Step 51189760 @ 3069.5 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 1.6313e+04, step = 51189760, mean_episode_return = 35.095, mean_episode_step = 1851.7, total_loss = 76.69, pg_loss = 54.677, baseline_loss = 36.628, entropy_loss = -14.615, learner_queue_size = 64, _tick = 7841, _time = 1.6548e+09)
[2022-06-09 18:12:34,750][root][INFO] - Step 51205120 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.6318e+04, step = 51205120, mean_episode_return = 78.372, mean_episode_step = 2119.3, total_loss = 123.89, pg_loss = 90.532, baseline_loss = 48.013, entropy_loss = -14.659, learner_queue_size = 64, _tick = 7844, _time = 1.6548e+09)
[2022-06-09 18:12:39,756][root][INFO] - Step 51220480 @ 3068.3 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 1.6323e+04, step = 51220480, mean_episode_return = 57.511, mean_episode_step = 2002.3, total_loss = -108.55, pg_loss = -109.76, baseline_loss = 15.956, entropy_loss = -14.749, learner_queue_size = 64, _tick = 7847, _time = 1.6548e+09)
[2022-06-09 18:12:44,762][root][INFO] - Step 51235840 @ 3068.4 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 1.6328e+04, step = 51235840, mean_episode_return = 57.133, mean_episode_step = 1983.5, total_loss = 112.39, pg_loss = 90.344, baseline_loss = 36.802, entropy_loss = -14.753, learner_queue_size = 64, _tick = 7850, _time = 1.6548e+09)
[2022-06-09 18:12:49,766][root][INFO] - Step 51251200 @ 3069.4 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 1.6333e+04, step = 51251200, mean_episode_return = 20.99, mean_episode_step = 2004.7, total_loss = -106.57, pg_loss = -109.63, baseline_loss = 17.707, entropy_loss = -14.648, learner_queue_size = 64, _tick = 7853, _time = 1.6548e+09)
[2022-06-09 18:12:54,770][root][INFO] - Step 51271680 @ 4092.9 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.6338e+04, step = 51271680, mean_episode_return = 27.659, mean_episode_step = 2078.3, total_loss = 109.77, pg_loss = 92.268, baseline_loss = 32.162, entropy_loss = -14.663, learner_queue_size = 64, _tick = 7857, _time = 1.6548e+09)
[2022-06-09 18:12:59,774][root][INFO] - Step 51287040 @ 3069.5 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 1.6343e+04, step = 51287040, mean_episode_return = 63.66, mean_episode_step = 2359.7, total_loss = -165.88, pg_loss = -175.46, baseline_loss = 24.281, entropy_loss = -14.706, learner_queue_size = 64, _tick = 7860, _time = 1.6548e+09)
[2022-06-09 18:13:04,778][root][INFO] - Step 51302400 @ 3069.6 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 1.6348e+04, step = 51302400, mean_episode_return = 69.847, mean_episode_step = 2044.2, total_loss = 67.081, pg_loss = 43.111, baseline_loss = 38.451, entropy_loss = -14.482, learner_queue_size = 64, _tick = 7863, _time = 1.6548e+09)
[2022-06-09 18:13:09,782][root][INFO] - Step 51317760 @ 3069.5 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.6353e+04, step = 51317760, mean_episode_return = 30.88, mean_episode_step = 2239.4, total_loss = 21.152, pg_loss = -6.4309, baseline_loss = 42.244, entropy_loss = -14.661, learner_queue_size = 64, _tick = 7866, _time = 1.6548e+09)
[2022-06-09 18:13:14,786][root][INFO] - Step 51333120 @ 3069.4 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 1.6358e+04, step = 51333120, mean_episode_return = 45.097, mean_episode_step = 1827.8, total_loss = 126.27, pg_loss = 76.114, baseline_loss = 64.892, entropy_loss = -14.739, learner_queue_size = 64, _tick = 7869, _time = 1.6548e+09)
[2022-06-09 18:13:19,790][root][INFO] - Step 51348480 @ 3069.5 SPS. Inference batcher size: 10. Learner queue size: 64. Other stats: (train_seconds = 1.6363e+04, step = 51348480, mean_episode_return = 110.53, mean_episode_step = 2063.7, total_loss = 90.406, pg_loss = 77.682, baseline_loss = 27.381, entropy_loss = -14.657, learner_queue_size = 64, _tick = 7872, _time = 1.6548e+09)
[2022-06-09 18:13:24,794][root][INFO] - Step 51363840 @ 3069.7 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 1.6368e+04, step = 51363840, mean_episode_return = 17.46, mean_episode_step = 1868.1, total_loss = 116.98, pg_loss = 89.884, baseline_loss = 41.949, entropy_loss = -14.857, learner_queue_size = 64, _tick = 7875, _time = 1.6548e+09)
[2022-06-09 18:13:29,798][root][INFO] - Step 51379200 @ 3069.6 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.6373e+04, step = 51379200, mean_episode_return = 40.183, mean_episode_step = 2212.9, total_loss = 159.32, pg_loss = 116.69, baseline_loss = 57.439, entropy_loss = -14.806, learner_queue_size = 64, _tick = 7877, _time = 1.6548e+09)
[2022-06-09 18:13:34,802][root][INFO] - Step 51394560 @ 3069.5 SPS. Inference batcher size: 4. Learner queue size: 64. Other stats: (train_seconds = 1.6378e+04, step = 51394560, mean_episode_return = 46.636, mean_episode_step = 2070.0, total_loss = 13.726, pg_loss = -2.2122, baseline_loss = 30.669, entropy_loss = -14.731, learner_queue_size = 64, _tick = 7880, _time = 1.6548e+09)
[2022-06-09 18:13:39,806][root][INFO] - Step 51409920 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.6383e+04, step = 51409920, mean_episode_return = 36.003, mean_episode_step = 1874.6, total_loss = 67.384, pg_loss = 30.409, baseline_loss = 51.658, entropy_loss = -14.683, learner_queue_size = 64, _tick = 7882, _time = 1.6548e+09)
[2022-06-09 18:13:44,810][root][INFO] - Step 51430400 @ 4092.7 SPS. Inference batcher size: 80. Learner queue size: 64. Other stats: (train_seconds = 1.6388e+04, step = 51430400, mean_episode_return = None, mean_episode_step = 1750.5, total_loss = -39.003, pg_loss = -43.665, baseline_loss = 19.106, entropy_loss = -14.444, learner_queue_size = 64, _tick = 7885, _time = 1.6548e+09)
[2022-06-09 18:13:49,816][root][INFO] - Step 51445760 @ 3068.2 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.6393e+04, step = 51445760, mean_episode_return = 50.001, mean_episode_step = 1917.2, total_loss = -188.1, pg_loss = -189.81, baseline_loss = 16.202, entropy_loss = -14.494, learner_queue_size = 64, _tick = 7888, _time = 1.6548e+09)
[2022-06-09 18:13:54,822][root][INFO] - Step 51461120 @ 3068.4 SPS. Inference batcher size: 78. Learner queue size: 64. Other stats: (train_seconds = 1.6398e+04, step = 51461120, mean_episode_return = 94.925, mean_episode_step = 2117.8, total_loss = -53.407, pg_loss = -68.132, baseline_loss = 29.247, entropy_loss = -14.523, learner_queue_size = 64, _tick = 7890, _time = 1.6548e+09)
[2022-06-09 18:13:59,826][root][INFO] - Step 51476480 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.6403e+04, step = 51476480, mean_episode_return = 30.62, mean_episode_step = 2202.8, total_loss = -55.721, pg_loss = -66.119, baseline_loss = 24.833, entropy_loss = -14.434, learner_queue_size = 64, _tick = 7893, _time = 1.6548e+09)
[2022-06-09 18:14:04,830][root][INFO] - Step 51491840 @ 3069.5 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 1.6408e+04, step = 51491840, mean_episode_return = 60.815, mean_episode_step = 1795.9, total_loss = -254.0, pg_loss = -268.46, baseline_loss = 28.781, entropy_loss = -14.319, learner_queue_size = 64, _tick = 7896, _time = 1.6548e+09)
[2022-06-09 18:14:09,834][root][INFO] - Step 51507200 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.6413e+04, step = 51507200, mean_episode_return = 138.53, mean_episode_step = 1830.6, total_loss = -96.82, pg_loss = -101.65, baseline_loss = 19.283, entropy_loss = -14.453, learner_queue_size = 64, _tick = 7899, _time = 1.6548e+09)
[2022-06-09 18:14:14,838][root][INFO] - Step 51522560 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.6418e+04, step = 51522560, mean_episode_return = 65.162, mean_episode_step = 2155.2, total_loss = 93.841, pg_loss = 65.184, baseline_loss = 43.083, entropy_loss = -14.425, learner_queue_size = 64, _tick = 7901, _time = 1.6548e+09)
[2022-06-09 18:14:19,842][root][INFO] - Step 51537920 @ 3069.6 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 1.6423e+04, step = 51537920, mean_episode_return = None, mean_episode_step = 2055.8, total_loss = 188.08, pg_loss = 171.34, baseline_loss = 31.169, entropy_loss = -14.433, learner_queue_size = 64, _tick = 7902, _time = 1.6548e+09)
[2022-06-09 18:14:24,846][root][INFO] - Step 51553280 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.6428e+04, step = 51553280, mean_episode_return = 49.581, mean_episode_step = 1808.5, total_loss = -222.09, pg_loss = -220.65, baseline_loss = 12.912, entropy_loss = -14.35, learner_queue_size = 64, _tick = 7905, _time = 1.6548e+09)
[2022-06-09 18:14:29,850][root][INFO] - Step 51573760 @ 4092.7 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 1.6433e+04, step = 51573760, mean_episode_return = 82.583, mean_episode_step = 2143.7, total_loss = 220.92, pg_loss = 186.56, baseline_loss = 48.713, entropy_loss = -14.349, learner_queue_size = 64, _tick = 7908, _time = 1.6548e+09)
[2022-06-09 18:14:34,854][root][INFO] - Step 51589120 @ 3069.5 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 1.6438e+04, step = 51589120, mean_episode_return = None, mean_episode_step = 2038.5, total_loss = 112.53, pg_loss = 102.87, baseline_loss = 23.865, entropy_loss = -14.212, learner_queue_size = 64, _tick = 7909, _time = 1.6548e+09)
[2022-06-09 18:14:39,858][root][INFO] - Step 51604480 @ 3069.5 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 1.6443e+04, step = 51604480, mean_episode_return = 35.83, mean_episode_step = 2350.1, total_loss = -134.88, pg_loss = -140.85, baseline_loss = 20.298, entropy_loss = -14.325, learner_queue_size = 64, _tick = 7912, _time = 1.6548e+09)
[2022-06-09 18:14:44,862][root][INFO] - Step 51619840 @ 3069.5 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 1.6448e+04, step = 51619840, mean_episode_return = 44.434, mean_episode_step = 2084.8, total_loss = 87.885, pg_loss = 59.165, baseline_loss = 43.114, entropy_loss = -14.394, learner_queue_size = 64, _tick = 7914, _time = 1.6548e+09)
[2022-06-09 18:14:49,866][root][INFO] - Step 51635200 @ 3069.6 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 1.6453e+04, step = 51635200, mean_episode_return = 24.282, mean_episode_step = 2029.7, total_loss = -268.21, pg_loss = -262.02, baseline_loss = 8.2222, entropy_loss = -14.418, learner_queue_size = 64, _tick = 7916, _time = 1.6548e+09)
[2022-06-09 18:14:54,870][root][INFO] - Step 51650560 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.6458e+04, step = 51650560, mean_episode_return = None, mean_episode_step = 2029.6, total_loss = -126.12, pg_loss = -127.53, baseline_loss = 15.853, entropy_loss = -14.448, learner_queue_size = 64, _tick = 7918, _time = 1.6548e+09)
[2022-06-09 18:14:59,874][root][INFO] - Step 51665920 @ 3069.6 SPS. Inference batcher size: 11. Learner queue size: 64. Other stats: (train_seconds = 1.6463e+04, step = 51665920, mean_episode_return = 82.853, mean_episode_step = 1929.0, total_loss = -315.28, pg_loss = -307.04, baseline_loss = 6.2794, entropy_loss = -14.518, learner_queue_size = 64, _tick = 7921, _time = 1.6548e+09)
[2022-06-09 18:15:04,878][root][INFO] - Step 51681280 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.6468e+04, step = 51681280, mean_episode_return = 61.865, mean_episode_step = 2222.1, total_loss = 459.2, pg_loss = 409.24, baseline_loss = 64.554, entropy_loss = -14.592, learner_queue_size = 64, _tick = 7924, _time = 1.6548e+09)
[2022-06-09 18:15:09,885][root][INFO] - Step 51696640 @ 3067.4 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.6473e+04, step = 51696640, mean_episode_return = 42.75, mean_episode_step = 2174.3, total_loss = 7.4773, pg_loss = -3.8005, baseline_loss = 26.059, entropy_loss = -14.781, learner_queue_size = 64, _tick = 7927, _time = 1.6548e+09)
[2022-06-09 18:15:14,892][root][INFO] - Step 51712000 @ 3067.9 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.6478e+04, step = 51712000, mean_episode_return = 82.564, mean_episode_step = 2301.6, total_loss = 69.312, pg_loss = 45.792, baseline_loss = 38.38, entropy_loss = -14.86, learner_queue_size = 64, _tick = 7930, _time = 1.6548e+09)
[2022-06-09 18:15:19,898][root][INFO] - Step 51732480 @ 4091.2 SPS. Inference batcher size: 84. Learner queue size: 64. Other stats: (train_seconds = 1.6483e+04, step = 51732480, mean_episode_return = 34.99, mean_episode_step = 2419.3, total_loss = -63.835, pg_loss = -70.989, baseline_loss = 22.232, entropy_loss = -15.079, learner_queue_size = 64, _tick = 7934, _time = 1.6548e+09)
[2022-06-09 18:15:24,902][root][INFO] - Step 51747840 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.6488e+04, step = 51747840, mean_episode_return = 40.1, mean_episode_step = 2316.7, total_loss = -60.741, pg_loss = -69.98, baseline_loss = 24.285, entropy_loss = -15.046, learner_queue_size = 64, _tick = 7936, _time = 1.6548e+09)
[2022-06-09 18:15:29,917][root][INFO] - Step 51763200 @ 3062.6 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 1.6493e+04, step = 51763200, mean_episode_return = 33.31, mean_episode_step = 2096.5, total_loss = 129.7, pg_loss = 108.66, baseline_loss = 36.178, entropy_loss = -15.138, learner_queue_size = 64, _tick = 7939, _time = 1.6548e+09)
[2022-06-09 18:15:34,922][root][INFO] - Step 51778560 @ 3069.0 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.6498e+04, step = 51778560, mean_episode_return = 65.096, mean_episode_step = 2095.5, total_loss = -209.34, pg_loss = -220.11, baseline_loss = 25.917, entropy_loss = -15.143, learner_queue_size = 64, _tick = 7942, _time = 1.6548e+09)
[2022-06-09 18:15:39,926][root][INFO] - Step 51793920 @ 3069.6 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.6503e+04, step = 51793920, mean_episode_return = 118.55, mean_episode_step = 1903.2, total_loss = 21.789, pg_loss = -1.7993, baseline_loss = 39.024, entropy_loss = -15.436, learner_queue_size = 64, _tick = 7945, _time = 1.6548e+09)
[2022-06-09 18:15:44,930][root][INFO] - Step 51809280 @ 3069.5 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 1.6508e+04, step = 51809280, mean_episode_return = 34.482, mean_episode_step = 1988.1, total_loss = -52.499, pg_loss = -71.165, baseline_loss = 34.048, entropy_loss = -15.382, learner_queue_size = 64, _tick = 7948, _time = 1.6548e+09)
[2022-06-09 18:15:49,934][root][INFO] - Step 51829760 @ 4092.8 SPS. Inference batcher size: 12. Learner queue size: 64. Other stats: (train_seconds = 1.6513e+04, step = 51829760, mean_episode_return = 54.852, mean_episode_step = 2415.4, total_loss = -37.243, pg_loss = -42.995, baseline_loss = 21.049, entropy_loss = -15.297, learner_queue_size = 64, _tick = 7951, _time = 1.6548e+09)
[2022-06-09 18:15:54,938][root][INFO] - Step 51845120 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.6518e+04, step = 51845120, mean_episode_return = 21.613, mean_episode_step = 2180.9, total_loss = -117.58, pg_loss = -122.84, baseline_loss = 20.689, entropy_loss = -15.424, learner_queue_size = 64, _tick = 7954, _time = 1.6548e+09)
[2022-06-09 18:15:59,942][root][INFO] - Step 51860480 @ 3069.6 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 1.6523e+04, step = 51860480, mean_episode_return = None, mean_episode_step = 2106.2, total_loss = -88.25, pg_loss = -85.157, baseline_loss = 12.386, entropy_loss = -15.479, learner_queue_size = 64, _tick = 7956, _time = 1.6548e+09)
[2022-06-09 18:16:04,946][root][INFO] - Step 51875840 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.6528e+04, step = 51875840, mean_episode_return = 47.469, mean_episode_step = 1709.4, total_loss = 139.33, pg_loss = 120.03, baseline_loss = 34.849, entropy_loss = -15.554, learner_queue_size = 64, _tick = 7959, _time = 1.6548e+09)
[2022-06-09 18:16:09,950][root][INFO] - Step 51891200 @ 3069.6 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.6533e+04, step = 51891200, mean_episode_return = 28.546, mean_episode_step = 1826.9, total_loss = -88.892, pg_loss = -95.184, baseline_loss = 21.59, entropy_loss = -15.298, learner_queue_size = 64, _tick = 7962, _time = 1.6548e+09)
[2022-06-09 18:16:14,954][root][INFO] - Step 51906560 @ 3069.5 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 1.6538e+04, step = 51906560, mean_episode_return = 69.904, mean_episode_step = 2045.2, total_loss = -33.082, pg_loss = -37.721, baseline_loss = 19.915, entropy_loss = -15.276, learner_queue_size = 64, _tick = 7965, _time = 1.6548e+09)
[2022-06-09 18:16:19,958][root][INFO] - Step 51921920 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.6543e+04, step = 51921920, mean_episode_return = 90.096, mean_episode_step = 1915.6, total_loss = 79.25, pg_loss = 57.647, baseline_loss = 37.026, entropy_loss = -15.423, learner_queue_size = 64, _tick = 7968, _time = 1.6548e+09)
[2022-06-09 18:16:24,962][root][INFO] - Step 51937280 @ 3069.6 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 1.6548e+04, step = 51937280, mean_episode_return = None, mean_episode_step = 2035.6, total_loss = 239.8, pg_loss = 210.96, baseline_loss = 44.246, entropy_loss = -15.407, learner_queue_size = 64, _tick = 7970, _time = 1.6548e+09)
[2022-06-09 18:16:29,966][root][INFO] - Step 51952640 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.6553e+04, step = 51952640, mean_episode_return = 109.84, mean_episode_step = 2032.0, total_loss = 190.71, pg_loss = 148.12, baseline_loss = 57.818, entropy_loss = -15.23, learner_queue_size = 64, _tick = 7973, _time = 1.6548e+09)
[2022-06-09 18:16:34,970][root][INFO] - Step 51968000 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.6558e+04, step = 51968000, mean_episode_return = 34.642, mean_episode_step = 1966.2, total_loss = 307.66, pg_loss = 255.73, baseline_loss = 67.002, entropy_loss = -15.069, learner_queue_size = 64, _tick = 7976, _time = 1.6548e+09)
[2022-06-09 18:16:39,974][root][INFO] - Step 51988480 @ 4092.6 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 1.6563e+04, step = 51988480, mean_episode_return = 32.929, mean_episode_step = 1680.7, total_loss = 464.2, pg_loss = 375.84, baseline_loss = 103.13, entropy_loss = -14.773, learner_queue_size = 64, _tick = 7980, _time = 1.6548e+09)
[2022-06-09 18:16:44,978][root][INFO] - Step 52003840 @ 3069.6 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 1.6568e+04, step = 52003840, mean_episode_return = 15.49, mean_episode_step = 2214.2, total_loss = 72.992, pg_loss = 51.432, baseline_loss = 36.238, entropy_loss = -14.677, learner_queue_size = 64, _tick = 7982, _time = 1.6548e+09)
[2022-06-09 18:16:49,982][root][INFO] - Step 52019200 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.6573e+04, step = 52019200, mean_episode_return = 26.982, mean_episode_step = 2111.3, total_loss = -105.0, pg_loss = -128.56, baseline_loss = 38.209, entropy_loss = -14.656, learner_queue_size = 64, _tick = 7984, _time = 1.6548e+09)
[2022-06-09 18:16:54,986][root][INFO] - Step 52034560 @ 3069.6 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 1.6578e+04, step = 52034560, mean_episode_return = 35.007, mean_episode_step = 1962.0, total_loss = -6.2638, pg_loss = -40.665, baseline_loss = 48.699, entropy_loss = -14.298, learner_queue_size = 64, _tick = 7987, _time = 1.6548e+09)
[2022-06-09 18:16:59,990][root][INFO] - Step 52049920 @ 3069.5 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 1.6583e+04, step = 52049920, mean_episode_return = 29.692, mean_episode_step = 1867.2, total_loss = 342.96, pg_loss = 282.32, baseline_loss = 75.057, entropy_loss = -14.417, learner_queue_size = 64, _tick = 7990, _time = 1.6548e+09)
[2022-06-09 18:17:04,994][root][INFO] - Step 52065280 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.6588e+04, step = 52065280, mean_episode_return = 51.587, mean_episode_step = 1880.4, total_loss = -136.69, pg_loss = -158.36, baseline_loss = 35.859, entropy_loss = -14.18, learner_queue_size = 64, _tick = 7992, _time = 1.6548e+09)
[2022-06-09 18:17:09,998][root][INFO] - Step 52080640 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.6593e+04, step = 52080640, mean_episode_return = 68.99, mean_episode_step = 1703.1, total_loss = 102.17, pg_loss = 64.136, baseline_loss = 52.089, entropy_loss = -14.06, learner_queue_size = 64, _tick = 7995, _time = 1.6548e+09)
[2022-06-09 18:17:15,002][root][INFO] - Step 52096000 @ 3069.5 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.6598e+04, step = 52096000, mean_episode_return = 81.922, mean_episode_step = 1861.2, total_loss = 35.88, pg_loss = 12.172, baseline_loss = 37.717, entropy_loss = -14.008, learner_queue_size = 64, _tick = 7998, _time = 1.6548e+09)
[2022-06-09 18:17:20,006][root][INFO] - Step 52111360 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.6603e+04, step = 52111360, mean_episode_return = 51.654, mean_episode_step = 1610.4, total_loss = -20.386, pg_loss = -48.083, baseline_loss = 41.642, entropy_loss = -13.945, learner_queue_size = 64, _tick = 8000, _time = 1.6548e+09)
[2022-06-09 18:17:25,010][root][INFO] - Step 52131840 @ 4092.8 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 1.6608e+04, step = 52131840, mean_episode_return = 40.623, mean_episode_step = 2032.6, total_loss = -167.31, pg_loss = -167.44, baseline_loss = 14.207, entropy_loss = -14.073, learner_queue_size = 64, _tick = 8003, _time = 1.6548e+09)
[2022-06-09 18:17:30,014][root][INFO] - Step 52147200 @ 3069.5 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 1.6613e+04, step = 52147200, mean_episode_return = -78.078, mean_episode_step = 1705.6, total_loss = 186.74, pg_loss = 149.09, baseline_loss = 51.703, entropy_loss = -14.046, learner_queue_size = 64, _tick = 8005, _time = 1.6548e+09)
[2022-06-09 18:17:35,018][root][INFO] - Step 52162560 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.6618e+04, step = 52162560, mean_episode_return = 72.113, mean_episode_step = 2151.0, total_loss = -245.92, pg_loss = -244.2, baseline_loss = 12.39, entropy_loss = -14.109, learner_queue_size = 64, _tick = 8008, _time = 1.6548e+09)
[2022-06-09 18:17:40,022][root][INFO] - Step 52177920 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.6623e+04, step = 52177920, mean_episode_return = 54.06, mean_episode_step = 1886.9, total_loss = 102.49, pg_loss = 79.141, baseline_loss = 37.536, entropy_loss = -14.191, learner_queue_size = 64, _tick = 8011, _time = 1.6548e+09)
[2022-06-09 18:17:45,026][root][INFO] - Step 52193280 @ 3069.6 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 1.6628e+04, step = 52193280, mean_episode_return = 86.826, mean_episode_step = 1825.1, total_loss = -135.93, pg_loss = -150.94, baseline_loss = 29.261, entropy_loss = -14.26, learner_queue_size = 64, _tick = 8014, _time = 1.6548e+09)
[2022-06-09 18:17:50,030][root][INFO] - Step 52208640 @ 3069.5 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 1.6633e+04, step = 52208640, mean_episode_return = 91.773, mean_episode_step = 1570.0, total_loss = -78.084, pg_loss = -87.858, baseline_loss = 24.133, entropy_loss = -14.359, learner_queue_size = 64, _tick = 8017, _time = 1.6548e+09)
[2022-06-09 18:17:55,034][root][INFO] - Step 52224000 @ 3069.6 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.6638e+04, step = 52224000, mean_episode_return = 61.36, mean_episode_step = 1881.0, total_loss = -181.83, pg_loss = -179.47, baseline_loss = 12.165, entropy_loss = -14.53, learner_queue_size = 64, _tick = 8019, _time = 1.6548e+09)
[2022-06-09 18:18:00,038][root][INFO] - Step 52244480 @ 4092.7 SPS. Inference batcher size: 104. Learner queue size: 64. Other stats: (train_seconds = 1.6643e+04, step = 52244480, mean_episode_return = 10.69, mean_episode_step = 1926.4, total_loss = 45.983, pg_loss = 23.214, baseline_loss = 37.318, entropy_loss = -14.549, learner_queue_size = 64, _tick = 8023, _time = 1.6548e+09)
[2022-06-09 18:18:05,042][root][INFO] - Step 52259840 @ 3069.6 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 1.6648e+04, step = 52259840, mean_episode_return = 24.031, mean_episode_step = 1701.7, total_loss = -261.11, pg_loss = -266.68, baseline_loss = 20.077, entropy_loss = -14.505, learner_queue_size = 64, _tick = 8024, _time = 1.6548e+09)
[2022-06-09 18:18:10,046][root][INFO] - Step 52275200 @ 3069.5 SPS. Inference batcher size: 67. Learner queue size: 64. Other stats: (train_seconds = 1.6653e+04, step = 52275200, mean_episode_return = None, mean_episode_step = 2068.6, total_loss = -68.144, pg_loss = -74.242, baseline_loss = 20.771, entropy_loss = -14.673, learner_queue_size = 64, _tick = 8025, _time = 1.6548e+09)
[2022-06-09 18:18:15,050][root][INFO] - Step 52290560 @ 3069.6 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.6658e+04, step = 52290560, mean_episode_return = 31.77, mean_episode_step = 2127.7, total_loss = -86.367, pg_loss = -88.775, baseline_loss = 17.055, entropy_loss = -14.648, learner_queue_size = 64, _tick = 8028, _time = 1.6548e+09)
[2022-06-09 18:18:20,054][root][INFO] - Step 52305920 @ 3069.5 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 1.6663e+04, step = 52305920, mean_episode_return = None, mean_episode_step = 1899.6, total_loss = 23.677, pg_loss = 14.279, baseline_loss = 24.011, entropy_loss = -14.613, learner_queue_size = 64, _tick = 8030, _time = 1.6548e+09)
[2022-06-09 18:18:25,058][root][INFO] - Step 52321280 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.6668e+04, step = 52321280, mean_episode_return = 149.79, mean_episode_step = 1970.8, total_loss = -11.304, pg_loss = -30.913, baseline_loss = 33.996, entropy_loss = -14.387, learner_queue_size = 64, _tick = 8033, _time = 1.6548e+09)
[2022-06-09 18:18:30,062][root][INFO] - Step 52336640 @ 3069.6 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.6673e+04, step = 52336640, mean_episode_return = None, mean_episode_step = 2115.1, total_loss = 65.016, pg_loss = 53.436, baseline_loss = 26.111, entropy_loss = -14.531, learner_queue_size = 64, _tick = 8035, _time = 1.6548e+09)
[2022-06-09 18:18:35,066][root][INFO] - Step 52352000 @ 3069.4 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.6678e+04, step = 52352000, mean_episode_return = 18.701, mean_episode_step = 1968.8, total_loss = -104.03, pg_loss = -111.58, baseline_loss = 22.154, entropy_loss = -14.606, learner_queue_size = 64, _tick = 8038, _time = 1.6548e+09)
[2022-06-09 18:18:40,070][root][INFO] - Step 52367360 @ 3069.4 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 1.6683e+04, step = 52367360, mean_episode_return = 35.296, mean_episode_step = 2048.1, total_loss = -36.647, pg_loss = -48.811, baseline_loss = 26.633, entropy_loss = -14.469, learner_queue_size = 64, _tick = 8041, _time = 1.6548e+09)
[2022-06-09 18:18:45,074][root][INFO] - Step 52382720 @ 3069.7 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 1.6688e+04, step = 52382720, mean_episode_return = 40.055, mean_episode_step = 1868.2, total_loss = 218.15, pg_loss = 181.24, baseline_loss = 51.608, entropy_loss = -14.705, learner_queue_size = 64, _tick = 8043, _time = 1.6548e+09)
[2022-06-09 18:18:50,080][root][INFO] - Step 52403200 @ 4091.1 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.6693e+04, step = 52403200, mean_episode_return = 40.836, mean_episode_step = 2087.6, total_loss = -204.76, pg_loss = -215.02, baseline_loss = 24.874, entropy_loss = -14.61, learner_queue_size = 64, _tick = 8047, _time = 1.6548e+09)
[2022-06-09 18:18:55,086][root][INFO] - Step 52418560 @ 3068.3 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.6698e+04, step = 52418560, mean_episode_return = -34.08, mean_episode_step = 2024.5, total_loss = 216.78, pg_loss = 176.34, baseline_loss = 54.989, entropy_loss = -14.554, learner_queue_size = 64, _tick = 8050, _time = 1.6548e+09)
[2022-06-09 18:19:00,090][root][INFO] - Step 52433920 @ 3069.5 SPS. Inference batcher size: 71. Learner queue size: 64. Other stats: (train_seconds = 1.6703e+04, step = 52433920, mean_episode_return = 27.74, mean_episode_step = 1865.4, total_loss = 226.69, pg_loss = 165.03, baseline_loss = 76.027, entropy_loss = -14.376, learner_queue_size = 64, _tick = 8053, _time = 1.6548e+09)
[2022-06-09 18:19:05,096][root][INFO] - Step 52449280 @ 3068.2 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1.6708e+04, step = 52449280, mean_episode_return = -2.6305, mean_episode_step = 1852.1, total_loss = -38.492, pg_loss = -50.83, baseline_loss = 26.593, entropy_loss = -14.255, learner_queue_size = 64, _tick = 8056, _time = 1.6548e+09)
[2022-06-09 18:19:10,102][root][INFO] - Step 52464640 @ 3068.5 SPS. Inference batcher size: 3. Learner queue size: 64. Other stats: (train_seconds = 1.6713e+04, step = 52464640, mean_episode_return = None, mean_episode_step = 2027.1, total_loss = -209.6, pg_loss = -203.17, baseline_loss = 7.9634, entropy_loss = -14.394, learner_queue_size = 64, _tick = 8056, _time = 1.6548e+09)
[2022-06-09 18:19:15,106][root][INFO] - Step 52480000 @ 3069.5 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 1.6718e+04, step = 52480000, mean_episode_return = 5.4411, mean_episode_step = 2344.9, total_loss = -79.548, pg_loss = -86.597, baseline_loss = 21.56, entropy_loss = -14.511, learner_queue_size = 64, _tick = 8059, _time = 1.6548e+09)
[2022-06-09 18:19:20,110][root][INFO] - Step 52495360 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.6723e+04, step = 52495360, mean_episode_return = 13.25, mean_episode_step = 1967.7, total_loss = 113.79, pg_loss = 93.214, baseline_loss = 35.127, entropy_loss = -14.551, learner_queue_size = 64, _tick = 8062, _time = 1.6548e+09)
[2022-06-09 18:19:25,114][root][INFO] - Step 52510720 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 1.6728e+04, step = 52510720, mean_episode_return = 69.089, mean_episode_step = 1775.8, total_loss = 147.94, pg_loss = 113.88, baseline_loss = 48.38, entropy_loss = -14.315, learner_queue_size = 64, _tick = 8065, _time = 1.6548e+09)
[2022-06-09 18:19:30,118][root][INFO] - Step 52526080 @ 3069.7 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.6733e+04, step = 52526080, mean_episode_return = -9.3705, mean_episode_step = 2000.1, total_loss = -319.61, pg_loss = -312.72, baseline_loss = 7.3247, entropy_loss = -14.214, learner_queue_size = 64, _tick = 8068, _time = 1.6548e+09)
[2022-06-09 18:19:35,122][root][INFO] - Step 52546560 @ 4092.5 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 1.6738e+04, step = 52546560, mean_episode_return = 96.168, mean_episode_step = 1973.4, total_loss = 182.47, pg_loss = 148.1, baseline_loss = 48.75, entropy_loss = -14.373, learner_queue_size = 64, _tick = 8072, _time = 1.6548e+09)
[2022-06-09 18:19:40,127][root][INFO] - Step 52561920 @ 3069.0 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.6743e+04, step = 52561920, mean_episode_return = 66.186, mean_episode_step = 1811.8, total_loss = 241.32, pg_loss = 188.63, baseline_loss = 66.972, entropy_loss = -14.282, learner_queue_size = 64, _tick = 8075, _time = 1.6548e+09)
[2022-06-09 18:19:45,130][root][INFO] - Step 52577280 @ 3069.9 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.6748e+04, step = 52577280, mean_episode_return = None, mean_episode_step = 1999.2, total_loss = 158.87, pg_loss = 135.22, baseline_loss = 38.146, entropy_loss = -14.494, learner_queue_size = 64, _tick = 8076, _time = 1.6548e+09)
[2022-06-09 18:19:50,134][root][INFO] - Step 52592640 @ 3069.7 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.6753e+04, step = 52592640, mean_episode_return = 75.464, mean_episode_step = 2016.8, total_loss = -73.98, pg_loss = -84.971, baseline_loss = 25.373, entropy_loss = -14.382, learner_queue_size = 64, _tick = 8079, _time = 1.6548e+09)
[2022-06-09 18:19:55,150][root][INFO] - Step 52608000 @ 3062.2 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.6758e+04, step = 52608000, mean_episode_return = None, mean_episode_step = 2408.2, total_loss = 64.883, pg_loss = 48.033, baseline_loss = 31.124, entropy_loss = -14.274, learner_queue_size = 64, _tick = 8081, _time = 1.6548e+09)
[2022-06-09 18:20:00,154][root][INFO] - Step 52623360 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.6763e+04, step = 52623360, mean_episode_return = 28.968, mean_episode_step = 2188.9, total_loss = -177.45, pg_loss = -194.64, baseline_loss = 31.352, entropy_loss = -14.16, learner_queue_size = 64, _tick = 8084, _time = 1.6548e+09)
[2022-06-09 18:20:05,158][root][INFO] - Step 52638720 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.6768e+04, step = 52638720, mean_episode_return = 31.66, mean_episode_step = 2065.2, total_loss = -105.46, pg_loss = -119.59, baseline_loss = 28.383, entropy_loss = -14.257, learner_queue_size = 64, _tick = 8086, _time = 1.6548e+09)
[2022-06-09 18:20:10,162][root][INFO] - Step 52654080 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.6773e+04, step = 52654080, mean_episode_return = 35.68, mean_episode_step = 2088.5, total_loss = 120.21, pg_loss = 81.917, baseline_loss = 52.431, entropy_loss = -14.135, learner_queue_size = 64, _tick = 8089, _time = 1.6548e+09)
[2022-06-09 18:20:15,166][root][INFO] - Step 52669440 @ 3069.5 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1.6778e+04, step = 52669440, mean_episode_return = None, mean_episode_step = 1984.6, total_loss = 5.0223, pg_loss = -4.979, baseline_loss = 24.201, entropy_loss = -14.2, learner_queue_size = 64, _tick = 8091, _time = 1.6548e+09)
[2022-06-09 18:20:20,170][root][INFO] - Step 52684800 @ 3069.5 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 1.6783e+04, step = 52684800, mean_episode_return = 68.405, mean_episode_step = 2234.1, total_loss = 57.968, pg_loss = 26.139, baseline_loss = 45.866, entropy_loss = -14.038, learner_queue_size = 64, _tick = 8093, _time = 1.6548e+09)
[2022-06-09 18:20:25,174][root][INFO] - Step 52705280 @ 4092.7 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 1.6788e+04, step = 52705280, mean_episode_return = None, mean_episode_step = 1861.0, total_loss = 188.15, pg_loss = 163.52, baseline_loss = 38.414, entropy_loss = -13.781, learner_queue_size = 64, _tick = 8095, _time = 1.6548e+09)
[2022-06-09 18:20:30,178][root][INFO] - Step 52720640 @ 3069.6 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 1.6793e+04, step = 52720640, mean_episode_return = None, mean_episode_step = 2209.5, total_loss = -212.13, pg_loss = -204.12, baseline_loss = 5.8275, entropy_loss = -13.838, learner_queue_size = 64, _tick = 8096, _time = 1.6548e+09)
[2022-06-09 18:20:35,182][root][INFO] - Step 52736000 @ 3069.5 SPS. Inference batcher size: 77. Learner queue size: 64. Other stats: (train_seconds = 1.6798e+04, step = 52736000, mean_episode_return = None, mean_episode_step = 2179.4, total_loss = 158.19, pg_loss = 135.37, baseline_loss = 36.585, entropy_loss = -13.768, learner_queue_size = 64, _tick = 8097, _time = 1.6548e+09)
[2022-06-09 18:20:40,186][root][INFO] - Step 52751360 @ 3069.5 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 1.6803e+04, step = 52751360, mean_episode_return = 2.6829, mean_episode_step = 2043.0, total_loss = 13.293, pg_loss = -10.129, baseline_loss = 37.02, entropy_loss = -13.597, learner_queue_size = 64, _tick = 8100, _time = 1.6548e+09)
[2022-06-09 18:20:45,190][root][INFO] - Step 52766720 @ 3069.6 SPS. Inference batcher size: 9. Learner queue size: 64. Other stats: (train_seconds = 1.6808e+04, step = 52766720, mean_episode_return = 54.821, mean_episode_step = 1886.2, total_loss = 125.15, pg_loss = 93.532, baseline_loss = 45.226, entropy_loss = -13.609, learner_queue_size = 64, _tick = 8103, _time = 1.6548e+09)
[2022-06-09 18:20:50,194][root][INFO] - Step 52782080 @ 3069.5 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.6813e+04, step = 52782080, mean_episode_return = 69.982, mean_episode_step = 2603.6, total_loss = 304.16, pg_loss = 162.47, baseline_loss = 155.29, entropy_loss = -13.602, learner_queue_size = 64, _tick = 8104, _time = 1.6548e+09)
[2022-06-09 18:20:55,198][root][INFO] - Step 52797440 @ 3069.6 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.6818e+04, step = 52797440, mean_episode_return = 72.071, mean_episode_step = 2078.8, total_loss = -204.28, pg_loss = -201.99, baseline_loss = 11.315, entropy_loss = -13.609, learner_queue_size = 64, _tick = 8105, _time = 1.6548e+09)
[2022-06-09 18:21:00,202][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 18:21:00,410][root][INFO] - Step 52812800 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.6823e+04, step = 52812800, mean_episode_return = 80.953, mean_episode_step = 2602.9, total_loss = 220.67, pg_loss = 176.83, baseline_loss = 57.55, entropy_loss = -13.703, learner_queue_size = 64, _tick = 8108, _time = 1.6548e+09)
[2022-06-09 18:21:05,414][root][INFO] - Step 52828160 @ 2947.0 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.6828e+04, step = 52828160, mean_episode_return = None, mean_episode_step = 2361.1, total_loss = 66.761, pg_loss = 40.584, baseline_loss = 39.83, entropy_loss = -13.653, learner_queue_size = 64, _tick = 8108, _time = 1.6548e+09)
[2022-06-09 18:21:10,418][root][INFO] - Step 52848640 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.6833e+04, step = 52848640, mean_episode_return = 78.88, mean_episode_step = 2263.7, total_loss = -46.829, pg_loss = -69.401, baseline_loss = 36.448, entropy_loss = -13.876, learner_queue_size = 64, _tick = 8112, _time = 1.6548e+09)
[2022-06-09 18:21:15,422][root][INFO] - Step 52864000 @ 3069.6 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 1.6838e+04, step = 52864000, mean_episode_return = -37.38, mean_episode_step = 2180.2, total_loss = -76.312, pg_loss = -85.249, baseline_loss = 22.585, entropy_loss = -13.648, learner_queue_size = 64, _tick = 8115, _time = 1.6548e+09)
[2022-06-09 18:21:20,426][root][INFO] - Step 52879360 @ 3069.5 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 1.6843e+04, step = 52879360, mean_episode_return = 24.29, mean_episode_step = 2394.3, total_loss = 116.92, pg_loss = 89.312, baseline_loss = 41.265, entropy_loss = -13.656, learner_queue_size = 64, _tick = 8117, _time = 1.6548e+09)
[2022-06-09 18:21:25,430][root][INFO] - Step 52894720 @ 3069.6 SPS. Inference batcher size: 72. Learner queue size: 64. Other stats: (train_seconds = 1.6848e+04, step = 52894720, mean_episode_return = 25.781, mean_episode_step = 2167.9, total_loss = 290.26, pg_loss = 240.3, baseline_loss = 63.78, entropy_loss = -13.826, learner_queue_size = 64, _tick = 8120, _time = 1.6548e+09)
[2022-06-09 18:21:30,434][root][INFO] - Step 52910080 @ 3069.5 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 1.6853e+04, step = 52910080, mean_episode_return = 54.87, mean_episode_step = 2127.2, total_loss = -122.3, pg_loss = -130.3, baseline_loss = 21.669, entropy_loss = -13.671, learner_queue_size = 64, _tick = 8123, _time = 1.6548e+09)
[2022-06-09 18:21:35,438][root][INFO] - Step 52925440 @ 3069.5 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 1.6858e+04, step = 52925440, mean_episode_return = None, mean_episode_step = 1805.8, total_loss = 264.53, pg_loss = 235.71, baseline_loss = 42.617, entropy_loss = -13.799, learner_queue_size = 64, _tick = 8125, _time = 1.6548e+09)
[2022-06-09 18:21:40,442][root][INFO] - Step 52940800 @ 3069.6 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.6863e+04, step = 52940800, mean_episode_return = 63.943, mean_episode_step = 2103.6, total_loss = 36.495, pg_loss = 12.413, baseline_loss = 37.783, entropy_loss = -13.701, learner_queue_size = 64, _tick = 8128, _time = 1.6548e+09)
[2022-06-09 18:21:45,446][root][INFO] - Step 52956160 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.6868e+04, step = 52956160, mean_episode_return = 23.489, mean_episode_step = 2267.2, total_loss = -37.638, pg_loss = -46.561, baseline_loss = 22.625, entropy_loss = -13.703, learner_queue_size = 64, _tick = 8130, _time = 1.6548e+09)
[2022-06-09 18:21:50,450][root][INFO] - Step 52971520 @ 3069.6 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.6873e+04, step = 52971520, mean_episode_return = 155.87, mean_episode_step = 2486.8, total_loss = 109.16, pg_loss = 85.539, baseline_loss = 37.576, entropy_loss = -13.958, learner_queue_size = 64, _tick = 8132, _time = 1.6548e+09)
[2022-06-09 18:21:55,454][root][INFO] - Step 52992000 @ 4092.7 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.6878e+04, step = 52992000, mean_episode_return = 99.888, mean_episode_step = 2059.1, total_loss = -280.11, pg_loss = -284.35, baseline_loss = 18.144, entropy_loss = -13.91, learner_queue_size = 64, _tick = 8136, _time = 1.6548e+09)
[2022-06-09 18:22:00,458][root][INFO] - Step 53007360 @ 3069.5 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 1.6883e+04, step = 53007360, mean_episode_return = 32.466, mean_episode_step = 2006.9, total_loss = 19.357, pg_loss = -8.6219, baseline_loss = 41.986, entropy_loss = -14.007, learner_queue_size = 64, _tick = 8139, _time = 1.6548e+09)
[2022-06-09 18:22:05,462][root][INFO] - Step 53022720 @ 3069.6 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 1.6888e+04, step = 53022720, mean_episode_return = 45.966, mean_episode_step = 1933.5, total_loss = -13.235, pg_loss = -23.947, baseline_loss = 24.779, entropy_loss = -14.067, learner_queue_size = 64, _tick = 8141, _time = 1.6548e+09)
[2022-06-09 18:22:10,466][root][INFO] - Step 53038080 @ 3069.5 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1.6893e+04, step = 53038080, mean_episode_return = None, mean_episode_step = 2398.4, total_loss = 460.51, pg_loss = 403.54, baseline_loss = 71.068, entropy_loss = -14.094, learner_queue_size = 64, _tick = 8143, _time = 1.6548e+09)
[2022-06-09 18:22:15,470][root][INFO] - Step 53053440 @ 3069.6 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.6898e+04, step = 53053440, mean_episode_return = -27.281, mean_episode_step = 2253.9, total_loss = 83.799, pg_loss = 64.666, baseline_loss = 33.413, entropy_loss = -14.281, learner_queue_size = 64, _tick = 8146, _time = 1.6548e+09)
[2022-06-09 18:22:20,474][root][INFO] - Step 53068800 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.6903e+04, step = 53068800, mean_episode_return = 39.841, mean_episode_step = 2325.1, total_loss = -102.91, pg_loss = -108.26, baseline_loss = 19.671, entropy_loss = -14.323, learner_queue_size = 64, _tick = 8148, _time = 1.6548e+09)
[2022-06-09 18:22:25,478][root][INFO] - Step 53084160 @ 3069.6 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.6908e+04, step = 53084160, mean_episode_return = 68.646, mean_episode_step = 2141.2, total_loss = -177.14, pg_loss = -176.24, baseline_loss = 13.492, entropy_loss = -14.392, learner_queue_size = 64, _tick = 8150, _time = 1.6548e+09)
[2022-06-09 18:22:30,482][root][INFO] - Step 53099520 @ 3069.5 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 1.6913e+04, step = 53099520, mean_episode_return = 27.35, mean_episode_step = 2106.4, total_loss = 179.63, pg_loss = 127.02, baseline_loss = 67.031, entropy_loss = -14.416, learner_queue_size = 64, _tick = 8152, _time = 1.6548e+09)
[2022-06-09 18:22:35,486][root][INFO] - Step 53114880 @ 3069.5 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.6918e+04, step = 53114880, mean_episode_return = -16.081, mean_episode_step = 2585.5, total_loss = 265.63, pg_loss = 221.1, baseline_loss = 59.045, entropy_loss = -14.514, learner_queue_size = 64, _tick = 8154, _time = 1.6548e+09)
[2022-06-09 18:22:40,490][root][INFO] - Step 53135360 @ 4092.8 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 1.6923e+04, step = 53135360, mean_episode_return = -9.8505, mean_episode_step = 2716.3, total_loss = 160.28, pg_loss = 135.93, baseline_loss = 39.125, entropy_loss = -14.776, learner_queue_size = 64, _tick = 8156, _time = 1.6548e+09)
[2022-06-09 18:22:45,494][root][INFO] - Step 53145600 @ 2046.4 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.6928e+04, step = 53145600, mean_episode_return = 46.513, mean_episode_step = 2349.6, total_loss = -116.04, pg_loss = -128.36, baseline_loss = 27.063, entropy_loss = -14.748, learner_queue_size = 64, _tick = 8157, _time = 1.6548e+09)
[2022-06-09 18:22:50,498][root][INFO] - Step 53166080 @ 4092.7 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.6933e+04, step = 53166080, mean_episode_return = 31.364, mean_episode_step = 2466.9, total_loss = 85.916, pg_loss = 74.521, baseline_loss = 26.071, entropy_loss = -14.676, learner_queue_size = 64, _tick = 8161, _time = 1.6548e+09)
[2022-06-09 18:22:55,502][root][INFO] - Step 53181440 @ 3069.6 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 1.6938e+04, step = 53181440, mean_episode_return = 5.5473, mean_episode_step = 2020.5, total_loss = -64.343, pg_loss = -69.856, baseline_loss = 19.975, entropy_loss = -14.461, learner_queue_size = 64, _tick = 8164, _time = 1.6548e+09)
[2022-06-09 18:23:00,506][root][INFO] - Step 53196800 @ 3069.5 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 1.6943e+04, step = 53196800, mean_episode_return = 56.561, mean_episode_step = 2588.2, total_loss = 8.3114, pg_loss = -11.428, baseline_loss = 34.197, entropy_loss = -14.457, learner_queue_size = 64, _tick = 8167, _time = 1.6548e+09)
[2022-06-09 18:23:05,512][root][INFO] - Step 53212160 @ 3068.3 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 1.6948e+04, step = 53212160, mean_episode_return = 50.054, mean_episode_step = 2569.9, total_loss = -253.77, pg_loss = -249.81, baseline_loss = 10.531, entropy_loss = -14.491, learner_queue_size = 64, _tick = 8169, _time = 1.6548e+09)
[2022-06-09 18:23:10,518][root][INFO] - Step 53227520 @ 3068.3 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 1.6954e+04, step = 53227520, mean_episode_return = None, mean_episode_step = 2196.3, total_loss = 98.994, pg_loss = 83.927, baseline_loss = 29.546, entropy_loss = -14.479, learner_queue_size = 64, _tick = 8171, _time = 1.6548e+09)
[2022-06-09 18:23:15,522][root][INFO] - Step 53242880 @ 3069.5 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 1.6958e+04, step = 53242880, mean_episode_return = 19.085, mean_episode_step = 2162.6, total_loss = -262.01, pg_loss = -259.35, baseline_loss = 11.844, entropy_loss = -14.5, learner_queue_size = 64, _tick = 8174, _time = 1.6548e+09)
[2022-06-09 18:23:20,526][root][INFO] - Step 53258240 @ 3069.6 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 1.6964e+04, step = 53258240, mean_episode_return = 36.561, mean_episode_step = 2272.4, total_loss = 46.011, pg_loss = 25.625, baseline_loss = 34.84, entropy_loss = -14.454, learner_queue_size = 64, _tick = 8177, _time = 1.6548e+09)
[2022-06-09 18:23:25,530][root][INFO] - Step 53273600 @ 3069.5 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.6968e+04, step = 53273600, mean_episode_return = 36.19, mean_episode_step = 1797.0, total_loss = -267.12, pg_loss = -259.95, baseline_loss = 7.4901, entropy_loss = -14.662, learner_queue_size = 64, _tick = 8180, _time = 1.6548e+09)
[2022-06-09 18:23:30,534][root][INFO] - Step 53288960 @ 3069.5 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 1.6974e+04, step = 53288960, mean_episode_return = None, mean_episode_step = 2303.9, total_loss = 26.578, pg_loss = 11.048, baseline_loss = 30.312, entropy_loss = -14.782, learner_queue_size = 64, _tick = 8182, _time = 1.6548e+09)
[2022-06-09 18:23:35,538][root][INFO] - Step 53309440 @ 4092.8 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 1.6978e+04, step = 53309440, mean_episode_return = 26.01, mean_episode_step = 2248.1, total_loss = 134.44, pg_loss = 113.46, baseline_loss = 35.904, entropy_loss = -14.922, learner_queue_size = 64, _tick = 8186, _time = 1.6548e+09)
[2022-06-09 18:23:40,542][root][INFO] - Step 53324800 @ 3069.4 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.6984e+04, step = 53324800, mean_episode_return = 66.978, mean_episode_step = 2290.9, total_loss = -147.52, pg_loss = -140.51, baseline_loss = 7.9519, entropy_loss = -14.964, learner_queue_size = 64, _tick = 8189, _time = 1.6548e+09)
[2022-06-09 18:23:45,546][root][INFO] - Step 53340160 @ 3069.7 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.6988e+04, step = 53340160, mean_episode_return = 54.078, mean_episode_step = 1807.1, total_loss = 181.29, pg_loss = 151.6, baseline_loss = 44.595, entropy_loss = -14.905, learner_queue_size = 64, _tick = 8192, _time = 1.6548e+09)
[2022-06-09 18:23:50,552][root][INFO] - Step 53355520 @ 3068.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.6994e+04, step = 53355520, mean_episode_return = 9.5713, mean_episode_step = 2028.8, total_loss = 47.723, pg_loss = 34.124, baseline_loss = 28.293, entropy_loss = -14.694, learner_queue_size = 64, _tick = 8195, _time = 1.6548e+09)
[2022-06-09 18:23:55,554][root][INFO] - Step 53370880 @ 3070.6 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.6998e+04, step = 53370880, mean_episode_return = 78.125, mean_episode_step = 2358.7, total_loss = -122.89, pg_loss = -133.06, baseline_loss = 24.642, entropy_loss = -14.471, learner_queue_size = 64, _tick = 8198, _time = 1.6548e+09)
[2022-06-09 18:24:00,558][root][INFO] - Step 53386240 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.7004e+04, step = 53386240, mean_episode_return = 27.961, mean_episode_step = 1694.9, total_loss = 147.15, pg_loss = 121.32, baseline_loss = 40.368, entropy_loss = -14.537, learner_queue_size = 64, _tick = 8200, _time = 1.6548e+09)
[2022-06-09 18:24:05,562][root][INFO] - Step 53401600 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.7008e+04, step = 53401600, mean_episode_return = 59.506, mean_episode_step = 2041.1, total_loss = -280.48, pg_loss = -273.25, baseline_loss = 7.3767, entropy_loss = -14.604, learner_queue_size = 64, _tick = 8203, _time = 1.6548e+09)
[2022-06-09 18:24:10,568][root][INFO] - Step 53416960 @ 3068.3 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 1.7014e+04, step = 53416960, mean_episode_return = 122.06, mean_episode_step = 1948.0, total_loss = -29.703, pg_loss = -36.61, baseline_loss = 21.417, entropy_loss = -14.51, learner_queue_size = 64, _tick = 8206, _time = 1.6548e+09)
[2022-06-09 18:24:15,574][root][INFO] - Step 53432320 @ 3068.4 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.7018e+04, step = 53432320, mean_episode_return = 82.327, mean_episode_step = 2028.9, total_loss = 328.01, pg_loss = 251.12, baseline_loss = 91.324, entropy_loss = -14.437, learner_queue_size = 64, _tick = 8209, _time = 1.6548e+09)
[2022-06-09 18:24:20,580][root][INFO] - Step 53447680 @ 3068.3 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.7024e+04, step = 53447680, mean_episode_return = 70.496, mean_episode_step = 1694.1, total_loss = 390.81, pg_loss = 334.95, baseline_loss = 70.106, entropy_loss = -14.239, learner_queue_size = 64, _tick = 8212, _time = 1.6548e+09)
[2022-06-09 18:24:25,586][root][INFO] - Step 53468160 @ 4091.0 SPS. Inference batcher size: 79. Learner queue size: 64. Other stats: (train_seconds = 1.7028e+04, step = 53468160, mean_episode_return = 22.72, mean_episode_step = 1675.0, total_loss = -94.305, pg_loss = -113.38, baseline_loss = 33.304, entropy_loss = -14.229, learner_queue_size = 64, _tick = 8216, _time = 1.6548e+09)
[2022-06-09 18:24:30,590][root][INFO] - Step 53483520 @ 3069.6 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 1.7034e+04, step = 53483520, mean_episode_return = 85.19, mean_episode_step = 1484.9, total_loss = 309.24, pg_loss = 255.24, baseline_loss = 68.099, entropy_loss = -14.106, learner_queue_size = 64, _tick = 8219, _time = 1.6548e+09)
[2022-06-09 18:24:35,594][root][INFO] - Step 53498880 @ 3069.5 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 1.7038e+04, step = 53498880, mean_episode_return = 38.441, mean_episode_step = 1768.9, total_loss = 259.34, pg_loss = 201.65, baseline_loss = 71.776, entropy_loss = -14.081, learner_queue_size = 64, _tick = 8222, _time = 1.6548e+09)
[2022-06-09 18:24:40,600][root][INFO] - Step 53514240 @ 3068.3 SPS. Inference batcher size: 2. Learner queue size: 64. Other stats: (train_seconds = 1.7044e+04, step = 53514240, mean_episode_return = -9.2501, mean_episode_step = 1775.2, total_loss = 73.369, pg_loss = 44.113, baseline_loss = 43.406, entropy_loss = -14.15, learner_queue_size = 64, _tick = 8224, _time = 1.6548e+09)
[2022-06-09 18:24:45,606][root][INFO] - Step 53529600 @ 3068.0 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.7048e+04, step = 53529600, mean_episode_return = 66.94, mean_episode_step = 1718.8, total_loss = -119.2, pg_loss = -163.79, baseline_loss = 58.643, entropy_loss = -14.055, learner_queue_size = 64, _tick = 8227, _time = 1.6548e+09)
[2022-06-09 18:24:50,610][root][INFO] - Step 53544960 @ 3069.9 SPS. Inference batcher size: 10. Learner queue size: 64. Other stats: (train_seconds = 1.7054e+04, step = 53544960, mean_episode_return = 98.998, mean_episode_step = 1768.7, total_loss = -197.38, pg_loss = -209.67, baseline_loss = 26.204, entropy_loss = -13.909, learner_queue_size = 64, _tick = 8230, _time = 1.6548e+09)
[2022-06-09 18:24:55,614][root][INFO] - Step 53560320 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.7059e+04, step = 53560320, mean_episode_return = 66.116, mean_episode_step = 1551.2, total_loss = -26.534, pg_loss = -45.838, baseline_loss = 33.486, entropy_loss = -14.182, learner_queue_size = 64, _tick = 8233, _time = 1.6548e+09)
[2022-06-09 18:25:00,618][root][INFO] - Step 53575680 @ 3069.5 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 1.7064e+04, step = 53575680, mean_episode_return = 71.713, mean_episode_step = 1746.3, total_loss = 51.944, pg_loss = 39.95, baseline_loss = 26.159, entropy_loss = -14.165, learner_queue_size = 64, _tick = 8236, _time = 1.6548e+09)
[2022-06-09 18:25:05,622][root][INFO] - Step 53591040 @ 3069.6 SPS. Inference batcher size: 15. Learner queue size: 64. Other stats: (train_seconds = 1.7069e+04, step = 53591040, mean_episode_return = 4.7202, mean_episode_step = 1423.7, total_loss = 152.22, pg_loss = 119.7, baseline_loss = 46.816, entropy_loss = -14.296, learner_queue_size = 64, _tick = 8239, _time = 1.6548e+09)
[2022-06-09 18:25:10,628][root][INFO] - Step 53606400 @ 3068.3 SPS. Inference batcher size: 14. Learner queue size: 64. Other stats: (train_seconds = 1.7074e+04, step = 53606400, mean_episode_return = 96.119, mean_episode_step = 1630.7, total_loss = 3.3686, pg_loss = -8.0345, baseline_loss = 25.679, entropy_loss = -14.276, learner_queue_size = 64, _tick = 8241, _time = 1.6548e+09)
[2022-06-09 18:25:15,635][root][INFO] - Step 53626880 @ 4090.2 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 1.7079e+04, step = 53626880, mean_episode_return = None, mean_episode_step = 1813.2, total_loss = -203.28, pg_loss = -191.69, baseline_loss = 2.6762, entropy_loss = -14.264, learner_queue_size = 64, _tick = 8243, _time = 1.6548e+09)
[2022-06-09 18:25:20,638][root][INFO] - Step 53642240 @ 3070.2 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.7084e+04, step = 53642240, mean_episode_return = 84.544, mean_episode_step = 1805.3, total_loss = -204.56, pg_loss = -207.68, baseline_loss = 17.458, entropy_loss = -14.337, learner_queue_size = 64, _tick = 8246, _time = 1.6548e+09)
[2022-06-09 18:25:25,642][root][INFO] - Step 53657600 @ 3069.5 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.7089e+04, step = 53657600, mean_episode_return = 71.224, mean_episode_step = 1671.7, total_loss = 56.404, pg_loss = 32.117, baseline_loss = 38.706, entropy_loss = -14.419, learner_queue_size = 64, _tick = 8249, _time = 1.6548e+09)
[2022-06-09 18:25:30,646][root][INFO] - Step 53672960 @ 3069.7 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 1.7094e+04, step = 53672960, mean_episode_return = 52.577, mean_episode_step = 1259.2, total_loss = -241.71, pg_loss = -251.82, baseline_loss = 24.374, entropy_loss = -14.267, learner_queue_size = 64, _tick = 8252, _time = 1.6548e+09)
[2022-06-09 18:25:35,650][root][INFO] - Step 53688320 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.7099e+04, step = 53688320, mean_episode_return = 19.659, mean_episode_step = 1547.9, total_loss = -79.757, pg_loss = -92.554, baseline_loss = 27.088, entropy_loss = -14.291, learner_queue_size = 64, _tick = 8254, _time = 1.6548e+09)
[2022-06-09 18:25:40,654][root][INFO] - Step 53703680 @ 3069.2 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.7104e+04, step = 53703680, mean_episode_return = 6.8599, mean_episode_step = 1614.1, total_loss = 63.111, pg_loss = 38.509, baseline_loss = 38.789, entropy_loss = -14.188, learner_queue_size = 64, _tick = 8257, _time = 1.6548e+09)
[2022-06-09 18:25:45,658][root][INFO] - Step 53719040 @ 3069.9 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.7109e+04, step = 53719040, mean_episode_return = -2.49, mean_episode_step = 1529.0, total_loss = 82.917, pg_loss = 56.968, baseline_loss = 40.099, entropy_loss = -14.15, learner_queue_size = 64, _tick = 8260, _time = 1.6548e+09)
[2022-06-09 18:25:50,662][root][INFO] - Step 53734400 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.7114e+04, step = 53734400, mean_episode_return = 44.105, mean_episode_step = 1658.4, total_loss = -205.81, pg_loss = -208.92, baseline_loss = 17.192, entropy_loss = -14.082, learner_queue_size = 64, _tick = 8263, _time = 1.6548e+09)
[2022-06-09 18:25:55,666][root][INFO] - Step 53749760 @ 3069.5 SPS. Inference batcher size: 18. Learner queue size: 64. Other stats: (train_seconds = 1.7119e+04, step = 53749760, mean_episode_return = 96.458, mean_episode_step = 1655.5, total_loss = 386.79, pg_loss = 347.4, baseline_loss = 53.371, entropy_loss = -13.982, learner_queue_size = 64, _tick = 8265, _time = 1.6548e+09)
[2022-06-09 18:26:00,671][root][INFO] - Step 53765120 @ 3068.8 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.7124e+04, step = 53765120, mean_episode_return = 22.33, mean_episode_step = 1651.4, total_loss = -56.534, pg_loss = -63.707, baseline_loss = 21.114, entropy_loss = -13.941, learner_queue_size = 64, _tick = 8268, _time = 1.6548e+09)
[2022-06-09 18:26:05,674][root][INFO] - Step 53785600 @ 4093.7 SPS. Inference batcher size: 3. Learner queue size: 64. Other stats: (train_seconds = 1.7129e+04, step = 53785600, mean_episode_return = None, mean_episode_step = 1490.7, total_loss = 105.19, pg_loss = 86.522, baseline_loss = 32.833, entropy_loss = -14.165, learner_queue_size = 64, _tick = 8270, _time = 1.6548e+09)
[2022-06-09 18:26:10,678][root][INFO] - Step 53800960 @ 3069.5 SPS. Inference batcher size: 73. Learner queue size: 64. Other stats: (train_seconds = 1.7134e+04, step = 53800960, mean_episode_return = None, mean_episode_step = 1364.1, total_loss = 80.017, pg_loss = 59.099, baseline_loss = 35.323, entropy_loss = -14.404, learner_queue_size = 64, _tick = 8271, _time = 1.6548e+09)
[2022-06-09 18:26:15,682][root][INFO] - Step 53816320 @ 3069.6 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 1.7139e+04, step = 53816320, mean_episode_return = 32.892, mean_episode_step = 1698.6, total_loss = 477.23, pg_loss = 413.13, baseline_loss = 78.212, entropy_loss = -14.112, learner_queue_size = 64, _tick = 8273, _time = 1.6548e+09)
[2022-06-09 18:26:20,686][root][INFO] - Step 53831680 @ 3069.5 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 1.7144e+04, step = 53831680, mean_episode_return = -1.44, mean_episode_step = 1733.8, total_loss = 124.38, pg_loss = 71.865, baseline_loss = 66.442, entropy_loss = -13.931, learner_queue_size = 64, _tick = 8275, _time = 1.6548e+09)
[2022-06-09 18:26:25,690][root][INFO] - Step 53847040 @ 3069.5 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 1.7149e+04, step = 53847040, mean_episode_return = 6.37, mean_episode_step = 1650.9, total_loss = -71.017, pg_loss = -88.978, baseline_loss = 31.882, entropy_loss = -13.92, learner_queue_size = 64, _tick = 8278, _time = 1.6548e+09)
[2022-06-09 18:26:30,694][root][INFO] - Step 53862400 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.7154e+04, step = 53862400, mean_episode_return = 46.59, mean_episode_step = 1370.2, total_loss = -272.92, pg_loss = -277.74, baseline_loss = 18.72, entropy_loss = -13.9, learner_queue_size = 64, _tick = 8281, _time = 1.6548e+09)
[2022-06-09 18:26:35,698][root][INFO] - Step 53877760 @ 3069.5 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 1.7159e+04, step = 53877760, mean_episode_return = 35.882, mean_episode_step = 1611.6, total_loss = -15.728, pg_loss = -78.596, baseline_loss = 76.679, entropy_loss = -13.812, learner_queue_size = 64, _tick = 8284, _time = 1.6548e+09)
[2022-06-09 18:26:40,702][root][INFO] - Step 53893120 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.7164e+04, step = 53893120, mean_episode_return = 65.9, mean_episode_step = 1605.9, total_loss = -11.744, pg_loss = -29.101, baseline_loss = 31.141, entropy_loss = -13.784, learner_queue_size = 64, _tick = 8285, _time = 1.6548e+09)
[2022-06-09 18:26:45,706][root][INFO] - Step 53913600 @ 4092.8 SPS. Inference batcher size: 85. Learner queue size: 64. Other stats: (train_seconds = 1.7169e+04, step = 53913600, mean_episode_return = 20.72, mean_episode_step = 1741.8, total_loss = -200.46, pg_loss = -199.08, baseline_loss = 12.778, entropy_loss = -14.153, learner_queue_size = 64, _tick = 8289, _time = 1.6548e+09)
[2022-06-09 18:26:50,710][root][INFO] - Step 53928960 @ 3069.5 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 1.7174e+04, step = 53928960, mean_episode_return = 35.83, mean_episode_step = 1949.1, total_loss = -127.75, pg_loss = -149.9, baseline_loss = 36.32, entropy_loss = -14.169, learner_queue_size = 64, _tick = 8292, _time = 1.6548e+09)
[2022-06-09 18:26:55,714][root][INFO] - Step 53944320 @ 3069.6 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 1.7179e+04, step = 53944320, mean_episode_return = 41.107, mean_episode_step = 1934.8, total_loss = 38.994, pg_loss = 8.0439, baseline_loss = 45.108, entropy_loss = -14.158, learner_queue_size = 64, _tick = 8295, _time = 1.6548e+09)
[2022-06-09 18:27:00,718][root][INFO] - Step 53959680 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.7184e+04, step = 53959680, mean_episode_return = 19.9, mean_episode_step = 2002.4, total_loss = -349.31, pg_loss = -340.27, baseline_loss = 5.0157, entropy_loss = -14.054, learner_queue_size = 64, _tick = 8298, _time = 1.6548e+09)
[2022-06-09 18:27:05,722][root][INFO] - Step 53975040 @ 3069.5 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.7189e+04, step = 53975040, mean_episode_return = 17.405, mean_episode_step = 2037.0, total_loss = 96.8, pg_loss = 68.128, baseline_loss = 42.796, entropy_loss = -14.124, learner_queue_size = 64, _tick = 8299, _time = 1.6548e+09)
[2022-06-09 18:27:10,726][root][INFO] - Step 53990400 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.7194e+04, step = 53990400, mean_episode_return = 65.901, mean_episode_step = 1836.0, total_loss = 79.351, pg_loss = 45.611, baseline_loss = 47.699, entropy_loss = -13.958, learner_queue_size = 64, _tick = 8302, _time = 1.6548e+09)
[2022-06-09 18:27:15,730][root][INFO] - Step 54005760 @ 3069.6 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.7199e+04, step = 54005760, mean_episode_return = 79.488, mean_episode_step = 2036.1, total_loss = -268.07, pg_loss = -264.33, baseline_loss = 9.9581, entropy_loss = -13.69, learner_queue_size = 64, _tick = 8305, _time = 1.6548e+09)
[2022-06-09 18:27:20,734][root][INFO] - Step 54026240 @ 4092.8 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 1.7204e+04, step = 54026240, mean_episode_return = None, mean_episode_step = 1671.2, total_loss = 51.587, pg_loss = 31.256, baseline_loss = 34.059, entropy_loss = -13.728, learner_queue_size = 64, _tick = 8308, _time = 1.6548e+09)
[2022-06-09 18:27:25,738][root][INFO] - Step 54041600 @ 3069.6 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 1.7209e+04, step = 54041600, mean_episode_return = 0.57, mean_episode_step = 1850.1, total_loss = -28.62, pg_loss = -41.253, baseline_loss = 26.392, entropy_loss = -13.759, learner_queue_size = 64, _tick = 8310, _time = 1.6548e+09)
[2022-06-09 18:27:30,742][root][INFO] - Step 54056960 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.7214e+04, step = 54056960, mean_episode_return = 40.442, mean_episode_step = 2032.9, total_loss = 92.554, pg_loss = 55.267, baseline_loss = 51.07, entropy_loss = -13.784, learner_queue_size = 64, _tick = 8313, _time = 1.6548e+09)
[2022-06-09 18:27:35,746][root][INFO] - Step 54072320 @ 3069.5 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 1.7219e+04, step = 54072320, mean_episode_return = 92.142, mean_episode_step = 1869.2, total_loss = 75.637, pg_loss = 48.086, baseline_loss = 41.243, entropy_loss = -13.692, learner_queue_size = 64, _tick = 8316, _time = 1.6548e+09)
[2022-06-09 18:27:40,750][root][INFO] - Step 54087680 @ 3069.6 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 1.7224e+04, step = 54087680, mean_episode_return = 111.59, mean_episode_step = 2351.3, total_loss = -228.5, pg_loss = -222.84, baseline_loss = 7.9918, entropy_loss = -13.651, learner_queue_size = 64, _tick = 8319, _time = 1.6548e+09)
[2022-06-09 18:27:45,754][root][INFO] - Step 54103040 @ 3069.5 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 1.7229e+04, step = 54103040, mean_episode_return = 24.611, mean_episode_step = 1995.7, total_loss = 16.284, pg_loss = 8.988, baseline_loss = 21.043, entropy_loss = -13.747, learner_queue_size = 64, _tick = 8322, _time = 1.6548e+09)
[2022-06-09 18:27:50,758][root][INFO] - Step 54118400 @ 3069.6 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.7234e+04, step = 54118400, mean_episode_return = 7.9693, mean_episode_step = 1771.5, total_loss = 7.6254, pg_loss = -15.512, baseline_loss = 36.782, entropy_loss = -13.645, learner_queue_size = 64, _tick = 8325, _time = 1.6548e+09)
[2022-06-09 18:27:55,762][root][INFO] - Step 54133760 @ 3069.5 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.7239e+04, step = 54133760, mean_episode_return = -18.931, mean_episode_step = 1972.5, total_loss = -33.439, pg_loss = -50.177, baseline_loss = 30.297, entropy_loss = -13.559, learner_queue_size = 64, _tick = 8327, _time = 1.6548e+09)
[2022-06-09 18:28:00,766][root][INFO] - Step 54149120 @ 3069.5 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.7244e+04, step = 54149120, mean_episode_return = None, mean_episode_step = 2109.3, total_loss = 304.55, pg_loss = 263.44, baseline_loss = 54.769, entropy_loss = -13.662, learner_queue_size = 64, _tick = 8329, _time = 1.6548e+09)
[2022-06-09 18:28:05,770][root][INFO] - Step 54164480 @ 3069.6 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 1.7249e+04, step = 54164480, mean_episode_return = 65.44, mean_episode_step = 1839.7, total_loss = 148.36, pg_loss = 96.705, baseline_loss = 65.2, entropy_loss = -13.545, learner_queue_size = 64, _tick = 8332, _time = 1.6548e+09)
[2022-06-09 18:28:10,774][root][INFO] - Step 54179840 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.7254e+04, step = 54179840, mean_episode_return = 52.253, mean_episode_step = 2022.7, total_loss = 10.377, pg_loss = -2.8734, baseline_loss = 26.787, entropy_loss = -13.537, learner_queue_size = 64, _tick = 8334, _time = 1.6548e+09)
[2022-06-09 18:28:15,780][root][INFO] - Step 54195200 @ 3068.3 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.7259e+04, step = 54195200, mean_episode_return = 43.87, mean_episode_step = 2089.7, total_loss = 116.53, pg_loss = 77.527, baseline_loss = 52.731, entropy_loss = -13.727, learner_queue_size = 64, _tick = 8337, _time = 1.6548e+09)
[2022-06-09 18:28:20,786][root][INFO] - Step 54210560 @ 3068.3 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.7264e+04, step = 54210560, mean_episode_return = 66.855, mean_episode_step = 1820.3, total_loss = 528.56, pg_loss = 460.29, baseline_loss = 82.089, entropy_loss = -13.82, learner_queue_size = 64, _tick = 8340, _time = 1.6548e+09)
[2022-06-09 18:28:25,790][root][INFO] - Step 54231040 @ 4092.7 SPS. Inference batcher size: 6. Learner queue size: 64. Other stats: (train_seconds = 1.7269e+04, step = 54231040, mean_episode_return = 38.198, mean_episode_step = 2178.4, total_loss = 24.996, pg_loss = -21.178, baseline_loss = 60.059, entropy_loss = -13.885, learner_queue_size = 64, _tick = 8344, _time = 1.6548e+09)
[2022-06-09 18:28:30,794][root][INFO] - Step 54246400 @ 3069.6 SPS. Inference batcher size: 92. Learner queue size: 64. Other stats: (train_seconds = 1.7274e+04, step = 54246400, mean_episode_return = 8.5696, mean_episode_step = 1740.7, total_loss = -174.89, pg_loss = -167.04, baseline_loss = 6.0542, entropy_loss = -13.904, learner_queue_size = 64, _tick = 8347, _time = 1.6548e+09)
[2022-06-09 18:28:35,815][root][INFO] - Step 54261760 @ 3059.3 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.7279e+04, step = 54261760, mean_episode_return = 137.05, mean_episode_step = 2175.2, total_loss = 134.18, pg_loss = 104.51, baseline_loss = 43.621, entropy_loss = -13.958, learner_queue_size = 64, _tick = 8350, _time = 1.6548e+09)
[2022-06-09 18:28:40,818][root][INFO] - Step 54277120 @ 3070.0 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 1.7284e+04, step = 54277120, mean_episode_return = 25.594, mean_episode_step = 1794.7, total_loss = 32.735, pg_loss = -0.8302, baseline_loss = 47.341, entropy_loss = -13.776, learner_queue_size = 64, _tick = 8352, _time = 1.6548e+09)
[2022-06-09 18:28:45,822][root][INFO] - Step 54292480 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.7289e+04, step = 54292480, mean_episode_return = 36.848, mean_episode_step = 1966.9, total_loss = 237.27, pg_loss = 135.44, baseline_loss = 115.64, entropy_loss = -13.805, learner_queue_size = 64, _tick = 8354, _time = 1.6548e+09)
[2022-06-09 18:28:50,826][root][INFO] - Step 54307840 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.7294e+04, step = 54307840, mean_episode_return = None, mean_episode_step = 2032.2, total_loss = 172.7, pg_loss = 149.45, baseline_loss = 37.053, entropy_loss = -13.808, learner_queue_size = 64, _tick = 8355, _time = 1.6548e+09)
[2022-06-09 18:28:55,830][root][INFO] - Step 54323200 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.7299e+04, step = 54323200, mean_episode_return = 79.895, mean_episode_step = 1855.6, total_loss = 405.35, pg_loss = 240.76, baseline_loss = 178.56, entropy_loss = -13.969, learner_queue_size = 64, _tick = 8358, _time = 1.6548e+09)
[2022-06-09 18:29:00,836][root][INFO] - Step 54338560 @ 3068.3 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 1.7304e+04, step = 54338560, mean_episode_return = 56.374, mean_episode_step = 1788.1, total_loss = -171.2, pg_loss = -180.1, baseline_loss = 22.994, entropy_loss = -14.096, learner_queue_size = 64, _tick = 8361, _time = 1.6548e+09)
[2022-06-09 18:29:05,842][root][INFO] - Step 54359040 @ 4091.2 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 1.7309e+04, step = 54359040, mean_episode_return = 45.692, mean_episode_step = 1842.2, total_loss = -180.67, pg_loss = -180.18, baseline_loss = 13.778, entropy_loss = -14.267, learner_queue_size = 64, _tick = 8363, _time = 1.6548e+09)
[2022-06-09 18:29:10,846][root][INFO] - Step 54374400 @ 3069.5 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 1.7314e+04, step = 54374400, mean_episode_return = 19.458, mean_episode_step = 2180.8, total_loss = -242.07, pg_loss = -260.09, baseline_loss = 32.315, entropy_loss = -14.292, learner_queue_size = 64, _tick = 8366, _time = 1.6548e+09)
[2022-06-09 18:29:15,850][root][INFO] - Step 54389760 @ 3069.5 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 1.7319e+04, step = 54389760, mean_episode_return = 6.9535, mean_episode_step = 1861.6, total_loss = -244.91, pg_loss = -255.02, baseline_loss = 24.422, entropy_loss = -14.306, learner_queue_size = 64, _tick = 8369, _time = 1.6548e+09)
[2022-06-09 18:29:20,854][root][INFO] - Step 54405120 @ 3069.5 SPS. Inference batcher size: 4. Learner queue size: 64. Other stats: (train_seconds = 1.7324e+04, step = 54405120, mean_episode_return = 52.89, mean_episode_step = 2106.3, total_loss = -159.53, pg_loss = -175.56, baseline_loss = 30.214, entropy_loss = -14.19, learner_queue_size = 64, _tick = 8372, _time = 1.6548e+09)
[2022-06-09 18:29:25,858][root][INFO] - Step 54420480 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.7329e+04, step = 54420480, mean_episode_return = None, mean_episode_step = 1536.2, total_loss = 210.57, pg_loss = 182.59, baseline_loss = 42.222, entropy_loss = -14.236, learner_queue_size = 64, _tick = 8374, _time = 1.6548e+09)
[2022-06-09 18:29:30,862][root][INFO] - Step 54435840 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.7334e+04, step = 54435840, mean_episode_return = None, mean_episode_step = 1921.0, total_loss = 139.07, pg_loss = 118.05, baseline_loss = 35.197, entropy_loss = -14.175, learner_queue_size = 64, _tick = 8376, _time = 1.6548e+09)
[2022-06-09 18:29:35,866][root][INFO] - Step 54451200 @ 3069.6 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.7339e+04, step = 54451200, mean_episode_return = 10.519, mean_episode_step = 2141.8, total_loss = 169.12, pg_loss = 146.79, baseline_loss = 36.465, entropy_loss = -14.136, learner_queue_size = 64, _tick = 8378, _time = 1.6548e+09)
[2022-06-09 18:29:40,870][root][INFO] - Step 54466560 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.7344e+04, step = 54466560, mean_episode_return = -60.276, mean_episode_step = 2044.6, total_loss = -108.07, pg_loss = -119.21, baseline_loss = 25.136, entropy_loss = -14.003, learner_queue_size = 64, _tick = 8380, _time = 1.6548e+09)
[2022-06-09 18:29:45,874][root][INFO] - Step 54487040 @ 4092.8 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 1.7349e+04, step = 54487040, mean_episode_return = 51.532, mean_episode_step = 2133.8, total_loss = -10.139, pg_loss = -18.304, baseline_loss = 22.279, entropy_loss = -14.114, learner_queue_size = 64, _tick = 8384, _time = 1.6548e+09)
[2022-06-09 18:29:50,878][root][INFO] - Step 54502400 @ 3069.5 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 1.7354e+04, step = 54502400, mean_episode_return = 23.28, mean_episode_step = 1788.0, total_loss = -16.127, pg_loss = -30.703, baseline_loss = 28.788, entropy_loss = -14.212, learner_queue_size = 64, _tick = 8386, _time = 1.6548e+09)
[2022-06-09 18:29:55,882][root][INFO] - Step 54517760 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.7359e+04, step = 54517760, mean_episode_return = 60.663, mean_episode_step = 2098.9, total_loss = -129.99, pg_loss = -133.41, baseline_loss = 17.734, entropy_loss = -14.314, learner_queue_size = 64, _tick = 8388, _time = 1.6548e+09)
[2022-06-09 18:30:00,888][root][INFO] - Step 54533120 @ 3068.3 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.7364e+04, step = 54533120, mean_episode_return = 35.491, mean_episode_step = 1716.6, total_loss = -47.364, pg_loss = -55.502, baseline_loss = 22.38, entropy_loss = -14.242, learner_queue_size = 64, _tick = 8391, _time = 1.6548e+09)
[2022-06-09 18:30:05,890][root][INFO] - Step 54548480 @ 3070.9 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 1.7369e+04, step = 54548480, mean_episode_return = 69.44, mean_episode_step = 2191.4, total_loss = 267.59, pg_loss = 234.12, baseline_loss = 47.889, entropy_loss = -14.419, learner_queue_size = 64, _tick = 8394, _time = 1.6548e+09)
[2022-06-09 18:30:10,894][root][INFO] - Step 54563840 @ 3069.5 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 1.7374e+04, step = 54563840, mean_episode_return = None, mean_episode_step = 1945.5, total_loss = -76.901, pg_loss = -74.803, baseline_loss = 12.25, entropy_loss = -14.349, learner_queue_size = 64, _tick = 8396, _time = 1.6548e+09)
[2022-06-09 18:30:15,898][root][INFO] - Step 54579200 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.7379e+04, step = 54579200, mean_episode_return = 59.982, mean_episode_step = 2119.6, total_loss = -339.25, pg_loss = -329.55, baseline_loss = 4.7016, entropy_loss = -14.4, learner_queue_size = 64, _tick = 8399, _time = 1.6548e+09)
[2022-06-09 18:30:20,904][root][INFO] - Step 54594560 @ 3068.2 SPS. Inference batcher size: 13. Learner queue size: 64. Other stats: (train_seconds = 1.7384e+04, step = 54594560, mean_episode_return = 45.198, mean_episode_step = 1951.0, total_loss = 65.481, pg_loss = 41.685, baseline_loss = 38.3, entropy_loss = -14.505, learner_queue_size = 64, _tick = 8402, _time = 1.6548e+09)
[2022-06-09 18:30:25,910][root][INFO] - Step 54615040 @ 4091.2 SPS. Inference batcher size: 89. Learner queue size: 64. Other stats: (train_seconds = 1.7389e+04, step = 54615040, mean_episode_return = 6.8011, mean_episode_step = 2151.7, total_loss = 143.55, pg_loss = 115.69, baseline_loss = 42.344, entropy_loss = -14.485, learner_queue_size = 64, _tick = 8406, _time = 1.6548e+09)
[2022-06-09 18:30:30,914][root][INFO] - Step 54630400 @ 3069.5 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 1.7394e+04, step = 54630400, mean_episode_return = None, mean_episode_step = 1868.9, total_loss = -83.39, pg_loss = -78.859, baseline_loss = 9.9504, entropy_loss = -14.481, learner_queue_size = 64, _tick = 8408, _time = 1.6548e+09)
[2022-06-09 18:30:35,918][root][INFO] - Step 54645760 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.7399e+04, step = 54645760, mean_episode_return = 47.282, mean_episode_step = 2223.2, total_loss = -219.52, pg_loss = -220.41, baseline_loss = 15.572, entropy_loss = -14.677, learner_queue_size = 64, _tick = 8411, _time = 1.6548e+09)
[2022-06-09 18:30:40,922][root][INFO] - Step 54661120 @ 3069.5 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.7404e+04, step = 54661120, mean_episode_return = 78.176, mean_episode_step = 1768.8, total_loss = -149.93, pg_loss = -152.76, baseline_loss = 17.451, entropy_loss = -14.616, learner_queue_size = 64, _tick = 8414, _time = 1.6548e+09)
[2022-06-09 18:30:45,926][root][INFO] - Step 54676480 @ 3069.5 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 1.7409e+04, step = 54676480, mean_episode_return = 20.207, mean_episode_step = 1849.7, total_loss = -72.006, pg_loss = -83.681, baseline_loss = 26.35, entropy_loss = -14.676, learner_queue_size = 64, _tick = 8416, _time = 1.6548e+09)
[2022-06-09 18:30:50,930][root][INFO] - Step 54691840 @ 3069.6 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.7414e+04, step = 54691840, mean_episode_return = 59.113, mean_episode_step = 1912.6, total_loss = 85.214, pg_loss = 52.165, baseline_loss = 47.676, entropy_loss = -14.627, learner_queue_size = 64, _tick = 8419, _time = 1.6548e+09)
[2022-06-09 18:30:55,934][root][INFO] - Step 54707200 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.7419e+04, step = 54707200, mean_episode_return = 24.281, mean_episode_step = 1774.0, total_loss = 29.275, pg_loss = 20.022, baseline_loss = 23.702, entropy_loss = -14.448, learner_queue_size = 64, _tick = 8422, _time = 1.6548e+09)
[2022-06-09 18:31:00,938][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 18:31:01,236][root][INFO] - Step 54727680 @ 4092.7 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 1.7424e+04, step = 54727680, mean_episode_return = 92.032, mean_episode_step = 1956.2, total_loss = 1.9284, pg_loss = -4.8808, baseline_loss = 21.269, entropy_loss = -14.46, learner_queue_size = 64, _tick = 8426, _time = 1.6548e+09)
[2022-06-09 18:31:06,238][root][INFO] - Step 54743040 @ 2898.1 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 1.7429e+04, step = 54743040, mean_episode_return = None, mean_episode_step = 1871.1, total_loss = 46.324, pg_loss = 38.93, baseline_loss = 22.008, entropy_loss = -14.614, learner_queue_size = 64, _tick = 8428, _time = 1.6548e+09)
[2022-06-09 18:31:11,242][root][INFO] - Step 54758400 @ 3069.5 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.7434e+04, step = 54758400, mean_episode_return = None, mean_episode_step = 1892.9, total_loss = 78.281, pg_loss = 66.791, baseline_loss = 25.861, entropy_loss = -14.371, learner_queue_size = 64, _tick = 8430, _time = 1.6548e+09)
[2022-06-09 18:31:16,248][root][INFO] - Step 54773760 @ 3068.3 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.7439e+04, step = 54773760, mean_episode_return = None, mean_episode_step = 1841.6, total_loss = 357.1, pg_loss = 307.4, baseline_loss = 64.039, entropy_loss = -14.333, learner_queue_size = 64, _tick = 8431, _time = 1.6548e+09)
[2022-06-09 18:31:21,254][root][INFO] - Step 54789120 @ 3068.3 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.7444e+04, step = 54789120, mean_episode_return = 76.419, mean_episode_step = 1939.8, total_loss = 120.88, pg_loss = 73.728, baseline_loss = 61.559, entropy_loss = -14.41, learner_queue_size = 64, _tick = 8433, _time = 1.6548e+09)
[2022-06-09 18:31:26,258][root][INFO] - Step 54809600 @ 4092.7 SPS. Inference batcher size: 105. Learner queue size: 64. Other stats: (train_seconds = 1.7449e+04, step = 54809600, mean_episode_return = None, mean_episode_step = 2208.8, total_loss = 112.3, pg_loss = 86.708, baseline_loss = 39.914, entropy_loss = -14.321, learner_queue_size = 64, _tick = 8436, _time = 1.6548e+09)
[2022-06-09 18:31:31,262][root][INFO] - Step 54824960 @ 3069.6 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 1.7454e+04, step = 54824960, mean_episode_return = 38.65, mean_episode_step = 2165.1, total_loss = 327.52, pg_loss = 285.99, baseline_loss = 55.788, entropy_loss = -14.263, learner_queue_size = 64, _tick = 8439, _time = 1.6548e+09)
[2022-06-09 18:31:36,266][root][INFO] - Step 54840320 @ 3069.6 SPS. Inference batcher size: 86. Learner queue size: 64. Other stats: (train_seconds = 1.7459e+04, step = 54840320, mean_episode_return = 40.592, mean_episode_step = 1774.4, total_loss = 205.36, pg_loss = 170.01, baseline_loss = 49.759, entropy_loss = -14.415, learner_queue_size = 64, _tick = 8442, _time = 1.6548e+09)
[2022-06-09 18:31:41,270][root][INFO] - Step 54855680 @ 3069.5 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 1.7464e+04, step = 54855680, mean_episode_return = 42.975, mean_episode_step = 1968.2, total_loss = 84.779, pg_loss = 44.994, baseline_loss = 54.229, entropy_loss = -14.444, learner_queue_size = 64, _tick = 8445, _time = 1.6548e+09)
[2022-06-09 18:31:46,274][root][INFO] - Step 54871040 @ 3069.5 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 1.7469e+04, step = 54871040, mean_episode_return = 27.104, mean_episode_step = 1906.3, total_loss = -148.5, pg_loss = -157.84, baseline_loss = 23.666, entropy_loss = -14.325, learner_queue_size = 64, _tick = 8447, _time = 1.6548e+09)
[2022-06-09 18:31:51,278][root][INFO] - Step 54886400 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.7474e+04, step = 54886400, mean_episode_return = 15.98, mean_episode_step = 1766.8, total_loss = -238.81, pg_loss = -236.86, baseline_loss = 12.374, entropy_loss = -14.331, learner_queue_size = 64, _tick = 8449, _time = 1.6548e+09)
[2022-06-09 18:31:56,282][root][INFO] - Step 54901760 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.7479e+04, step = 54901760, mean_episode_return = 54.912, mean_episode_step = 1941.4, total_loss = 10.464, pg_loss = 5.1831, baseline_loss = 19.757, entropy_loss = -14.476, learner_queue_size = 64, _tick = 8451, _time = 1.6548e+09)
[2022-06-09 18:32:01,286][root][INFO] - Step 54917120 @ 3069.6 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.7484e+04, step = 54917120, mean_episode_return = 20.72, mean_episode_step = 1917.0, total_loss = -216.58, pg_loss = -216.75, baseline_loss = 14.685, entropy_loss = -14.513, learner_queue_size = 64, _tick = 8453, _time = 1.6548e+09)
[2022-06-09 18:32:06,290][root][INFO] - Step 54932480 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.7489e+04, step = 54932480, mean_episode_return = None, mean_episode_step = 1717.2, total_loss = 154.59, pg_loss = 141.18, baseline_loss = 28.062, entropy_loss = -14.648, learner_queue_size = 64, _tick = 8455, _time = 1.6548e+09)
[2022-06-09 18:32:11,294][root][INFO] - Step 54947840 @ 3069.5 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.7494e+04, step = 54947840, mean_episode_return = None, mean_episode_step = 2111.5, total_loss = 319.98, pg_loss = 277.44, baseline_loss = 57.124, entropy_loss = -14.583, learner_queue_size = 64, _tick = 8457, _time = 1.6548e+09)
[2022-06-09 18:32:16,298][root][INFO] - Step 54963200 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.7499e+04, step = 54963200, mean_episode_return = 79.948, mean_episode_step = 1834.6, total_loss = -382.93, pg_loss = -376.1, baseline_loss = 7.7783, entropy_loss = -14.607, learner_queue_size = 64, _tick = 8460, _time = 1.6548e+09)
[2022-06-09 18:32:21,304][root][INFO] - Step 54978560 @ 3068.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.7504e+04, step = 54978560, mean_episode_return = 29.495, mean_episode_step = 2085.3, total_loss = -37.594, pg_loss = -49.745, baseline_loss = 26.765, entropy_loss = -14.615, learner_queue_size = 64, _tick = 8463, _time = 1.6548e+09)
[2022-06-09 18:32:26,306][root][INFO] - Step 54999040 @ 4094.0 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.7509e+04, step = 54999040, mean_episode_return = -3.66, mean_episode_step = 1882.4, total_loss = 5.7553, pg_loss = -2.083, baseline_loss = 22.381, entropy_loss = -14.543, learner_queue_size = 64, _tick = 8467, _time = 1.6548e+09)
[2022-06-09 18:32:31,309][root][INFO] - Step 55014400 @ 3070.0 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 1.7514e+04, step = 55014400, mean_episode_return = 36.17, mean_episode_step = 1936.1, total_loss = -166.85, pg_loss = -171.82, baseline_loss = 19.506, entropy_loss = -14.544, learner_queue_size = 64, _tick = 8469, _time = 1.6548e+09)
[2022-06-09 18:32:36,314][root][INFO] - Step 55029760 @ 3069.2 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 1.7519e+04, step = 55029760, mean_episode_return = 137.62, mean_episode_step = 1812.9, total_loss = 139.97, pg_loss = 91.468, baseline_loss = 62.983, entropy_loss = -14.481, learner_queue_size = 64, _tick = 8470, _time = 1.6548e+09)
[2022-06-09 18:32:41,318][root][INFO] - Step 55045120 @ 3069.5 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 1.7524e+04, step = 55045120, mean_episode_return = 66.87, mean_episode_step = 1757.7, total_loss = 73.8, pg_loss = 58.64, baseline_loss = 29.472, entropy_loss = -14.313, learner_queue_size = 64, _tick = 8473, _time = 1.6548e+09)
[2022-06-09 18:32:46,322][root][INFO] - Step 55060480 @ 3069.6 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.7529e+04, step = 55060480, mean_episode_return = 21.983, mean_episode_step = 2257.2, total_loss = 262.12, pg_loss = 221.87, baseline_loss = 54.443, entropy_loss = -14.19, learner_queue_size = 64, _tick = 8476, _time = 1.6548e+09)
[2022-06-09 18:32:51,326][root][INFO] - Step 55075840 @ 3069.5 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 1.7534e+04, step = 55075840, mean_episode_return = 36.321, mean_episode_step = 2143.9, total_loss = 6.4807, pg_loss = -12.199, baseline_loss = 32.736, entropy_loss = -14.056, learner_queue_size = 64, _tick = 8479, _time = 1.6548e+09)
[2022-06-09 18:32:56,330][root][INFO] - Step 55091200 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.7539e+04, step = 55091200, mean_episode_return = 40.222, mean_episode_step = 2133.6, total_loss = -195.63, pg_loss = -194.61, baseline_loss = 12.975, entropy_loss = -13.999, learner_queue_size = 64, _tick = 8482, _time = 1.6548e+09)
[2022-06-09 18:33:01,334][root][INFO] - Step 55106560 @ 3069.5 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 1.7544e+04, step = 55106560, mean_episode_return = 8.3495, mean_episode_step = 2014.1, total_loss = 450.32, pg_loss = 383.06, baseline_loss = 81.214, entropy_loss = -13.955, learner_queue_size = 64, _tick = 8485, _time = 1.6548e+09)
[2022-06-09 18:33:06,338][root][INFO] - Step 55121920 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.7549e+04, step = 55121920, mean_episode_return = 59.186, mean_episode_step = 1655.6, total_loss = 43.071, pg_loss = 26.058, baseline_loss = 31.224, entropy_loss = -14.21, learner_queue_size = 64, _tick = 8488, _time = 1.6548e+09)
[2022-06-09 18:33:11,342][root][INFO] - Step 55142400 @ 4092.7 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.7554e+04, step = 55142400, mean_episode_return = 18.72, mean_episode_step = 2092.8, total_loss = 6.9724, pg_loss = -4.9017, baseline_loss = 26.269, entropy_loss = -14.395, learner_queue_size = 64, _tick = 8492, _time = 1.6548e+09)
[2022-06-09 18:33:16,346][root][INFO] - Step 55157760 @ 3069.6 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 1.7559e+04, step = 55157760, mean_episode_return = None, mean_episode_step = 1936.6, total_loss = 257.41, pg_loss = 217.65, baseline_loss = 54.242, entropy_loss = -14.486, learner_queue_size = 64, _tick = 8493, _time = 1.6548e+09)
[2022-06-09 18:33:21,350][root][INFO] - Step 55173120 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.7564e+04, step = 55173120, mean_episode_return = 31.02, mean_episode_step = 1996.2, total_loss = 28.824, pg_loss = 11.297, baseline_loss = 31.917, entropy_loss = -14.391, learner_queue_size = 64, _tick = 8496, _time = 1.6548e+09)
[2022-06-09 18:33:26,354][root][INFO] - Step 55188480 @ 3069.5 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 1.7569e+04, step = 55188480, mean_episode_return = 9.9094, mean_episode_step = 1913.4, total_loss = 178.71, pg_loss = 147.03, baseline_loss = 46.107, entropy_loss = -14.428, learner_queue_size = 64, _tick = 8499, _time = 1.6548e+09)
[2022-06-09 18:33:31,358][root][INFO] - Step 55203840 @ 3069.5 SPS. Inference batcher size: 13. Learner queue size: 64. Other stats: (train_seconds = 1.7574e+04, step = 55203840, mean_episode_return = 38.546, mean_episode_step = 2231.3, total_loss = 126.3, pg_loss = 94.885, baseline_loss = 45.722, entropy_loss = -14.303, learner_queue_size = 64, _tick = 8502, _time = 1.6548e+09)
[2022-06-09 18:33:36,362][root][INFO] - Step 55219200 @ 3069.4 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.7579e+04, step = 55219200, mean_episode_return = 118.21, mean_episode_step = 2298.6, total_loss = -106.64, pg_loss = -106.09, baseline_loss = 13.834, entropy_loss = -14.384, learner_queue_size = 64, _tick = 8504, _time = 1.6548e+09)
[2022-06-09 18:33:41,368][root][INFO] - Step 55234560 @ 3068.3 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.7584e+04, step = 55234560, mean_episode_return = 14.695, mean_episode_step = 2189.9, total_loss = 145.58, pg_loss = 123.18, baseline_loss = 36.797, entropy_loss = -14.394, learner_queue_size = 64, _tick = 8507, _time = 1.6548e+09)
[2022-06-09 18:33:46,375][root][INFO] - Step 55249920 @ 3068.1 SPS. Inference batcher size: 14. Learner queue size: 64. Other stats: (train_seconds = 1.7589e+04, step = 55249920, mean_episode_return = None, mean_episode_step = 2250.7, total_loss = 118.63, pg_loss = 95.469, baseline_loss = 37.516, entropy_loss = -14.355, learner_queue_size = 64, _tick = 8509, _time = 1.6548e+09)
[2022-06-09 18:33:51,378][root][INFO] - Step 55265280 @ 3069.8 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.7594e+04, step = 55265280, mean_episode_return = 69.269, mean_episode_step = 2165.8, total_loss = -41.064, pg_loss = -55.569, baseline_loss = 28.815, entropy_loss = -14.31, learner_queue_size = 64, _tick = 8511, _time = 1.6548e+09)
[2022-06-09 18:33:56,382][root][INFO] - Step 55280640 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.7599e+04, step = 55280640, mean_episode_return = 60.624, mean_episode_step = 2236.3, total_loss = -79.359, pg_loss = -88.308, baseline_loss = 23.419, entropy_loss = -14.47, learner_queue_size = 64, _tick = 8514, _time = 1.6548e+09)
[2022-06-09 18:34:01,388][root][INFO] - Step 55296000 @ 3068.1 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1.7604e+04, step = 55296000, mean_episode_return = 42.6, mean_episode_step = 2020.6, total_loss = 21.258, pg_loss = 9.7985, baseline_loss = 25.914, entropy_loss = -14.454, learner_queue_size = 64, _tick = 8517, _time = 1.6548e+09)
[2022-06-09 18:34:06,394][root][INFO] - Step 55316480 @ 4091.3 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 1.7609e+04, step = 55316480, mean_episode_return = 35.47, mean_episode_step = 2283.1, total_loss = 47.199, pg_loss = 28.268, baseline_loss = 33.386, entropy_loss = -14.456, learner_queue_size = 64, _tick = 8520, _time = 1.6548e+09)
[2022-06-09 18:34:11,398][root][INFO] - Step 55331840 @ 3069.5 SPS. Inference batcher size: 103. Learner queue size: 64. Other stats: (train_seconds = 1.7614e+04, step = 55331840, mean_episode_return = 49.292, mean_episode_step = 1869.6, total_loss = -62.895, pg_loss = -67.621, baseline_loss = 19.254, entropy_loss = -14.528, learner_queue_size = 64, _tick = 8523, _time = 1.6548e+09)
[2022-06-09 18:34:16,402][root][INFO] - Step 55347200 @ 3069.6 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.7619e+04, step = 55347200, mean_episode_return = 47.169, mean_episode_step = 1983.1, total_loss = -16.35, pg_loss = -25.015, baseline_loss = 23.086, entropy_loss = -14.421, learner_queue_size = 64, _tick = 8526, _time = 1.6548e+09)
[2022-06-09 18:34:21,406][root][INFO] - Step 55362560 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.7624e+04, step = 55362560, mean_episode_return = 23.793, mean_episode_step = 1717.7, total_loss = -238.72, pg_loss = -236.98, baseline_loss = 12.789, entropy_loss = -14.532, learner_queue_size = 64, _tick = 8529, _time = 1.6548e+09)
[2022-06-09 18:34:26,410][root][INFO] - Step 55377920 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.7629e+04, step = 55377920, mean_episode_return = 56.291, mean_episode_step = 2193.5, total_loss = 13.039, pg_loss = 6.5835, baseline_loss = 21.104, entropy_loss = -14.649, learner_queue_size = 64, _tick = 8532, _time = 1.6548e+09)
[2022-06-09 18:34:31,414][root][INFO] - Step 55393280 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.7634e+04, step = 55393280, mean_episode_return = 28.076, mean_episode_step = 2093.0, total_loss = 135.99, pg_loss = 117.76, baseline_loss = 32.77, entropy_loss = -14.539, learner_queue_size = 64, _tick = 8535, _time = 1.6548e+09)
[2022-06-09 18:34:36,418][root][INFO] - Step 55408640 @ 3069.5 SPS. Inference batcher size: 6. Learner queue size: 64. Other stats: (train_seconds = 1.7639e+04, step = 55408640, mean_episode_return = 96.394, mean_episode_step = 1960.3, total_loss = 161.71, pg_loss = 130.6, baseline_loss = 45.652, entropy_loss = -14.536, learner_queue_size = 64, _tick = 8537, _time = 1.6548e+09)
[2022-06-09 18:34:41,422][root][INFO] - Step 55424000 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.7644e+04, step = 55424000, mean_episode_return = 9.7151, mean_episode_step = 2241.5, total_loss = 18.09, pg_loss = 4.324, baseline_loss = 28.239, entropy_loss = -14.474, learner_queue_size = 64, _tick = 8540, _time = 1.6548e+09)
[2022-06-09 18:34:46,426][root][INFO] - Step 55444480 @ 4092.7 SPS. Inference batcher size: 23. Learner queue size: 18. Other stats: (train_seconds = 1.7649e+04, step = 55444480, mean_episode_return = None, mean_episode_step = 1792.8, total_loss = -80.991, pg_loss = -76.605, baseline_loss = 10.118, entropy_loss = -14.504, learner_queue_size = 64, _tick = 8543, _time = 1.6548e+09)
[2022-06-09 18:34:51,430][root][INFO] - Step 55459840 @ 3069.5 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 1.7654e+04, step = 55459840, mean_episode_return = 87.608, mean_episode_step = 2135.2, total_loss = 164.74, pg_loss = 142.24, baseline_loss = 37.122, entropy_loss = -14.626, learner_queue_size = 64, _tick = 8546, _time = 1.6548e+09)
[2022-06-09 18:34:56,434][root][INFO] - Step 55475200 @ 3069.5 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 1.7659e+04, step = 55475200, mean_episode_return = 26.012, mean_episode_step = 2188.1, total_loss = -69.451, pg_loss = -92.449, baseline_loss = 37.624, entropy_loss = -14.626, learner_queue_size = 64, _tick = 8549, _time = 1.6548e+09)
[2022-06-09 18:35:01,438][root][INFO] - Step 55490560 @ 3069.6 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.7664e+04, step = 55490560, mean_episode_return = 50.652, mean_episode_step = 1919.6, total_loss = 555.3, pg_loss = 348.02, baseline_loss = 221.89, entropy_loss = -14.612, learner_queue_size = 64, _tick = 8552, _time = 1.6548e+09)
[2022-06-09 18:35:06,442][root][INFO] - Step 55505920 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.7669e+04, step = 55505920, mean_episode_return = 52.583, mean_episode_step = 2094.4, total_loss = -143.99, pg_loss = -136.92, baseline_loss = 7.642, entropy_loss = -14.718, learner_queue_size = 64, _tick = 8555, _time = 1.6548e+09)
[2022-06-09 18:35:11,446][root][INFO] - Step 55521280 @ 3069.5 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.7674e+04, step = 55521280, mean_episode_return = None, mean_episode_step = 1792.1, total_loss = 235.59, pg_loss = 209.75, baseline_loss = 40.555, entropy_loss = -14.723, learner_queue_size = 64, _tick = 8557, _time = 1.6548e+09)
[2022-06-09 18:35:16,450][root][INFO] - Step 55536640 @ 3069.6 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 1.7679e+04, step = 55536640, mean_episode_return = 49.039, mean_episode_step = 1976.7, total_loss = -8.2806, pg_loss = -30.55, baseline_loss = 36.965, entropy_loss = -14.695, learner_queue_size = 64, _tick = 8560, _time = 1.6548e+09)
[2022-06-09 18:35:21,456][root][INFO] - Step 55552000 @ 3068.3 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.7684e+04, step = 55552000, mean_episode_return = None, mean_episode_step = 1924.1, total_loss = 239.38, pg_loss = 208.52, baseline_loss = 45.457, entropy_loss = -14.591, learner_queue_size = 64, _tick = 8562, _time = 1.6548e+09)
[2022-06-09 18:35:26,462][root][INFO] - Step 55572480 @ 4091.1 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 1.7689e+04, step = 55572480, mean_episode_return = -7.0304, mean_episode_step = 2002.0, total_loss = -134.05, pg_loss = -138.37, baseline_loss = 19.109, entropy_loss = -14.792, learner_queue_size = 64, _tick = 8565, _time = 1.6548e+09)
[2022-06-09 18:35:31,466][root][INFO] - Step 55587840 @ 3069.6 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 1.7694e+04, step = 55587840, mean_episode_return = 63.58, mean_episode_step = 2116.1, total_loss = -84.483, pg_loss = -96.779, baseline_loss = 27.052, entropy_loss = -14.756, learner_queue_size = 64, _tick = 8568, _time = 1.6548e+09)
[2022-06-09 18:35:36,470][root][INFO] - Step 55603200 @ 3069.6 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 1.7699e+04, step = 55603200, mean_episode_return = 22.81, mean_episode_step = 2238.3, total_loss = -28.92, pg_loss = -32.339, baseline_loss = 18.252, entropy_loss = -14.833, learner_queue_size = 64, _tick = 8571, _time = 1.6548e+09)
[2022-06-09 18:35:41,474][root][INFO] - Step 55618560 @ 3069.6 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 1.7704e+04, step = 55618560, mean_episode_return = 80.598, mean_episode_step = 1846.3, total_loss = 203.58, pg_loss = 170.77, baseline_loss = 47.649, entropy_loss = -14.842, learner_queue_size = 64, _tick = 8574, _time = 1.6548e+09)
[2022-06-09 18:35:46,478][root][INFO] - Step 55633920 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.7709e+04, step = 55633920, mean_episode_return = 16.751, mean_episode_step = 1946.2, total_loss = 50.65, pg_loss = 25.446, baseline_loss = 39.786, entropy_loss = -14.583, learner_queue_size = 64, _tick = 8576, _time = 1.6548e+09)
[2022-06-09 18:35:51,482][root][INFO] - Step 55649280 @ 3069.6 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.7714e+04, step = 55649280, mean_episode_return = 39.89, mean_episode_step = 2029.9, total_loss = 50.282, pg_loss = 25.942, baseline_loss = 38.918, entropy_loss = -14.578, learner_queue_size = 64, _tick = 8579, _time = 1.6548e+09)
[2022-06-09 18:35:56,486][root][INFO] - Step 55664640 @ 3069.5 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 1.7719e+04, step = 55664640, mean_episode_return = -70.807, mean_episode_step = 2280.3, total_loss = -41.39, pg_loss = -49.901, baseline_loss = 23.096, entropy_loss = -14.585, learner_queue_size = 64, _tick = 8582, _time = 1.6548e+09)
[2022-06-09 18:36:01,490][root][INFO] - Step 55680000 @ 3069.6 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.7724e+04, step = 55680000, mean_episode_return = None, mean_episode_step = 1945.6, total_loss = 91.562, pg_loss = 66.743, baseline_loss = 39.409, entropy_loss = -14.589, learner_queue_size = 64, _tick = 8583, _time = 1.6548e+09)
[2022-06-09 18:36:06,494][root][INFO] - Step 55695360 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.7729e+04, step = 55695360, mean_episode_return = 52.381, mean_episode_step = 2106.5, total_loss = 459.55, pg_loss = 393.06, baseline_loss = 80.964, entropy_loss = -14.466, learner_queue_size = 64, _tick = 8586, _time = 1.6548e+09)
[2022-06-09 18:36:11,498][root][INFO] - Step 55710720 @ 3069.6 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.7734e+04, step = 55710720, mean_episode_return = 85.424, mean_episode_step = 2039.7, total_loss = 109.5, pg_loss = 88.105, baseline_loss = 35.918, entropy_loss = -14.52, learner_queue_size = 64, _tick = 8589, _time = 1.6548e+09)
[2022-06-09 18:36:16,502][root][INFO] - Step 55731200 @ 4092.7 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 1.7739e+04, step = 55731200, mean_episode_return = 124.02, mean_episode_step = 2017.7, total_loss = -28.381, pg_loss = -39.517, baseline_loss = 25.404, entropy_loss = -14.268, learner_queue_size = 64, _tick = 8593, _time = 1.6548e+09)
[2022-06-09 18:36:21,506][root][INFO] - Step 55746560 @ 3069.5 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 1.7744e+04, step = 55746560, mean_episode_return = 50.083, mean_episode_step = 1970.9, total_loss = -106.01, pg_loss = -122.04, baseline_loss = 30.358, entropy_loss = -14.326, learner_queue_size = 64, _tick = 8596, _time = 1.6548e+09)
[2022-06-09 18:36:26,510][root][INFO] - Step 55761920 @ 3069.6 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 1.7749e+04, step = 55761920, mean_episode_return = None, mean_episode_step = 1876.3, total_loss = -14.613, pg_loss = -15.473, baseline_loss = 15.049, entropy_loss = -14.189, learner_queue_size = 64, _tick = 8598, _time = 1.6548e+09)
[2022-06-09 18:36:31,514][root][INFO] - Step 55777280 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.7754e+04, step = 55777280, mean_episode_return = 52.023, mean_episode_step = 1880.8, total_loss = -9.6838, pg_loss = -18.954, baseline_loss = 23.525, entropy_loss = -14.255, learner_queue_size = 64, _tick = 8601, _time = 1.6548e+09)
[2022-06-09 18:36:36,518][root][INFO] - Step 55792640 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.776e+04, step = 55792640, mean_episode_return = 46.221, mean_episode_step = 1881.3, total_loss = 27.307, pg_loss = 16.978, baseline_loss = 24.489, entropy_loss = -14.161, learner_queue_size = 64, _tick = 8604, _time = 1.6548e+09)
[2022-06-09 18:36:41,522][root][INFO] - Step 55808000 @ 3069.6 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 1.7764e+04, step = 55808000, mean_episode_return = 32.285, mean_episode_step = 2397.1, total_loss = -126.51, pg_loss = -133.28, baseline_loss = 20.922, entropy_loss = -14.149, learner_queue_size = 64, _tick = 8607, _time = 1.6548e+09)
[2022-06-09 18:36:46,526][root][INFO] - Step 55823360 @ 3069.5 SPS. Inference batcher size: 14. Learner queue size: 64. Other stats: (train_seconds = 1.777e+04, step = 55823360, mean_episode_return = 77.951, mean_episode_step = 1721.3, total_loss = -190.88, pg_loss = -185.71, baseline_loss = 8.9558, entropy_loss = -14.122, learner_queue_size = 64, _tick = 8609, _time = 1.6548e+09)
[2022-06-09 18:36:51,530][root][INFO] - Step 55838720 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 1.7774e+04, step = 55838720, mean_episode_return = 116.19, mean_episode_step = 2143.0, total_loss = -23.962, pg_loss = -31.027, baseline_loss = 21.316, entropy_loss = -14.25, learner_queue_size = 64, _tick = 8612, _time = 1.6548e+09)
[2022-06-09 18:36:56,534][root][INFO] - Step 55859200 @ 4092.7 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 1.778e+04, step = 55859200, mean_episode_return = 82.18, mean_episode_step = 2127.4, total_loss = 308.89, pg_loss = 272.14, baseline_loss = 50.966, entropy_loss = -14.223, learner_queue_size = 64, _tick = 8615, _time = 1.6548e+09)
[2022-06-09 18:37:01,538][root][INFO] - Step 55874560 @ 3069.5 SPS. Inference batcher size: 77. Learner queue size: 64. Other stats: (train_seconds = 1.7784e+04, step = 55874560, mean_episode_return = 70.8, mean_episode_step = 1692.9, total_loss = 449.82, pg_loss = 404.34, baseline_loss = 59.661, entropy_loss = -14.174, learner_queue_size = 64, _tick = 8618, _time = 1.6548e+09)
[2022-06-09 18:37:06,542][root][INFO] - Step 55889920 @ 3069.6 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 1.779e+04, step = 55889920, mean_episode_return = 23.737, mean_episode_step = 1992.7, total_loss = 197.96, pg_loss = 156.94, baseline_loss = 55.166, entropy_loss = -14.146, learner_queue_size = 64, _tick = 8621, _time = 1.6548e+09)
[2022-06-09 18:37:11,555][root][INFO] - Step 55905280 @ 3063.7 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.7794e+04, step = 55905280, mean_episode_return = 60.858, mean_episode_step = 1954.2, total_loss = 110.21, pg_loss = 72.688, baseline_loss = 51.52, entropy_loss = -13.997, learner_queue_size = 64, _tick = 8624, _time = 1.6548e+09)
[2022-06-09 18:37:16,558][root][INFO] - Step 55920640 @ 3070.5 SPS. Inference batcher size: 14. Learner queue size: 64. Other stats: (train_seconds = 1.78e+04, step = 55920640, mean_episode_return = 23.59, mean_episode_step = 1981.9, total_loss = 190.66, pg_loss = 149.47, baseline_loss = 55.13, entropy_loss = -13.94, learner_queue_size = 64, _tick = 8626, _time = 1.6548e+09)
[2022-06-09 18:37:21,564][root][INFO] - Step 55936000 @ 3068.4 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 1.7804e+04, step = 55936000, mean_episode_return = 29.845, mean_episode_step = 2059.4, total_loss = 118.05, pg_loss = 78.961, baseline_loss = 53.002, entropy_loss = -13.914, learner_queue_size = 64, _tick = 8629, _time = 1.6548e+09)
[2022-06-09 18:37:26,566][root][INFO] - Step 55951360 @ 3070.7 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.781e+04, step = 55951360, mean_episode_return = -18.711, mean_episode_step = 2088.8, total_loss = -205.51, pg_loss = -196.24, baseline_loss = 4.8357, entropy_loss = -14.099, learner_queue_size = 64, _tick = 8632, _time = 1.6548e+09)
[2022-06-09 18:37:31,570][root][INFO] - Step 55966720 @ 3069.5 SPS. Inference batcher size: 7. Learner queue size: 64. Other stats: (train_seconds = 1.7814e+04, step = 55966720, mean_episode_return = None, mean_episode_step = 1841.3, total_loss = -8.6472, pg_loss = -16.325, baseline_loss = 22.057, entropy_loss = -14.38, learner_queue_size = 64, _tick = 8633, _time = 1.6548e+09)
[2022-06-09 18:37:36,574][root][INFO] - Step 55982080 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 1.782e+04, step = 55982080, mean_episode_return = 74.483, mean_episode_step = 2171.7, total_loss = 32.642, pg_loss = 12.414, baseline_loss = 34.481, entropy_loss = -14.253, learner_queue_size = 64, _tick = 8636, _time = 1.6548e+09)
[2022-06-09 18:37:41,578][root][INFO] - Step 56002560 @ 4092.7 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.7824e+04, step = 56002560, mean_episode_return = None, mean_episode_step = 2035.2, total_loss = -22.364, pg_loss = -26.78, baseline_loss = 18.718, entropy_loss = -14.301, learner_queue_size = 64, _tick = 8638, _time = 1.6548e+09)
[2022-06-09 18:37:46,582][root][INFO] - Step 56017920 @ 3069.6 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 1.783e+04, step = 56017920, mean_episode_return = None, mean_episode_step = 1860.9, total_loss = 143.67, pg_loss = 130.84, baseline_loss = 27.328, entropy_loss = -14.492, learner_queue_size = 64, _tick = 8640, _time = 1.6548e+09)
[2022-06-09 18:37:51,588][root][INFO] - Step 56033280 @ 3068.5 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 1.7834e+04, step = 56033280, mean_episode_return = -5.8, mean_episode_step = 1980.4, total_loss = -164.82, pg_loss = -164.48, baseline_loss = 14.124, entropy_loss = -14.456, learner_queue_size = 64, _tick = 8643, _time = 1.6548e+09)
[2022-06-09 18:37:56,594][root][INFO] - Step 56048640 @ 3068.3 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1.784e+04, step = 56048640, mean_episode_return = 70.645, mean_episode_step = 1728.3, total_loss = 143.77, pg_loss = 106.69, baseline_loss = 51.604, entropy_loss = -14.528, learner_queue_size = 64, _tick = 8645, _time = 1.6548e+09)
[2022-06-09 18:38:01,598][root][INFO] - Step 56064000 @ 3069.3 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.7844e+04, step = 56064000, mean_episode_return = 12.855, mean_episode_step = 1815.8, total_loss = -31.053, pg_loss = -53.315, baseline_loss = 36.715, entropy_loss = -14.453, learner_queue_size = 64, _tick = 8647, _time = 1.6548e+09)
[2022-06-09 18:38:06,602][root][INFO] - Step 56079360 @ 3069.6 SPS. Inference batcher size: 14. Learner queue size: 64. Other stats: (train_seconds = 1.785e+04, step = 56079360, mean_episode_return = -3.4203, mean_episode_step = 1884.7, total_loss = -138.91, pg_loss = -136.22, baseline_loss = 11.754, entropy_loss = -14.447, learner_queue_size = 64, _tick = 8649, _time = 1.6548e+09)
[2022-06-09 18:38:11,606][root][INFO] - Step 56094720 @ 3069.5 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 1.7854e+04, step = 56094720, mean_episode_return = -7.9192, mean_episode_step = 2303.3, total_loss = -180.4, pg_loss = -174.25, baseline_loss = 8.375, entropy_loss = -14.531, learner_queue_size = 64, _tick = 8652, _time = 1.6548e+09)
[2022-06-09 18:38:16,610][root][INFO] - Step 56110080 @ 3069.5 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.786e+04, step = 56110080, mean_episode_return = None, mean_episode_step = 2125.0, total_loss = 158.38, pg_loss = 110.97, baseline_loss = 62.019, entropy_loss = -14.603, learner_queue_size = 64, _tick = 8654, _time = 1.6548e+09)
[2022-06-09 18:38:21,619][root][INFO] - Step 56130560 @ 4088.6 SPS. Inference batcher size: 82. Learner queue size: 64. Other stats: (train_seconds = 1.7865e+04, step = 56130560, mean_episode_return = 27.84, mean_episode_step = 1926.3, total_loss = -49.08, pg_loss = -54.305, baseline_loss = 19.843, entropy_loss = -14.618, learner_queue_size = 64, _tick = 8658, _time = 1.6548e+09)
[2022-06-09 18:38:26,622][root][INFO] - Step 56145920 @ 3070.2 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 1.787e+04, step = 56145920, mean_episode_return = 41.536, mean_episode_step = 2217.2, total_loss = 5.2099, pg_loss = -9.0515, baseline_loss = 28.87, entropy_loss = -14.609, learner_queue_size = 64, _tick = 8659, _time = 1.6548e+09)
[2022-06-09 18:38:31,626][root][INFO] - Step 56161280 @ 3069.6 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 1.7875e+04, step = 56161280, mean_episode_return = 33.778, mean_episode_step = 2076.6, total_loss = -209.25, pg_loss = -202.9, baseline_loss = 8.367, entropy_loss = -14.71, learner_queue_size = 64, _tick = 8662, _time = 1.6548e+09)
[2022-06-09 18:38:36,630][root][INFO] - Step 56176640 @ 3069.5 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 1.788e+04, step = 56176640, mean_episode_return = 35.704, mean_episode_step = 1939.8, total_loss = -170.37, pg_loss = -171.9, baseline_loss = 16.132, entropy_loss = -14.604, learner_queue_size = 64, _tick = 8665, _time = 1.6548e+09)
[2022-06-09 18:38:41,634][root][INFO] - Step 56192000 @ 3069.3 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 1.7885e+04, step = 56192000, mean_episode_return = 0.37518, mean_episode_step = 2193.4, total_loss = -57.423, pg_loss = -67.419, baseline_loss = 24.675, entropy_loss = -14.679, learner_queue_size = 64, _tick = 8668, _time = 1.6548e+09)
[2022-06-09 18:38:46,638][root][INFO] - Step 56207360 @ 3069.8 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.789e+04, step = 56207360, mean_episode_return = 85.889, mean_episode_step = 1701.9, total_loss = 95.863, pg_loss = 79.993, baseline_loss = 30.448, entropy_loss = -14.578, learner_queue_size = 64, _tick = 8671, _time = 1.6548e+09)
[2022-06-09 18:38:51,642][root][INFO] - Step 56222720 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.7895e+04, step = 56222720, mean_episode_return = 22.881, mean_episode_step = 1675.5, total_loss = -77.915, pg_loss = -85.82, baseline_loss = 22.532, entropy_loss = -14.627, learner_queue_size = 64, _tick = 8674, _time = 1.6548e+09)
[2022-06-09 18:38:56,646][root][INFO] - Step 56238080 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.79e+04, step = 56238080, mean_episode_return = None, mean_episode_step = 1996.5, total_loss = -31.832, pg_loss = -43.021, baseline_loss = 25.64, entropy_loss = -14.451, learner_queue_size = 64, _tick = 8676, _time = 1.6548e+09)
[2022-06-09 18:39:01,650][root][INFO] - Step 56253440 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 1.7905e+04, step = 56253440, mean_episode_return = 19.756, mean_episode_step = 1908.6, total_loss = -151.73, pg_loss = -152.51, baseline_loss = 15.131, entropy_loss = -14.353, learner_queue_size = 64, _tick = 8678, _time = 1.6548e+09)
[2022-06-09 18:39:06,654][root][INFO] - Step 56273920 @ 4092.6 SPS. Inference batcher size: 111. Learner queue size: 64. Other stats: (train_seconds = 1.791e+04, step = 56273920, mean_episode_return = 47.449, mean_episode_step = 2074.7, total_loss = -28.908, pg_loss = -40.951, baseline_loss = 26.604, entropy_loss = -14.561, learner_queue_size = 64, _tick = 8681, _time = 1.6548e+09)
[2022-06-09 18:39:11,658][root][INFO] - Step 56289280 @ 3069.6 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 1.7915e+04, step = 56289280, mean_episode_return = 80.158, mean_episode_step = 1883.0, total_loss = 30.674, pg_loss = 17.424, baseline_loss = 27.958, entropy_loss = -14.708, learner_queue_size = 64, _tick = 8684, _time = 1.6548e+09)
[2022-06-09 18:39:16,662][root][INFO] - Step 56304640 @ 3069.5 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 1.792e+04, step = 56304640, mean_episode_return = None, mean_episode_step = 1903.7, total_loss = -147.93, pg_loss = -140.38, baseline_loss = 6.9929, entropy_loss = -14.548, learner_queue_size = 64, _tick = 8686, _time = 1.6548e+09)
[2022-06-09 18:39:21,666][root][INFO] - Step 56320000 @ 3069.5 SPS. Inference batcher size: 13. Learner queue size: 64. Other stats: (train_seconds = 1.7925e+04, step = 56320000, mean_episode_return = 35.496, mean_episode_step = 2015.0, total_loss = 68.479, pg_loss = 52.415, baseline_loss = 30.517, entropy_loss = -14.453, learner_queue_size = 64, _tick = 8689, _time = 1.6548e+09)
[2022-06-09 18:39:26,670][root][INFO] - Step 56335360 @ 3069.5 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.793e+04, step = 56335360, mean_episode_return = 7.5298, mean_episode_step = 2283.0, total_loss = -25.526, pg_loss = -29.487, baseline_loss = 18.508, entropy_loss = -14.547, learner_queue_size = 64, _tick = 8692, _time = 1.6548e+09)
[2022-06-09 18:39:31,674][root][INFO] - Step 56350720 @ 3069.4 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.7935e+04, step = 56350720, mean_episode_return = 29.616, mean_episode_step = 2211.8, total_loss = -246.54, pg_loss = -240.88, baseline_loss = 9.0985, entropy_loss = -14.758, learner_queue_size = 64, _tick = 8694, _time = 1.6548e+09)
[2022-06-09 18:39:36,678][root][INFO] - Step 56366080 @ 3069.7 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.794e+04, step = 56366080, mean_episode_return = 20.892, mean_episode_step = 2240.9, total_loss = 173.77, pg_loss = 147.43, baseline_loss = 41.056, entropy_loss = -14.717, learner_queue_size = 64, _tick = 8697, _time = 1.6548e+09)
[2022-06-09 18:39:41,682][root][INFO] - Step 56381440 @ 3069.5 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 1.7945e+04, step = 56381440, mean_episode_return = 22.6, mean_episode_step = 1872.1, total_loss = -82.953, pg_loss = -86.602, baseline_loss = 18.386, entropy_loss = -14.737, learner_queue_size = 64, _tick = 8700, _time = 1.6548e+09)
[2022-06-09 18:39:46,686][root][INFO] - Step 56396800 @ 3069.6 SPS. Inference batcher size: 3. Learner queue size: 64. Other stats: (train_seconds = 1.795e+04, step = 56396800, mean_episode_return = -1.1855, mean_episode_step = 2101.9, total_loss = 364.01, pg_loss = 316.47, baseline_loss = 62.489, entropy_loss = -14.944, learner_queue_size = 64, _tick = 8703, _time = 1.6548e+09)
[2022-06-09 18:39:51,690][root][INFO] - Step 56412160 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.7955e+04, step = 56412160, mean_episode_return = None, mean_episode_step = 2091.0, total_loss = 322.53, pg_loss = 289.9, baseline_loss = 47.431, entropy_loss = -14.797, learner_queue_size = 64, _tick = 8705, _time = 1.6548e+09)
[2022-06-09 18:39:56,694][root][INFO] - Step 56427520 @ 3069.6 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.796e+04, step = 56427520, mean_episode_return = 38.805, mean_episode_step = 2150.6, total_loss = -3.4677, pg_loss = -25.307, baseline_loss = 36.7, entropy_loss = -14.86, learner_queue_size = 64, _tick = 8708, _time = 1.6548e+09)
[2022-06-09 18:40:01,698][root][INFO] - Step 56442880 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.7965e+04, step = 56442880, mean_episode_return = None, mean_episode_step = 2109.5, total_loss = 44.055, pg_loss = 34.126, baseline_loss = 24.73, entropy_loss = -14.801, learner_queue_size = 64, _tick = 8709, _time = 1.6548e+09)
[2022-06-09 18:40:06,702][root][INFO] - Step 56463360 @ 4092.8 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.797e+04, step = 56463360, mean_episode_return = None, mean_episode_step = 1750.3, total_loss = 291.83, pg_loss = 262.73, baseline_loss = 43.927, entropy_loss = -14.828, learner_queue_size = 64, _tick = 8712, _time = 1.6548e+09)
[2022-06-09 18:40:11,706][root][INFO] - Step 56478720 @ 3069.6 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 1.7975e+04, step = 56478720, mean_episode_return = 72.073, mean_episode_step = 2193.6, total_loss = 445.76, pg_loss = 389.82, baseline_loss = 70.817, entropy_loss = -14.881, learner_queue_size = 64, _tick = 8715, _time = 1.6548e+09)
[2022-06-09 18:40:16,710][root][INFO] - Step 56494080 @ 3069.5 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 1.798e+04, step = 56494080, mean_episode_return = None, mean_episode_step = 1770.9, total_loss = -56.028, pg_loss = -58.543, baseline_loss = 17.326, entropy_loss = -14.811, learner_queue_size = 64, _tick = 8717, _time = 1.6548e+09)
[2022-06-09 18:40:21,714][root][INFO] - Step 56509440 @ 3069.6 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 1.7985e+04, step = 56509440, mean_episode_return = 58.204, mean_episode_step = 1799.7, total_loss = 187.74, pg_loss = 157.59, baseline_loss = 44.879, entropy_loss = -14.733, learner_queue_size = 64, _tick = 8720, _time = 1.6548e+09)
[2022-06-09 18:40:26,718][root][INFO] - Step 56524800 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.799e+04, step = 56524800, mean_episode_return = 83.033, mean_episode_step = 1720.2, total_loss = 123.91, pg_loss = 100.61, baseline_loss = 38.03, entropy_loss = -14.735, learner_queue_size = 64, _tick = 8723, _time = 1.6548e+09)
[2022-06-09 18:40:31,722][root][INFO] - Step 56540160 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.7995e+04, step = 56540160, mean_episode_return = None, mean_episode_step = 2028.1, total_loss = 309.3, pg_loss = 263.49, baseline_loss = 60.41, entropy_loss = -14.6, learner_queue_size = 64, _tick = 8724, _time = 1.6548e+09)
[2022-06-09 18:40:36,726][root][INFO] - Step 56555520 @ 3069.6 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.8e+04, step = 56555520, mean_episode_return = 33.44, mean_episode_step = 1729.3, total_loss = 133.16, pg_loss = 109.42, baseline_loss = 38.361, entropy_loss = -14.619, learner_queue_size = 64, _tick = 8727, _time = 1.6548e+09)
[2022-06-09 18:40:41,730][root][INFO] - Step 56570880 @ 3069.5 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 1.8005e+04, step = 56570880, mean_episode_return = 127.04, mean_episode_step = 2087.5, total_loss = -103.08, pg_loss = -102.09, baseline_loss = 13.812, entropy_loss = -14.795, learner_queue_size = 64, _tick = 8729, _time = 1.6548e+09)
[2022-06-09 18:40:46,734][root][INFO] - Step 56591360 @ 4092.7 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 1.801e+04, step = 56591360, mean_episode_return = 104.34, mean_episode_step = 1795.3, total_loss = -144.89, pg_loss = -145.22, baseline_loss = 15.229, entropy_loss = -14.89, learner_queue_size = 64, _tick = 8732, _time = 1.6548e+09)
[2022-06-09 18:40:51,738][root][INFO] - Step 56606720 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.8015e+04, step = 56606720, mean_episode_return = 93.856, mean_episode_step = 1597.6, total_loss = 192.7, pg_loss = 154.16, baseline_loss = 53.46, entropy_loss = -14.918, learner_queue_size = 64, _tick = 8735, _time = 1.6548e+09)
[2022-06-09 18:40:56,742][root][INFO] - Step 56622080 @ 3069.5 SPS. Inference batcher size: 89. Learner queue size: 64. Other stats: (train_seconds = 1.802e+04, step = 56622080, mean_episode_return = 45.485, mean_episode_step = 1609.0, total_loss = 159.07, pg_loss = 152.51, baseline_loss = 21.331, entropy_loss = -14.768, learner_queue_size = 64, _tick = 8737, _time = 1.6548e+09)
[2022-06-09 18:41:01,746][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 18:41:01,971][root][INFO] - Step 56637440 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.8025e+04, step = 56637440, mean_episode_return = 43.961, mean_episode_step = 1744.5, total_loss = -48.779, pg_loss = -43.755, baseline_loss = 9.8024, entropy_loss = -14.827, learner_queue_size = 64, _tick = 8740, _time = 1.6548e+09)
[2022-06-09 18:41:06,974][root][INFO] - Step 56652800 @ 2938.1 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.803e+04, step = 56652800, mean_episode_return = None, mean_episode_step = 1835.0, total_loss = 363.59, pg_loss = 327.44, baseline_loss = 51.049, entropy_loss = -14.897, learner_queue_size = 64, _tick = 8741, _time = 1.6548e+09)
[2022-06-09 18:41:11,978][root][INFO] - Step 56668160 @ 3069.5 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 1.8035e+04, step = 56668160, mean_episode_return = 39.391, mean_episode_step = 1821.5, total_loss = 552.63, pg_loss = 472.27, baseline_loss = 95.216, entropy_loss = -14.855, learner_queue_size = 64, _tick = 8743, _time = 1.6548e+09)
[2022-06-09 18:41:16,982][root][INFO] - Step 56683520 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.804e+04, step = 56683520, mean_episode_return = 20.629, mean_episode_step = 1819.6, total_loss = -200.92, pg_loss = -198.46, baseline_loss = 12.295, entropy_loss = -14.755, learner_queue_size = 64, _tick = 8746, _time = 1.6548e+09)
[2022-06-09 18:41:21,986][root][INFO] - Step 56698880 @ 3069.6 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 1.8045e+04, step = 56698880, mean_episode_return = 79.18, mean_episode_step = 1766.2, total_loss = 82.263, pg_loss = 42.118, baseline_loss = 54.929, entropy_loss = -14.784, learner_queue_size = 64, _tick = 8748, _time = 1.6548e+09)
[2022-06-09 18:41:26,990][root][INFO] - Step 56714240 @ 3069.5 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 1.805e+04, step = 56714240, mean_episode_return = 75.125, mean_episode_step = 1687.4, total_loss = -52.065, pg_loss = -58.768, baseline_loss = 21.541, entropy_loss = -14.838, learner_queue_size = 64, _tick = 8751, _time = 1.6548e+09)
[2022-06-09 18:41:31,994][root][INFO] - Step 56734720 @ 4092.7 SPS. Inference batcher size: 79. Learner queue size: 64. Other stats: (train_seconds = 1.8055e+04, step = 56734720, mean_episode_return = 26.142, mean_episode_step = 1679.9, total_loss = 327.09, pg_loss = 293.22, baseline_loss = 48.672, entropy_loss = -14.807, learner_queue_size = 64, _tick = 8755, _time = 1.6548e+09)
[2022-06-09 18:41:36,998][root][INFO] - Step 56750080 @ 3069.6 SPS. Inference batcher size: 80. Learner queue size: 64. Other stats: (train_seconds = 1.806e+04, step = 56750080, mean_episode_return = -9.3102, mean_episode_step = 1758.3, total_loss = 301.46, pg_loss = 256.69, baseline_loss = 59.578, entropy_loss = -14.806, learner_queue_size = 64, _tick = 8758, _time = 1.6548e+09)
[2022-06-09 18:41:42,004][root][INFO] - Step 56765440 @ 3068.4 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 1.8065e+04, step = 56765440, mean_episode_return = 84.079, mean_episode_step = 1728.1, total_loss = 5.2281, pg_loss = -2.6899, baseline_loss = 22.657, entropy_loss = -14.739, learner_queue_size = 64, _tick = 8760, _time = 1.6548e+09)
[2022-06-09 18:41:47,009][root][INFO] - Step 56780800 @ 3068.6 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 1.807e+04, step = 56780800, mean_episode_return = -2.0105, mean_episode_step = 1639.8, total_loss = 93.835, pg_loss = 74.865, baseline_loss = 33.693, entropy_loss = -14.722, learner_queue_size = 64, _tick = 8763, _time = 1.6548e+09)
[2022-06-09 18:41:52,014][root][INFO] - Step 56796160 @ 3069.2 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.8075e+04, step = 56796160, mean_episode_return = None, mean_episode_step = 1815.3, total_loss = 812.63, pg_loss = 730.9, baseline_loss = 96.583, entropy_loss = -14.851, learner_queue_size = 64, _tick = 8765, _time = 1.6548e+09)
[2022-06-09 18:41:57,018][root][INFO] - Step 56811520 @ 3069.6 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.808e+04, step = 56811520, mean_episode_return = 33.09, mean_episode_step = 2050.9, total_loss = -75.071, pg_loss = -83.353, baseline_loss = 23.084, entropy_loss = -14.802, learner_queue_size = 64, _tick = 8768, _time = 1.6548e+09)
[2022-06-09 18:42:02,022][root][INFO] - Step 56826880 @ 3069.6 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.8085e+04, step = 56826880, mean_episode_return = 26.956, mean_episode_step = 1618.6, total_loss = 267.68, pg_loss = 229.8, baseline_loss = 52.606, entropy_loss = -14.722, learner_queue_size = 64, _tick = 8771, _time = 1.6548e+09)
[2022-06-09 18:42:07,026][root][INFO] - Step 56842240 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.809e+04, step = 56842240, mean_episode_return = None, mean_episode_step = 2372.0, total_loss = -132.94, pg_loss = -130.17, baseline_loss = 11.89, entropy_loss = -14.66, learner_queue_size = 64, _tick = 8771, _time = 1.6548e+09)
[2022-06-09 18:42:12,030][root][INFO] - Step 56857600 @ 3069.5 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.8095e+04, step = 56857600, mean_episode_return = None, mean_episode_step = 2175.9, total_loss = 193.96, pg_loss = 168.89, baseline_loss = 39.656, entropy_loss = -14.59, learner_queue_size = 64, _tick = 8772, _time = 1.6548e+09)
[2022-06-09 18:42:17,034][root][INFO] - Step 56878080 @ 4092.8 SPS. Inference batcher size: 67. Learner queue size: 64. Other stats: (train_seconds = 1.81e+04, step = 56878080, mean_episode_return = 33.233, mean_episode_step = 1766.4, total_loss = 51.861, pg_loss = 19.008, baseline_loss = 47.421, entropy_loss = -14.567, learner_queue_size = 64, _tick = 8776, _time = 1.6548e+09)
[2022-06-09 18:42:22,035][root][INFO] - Step 56893440 @ 3071.4 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 1.8105e+04, step = 56893440, mean_episode_return = 25.55, mean_episode_step = 1776.7, total_loss = 51.899, pg_loss = 32.562, baseline_loss = 33.952, entropy_loss = -14.615, learner_queue_size = 64, _tick = 8778, _time = 1.6548e+09)
[2022-06-09 18:42:27,041][root][INFO] - Step 56908800 @ 3068.2 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 1.811e+04, step = 56908800, mean_episode_return = None, mean_episode_step = 1891.5, total_loss = -34.383, pg_loss = -41.712, baseline_loss = 21.972, entropy_loss = -14.643, learner_queue_size = 64, _tick = 8779, _time = 1.6548e+09)
[2022-06-09 18:42:32,046][root][INFO] - Step 56924160 @ 3069.0 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 1.8115e+04, step = 56924160, mean_episode_return = 92.13, mean_episode_step = 1830.3, total_loss = -106.38, pg_loss = -117.33, baseline_loss = 25.784, entropy_loss = -14.831, learner_queue_size = 64, _tick = 8782, _time = 1.6548e+09)
[2022-06-09 18:42:37,050][root][INFO] - Step 56939520 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.812e+04, step = 56939520, mean_episode_return = None, mean_episode_step = 2031.1, total_loss = -12.552, pg_loss = -17.765, baseline_loss = 20.111, entropy_loss = -14.898, learner_queue_size = 64, _tick = 8783, _time = 1.6548e+09)
[2022-06-09 18:42:42,054][root][INFO] - Step 56954880 @ 3069.6 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.8125e+04, step = 56954880, mean_episode_return = 35.06, mean_episode_step = 1802.4, total_loss = 65.029, pg_loss = 48.917, baseline_loss = 31.075, entropy_loss = -14.963, learner_queue_size = 64, _tick = 8786, _time = 1.6548e+09)
[2022-06-09 18:42:47,058][root][INFO] - Step 56970240 @ 3069.6 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.813e+04, step = 56970240, mean_episode_return = 55.898, mean_episode_step = 2130.2, total_loss = -169.32, pg_loss = -168.59, baseline_loss = 14.319, entropy_loss = -15.049, learner_queue_size = 64, _tick = 8788, _time = 1.6548e+09)
[2022-06-09 18:42:52,062][root][INFO] - Step 56985600 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.8135e+04, step = 56985600, mean_episode_return = 3.6696, mean_episode_step = 1732.0, total_loss = 183.89, pg_loss = 165.02, baseline_loss = 33.931, entropy_loss = -15.054, learner_queue_size = 64, _tick = 8791, _time = 1.6548e+09)
[2022-06-09 18:42:57,066][root][INFO] - Step 57000960 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.814e+04, step = 57000960, mean_episode_return = 28.336, mean_episode_step = 2215.0, total_loss = -167.26, pg_loss = -177.05, baseline_loss = 24.91, entropy_loss = -15.119, learner_queue_size = 64, _tick = 8793, _time = 1.6548e+09)
[2022-06-09 18:43:02,070][root][INFO] - Step 57021440 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.8145e+04, step = 57021440, mean_episode_return = 88.832, mean_episode_step = 1938.4, total_loss = -16.297, pg_loss = -28.539, baseline_loss = 27.43, entropy_loss = -15.188, learner_queue_size = 64, _tick = 8797, _time = 1.6548e+09)
[2022-06-09 18:43:07,074][root][INFO] - Step 57036800 @ 3069.6 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 1.815e+04, step = 57036800, mean_episode_return = 40.72, mean_episode_step = 2081.1, total_loss = 391.86, pg_loss = 310.85, baseline_loss = 96.07, entropy_loss = -15.056, learner_queue_size = 64, _tick = 8799, _time = 1.6548e+09)
[2022-06-09 18:43:12,078][root][INFO] - Step 57052160 @ 3069.5 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 1.8155e+04, step = 57052160, mean_episode_return = 59.154, mean_episode_step = 1961.1, total_loss = 160.3, pg_loss = 130.46, baseline_loss = 44.817, entropy_loss = -14.981, learner_queue_size = 64, _tick = 8802, _time = 1.6548e+09)
[2022-06-09 18:43:17,082][root][INFO] - Step 57067520 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.816e+04, step = 57067520, mean_episode_return = None, mean_episode_step = 1962.6, total_loss = 183.38, pg_loss = 163.7, baseline_loss = 34.548, entropy_loss = -14.863, learner_queue_size = 64, _tick = 8804, _time = 1.6548e+09)
[2022-06-09 18:43:22,088][root][INFO] - Step 57082880 @ 3068.3 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.8165e+04, step = 57082880, mean_episode_return = None, mean_episode_step = 1791.1, total_loss = 161.01, pg_loss = 142.08, baseline_loss = 33.841, entropy_loss = -14.906, learner_queue_size = 64, _tick = 8806, _time = 1.6548e+09)
[2022-06-09 18:43:27,094][root][INFO] - Step 57098240 @ 3068.4 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 1.817e+04, step = 57098240, mean_episode_return = None, mean_episode_step = 2097.2, total_loss = 61.973, pg_loss = 41.99, baseline_loss = 34.732, entropy_loss = -14.749, learner_queue_size = 64, _tick = 8808, _time = 1.6548e+09)
[2022-06-09 18:43:32,098][root][INFO] - Step 57113600 @ 3069.5 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 1.8175e+04, step = 57113600, mean_episode_return = 47.532, mean_episode_step = 1883.2, total_loss = 7.4399, pg_loss = -5.9427, baseline_loss = 28.211, entropy_loss = -14.829, learner_queue_size = 64, _tick = 8810, _time = 1.6548e+09)
[2022-06-09 18:43:37,102][root][INFO] - Step 57128960 @ 3069.5 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 1.818e+04, step = 57128960, mean_episode_return = 77.886, mean_episode_step = 2113.9, total_loss = 83.808, pg_loss = 47.846, baseline_loss = 50.931, entropy_loss = -14.968, learner_queue_size = 64, _tick = 8812, _time = 1.6548e+09)
[2022-06-09 18:43:42,106][root][INFO] - Step 57144320 @ 3069.6 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 1.8185e+04, step = 57144320, mean_episode_return = 101.64, mean_episode_step = 2227.0, total_loss = 13.389, pg_loss = 7.363, baseline_loss = 20.936, entropy_loss = -14.909, learner_queue_size = 64, _tick = 8815, _time = 1.6548e+09)
[2022-06-09 18:43:47,110][root][INFO] - Step 57164800 @ 4092.7 SPS. Inference batcher size: 67. Learner queue size: 64. Other stats: (train_seconds = 1.819e+04, step = 57164800, mean_episode_return = 66.479, mean_episode_step = 1957.7, total_loss = 171.05, pg_loss = 130.48, baseline_loss = 55.407, entropy_loss = -14.829, learner_queue_size = 64, _tick = 8819, _time = 1.6548e+09)
[2022-06-09 18:43:52,114][root][INFO] - Step 57180160 @ 3069.5 SPS. Inference batcher size: 84. Learner queue size: 64. Other stats: (train_seconds = 1.8195e+04, step = 57180160, mean_episode_return = None, mean_episode_step = 2065.0, total_loss = -10.775, pg_loss = -17.254, baseline_loss = 21.245, entropy_loss = -14.767, learner_queue_size = 64, _tick = 8821, _time = 1.6548e+09)
[2022-06-09 18:43:57,118][root][INFO] - Step 57195520 @ 3069.5 SPS. Inference batcher size: 76. Learner queue size: 64. Other stats: (train_seconds = 1.82e+04, step = 57195520, mean_episode_return = 28.807, mean_episode_step = 1770.2, total_loss = 29.477, pg_loss = 9.0179, baseline_loss = 35.494, entropy_loss = -15.035, learner_queue_size = 64, _tick = 8823, _time = 1.6548e+09)
[2022-06-09 18:44:02,122][root][INFO] - Step 57210880 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.8205e+04, step = 57210880, mean_episode_return = None, mean_episode_step = 2142.7, total_loss = -97.776, pg_loss = -102.79, baseline_loss = 20.011, entropy_loss = -15.001, learner_queue_size = 64, _tick = 8825, _time = 1.6548e+09)
[2022-06-09 18:44:07,126][root][INFO] - Step 57226240 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.821e+04, step = 57226240, mean_episode_return = -11.975, mean_episode_step = 1872.9, total_loss = -26.58, pg_loss = -35.712, baseline_loss = 23.941, entropy_loss = -14.809, learner_queue_size = 64, _tick = 8827, _time = 1.6548e+09)
[2022-06-09 18:44:12,130][root][INFO] - Step 57241600 @ 3069.6 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.8215e+04, step = 57241600, mean_episode_return = 46.539, mean_episode_step = 1923.2, total_loss = 417.2, pg_loss = 282.6, baseline_loss = 149.42, entropy_loss = -14.819, learner_queue_size = 64, _tick = 8829, _time = 1.6548e+09)
[2022-06-09 18:44:17,134][root][INFO] - Step 57256960 @ 3069.6 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 1.822e+04, step = 57256960, mean_episode_return = 47.544, mean_episode_step = 2111.0, total_loss = 18.441, pg_loss = -6.0762, baseline_loss = 39.378, entropy_loss = -14.861, learner_queue_size = 64, _tick = 8832, _time = 1.6548e+09)
[2022-06-09 18:44:22,138][root][INFO] - Step 57272320 @ 3069.6 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.8225e+04, step = 57272320, mean_episode_return = None, mean_episode_step = 2046.2, total_loss = 67.428, pg_loss = 61.966, baseline_loss = 20.245, entropy_loss = -14.782, learner_queue_size = 64, _tick = 8834, _time = 1.6548e+09)
[2022-06-09 18:44:27,142][root][INFO] - Step 57287680 @ 3069.5 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 1.823e+04, step = 57287680, mean_episode_return = 81.489, mean_episode_step = 2152.4, total_loss = 201.31, pg_loss = 176.2, baseline_loss = 40.017, entropy_loss = -14.913, learner_queue_size = 64, _tick = 8836, _time = 1.6548e+09)
[2022-06-09 18:44:32,145][root][INFO] - Step 57303040 @ 3069.9 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.8235e+04, step = 57303040, mean_episode_return = 47.569, mean_episode_step = 1598.3, total_loss = -123.15, pg_loss = -139.27, baseline_loss = 30.941, entropy_loss = -14.822, learner_queue_size = 64, _tick = 8839, _time = 1.6548e+09)
[2022-06-09 18:44:37,150][root][INFO] - Step 57318400 @ 3069.3 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 1.824e+04, step = 57318400, mean_episode_return = None, mean_episode_step = 2159.5, total_loss = 1.9144, pg_loss = -0.581, baseline_loss = 17.3, entropy_loss = -14.804, learner_queue_size = 64, _tick = 8841, _time = 1.6548e+09)
[2022-06-09 18:44:42,155][root][INFO] - Step 57333760 @ 3068.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.8245e+04, step = 57333760, mean_episode_return = None, mean_episode_step = 1996.2, total_loss = 169.34, pg_loss = 110.15, baseline_loss = 74.05, entropy_loss = -14.86, learner_queue_size = 64, _tick = 8843, _time = 1.6548e+09)
[2022-06-09 18:44:47,158][root][INFO] - Step 57349120 @ 3070.4 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.825e+04, step = 57349120, mean_episode_return = 12.93, mean_episode_step = 2016.8, total_loss = 124.29, pg_loss = 102.92, baseline_loss = 36.357, entropy_loss = -14.983, learner_queue_size = 64, _tick = 8846, _time = 1.6548e+09)
[2022-06-09 18:44:52,162][root][INFO] - Step 57369600 @ 4092.8 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 1.8255e+04, step = 57369600, mean_episode_return = 62.905, mean_episode_step = 1947.3, total_loss = -110.67, pg_loss = -114.34, baseline_loss = 18.668, entropy_loss = -14.998, learner_queue_size = 64, _tick = 8850, _time = 1.6548e+09)
[2022-06-09 18:44:57,166][root][INFO] - Step 57384960 @ 3069.5 SPS. Inference batcher size: 89. Learner queue size: 64. Other stats: (train_seconds = 1.826e+04, step = 57384960, mean_episode_return = None, mean_episode_step = 2034.0, total_loss = 154.32, pg_loss = 120.13, baseline_loss = 49.115, entropy_loss = -14.919, learner_queue_size = 64, _tick = 8851, _time = 1.6548e+09)
[2022-06-09 18:45:02,170][root][INFO] - Step 57400320 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.8265e+04, step = 57400320, mean_episode_return = 2.4996, mean_episode_step = 1656.6, total_loss = 35.073, pg_loss = 21.125, baseline_loss = 28.743, entropy_loss = -14.795, learner_queue_size = 64, _tick = 8854, _time = 1.6548e+09)
[2022-06-09 18:45:07,174][root][INFO] - Step 57415680 @ 3069.5 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 1.827e+04, step = 57415680, mean_episode_return = 84.033, mean_episode_step = 2004.5, total_loss = 142.97, pg_loss = 125.03, baseline_loss = 32.827, entropy_loss = -14.887, learner_queue_size = 64, _tick = 8857, _time = 1.6548e+09)
[2022-06-09 18:45:12,178][root][INFO] - Step 57431040 @ 3069.5 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.8275e+04, step = 57431040, mean_episode_return = 88.973, mean_episode_step = 2061.3, total_loss = 40.165, pg_loss = 18.89, baseline_loss = 36.187, entropy_loss = -14.912, learner_queue_size = 64, _tick = 8860, _time = 1.6548e+09)
[2022-06-09 18:45:17,182][root][INFO] - Step 57446400 @ 3069.5 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 1.828e+04, step = 57446400, mean_episode_return = 31.101, mean_episode_step = 1939.5, total_loss = -143.84, pg_loss = -154.3, baseline_loss = 25.329, entropy_loss = -14.868, learner_queue_size = 64, _tick = 8863, _time = 1.6548e+09)
[2022-06-09 18:45:22,186][root][INFO] - Step 57461760 @ 3069.6 SPS. Inference batcher size: 6. Learner queue size: 64. Other stats: (train_seconds = 1.8285e+04, step = 57461760, mean_episode_return = 54.963, mean_episode_step = 1911.9, total_loss = -75.747, pg_loss = -82.992, baseline_loss = 22.083, entropy_loss = -14.838, learner_queue_size = 64, _tick = 8866, _time = 1.6548e+09)
[2022-06-09 18:45:27,190][root][INFO] - Step 57482240 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 1.829e+04, step = 57482240, mean_episode_return = 4.3998, mean_episode_step = 2151.9, total_loss = -134.94, pg_loss = -136.56, baseline_loss = 16.468, entropy_loss = -14.841, learner_queue_size = 64, _tick = 8869, _time = 1.6548e+09)
[2022-06-09 18:45:32,194][root][INFO] - Step 57497600 @ 3069.6 SPS. Inference batcher size: 77. Learner queue size: 64. Other stats: (train_seconds = 1.8295e+04, step = 57497600, mean_episode_return = None, mean_episode_step = 1960.8, total_loss = -140.22, pg_loss = -133.06, baseline_loss = 7.6415, entropy_loss = -14.797, learner_queue_size = 64, _tick = 8871, _time = 1.6548e+09)
[2022-06-09 18:45:37,198][root][INFO] - Step 57512960 @ 3069.5 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 1.83e+04, step = 57512960, mean_episode_return = None, mean_episode_step = 1987.3, total_loss = 650.29, pg_loss = 417.51, baseline_loss = 247.52, entropy_loss = -14.747, learner_queue_size = 64, _tick = 8873, _time = 1.6548e+09)
[2022-06-09 18:45:42,202][root][INFO] - Step 57528320 @ 3069.6 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1.8305e+04, step = 57528320, mean_episode_return = 48.51, mean_episode_step = 1443.4, total_loss = 64.337, pg_loss = 52.089, baseline_loss = 26.992, entropy_loss = -14.744, learner_queue_size = 64, _tick = 8876, _time = 1.6548e+09)
[2022-06-09 18:45:47,206][root][INFO] - Step 57543680 @ 3069.5 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 1.831e+04, step = 57543680, mean_episode_return = 35.717, mean_episode_step = 1803.1, total_loss = 195.05, pg_loss = 159.58, baseline_loss = 50.119, entropy_loss = -14.647, learner_queue_size = 64, _tick = 8879, _time = 1.6548e+09)
[2022-06-09 18:45:52,210][root][INFO] - Step 57559040 @ 3069.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.8315e+04, step = 57559040, mean_episode_return = None, mean_episode_step = 1830.3, total_loss = 159.45, pg_loss = 127.49, baseline_loss = 46.608, entropy_loss = -14.651, learner_queue_size = 64, _tick = 8881, _time = 1.6548e+09)
[2022-06-09 18:45:57,214][root][INFO] - Step 57574400 @ 3069.6 SPS. Inference batcher size: 5. Learner queue size: 64. Other stats: (train_seconds = 1.832e+04, step = 57574400, mean_episode_return = 14.94, mean_episode_step = 1678.6, total_loss = 105.51, pg_loss = 86.829, baseline_loss = 33.513, entropy_loss = -14.831, learner_queue_size = 64, _tick = 8883, _time = 1.6548e+09)
[2022-06-09 18:46:02,218][root][INFO] - Step 57589760 @ 3069.5 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 1.8325e+04, step = 57589760, mean_episode_return = 56.095, mean_episode_step = 1621.6, total_loss = -25.663, pg_loss = -50.88, baseline_loss = 40.095, entropy_loss = -14.879, learner_queue_size = 64, _tick = 8886, _time = 1.6548e+09)
[2022-06-09 18:46:07,222][root][INFO] - Step 57605120 @ 3069.6 SPS. Inference batcher size: 14. Learner queue size: 64. Other stats: (train_seconds = 1.833e+04, step = 57605120, mean_episode_return = 22.676, mean_episode_step = 2083.9, total_loss = 67.316, pg_loss = 51.468, baseline_loss = 30.797, entropy_loss = -14.949, learner_queue_size = 64, _tick = 8889, _time = 1.6548e+09)
[2022-06-09 18:46:12,226][root][INFO] - Step 57620480 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.8335e+04, step = 57620480, mean_episode_return = 100.26, mean_episode_step = 1915.5, total_loss = 14.167, pg_loss = -4.465, baseline_loss = 33.512, entropy_loss = -14.88, learner_queue_size = 64, _tick = 8892, _time = 1.6548e+09)
[2022-06-09 18:46:17,230][root][INFO] - Step 57635840 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.834e+04, step = 57635840, mean_episode_return = 5.6196, mean_episode_step = 1946.7, total_loss = 134.29, pg_loss = 117.05, baseline_loss = 31.953, entropy_loss = -14.706, learner_queue_size = 64, _tick = 8894, _time = 1.6548e+09)
[2022-06-09 18:46:22,234][root][INFO] - Step 57651200 @ 3069.6 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 1.8345e+04, step = 57651200, mean_episode_return = 75.11, mean_episode_step = 2057.2, total_loss = -86.353, pg_loss = -86.236, baseline_loss = 14.419, entropy_loss = -14.536, learner_queue_size = 64, _tick = 8897, _time = 1.6548e+09)
[2022-06-09 18:46:27,238][root][INFO] - Step 57671680 @ 4092.8 SPS. Inference batcher size: 76. Learner queue size: 64. Other stats: (train_seconds = 1.835e+04, step = 57671680, mean_episode_return = 59.819, mean_episode_step = 1709.6, total_loss = 260.67, pg_loss = 208.83, baseline_loss = 66.691, entropy_loss = -14.852, learner_queue_size = 64, _tick = 8901, _time = 1.6548e+09)
[2022-06-09 18:46:32,242][root][INFO] - Step 57687040 @ 3069.5 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 1.8355e+04, step = 57687040, mean_episode_return = 173.02, mean_episode_step = 1852.6, total_loss = -108.43, pg_loss = -104.31, baseline_loss = 10.762, entropy_loss = -14.883, learner_queue_size = 64, _tick = 8904, _time = 1.6548e+09)
[2022-06-09 18:46:37,246][root][INFO] - Step 57702400 @ 3069.5 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 1.836e+04, step = 57702400, mean_episode_return = 59.133, mean_episode_step = 1724.5, total_loss = 351.34, pg_loss = 293.17, baseline_loss = 73.117, entropy_loss = -14.945, learner_queue_size = 64, _tick = 8906, _time = 1.6548e+09)
[2022-06-09 18:46:42,260][root][INFO] - Step 57717760 @ 3063.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.8365e+04, step = 57717760, mean_episode_return = 40.42, mean_episode_step = 1664.6, total_loss = -150.18, pg_loss = -157.83, baseline_loss = 22.516, entropy_loss = -14.859, learner_queue_size = 64, _tick = 8909, _time = 1.6548e+09)
[2022-06-09 18:46:47,262][root][INFO] - Step 57733120 @ 3070.7 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.837e+04, step = 57733120, mean_episode_return = 87.103, mean_episode_step = 2029.6, total_loss = -191.54, pg_loss = -201.71, baseline_loss = 24.978, entropy_loss = -14.812, learner_queue_size = 64, _tick = 8912, _time = 1.6548e+09)
[2022-06-09 18:46:52,266][root][INFO] - Step 57748480 @ 3069.6 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 1.8375e+04, step = 57748480, mean_episode_return = -23.501, mean_episode_step = 1639.4, total_loss = 85.894, pg_loss = 65.342, baseline_loss = 35.389, entropy_loss = -14.837, learner_queue_size = 64, _tick = 8915, _time = 1.6548e+09)
[2022-06-09 18:46:57,270][root][INFO] - Step 57763840 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.838e+04, step = 57763840, mean_episode_return = -4.9471, mean_episode_step = 1823.5, total_loss = -274.51, pg_loss = -275.25, baseline_loss = 15.578, entropy_loss = -14.837, learner_queue_size = 64, _tick = 8918, _time = 1.6548e+09)
[2022-06-09 18:47:02,276][root][INFO] - Step 57779200 @ 3068.3 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.8385e+04, step = 57779200, mean_episode_return = 56.256, mean_episode_step = 1835.1, total_loss = -118.67, pg_loss = -129.56, baseline_loss = 25.7, entropy_loss = -14.807, learner_queue_size = 64, _tick = 8921, _time = 1.6548e+09)
[2022-06-09 18:47:07,278][root][INFO] - Step 57799680 @ 4094.4 SPS. Inference batcher size: 12. Learner queue size: 64. Other stats: (train_seconds = 1.839e+04, step = 57799680, mean_episode_return = 61.545, mean_episode_step = 1609.0, total_loss = -258.31, pg_loss = -271.24, baseline_loss = 27.658, entropy_loss = -14.731, learner_queue_size = 64, _tick = 8925, _time = 1.6548e+09)
[2022-06-09 18:47:12,282][root][INFO] - Step 57815040 @ 3069.3 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.8395e+04, step = 57815040, mean_episode_return = -2.0401, mean_episode_step = 1847.3, total_loss = -124.61, pg_loss = -129.05, baseline_loss = 19.039, entropy_loss = -14.601, learner_queue_size = 64, _tick = 8928, _time = 1.6548e+09)
[2022-06-09 18:47:17,286][root][INFO] - Step 57830400 @ 3069.8 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 1.84e+04, step = 57830400, mean_episode_return = 23.667, mean_episode_step = 1969.5, total_loss = 55.256, pg_loss = 26.911, baseline_loss = 43.043, entropy_loss = -14.697, learner_queue_size = 64, _tick = 8931, _time = 1.6548e+09)
[2022-06-09 18:47:22,306][root][INFO] - Step 57845760 @ 3059.8 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 1.8405e+04, step = 57845760, mean_episode_return = 20.686, mean_episode_step = 1671.6, total_loss = 96.271, pg_loss = 52.605, baseline_loss = 58.28, entropy_loss = -14.614, learner_queue_size = 64, _tick = 8934, _time = 1.6548e+09)
[2022-06-09 18:47:27,310][root][INFO] - Step 57861120 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.841e+04, step = 57861120, mean_episode_return = 43.859, mean_episode_step = 1711.2, total_loss = -139.88, pg_loss = -163.77, baseline_loss = 38.646, entropy_loss = -14.756, learner_queue_size = 64, _tick = 8937, _time = 1.6548e+09)
[2022-06-09 18:47:32,316][root][INFO] - Step 57876480 @ 3068.4 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.8415e+04, step = 57876480, mean_episode_return = None, mean_episode_step = 2036.0, total_loss = -69.47, pg_loss = -69.088, baseline_loss = 14.28, entropy_loss = -14.662, learner_queue_size = 64, _tick = 8939, _time = 1.6548e+09)
[2022-06-09 18:47:37,318][root][INFO] - Step 57891840 @ 3070.6 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.842e+04, step = 57891840, mean_episode_return = 46.737, mean_episode_step = 1709.1, total_loss = 66.656, pg_loss = 39.392, baseline_loss = 41.947, entropy_loss = -14.683, learner_queue_size = 64, _tick = 8941, _time = 1.6548e+09)
[2022-06-09 18:47:42,324][root][INFO] - Step 57907200 @ 3068.3 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.8425e+04, step = 57907200, mean_episode_return = 60.972, mean_episode_step = 1900.4, total_loss = 42.97, pg_loss = 26.644, baseline_loss = 30.764, entropy_loss = -14.439, learner_queue_size = 64, _tick = 8944, _time = 1.6548e+09)
[2022-06-09 18:47:47,330][root][INFO] - Step 57922560 @ 3068.3 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.843e+04, step = 57922560, mean_episode_return = None, mean_episode_step = 1549.3, total_loss = -90.597, pg_loss = -87.89, baseline_loss = 11.472, entropy_loss = -14.178, learner_queue_size = 64, _tick = 8946, _time = 1.6548e+09)
[2022-06-09 18:47:52,334][root][INFO] - Step 57937920 @ 3069.7 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.8435e+04, step = 57937920, mean_episode_return = 56.537, mean_episode_step = 1988.4, total_loss = 126.55, pg_loss = 97.661, baseline_loss = 43.245, entropy_loss = -14.352, learner_queue_size = 64, _tick = 8949, _time = 1.6548e+09)
[2022-06-09 18:47:57,338][root][INFO] - Step 57958400 @ 4092.8 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.844e+04, step = 57958400, mean_episode_return = 49.5, mean_episode_step = 1551.9, total_loss = 270.45, pg_loss = 226.23, baseline_loss = 58.635, entropy_loss = -14.415, learner_queue_size = 64, _tick = 8953, _time = 1.6548e+09)
[2022-06-09 18:48:02,342][root][INFO] - Step 57973760 @ 3069.4 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.8445e+04, step = 57973760, mean_episode_return = 44.606, mean_episode_step = 1699.6, total_loss = -28.581, pg_loss = -59.856, baseline_loss = 45.767, entropy_loss = -14.492, learner_queue_size = 64, _tick = 8956, _time = 1.6548e+09)
[2022-06-09 18:48:07,346][root][INFO] - Step 57989120 @ 3069.7 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 1.845e+04, step = 57989120, mean_episode_return = 63.023, mean_episode_step = 1646.2, total_loss = 97.584, pg_loss = 69.435, baseline_loss = 42.804, entropy_loss = -14.655, learner_queue_size = 64, _tick = 8958, _time = 1.6548e+09)
[2022-06-09 18:48:12,350][root][INFO] - Step 58004480 @ 3069.5 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 1.8455e+04, step = 58004480, mean_episode_return = 49.199, mean_episode_step = 1667.0, total_loss = 139.4, pg_loss = 110.26, baseline_loss = 43.865, entropy_loss = -14.728, learner_queue_size = 64, _tick = 8961, _time = 1.6548e+09)
[2022-06-09 18:48:17,354][root][INFO] - Step 58019840 @ 3069.6 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.846e+04, step = 58019840, mean_episode_return = 28.837, mean_episode_step = 1874.5, total_loss = -263.52, pg_loss = -270.09, baseline_loss = 21.11, entropy_loss = -14.549, learner_queue_size = 64, _tick = 8964, _time = 1.6548e+09)
[2022-06-09 18:48:22,358][root][INFO] - Step 58035200 @ 3069.8 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 1.8465e+04, step = 58035200, mean_episode_return = 37.798, mean_episode_step = 1854.5, total_loss = -282.06, pg_loss = -277.6, baseline_loss = 10.177, entropy_loss = -14.634, learner_queue_size = 64, _tick = 8966, _time = 1.6548e+09)
[2022-06-09 18:48:27,362][root][INFO] - Step 58050560 @ 3069.3 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 1.847e+04, step = 58050560, mean_episode_return = 33.376, mean_episode_step = 1784.2, total_loss = -247.35, pg_loss = -247.02, baseline_loss = 14.451, entropy_loss = -14.786, learner_queue_size = 64, _tick = 8969, _time = 1.6548e+09)
[2022-06-09 18:48:32,366][root][INFO] - Step 58065920 @ 3069.6 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 1.8475e+04, step = 58065920, mean_episode_return = None, mean_episode_step = 1782.6, total_loss = 198.36, pg_loss = 178.13, baseline_loss = 34.988, entropy_loss = -14.762, learner_queue_size = 64, _tick = 8970, _time = 1.6548e+09)
[2022-06-09 18:48:37,370][root][INFO] - Step 58081280 @ 3069.5 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.848e+04, step = 58081280, mean_episode_return = 37.682, mean_episode_step = 1587.0, total_loss = -70.294, pg_loss = -84.288, baseline_loss = 28.742, entropy_loss = -14.748, learner_queue_size = 64, _tick = 8972, _time = 1.6548e+09)
[2022-06-09 18:48:42,374][root][INFO] - Step 58096640 @ 3069.5 SPS. Inference batcher size: 11. Learner queue size: 64. Other stats: (train_seconds = 1.8485e+04, step = 58096640, mean_episode_return = 14.277, mean_episode_step = 1924.7, total_loss = -188.03, pg_loss = -191.44, baseline_loss = 18.305, entropy_loss = -14.899, learner_queue_size = 64, _tick = 8975, _time = 1.6548e+09)
[2022-06-09 18:48:47,378][root][INFO] - Step 58112000 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.849e+04, step = 58112000, mean_episode_return = 48.512, mean_episode_step = 1649.8, total_loss = 434.27, pg_loss = 347.42, baseline_loss = 101.79, entropy_loss = -14.937, learner_queue_size = 64, _tick = 8978, _time = 1.6548e+09)
[2022-06-09 18:48:52,382][root][INFO] - Step 58127360 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.8495e+04, step = 58127360, mean_episode_return = 64.514, mean_episode_step = 1542.2, total_loss = 91.256, pg_loss = 71.521, baseline_loss = 34.738, entropy_loss = -15.003, learner_queue_size = 64, _tick = 8980, _time = 1.6548e+09)
[2022-06-09 18:48:57,386][root][INFO] - Step 58142720 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.85e+04, step = 58142720, mean_episode_return = 117.13, mean_episode_step = 1661.0, total_loss = 400.82, pg_loss = 325.11, baseline_loss = 90.659, entropy_loss = -14.949, learner_queue_size = 64, _tick = 8983, _time = 1.6548e+09)
[2022-06-09 18:49:02,388][root][INFO] - Step 58158080 @ 3071.0 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 1.8505e+04, step = 58158080, mean_episode_return = 30.07, mean_episode_step = 1841.6, total_loss = 55.433, pg_loss = 42.321, baseline_loss = 28.116, entropy_loss = -15.004, learner_queue_size = 64, _tick = 8985, _time = 1.6548e+09)
[2022-06-09 18:49:07,390][root][INFO] - Step 58178560 @ 4094.1 SPS. Inference batcher size: 0. Learner queue size: 4. Other stats: (train_seconds = 1.851e+04, step = 58178560, mean_episode_return = 1.361, mean_episode_step = 1463.3, total_loss = 9.6197, pg_loss = -8.527, baseline_loss = 33.196, entropy_loss = -15.05, learner_queue_size = 64, _tick = 8989, _time = 1.6548e+09)
[2022-06-09 18:49:12,394][root][INFO] - Step 58193920 @ 3069.5 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 1.8515e+04, step = 58193920, mean_episode_return = 52.482, mean_episode_step = 1625.2, total_loss = 256.63, pg_loss = 222.55, baseline_loss = 49.282, entropy_loss = -15.204, learner_queue_size = 64, _tick = 8992, _time = 1.6548e+09)
[2022-06-09 18:49:17,398][root][INFO] - Step 58209280 @ 3069.5 SPS. Inference batcher size: 90. Learner queue size: 64. Other stats: (train_seconds = 1.852e+04, step = 58209280, mean_episode_return = 10.026, mean_episode_step = 1824.7, total_loss = 290.72, pg_loss = 240.01, baseline_loss = 65.984, entropy_loss = -15.266, learner_queue_size = 64, _tick = 8995, _time = 1.6548e+09)
[2022-06-09 18:49:22,402][root][INFO] - Step 58224640 @ 3069.6 SPS. Inference batcher size: 73. Learner queue size: 64. Other stats: (train_seconds = 1.8525e+04, step = 58224640, mean_episode_return = 22.82, mean_episode_step = 1223.3, total_loss = 227.65, pg_loss = 192.67, baseline_loss = 50.366, entropy_loss = -15.384, learner_queue_size = 64, _tick = 8998, _time = 1.6548e+09)
[2022-06-09 18:49:27,406][root][INFO] - Step 58240000 @ 3069.5 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 1.853e+04, step = 58240000, mean_episode_return = 30.85, mean_episode_step = 1337.2, total_loss = 375.54, pg_loss = 321.37, baseline_loss = 69.429, entropy_loss = -15.259, learner_queue_size = 64, _tick = 9001, _time = 1.6548e+09)
[2022-06-09 18:49:32,420][root][INFO] - Step 58255360 @ 3063.3 SPS. Inference batcher size: 67. Learner queue size: 64. Other stats: (train_seconds = 1.8535e+04, step = 58255360, mean_episode_return = 106.34, mean_episode_step = 1866.5, total_loss = -112.82, pg_loss = -122.95, baseline_loss = 25.271, entropy_loss = -15.137, learner_queue_size = 64, _tick = 9004, _time = 1.6548e+09)
[2022-06-09 18:49:37,426][root][INFO] - Step 58270720 @ 3068.4 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.854e+04, step = 58270720, mean_episode_return = 30.39, mean_episode_step = 1790.3, total_loss = 270.03, pg_loss = 225.87, baseline_loss = 59.16, entropy_loss = -15.004, learner_queue_size = 64, _tick = 9007, _time = 1.6548e+09)
[2022-06-09 18:49:42,430][root][INFO] - Step 58286080 @ 3069.6 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 1.8545e+04, step = 58286080, mean_episode_return = None, mean_episode_step = 1750.5, total_loss = 170.2, pg_loss = 152.39, baseline_loss = 32.712, entropy_loss = -14.904, learner_queue_size = 64, _tick = 9007, _time = 1.6548e+09)
[2022-06-09 18:49:47,434][root][INFO] - Step 58301440 @ 3069.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.855e+04, step = 58301440, mean_episode_return = 45.089, mean_episode_step = 1847.2, total_loss = -178.41, pg_loss = -192.97, baseline_loss = 29.515, entropy_loss = -14.955, learner_queue_size = 64, _tick = 9009, _time = 1.6548e+09)
[2022-06-09 18:49:52,438][root][INFO] - Step 58321920 @ 4092.7 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.8555e+04, step = 58321920, mean_episode_return = 31.972, mean_episode_step = 1464.3, total_loss = 37.566, pg_loss = 16.475, baseline_loss = 36.044, entropy_loss = -14.953, learner_queue_size = 64, _tick = 9013, _time = 1.6548e+09)
[2022-06-09 18:49:57,442][root][INFO] - Step 58337280 @ 3069.5 SPS. Inference batcher size: 72. Learner queue size: 64. Other stats: (train_seconds = 1.856e+04, step = 58337280, mean_episode_return = None, mean_episode_step = 1856.5, total_loss = 251.66, pg_loss = 219.03, baseline_loss = 47.617, entropy_loss = -14.985, learner_queue_size = 64, _tick = 9015, _time = 1.6548e+09)
[2022-06-09 18:50:02,446][root][INFO] - Step 58352640 @ 3069.5 SPS. Inference batcher size: 80. Learner queue size: 64. Other stats: (train_seconds = 1.8565e+04, step = 58352640, mean_episode_return = 62.601, mean_episode_step = 1496.5, total_loss = 278.29, pg_loss = 229.42, baseline_loss = 63.903, entropy_loss = -15.031, learner_queue_size = 64, _tick = 9017, _time = 1.6548e+09)
[2022-06-09 18:50:07,450][root][INFO] - Step 58368000 @ 3069.5 SPS. Inference batcher size: 86. Learner queue size: 64. Other stats: (train_seconds = 1.857e+04, step = 58368000, mean_episode_return = 39.075, mean_episode_step = 1551.1, total_loss = -63.95, pg_loss = -83.185, baseline_loss = 34.288, entropy_loss = -15.053, learner_queue_size = 64, _tick = 9020, _time = 1.6548e+09)
[2022-06-09 18:50:12,454][root][INFO] - Step 58383360 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.8575e+04, step = 58383360, mean_episode_return = 109.87, mean_episode_step = 1714.7, total_loss = -84.691, pg_loss = -104.96, baseline_loss = 35.167, entropy_loss = -14.895, learner_queue_size = 64, _tick = 9022, _time = 1.6548e+09)
[2022-06-09 18:50:17,458][root][INFO] - Step 58398720 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.858e+04, step = 58398720, mean_episode_return = 108.66, mean_episode_step = 1346.6, total_loss = 27.59, pg_loss = 4.9271, baseline_loss = 37.581, entropy_loss = -14.918, learner_queue_size = 64, _tick = 9025, _time = 1.6548e+09)
[2022-06-09 18:50:22,462][root][INFO] - Step 58414080 @ 3069.6 SPS. Inference batcher size: 2. Learner queue size: 64. Other stats: (train_seconds = 1.8585e+04, step = 58414080, mean_episode_return = None, mean_episode_step = 1822.5, total_loss = 207.17, pg_loss = 182.72, baseline_loss = 39.304, entropy_loss = -14.855, learner_queue_size = 64, _tick = 9027, _time = 1.6548e+09)
[2022-06-09 18:50:27,466][root][INFO] - Step 58429440 @ 3069.6 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.859e+04, step = 58429440, mean_episode_return = 41.04, mean_episode_step = 1893.4, total_loss = -82.378, pg_loss = -95.09, baseline_loss = 27.526, entropy_loss = -14.814, learner_queue_size = 64, _tick = 9030, _time = 1.6548e+09)
[2022-06-09 18:50:32,472][root][INFO] - Step 58444800 @ 3068.1 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.8595e+04, step = 58444800, mean_episode_return = 48.07, mean_episode_step = 1823.0, total_loss = -249.87, pg_loss = -247.06, baseline_loss = 11.795, entropy_loss = -14.599, learner_queue_size = 64, _tick = 9033, _time = 1.6548e+09)
[2022-06-09 18:50:37,478][root][INFO] - Step 58465280 @ 4091.4 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 1.86e+04, step = 58465280, mean_episode_return = 16.12, mean_episode_step = 1683.3, total_loss = 39.836, pg_loss = 22.032, baseline_loss = 32.366, entropy_loss = -14.563, learner_queue_size = 64, _tick = 9037, _time = 1.6548e+09)
[2022-06-09 18:50:42,482][root][INFO] - Step 58480640 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.8605e+04, step = 58480640, mean_episode_return = None, mean_episode_step = 1819.5, total_loss = 516.37, pg_loss = 446.06, baseline_loss = 84.773, entropy_loss = -14.469, learner_queue_size = 64, _tick = 9039, _time = 1.6548e+09)
[2022-06-09 18:50:47,486][root][INFO] - Step 58496000 @ 3069.6 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 1.861e+04, step = 58496000, mean_episode_return = 83.834, mean_episode_step = 1739.1, total_loss = 44.25, pg_loss = 27.096, baseline_loss = 31.685, entropy_loss = -14.531, learner_queue_size = 64, _tick = 9041, _time = 1.6548e+09)
[2022-06-09 18:50:52,492][root][INFO] - Step 58511360 @ 3068.3 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 1.8615e+04, step = 58511360, mean_episode_return = 39.784, mean_episode_step = 1853.0, total_loss = -290.03, pg_loss = -294.4, baseline_loss = 19.256, entropy_loss = -14.882, learner_queue_size = 64, _tick = 9043, _time = 1.6548e+09)
[2022-06-09 18:50:57,498][root][INFO] - Step 58526720 @ 3068.4 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 1.862e+04, step = 58526720, mean_episode_return = None, mean_episode_step = 1634.8, total_loss = -41.581, pg_loss = -52.357, baseline_loss = 25.775, entropy_loss = -14.999, learner_queue_size = 64, _tick = 9045, _time = 1.6548e+09)
[2022-06-09 18:51:02,502][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 18:51:02,716][root][INFO] - Step 58542080 @ 3069.5 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 1.8625e+04, step = 58542080, mean_episode_return = 51.797, mean_episode_step = 2216.0, total_loss = -406.53, pg_loss = -405.88, baseline_loss = 14.419, entropy_loss = -15.071, learner_queue_size = 64, _tick = 9047, _time = 1.6548e+09)
[2022-06-09 18:51:07,722][root][INFO] - Step 58557440 @ 2942.6 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.8631e+04, step = 58557440, mean_episode_return = 54.935, mean_episode_step = 1718.5, total_loss = -102.6, pg_loss = -116.48, baseline_loss = 29.007, entropy_loss = -15.122, learner_queue_size = 64, _tick = 9050, _time = 1.6548e+09)
[2022-06-09 18:51:12,726][root][INFO] - Step 58572800 @ 3069.4 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.8636e+04, step = 58572800, mean_episode_return = 67.109, mean_episode_step = 1439.7, total_loss = -13.53, pg_loss = -24.634, baseline_loss = 26.138, entropy_loss = -15.035, learner_queue_size = 64, _tick = 9053, _time = 1.6548e+09)
[2022-06-09 18:51:17,730][root][INFO] - Step 58588160 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.8641e+04, step = 58588160, mean_episode_return = 58.803, mean_episode_step = 1644.8, total_loss = 148.1, pg_loss = 124.76, baseline_loss = 38.481, entropy_loss = -15.139, learner_queue_size = 64, _tick = 9056, _time = 1.6548e+09)
[2022-06-09 18:51:22,734][root][INFO] - Step 58603520 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.8646e+04, step = 58603520, mean_episode_return = 32.261, mean_episode_step = 1843.4, total_loss = 109.89, pg_loss = 73.728, baseline_loss = 51.274, entropy_loss = -15.115, learner_queue_size = 64, _tick = 9058, _time = 1.6548e+09)
[2022-06-09 18:51:27,738][root][INFO] - Step 58618880 @ 3069.5 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 1.8651e+04, step = 58618880, mean_episode_return = 70.406, mean_episode_step = 1637.3, total_loss = -20.325, pg_loss = -47.352, baseline_loss = 42.295, entropy_loss = -15.268, learner_queue_size = 64, _tick = 9061, _time = 1.6548e+09)
[2022-06-09 18:51:32,742][root][INFO] - Step 58639360 @ 4092.8 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 1.8656e+04, step = 58639360, mean_episode_return = None, mean_episode_step = 1768.8, total_loss = -41.478, pg_loss = -41.987, baseline_loss = 15.859, entropy_loss = -15.349, learner_queue_size = 64, _tick = 9064, _time = 1.6548e+09)
[2022-06-09 18:51:37,746][root][INFO] - Step 58654720 @ 3069.5 SPS. Inference batcher size: 91. Learner queue size: 64. Other stats: (train_seconds = 1.8661e+04, step = 58654720, mean_episode_return = 36.3, mean_episode_step = 1855.3, total_loss = 123.89, pg_loss = 99.737, baseline_loss = 39.394, entropy_loss = -15.237, learner_queue_size = 64, _tick = 9067, _time = 1.6548e+09)
[2022-06-09 18:51:42,750][root][INFO] - Step 58670080 @ 3069.6 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 1.8666e+04, step = 58670080, mean_episode_return = 23.956, mean_episode_step = 1792.6, total_loss = -181.57, pg_loss = -190.92, baseline_loss = 24.453, entropy_loss = -15.11, learner_queue_size = 64, _tick = 9069, _time = 1.6548e+09)
[2022-06-09 18:51:47,754][root][INFO] - Step 58685440 @ 3069.3 SPS. Inference batcher size: 7. Learner queue size: 64. Other stats: (train_seconds = 1.8671e+04, step = 58685440, mean_episode_return = 22.416, mean_episode_step = 1765.9, total_loss = -121.81, pg_loss = -122.92, baseline_loss = 16.046, entropy_loss = -14.936, learner_queue_size = 64, _tick = 9072, _time = 1.6548e+09)
[2022-06-09 18:51:52,758][root][INFO] - Step 58700800 @ 3069.8 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 1.8676e+04, step = 58700800, mean_episode_return = 73.67, mean_episode_step = 1898.5, total_loss = -38.515, pg_loss = -56.05, baseline_loss = 32.483, entropy_loss = -14.948, learner_queue_size = 64, _tick = 9074, _time = 1.6548e+09)
[2022-06-09 18:51:57,762][root][INFO] - Step 58716160 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.8681e+04, step = 58716160, mean_episode_return = 39.719, mean_episode_step = 1695.3, total_loss = 97.058, pg_loss = 74.307, baseline_loss = 37.543, entropy_loss = -14.791, learner_queue_size = 64, _tick = 9077, _time = 1.6548e+09)
[2022-06-09 18:52:02,766][root][INFO] - Step 58731520 @ 3069.5 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.8686e+04, step = 58731520, mean_episode_return = 69.4, mean_episode_step = 1831.0, total_loss = 307.7, pg_loss = 264.91, baseline_loss = 57.557, entropy_loss = -14.765, learner_queue_size = 64, _tick = 9080, _time = 1.6548e+09)
[2022-06-09 18:52:07,770][root][INFO] - Step 58746880 @ 3069.6 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.8691e+04, step = 58746880, mean_episode_return = 64.226, mean_episode_step = 1859.6, total_loss = -151.77, pg_loss = -157.73, baseline_loss = 20.716, entropy_loss = -14.751, learner_queue_size = 64, _tick = 9081, _time = 1.6548e+09)
[2022-06-09 18:52:12,776][root][INFO] - Step 58762240 @ 3068.2 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.8696e+04, step = 58762240, mean_episode_return = 49.692, mean_episode_step = 2002.3, total_loss = 156.79, pg_loss = 120.2, baseline_loss = 51.3, entropy_loss = -14.708, learner_queue_size = 64, _tick = 9084, _time = 1.6548e+09)
[2022-06-09 18:52:17,782][root][INFO] - Step 58777600 @ 3068.3 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.8701e+04, step = 58777600, mean_episode_return = 97.198, mean_episode_step = 1893.8, total_loss = 352.94, pg_loss = 304.6, baseline_loss = 62.976, entropy_loss = -14.639, learner_queue_size = 64, _tick = 9087, _time = 1.6548e+09)
[2022-06-09 18:52:22,786][root][INFO] - Step 58798080 @ 4092.8 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 1.8706e+04, step = 58798080, mean_episode_return = -16.871, mean_episode_step = 1995.0, total_loss = 227.51, pg_loss = 183.74, baseline_loss = 58.407, entropy_loss = -14.635, learner_queue_size = 64, _tick = 9091, _time = 1.6548e+09)
[2022-06-09 18:52:27,790][root][INFO] - Step 58813440 @ 3069.5 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 1.8711e+04, step = 58813440, mean_episode_return = None, mean_episode_step = 1657.4, total_loss = 82.767, pg_loss = 78.328, baseline_loss = 19.01, entropy_loss = -14.57, learner_queue_size = 64, _tick = 9093, _time = 1.6548e+09)
[2022-06-09 18:52:32,794][root][INFO] - Step 58828800 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.8716e+04, step = 58828800, mean_episode_return = None, mean_episode_step = 2012.9, total_loss = 101.07, pg_loss = 88.01, baseline_loss = 27.68, entropy_loss = -14.619, learner_queue_size = 64, _tick = 9095, _time = 1.6548e+09)
[2022-06-09 18:52:37,798][root][INFO] - Step 58844160 @ 3069.5 SPS. Inference batcher size: 68. Learner queue size: 64. Other stats: (train_seconds = 1.8721e+04, step = 58844160, mean_episode_return = 64.456, mean_episode_step = 1920.6, total_loss = -220.66, pg_loss = -228.35, baseline_loss = 22.349, entropy_loss = -14.657, learner_queue_size = 64, _tick = 9098, _time = 1.6548e+09)
[2022-06-09 18:52:42,802][root][INFO] - Step 58859520 @ 3069.6 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.8726e+04, step = 58859520, mean_episode_return = 34.296, mean_episode_step = 2029.8, total_loss = -68.683, pg_loss = -112.98, baseline_loss = 58.998, entropy_loss = -14.698, learner_queue_size = 64, _tick = 9100, _time = 1.6548e+09)
[2022-06-09 18:52:47,806][root][INFO] - Step 58874880 @ 3069.4 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 1.8731e+04, step = 58874880, mean_episode_return = 52.684, mean_episode_step = 1859.4, total_loss = -160.31, pg_loss = -196.78, baseline_loss = 51.145, entropy_loss = -14.68, learner_queue_size = 64, _tick = 9102, _time = 1.6548e+09)
[2022-06-09 18:52:52,810][root][INFO] - Step 58890240 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.8736e+04, step = 58890240, mean_episode_return = 31.875, mean_episode_step = 1970.5, total_loss = -67.147, pg_loss = -74.322, baseline_loss = 21.855, entropy_loss = -14.679, learner_queue_size = 64, _tick = 9105, _time = 1.6548e+09)
[2022-06-09 18:52:57,814][root][INFO] - Step 58905600 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.8741e+04, step = 58905600, mean_episode_return = 45.932, mean_episode_step = 1804.6, total_loss = 433.95, pg_loss = 300.3, baseline_loss = 148.3, entropy_loss = -14.649, learner_queue_size = 64, _tick = 9108, _time = 1.6548e+09)
[2022-06-09 18:53:02,818][root][INFO] - Step 58920960 @ 3069.5 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 1.8746e+04, step = 58920960, mean_episode_return = 80.997, mean_episode_step = 1831.4, total_loss = -206.06, pg_loss = -213.08, baseline_loss = 21.767, entropy_loss = -14.747, learner_queue_size = 64, _tick = 9111, _time = 1.6548e+09)
[2022-06-09 18:53:07,822][root][INFO] - Step 58936320 @ 3069.6 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.8751e+04, step = 58936320, mean_episode_return = 18.75, mean_episode_step = 1829.1, total_loss = -319.03, pg_loss = -309.48, baseline_loss = 5.1844, entropy_loss = -14.736, learner_queue_size = 64, _tick = 9114, _time = 1.6548e+09)
[2022-06-09 18:53:12,826][root][INFO] - Step 58951680 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.8756e+04, step = 58951680, mean_episode_return = 51.591, mean_episode_step = 1896.6, total_loss = -67.02, pg_loss = -81.641, baseline_loss = 29.449, entropy_loss = -14.828, learner_queue_size = 64, _tick = 9117, _time = 1.6548e+09)
[2022-06-09 18:53:17,830][root][INFO] - Step 58967040 @ 3069.5 SPS. Inference batcher size: 6. Learner queue size: 64. Other stats: (train_seconds = 1.8761e+04, step = 58967040, mean_episode_return = 61.908, mean_episode_step = 1727.2, total_loss = 44.046, pg_loss = 24.452, baseline_loss = 34.406, entropy_loss = -14.812, learner_queue_size = 64, _tick = 9120, _time = 1.6548e+09)
[2022-06-09 18:53:22,834][root][INFO] - Step 58982400 @ 3069.5 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 1.8766e+04, step = 58982400, mean_episode_return = 61.768, mean_episode_step = 1885.3, total_loss = -100.46, pg_loss = -105.77, baseline_loss = 20.168, entropy_loss = -14.858, learner_queue_size = 64, _tick = 9123, _time = 1.6548e+09)
[2022-06-09 18:53:27,838][root][INFO] - Step 59002880 @ 4092.8 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 1.8771e+04, step = 59002880, mean_episode_return = None, mean_episode_step = 1692.0, total_loss = 275.04, pg_loss = 252.51, baseline_loss = 37.451, entropy_loss = -14.917, learner_queue_size = 64, _tick = 9125, _time = 1.6548e+09)
[2022-06-09 18:53:32,842][root][INFO] - Step 59018240 @ 3069.5 SPS. Inference batcher size: 75. Learner queue size: 64. Other stats: (train_seconds = 1.8776e+04, step = 59018240, mean_episode_return = 43.989, mean_episode_step = 1697.5, total_loss = -343.11, pg_loss = -342.98, baseline_loss = 14.878, entropy_loss = -15.006, learner_queue_size = 64, _tick = 9127, _time = 1.6548e+09)
[2022-06-09 18:53:37,846][root][INFO] - Step 59033600 @ 3069.6 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 1.8781e+04, step = 59033600, mean_episode_return = 41.282, mean_episode_step = 1721.7, total_loss = 132.77, pg_loss = 106.6, baseline_loss = 41.285, entropy_loss = -15.114, learner_queue_size = 64, _tick = 9130, _time = 1.6548e+09)
[2022-06-09 18:53:42,850][root][INFO] - Step 59048960 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.8786e+04, step = 59048960, mean_episode_return = 26.073, mean_episode_step = 1803.4, total_loss = 39.475, pg_loss = 21.716, baseline_loss = 33.054, entropy_loss = -15.295, learner_queue_size = 64, _tick = 9133, _time = 1.6548e+09)
[2022-06-09 18:53:47,854][root][INFO] - Step 59064320 @ 3069.5 SPS. Inference batcher size: 15. Learner queue size: 64. Other stats: (train_seconds = 1.8791e+04, step = 59064320, mean_episode_return = 71.952, mean_episode_step = 1644.8, total_loss = 346.33, pg_loss = 310.67, baseline_loss = 50.813, entropy_loss = -15.157, learner_queue_size = 64, _tick = 9136, _time = 1.6548e+09)
[2022-06-09 18:53:52,858][root][INFO] - Step 59079680 @ 3069.6 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.8796e+04, step = 59079680, mean_episode_return = -17.17, mean_episode_step = 1697.8, total_loss = 66.077, pg_loss = 49.795, baseline_loss = 31.285, entropy_loss = -15.003, learner_queue_size = 64, _tick = 9138, _time = 1.6548e+09)
[2022-06-09 18:53:57,862][root][INFO] - Step 59095040 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.8801e+04, step = 59095040, mean_episode_return = 55.461, mean_episode_step = 1787.8, total_loss = -29.853, pg_loss = -54.653, baseline_loss = 40.009, entropy_loss = -15.209, learner_queue_size = 64, _tick = 9141, _time = 1.6548e+09)
[2022-06-09 18:54:02,866][root][INFO] - Step 59115520 @ 4092.7 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 1.8806e+04, step = 59115520, mean_episode_return = 12.98, mean_episode_step = 1698.6, total_loss = 543.52, pg_loss = 344.1, baseline_loss = 214.75, entropy_loss = -15.333, learner_queue_size = 64, _tick = 9145, _time = 1.6548e+09)
[2022-06-09 18:54:07,872][root][INFO] - Step 59130880 @ 3068.3 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 1.8811e+04, step = 59130880, mean_episode_return = 58.371, mean_episode_step = 1849.6, total_loss = -30.448, pg_loss = -30.585, baseline_loss = 15.506, entropy_loss = -15.37, learner_queue_size = 64, _tick = 9148, _time = 1.6548e+09)
[2022-06-09 18:54:12,878][root][INFO] - Step 59146240 @ 3068.3 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 1.8816e+04, step = 59146240, mean_episode_return = 74.89, mean_episode_step = 1586.7, total_loss = -37.784, pg_loss = -55.884, baseline_loss = 33.629, entropy_loss = -15.528, learner_queue_size = 64, _tick = 9151, _time = 1.6548e+09)
[2022-06-09 18:54:17,882][root][INFO] - Step 59161600 @ 3069.6 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 1.8821e+04, step = 59161600, mean_episode_return = 51.436, mean_episode_step = 1662.5, total_loss = 44.904, pg_loss = 21.529, baseline_loss = 38.831, entropy_loss = -15.456, learner_queue_size = 64, _tick = 9153, _time = 1.6548e+09)
[2022-06-09 18:54:22,886][root][INFO] - Step 59176960 @ 3069.5 SPS. Inference batcher size: 18. Learner queue size: 64. Other stats: (train_seconds = 1.8826e+04, step = 59176960, mean_episode_return = 63.521, mean_episode_step = 1595.1, total_loss = -179.46, pg_loss = -169.95, baseline_loss = 5.6976, entropy_loss = -15.208, learner_queue_size = 64, _tick = 9156, _time = 1.6548e+09)
[2022-06-09 18:54:27,890][root][INFO] - Step 59192320 @ 3069.6 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.8831e+04, step = 59192320, mean_episode_return = 63.63, mean_episode_step = 1694.5, total_loss = -48.961, pg_loss = -54.34, baseline_loss = 20.587, entropy_loss = -15.209, learner_queue_size = 64, _tick = 9159, _time = 1.6548e+09)
[2022-06-09 18:54:32,894][root][INFO] - Step 59207680 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.8836e+04, step = 59207680, mean_episode_return = 48.123, mean_episode_step = 1672.4, total_loss = 84.384, pg_loss = 65.841, baseline_loss = 33.776, entropy_loss = -15.233, learner_queue_size = 64, _tick = 9162, _time = 1.6548e+09)
[2022-06-09 18:54:37,898][root][INFO] - Step 59223040 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.8841e+04, step = 59223040, mean_episode_return = -3.3701, mean_episode_step = 1699.8, total_loss = 161.43, pg_loss = 151.8, baseline_loss = 24.823, entropy_loss = -15.2, learner_queue_size = 64, _tick = 9165, _time = 1.6548e+09)
[2022-06-09 18:54:42,902][root][INFO] - Step 59238400 @ 3069.5 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 1.8846e+04, step = 59238400, mean_episode_return = None, mean_episode_step = 1874.7, total_loss = 470.54, pg_loss = 418.86, baseline_loss = 66.723, entropy_loss = -15.043, learner_queue_size = 64, _tick = 9167, _time = 1.6548e+09)
[2022-06-09 18:54:47,906][root][INFO] - Step 59253760 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.8851e+04, step = 59253760, mean_episode_return = None, mean_episode_step = 1821.0, total_loss = -71.324, pg_loss = -70.884, baseline_loss = 14.716, entropy_loss = -15.156, learner_queue_size = 64, _tick = 9168, _time = 1.6548e+09)
[2022-06-09 18:54:52,910][root][INFO] - Step 59269120 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.8856e+04, step = 59269120, mean_episode_return = 20.617, mean_episode_step = 1769.0, total_loss = 50.412, pg_loss = 32.544, baseline_loss = 32.966, entropy_loss = -15.098, learner_queue_size = 64, _tick = 9171, _time = 1.6548e+09)
[2022-06-09 18:54:57,914][root][INFO] - Step 59284480 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.8861e+04, step = 59284480, mean_episode_return = None, mean_episode_step = 1854.4, total_loss = 69.519, pg_loss = 62.83, baseline_loss = 21.832, entropy_loss = -15.143, learner_queue_size = 64, _tick = 9173, _time = 1.6548e+09)
[2022-06-09 18:55:02,920][root][INFO] - Step 59299840 @ 3068.3 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.8866e+04, step = 59299840, mean_episode_return = None, mean_episode_step = 1935.3, total_loss = 74.81, pg_loss = 73.236, baseline_loss = 16.701, entropy_loss = -15.127, learner_queue_size = 64, _tick = 9174, _time = 1.6548e+09)
[2022-06-09 18:55:07,926][root][INFO] - Step 59320320 @ 4091.2 SPS. Inference batcher size: 11. Learner queue size: 64. Other stats: (train_seconds = 1.8871e+04, step = 59320320, mean_episode_return = 57.251, mean_episode_step = 1852.4, total_loss = -126.86, pg_loss = -128.89, baseline_loss = 17.339, entropy_loss = -15.304, learner_queue_size = 64, _tick = 9178, _time = 1.6548e+09)
[2022-06-09 18:55:12,930][root][INFO] - Step 59335680 @ 3069.5 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 1.8876e+04, step = 59335680, mean_episode_return = None, mean_episode_step = 1866.3, total_loss = 171.23, pg_loss = 133.42, baseline_loss = 53.061, entropy_loss = -15.252, learner_queue_size = 64, _tick = 9180, _time = 1.6548e+09)
[2022-06-09 18:55:17,934][root][INFO] - Step 59351040 @ 3069.6 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.8881e+04, step = 59351040, mean_episode_return = 56.433, mean_episode_step = 1904.7, total_loss = -199.0, pg_loss = -199.39, baseline_loss = 15.649, entropy_loss = -15.253, learner_queue_size = 64, _tick = 9183, _time = 1.6548e+09)
[2022-06-09 18:55:22,938][root][INFO] - Step 59366400 @ 3069.5 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.8886e+04, step = 59366400, mean_episode_return = 52.779, mean_episode_step = 1784.2, total_loss = -190.78, pg_loss = -198.18, baseline_loss = 22.571, entropy_loss = -15.167, learner_queue_size = 64, _tick = 9186, _time = 1.6548e+09)
[2022-06-09 18:55:27,942][root][INFO] - Step 59381760 @ 3069.4 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.8891e+04, step = 59381760, mean_episode_return = 30.351, mean_episode_step = 1890.0, total_loss = -145.03, pg_loss = -149.2, baseline_loss = 19.488, entropy_loss = -15.311, learner_queue_size = 64, _tick = 9189, _time = 1.6548e+09)
[2022-06-09 18:55:32,946][root][INFO] - Step 59397120 @ 3069.7 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.8896e+04, step = 59397120, mean_episode_return = None, mean_episode_step = 2086.6, total_loss = -32.397, pg_loss = -43.355, baseline_loss = 26.211, entropy_loss = -15.253, learner_queue_size = 64, _tick = 9191, _time = 1.6548e+09)
[2022-06-09 18:55:37,950][root][INFO] - Step 59412480 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.8901e+04, step = 59412480, mean_episode_return = 60.731, mean_episode_step = 1931.5, total_loss = 160.57, pg_loss = 135.37, baseline_loss = 40.559, entropy_loss = -15.355, learner_queue_size = 64, _tick = 9193, _time = 1.6548e+09)
[2022-06-09 18:55:42,954][root][INFO] - Step 59427840 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.8906e+04, step = 59427840, mean_episode_return = 33.044, mean_episode_step = 1874.5, total_loss = 43.238, pg_loss = 23.624, baseline_loss = 34.855, entropy_loss = -15.241, learner_queue_size = 64, _tick = 9195, _time = 1.6548e+09)
[2022-06-09 18:55:47,958][root][INFO] - Step 59448320 @ 4092.7 SPS. Inference batcher size: 95. Learner queue size: 64. Other stats: (train_seconds = 1.8911e+04, step = 59448320, mean_episode_return = None, mean_episode_step = 2005.2, total_loss = -176.47, pg_loss = -168.2, baseline_loss = 6.9895, entropy_loss = -15.262, learner_queue_size = 64, _tick = 9198, _time = 1.6548e+09)
[2022-06-09 18:55:52,962][root][INFO] - Step 59463680 @ 3069.4 SPS. Inference batcher size: 14. Learner queue size: 64. Other stats: (train_seconds = 1.8916e+04, step = 59463680, mean_episode_return = 41.915, mean_episode_step = 1982.5, total_loss = 177.26, pg_loss = 142.88, baseline_loss = 49.602, entropy_loss = -15.222, learner_queue_size = 64, _tick = 9201, _time = 1.6548e+09)
[2022-06-09 18:55:57,966][root][INFO] - Step 59479040 @ 3069.7 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 1.8921e+04, step = 59479040, mean_episode_return = 10.603, mean_episode_step = 1891.5, total_loss = 18.032, pg_loss = 7.818, baseline_loss = 25.403, entropy_loss = -15.189, learner_queue_size = 64, _tick = 9204, _time = 1.6548e+09)
[2022-06-09 18:56:02,970][root][INFO] - Step 59494400 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.8926e+04, step = 59494400, mean_episode_return = 87.127, mean_episode_step = 2453.3, total_loss = 138.76, pg_loss = 121.58, baseline_loss = 32.466, entropy_loss = -15.283, learner_queue_size = 64, _tick = 9207, _time = 1.6548e+09)
[2022-06-09 18:56:07,974][root][INFO] - Step 59509760 @ 3069.5 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1.8931e+04, step = 59509760, mean_episode_return = 23.865, mean_episode_step = 2025.9, total_loss = -72.053, pg_loss = -81.231, baseline_loss = 24.346, entropy_loss = -15.167, learner_queue_size = 64, _tick = 9210, _time = 1.6548e+09)
[2022-06-09 18:56:12,978][root][INFO] - Step 59525120 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.8936e+04, step = 59525120, mean_episode_return = 56.639, mean_episode_step = 1883.7, total_loss = -85.666, pg_loss = -85.359, baseline_loss = 14.874, entropy_loss = -15.18, learner_queue_size = 64, _tick = 9213, _time = 1.6548e+09)
[2022-06-09 18:56:17,982][root][INFO] - Step 59540480 @ 3069.5 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1.8941e+04, step = 59540480, mean_episode_return = 24.44, mean_episode_step = 1956.7, total_loss = 22.183, pg_loss = 17.19, baseline_loss = 20.282, entropy_loss = -15.289, learner_queue_size = 64, _tick = 9216, _time = 1.6548e+09)
[2022-06-09 18:56:22,986][root][INFO] - Step 59555840 @ 3069.6 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 1.8946e+04, step = 59555840, mean_episode_return = -4.8003, mean_episode_step = 1806.5, total_loss = 42.129, pg_loss = 39.247, baseline_loss = 18.128, entropy_loss = -15.246, learner_queue_size = 64, _tick = 9219, _time = 1.6548e+09)
[2022-06-09 18:56:27,990][root][INFO] - Step 59576320 @ 4092.6 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.8951e+04, step = 59576320, mean_episode_return = -8.9707, mean_episode_step = 1777.9, total_loss = 61.402, pg_loss = 54.027, baseline_loss = 22.71, entropy_loss = -15.335, learner_queue_size = 64, _tick = 9223, _time = 1.6548e+09)
[2022-06-09 18:56:32,994][root][INFO] - Step 59591680 @ 3069.6 SPS. Inference batcher size: 71. Learner queue size: 64. Other stats: (train_seconds = 1.8956e+04, step = 59591680, mean_episode_return = None, mean_episode_step = 1902.8, total_loss = 117.95, pg_loss = 111.9, baseline_loss = 21.249, entropy_loss = -15.205, learner_queue_size = 64, _tick = 9224, _time = 1.6548e+09)
[2022-06-09 18:56:37,998][root][INFO] - Step 59607040 @ 3069.6 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.8961e+04, step = 59607040, mean_episode_return = 55.525, mean_episode_step = 1731.3, total_loss = 66.254, pg_loss = 47.937, baseline_loss = 33.634, entropy_loss = -15.317, learner_queue_size = 64, _tick = 9226, _time = 1.6548e+09)
[2022-06-09 18:56:43,002][root][INFO] - Step 59622400 @ 3069.5 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 1.8966e+04, step = 59622400, mean_episode_return = 34.112, mean_episode_step = 1992.7, total_loss = -47.627, pg_loss = -53.55, baseline_loss = 21.344, entropy_loss = -15.422, learner_queue_size = 64, _tick = 9229, _time = 1.6548e+09)
[2022-06-09 18:56:48,006][root][INFO] - Step 59637760 @ 3069.6 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 1.8971e+04, step = 59637760, mean_episode_return = 7.5601, mean_episode_step = 2243.6, total_loss = -70.442, pg_loss = -84.479, baseline_loss = 29.464, entropy_loss = -15.428, learner_queue_size = 64, _tick = 9231, _time = 1.6548e+09)
[2022-06-09 18:56:53,010][root][INFO] - Step 59653120 @ 3069.6 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.8976e+04, step = 59653120, mean_episode_return = 14.48, mean_episode_step = 2074.0, total_loss = -78.786, pg_loss = -83.151, baseline_loss = 19.655, entropy_loss = -15.29, learner_queue_size = 64, _tick = 9234, _time = 1.6548e+09)
[2022-06-09 18:56:58,014][root][INFO] - Step 59668480 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.8981e+04, step = 59668480, mean_episode_return = 45.806, mean_episode_step = 2039.4, total_loss = 38.399, pg_loss = 19.234, baseline_loss = 34.414, entropy_loss = -15.25, learner_queue_size = 64, _tick = 9237, _time = 1.6548e+09)
[2022-06-09 18:57:03,019][root][INFO] - Step 59683840 @ 3069.0 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.8986e+04, step = 59683840, mean_episode_return = 70.485, mean_episode_step = 2303.4, total_loss = 2.3998, pg_loss = -7.2494, baseline_loss = 25.035, entropy_loss = -15.386, learner_queue_size = 64, _tick = 9239, _time = 1.6548e+09)
[2022-06-09 18:57:08,022][root][INFO] - Step 59699200 @ 3070.1 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 1.8991e+04, step = 59699200, mean_episode_return = 14.09, mean_episode_step = 1938.1, total_loss = -111.91, pg_loss = -110.83, baseline_loss = 14.262, entropy_loss = -15.344, learner_queue_size = 64, _tick = 9242, _time = 1.6548e+09)
[2022-06-09 18:57:13,026][root][INFO] - Step 59719680 @ 4092.7 SPS. Inference batcher size: 84. Learner queue size: 64. Other stats: (train_seconds = 1.8996e+04, step = 59719680, mean_episode_return = 37.262, mean_episode_step = 1726.4, total_loss = -221.25, pg_loss = -213.52, baseline_loss = 7.6786, entropy_loss = -15.404, learner_queue_size = 64, _tick = 9246, _time = 1.6548e+09)
[2022-06-09 18:57:18,030][root][INFO] - Step 59735040 @ 3069.6 SPS. Inference batcher size: 72. Learner queue size: 64. Other stats: (train_seconds = 1.9001e+04, step = 59735040, mean_episode_return = 39.69, mean_episode_step = 2089.8, total_loss = 419.52, pg_loss = 361.49, baseline_loss = 73.461, entropy_loss = -15.436, learner_queue_size = 64, _tick = 9249, _time = 1.6548e+09)
[2022-06-09 18:57:23,034][root][INFO] - Step 59750400 @ 3069.6 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 1.9006e+04, step = 59750400, mean_episode_return = 87.908, mean_episode_step = 1711.5, total_loss = -145.63, pg_loss = -141.64, baseline_loss = 11.235, entropy_loss = -15.226, learner_queue_size = 64, _tick = 9251, _time = 1.6548e+09)
[2022-06-09 18:57:28,038][root][INFO] - Step 59765760 @ 3069.5 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 1.9011e+04, step = 59765760, mean_episode_return = -5.2944, mean_episode_step = 1901.8, total_loss = -66.531, pg_loss = -87.587, baseline_loss = 36.355, entropy_loss = -15.299, learner_queue_size = 64, _tick = 9253, _time = 1.6548e+09)
[2022-06-09 18:57:33,042][root][INFO] - Step 59781120 @ 3069.5 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 1.9016e+04, step = 59781120, mean_episode_return = 84.449, mean_episode_step = 1872.2, total_loss = -24.78, pg_loss = -30.517, baseline_loss = 20.927, entropy_loss = -15.19, learner_queue_size = 64, _tick = 9256, _time = 1.6548e+09)
[2022-06-09 18:57:38,046][root][INFO] - Step 59796480 @ 3069.6 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.9021e+04, step = 59796480, mean_episode_return = 55.421, mean_episode_step = 1898.6, total_loss = -148.54, pg_loss = -137.92, baseline_loss = 4.5294, entropy_loss = -15.145, learner_queue_size = 64, _tick = 9259, _time = 1.6548e+09)
[2022-06-09 18:57:43,050][root][INFO] - Step 59811840 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.9026e+04, step = 59811840, mean_episode_return = 1.2993, mean_episode_step = 2315.9, total_loss = -17.456, pg_loss = -27.937, baseline_loss = 25.627, entropy_loss = -15.146, learner_queue_size = 64, _tick = 9262, _time = 1.6548e+09)
[2022-06-09 18:57:48,054][root][INFO] - Step 59827200 @ 3069.6 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 1.9031e+04, step = 59827200, mean_episode_return = 53.344, mean_episode_step = 2127.9, total_loss = 109.35, pg_loss = 75.547, baseline_loss = 48.929, entropy_loss = -15.123, learner_queue_size = 64, _tick = 9265, _time = 1.6548e+09)
[2022-06-09 18:57:53,058][root][INFO] - Step 59842560 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.9036e+04, step = 59842560, mean_episode_return = 1.9747, mean_episode_step = 1659.2, total_loss = 239.04, pg_loss = 202.72, baseline_loss = 51.137, entropy_loss = -14.818, learner_queue_size = 64, _tick = 9268, _time = 1.6548e+09)
[2022-06-09 18:57:58,062][root][INFO] - Step 59857920 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.9041e+04, step = 59857920, mean_episode_return = None, mean_episode_step = 1857.6, total_loss = -169.48, pg_loss = -160.06, baseline_loss = 5.2924, entropy_loss = -14.71, learner_queue_size = 64, _tick = 9269, _time = 1.6548e+09)
[2022-06-09 18:58:03,066][root][INFO] - Step 59878400 @ 4092.8 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 1.9046e+04, step = 59878400, mean_episode_return = 41.5, mean_episode_step = 1957.4, total_loss = 60.952, pg_loss = 41.036, baseline_loss = 34.634, entropy_loss = -14.718, learner_queue_size = 64, _tick = 9271, _time = 1.6548e+09)
[2022-06-09 18:58:08,070][root][INFO] - Step 59888640 @ 2046.4 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 1.9051e+04, step = 59888640, mean_episode_return = None, mean_episode_step = 1999.9, total_loss = -108.59, pg_loss = -105.85, baseline_loss = 11.919, entropy_loss = -14.659, learner_queue_size = 64, _tick = 9272, _time = 1.6548e+09)
[2022-06-09 18:58:13,074][root][INFO] - Step 59909120 @ 4092.7 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 1.9056e+04, step = 59909120, mean_episode_return = 22.586, mean_episode_step = 1653.9, total_loss = -125.01, pg_loss = -130.74, baseline_loss = 20.497, entropy_loss = -14.765, learner_queue_size = 64, _tick = 9276, _time = 1.6548e+09)
[2022-06-09 18:58:18,078][root][INFO] - Step 59924480 @ 3069.5 SPS. Inference batcher size: 11. Learner queue size: 64. Other stats: (train_seconds = 1.9061e+04, step = 59924480, mean_episode_return = 91.283, mean_episode_step = 1972.0, total_loss = 210.79, pg_loss = 167.78, baseline_loss = 57.787, entropy_loss = -14.781, learner_queue_size = 64, _tick = 9279, _time = 1.6548e+09)
[2022-06-09 18:58:23,082][root][INFO] - Step 59939840 @ 3069.6 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.9066e+04, step = 59939840, mean_episode_return = 24.574, mean_episode_step = 1777.7, total_loss = -129.19, pg_loss = -150.91, baseline_loss = 36.578, entropy_loss = -14.854, learner_queue_size = 64, _tick = 9282, _time = 1.6548e+09)
[2022-06-09 18:58:28,086][root][INFO] - Step 59955200 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.9071e+04, step = 59955200, mean_episode_return = 30.417, mean_episode_step = 1785.2, total_loss = 341.42, pg_loss = 294.24, baseline_loss = 62.063, entropy_loss = -14.889, learner_queue_size = 64, _tick = 9285, _time = 1.6548e+09)
[2022-06-09 18:58:33,090][root][INFO] - Step 59970560 @ 3069.6 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.9076e+04, step = 59970560, mean_episode_return = -2.1203, mean_episode_step = 1724.2, total_loss = -176.53, pg_loss = -174.47, baseline_loss = 12.866, entropy_loss = -14.93, learner_queue_size = 64, _tick = 9288, _time = 1.6548e+09)
[2022-06-09 18:58:38,094][root][INFO] - Step 59985920 @ 3069.5 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 1.9081e+04, step = 59985920, mean_episode_return = 57.494, mean_episode_step = 1796.6, total_loss = 127.57, pg_loss = 104.22, baseline_loss = 38.326, entropy_loss = -14.976, learner_queue_size = 64, _tick = 9290, _time = 1.6548e+09)
[2022-06-09 18:58:43,098][root][INFO] - Step 60001280 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.9086e+04, step = 60001280, mean_episode_return = -2.2554, mean_episode_step = 1949.3, total_loss = 3.0471, pg_loss = -6.4812, baseline_loss = 24.492, entropy_loss = -14.963, learner_queue_size = 64, _tick = 9292, _time = 1.6548e+09)
[2022-06-09 18:58:48,102][root][INFO] - Step 60021760 @ 4092.8 SPS. Inference batcher size: 83. Learner queue size: 64. Other stats: (train_seconds = 1.9091e+04, step = 60021760, mean_episode_return = None, mean_episode_step = 1911.7, total_loss = -184.24, pg_loss = -171.85, baseline_loss = 2.6851, entropy_loss = -15.076, learner_queue_size = 64, _tick = 9295, _time = 1.6548e+09)
[2022-06-09 18:58:53,106][root][INFO] - Step 60037120 @ 3069.5 SPS. Inference batcher size: 96. Learner queue size: 64. Other stats: (train_seconds = 1.9096e+04, step = 60037120, mean_episode_return = None, mean_episode_step = 1841.0, total_loss = 217.83, pg_loss = 197.31, baseline_loss = 35.592, entropy_loss = -15.071, learner_queue_size = 64, _tick = 9297, _time = 1.6548e+09)
[2022-06-09 18:58:58,110][root][INFO] - Step 60052480 @ 3069.6 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 1.9101e+04, step = 60052480, mean_episode_return = None, mean_episode_step = 1786.7, total_loss = -74.953, pg_loss = -85.676, baseline_loss = 25.888, entropy_loss = -15.165, learner_queue_size = 64, _tick = 9299, _time = 1.6548e+09)
[2022-06-09 18:59:03,114][root][INFO] - Step 60067840 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.9106e+04, step = 60067840, mean_episode_return = 69.636, mean_episode_step = 1681.5, total_loss = 1.5705, pg_loss = -21.243, baseline_loss = 38.075, entropy_loss = -15.262, learner_queue_size = 64, _tick = 9301, _time = 1.6548e+09)
[2022-06-09 18:59:08,118][root][INFO] - Step 60083200 @ 3069.6 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 1.9111e+04, step = 60083200, mean_episode_return = 46.695, mean_episode_step = 1784.8, total_loss = 16.925, pg_loss = 1.0959, baseline_loss = 30.963, entropy_loss = -15.134, learner_queue_size = 64, _tick = 9304, _time = 1.6548e+09)
[2022-06-09 18:59:13,124][root][INFO] - Step 60098560 @ 3068.6 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.9116e+04, step = 60098560, mean_episode_return = 57.333, mean_episode_step = 1726.9, total_loss = 81.107, pg_loss = 60.301, baseline_loss = 35.923, entropy_loss = -15.116, learner_queue_size = 64, _tick = 9307, _time = 1.6548e+09)
[2022-06-09 18:59:18,130][root][INFO] - Step 60113920 @ 3068.0 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.9121e+04, step = 60113920, mean_episode_return = 74.318, mean_episode_step = 1709.4, total_loss = -150.27, pg_loss = -155.39, baseline_loss = 20.213, entropy_loss = -15.103, learner_queue_size = 64, _tick = 9309, _time = 1.6548e+09)
[2022-06-09 18:59:23,134][root][INFO] - Step 60134400 @ 4092.8 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 1.9126e+04, step = 60134400, mean_episode_return = 39.47, mean_episode_step = 1789.7, total_loss = 74.8, pg_loss = 43.876, baseline_loss = 46.061, entropy_loss = -15.137, learner_queue_size = 64, _tick = 9312, _time = 1.6548e+09)
[2022-06-09 18:59:28,138][root][INFO] - Step 60149760 @ 3069.4 SPS. Inference batcher size: 2. Learner queue size: 64. Other stats: (train_seconds = 1.9131e+04, step = 60149760, mean_episode_return = -3.3305, mean_episode_step = 1765.2, total_loss = -285.38, pg_loss = -291.45, baseline_loss = 21.252, entropy_loss = -15.181, learner_queue_size = 64, _tick = 9315, _time = 1.6548e+09)
[2022-06-09 18:59:33,142][root][INFO] - Step 60165120 @ 3069.7 SPS. Inference batcher size: 68. Learner queue size: 64. Other stats: (train_seconds = 1.9136e+04, step = 60165120, mean_episode_return = None, mean_episode_step = 1695.9, total_loss = 324.43, pg_loss = 297.48, baseline_loss = 42.203, entropy_loss = -15.255, learner_queue_size = 64, _tick = 9317, _time = 1.6548e+09)
[2022-06-09 18:59:38,146][root][INFO] - Step 60180480 @ 3069.5 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 1.9141e+04, step = 60180480, mean_episode_return = 14.163, mean_episode_step = 1585.3, total_loss = 69.617, pg_loss = 40.615, baseline_loss = 44.21, entropy_loss = -15.208, learner_queue_size = 64, _tick = 9319, _time = 1.6548e+09)
[2022-06-09 18:59:43,150][root][INFO] - Step 60195840 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.9146e+04, step = 60195840, mean_episode_return = 44.232, mean_episode_step = 1997.8, total_loss = 101.49, pg_loss = 72.043, baseline_loss = 44.58, entropy_loss = -15.132, learner_queue_size = 64, _tick = 9322, _time = 1.6548e+09)
[2022-06-09 18:59:48,154][root][INFO] - Step 60211200 @ 3069.5 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 1.9151e+04, step = 60211200, mean_episode_return = None, mean_episode_step = 1622.2, total_loss = 18.94, pg_loss = 8.2165, baseline_loss = 25.808, entropy_loss = -15.085, learner_queue_size = 64, _tick = 9323, _time = 1.6548e+09)
[2022-06-09 18:59:53,158][root][INFO] - Step 60226560 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.9156e+04, step = 60226560, mean_episode_return = 48.144, mean_episode_step = 2086.7, total_loss = -148.05, pg_loss = -153.11, baseline_loss = 20.132, entropy_loss = -15.071, learner_queue_size = 64, _tick = 9326, _time = 1.6548e+09)
[2022-06-09 18:59:58,162][root][INFO] - Step 60241920 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.9161e+04, step = 60241920, mean_episode_return = None, mean_episode_step = 1733.3, total_loss = 118.2, pg_loss = 92.351, baseline_loss = 40.958, entropy_loss = -15.105, learner_queue_size = 64, _tick = 9328, _time = 1.6548e+09)
[2022-06-09 19:00:03,166][root][INFO] - Step 60262400 @ 4092.8 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 1.9166e+04, step = 60262400, mean_episode_return = 38.47, mean_episode_step = 1761.4, total_loss = -154.18, pg_loss = -153.04, baseline_loss = 13.936, entropy_loss = -15.08, learner_queue_size = 64, _tick = 9331, _time = 1.6548e+09)
[2022-06-09 19:00:08,170][root][INFO] - Step 60277760 @ 3069.6 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 1.9171e+04, step = 60277760, mean_episode_return = 9.638, mean_episode_step = 1693.2, total_loss = -131.63, pg_loss = -155.87, baseline_loss = 39.359, entropy_loss = -15.12, learner_queue_size = 64, _tick = 9334, _time = 1.6548e+09)
[2022-06-09 19:00:13,174][root][INFO] - Step 60293120 @ 3069.6 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 1.9176e+04, step = 60293120, mean_episode_return = 87.639, mean_episode_step = 1857.3, total_loss = 116.58, pg_loss = 91.175, baseline_loss = 40.465, entropy_loss = -15.063, learner_queue_size = 64, _tick = 9336, _time = 1.6548e+09)
[2022-06-09 19:00:18,183][root][INFO] - Step 60308480 @ 3066.2 SPS. Inference batcher size: 78. Learner queue size: 64. Other stats: (train_seconds = 1.9181e+04, step = 60308480, mean_episode_return = 41.346, mean_episode_step = 2070.3, total_loss = 26.684, pg_loss = 1.4513, baseline_loss = 40.28, entropy_loss = -15.047, learner_queue_size = 64, _tick = 9339, _time = 1.6548e+09)
[2022-06-09 19:00:23,186][root][INFO] - Step 60323840 @ 3070.4 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 1.9186e+04, step = 60323840, mean_episode_return = 60.331, mean_episode_step = 1821.9, total_loss = -102.96, pg_loss = -112.76, baseline_loss = 24.73, entropy_loss = -14.924, learner_queue_size = 64, _tick = 9341, _time = 1.6548e+09)
[2022-06-09 19:00:28,190][root][INFO] - Step 60339200 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.9191e+04, step = 60339200, mean_episode_return = 42.831, mean_episode_step = 1730.3, total_loss = 107.35, pg_loss = 88.546, baseline_loss = 33.75, entropy_loss = -14.95, learner_queue_size = 64, _tick = 9344, _time = 1.6548e+09)
[2022-06-09 19:00:33,194][root][INFO] - Step 60354560 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.9196e+04, step = 60354560, mean_episode_return = None, mean_episode_step = 2243.0, total_loss = 51.231, pg_loss = 44.272, baseline_loss = 21.911, entropy_loss = -14.952, learner_queue_size = 64, _tick = 9345, _time = 1.6548e+09)
[2022-06-09 19:00:38,198][root][INFO] - Step 60369920 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.9201e+04, step = 60369920, mean_episode_return = 50.236, mean_episode_step = 1872.0, total_loss = 97.468, pg_loss = 51.978, baseline_loss = 60.435, entropy_loss = -14.944, learner_queue_size = 64, _tick = 9347, _time = 1.6548e+09)
[2022-06-09 19:00:43,202][root][INFO] - Step 60390400 @ 4092.7 SPS. Inference batcher size: 77. Learner queue size: 64. Other stats: (train_seconds = 1.9206e+04, step = 60390400, mean_episode_return = 62.347, mean_episode_step = 1679.1, total_loss = 66.282, pg_loss = 24.94, baseline_loss = 56.229, entropy_loss = -14.886, learner_queue_size = 64, _tick = 9351, _time = 1.6548e+09)
[2022-06-09 19:00:48,206][root][INFO] - Step 60405760 @ 3069.6 SPS. Inference batcher size: 73. Learner queue size: 64. Other stats: (train_seconds = 1.9211e+04, step = 60405760, mean_episode_return = 20.66, mean_episode_step = 1914.1, total_loss = 100.78, pg_loss = 80.943, baseline_loss = 34.77, entropy_loss = -14.937, learner_queue_size = 64, _tick = 9354, _time = 1.6548e+09)
[2022-06-09 19:00:53,210][root][INFO] - Step 60421120 @ 3069.5 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 1.9216e+04, step = 60421120, mean_episode_return = 86.558, mean_episode_step = 1659.2, total_loss = -124.51, pg_loss = -135.2, baseline_loss = 25.419, entropy_loss = -14.732, learner_queue_size = 64, _tick = 9357, _time = 1.6548e+09)
[2022-06-09 19:00:58,214][root][INFO] - Step 60436480 @ 3069.6 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 1.9221e+04, step = 60436480, mean_episode_return = None, mean_episode_step = 1805.9, total_loss = 245.27, pg_loss = 203.92, baseline_loss = 56.04, entropy_loss = -14.693, learner_queue_size = 64, _tick = 9358, _time = 1.6548e+09)
[2022-06-09 19:01:03,218][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 19:01:03,414][root][INFO] - Step 60451840 @ 3069.5 SPS. Inference batcher size: 15. Learner queue size: 64. Other stats: (train_seconds = 1.9226e+04, step = 60451840, mean_episode_return = 145.21, mean_episode_step = 1677.9, total_loss = -34.43, pg_loss = -42.347, baseline_loss = 22.39, entropy_loss = -14.474, learner_queue_size = 64, _tick = 9361, _time = 1.6548e+09)
[2022-06-09 19:01:08,418][root][INFO] - Step 60467200 @ 2953.8 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.9231e+04, step = 60467200, mean_episode_return = 80.217, mean_episode_step = 1995.5, total_loss = 347.07, pg_loss = 257.88, baseline_loss = 103.66, entropy_loss = -14.472, learner_queue_size = 64, _tick = 9364, _time = 1.6548e+09)
[2022-06-09 19:01:13,422][root][INFO] - Step 60482560 @ 3069.5 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 1.9236e+04, step = 60482560, mean_episode_return = 62.502, mean_episode_step = 2189.6, total_loss = -203.96, pg_loss = -194.21, baseline_loss = 4.7659, entropy_loss = -14.512, learner_queue_size = 64, _tick = 9367, _time = 1.6548e+09)
[2022-06-09 19:01:18,426][root][INFO] - Step 60497920 @ 3069.6 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 1.9241e+04, step = 60497920, mean_episode_return = None, mean_episode_step = 2082.0, total_loss = -21.706, pg_loss = -34.906, baseline_loss = 27.673, entropy_loss = -14.472, learner_queue_size = 64, _tick = 9368, _time = 1.6548e+09)
[2022-06-09 19:01:23,430][root][INFO] - Step 60513280 @ 3069.5 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.9246e+04, step = 60513280, mean_episode_return = None, mean_episode_step = 1965.2, total_loss = -124.59, pg_loss = -122.13, baseline_loss = 12.039, entropy_loss = -14.506, learner_queue_size = 64, _tick = 9369, _time = 1.6548e+09)
[2022-06-09 19:01:28,434][root][INFO] - Step 60528640 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.9251e+04, step = 60528640, mean_episode_return = 22.826, mean_episode_step = 2231.4, total_loss = -16.208, pg_loss = -38.261, baseline_loss = 36.535, entropy_loss = -14.482, learner_queue_size = 64, _tick = 9372, _time = 1.6548e+09)
[2022-06-09 19:01:33,438][root][INFO] - Step 60544000 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.9256e+04, step = 60544000, mean_episode_return = 66.36, mean_episode_step = 1697.1, total_loss = 158.64, pg_loss = 142.65, baseline_loss = 30.309, entropy_loss = -14.319, learner_queue_size = 64, _tick = 9375, _time = 1.6548e+09)
[2022-06-09 19:01:38,442][root][INFO] - Step 60559360 @ 3069.5 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.9261e+04, step = 60559360, mean_episode_return = 83.548, mean_episode_step = 1877.2, total_loss = -91.353, pg_loss = -98.156, baseline_loss = 21.058, entropy_loss = -14.256, learner_queue_size = 64, _tick = 9378, _time = 1.6548e+09)
[2022-06-09 19:01:43,446][root][INFO] - Step 60579840 @ 4092.7 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 1.9266e+04, step = 60579840, mean_episode_return = 28.135, mean_episode_step = 1808.2, total_loss = -401.12, pg_loss = -395.62, baseline_loss = 8.63, entropy_loss = -14.128, learner_queue_size = 64, _tick = 9381, _time = 1.6548e+09)
[2022-06-09 19:01:48,450][root][INFO] - Step 60595200 @ 3069.6 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 1.9271e+04, step = 60595200, mean_episode_return = 41.74, mean_episode_step = 1875.3, total_loss = -137.58, pg_loss = -147.31, baseline_loss = 23.893, entropy_loss = -14.166, learner_queue_size = 64, _tick = 9383, _time = 1.6548e+09)
[2022-06-09 19:01:53,454][root][INFO] - Step 60610560 @ 3069.5 SPS. Inference batcher size: 77. Learner queue size: 64. Other stats: (train_seconds = 1.9276e+04, step = 60610560, mean_episode_return = 29.74, mean_episode_step = 1991.1, total_loss = -130.11, pg_loss = -130.19, baseline_loss = 14.33, entropy_loss = -14.251, learner_queue_size = 64, _tick = 9386, _time = 1.6548e+09)
[2022-06-09 19:01:58,458][root][INFO] - Step 60625920 @ 3069.5 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 1.9281e+04, step = 60625920, mean_episode_return = 26.796, mean_episode_step = 1649.7, total_loss = 23.446, pg_loss = 5.4852, baseline_loss = 32.216, entropy_loss = -14.255, learner_queue_size = 64, _tick = 9388, _time = 1.6548e+09)
[2022-06-09 19:02:03,462][root][INFO] - Step 60641280 @ 3069.6 SPS. Inference batcher size: 14. Learner queue size: 64. Other stats: (train_seconds = 1.9286e+04, step = 60641280, mean_episode_return = 25.85, mean_episode_step = 2177.8, total_loss = -305.56, pg_loss = -304.38, baseline_loss = 13.097, entropy_loss = -14.277, learner_queue_size = 64, _tick = 9391, _time = 1.6548e+09)
[2022-06-09 19:02:08,466][root][INFO] - Step 60656640 @ 3069.5 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.9291e+04, step = 60656640, mean_episode_return = 51.1, mean_episode_step = 1657.7, total_loss = 25.22, pg_loss = 1.32, baseline_loss = 38.148, entropy_loss = -14.248, learner_queue_size = 64, _tick = 9394, _time = 1.6548e+09)
[2022-06-09 19:02:13,470][root][INFO] - Step 60672000 @ 3069.6 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.9296e+04, step = 60672000, mean_episode_return = 64.129, mean_episode_step = 1698.7, total_loss = -146.56, pg_loss = -138.75, baseline_loss = 6.3528, entropy_loss = -14.162, learner_queue_size = 64, _tick = 9397, _time = 1.6548e+09)
[2022-06-09 19:02:18,474][root][INFO] - Step 60687360 @ 3069.6 SPS. Inference batcher size: 7. Learner queue size: 64. Other stats: (train_seconds = 1.9301e+04, step = 60687360, mean_episode_return = 18.68, mean_episode_step = 1752.6, total_loss = 190.29, pg_loss = 154.3, baseline_loss = 50.203, entropy_loss = -14.218, learner_queue_size = 64, _tick = 9400, _time = 1.6548e+09)
[2022-06-09 19:02:23,478][root][INFO] - Step 60702720 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.9306e+04, step = 60702720, mean_episode_return = 34.853, mean_episode_step = 1677.8, total_loss = -88.797, pg_loss = -88.384, baseline_loss = 13.745, entropy_loss = -14.159, learner_queue_size = 64, _tick = 9402, _time = 1.6548e+09)
[2022-06-09 19:02:28,484][root][INFO] - Step 60723200 @ 4091.3 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.9311e+04, step = 60723200, mean_episode_return = 85.81, mean_episode_step = 1682.8, total_loss = 246.12, pg_loss = 200.69, baseline_loss = 59.574, entropy_loss = -14.136, learner_queue_size = 64, _tick = 9406, _time = 1.6548e+09)
[2022-06-09 19:02:33,486][root][INFO] - Step 60738560 @ 3070.6 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 1.9316e+04, step = 60738560, mean_episode_return = 29.911, mean_episode_step = 1885.1, total_loss = -261.25, pg_loss = -266.2, baseline_loss = 19.027, entropy_loss = -14.075, learner_queue_size = 64, _tick = 9409, _time = 1.6548e+09)
[2022-06-09 19:02:38,490][root][INFO] - Step 60753920 @ 3069.5 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 1.9321e+04, step = 60753920, mean_episode_return = 56.18, mean_episode_step = 1753.2, total_loss = 441.46, pg_loss = 367.53, baseline_loss = 88.131, entropy_loss = -14.203, learner_queue_size = 64, _tick = 9412, _time = 1.6548e+09)
[2022-06-09 19:02:43,494][root][INFO] - Step 60769280 @ 3069.6 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 1.9326e+04, step = 60769280, mean_episode_return = 24.427, mean_episode_step = 1628.9, total_loss = -56.906, pg_loss = -73.789, baseline_loss = 31.039, entropy_loss = -14.155, learner_queue_size = 64, _tick = 9415, _time = 1.6548e+09)
[2022-06-09 19:02:48,498][root][INFO] - Step 60784640 @ 3069.6 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.9331e+04, step = 60784640, mean_episode_return = 34.461, mean_episode_step = 1821.3, total_loss = 19.35, pg_loss = 1.5864, baseline_loss = 31.935, entropy_loss = -14.171, learner_queue_size = 64, _tick = 9418, _time = 1.6548e+09)
[2022-06-09 19:02:53,502][root][INFO] - Step 60800000 @ 3069.5 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 1.9336e+04, step = 60800000, mean_episode_return = 50.725, mean_episode_step = 1828.9, total_loss = 334.89, pg_loss = 297.9, baseline_loss = 51.203, entropy_loss = -14.21, learner_queue_size = 64, _tick = 9420, _time = 1.6548e+09)
[2022-06-09 19:02:58,506][root][INFO] - Step 60815360 @ 3069.6 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.9341e+04, step = 60815360, mean_episode_return = 45.37, mean_episode_step = 1792.9, total_loss = -62.654, pg_loss = -64.699, baseline_loss = 16.16, entropy_loss = -14.115, learner_queue_size = 64, _tick = 9423, _time = 1.6548e+09)
[2022-06-09 19:03:03,513][root][INFO] - Step 60830720 @ 3067.7 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.9346e+04, step = 60830720, mean_episode_return = 60.061, mean_episode_step = 1615.9, total_loss = 118.86, pg_loss = 99.715, baseline_loss = 33.249, entropy_loss = -14.102, learner_queue_size = 64, _tick = 9426, _time = 1.6548e+09)
[2022-06-09 19:03:08,515][root][INFO] - Step 60846080 @ 3070.7 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 1.9352e+04, step = 60846080, mean_episode_return = 96.006, mean_episode_step = 1765.8, total_loss = 155.37, pg_loss = 123.5, baseline_loss = 45.989, entropy_loss = -14.111, learner_queue_size = 64, _tick = 9429, _time = 1.6548e+09)
[2022-06-09 19:03:13,518][root][INFO] - Step 60866560 @ 4093.7 SPS. Inference batcher size: 88. Learner queue size: 64. Other stats: (train_seconds = 1.9356e+04, step = 60866560, mean_episode_return = None, mean_episode_step = 1869.4, total_loss = -65.455, pg_loss = -70.688, baseline_loss = 19.196, entropy_loss = -13.962, learner_queue_size = 64, _tick = 9432, _time = 1.6548e+09)
[2022-06-09 19:03:18,522][root][INFO] - Step 60881920 @ 3069.6 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.9362e+04, step = 60881920, mean_episode_return = 40.183, mean_episode_step = 1701.8, total_loss = -43.469, pg_loss = -56.003, baseline_loss = 26.412, entropy_loss = -13.878, learner_queue_size = 64, _tick = 9433, _time = 1.6548e+09)
[2022-06-09 19:03:23,526][root][INFO] - Step 60897280 @ 3069.4 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 1.9366e+04, step = 60897280, mean_episode_return = -35.72, mean_episode_step = 1735.0, total_loss = -48.239, pg_loss = -60.038, baseline_loss = 25.83, entropy_loss = -14.031, learner_queue_size = 64, _tick = 9436, _time = 1.6548e+09)
[2022-06-09 19:03:28,530][root][INFO] - Step 60912640 @ 3069.6 SPS. Inference batcher size: 73. Learner queue size: 64. Other stats: (train_seconds = 1.9372e+04, step = 60912640, mean_episode_return = 31.231, mean_episode_step = 1948.9, total_loss = -64.938, pg_loss = -78.608, baseline_loss = 27.739, entropy_loss = -14.07, learner_queue_size = 64, _tick = 9438, _time = 1.6548e+09)
[2022-06-09 19:03:33,534][root][INFO] - Step 60928000 @ 3069.6 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.9376e+04, step = 60928000, mean_episode_return = None, mean_episode_step = 1839.1, total_loss = 312.29, pg_loss = 259.69, baseline_loss = 66.894, entropy_loss = -14.302, learner_queue_size = 64, _tick = 9438, _time = 1.6548e+09)
[2022-06-09 19:03:38,538][root][INFO] - Step 60943360 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.9382e+04, step = 60943360, mean_episode_return = 37.866, mean_episode_step = 1811.0, total_loss = -158.71, pg_loss = -167.36, baseline_loss = 22.926, entropy_loss = -14.275, learner_queue_size = 64, _tick = 9441, _time = 1.6548e+09)
[2022-06-09 19:03:43,542][root][INFO] - Step 60958720 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.9386e+04, step = 60958720, mean_episode_return = None, mean_episode_step = 1796.5, total_loss = 3.3876, pg_loss = -5.1257, baseline_loss = 22.709, entropy_loss = -14.195, learner_queue_size = 64, _tick = 9442, _time = 1.6548e+09)
[2022-06-09 19:03:48,546][root][INFO] - Step 60979200 @ 4092.5 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 1.9392e+04, step = 60979200, mean_episode_return = 65.409, mean_episode_step = 2224.8, total_loss = 209.35, pg_loss = 171.81, baseline_loss = 51.497, entropy_loss = -13.962, learner_queue_size = 64, _tick = 9446, _time = 1.6548e+09)
[2022-06-09 19:03:53,550][root][INFO] - Step 60994560 @ 3069.7 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 1.9396e+04, step = 60994560, mean_episode_return = 7.8495, mean_episode_step = 1948.6, total_loss = -45.939, pg_loss = -49.353, baseline_loss = 17.333, entropy_loss = -13.919, learner_queue_size = 64, _tick = 9449, _time = 1.6548e+09)
[2022-06-09 19:03:58,554][root][INFO] - Step 61009920 @ 3069.6 SPS. Inference batcher size: 76. Learner queue size: 64. Other stats: (train_seconds = 1.9402e+04, step = 61009920, mean_episode_return = 72.38, mean_episode_step = 1824.0, total_loss = 249.69, pg_loss = 208.14, baseline_loss = 55.136, entropy_loss = -13.585, learner_queue_size = 64, _tick = 9452, _time = 1.6548e+09)
[2022-06-09 19:04:03,558][root][INFO] - Step 61025280 @ 3069.6 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 1.9406e+04, step = 61025280, mean_episode_return = 104.05, mean_episode_step = 1925.3, total_loss = 72.077, pg_loss = 37.95, baseline_loss = 47.962, entropy_loss = -13.835, learner_queue_size = 64, _tick = 9454, _time = 1.6548e+09)
[2022-06-09 19:04:08,562][root][INFO] - Step 61040640 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.9412e+04, step = 61040640, mean_episode_return = 20.21, mean_episode_step = 2212.8, total_loss = -173.27, pg_loss = -175.44, baseline_loss = 15.946, entropy_loss = -13.775, learner_queue_size = 64, _tick = 9457, _time = 1.6548e+09)
[2022-06-09 19:04:13,566][root][INFO] - Step 61056000 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.9416e+04, step = 61056000, mean_episode_return = 50.326, mean_episode_step = 1893.5, total_loss = -138.12, pg_loss = -140.91, baseline_loss = 16.603, entropy_loss = -13.814, learner_queue_size = 64, _tick = 9459, _time = 1.6548e+09)
[2022-06-09 19:04:18,570][root][INFO] - Step 61071360 @ 3069.6 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.9422e+04, step = 61071360, mean_episode_return = 29.679, mean_episode_step = 1911.8, total_loss = -28.038, pg_loss = -50.163, baseline_loss = 35.952, entropy_loss = -13.826, learner_queue_size = 64, _tick = 9461, _time = 1.6548e+09)
[2022-06-09 19:04:23,574][root][INFO] - Step 61086720 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.9426e+04, step = 61086720, mean_episode_return = 69.258, mean_episode_step = 1640.9, total_loss = 315.35, pg_loss = 248.08, baseline_loss = 81.207, entropy_loss = -13.942, learner_queue_size = 64, _tick = 9463, _time = 1.6548e+09)
[2022-06-09 19:04:28,578][root][INFO] - Step 61102080 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 1.9432e+04, step = 61102080, mean_episode_return = None, mean_episode_step = 2155.6, total_loss = 366.55, pg_loss = 320.94, baseline_loss = 59.427, entropy_loss = -13.813, learner_queue_size = 64, _tick = 9465, _time = 1.6548e+09)
[2022-06-09 19:04:33,582][root][INFO] - Step 61117440 @ 3069.6 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.9436e+04, step = 61117440, mean_episode_return = 76.93, mean_episode_step = 1876.4, total_loss = 107.42, pg_loss = 88.104, baseline_loss = 32.982, entropy_loss = -13.662, learner_queue_size = 64, _tick = 9467, _time = 1.6548e+09)
[2022-06-09 19:04:38,586][root][INFO] - Step 61137920 @ 4092.8 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.9442e+04, step = 61137920, mean_episode_return = -13.011, mean_episode_step = 2199.1, total_loss = 298.28, pg_loss = 201.32, baseline_loss = 110.65, entropy_loss = -13.683, learner_queue_size = 64, _tick = 9471, _time = 1.6548e+09)
[2022-06-09 19:04:43,590][root][INFO] - Step 61153280 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.9446e+04, step = 61153280, mean_episode_return = 11.75, mean_episode_step = 1923.4, total_loss = -29.102, pg_loss = -73.737, baseline_loss = 58.23, entropy_loss = -13.596, learner_queue_size = 64, _tick = 9474, _time = 1.6548e+09)
[2022-06-09 19:04:48,604][root][INFO] - Step 61168640 @ 3063.4 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 1.9452e+04, step = 61168640, mean_episode_return = -5.5603, mean_episode_step = 2157.8, total_loss = 96.575, pg_loss = 54.612, baseline_loss = 55.594, entropy_loss = -13.632, learner_queue_size = 64, _tick = 9477, _time = 1.6548e+09)
[2022-06-09 19:04:53,610][root][INFO] - Step 61184000 @ 3068.3 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 1.9456e+04, step = 61184000, mean_episode_return = 55.895, mean_episode_step = 2024.0, total_loss = 103.21, pg_loss = 72.803, baseline_loss = 44.267, entropy_loss = -13.856, learner_queue_size = 64, _tick = 9480, _time = 1.6548e+09)
[2022-06-09 19:04:58,614][root][INFO] - Step 61199360 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.9462e+04, step = 61199360, mean_episode_return = 116.96, mean_episode_step = 2216.6, total_loss = -40.469, pg_loss = -48.429, baseline_loss = 21.933, entropy_loss = -13.973, learner_queue_size = 64, _tick = 9483, _time = 1.6548e+09)
[2022-06-09 19:05:03,618][root][INFO] - Step 61214720 @ 3069.6 SPS. Inference batcher size: 15. Learner queue size: 64. Other stats: (train_seconds = 1.9467e+04, step = 61214720, mean_episode_return = 2.8345, mean_episode_step = 1945.5, total_loss = 382.24, pg_loss = 260.33, baseline_loss = 135.95, entropy_loss = -14.038, learner_queue_size = 64, _tick = 9486, _time = 1.6548e+09)
[2022-06-09 19:05:08,622][root][INFO] - Step 61230080 @ 3069.5 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 1.9472e+04, step = 61230080, mean_episode_return = 105.36, mean_episode_step = 1747.2, total_loss = -92.062, pg_loss = -97.182, baseline_loss = 19.23, entropy_loss = -14.111, learner_queue_size = 64, _tick = 9489, _time = 1.6548e+09)
[2022-06-09 19:05:13,626][root][INFO] - Step 61245440 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 1.9477e+04, step = 61245440, mean_episode_return = 27.286, mean_episode_step = 2076.0, total_loss = -159.67, pg_loss = -161.53, baseline_loss = 15.963, entropy_loss = -14.099, learner_queue_size = 64, _tick = 9492, _time = 1.6548e+09)
[2022-06-09 19:05:18,630][root][INFO] - Step 61260800 @ 3069.6 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.9482e+04, step = 61260800, mean_episode_return = 27.891, mean_episode_step = 2143.2, total_loss = -38.763, pg_loss = -55.764, baseline_loss = 31.121, entropy_loss = -14.12, learner_queue_size = 64, _tick = 9495, _time = 1.6548e+09)
[2022-06-09 19:05:23,634][root][INFO] - Step 61276160 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.9487e+04, step = 61276160, mean_episode_return = 29.318, mean_episode_step = 2243.2, total_loss = -397.15, pg_loss = -390.16, baseline_loss = 7.2313, entropy_loss = -14.218, learner_queue_size = 64, _tick = 9498, _time = 1.6548e+09)
[2022-06-09 19:05:28,640][root][INFO] - Step 61291520 @ 3068.3 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.9492e+04, step = 61291520, mean_episode_return = 43.401, mean_episode_step = 1909.8, total_loss = 27.898, pg_loss = 12.153, baseline_loss = 30.049, entropy_loss = -14.304, learner_queue_size = 64, _tick = 9501, _time = 1.6548e+09)
[2022-06-09 19:05:33,646][root][INFO] - Step 61312000 @ 4091.0 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 1.9497e+04, step = 61312000, mean_episode_return = 15.2, mean_episode_step = 1886.5, total_loss = 7.9821, pg_loss = 4.34, baseline_loss = 17.816, entropy_loss = -14.174, learner_queue_size = 64, _tick = 9505, _time = 1.6548e+09)
[2022-06-09 19:05:38,650][root][INFO] - Step 61327360 @ 3069.6 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 1.9502e+04, step = 61327360, mean_episode_return = 51.641, mean_episode_step = 1872.3, total_loss = 194.19, pg_loss = 163.6, baseline_loss = 44.953, entropy_loss = -14.369, learner_queue_size = 64, _tick = 9508, _time = 1.6548e+09)
[2022-06-09 19:05:43,656][root][INFO] - Step 61342720 @ 3068.3 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 1.9507e+04, step = 61342720, mean_episode_return = 111.66, mean_episode_step = 1941.9, total_loss = -103.11, pg_loss = -104.07, baseline_loss = 15.308, entropy_loss = -14.353, learner_queue_size = 64, _tick = 9511, _time = 1.6548e+09)
[2022-06-09 19:05:48,658][root][INFO] - Step 61358080 @ 3070.8 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 1.9512e+04, step = 61358080, mean_episode_return = -4.6409, mean_episode_step = 2088.2, total_loss = 200.21, pg_loss = 152.77, baseline_loss = 61.798, entropy_loss = -14.363, learner_queue_size = 64, _tick = 9513, _time = 1.6548e+09)
[2022-06-09 19:05:53,662][root][INFO] - Step 61373440 @ 3069.6 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 1.9517e+04, step = 61373440, mean_episode_return = 6.9595, mean_episode_step = 1779.4, total_loss = -109.06, pg_loss = -106.32, baseline_loss = 11.608, entropy_loss = -14.353, learner_queue_size = 64, _tick = 9516, _time = 1.6548e+09)
[2022-06-09 19:05:58,666][root][INFO] - Step 61388800 @ 3069.5 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 1.9522e+04, step = 61388800, mean_episode_return = 58.706, mean_episode_step = 2144.7, total_loss = -18.348, pg_loss = -38.258, baseline_loss = 34.224, entropy_loss = -14.314, learner_queue_size = 64, _tick = 9519, _time = 1.6548e+09)
[2022-06-09 19:06:03,672][root][INFO] - Step 61404160 @ 3068.4 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.9527e+04, step = 61404160, mean_episode_return = 50.474, mean_episode_step = 1812.6, total_loss = -127.39, pg_loss = -122.81, baseline_loss = 9.6367, entropy_loss = -14.221, learner_queue_size = 64, _tick = 9522, _time = 1.6548e+09)
[2022-06-09 19:06:08,674][root][INFO] - Step 61419520 @ 3070.7 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 1.9532e+04, step = 61419520, mean_episode_return = 46.514, mean_episode_step = 1941.9, total_loss = 73.121, pg_loss = 61.043, baseline_loss = 26.367, entropy_loss = -14.289, learner_queue_size = 64, _tick = 9525, _time = 1.6548e+09)
[2022-06-09 19:06:13,678][root][INFO] - Step 61434880 @ 3069.5 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 1.9537e+04, step = 61434880, mean_episode_return = 70.832, mean_episode_step = 1807.3, total_loss = 250.91, pg_loss = 212.11, baseline_loss = 53.133, entropy_loss = -14.331, learner_queue_size = 64, _tick = 9528, _time = 1.6548e+09)
[2022-06-09 19:06:18,684][root][INFO] - Step 61450240 @ 3068.3 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.9542e+04, step = 61450240, mean_episode_return = 90.657, mean_episode_step = 1715.6, total_loss = -170.46, pg_loss = -168.74, baseline_loss = 12.682, entropy_loss = -14.394, learner_queue_size = 64, _tick = 9531, _time = 1.6548e+09)
[2022-06-09 19:06:23,690][root][INFO] - Step 61465600 @ 3068.4 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.9547e+04, step = 61465600, mean_episode_return = 24.705, mean_episode_step = 1503.9, total_loss = 101.93, pg_loss = 65.802, baseline_loss = 50.466, entropy_loss = -14.341, learner_queue_size = 64, _tick = 9534, _time = 1.6548e+09)
[2022-06-09 19:06:28,694][root][INFO] - Step 61486080 @ 4092.8 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.9552e+04, step = 61486080, mean_episode_return = -8.8505, mean_episode_step = 1795.0, total_loss = 229.67, pg_loss = 197.91, baseline_loss = 46.071, entropy_loss = -14.309, learner_queue_size = 64, _tick = 9538, _time = 1.6548e+09)
[2022-06-09 19:06:33,698][root][INFO] - Step 61501440 @ 3069.5 SPS. Inference batcher size: 6. Learner queue size: 64. Other stats: (train_seconds = 1.9557e+04, step = 61501440, mean_episode_return = 68.102, mean_episode_step = 1501.4, total_loss = 83.55, pg_loss = 62.891, baseline_loss = 34.957, entropy_loss = -14.298, learner_queue_size = 64, _tick = 9540, _time = 1.6548e+09)
[2022-06-09 19:06:38,702][root][INFO] - Step 61516800 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.9562e+04, step = 61516800, mean_episode_return = None, mean_episode_step = 1823.3, total_loss = 205.79, pg_loss = 164.02, baseline_loss = 55.923, entropy_loss = -14.144, learner_queue_size = 64, _tick = 9542, _time = 1.6548e+09)
[2022-06-09 19:06:43,706][root][INFO] - Step 61532160 @ 3069.5 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 1.9567e+04, step = 61532160, mean_episode_return = 58.704, mean_episode_step = 1884.1, total_loss = 14.527, pg_loss = -2.1641, baseline_loss = 31.009, entropy_loss = -14.318, learner_queue_size = 64, _tick = 9544, _time = 1.6548e+09)
[2022-06-09 19:06:48,710][root][INFO] - Step 61547520 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.9572e+04, step = 61547520, mean_episode_return = 14.789, mean_episode_step = 1708.2, total_loss = 463.35, pg_loss = 374.17, baseline_loss = 103.34, entropy_loss = -14.169, learner_queue_size = 64, _tick = 9546, _time = 1.6548e+09)
[2022-06-09 19:06:53,714][root][INFO] - Step 61562880 @ 3069.5 SPS. Inference batcher size: 7. Learner queue size: 64. Other stats: (train_seconds = 1.9577e+04, step = 61562880, mean_episode_return = 18.62, mean_episode_step = 1671.6, total_loss = -142.48, pg_loss = -141.54, baseline_loss = 13.256, entropy_loss = -14.199, learner_queue_size = 64, _tick = 9549, _time = 1.6548e+09)
[2022-06-09 19:06:58,718][root][INFO] - Step 61578240 @ 3069.6 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.9582e+04, step = 61578240, mean_episode_return = 60.339, mean_episode_step = 1913.6, total_loss = 346.67, pg_loss = 300.55, baseline_loss = 60.248, entropy_loss = -14.137, learner_queue_size = 64, _tick = 9552, _time = 1.6548e+09)
[2022-06-09 19:07:03,722][root][INFO] - Step 61593600 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.9587e+04, step = 61593600, mean_episode_return = 37.804, mean_episode_step = 1658.6, total_loss = 86.073, pg_loss = 45.357, baseline_loss = 54.798, entropy_loss = -14.082, learner_queue_size = 64, _tick = 9555, _time = 1.6548e+09)
[2022-06-09 19:07:08,726][root][INFO] - Step 61614080 @ 4092.7 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.9592e+04, step = 61614080, mean_episode_return = None, mean_episode_step = 1745.3, total_loss = -128.03, pg_loss = -124.38, baseline_loss = 10.469, entropy_loss = -14.119, learner_queue_size = 64, _tick = 9558, _time = 1.6548e+09)
[2022-06-09 19:07:13,730][root][INFO] - Step 61629440 @ 3069.5 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 1.9597e+04, step = 61629440, mean_episode_return = 23.216, mean_episode_step = 1608.0, total_loss = -230.51, pg_loss = -228.77, baseline_loss = 12.615, entropy_loss = -14.354, learner_queue_size = 64, _tick = 9560, _time = 1.6548e+09)
[2022-06-09 19:07:18,734][root][INFO] - Step 61644800 @ 3069.6 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.9602e+04, step = 61644800, mean_episode_return = 56.784, mean_episode_step = 1806.6, total_loss = -203.17, pg_loss = -204.91, baseline_loss = 15.993, entropy_loss = -14.253, learner_queue_size = 64, _tick = 9563, _time = 1.6548e+09)
[2022-06-09 19:07:23,738][root][INFO] - Step 61660160 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 1.9607e+04, step = 61660160, mean_episode_return = None, mean_episode_step = 1380.1, total_loss = 387.7, pg_loss = 351.82, baseline_loss = 50.114, entropy_loss = -14.237, learner_queue_size = 64, _tick = 9565, _time = 1.6548e+09)
[2022-06-09 19:07:28,742][root][INFO] - Step 61675520 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.9612e+04, step = 61675520, mean_episode_return = 26.649, mean_episode_step = 1595.9, total_loss = 63.098, pg_loss = 37.445, baseline_loss = 39.861, entropy_loss = -14.209, learner_queue_size = 64, _tick = 9567, _time = 1.6548e+09)
[2022-06-09 19:07:33,746][root][INFO] - Step 61690880 @ 3069.5 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.9617e+04, step = 61690880, mean_episode_return = 19.6, mean_episode_step = 1673.4, total_loss = -56.485, pg_loss = -59.388, baseline_loss = 17.052, entropy_loss = -14.149, learner_queue_size = 64, _tick = 9570, _time = 1.6548e+09)
[2022-06-09 19:07:38,750][root][INFO] - Step 61706240 @ 3069.5 SPS. Inference batcher size: 2. Learner queue size: 64. Other stats: (train_seconds = 1.9622e+04, step = 61706240, mean_episode_return = 194.3, mean_episode_step = 1570.8, total_loss = -80.809, pg_loss = -89.555, baseline_loss = 23.037, entropy_loss = -14.292, learner_queue_size = 64, _tick = 9572, _time = 1.6548e+09)
[2022-06-09 19:07:43,754][root][INFO] - Step 61721600 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.9627e+04, step = 61721600, mean_episode_return = 3.2399, mean_episode_step = 1743.4, total_loss = 147.3, pg_loss = 116.65, baseline_loss = 44.997, entropy_loss = -14.353, learner_queue_size = 64, _tick = 9574, _time = 1.6548e+09)
[2022-06-09 19:07:48,760][root][INFO] - Step 61736960 @ 3068.3 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.9632e+04, step = 61736960, mean_episode_return = -3.7203, mean_episode_step = 1686.0, total_loss = -159.33, pg_loss = -157.24, baseline_loss = 12.085, entropy_loss = -14.174, learner_queue_size = 64, _tick = 9577, _time = 1.6548e+09)
[2022-06-09 19:07:53,761][root][INFO] - Step 61752320 @ 3071.3 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.9637e+04, step = 61752320, mean_episode_return = 33.817, mean_episode_step = 1821.9, total_loss = -51.677, pg_loss = -61.435, baseline_loss = 24.007, entropy_loss = -14.25, learner_queue_size = 64, _tick = 9580, _time = 1.6548e+09)
[2022-06-09 19:07:58,767][root][INFO] - Step 61767680 @ 3068.3 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 1.9642e+04, step = 61767680, mean_episode_return = 69.739, mean_episode_step = 1818.3, total_loss = 600.86, pg_loss = 354.11, baseline_loss = 260.96, entropy_loss = -14.207, learner_queue_size = 64, _tick = 9582, _time = 1.6548e+09)
[2022-06-09 19:08:03,773][root][INFO] - Step 61788160 @ 4091.0 SPS. Inference batcher size: 87. Learner queue size: 64. Other stats: (train_seconds = 1.9647e+04, step = 61788160, mean_episode_return = None, mean_episode_step = 1992.5, total_loss = 231.94, pg_loss = 189.87, baseline_loss = 56.27, entropy_loss = -14.202, learner_queue_size = 64, _tick = 9583, _time = 1.6548e+09)
[2022-06-09 19:08:08,780][root][INFO] - Step 61803520 @ 3068.2 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 1.9652e+04, step = 61803520, mean_episode_return = 61.551, mean_episode_step = 1929.6, total_loss = 123.52, pg_loss = 99.571, baseline_loss = 38.142, entropy_loss = -14.195, learner_queue_size = 64, _tick = 9586, _time = 1.6548e+09)
[2022-06-09 19:08:13,782][root][INFO] - Step 61818880 @ 3070.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.9657e+04, step = 61818880, mean_episode_return = -12.221, mean_episode_step = 1822.5, total_loss = 1580.7, pg_loss = 519.89, baseline_loss = 1074.8, entropy_loss = -13.927, learner_queue_size = 64, _tick = 9589, _time = 1.6548e+09)
[2022-06-09 19:08:18,786][root][INFO] - Step 61834240 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.9662e+04, step = 61834240, mean_episode_return = 44.581, mean_episode_step = 1620.5, total_loss = 188.01, pg_loss = 146.21, baseline_loss = 55.484, entropy_loss = -13.678, learner_queue_size = 64, _tick = 9591, _time = 1.6548e+09)
[2022-06-09 19:08:23,790][root][INFO] - Step 61849600 @ 3069.4 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.9667e+04, step = 61849600, mean_episode_return = 51.257, mean_episode_step = 2079.1, total_loss = 39.559, pg_loss = 15.606, baseline_loss = 37.676, entropy_loss = -13.723, learner_queue_size = 64, _tick = 9592, _time = 1.6548e+09)
[2022-06-09 19:08:28,794][root][INFO] - Step 61864960 @ 3069.7 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 1.9672e+04, step = 61864960, mean_episode_return = 58.95, mean_episode_step = 1919.5, total_loss = -94.138, pg_loss = -107.14, baseline_loss = 27.031, entropy_loss = -14.028, learner_queue_size = 64, _tick = 9593, _time = 1.6548e+09)
[2022-06-09 19:08:33,798][root][INFO] - Step 61885440 @ 4092.5 SPS. Inference batcher size: 100. Learner queue size: 64. Other stats: (train_seconds = 1.9677e+04, step = 61885440, mean_episode_return = 44.953, mean_episode_step = 2231.3, total_loss = 130.73, pg_loss = 96.123, baseline_loss = 48.646, entropy_loss = -14.039, learner_queue_size = 64, _tick = 9597, _time = 1.6548e+09)
[2022-06-09 19:08:38,802][root][INFO] - Step 61900800 @ 3069.8 SPS. Inference batcher size: 80. Learner queue size: 64. Other stats: (train_seconds = 1.9682e+04, step = 61900800, mean_episode_return = 95.217, mean_episode_step = 2089.7, total_loss = 215.77, pg_loss = 186.72, baseline_loss = 43.367, entropy_loss = -14.319, learner_queue_size = 64, _tick = 9600, _time = 1.6548e+09)
[2022-06-09 19:08:43,806][root][INFO] - Step 61916160 @ 3069.5 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 1.9687e+04, step = 61916160, mean_episode_return = 60.092, mean_episode_step = 1825.0, total_loss = 93.425, pg_loss = 64.432, baseline_loss = 43.3, entropy_loss = -14.307, learner_queue_size = 64, _tick = 9603, _time = 1.6548e+09)
[2022-06-09 19:08:48,810][root][INFO] - Step 61931520 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.9692e+04, step = 61931520, mean_episode_return = 41.71, mean_episode_step = 1889.8, total_loss = -115.88, pg_loss = -128.44, baseline_loss = 26.905, entropy_loss = -14.35, learner_queue_size = 64, _tick = 9606, _time = 1.6548e+09)
[2022-06-09 19:08:53,814][root][INFO] - Step 61946880 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.9697e+04, step = 61946880, mean_episode_return = 19.21, mean_episode_step = 1738.5, total_loss = 356.75, pg_loss = 299.86, baseline_loss = 71.357, entropy_loss = -14.466, learner_queue_size = 64, _tick = 9608, _time = 1.6548e+09)
[2022-06-09 19:08:58,818][root][INFO] - Step 61962240 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.9702e+04, step = 61962240, mean_episode_return = None, mean_episode_step = 2009.1, total_loss = 360.76, pg_loss = 317.0, baseline_loss = 58.27, entropy_loss = -14.516, learner_queue_size = 64, _tick = 9610, _time = 1.6548e+09)
[2022-06-09 19:09:03,824][root][INFO] - Step 61977600 @ 3068.6 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 1.9707e+04, step = 61977600, mean_episode_return = 89.156, mean_episode_step = 1703.4, total_loss = 196.45, pg_loss = 167.64, baseline_loss = 43.271, entropy_loss = -14.46, learner_queue_size = 64, _tick = 9612, _time = 1.6548e+09)
[2022-06-09 19:09:08,826][root][INFO] - Step 61998080 @ 4094.0 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 1.9712e+04, step = 61998080, mean_episode_return = 23.981, mean_episode_step = 1873.7, total_loss = -12.908, pg_loss = -23.591, baseline_loss = 25.299, entropy_loss = -14.617, learner_queue_size = 64, _tick = 9616, _time = 1.6548e+09)
[2022-06-09 19:09:13,830][root][INFO] - Step 62013440 @ 3069.5 SPS. Inference batcher size: 68. Learner queue size: 64. Other stats: (train_seconds = 1.9717e+04, step = 62013440, mean_episode_return = 59.078, mean_episode_step = 2164.6, total_loss = 75.563, pg_loss = 55.049, baseline_loss = 35.22, entropy_loss = -14.706, learner_queue_size = 64, _tick = 9619, _time = 1.6548e+09)
[2022-06-09 19:09:18,834][root][INFO] - Step 62028800 @ 3069.6 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 1.9722e+04, step = 62028800, mean_episode_return = 9.8848, mean_episode_step = 1874.5, total_loss = -76.447, pg_loss = -84.854, baseline_loss = 22.995, entropy_loss = -14.587, learner_queue_size = 64, _tick = 9622, _time = 1.6548e+09)
[2022-06-09 19:09:23,838][root][INFO] - Step 62044160 @ 3069.5 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 1.9727e+04, step = 62044160, mean_episode_return = 38.877, mean_episode_step = 1769.4, total_loss = 72.423, pg_loss = 54.281, baseline_loss = 32.682, entropy_loss = -14.54, learner_queue_size = 64, _tick = 9624, _time = 1.6548e+09)
[2022-06-09 19:09:28,842][root][INFO] - Step 62059520 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.9732e+04, step = 62059520, mean_episode_return = None, mean_episode_step = 2103.1, total_loss = -9.6999, pg_loss = -20.155, baseline_loss = 24.776, entropy_loss = -14.321, learner_queue_size = 64, _tick = 9626, _time = 1.6548e+09)
[2022-06-09 19:09:33,846][root][INFO] - Step 62074880 @ 3069.6 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.9737e+04, step = 62074880, mean_episode_return = 59.446, mean_episode_step = 2176.3, total_loss = 216.44, pg_loss = 174.02, baseline_loss = 56.681, entropy_loss = -14.262, learner_queue_size = 64, _tick = 9629, _time = 1.6548e+09)
[2022-06-09 19:09:38,850][root][INFO] - Step 62090240 @ 3069.6 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 1.9742e+04, step = 62090240, mean_episode_return = 57.569, mean_episode_step = 1814.9, total_loss = 34.306, pg_loss = 14.514, baseline_loss = 34.069, entropy_loss = -14.277, learner_queue_size = 64, _tick = 9632, _time = 1.6548e+09)
[2022-06-09 19:09:43,854][root][INFO] - Step 62105600 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 1.9747e+04, step = 62105600, mean_episode_return = 18.3, mean_episode_step = 2156.5, total_loss = -199.52, pg_loss = -198.1, baseline_loss = 12.768, entropy_loss = -14.193, learner_queue_size = 64, _tick = 9635, _time = 1.6548e+09)
[2022-06-09 19:09:48,858][root][INFO] - Step 62120960 @ 3069.6 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.9752e+04, step = 62120960, mean_episode_return = 42.815, mean_episode_step = 2115.8, total_loss = -13.567, pg_loss = -25.245, baseline_loss = 25.75, entropy_loss = -14.072, learner_queue_size = 64, _tick = 9637, _time = 1.6548e+09)
[2022-06-09 19:09:53,862][root][INFO] - Step 62136320 @ 3069.6 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.9757e+04, step = 62136320, mean_episode_return = 81.626, mean_episode_step = 1870.7, total_loss = -32.952, pg_loss = -49.429, baseline_loss = 30.424, entropy_loss = -13.947, learner_queue_size = 64, _tick = 9640, _time = 1.6548e+09)
[2022-06-09 19:09:58,866][root][INFO] - Step 62156800 @ 4092.7 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 1.9762e+04, step = 62156800, mean_episode_return = -25.611, mean_episode_step = 2401.5, total_loss = 448.58, pg_loss = 393.3, baseline_loss = 69.145, entropy_loss = -13.866, learner_queue_size = 64, _tick = 9642, _time = 1.6548e+09)
[2022-06-09 19:10:03,870][root][INFO] - Step 62172160 @ 3069.5 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 1.9767e+04, step = 62172160, mean_episode_return = 29.24, mean_episode_step = 1853.6, total_loss = -78.258, pg_loss = -82.267, baseline_loss = 17.918, entropy_loss = -13.909, learner_queue_size = 64, _tick = 9645, _time = 1.6548e+09)
[2022-06-09 19:10:08,874][root][INFO] - Step 62187520 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.9772e+04, step = 62187520, mean_episode_return = None, mean_episode_step = 2071.1, total_loss = 128.35, pg_loss = 104.12, baseline_loss = 38.082, entropy_loss = -13.846, learner_queue_size = 64, _tick = 9647, _time = 1.6548e+09)
[2022-06-09 19:10:13,878][root][INFO] - Step 62202880 @ 3069.5 SPS. Inference batcher size: 68. Learner queue size: 64. Other stats: (train_seconds = 1.9777e+04, step = 62202880, mean_episode_return = 16.243, mean_episode_step = 1738.6, total_loss = -74.98, pg_loss = -95.383, baseline_loss = 34.077, entropy_loss = -13.675, learner_queue_size = 64, _tick = 9650, _time = 1.6548e+09)
[2022-06-09 19:10:18,882][root][INFO] - Step 62218240 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.9782e+04, step = 62218240, mean_episode_return = 53.62, mean_episode_step = 2023.6, total_loss = -54.768, pg_loss = -64.564, baseline_loss = 23.641, entropy_loss = -13.845, learner_queue_size = 64, _tick = 9653, _time = 1.6548e+09)
[2022-06-09 19:10:23,886][root][INFO] - Step 62233600 @ 3069.7 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.9787e+04, step = 62233600, mean_episode_return = 38.762, mean_episode_step = 2119.2, total_loss = 35.529, pg_loss = 22.814, baseline_loss = 26.671, entropy_loss = -13.956, learner_queue_size = 64, _tick = 9656, _time = 1.6548e+09)
[2022-06-09 19:10:28,904][root][INFO] - Step 62248960 @ 3060.7 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 1.9792e+04, step = 62248960, mean_episode_return = 70.669, mean_episode_step = 2117.8, total_loss = 140.01, pg_loss = 116.04, baseline_loss = 38.017, entropy_loss = -14.049, learner_queue_size = 64, _tick = 9658, _time = 1.6548e+09)
[2022-06-09 19:10:33,910][root][INFO] - Step 62264320 @ 3068.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.9797e+04, step = 62264320, mean_episode_return = 68.648, mean_episode_step = 2145.1, total_loss = -301.27, pg_loss = -303.91, baseline_loss = 16.518, entropy_loss = -13.883, learner_queue_size = 64, _tick = 9661, _time = 1.6548e+09)
[2022-06-09 19:10:38,914][root][INFO] - Step 62279680 @ 3069.5 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 1.9802e+04, step = 62279680, mean_episode_return = 50.34, mean_episode_step = 1597.4, total_loss = -59.413, pg_loss = -77.569, baseline_loss = 32.162, entropy_loss = -14.006, learner_queue_size = 64, _tick = 9664, _time = 1.6548e+09)
[2022-06-09 19:10:43,918][root][INFO] - Step 62295040 @ 3069.5 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 1.9807e+04, step = 62295040, mean_episode_return = None, mean_episode_step = 1935.7, total_loss = 26.905, pg_loss = 14.616, baseline_loss = 26.121, entropy_loss = -13.832, learner_queue_size = 64, _tick = 9665, _time = 1.6548e+09)
[2022-06-09 19:10:48,922][root][INFO] - Step 62310400 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 1.9812e+04, step = 62310400, mean_episode_return = -27.891, mean_episode_step = 1642.0, total_loss = 214.62, pg_loss = 189.65, baseline_loss = 38.934, entropy_loss = -13.962, learner_queue_size = 64, _tick = 9668, _time = 1.6548e+09)
[2022-06-09 19:10:53,926][root][INFO] - Step 62325760 @ 3069.6 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 1.9817e+04, step = 62325760, mean_episode_return = 35.422, mean_episode_step = 1795.1, total_loss = -6.7926, pg_loss = -9.1601, baseline_loss = 16.469, entropy_loss = -14.102, learner_queue_size = 64, _tick = 9670, _time = 1.6548e+09)
[2022-06-09 19:10:58,930][root][INFO] - Step 62346240 @ 4092.7 SPS. Inference batcher size: 76. Learner queue size: 64. Other stats: (train_seconds = 1.9822e+04, step = 62346240, mean_episode_return = 31.365, mean_episode_step = 1349.6, total_loss = -14.293, pg_loss = -23.869, baseline_loss = 23.546, entropy_loss = -13.969, learner_queue_size = 64, _tick = 9674, _time = 1.6548e+09)
[2022-06-09 19:11:03,934][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 19:11:04,230][root][INFO] - Step 62361600 @ 3069.3 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 1.9827e+04, step = 62361600, mean_episode_return = None, mean_episode_step = 1733.7, total_loss = 226.81, pg_loss = 202.76, baseline_loss = 38.045, entropy_loss = -13.988, learner_queue_size = 64, _tick = 9676, _time = 1.6548e+09)
[2022-06-09 19:11:09,234][root][INFO] - Step 62376960 @ 2898.3 SPS. Inference batcher size: 83. Learner queue size: 64. Other stats: (train_seconds = 1.9832e+04, step = 62376960, mean_episode_return = 39.431, mean_episode_step = 1783.8, total_loss = 255.42, pg_loss = 219.15, baseline_loss = 50.26, entropy_loss = -13.989, learner_queue_size = 64, _tick = 9679, _time = 1.6548e+09)
[2022-06-09 19:11:14,238][root][INFO] - Step 62392320 @ 3069.6 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 1.9837e+04, step = 62392320, mean_episode_return = -2.7204, mean_episode_step = 2026.0, total_loss = -61.976, pg_loss = -74.425, baseline_loss = 26.52, entropy_loss = -14.07, learner_queue_size = 64, _tick = 9682, _time = 1.6548e+09)
[2022-06-09 19:11:19,242][root][INFO] - Step 62407680 @ 3069.4 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 1.9842e+04, step = 62407680, mean_episode_return = 14.35, mean_episode_step = 2123.7, total_loss = 11.254, pg_loss = 5.1962, baseline_loss = 20.359, entropy_loss = -14.302, learner_queue_size = 64, _tick = 9684, _time = 1.6548e+09)
[2022-06-09 19:11:24,248][root][INFO] - Step 62423040 @ 3068.6 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 1.9847e+04, step = 62423040, mean_episode_return = -27.481, mean_episode_step = 2076.3, total_loss = 164.07, pg_loss = 139.4, baseline_loss = 39.293, entropy_loss = -14.623, learner_queue_size = 64, _tick = 9687, _time = 1.6548e+09)
[2022-06-09 19:11:29,250][root][INFO] - Step 62438400 @ 3070.6 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 1.9852e+04, step = 62438400, mean_episode_return = None, mean_episode_step = 2258.3, total_loss = 420.18, pg_loss = 374.99, baseline_loss = 59.849, entropy_loss = -14.656, learner_queue_size = 64, _tick = 9689, _time = 1.6548e+09)
[2022-06-09 19:11:34,254][root][INFO] - Step 62453760 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.9857e+04, step = 62453760, mean_episode_return = 37.882, mean_episode_step = 1700.4, total_loss = -181.02, pg_loss = -174.63, baseline_loss = 8.2999, entropy_loss = -14.69, learner_queue_size = 64, _tick = 9691, _time = 1.6548e+09)
[2022-06-09 19:11:39,258][root][INFO] - Step 62469120 @ 3069.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.9862e+04, step = 62469120, mean_episode_return = None, mean_episode_step = 1851.2, total_loss = -40.983, pg_loss = -43.701, baseline_loss = 17.486, entropy_loss = -14.768, learner_queue_size = 64, _tick = 9693, _time = 1.6548e+09)
[2022-06-09 19:11:44,262][root][INFO] - Step 62484480 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 1.9867e+04, step = 62484480, mean_episode_return = -1.33, mean_episode_step = 2178.2, total_loss = 25.775, pg_loss = 20.325, baseline_loss = 20.408, entropy_loss = -14.958, learner_queue_size = 64, _tick = 9696, _time = 1.6548e+09)
[2022-06-09 19:11:49,267][root][INFO] - Step 62504960 @ 4092.2 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 1.9872e+04, step = 62504960, mean_episode_return = 20.249, mean_episode_step = 1949.6, total_loss = 108.73, pg_loss = 86.509, baseline_loss = 37.155, entropy_loss = -14.934, learner_queue_size = 64, _tick = 9698, _time = 1.6548e+09)
[2022-06-09 19:11:54,270][root][INFO] - Step 62520320 @ 3070.0 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 1.9877e+04, step = 62520320, mean_episode_return = 31.299, mean_episode_step = 2282.6, total_loss = -100.89, pg_loss = -115.45, baseline_loss = 29.571, entropy_loss = -15.004, learner_queue_size = 64, _tick = 9701, _time = 1.6548e+09)
[2022-06-09 19:11:59,274][root][INFO] - Step 62535680 @ 3069.5 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 1.9882e+04, step = 62535680, mean_episode_return = 24.71, mean_episode_step = 2186.2, total_loss = -34.876, pg_loss = -46.384, baseline_loss = 26.568, entropy_loss = -15.059, learner_queue_size = 64, _tick = 9704, _time = 1.6548e+09)
[2022-06-09 19:12:04,278][root][INFO] - Step 62551040 @ 3069.6 SPS. Inference batcher size: 77. Learner queue size: 64. Other stats: (train_seconds = 1.9887e+04, step = 62551040, mean_episode_return = 36.006, mean_episode_step = 2100.1, total_loss = -203.73, pg_loss = -196.2, baseline_loss = 7.5714, entropy_loss = -15.095, learner_queue_size = 64, _tick = 9707, _time = 1.6548e+09)
[2022-06-09 19:12:09,284][root][INFO] - Step 62566400 @ 3068.1 SPS. Inference batcher size: 87. Learner queue size: 64. Other stats: (train_seconds = 1.9892e+04, step = 62566400, mean_episode_return = None, mean_episode_step = 2008.4, total_loss = -77.482, pg_loss = -75.039, baseline_loss = 12.629, entropy_loss = -15.073, learner_queue_size = 64, _tick = 9707, _time = 1.6548e+09)
[2022-06-09 19:12:14,290][root][INFO] - Step 62581760 @ 3068.4 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 1.9897e+04, step = 62581760, mean_episode_return = 47.706, mean_episode_step = 2130.9, total_loss = -189.59, pg_loss = -192.83, baseline_loss = 18.32, entropy_loss = -15.084, learner_queue_size = 64, _tick = 9708, _time = 1.6548e+09)
[2022-06-09 19:12:19,294][root][INFO] - Step 62597120 @ 3069.6 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 1.9902e+04, step = 62597120, mean_episode_return = 12.73, mean_episode_step = 2252.4, total_loss = 38.577, pg_loss = 23.563, baseline_loss = 30.144, entropy_loss = -15.13, learner_queue_size = 64, _tick = 9711, _time = 1.6548e+09)
[2022-06-09 19:12:24,298][root][INFO] - Step 62612480 @ 3069.5 SPS. Inference batcher size: 13. Learner queue size: 64. Other stats: (train_seconds = 1.9907e+04, step = 62612480, mean_episode_return = 19.86, mean_episode_step = 1940.7, total_loss = -52.641, pg_loss = -52.079, baseline_loss = 14.585, entropy_loss = -15.147, learner_queue_size = 64, _tick = 9714, _time = 1.6548e+09)
[2022-06-09 19:12:29,302][root][INFO] - Step 62627840 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 1.9912e+04, step = 62627840, mean_episode_return = None, mean_episode_step = 1899.5, total_loss = 18.092, pg_loss = 6.1567, baseline_loss = 27.1, entropy_loss = -15.165, learner_queue_size = 64, _tick = 9716, _time = 1.6548e+09)
[2022-06-09 19:12:34,306][root][INFO] - Step 62643200 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 1.9917e+04, step = 62643200, mean_episode_return = 39.366, mean_episode_step = 1893.4, total_loss = 146.58, pg_loss = 33.048, baseline_loss = 128.81, entropy_loss = -15.283, learner_queue_size = 64, _tick = 9718, _time = 1.6548e+09)
[2022-06-09 19:12:39,310][root][INFO] - Step 62658560 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 1.9922e+04, step = 62658560, mean_episode_return = None, mean_episode_step = 2310.5, total_loss = 214.64, pg_loss = 193.39, baseline_loss = 36.672, entropy_loss = -15.421, learner_queue_size = 64, _tick = 9720, _time = 1.6548e+09)
[2022-06-09 19:12:44,314][root][INFO] - Step 62679040 @ 4092.7 SPS. Inference batcher size: 75. Learner queue size: 64. Other stats: (train_seconds = 1.9927e+04, step = 62679040, mean_episode_return = -5.0354, mean_episode_step = 2316.0, total_loss = 136.52, pg_loss = 81.945, baseline_loss = 69.922, entropy_loss = -15.351, learner_queue_size = 64, _tick = 9724, _time = 1.6548e+09)
[2022-06-09 19:12:49,318][root][INFO] - Step 62694400 @ 3069.5 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 1.9932e+04, step = 62694400, mean_episode_return = 4.7297, mean_episode_step = 1892.0, total_loss = -62.336, pg_loss = -68.264, baseline_loss = 21.25, entropy_loss = -15.322, learner_queue_size = 64, _tick = 9727, _time = 1.6548e+09)
[2022-06-09 19:12:54,322][root][INFO] - Step 62709760 @ 3069.6 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 1.9937e+04, step = 62709760, mean_episode_return = 8.4797, mean_episode_step = 2283.1, total_loss = 66.863, pg_loss = 56.626, baseline_loss = 25.388, entropy_loss = -15.152, learner_queue_size = 64, _tick = 9730, _time = 1.6548e+09)
[2022-06-09 19:12:59,326][root][INFO] - Step 62725120 @ 3069.5 SPS. Inference batcher size: 74. Learner queue size: 64. Other stats: (train_seconds = 1.9942e+04, step = 62725120, mean_episode_return = 66.109, mean_episode_step = 2417.7, total_loss = -66.152, pg_loss = -73.993, baseline_loss = 22.833, entropy_loss = -14.991, learner_queue_size = 64, _tick = 9733, _time = 1.6548e+09)
[2022-06-09 19:13:04,330][root][INFO] - Step 62740480 @ 3069.6 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 1.9947e+04, step = 62740480, mean_episode_return = 29.16, mean_episode_step = 2079.2, total_loss = 348.51, pg_loss = 304.2, baseline_loss = 59.302, entropy_loss = -14.989, learner_queue_size = 64, _tick = 9736, _time = 1.6548e+09)
[2022-06-09 19:13:09,334][root][INFO] - Step 62755840 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 1.9952e+04, step = 62755840, mean_episode_return = 36.538, mean_episode_step = 2042.8, total_loss = -87.09, pg_loss = -89.199, baseline_loss = 17.1, entropy_loss = -14.991, learner_queue_size = 64, _tick = 9739, _time = 1.6548e+09)
[2022-06-09 19:13:14,338][root][INFO] - Step 62771200 @ 3069.6 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 1.9957e+04, step = 62771200, mean_episode_return = 77.229, mean_episode_step = 1852.9, total_loss = 139.2, pg_loss = 118.07, baseline_loss = 36.121, entropy_loss = -14.991, learner_queue_size = 64, _tick = 9741, _time = 1.6548e+09)
[2022-06-09 19:13:19,342][root][INFO] - Step 62786560 @ 3069.5 SPS. Inference batcher size: 7. Learner queue size: 64. Other stats: (train_seconds = 1.9962e+04, step = 62786560, mean_episode_return = 25.945, mean_episode_step = 1765.0, total_loss = -43.294, pg_loss = -46.647, baseline_loss = 18.214, entropy_loss = -14.862, learner_queue_size = 64, _tick = 9744, _time = 1.6548e+09)
[2022-06-09 19:13:24,346][root][INFO] - Step 62801920 @ 3069.6 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 1.9967e+04, step = 62801920, mean_episode_return = 43.242, mean_episode_step = 1889.7, total_loss = 185.98, pg_loss = 163.93, baseline_loss = 36.902, entropy_loss = -14.852, learner_queue_size = 64, _tick = 9747, _time = 1.6548e+09)
[2022-06-09 19:13:29,350][root][INFO] - Step 62817280 @ 3069.4 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.9972e+04, step = 62817280, mean_episode_return = 103.29, mean_episode_step = 2141.3, total_loss = -214.81, pg_loss = -211.33, baseline_loss = 11.269, entropy_loss = -14.753, learner_queue_size = 64, _tick = 9750, _time = 1.6548e+09)
[2022-06-09 19:13:34,354][root][INFO] - Step 62832640 @ 3069.6 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 1.9977e+04, step = 62832640, mean_episode_return = 1.4996, mean_episode_step = 1857.6, total_loss = 92.748, pg_loss = 77.004, baseline_loss = 30.52, entropy_loss = -14.776, learner_queue_size = 64, _tick = 9752, _time = 1.6548e+09)
[2022-06-09 19:13:39,358][root][INFO] - Step 62848000 @ 3069.4 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 1.9982e+04, step = 62848000, mean_episode_return = 76.425, mean_episode_step = 2539.8, total_loss = -179.73, pg_loss = -181.03, baseline_loss = 16.057, entropy_loss = -14.759, learner_queue_size = 64, _tick = 9754, _time = 1.6548e+09)
[2022-06-09 19:13:44,362][root][INFO] - Step 62863360 @ 3069.6 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 1.9987e+04, step = 62863360, mean_episode_return = 96.086, mean_episode_step = 2257.3, total_loss = 143.3, pg_loss = 93.969, baseline_loss = 64.074, entropy_loss = -14.745, learner_queue_size = 64, _tick = 9757, _time = 1.6548e+09)
[2022-06-09 19:13:49,366][root][INFO] - Step 62883840 @ 4092.8 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 1.9992e+04, step = 62883840, mean_episode_return = 62.62, mean_episode_step = 2359.4, total_loss = -65.588, pg_loss = -68.612, baseline_loss = 17.836, entropy_loss = -14.811, learner_queue_size = 64, _tick = 9760, _time = 1.6548e+09)
[2022-06-09 19:13:54,370][root][INFO] - Step 62899200 @ 3069.5 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 1.9997e+04, step = 62899200, mean_episode_return = 89.083, mean_episode_step = 2226.2, total_loss = 202.23, pg_loss = 173.16, baseline_loss = 43.658, entropy_loss = -14.59, learner_queue_size = 64, _tick = 9763, _time = 1.6548e+09)
[2022-06-09 19:13:59,374][root][INFO] - Step 62914560 @ 3069.5 SPS. Inference batcher size: 68. Learner queue size: 64. Other stats: (train_seconds = 2.0002e+04, step = 62914560, mean_episode_return = 49.085, mean_episode_step = 1878.3, total_loss = -140.64, pg_loss = -137.73, baseline_loss = 11.658, entropy_loss = -14.565, learner_queue_size = 64, _tick = 9766, _time = 1.6548e+09)
[2022-06-09 19:14:04,379][root][INFO] - Step 62929920 @ 3069.1 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 2.0007e+04, step = 62929920, mean_episode_return = 44.509, mean_episode_step = 1929.2, total_loss = -49.229, pg_loss = -71.397, baseline_loss = 36.688, entropy_loss = -14.52, learner_queue_size = 64, _tick = 9769, _time = 1.6548e+09)
[2022-06-09 19:14:09,382][root][INFO] - Step 62945280 @ 3070.0 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 2.0012e+04, step = 62945280, mean_episode_return = None, mean_episode_step = 2132.3, total_loss = 18.853, pg_loss = 6.6032, baseline_loss = 26.522, entropy_loss = -14.272, learner_queue_size = 64, _tick = 9770, _time = 1.6548e+09)
[2022-06-09 19:14:14,386][root][INFO] - Step 62960640 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 2.0017e+04, step = 62960640, mean_episode_return = 17.96, mean_episode_step = 2140.3, total_loss = -164.98, pg_loss = -162.35, baseline_loss = 11.565, entropy_loss = -14.195, learner_queue_size = 64, _tick = 9773, _time = 1.6548e+09)
[2022-06-09 19:14:19,390][root][INFO] - Step 62976000 @ 3069.6 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 2.0022e+04, step = 62976000, mean_episode_return = None, mean_episode_step = 2142.2, total_loss = 104.03, pg_loss = 87.417, baseline_loss = 30.891, entropy_loss = -14.277, learner_queue_size = 64, _tick = 9774, _time = 1.6548e+09)
[2022-06-09 19:14:24,394][root][INFO] - Step 62991360 @ 3069.5 SPS. Inference batcher size: 7. Learner queue size: 64. Other stats: (train_seconds = 2.0027e+04, step = 62991360, mean_episode_return = -10.64, mean_episode_step = 2082.7, total_loss = 338.98, pg_loss = 168.18, baseline_loss = 185.04, entropy_loss = -14.24, learner_queue_size = 64, _tick = 9776, _time = 1.6548e+09)
[2022-06-09 19:14:29,398][root][INFO] - Step 63006720 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 2.0032e+04, step = 63006720, mean_episode_return = None, mean_episode_step = 2130.3, total_loss = 145.15, pg_loss = 126.58, baseline_loss = 32.666, entropy_loss = -14.092, learner_queue_size = 64, _tick = 9778, _time = 1.6548e+09)
[2022-06-09 19:14:34,402][root][INFO] - Step 63022080 @ 3069.6 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 2.0037e+04, step = 63022080, mean_episode_return = -0.27, mean_episode_step = 2358.8, total_loss = -42.749, pg_loss = -50.057, baseline_loss = 21.568, entropy_loss = -14.26, learner_queue_size = 64, _tick = 9780, _time = 1.6548e+09)
[2022-06-09 19:14:39,406][root][INFO] - Step 63042560 @ 4092.7 SPS. Inference batcher size: 71. Learner queue size: 64. Other stats: (train_seconds = 2.0042e+04, step = 63042560, mean_episode_return = 63.568, mean_episode_step = 2154.7, total_loss = -117.9, pg_loss = -126.63, baseline_loss = 23.185, entropy_loss = -14.461, learner_queue_size = 64, _tick = 9784, _time = 1.6548e+09)
[2022-06-09 19:14:44,410][root][INFO] - Step 63057920 @ 3069.6 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 2.0047e+04, step = 63057920, mean_episode_return = 53.921, mean_episode_step = 2027.0, total_loss = -82.184, pg_loss = -98.063, baseline_loss = 30.346, entropy_loss = -14.467, learner_queue_size = 64, _tick = 9787, _time = 1.6548e+09)
[2022-06-09 19:14:49,414][root][INFO] - Step 63073280 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 2.0052e+04, step = 63073280, mean_episode_return = 30.361, mean_episode_step = 1984.2, total_loss = -152.08, pg_loss = -161.81, baseline_loss = 24.293, entropy_loss = -14.564, learner_queue_size = 64, _tick = 9790, _time = 1.6548e+09)
[2022-06-09 19:14:54,418][root][INFO] - Step 63088640 @ 3069.6 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 2.0057e+04, step = 63088640, mean_episode_return = 5.3994, mean_episode_step = 1877.7, total_loss = -90.611, pg_loss = -92.116, baseline_loss = 16.042, entropy_loss = -14.537, learner_queue_size = 64, _tick = 9793, _time = 1.6548e+09)
[2022-06-09 19:14:59,422][root][INFO] - Step 63104000 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 2.0062e+04, step = 63104000, mean_episode_return = -7.8421, mean_episode_step = 1746.1, total_loss = -170.78, pg_loss = -172.58, baseline_loss = 16.553, entropy_loss = -14.751, learner_queue_size = 64, _tick = 9796, _time = 1.6548e+09)
[2022-06-09 19:15:04,426][root][INFO] - Step 63119360 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 2.0067e+04, step = 63119360, mean_episode_return = 62.428, mean_episode_step = 1992.8, total_loss = 36.769, pg_loss = 25.662, baseline_loss = 26.116, entropy_loss = -15.008, learner_queue_size = 64, _tick = 9799, _time = 1.6548e+09)
[2022-06-09 19:15:09,430][root][INFO] - Step 63134720 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 2.0072e+04, step = 63134720, mean_episode_return = None, mean_episode_step = 2088.0, total_loss = -83.994, pg_loss = -82.69, baseline_loss = 13.553, entropy_loss = -14.858, learner_queue_size = 64, _tick = 9801, _time = 1.6548e+09)
[2022-06-09 19:15:14,434][root][INFO] - Step 63155200 @ 4092.7 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 2.0077e+04, step = 63155200, mean_episode_return = 77.126, mean_episode_step = 1953.8, total_loss = 170.58, pg_loss = 145.1, baseline_loss = 40.328, entropy_loss = -14.848, learner_queue_size = 64, _tick = 9805, _time = 1.6548e+09)
[2022-06-09 19:15:19,438][root][INFO] - Step 63170560 @ 3069.5 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 2.0082e+04, step = 63170560, mean_episode_return = None, mean_episode_step = 1656.6, total_loss = 356.21, pg_loss = 292.41, baseline_loss = 78.902, entropy_loss = -15.101, learner_queue_size = 64, _tick = 9806, _time = 1.6548e+09)
[2022-06-09 19:15:24,442][root][INFO] - Step 63185920 @ 3069.5 SPS. Inference batcher size: 71. Learner queue size: 64. Other stats: (train_seconds = 2.0087e+04, step = 63185920, mean_episode_return = None, mean_episode_step = 1961.1, total_loss = -201.79, pg_loss = -193.1, baseline_loss = 6.4239, entropy_loss = -15.118, learner_queue_size = 64, _tick = 9808, _time = 1.6548e+09)
[2022-06-09 19:15:29,446][root][INFO] - Step 63201280 @ 3069.5 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 2.0092e+04, step = 63201280, mean_episode_return = None, mean_episode_step = 1934.5, total_loss = -147.38, pg_loss = -140.86, baseline_loss = 8.5784, entropy_loss = -15.101, learner_queue_size = 64, _tick = 9810, _time = 1.6548e+09)
[2022-06-09 19:15:34,450][root][INFO] - Step 63216640 @ 3069.5 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 2.0097e+04, step = 63216640, mean_episode_return = 26.72, mean_episode_step = 1974.2, total_loss = 111.9, pg_loss = 102.03, baseline_loss = 24.998, entropy_loss = -15.133, learner_queue_size = 64, _tick = 9813, _time = 1.6548e+09)
[2022-06-09 19:15:39,454][root][INFO] - Step 63232000 @ 3069.6 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 2.0102e+04, step = 63232000, mean_episode_return = 6.9698, mean_episode_step = 2043.2, total_loss = 113.03, pg_loss = 99.233, baseline_loss = 28.981, entropy_loss = -15.188, learner_queue_size = 64, _tick = 9815, _time = 1.6548e+09)
[2022-06-09 19:15:44,458][root][INFO] - Step 63247360 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 2.0107e+04, step = 63247360, mean_episode_return = 54.975, mean_episode_step = 1775.1, total_loss = 152.11, pg_loss = 132.52, baseline_loss = 34.795, entropy_loss = -15.199, learner_queue_size = 64, _tick = 9818, _time = 1.6548e+09)
[2022-06-09 19:15:49,462][root][INFO] - Step 63262720 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 2.0112e+04, step = 63262720, mean_episode_return = 39.712, mean_episode_step = 1707.9, total_loss = 316.07, pg_loss = 279.83, baseline_loss = 51.434, entropy_loss = -15.199, learner_queue_size = 64, _tick = 9821, _time = 1.6548e+09)
[2022-06-09 19:15:54,466][root][INFO] - Step 63278080 @ 3069.4 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 2.0117e+04, step = 63278080, mean_episode_return = 35.228, mean_episode_step = 1753.1, total_loss = 236.32, pg_loss = 201.39, baseline_loss = 50.117, entropy_loss = -15.191, learner_queue_size = 64, _tick = 9824, _time = 1.6548e+09)
[2022-06-09 19:15:59,470][root][INFO] - Step 63293440 @ 3069.6 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 2.0122e+04, step = 63293440, mean_episode_return = 49.771, mean_episode_step = 1870.7, total_loss = -126.36, pg_loss = -130.13, baseline_loss = 18.681, entropy_loss = -14.91, learner_queue_size = 64, _tick = 9827, _time = 1.6548e+09)
[2022-06-09 19:16:04,474][root][INFO] - Step 63313920 @ 4092.7 SPS. Inference batcher size: 99. Learner queue size: 64. Other stats: (train_seconds = 2.0127e+04, step = 63313920, mean_episode_return = 21.455, mean_episode_step = 1632.8, total_loss = 220.17, pg_loss = 192.69, baseline_loss = 42.422, entropy_loss = -14.938, learner_queue_size = 64, _tick = 9831, _time = 1.6548e+09)
[2022-06-09 19:16:09,478][root][INFO] - Step 63329280 @ 3069.5 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 2.0132e+04, step = 63329280, mean_episode_return = None, mean_episode_step = 2041.7, total_loss = 208.69, pg_loss = 184.61, baseline_loss = 39.02, entropy_loss = -14.942, learner_queue_size = 64, _tick = 9832, _time = 1.6548e+09)
[2022-06-09 19:16:14,482][root][INFO] - Step 63344640 @ 3069.6 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 2.0137e+04, step = 63344640, mean_episode_return = None, mean_episode_step = 1702.1, total_loss = 290.43, pg_loss = 256.85, baseline_loss = 48.705, entropy_loss = -15.119, learner_queue_size = 64, _tick = 9834, _time = 1.6548e+09)
[2022-06-09 19:16:19,486][root][INFO] - Step 63360000 @ 3069.6 SPS. Inference batcher size: 83. Learner queue size: 64. Other stats: (train_seconds = 2.0142e+04, step = 63360000, mean_episode_return = 51.731, mean_episode_step = 1816.6, total_loss = 131.42, pg_loss = 99.105, baseline_loss = 47.417, entropy_loss = -15.103, learner_queue_size = 64, _tick = 9837, _time = 1.6548e+09)
[2022-06-09 19:16:24,491][root][INFO] - Step 63375360 @ 3069.2 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 2.0147e+04, step = 63375360, mean_episode_return = None, mean_episode_step = 1955.9, total_loss = -121.31, pg_loss = -115.28, baseline_loss = 9.1129, entropy_loss = -15.141, learner_queue_size = 64, _tick = 9838, _time = 1.6548e+09)
[2022-06-09 19:16:29,494][root][INFO] - Step 63390720 @ 3069.9 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 2.0152e+04, step = 63390720, mean_episode_return = -16.321, mean_episode_step = 2105.1, total_loss = -40.324, pg_loss = -54.93, baseline_loss = 29.782, entropy_loss = -15.177, learner_queue_size = 64, _tick = 9841, _time = 1.6548e+09)
[2022-06-09 19:16:34,498][root][INFO] - Step 63406080 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 2.0157e+04, step = 63406080, mean_episode_return = None, mean_episode_step = 2103.5, total_loss = -77.201, pg_loss = -77.537, baseline_loss = 15.506, entropy_loss = -15.17, learner_queue_size = 64, _tick = 9843, _time = 1.6548e+09)
[2022-06-09 19:16:39,502][root][INFO] - Step 63421440 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 2.0162e+04, step = 63421440, mean_episode_return = 6.3852, mean_episode_step = 2094.3, total_loss = 296.58, pg_loss = 233.39, baseline_loss = 78.299, entropy_loss = -15.11, learner_queue_size = 64, _tick = 9846, _time = 1.6548e+09)
[2022-06-09 19:16:44,508][root][INFO] - Step 63436800 @ 3068.3 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 2.0167e+04, step = 63436800, mean_episode_return = None, mean_episode_step = 2005.5, total_loss = 93.559, pg_loss = 74.596, baseline_loss = 34.052, entropy_loss = -15.089, learner_queue_size = 64, _tick = 9848, _time = 1.6548e+09)
[2022-06-09 19:16:49,514][root][INFO] - Step 63452160 @ 3068.3 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 2.0172e+04, step = 63452160, mean_episode_return = None, mean_episode_step = 2036.7, total_loss = -5.9251, pg_loss = -10.231, baseline_loss = 19.232, entropy_loss = -14.927, learner_queue_size = 64, _tick = 9850, _time = 1.6548e+09)
[2022-06-09 19:16:54,518][root][INFO] - Step 63467520 @ 3069.5 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 2.0178e+04, step = 63467520, mean_episode_return = 49.561, mean_episode_step = 1920.9, total_loss = -109.29, pg_loss = -115.29, baseline_loss = 20.891, entropy_loss = -14.892, learner_queue_size = 64, _tick = 9853, _time = 1.6548e+09)
[2022-06-09 19:16:59,522][root][INFO] - Step 63488000 @ 4092.7 SPS. Inference batcher size: 85. Learner queue size: 64. Other stats: (train_seconds = 2.0182e+04, step = 63488000, mean_episode_return = 17.33, mean_episode_step = 1786.1, total_loss = 236.69, pg_loss = 217.05, baseline_loss = 34.586, entropy_loss = -14.939, learner_queue_size = 64, _tick = 9857, _time = 1.6548e+09)
[2022-06-09 19:17:04,526][root][INFO] - Step 63503360 @ 3069.6 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 2.0188e+04, step = 63503360, mean_episode_return = 31.18, mean_episode_step = 2125.4, total_loss = -93.571, pg_loss = -95.028, baseline_loss = 16.538, entropy_loss = -15.082, learner_queue_size = 64, _tick = 9860, _time = 1.6548e+09)
[2022-06-09 19:17:09,530][root][INFO] - Step 63518720 @ 3069.5 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 2.0192e+04, step = 63518720, mean_episode_return = 41.57, mean_episode_step = 1870.0, total_loss = 466.79, pg_loss = 406.19, baseline_loss = 75.869, entropy_loss = -15.274, learner_queue_size = 64, _tick = 9863, _time = 1.6548e+09)
[2022-06-09 19:17:14,534][root][INFO] - Step 63534080 @ 3069.6 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 2.0198e+04, step = 63534080, mean_episode_return = 69.726, mean_episode_step = 2095.6, total_loss = 42.202, pg_loss = 21.113, baseline_loss = 36.361, entropy_loss = -15.272, learner_queue_size = 64, _tick = 9866, _time = 1.6548e+09)
[2022-06-09 19:17:19,538][root][INFO] - Step 63549440 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 2.0202e+04, step = 63549440, mean_episode_return = 48.809, mean_episode_step = 1925.0, total_loss = -112.46, pg_loss = -125.47, baseline_loss = 28.185, entropy_loss = -15.173, learner_queue_size = 64, _tick = 9869, _time = 1.6548e+09)
[2022-06-09 19:17:24,542][root][INFO] - Step 63564800 @ 3069.6 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 2.0208e+04, step = 63564800, mean_episode_return = 37.035, mean_episode_step = 1724.3, total_loss = -183.93, pg_loss = -181.3, baseline_loss = 12.49, entropy_loss = -15.12, learner_queue_size = 64, _tick = 9872, _time = 1.6548e+09)
[2022-06-09 19:17:29,546][root][INFO] - Step 63580160 @ 3069.5 SPS. Inference batcher size: 13. Learner queue size: 64. Other stats: (train_seconds = 2.0212e+04, step = 63580160, mean_episode_return = 26.73, mean_episode_step = 1688.6, total_loss = 556.27, pg_loss = 503.25, baseline_loss = 68.127, entropy_loss = -15.107, learner_queue_size = 64, _tick = 9875, _time = 1.6548e+09)
[2022-06-09 19:17:34,550][root][INFO] - Step 63600640 @ 4092.8 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 2.0218e+04, step = 63600640, mean_episode_return = 45.911, mean_episode_step = 1827.9, total_loss = 405.7, pg_loss = 341.27, baseline_loss = 79.414, entropy_loss = -14.988, learner_queue_size = 64, _tick = 9879, _time = 1.6548e+09)
[2022-06-09 19:17:39,554][root][INFO] - Step 63616000 @ 3069.5 SPS. Inference batcher size: 75. Learner queue size: 64. Other stats: (train_seconds = 2.0222e+04, step = 63616000, mean_episode_return = 33.066, mean_episode_step = 1929.2, total_loss = -81.638, pg_loss = -86.778, baseline_loss = 20.165, entropy_loss = -15.026, learner_queue_size = 64, _tick = 9881, _time = 1.6548e+09)
[2022-06-09 19:17:44,558][root][INFO] - Step 63631360 @ 3069.5 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 2.0228e+04, step = 63631360, mean_episode_return = 88.078, mean_episode_step = 1629.7, total_loss = -19.799, pg_loss = -27.801, baseline_loss = 23.053, entropy_loss = -15.051, learner_queue_size = 64, _tick = 9884, _time = 1.6548e+09)
[2022-06-09 19:17:49,562][root][INFO] - Step 63646720 @ 3069.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 2.0232e+04, step = 63646720, mean_episode_return = 84.957, mean_episode_step = 1645.8, total_loss = 26.785, pg_loss = -0.69653, baseline_loss = 42.52, entropy_loss = -15.038, learner_queue_size = 64, _tick = 9887, _time = 1.6548e+09)
[2022-06-09 19:17:54,566][root][INFO] - Step 63662080 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 2.0238e+04, step = 63662080, mean_episode_return = 65.48, mean_episode_step = 1709.9, total_loss = 455.54, pg_loss = 396.92, baseline_loss = 73.648, entropy_loss = -15.033, learner_queue_size = 64, _tick = 9890, _time = 1.6548e+09)
[2022-06-09 19:17:59,570][root][INFO] - Step 63677440 @ 3069.5 SPS. Inference batcher size: 7. Learner queue size: 64. Other stats: (train_seconds = 2.0242e+04, step = 63677440, mean_episode_return = 42.695, mean_episode_step = 2048.4, total_loss = 27.832, pg_loss = 21.931, baseline_loss = 21.014, entropy_loss = -15.113, learner_queue_size = 64, _tick = 9893, _time = 1.6548e+09)
[2022-06-09 19:18:04,574][root][INFO] - Step 63692800 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 2.0248e+04, step = 63692800, mean_episode_return = 74.325, mean_episode_step = 1877.6, total_loss = -140.12, pg_loss = -137.44, baseline_loss = 12.309, entropy_loss = -14.993, learner_queue_size = 64, _tick = 9896, _time = 1.6548e+09)
[2022-06-09 19:18:09,578][root][INFO] - Step 63713280 @ 4092.7 SPS. Inference batcher size: 91. Learner queue size: 64. Other stats: (train_seconds = 2.0252e+04, step = 63713280, mean_episode_return = 40.43, mean_episode_step = 1535.5, total_loss = 80.421, pg_loss = 58.828, baseline_loss = 36.662, entropy_loss = -15.069, learner_queue_size = 64, _tick = 9900, _time = 1.6548e+09)
[2022-06-09 19:18:14,584][root][INFO] - Step 63728640 @ 3068.3 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 2.0258e+04, step = 63728640, mean_episode_return = 33.9, mean_episode_step = 1855.8, total_loss = 89.884, pg_loss = 71.379, baseline_loss = 33.548, entropy_loss = -15.042, learner_queue_size = 64, _tick = 9902, _time = 1.6548e+09)
[2022-06-09 19:18:19,590][root][INFO] - Step 63744000 @ 3068.4 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 2.0262e+04, step = 63744000, mean_episode_return = 63.314, mean_episode_step = 1697.4, total_loss = 147.51, pg_loss = 117.47, baseline_loss = 45.272, entropy_loss = -15.235, learner_queue_size = 64, _tick = 9905, _time = 1.6548e+09)
[2022-06-09 19:18:24,594][root][INFO] - Step 63759360 @ 3069.6 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 2.0268e+04, step = 63759360, mean_episode_return = 119.65, mean_episode_step = 1757.0, total_loss = 302.0, pg_loss = 249.46, baseline_loss = 67.752, entropy_loss = -15.218, learner_queue_size = 64, _tick = 9908, _time = 1.6548e+09)
[2022-06-09 19:18:29,598][root][INFO] - Step 63774720 @ 3069.6 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 2.0272e+04, step = 63774720, mean_episode_return = 74.29, mean_episode_step = 1598.7, total_loss = 128.07, pg_loss = 93.31, baseline_loss = 49.979, entropy_loss = -15.218, learner_queue_size = 64, _tick = 9911, _time = 1.6548e+09)
[2022-06-09 19:18:34,602][root][INFO] - Step 63790080 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 2.0278e+04, step = 63790080, mean_episode_return = 45.367, mean_episode_step = 1891.0, total_loss = 150.43, pg_loss = 103.09, baseline_loss = 62.501, entropy_loss = -15.154, learner_queue_size = 64, _tick = 9913, _time = 1.6548e+09)
[2022-06-09 19:18:39,606][root][INFO] - Step 63805440 @ 3069.6 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 2.0282e+04, step = 63805440, mean_episode_return = None, mean_episode_step = 1661.9, total_loss = 321.46, pg_loss = 287.43, baseline_loss = 49.188, entropy_loss = -15.156, learner_queue_size = 64, _tick = 9915, _time = 1.6548e+09)
[2022-06-09 19:18:44,610][root][INFO] - Step 63820800 @ 3069.6 SPS. Inference batcher size: 15. Learner queue size: 64. Other stats: (train_seconds = 2.0288e+04, step = 63820800, mean_episode_return = None, mean_episode_step = 1671.2, total_loss = 316.49, pg_loss = 282.36, baseline_loss = 49.351, entropy_loss = -15.223, learner_queue_size = 64, _tick = 9916, _time = 1.6548e+09)
[2022-06-09 19:18:49,615][root][INFO] - Step 63836160 @ 3069.2 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 2.0293e+04, step = 63836160, mean_episode_return = 30.672, mean_episode_step = 1888.6, total_loss = 67.512, pg_loss = 35.542, baseline_loss = 47.313, entropy_loss = -15.344, learner_queue_size = 64, _tick = 9918, _time = 1.6548e+09)
[2022-06-09 19:18:54,618][root][INFO] - Step 63851520 @ 3069.9 SPS. Inference batcher size: 4. Learner queue size: 64. Other stats: (train_seconds = 2.0298e+04, step = 63851520, mean_episode_return = 38.982, mean_episode_step = 1966.0, total_loss = 27.041, pg_loss = 13.114, baseline_loss = 29.185, entropy_loss = -15.258, learner_queue_size = 64, _tick = 9921, _time = 1.6548e+09)
[2022-06-09 19:18:59,622][root][INFO] - Step 63866880 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 2.0303e+04, step = 63866880, mean_episode_return = 82.521, mean_episode_step = 1924.4, total_loss = 191.75, pg_loss = 142.78, baseline_loss = 64.042, entropy_loss = -15.072, learner_queue_size = 64, _tick = 9923, _time = 1.6548e+09)
[2022-06-09 19:19:04,626][root][INFO] - Step 63887360 @ 4092.8 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 2.0308e+04, step = 63887360, mean_episode_return = 93.174, mean_episode_step = 2057.7, total_loss = -211.45, pg_loss = -210.03, baseline_loss = 13.584, entropy_loss = -15.001, learner_queue_size = 64, _tick = 9927, _time = 1.6548e+09)
[2022-06-09 19:19:09,632][root][INFO] - Step 63902720 @ 3068.3 SPS. Inference batcher size: 96. Learner queue size: 64. Other stats: (train_seconds = 2.0313e+04, step = 63902720, mean_episode_return = 65.638, mean_episode_step = 2395.4, total_loss = 36.611, pg_loss = 21.833, baseline_loss = 29.875, entropy_loss = -15.097, learner_queue_size = 64, _tick = 9930, _time = 1.6548e+09)
[2022-06-09 19:19:14,634][root][INFO] - Step 63918080 @ 3070.7 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 2.0318e+04, step = 63918080, mean_episode_return = None, mean_episode_step = 1622.0, total_loss = 56.999, pg_loss = 44.639, baseline_loss = 27.604, entropy_loss = -15.244, learner_queue_size = 64, _tick = 9932, _time = 1.6548e+09)
[2022-06-09 19:19:19,638][root][INFO] - Step 63933440 @ 3069.6 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 2.0323e+04, step = 63933440, mean_episode_return = 39.711, mean_episode_step = 1802.8, total_loss = 92.963, pg_loss = 71.054, baseline_loss = 37.24, entropy_loss = -15.331, learner_queue_size = 64, _tick = 9935, _time = 1.6548e+09)
[2022-06-09 19:19:24,642][root][INFO] - Step 63948800 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 2.0328e+04, step = 63948800, mean_episode_return = 41.31, mean_episode_step = 1817.7, total_loss = -165.75, pg_loss = -174.71, baseline_loss = 24.235, entropy_loss = -15.281, learner_queue_size = 64, _tick = 9938, _time = 1.6548e+09)
[2022-06-09 19:19:29,647][root][INFO] - Step 63964160 @ 3069.1 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 2.0333e+04, step = 63964160, mean_episode_return = 75.718, mean_episode_step = 1676.8, total_loss = 26.112, pg_loss = 5.1961, baseline_loss = 36.103, entropy_loss = -15.187, learner_queue_size = 64, _tick = 9941, _time = 1.6548e+09)
[2022-06-09 19:19:34,650][root][INFO] - Step 63979520 @ 3069.9 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 2.0338e+04, step = 63979520, mean_episode_return = 89.951, mean_episode_step = 1832.9, total_loss = -174.69, pg_loss = -184.86, baseline_loss = 25.428, entropy_loss = -15.253, learner_queue_size = 64, _tick = 9944, _time = 1.6548e+09)
[2022-06-09 19:19:39,654][root][INFO] - Step 63994880 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 2.0343e+04, step = 63994880, mean_episode_return = 32.672, mean_episode_step = 1829.5, total_loss = -255.82, pg_loss = -244.41, baseline_loss = 3.9055, entropy_loss = -15.321, learner_queue_size = 64, _tick = 9946, _time = 1.6548e+09)
[2022-06-09 19:19:44,658][root][INFO] - Step 64010240 @ 3069.6 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 2.0348e+04, step = 64010240, mean_episode_return = None, mean_episode_step = 1813.0, total_loss = -169.03, pg_loss = -161.47, baseline_loss = 7.9032, entropy_loss = -15.456, learner_queue_size = 64, _tick = 9948, _time = 1.6548e+09)
[2022-06-09 19:19:49,662][root][INFO] - Step 64025600 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 2.0353e+04, step = 64025600, mean_episode_return = 15.33, mean_episode_step = 1745.1, total_loss = -76.189, pg_loss = -76.95, baseline_loss = 16.307, entropy_loss = -15.546, learner_queue_size = 64, _tick = 9951, _time = 1.6548e+09)
[2022-06-09 19:19:54,666][root][INFO] - Step 64040960 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 2.0358e+04, step = 64040960, mean_episode_return = 49.145, mean_episode_step = 1936.7, total_loss = 138.56, pg_loss = 113.97, baseline_loss = 40.213, entropy_loss = -15.625, learner_queue_size = 64, _tick = 9954, _time = 1.6548e+09)
[2022-06-09 19:19:59,670][root][INFO] - Step 64056320 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 2.0363e+04, step = 64056320, mean_episode_return = None, mean_episode_step = 1914.8, total_loss = 153.71, pg_loss = 136.22, baseline_loss = 32.988, entropy_loss = -15.496, learner_queue_size = 64, _tick = 9955, _time = 1.6548e+09)
[2022-06-09 19:20:04,674][root][INFO] - Step 64076800 @ 4092.7 SPS. Inference batcher size: 89. Learner queue size: 64. Other stats: (train_seconds = 2.0368e+04, step = 64076800, mean_episode_return = None, mean_episode_step = 2139.2, total_loss = -56.801, pg_loss = -64.588, baseline_loss = 23.233, entropy_loss = -15.447, learner_queue_size = 64, _tick = 9958, _time = 1.6548e+09)
[2022-06-09 19:20:09,678][root][INFO] - Step 64092160 @ 3069.6 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 2.0373e+04, step = 64092160, mean_episode_return = 69.07, mean_episode_step = 1749.9, total_loss = -76.286, pg_loss = -101.52, baseline_loss = 40.439, entropy_loss = -15.205, learner_queue_size = 64, _tick = 9961, _time = 1.6548e+09)
[2022-06-09 19:20:14,682][root][INFO] - Step 64107520 @ 3069.5 SPS. Inference batcher size: 15. Learner queue size: 64. Other stats: (train_seconds = 2.0378e+04, step = 64107520, mean_episode_return = 16.56, mean_episode_step = 1939.7, total_loss = 119.52, pg_loss = 94.995, baseline_loss = 39.617, entropy_loss = -15.09, learner_queue_size = 64, _tick = 9964, _time = 1.6548e+09)
[2022-06-09 19:20:19,686][root][INFO] - Step 64122880 @ 3069.5 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 2.0383e+04, step = 64122880, mean_episode_return = 12.968, mean_episode_step = 1700.0, total_loss = -122.08, pg_loss = -128.75, baseline_loss = 21.7, entropy_loss = -15.034, learner_queue_size = 64, _tick = 9966, _time = 1.6548e+09)
[2022-06-09 19:20:24,690][root][INFO] - Step 64138240 @ 3069.5 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 2.0388e+04, step = 64138240, mean_episode_return = 84.978, mean_episode_step = 1633.0, total_loss = -52.333, pg_loss = -72.211, baseline_loss = 34.928, entropy_loss = -15.05, learner_queue_size = 64, _tick = 9969, _time = 1.6548e+09)
[2022-06-09 19:20:29,694][root][INFO] - Step 64153600 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 2.0393e+04, step = 64153600, mean_episode_return = 23.577, mean_episode_step = 1851.3, total_loss = 163.69, pg_loss = 101.96, baseline_loss = 76.718, entropy_loss = -14.99, learner_queue_size = 64, _tick = 9971, _time = 1.6548e+09)
[2022-06-09 19:20:34,698][root][INFO] - Step 64168960 @ 3069.6 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 2.0398e+04, step = 64168960, mean_episode_return = 34.741, mean_episode_step = 1572.6, total_loss = -138.0, pg_loss = -137.18, baseline_loss = 14.142, entropy_loss = -14.956, learner_queue_size = 64, _tick = 9974, _time = 1.6548e+09)
[2022-06-09 19:20:39,702][root][INFO] - Step 64184320 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 2.0403e+04, step = 64184320, mean_episode_return = 44.596, mean_episode_step = 1930.3, total_loss = 38.963, pg_loss = 28.817, baseline_loss = 25.12, entropy_loss = -14.974, learner_queue_size = 64, _tick = 9976, _time = 1.6548e+09)
[2022-06-09 19:20:44,706][root][INFO] - Step 64199680 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 2.0408e+04, step = 64199680, mean_episode_return = None, mean_episode_step = 1804.4, total_loss = -169.23, pg_loss = -157.51, baseline_loss = 3.0946, entropy_loss = -14.814, learner_queue_size = 64, _tick = 9978, _time = 1.6548e+09)
[2022-06-09 19:20:49,710][root][INFO] - Step 64215040 @ 3069.6 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 2.0413e+04, step = 64215040, mean_episode_return = 14.672, mean_episode_step = 1858.5, total_loss = 628.19, pg_loss = 553.49, baseline_loss = 89.533, entropy_loss = -14.826, learner_queue_size = 64, _tick = 9981, _time = 1.6548e+09)
[2022-06-09 19:20:54,714][root][INFO] - Step 64235520 @ 4092.8 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 2.0418e+04, step = 64235520, mean_episode_return = 51.764, mean_episode_step = 2061.4, total_loss = -61.359, pg_loss = -80.097, baseline_loss = 33.518, entropy_loss = -14.78, learner_queue_size = 64, _tick = 9983, _time = 1.6548e+09)
[2022-06-09 19:20:59,718][root][INFO] - Step 64250880 @ 3069.5 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 2.0423e+04, step = 64250880, mean_episode_return = 24.231, mean_episode_step = 1966.4, total_loss = -25.62, pg_loss = -41.228, baseline_loss = 30.395, entropy_loss = -14.786, learner_queue_size = 64, _tick = 9986, _time = 1.6548e+09)
[2022-06-09 19:21:04,722][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 19:21:05,027][root][INFO] - Step 64266240 @ 3069.6 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 2.0428e+04, step = 64266240, mean_episode_return = 32.44, mean_episode_step = 2229.3, total_loss = -26.466, pg_loss = -42.755, baseline_loss = 30.998, entropy_loss = -14.708, learner_queue_size = 64, _tick = 9989, _time = 1.6548e+09)
[2022-06-09 19:21:10,030][root][INFO] - Step 64281600 @ 2893.8 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 2.0433e+04, step = 64281600, mean_episode_return = None, mean_episode_step = 1998.4, total_loss = 204.67, pg_loss = 187.64, baseline_loss = 32.031, entropy_loss = -14.997, learner_queue_size = 64, _tick = 9990, _time = 1.6548e+09)
[2022-06-09 19:21:15,034][root][INFO] - Step 64296960 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 2.0438e+04, step = 64296960, mean_episode_return = 74.99, mean_episode_step = 1897.4, total_loss = 436.25, pg_loss = 378.3, baseline_loss = 73.036, entropy_loss = -15.079, learner_queue_size = 64, _tick = 9993, _time = 1.6548e+09)
[2022-06-09 19:21:20,038][root][INFO] - Step 64312320 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 2.0443e+04, step = 64312320, mean_episode_return = 19.257, mean_episode_step = 1865.6, total_loss = -46.185, pg_loss = -56.169, baseline_loss = 24.959, entropy_loss = -14.975, learner_queue_size = 64, _tick = 9996, _time = 1.6548e+09)
[2022-06-09 19:21:25,042][root][INFO] - Step 64327680 @ 3069.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 2.0448e+04, step = 64327680, mean_episode_return = -33.285, mean_episode_step = 1691.7, total_loss = 353.42, pg_loss = 319.67, baseline_loss = 48.747, entropy_loss = -15.005, learner_queue_size = 64, _tick = 9999, _time = 1.6548e+09)
[2022-06-09 19:21:30,046][root][INFO] - Step 64343040 @ 3069.5 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 2.0453e+04, step = 64343040, mean_episode_return = 31.05, mean_episode_step = 1433.1, total_loss = 180.89, pg_loss = 156.61, baseline_loss = 39.209, entropy_loss = -14.928, learner_queue_size = 64, _tick = 10002, _time = 1.6548e+09)
[2022-06-09 19:21:35,050][root][INFO] - Step 64358400 @ 3069.6 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 2.0458e+04, step = 64358400, mean_episode_return = 60.634, mean_episode_step = 1825.7, total_loss = 2.675, pg_loss = -14.086, baseline_loss = 31.531, entropy_loss = -14.77, learner_queue_size = 64, _tick = 10005, _time = 1.6548e+09)
[2022-06-09 19:21:40,054][root][INFO] - Step 64378880 @ 4092.7 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 2.0463e+04, step = 64378880, mean_episode_return = 41.906, mean_episode_step = 1503.3, total_loss = -25.281, pg_loss = -42.776, baseline_loss = 32.406, entropy_loss = -14.911, learner_queue_size = 64, _tick = 10008, _time = 1.6548e+09)
[2022-06-09 19:21:45,058][root][INFO] - Step 64394240 @ 3069.5 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 2.0468e+04, step = 64394240, mean_episode_return = 52.069, mean_episode_step = 1514.1, total_loss = -99.655, pg_loss = -116.5, baseline_loss = 31.675, entropy_loss = -14.828, learner_queue_size = 64, _tick = 10011, _time = 1.6548e+09)
[2022-06-09 19:21:50,062][root][INFO] - Step 64409600 @ 3069.6 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 2.0473e+04, step = 64409600, mean_episode_return = 47.181, mean_episode_step = 1594.3, total_loss = 205.81, pg_loss = 180.69, baseline_loss = 39.825, entropy_loss = -14.707, learner_queue_size = 64, _tick = 10014, _time = 1.6548e+09)
[2022-06-09 19:21:55,066][root][INFO] - Step 64424960 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 2.0478e+04, step = 64424960, mean_episode_return = 36.534, mean_episode_step = 1582.5, total_loss = 230.9, pg_loss = 194.5, baseline_loss = 51.066, entropy_loss = -14.663, learner_queue_size = 64, _tick = 10017, _time = 1.6548e+09)
[2022-06-09 19:22:00,070][root][INFO] - Step 64440320 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 2.0483e+04, step = 64440320, mean_episode_return = 56.33, mean_episode_step = 1815.0, total_loss = -57.563, pg_loss = -75.369, baseline_loss = 32.509, entropy_loss = -14.704, learner_queue_size = 64, _tick = 10020, _time = 1.6548e+09)
[2022-06-09 19:22:05,074][root][INFO] - Step 64455680 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 2.0488e+04, step = 64455680, mean_episode_return = 3.8199, mean_episode_step = 1717.2, total_loss = 171.08, pg_loss = 135.82, baseline_loss = 50.004, entropy_loss = -14.751, learner_queue_size = 64, _tick = 10023, _time = 1.6548e+09)
[2022-06-09 19:22:10,078][root][INFO] - Step 64471040 @ 3069.6 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 2.0493e+04, step = 64471040, mean_episode_return = 11.957, mean_episode_step = 2087.1, total_loss = -32.495, pg_loss = -48.668, baseline_loss = 30.866, entropy_loss = -14.693, learner_queue_size = 64, _tick = 10024, _time = 1.6548e+09)
[2022-06-09 19:22:15,082][root][INFO] - Step 64491520 @ 4092.7 SPS. Inference batcher size: 83. Learner queue size: 64. Other stats: (train_seconds = 2.0498e+04, step = 64491520, mean_episode_return = 46.986, mean_episode_step = 1834.5, total_loss = 31.162, pg_loss = 17.74, baseline_loss = 28.131, entropy_loss = -14.709, learner_queue_size = 64, _tick = 10028, _time = 1.6548e+09)
[2022-06-09 19:22:20,086][root][INFO] - Step 64506880 @ 3069.6 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 2.0503e+04, step = 64506880, mean_episode_return = 23.709, mean_episode_step = 1648.4, total_loss = 188.69, pg_loss = 143.15, baseline_loss = 60.206, entropy_loss = -14.661, learner_queue_size = 64, _tick = 10031, _time = 1.6548e+09)
[2022-06-09 19:22:25,090][root][INFO] - Step 64522240 @ 3069.5 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 2.0508e+04, step = 64522240, mean_episode_return = 37.069, mean_episode_step = 1608.6, total_loss = 228.99, pg_loss = 191.47, baseline_loss = 52.208, entropy_loss = -14.688, learner_queue_size = 64, _tick = 10034, _time = 1.6548e+09)
[2022-06-09 19:22:30,094][root][INFO] - Step 64537600 @ 3069.6 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 2.0513e+04, step = 64537600, mean_episode_return = 183.76, mean_episode_step = 1993.1, total_loss = 42.334, pg_loss = 27.905, baseline_loss = 29.099, entropy_loss = -14.67, learner_queue_size = 64, _tick = 10037, _time = 1.6548e+09)
[2022-06-09 19:22:35,098][root][INFO] - Step 64552960 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 2.0518e+04, step = 64552960, mean_episode_return = 18.081, mean_episode_step = 1697.3, total_loss = 488.41, pg_loss = 385.84, baseline_loss = 117.23, entropy_loss = -14.653, learner_queue_size = 64, _tick = 10040, _time = 1.6548e+09)
[2022-06-09 19:22:40,102][root][INFO] - Step 64568320 @ 3069.5 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 2.0523e+04, step = 64568320, mean_episode_return = -1.2403, mean_episode_step = 2037.6, total_loss = -40.049, pg_loss = -46.249, baseline_loss = 20.763, entropy_loss = -14.563, learner_queue_size = 64, _tick = 10043, _time = 1.6548e+09)
[2022-06-09 19:22:45,106][root][INFO] - Step 64583680 @ 3069.5 SPS. Inference batcher size: 5. Learner queue size: 64. Other stats: (train_seconds = 2.0528e+04, step = 64583680, mean_episode_return = 5.3498, mean_episode_step = 1379.0, total_loss = 192.56, pg_loss = 152.05, baseline_loss = 55.002, entropy_loss = -14.501, learner_queue_size = 64, _tick = 10046, _time = 1.6548e+09)
[2022-06-09 19:22:50,110][root][INFO] - Step 64599040 @ 3069.6 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 2.0533e+04, step = 64599040, mean_episode_return = 80.165, mean_episode_step = 1771.7, total_loss = 72.327, pg_loss = 44.271, baseline_loss = 42.495, entropy_loss = -14.439, learner_queue_size = 64, _tick = 10049, _time = 1.6548e+09)
[2022-06-09 19:22:55,114][root][INFO] - Step 64614400 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 2.0538e+04, step = 64614400, mean_episode_return = None, mean_episode_step = 1910.9, total_loss = 173.6, pg_loss = 144.79, baseline_loss = 43.16, entropy_loss = -14.348, learner_queue_size = 64, _tick = 10051, _time = 1.6548e+09)
[2022-06-09 19:23:00,118][root][INFO] - Step 64634880 @ 4092.7 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 2.0543e+04, step = 64634880, mean_episode_return = None, mean_episode_step = 2167.4, total_loss = -123.61, pg_loss = -124.19, baseline_loss = 14.816, entropy_loss = -14.246, learner_queue_size = 64, _tick = 10053, _time = 1.6548e+09)
[2022-06-09 19:23:05,122][root][INFO] - Step 64650240 @ 3069.5 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 2.0548e+04, step = 64650240, mean_episode_return = 57.78, mean_episode_step = 1726.9, total_loss = 19.323, pg_loss = 6.6924, baseline_loss = 26.952, entropy_loss = -14.321, learner_queue_size = 64, _tick = 10055, _time = 1.6548e+09)
[2022-06-09 19:23:10,126][root][INFO] - Step 64665600 @ 3069.5 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 2.0553e+04, step = 64665600, mean_episode_return = None, mean_episode_step = 2075.8, total_loss = -236.15, pg_loss = -223.95, baseline_loss = 2.2119, entropy_loss = -14.413, learner_queue_size = 64, _tick = 10057, _time = 1.6548e+09)
[2022-06-09 19:23:15,130][root][INFO] - Step 64680960 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 2.0558e+04, step = 64680960, mean_episode_return = 13.81, mean_episode_step = 2063.6, total_loss = -129.48, pg_loss = -124.4, baseline_loss = 9.525, entropy_loss = -14.597, learner_queue_size = 64, _tick = 10059, _time = 1.6548e+09)
[2022-06-09 19:23:20,134][root][INFO] - Step 64696320 @ 3069.6 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 2.0563e+04, step = 64696320, mean_episode_return = 53.799, mean_episode_step = 1934.1, total_loss = -169.11, pg_loss = -168.68, baseline_loss = 14.242, entropy_loss = -14.668, learner_queue_size = 64, _tick = 10061, _time = 1.6548e+09)
[2022-06-09 19:23:25,138][root][INFO] - Step 64711680 @ 3069.5 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 2.0568e+04, step = 64711680, mean_episode_return = None, mean_episode_step = 2228.1, total_loss = -101.12, pg_loss = -95.077, baseline_loss = 8.7551, entropy_loss = -14.801, learner_queue_size = 64, _tick = 10063, _time = 1.6548e+09)
[2022-06-09 19:23:30,142][root][INFO] - Step 64727040 @ 3069.6 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 2.0573e+04, step = 64727040, mean_episode_return = 163.86, mean_episode_step = 2121.7, total_loss = 12.128, pg_loss = -0.6368, baseline_loss = 27.687, entropy_loss = -14.922, learner_queue_size = 64, _tick = 10066, _time = 1.6548e+09)
[2022-06-09 19:23:35,146][root][INFO] - Step 64742400 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 2.0578e+04, step = 64742400, mean_episode_return = 13.135, mean_episode_step = 2382.2, total_loss = 54.811, pg_loss = 22.439, baseline_loss = 47.222, entropy_loss = -14.851, learner_queue_size = 64, _tick = 10068, _time = 1.6548e+09)
[2022-06-09 19:23:40,150][root][INFO] - Step 64762880 @ 4092.7 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 2.0583e+04, step = 64762880, mean_episode_return = None, mean_episode_step = 1942.3, total_loss = 194.29, pg_loss = 170.98, baseline_loss = 38.277, entropy_loss = -14.968, learner_queue_size = 64, _tick = 10070, _time = 1.6548e+09)
[2022-06-09 19:23:45,154][root][INFO] - Step 64778240 @ 3069.5 SPS. Inference batcher size: 68. Learner queue size: 64. Other stats: (train_seconds = 2.0588e+04, step = 64778240, mean_episode_return = None, mean_episode_step = 2129.5, total_loss = 143.33, pg_loss = 122.9, baseline_loss = 35.332, entropy_loss = -14.9, learner_queue_size = 64, _tick = 10072, _time = 1.6548e+09)
[2022-06-09 19:23:50,158][root][INFO] - Step 64793600 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 2.0593e+04, step = 64793600, mean_episode_return = None, mean_episode_step = 2464.3, total_loss = -67.289, pg_loss = -68.343, baseline_loss = 15.914, entropy_loss = -14.86, learner_queue_size = 64, _tick = 10074, _time = 1.6548e+09)
[2022-06-09 19:23:55,162][root][INFO] - Step 64808960 @ 3069.5 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 2.0598e+04, step = 64808960, mean_episode_return = 73.489, mean_episode_step = 1911.1, total_loss = -62.386, pg_loss = -83.738, baseline_loss = 36.312, entropy_loss = -14.961, learner_queue_size = 64, _tick = 10077, _time = 1.6548e+09)
[2022-06-09 19:24:00,168][root][INFO] - Step 64824320 @ 3068.6 SPS. Inference batcher size: 10. Learner queue size: 64. Other stats: (train_seconds = 2.0603e+04, step = 64824320, mean_episode_return = 18.055, mean_episode_step = 1778.2, total_loss = -232.4, pg_loss = -230.45, baseline_loss = 13.054, entropy_loss = -15.004, learner_queue_size = 64, _tick = 10080, _time = 1.6548e+09)
[2022-06-09 19:24:05,170][root][INFO] - Step 64839680 @ 3070.6 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 2.0608e+04, step = 64839680, mean_episode_return = None, mean_episode_step = 2134.9, total_loss = 127.58, pg_loss = 106.41, baseline_loss = 36.251, entropy_loss = -15.075, learner_queue_size = 64, _tick = 10082, _time = 1.6548e+09)
[2022-06-09 19:24:10,174][root][INFO] - Step 64855040 @ 3069.5 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 2.0613e+04, step = 64855040, mean_episode_return = 63.861, mean_episode_step = 1930.0, total_loss = -85.651, pg_loss = -94.702, baseline_loss = 24.125, entropy_loss = -15.074, learner_queue_size = 64, _tick = 10085, _time = 1.6548e+09)
[2022-06-09 19:24:15,178][root][INFO] - Step 64870400 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 2.0618e+04, step = 64870400, mean_episode_return = 62.611, mean_episode_step = 1863.3, total_loss = -268.74, pg_loss = -265.73, baseline_loss = 11.924, entropy_loss = -14.933, learner_queue_size = 64, _tick = 10088, _time = 1.6548e+09)
[2022-06-09 19:24:20,182][root][INFO] - Step 64885760 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 2.0623e+04, step = 64885760, mean_episode_return = 14.815, mean_episode_step = 1703.6, total_loss = 313.08, pg_loss = 283.89, baseline_loss = 43.987, entropy_loss = -14.8, learner_queue_size = 64, _tick = 10091, _time = 1.6548e+09)
[2022-06-09 19:24:25,188][root][INFO] - Step 64901120 @ 3068.4 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 2.0628e+04, step = 64901120, mean_episode_return = -6.0904, mean_episode_step = 1612.2, total_loss = 29.836, pg_loss = 16.848, baseline_loss = 27.744, entropy_loss = -14.755, learner_queue_size = 64, _tick = 10094, _time = 1.6548e+09)
[2022-06-09 19:24:30,190][root][INFO] - Step 64921600 @ 4094.1 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 2.0633e+04, step = 64921600, mean_episode_return = 71.485, mean_episode_step = 2200.6, total_loss = 17.928, pg_loss = 0.14653, baseline_loss = 32.502, entropy_loss = -14.721, learner_queue_size = 64, _tick = 10098, _time = 1.6548e+09)
[2022-06-09 19:24:35,194][root][INFO] - Step 64936960 @ 3069.6 SPS. Inference batcher size: 71. Learner queue size: 64. Other stats: (train_seconds = 2.0638e+04, step = 64936960, mean_episode_return = 68.087, mean_episode_step = 1918.6, total_loss = -28.103, pg_loss = -38.072, baseline_loss = 24.712, entropy_loss = -14.744, learner_queue_size = 64, _tick = 10101, _time = 1.6548e+09)
[2022-06-09 19:24:40,198][root][INFO] - Step 64952320 @ 3069.5 SPS. Inference batcher size: 75. Learner queue size: 64. Other stats: (train_seconds = 2.0643e+04, step = 64952320, mean_episode_return = 1.9946, mean_episode_step = 2125.1, total_loss = 238.17, pg_loss = 189.83, baseline_loss = 63.042, entropy_loss = -14.7, learner_queue_size = 64, _tick = 10104, _time = 1.6548e+09)
[2022-06-09 19:24:45,202][root][INFO] - Step 64967680 @ 3069.6 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 2.0648e+04, step = 64967680, mean_episode_return = 69.36, mean_episode_step = 2227.0, total_loss = -164.34, pg_loss = -157.83, baseline_loss = 7.9225, entropy_loss = -14.435, learner_queue_size = 64, _tick = 10107, _time = 1.6548e+09)
[2022-06-09 19:24:50,206][root][INFO] - Step 64983040 @ 3069.6 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 2.0653e+04, step = 64983040, mean_episode_return = -3.1553, mean_episode_step = 2037.4, total_loss = 181.84, pg_loss = 152.09, baseline_loss = 44.255, entropy_loss = -14.5, learner_queue_size = 64, _tick = 10109, _time = 1.6548e+09)
[2022-06-09 19:24:55,210][root][INFO] - Step 64998400 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 2.0658e+04, step = 64998400, mean_episode_return = 0.91964, mean_episode_step = 1812.2, total_loss = 633.3, pg_loss = 564.64, baseline_loss = 83.171, entropy_loss = -14.517, learner_queue_size = 64, _tick = 10112, _time = 1.6548e+09)
[2022-06-09 19:25:00,214][root][INFO] - Step 65013760 @ 3069.5 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 2.0663e+04, step = 65013760, mean_episode_return = 64.333, mean_episode_step = 1977.6, total_loss = -82.701, pg_loss = -94.796, baseline_loss = 26.526, entropy_loss = -14.43, learner_queue_size = 64, _tick = 10115, _time = 1.6548e+09)
[2022-06-09 19:25:05,218][root][INFO] - Step 65029120 @ 3069.6 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 2.0668e+04, step = 65029120, mean_episode_return = 12.623, mean_episode_step = 1795.1, total_loss = -77.056, pg_loss = -85.852, baseline_loss = 23.258, entropy_loss = -14.462, learner_queue_size = 64, _tick = 10118, _time = 1.6548e+09)
[2022-06-09 19:25:10,222][root][INFO] - Step 65044480 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 2.0673e+04, step = 65044480, mean_episode_return = 59.132, mean_episode_step = 2012.6, total_loss = 132.19, pg_loss = 95.087, baseline_loss = 51.577, entropy_loss = -14.473, learner_queue_size = 64, _tick = 10120, _time = 1.6548e+09)
[2022-06-09 19:25:15,226][root][INFO] - Step 65064960 @ 4092.8 SPS. Inference batcher size: 12. Learner queue size: 64. Other stats: (train_seconds = 2.0678e+04, step = 65064960, mean_episode_return = 84.57, mean_episode_step = 1734.8, total_loss = -31.298, pg_loss = -34.615, baseline_loss = 17.799, entropy_loss = -14.483, learner_queue_size = 64, _tick = 10123, _time = 1.6548e+09)
[2022-06-09 19:25:20,230][root][INFO] - Step 65080320 @ 3069.5 SPS. Inference batcher size: 85. Learner queue size: 64. Other stats: (train_seconds = 2.0683e+04, step = 65080320, mean_episode_return = -13.543, mean_episode_step = 2209.7, total_loss = -11.825, pg_loss = -27.825, baseline_loss = 30.652, entropy_loss = -14.653, learner_queue_size = 64, _tick = 10125, _time = 1.6548e+09)
[2022-06-09 19:25:25,234][root][INFO] - Step 65095680 @ 3069.6 SPS. Inference batcher size: 72. Learner queue size: 64. Other stats: (train_seconds = 2.0688e+04, step = 65095680, mean_episode_return = 25.501, mean_episode_step = 2012.2, total_loss = -114.31, pg_loss = -112.35, baseline_loss = 12.831, entropy_loss = -14.797, learner_queue_size = 64, _tick = 10128, _time = 1.6548e+09)
[2022-06-09 19:25:30,238][root][INFO] - Step 65111040 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 2.0693e+04, step = 65111040, mean_episode_return = 26.966, mean_episode_step = 1925.9, total_loss = 1744.7, pg_loss = 1178.6, baseline_loss = 581.05, entropy_loss = -14.891, learner_queue_size = 64, _tick = 10131, _time = 1.6548e+09)
[2022-06-09 19:25:35,242][root][INFO] - Step 65126400 @ 3069.5 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 2.0698e+04, step = 65126400, mean_episode_return = 98.571, mean_episode_step = 1920.4, total_loss = 463.16, pg_loss = 415.73, baseline_loss = 62.61, entropy_loss = -15.18, learner_queue_size = 64, _tick = 10134, _time = 1.6548e+09)
[2022-06-09 19:25:40,246][root][INFO] - Step 65141760 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 2.0703e+04, step = 65141760, mean_episode_return = 48.6, mean_episode_step = 1846.8, total_loss = 323.92, pg_loss = 300.31, baseline_loss = 38.81, entropy_loss = -15.205, learner_queue_size = 64, _tick = 10137, _time = 1.6548e+09)
[2022-06-09 19:25:45,250][root][INFO] - Step 65157120 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 2.0708e+04, step = 65157120, mean_episode_return = None, mean_episode_step = 1969.3, total_loss = 328.59, pg_loss = 295.42, baseline_loss = 48.408, entropy_loss = -15.242, learner_queue_size = 64, _tick = 10139, _time = 1.6548e+09)
[2022-06-09 19:25:50,256][root][INFO] - Step 65172480 @ 3068.3 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 2.0713e+04, step = 65172480, mean_episode_return = 20.19, mean_episode_step = 1790.8, total_loss = 183.19, pg_loss = 151.62, baseline_loss = 46.643, entropy_loss = -15.08, learner_queue_size = 64, _tick = 10141, _time = 1.6548e+09)
[2022-06-09 19:25:55,262][root][INFO] - Step 65187840 @ 3068.3 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 2.0718e+04, step = 65187840, mean_episode_return = None, mean_episode_step = 2121.3, total_loss = 473.8, pg_loss = 423.63, baseline_loss = 65.35, entropy_loss = -15.175, learner_queue_size = 64, _tick = 10141, _time = 1.6548e+09)
[2022-06-09 19:26:00,266][root][INFO] - Step 65208320 @ 4092.9 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 2.0723e+04, step = 65208320, mean_episode_return = 38.82, mean_episode_step = 2115.8, total_loss = -58.884, pg_loss = -62.011, baseline_loss = 18.176, entropy_loss = -15.049, learner_queue_size = 64, _tick = 10145, _time = 1.6548e+09)
[2022-06-09 19:26:05,270][root][INFO] - Step 65223680 @ 3069.5 SPS. Inference batcher size: 73. Learner queue size: 64. Other stats: (train_seconds = 2.0728e+04, step = 65223680, mean_episode_return = -12.358, mean_episode_step = 2198.1, total_loss = 362.47, pg_loss = 324.37, baseline_loss = 52.956, entropy_loss = -14.855, learner_queue_size = 64, _tick = 10148, _time = 1.6548e+09)
[2022-06-09 19:26:10,276][root][INFO] - Step 65239040 @ 3068.2 SPS. Inference batcher size: 71. Learner queue size: 64. Other stats: (train_seconds = 2.0733e+04, step = 65239040, mean_episode_return = 46.98, mean_episode_step = 1653.8, total_loss = -37.207, pg_loss = -55.022, baseline_loss = 32.508, entropy_loss = -14.693, learner_queue_size = 64, _tick = 10151, _time = 1.6548e+09)
[2022-06-09 19:26:15,282][root][INFO] - Step 65254400 @ 3068.3 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 2.0738e+04, step = 65254400, mean_episode_return = 16.52, mean_episode_step = 2009.6, total_loss = -117.89, pg_loss = -118.41, baseline_loss = 15.144, entropy_loss = -14.622, learner_queue_size = 64, _tick = 10153, _time = 1.6548e+09)
[2022-06-09 19:26:20,286][root][INFO] - Step 65269760 @ 3069.6 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 2.0743e+04, step = 65269760, mean_episode_return = 52.021, mean_episode_step = 1951.2, total_loss = 698.72, pg_loss = 588.08, baseline_loss = 125.35, entropy_loss = -14.706, learner_queue_size = 64, _tick = 10155, _time = 1.6548e+09)
[2022-06-09 19:26:25,290][root][INFO] - Step 65285120 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 2.0748e+04, step = 65285120, mean_episode_return = 83.996, mean_episode_step = 2394.1, total_loss = 34.64, pg_loss = -1.3867, baseline_loss = 50.757, entropy_loss = -14.73, learner_queue_size = 64, _tick = 10157, _time = 1.6548e+09)
[2022-06-09 19:26:30,294][root][INFO] - Step 65300480 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 2.0753e+04, step = 65300480, mean_episode_return = 77.379, mean_episode_step = 2298.1, total_loss = 90.818, pg_loss = 74.421, baseline_loss = 31.22, entropy_loss = -14.823, learner_queue_size = 64, _tick = 10160, _time = 1.6548e+09)
[2022-06-09 19:26:35,298][root][INFO] - Step 65315840 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 2.0758e+04, step = 65315840, mean_episode_return = 8.6609, mean_episode_step = 2229.7, total_loss = -1.3093, pg_loss = -18.664, baseline_loss = 32.158, entropy_loss = -14.803, learner_queue_size = 64, _tick = 10163, _time = 1.6548e+09)
[2022-06-09 19:26:40,302][root][INFO] - Step 65336320 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 2.0763e+04, step = 65336320, mean_episode_return = 83.199, mean_episode_step = 2371.1, total_loss = -201.82, pg_loss = -192.54, baseline_loss = 5.217, entropy_loss = -14.489, learner_queue_size = 64, _tick = 10167, _time = 1.6548e+09)
[2022-06-09 19:26:45,306][root][INFO] - Step 65351680 @ 3069.5 SPS. Inference batcher size: 80. Learner queue size: 64. Other stats: (train_seconds = 2.0768e+04, step = 65351680, mean_episode_return = 66.68, mean_episode_step = 2413.0, total_loss = -125.58, pg_loss = -132.36, baseline_loss = 21.371, entropy_loss = -14.597, learner_queue_size = 64, _tick = 10170, _time = 1.6548e+09)
[2022-06-09 19:26:50,310][root][INFO] - Step 65367040 @ 3069.6 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 2.0773e+04, step = 65367040, mean_episode_return = 51.101, mean_episode_step = 1917.1, total_loss = 167.84, pg_loss = 140.67, baseline_loss = 41.768, entropy_loss = -14.596, learner_queue_size = 64, _tick = 10173, _time = 1.6548e+09)
[2022-06-09 19:26:55,314][root][INFO] - Step 65382400 @ 3069.6 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 2.0778e+04, step = 65382400, mean_episode_return = 69.768, mean_episode_step = 2065.8, total_loss = 145.33, pg_loss = 121.25, baseline_loss = 38.69, entropy_loss = -14.605, learner_queue_size = 64, _tick = 10176, _time = 1.6548e+09)
[2022-06-09 19:27:00,318][root][INFO] - Step 65397760 @ 3069.5 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 2.0783e+04, step = 65397760, mean_episode_return = None, mean_episode_step = 1980.9, total_loss = 73.048, pg_loss = 62.606, baseline_loss = 25.202, entropy_loss = -14.76, learner_queue_size = 64, _tick = 10176, _time = 1.6548e+09)
[2022-06-09 19:27:05,322][root][INFO] - Step 65413120 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 2.0788e+04, step = 65413120, mean_episode_return = 23.58, mean_episode_step = 2153.6, total_loss = -158.76, pg_loss = -157.42, baseline_loss = 13.295, entropy_loss = -14.635, learner_queue_size = 64, _tick = 10179, _time = 1.6548e+09)
[2022-06-09 19:27:10,326][root][INFO] - Step 65428480 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 2.0793e+04, step = 65428480, mean_episode_return = 10.499, mean_episode_step = 2184.1, total_loss = 76.383, pg_loss = 43.076, baseline_loss = 48.051, entropy_loss = -14.744, learner_queue_size = 64, _tick = 10182, _time = 1.6548e+09)
[2022-06-09 19:27:15,330][root][INFO] - Step 65443840 @ 3069.6 SPS. Inference batcher size: 8. Learner queue size: 64. Other stats: (train_seconds = 2.0798e+04, step = 65443840, mean_episode_return = 22.801, mean_episode_step = 2442.9, total_loss = -137.91, pg_loss = -139.16, baseline_loss = 15.848, entropy_loss = -14.598, learner_queue_size = 64, _tick = 10185, _time = 1.6548e+09)
[2022-06-09 19:27:20,334][root][INFO] - Step 65459200 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 2.0803e+04, step = 65459200, mean_episode_return = 83.526, mean_episode_step = 2229.6, total_loss = -304.8, pg_loss = -295.41, baseline_loss = 5.3457, entropy_loss = -14.73, learner_queue_size = 64, _tick = 10187, _time = 1.6548e+09)
[2022-06-09 19:27:25,338][root][INFO] - Step 65474560 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 2.0808e+04, step = 65474560, mean_episode_return = 32.111, mean_episode_step = 1890.1, total_loss = -235.62, pg_loss = -233.95, baseline_loss = 13.271, entropy_loss = -14.95, learner_queue_size = 64, _tick = 10190, _time = 1.6548e+09)
[2022-06-09 19:27:30,342][root][INFO] - Step 65489920 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 2.0813e+04, step = 65489920, mean_episode_return = -11.108, mean_episode_step = 2429.6, total_loss = -249.65, pg_loss = -247.72, baseline_loss = 13.03, entropy_loss = -14.96, learner_queue_size = 64, _tick = 10192, _time = 1.6548e+09)
[2022-06-09 19:27:35,346][root][INFO] - Step 65510400 @ 4092.8 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 2.0818e+04, step = 65510400, mean_episode_return = 41.713, mean_episode_step = 2243.1, total_loss = -65.6, pg_loss = -81.142, baseline_loss = 30.452, entropy_loss = -14.91, learner_queue_size = 64, _tick = 10196, _time = 1.6548e+09)
[2022-06-09 19:27:40,350][root][INFO] - Step 65525760 @ 3069.5 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 2.0823e+04, step = 65525760, mean_episode_return = 97.819, mean_episode_step = 1990.5, total_loss = 304.68, pg_loss = 235.28, baseline_loss = 84.145, entropy_loss = -14.748, learner_queue_size = 64, _tick = 10199, _time = 1.6548e+09)
[2022-06-09 19:27:45,354][root][INFO] - Step 65541120 @ 3069.6 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 2.0828e+04, step = 65541120, mean_episode_return = 66.032, mean_episode_step = 1917.6, total_loss = 63.767, pg_loss = 30.865, baseline_loss = 47.586, entropy_loss = -14.683, learner_queue_size = 64, _tick = 10202, _time = 1.6548e+09)
[2022-06-09 19:27:50,358][root][INFO] - Step 65556480 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 2.0833e+04, step = 65556480, mean_episode_return = 15.156, mean_episode_step = 1937.9, total_loss = -177.32, pg_loss = -172.73, baseline_loss = 10.279, entropy_loss = -14.874, learner_queue_size = 64, _tick = 10204, _time = 1.6548e+09)
[2022-06-09 19:27:55,362][root][INFO] - Step 65571840 @ 3069.6 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 2.0838e+04, step = 65571840, mean_episode_return = 19.708, mean_episode_step = 2083.4, total_loss = 269.25, pg_loss = 190.0, baseline_loss = 94.064, entropy_loss = -14.807, learner_queue_size = 64, _tick = 10206, _time = 1.6548e+09)
[2022-06-09 19:28:00,366][root][INFO] - Step 65587200 @ 3069.5 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 2.0843e+04, step = 65587200, mean_episode_return = 72.883, mean_episode_step = 2022.8, total_loss = -117.79, pg_loss = -124.97, baseline_loss = 22.078, entropy_loss = -14.889, learner_queue_size = 64, _tick = 10209, _time = 1.6548e+09)
[2022-06-09 19:28:05,370][root][INFO] - Step 65602560 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 2.0848e+04, step = 65602560, mean_episode_return = -11.84, mean_episode_step = 2184.2, total_loss = 109.35, pg_loss = 41.435, baseline_loss = 82.617, entropy_loss = -14.702, learner_queue_size = 64, _tick = 10212, _time = 1.6548e+09)
[2022-06-09 19:28:10,374][root][INFO] - Step 65617920 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 2.0853e+04, step = 65617920, mean_episode_return = 26.981, mean_episode_step = 2048.2, total_loss = 193.9, pg_loss = 129.4, baseline_loss = 79.273, entropy_loss = -14.767, learner_queue_size = 64, _tick = 10215, _time = 1.6548e+09)
[2022-06-09 19:28:15,380][root][INFO] - Step 65633280 @ 3068.1 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 2.0858e+04, step = 65633280, mean_episode_return = 29.861, mean_episode_step = 2216.0, total_loss = -202.42, pg_loss = -202.99, baseline_loss = 15.287, entropy_loss = -14.716, learner_queue_size = 64, _tick = 10217, _time = 1.6548e+09)
[2022-06-09 19:28:20,386][root][INFO] - Step 65653760 @ 4091.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 2.0863e+04, step = 65653760, mean_episode_return = 107.82, mean_episode_step = 2366.5, total_loss = -68.05, pg_loss = -74.601, baseline_loss = 21.253, entropy_loss = -14.702, learner_queue_size = 64, _tick = 10220, _time = 1.6548e+09)
[2022-06-09 19:28:25,390][root][INFO] - Step 65669120 @ 3069.5 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 2.0868e+04, step = 65669120, mean_episode_return = 36.844, mean_episode_step = 2118.0, total_loss = 197.01, pg_loss = 165.51, baseline_loss = 46.137, entropy_loss = -14.644, learner_queue_size = 64, _tick = 10223, _time = 1.6548e+09)
[2022-06-09 19:28:30,394][root][INFO] - Step 65684480 @ 3069.5 SPS. Inference batcher size: 75. Learner queue size: 64. Other stats: (train_seconds = 2.0873e+04, step = 65684480, mean_episode_return = -5.8105, mean_episode_step = 1991.9, total_loss = -149.65, pg_loss = -151.34, baseline_loss = 16.18, entropy_loss = -14.487, learner_queue_size = 64, _tick = 10226, _time = 1.6548e+09)
[2022-06-09 19:28:35,398][root][INFO] - Step 65699840 @ 3069.5 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 2.0878e+04, step = 65699840, mean_episode_return = 40.321, mean_episode_step = 2150.1, total_loss = -63.54, pg_loss = -86.691, baseline_loss = 37.683, entropy_loss = -14.532, learner_queue_size = 64, _tick = 10229, _time = 1.6548e+09)
[2022-06-09 19:28:40,402][root][INFO] - Step 65715200 @ 3069.5 SPS. Inference batcher size: 15. Learner queue size: 64. Other stats: (train_seconds = 2.0883e+04, step = 65715200, mean_episode_return = 31.573, mean_episode_step = 2023.3, total_loss = -236.97, pg_loss = -230.11, baseline_loss = 7.6874, entropy_loss = -14.546, learner_queue_size = 64, _tick = 10231, _time = 1.6548e+09)
[2022-06-09 19:28:45,406][root][INFO] - Step 65730560 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 2.0888e+04, step = 65730560, mean_episode_return = 53.284, mean_episode_step = 2084.0, total_loss = 40.952, pg_loss = 3.7938, baseline_loss = 51.702, entropy_loss = -14.544, learner_queue_size = 64, _tick = 10234, _time = 1.6548e+09)
[2022-06-09 19:28:50,410][root][INFO] - Step 65745920 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 2.0893e+04, step = 65745920, mean_episode_return = 15.53, mean_episode_step = 1941.7, total_loss = 74.045, pg_loss = 55.283, baseline_loss = 33.365, entropy_loss = -14.603, learner_queue_size = 64, _tick = 10237, _time = 1.6548e+09)
[2022-06-09 19:28:55,416][root][INFO] - Step 65761280 @ 3068.4 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 2.0898e+04, step = 65761280, mean_episode_return = 45.59, mean_episode_step = 2192.9, total_loss = 390.99, pg_loss = 325.94, baseline_loss = 79.394, entropy_loss = -14.346, learner_queue_size = 64, _tick = 10240, _time = 1.6548e+09)
[2022-06-09 19:29:00,423][root][INFO] - Step 65776640 @ 3067.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 2.0903e+04, step = 65776640, mean_episode_return = None, mean_episode_step = 1984.9, total_loss = -93.97, pg_loss = -94.017, baseline_loss = 14.496, entropy_loss = -14.448, learner_queue_size = 64, _tick = 10242, _time = 1.6548e+09)
[2022-06-09 19:29:05,426][root][INFO] - Step 65797120 @ 4093.7 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 2.0908e+04, step = 65797120, mean_episode_return = 75.755, mean_episode_step = 1395.7, total_loss = 39.345, pg_loss = 7.6427, baseline_loss = 46.194, entropy_loss = -14.491, learner_queue_size = 64, _tick = 10246, _time = 1.6548e+09)
[2022-06-09 19:29:10,430][root][INFO] - Step 65812480 @ 3069.6 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 2.0913e+04, step = 65812480, mean_episode_return = 42.198, mean_episode_step = 1662.9, total_loss = -198.95, pg_loss = -208.4, baseline_loss = 23.719, entropy_loss = -14.271, learner_queue_size = 64, _tick = 10249, _time = 1.6548e+09)
[2022-06-09 19:29:15,434][root][INFO] - Step 65827840 @ 3069.6 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 2.0918e+04, step = 65827840, mean_episode_return = 42.665, mean_episode_step = 2027.5, total_loss = 179.3, pg_loss = 152.11, baseline_loss = 41.474, entropy_loss = -14.285, learner_queue_size = 64, _tick = 10251, _time = 1.6548e+09)
[2022-06-09 19:29:20,438][root][INFO] - Step 65843200 @ 3069.5 SPS. Inference batcher size: 101. Learner queue size: 64. Other stats: (train_seconds = 2.0923e+04, step = 65843200, mean_episode_return = 88.004, mean_episode_step = 2018.7, total_loss = 276.97, pg_loss = 242.84, baseline_loss = 48.502, entropy_loss = -14.373, learner_queue_size = 64, _tick = 10253, _time = 1.6548e+09)
[2022-06-09 19:29:25,442][root][INFO] - Step 65858560 @ 3069.6 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 2.0928e+04, step = 65858560, mean_episode_return = None, mean_episode_step = 1783.2, total_loss = 89.204, pg_loss = 62.609, baseline_loss = 41.024, entropy_loss = -14.428, learner_queue_size = 64, _tick = 10255, _time = 1.6548e+09)
[2022-06-09 19:29:30,446][root][INFO] - Step 65873920 @ 3069.6 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 2.0933e+04, step = 65873920, mean_episode_return = None, mean_episode_step = 1888.6, total_loss = 214.71, pg_loss = 182.17, baseline_loss = 47.061, entropy_loss = -14.525, learner_queue_size = 64, _tick = 10256, _time = 1.6548e+09)
[2022-06-09 19:29:35,452][root][INFO] - Step 65889280 @ 3068.3 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 2.0938e+04, step = 65889280, mean_episode_return = 62.61, mean_episode_step = 2161.9, total_loss = -146.42, pg_loss = -154.25, baseline_loss = 22.269, entropy_loss = -14.431, learner_queue_size = 64, _tick = 10259, _time = 1.6548e+09)
[2022-06-09 19:29:40,458][root][INFO] - Step 65904640 @ 3068.3 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 2.0943e+04, step = 65904640, mean_episode_return = None, mean_episode_step = 1770.0, total_loss = 57.988, pg_loss = 40.539, baseline_loss = 31.913, entropy_loss = -14.463, learner_queue_size = 64, _tick = 10260, _time = 1.6548e+09)
[2022-06-09 19:29:45,462][root][INFO] - Step 65920000 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 2.0948e+04, step = 65920000, mean_episode_return = None, mean_episode_step = 1876.1, total_loss = 0.25804, pg_loss = -9.4137, baseline_loss = 24.131, entropy_loss = -14.459, learner_queue_size = 64, _tick = 10261, _time = 1.6548e+09)
[2022-06-09 19:29:50,466][root][INFO] - Step 65935360 @ 3069.5 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 2.0953e+04, step = 65935360, mean_episode_return = -10.411, mean_episode_step = 2312.7, total_loss = -120.89, pg_loss = -128.87, baseline_loss = 22.485, entropy_loss = -14.503, learner_queue_size = 64, _tick = 10263, _time = 1.6548e+09)
[2022-06-09 19:29:55,470][root][INFO] - Step 65950720 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 2.0958e+04, step = 65950720, mean_episode_return = -21.211, mean_episode_step = 1727.3, total_loss = 139.51, pg_loss = 106.36, baseline_loss = 47.681, entropy_loss = -14.529, learner_queue_size = 64, _tick = 10266, _time = 1.6548e+09)
[2022-06-09 19:30:00,474][root][INFO] - Step 65966080 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 2.0963e+04, step = 65966080, mean_episode_return = 52.995, mean_episode_step = 2113.6, total_loss = -225.29, pg_loss = -235.74, baseline_loss = 25.003, entropy_loss = -14.553, learner_queue_size = 64, _tick = 10269, _time = 1.6548e+09)
[2022-06-09 19:30:05,478][root][INFO] - Step 65981440 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 2.0968e+04, step = 65981440, mean_episode_return = 81.867, mean_episode_step = 1706.3, total_loss = -25.623, pg_loss = -40.719, baseline_loss = 29.783, entropy_loss = -14.688, learner_queue_size = 64, _tick = 10272, _time = 1.6548e+09)
[2022-06-09 19:30:10,482][root][INFO] - Step 65996800 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 2.0973e+04, step = 65996800, mean_episode_return = 105.97, mean_episode_step = 1763.3, total_loss = 395.41, pg_loss = 344.69, baseline_loss = 65.275, entropy_loss = -14.553, learner_queue_size = 64, _tick = 10275, _time = 1.6548e+09)
[2022-06-09 19:30:15,488][root][INFO] - Step 66012160 @ 3068.4 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 2.0978e+04, step = 66012160, mean_episode_return = 41.661, mean_episode_step = 1849.4, total_loss = 47.82, pg_loss = 33.027, baseline_loss = 29.492, entropy_loss = -14.699, learner_queue_size = 64, _tick = 10277, _time = 1.6548e+09)
[2022-06-09 19:30:20,490][root][INFO] - Step 66027520 @ 3070.7 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 2.0983e+04, step = 66027520, mean_episode_return = 28.443, mean_episode_step = 1943.8, total_loss = 8.0741, pg_loss = -20.511, baseline_loss = 43.274, entropy_loss = -14.688, learner_queue_size = 64, _tick = 10280, _time = 1.6548e+09)
[2022-06-09 19:30:25,494][root][INFO] - Step 66042880 @ 3069.6 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 2.0988e+04, step = 66042880, mean_episode_return = 16.62, mean_episode_step = 1816.1, total_loss = -13.885, pg_loss = -19.325, baseline_loss = 20.095, entropy_loss = -14.655, learner_queue_size = 64, _tick = 10283, _time = 1.6548e+09)
[2022-06-09 19:30:30,498][root][INFO] - Step 66063360 @ 4092.8 SPS. Inference batcher size: 87. Learner queue size: 64. Other stats: (train_seconds = 2.0993e+04, step = 66063360, mean_episode_return = 70.005, mean_episode_step = 1860.8, total_loss = -32.494, pg_loss = -42.734, baseline_loss = 25.049, entropy_loss = -14.808, learner_queue_size = 64, _tick = 10287, _time = 1.6548e+09)
[2022-06-09 19:30:35,502][root][INFO] - Step 66078720 @ 3069.5 SPS. Inference batcher size: 83. Learner queue size: 64. Other stats: (train_seconds = 2.0998e+04, step = 66078720, mean_episode_return = 67.366, mean_episode_step = 1749.8, total_loss = -72.808, pg_loss = -84.775, baseline_loss = 26.785, entropy_loss = -14.818, learner_queue_size = 64, _tick = 10289, _time = 1.6548e+09)
[2022-06-09 19:30:40,506][root][INFO] - Step 66094080 @ 3069.5 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 2.1003e+04, step = 66094080, mean_episode_return = 47.372, mean_episode_step = 1735.4, total_loss = -56.946, pg_loss = -68.963, baseline_loss = 26.867, entropy_loss = -14.85, learner_queue_size = 64, _tick = 10292, _time = 1.6548e+09)
[2022-06-09 19:30:45,510][root][INFO] - Step 66109440 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 2.1008e+04, step = 66109440, mean_episode_return = 18.12, mean_episode_step = 1612.8, total_loss = 444.92, pg_loss = 395.78, baseline_loss = 63.923, entropy_loss = -14.779, learner_queue_size = 64, _tick = 10295, _time = 1.6548e+09)
[2022-06-09 19:30:50,515][root][INFO] - Step 66124800 @ 3068.7 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 2.1014e+04, step = 66124800, mean_episode_return = 20.363, mean_episode_step = 1705.4, total_loss = -64.53, pg_loss = -81.056, baseline_loss = 31.312, entropy_loss = -14.786, learner_queue_size = 64, _tick = 10298, _time = 1.6548e+09)
[2022-06-09 19:30:55,518][root][INFO] - Step 66140160 @ 3070.3 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 2.1018e+04, step = 66140160, mean_episode_return = 14.29, mean_episode_step = 1438.8, total_loss = -185.67, pg_loss = -178.37, baseline_loss = 7.254, entropy_loss = -14.556, learner_queue_size = 64, _tick = 10301, _time = 1.6548e+09)
[2022-06-09 19:31:00,522][root][INFO] - Step 66155520 @ 3069.6 SPS. Inference batcher size: 18. Learner queue size: 64. Other stats: (train_seconds = 2.1024e+04, step = 66155520, mean_episode_return = 35.63, mean_episode_step = 2004.1, total_loss = -32.991, pg_loss = -50.465, baseline_loss = 32.014, entropy_loss = -14.539, learner_queue_size = 64, _tick = 10304, _time = 1.6548e+09)
[2022-06-09 19:31:05,526][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 19:31:05,785][root][INFO] - Step 66170880 @ 3069.6 SPS. Inference batcher size: 5. Learner queue size: 64. Other stats: (train_seconds = 2.1028e+04, step = 66170880, mean_episode_return = 48.141, mean_episode_step = 1542.4, total_loss = 29.716, pg_loss = 8.9224, baseline_loss = 35.503, entropy_loss = -14.709, learner_queue_size = 64, _tick = 10307, _time = 1.6548e+09)
[2022-06-09 19:31:10,790][root][INFO] - Step 66186240 @ 2917.9 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 2.1034e+04, step = 66186240, mean_episode_return = 11.4, mean_episode_step = 1727.5, total_loss = -189.78, pg_loss = -205.77, baseline_loss = 30.765, entropy_loss = -14.776, learner_queue_size = 64, _tick = 10310, _time = 1.6548e+09)
[2022-06-09 19:31:15,794][root][INFO] - Step 66201600 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 2.1039e+04, step = 66201600, mean_episode_return = -2.03, mean_episode_step = 1709.8, total_loss = 177.56, pg_loss = 148.39, baseline_loss = 43.991, entropy_loss = -14.824, learner_queue_size = 64, _tick = 10312, _time = 1.6548e+09)
[2022-06-09 19:31:20,798][root][INFO] - Step 66216960 @ 3069.5 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 2.1044e+04, step = 66216960, mean_episode_return = 14.35, mean_episode_step = 1757.6, total_loss = -100.18, pg_loss = -102.71, baseline_loss = 17.152, entropy_loss = -14.629, learner_queue_size = 64, _tick = 10315, _time = 1.6548e+09)
[2022-06-09 19:31:25,802][root][INFO] - Step 66237440 @ 4092.8 SPS. Inference batcher size: 112. Learner queue size: 64. Other stats: (train_seconds = 2.1049e+04, step = 66237440, mean_episode_return = 64.25, mean_episode_step = 1718.5, total_loss = -90.416, pg_loss = -96.687, baseline_loss = 21.283, entropy_loss = -15.012, learner_queue_size = 64, _tick = 10319, _time = 1.6548e+09)
[2022-06-09 19:31:30,806][root][INFO] - Step 66252800 @ 3069.6 SPS. Inference batcher size: 71. Learner queue size: 64. Other stats: (train_seconds = 2.1054e+04, step = 66252800, mean_episode_return = 49.312, mean_episode_step = 1814.9, total_loss = -10.874, pg_loss = -30.7, baseline_loss = 34.831, entropy_loss = -15.005, learner_queue_size = 64, _tick = 10322, _time = 1.6548e+09)
[2022-06-09 19:31:35,812][root][INFO] - Step 66268160 @ 3068.3 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 2.1059e+04, step = 66268160, mean_episode_return = 40.94, mean_episode_step = 1563.0, total_loss = 102.37, pg_loss = 63.37, baseline_loss = 53.972, entropy_loss = -14.977, learner_queue_size = 64, _tick = 10325, _time = 1.6548e+09)
[2022-06-09 19:31:40,818][root][INFO] - Step 66283520 @ 3068.4 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 2.1064e+04, step = 66283520, mean_episode_return = 102.8, mean_episode_step = 1945.5, total_loss = -25.897, pg_loss = -26.134, baseline_loss = 15.15, entropy_loss = -14.914, learner_queue_size = 64, _tick = 10328, _time = 1.6548e+09)
[2022-06-09 19:31:45,822][root][INFO] - Step 66298880 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 2.1069e+04, step = 66298880, mean_episode_return = None, mean_episode_step = 1710.5, total_loss = 105.18, pg_loss = 94.881, baseline_loss = 25.196, entropy_loss = -14.897, learner_queue_size = 64, _tick = 10329, _time = 1.6548e+09)
[2022-06-09 19:31:50,826][root][INFO] - Step 66314240 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 2.1074e+04, step = 66314240, mean_episode_return = 38.26, mean_episode_step = 1526.0, total_loss = 551.88, pg_loss = 478.35, baseline_loss = 88.214, entropy_loss = -14.685, learner_queue_size = 64, _tick = 10332, _time = 1.6548e+09)
[2022-06-09 19:31:55,830][root][INFO] - Step 66329600 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 2.1079e+04, step = 66329600, mean_episode_return = 61.391, mean_episode_step = 1820.2, total_loss = 54.836, pg_loss = 42.13, baseline_loss = 27.25, entropy_loss = -14.544, learner_queue_size = 64, _tick = 10335, _time = 1.6548e+09)
[2022-06-09 19:32:00,834][root][INFO] - Step 66344960 @ 3069.3 SPS. Inference batcher size: 7. Learner queue size: 64. Other stats: (train_seconds = 2.1084e+04, step = 66344960, mean_episode_return = 30.28, mean_episode_step = 1630.8, total_loss = 469.98, pg_loss = 374.75, baseline_loss = 109.96, entropy_loss = -14.723, learner_queue_size = 64, _tick = 10338, _time = 1.6548e+09)
[2022-06-09 19:32:05,838][root][INFO] - Step 66360320 @ 3069.8 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 2.1089e+04, step = 66360320, mean_episode_return = 64.496, mean_episode_step = 1576.6, total_loss = -109.05, pg_loss = -123.42, baseline_loss = 29.113, entropy_loss = -14.744, learner_queue_size = 64, _tick = 10341, _time = 1.6548e+09)
[2022-06-09 19:32:10,842][root][INFO] - Step 66375680 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 2.1094e+04, step = 66375680, mean_episode_return = 1.2065, mean_episode_step = 1587.3, total_loss = -64.842, pg_loss = -76.494, baseline_loss = 26.257, entropy_loss = -14.605, learner_queue_size = 64, _tick = 10344, _time = 1.6548e+09)
[2022-06-09 19:32:15,846][root][INFO] - Step 66391040 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 2.1099e+04, step = 66391040, mean_episode_return = 59.651, mean_episode_step = 1865.9, total_loss = 165.92, pg_loss = 142.32, baseline_loss = 38.193, entropy_loss = -14.595, learner_queue_size = 64, _tick = 10347, _time = 1.6548e+09)
[2022-06-09 19:32:20,850][root][INFO] - Step 66406400 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 2.1104e+04, step = 66406400, mean_episode_return = 44.2, mean_episode_step = 1571.9, total_loss = 3.2813, pg_loss = -18.991, baseline_loss = 36.831, entropy_loss = -14.559, learner_queue_size = 64, _tick = 10350, _time = 1.6548e+09)
[2022-06-09 19:32:25,854][root][INFO] - Step 66421760 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 2.1109e+04, step = 66421760, mean_episode_return = None, mean_episode_step = 1843.5, total_loss = 282.16, pg_loss = 254.48, baseline_loss = 42.468, entropy_loss = -14.782, learner_queue_size = 64, _tick = 10351, _time = 1.6548e+09)
[2022-06-09 19:32:30,858][root][INFO] - Step 66442240 @ 4092.8 SPS. Inference batcher size: 68. Learner queue size: 64. Other stats: (train_seconds = 2.1114e+04, step = 66442240, mean_episode_return = 40.042, mean_episode_step = 1797.7, total_loss = -92.828, pg_loss = -96.954, baseline_loss = 18.836, entropy_loss = -14.711, learner_queue_size = 64, _tick = 10355, _time = 1.6548e+09)
[2022-06-09 19:32:35,862][root][INFO] - Step 66457600 @ 3069.5 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 2.1119e+04, step = 66457600, mean_episode_return = 43.343, mean_episode_step = 1671.8, total_loss = 222.1, pg_loss = 178.32, baseline_loss = 58.587, entropy_loss = -14.804, learner_queue_size = 64, _tick = 10358, _time = 1.6548e+09)
[2022-06-09 19:32:40,866][root][INFO] - Step 66472960 @ 3069.6 SPS. Inference batcher size: 18. Learner queue size: 64. Other stats: (train_seconds = 2.1124e+04, step = 66472960, mean_episode_return = 103.47, mean_episode_step = 1660.7, total_loss = 59.225, pg_loss = 48.562, baseline_loss = 25.382, entropy_loss = -14.719, learner_queue_size = 64, _tick = 10361, _time = 1.6548e+09)
[2022-06-09 19:32:45,870][root][INFO] - Step 66488320 @ 3069.5 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 2.1129e+04, step = 66488320, mean_episode_return = 55.31, mean_episode_step = 1997.0, total_loss = -13.992, pg_loss = -34.918, baseline_loss = 35.679, entropy_loss = -14.753, learner_queue_size = 64, _tick = 10363, _time = 1.6548e+09)
[2022-06-09 19:32:50,874][root][INFO] - Step 66503680 @ 3069.6 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 2.1134e+04, step = 66503680, mean_episode_return = 29.835, mean_episode_step = 2020.1, total_loss = -212.2, pg_loss = -215.46, baseline_loss = 18.094, entropy_loss = -14.843, learner_queue_size = 64, _tick = 10366, _time = 1.6548e+09)
[2022-06-09 19:32:55,878][root][INFO] - Step 66519040 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 2.1139e+04, step = 66519040, mean_episode_return = 47.732, mean_episode_step = 1796.1, total_loss = 155.19, pg_loss = 123.43, baseline_loss = 46.607, entropy_loss = -14.84, learner_queue_size = 64, _tick = 10369, _time = 1.6548e+09)
[2022-06-09 19:33:00,882][root][INFO] - Step 66534400 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 2.1144e+04, step = 66534400, mean_episode_return = 137.49, mean_episode_step = 1708.8, total_loss = 90.287, pg_loss = 59.386, baseline_loss = 45.635, entropy_loss = -14.734, learner_queue_size = 64, _tick = 10371, _time = 1.6548e+09)
[2022-06-09 19:33:05,886][root][INFO] - Step 66549760 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 2.1149e+04, step = 66549760, mean_episode_return = 67.585, mean_episode_step = 1685.4, total_loss = -87.594, pg_loss = -113.89, baseline_loss = 41.046, entropy_loss = -14.752, learner_queue_size = 64, _tick = 10374, _time = 1.6548e+09)
[2022-06-09 19:33:10,890][root][INFO] - Step 66560000 @ 2046.4 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 2.1154e+04, step = 66560000, mean_episode_return = 44.57, mean_episode_step = 1572.4, total_loss = 26.914, pg_loss = 8.6794, baseline_loss = 32.863, entropy_loss = -14.629, learner_queue_size = 64, _tick = 10376, _time = 1.6548e+09)
[2022-06-09 19:33:15,894][root][INFO] - Step 66575360 @ 3069.5 SPS. Inference batcher size: 72. Learner queue size: 64. Other stats: (train_seconds = 2.1159e+04, step = 66575360, mean_episode_return = 46.809, mean_episode_step = 1659.3, total_loss = -7.4482, pg_loss = -70.984, baseline_loss = 77.941, entropy_loss = -14.406, learner_queue_size = 64, _tick = 10379, _time = 1.6548e+09)
[2022-06-09 19:33:20,898][root][INFO] - Step 66590720 @ 3069.5 SPS. Inference batcher size: 101. Learner queue size: 64. Other stats: (train_seconds = 2.1164e+04, step = 66590720, mean_episode_return = 15.213, mean_episode_step = 1845.2, total_loss = 44.461, pg_loss = 22.383, baseline_loss = 36.433, entropy_loss = -14.355, learner_queue_size = 64, _tick = 10381, _time = 1.6548e+09)
[2022-06-09 19:33:25,902][root][INFO] - Step 66606080 @ 3069.5 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 2.1169e+04, step = 66606080, mean_episode_return = 11.799, mean_episode_step = 1732.0, total_loss = 212.47, pg_loss = 178.86, baseline_loss = 47.798, entropy_loss = -14.186, learner_queue_size = 64, _tick = 10384, _time = 1.6548e+09)
[2022-06-09 19:33:30,910][root][INFO] - Step 66621440 @ 3067.0 SPS. Inference batcher size: 94. Learner queue size: 64. Other stats: (train_seconds = 2.1174e+04, step = 66621440, mean_episode_return = 34.781, mean_episode_step = 1756.8, total_loss = 156.15, pg_loss = 122.16, baseline_loss = 48.05, entropy_loss = -14.061, learner_queue_size = 64, _tick = 10387, _time = 1.6548e+09)
[2022-06-09 19:33:35,914][root][INFO] - Step 66631680 @ 2046.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 2.1179e+04, step = 66631680, mean_episode_return = 50.793, mean_episode_step = 1617.6, total_loss = 17.762, pg_loss = 6.1857, baseline_loss = 25.569, entropy_loss = -13.994, learner_queue_size = 64, _tick = 10389, _time = 1.6548e+09)
[2022-06-09 19:33:40,918][root][INFO] - Step 66647040 @ 3069.6 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 2.1184e+04, step = 66647040, mean_episode_return = 59.796, mean_episode_step = 1645.7, total_loss = -30.045, pg_loss = -65.533, baseline_loss = 49.485, entropy_loss = -13.998, learner_queue_size = 64, _tick = 10391, _time = 1.6548e+09)
[2022-06-09 19:33:45,922][root][INFO] - Step 66662400 @ 3069.5 SPS. Inference batcher size: 75. Learner queue size: 64. Other stats: (train_seconds = 2.1189e+04, step = 66662400, mean_episode_return = 75.318, mean_episode_step = 1757.3, total_loss = -75.284, pg_loss = -84.201, baseline_loss = 22.85, entropy_loss = -13.932, learner_queue_size = 64, _tick = 10394, _time = 1.6548e+09)
[2022-06-09 19:33:50,926][root][INFO] - Step 66677760 @ 3069.3 SPS. Inference batcher size: 82. Learner queue size: 64. Other stats: (train_seconds = 2.1194e+04, step = 66677760, mean_episode_return = None, mean_episode_step = 1957.3, total_loss = 3.3283, pg_loss = -12.267, baseline_loss = 29.574, entropy_loss = -13.979, learner_queue_size = 64, _tick = 10395, _time = 1.6548e+09)
[2022-06-09 19:33:55,930][root][INFO] - Step 66693120 @ 3069.8 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 2.1199e+04, step = 66693120, mean_episode_return = 70.365, mean_episode_step = 1870.6, total_loss = 216.45, pg_loss = 154.65, baseline_loss = 75.6, entropy_loss = -13.795, learner_queue_size = 64, _tick = 10398, _time = 1.6548e+09)
[2022-06-09 19:34:00,935][root][INFO] - Step 66703360 @ 2046.0 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 2.1204e+04, step = 66703360, mean_episode_return = 58.263, mean_episode_step = 1763.6, total_loss = -177.95, pg_loss = -191.62, baseline_loss = 27.469, entropy_loss = -13.797, learner_queue_size = 64, _tick = 10399, _time = 1.6548e+09)
[2022-06-09 19:34:05,942][root][INFO] - Step 66718720 @ 3067.6 SPS. Inference batcher size: 72. Learner queue size: 64. Other stats: (train_seconds = 2.1209e+04, step = 66718720, mean_episode_return = 125.51, mean_episode_step = 1708.5, total_loss = -72.152, pg_loss = -85.894, baseline_loss = 27.57, entropy_loss = -13.827, learner_queue_size = 64, _tick = 10401, _time = 1.6548e+09)
[2022-06-09 19:34:10,946][root][INFO] - Step 66734080 @ 3069.6 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 2.1214e+04, step = 66734080, mean_episode_return = 152.45, mean_episode_step = 1915.2, total_loss = -183.83, pg_loss = -185.03, baseline_loss = 15.133, entropy_loss = -13.924, learner_queue_size = 64, _tick = 10404, _time = 1.6548e+09)
[2022-06-09 19:34:15,950][root][INFO] - Step 66749440 @ 3069.5 SPS. Inference batcher size: 88. Learner queue size: 64. Other stats: (train_seconds = 2.1219e+04, step = 66749440, mean_episode_return = None, mean_episode_step = 1858.2, total_loss = -85.398, pg_loss = -84.879, baseline_loss = 13.508, entropy_loss = -14.026, learner_queue_size = 64, _tick = 10406, _time = 1.6548e+09)
[2022-06-09 19:34:20,954][root][INFO] - Step 66759680 @ 2046.4 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 2.1224e+04, step = 66759680, mean_episode_return = None, mean_episode_step = 1860.7, total_loss = -220.06, pg_loss = -215.74, baseline_loss = 9.8061, entropy_loss = -14.12, learner_queue_size = 64, _tick = 10407, _time = 1.6548e+09)
[2022-06-09 19:34:25,960][root][INFO] - Step 66775040 @ 3068.4 SPS. Inference batcher size: 67. Learner queue size: 64. Other stats: (train_seconds = 2.1229e+04, step = 66775040, mean_episode_return = None, mean_episode_step = 1888.2, total_loss = 302.55, pg_loss = 258.25, baseline_loss = 58.383, entropy_loss = -14.079, learner_queue_size = 64, _tick = 10408, _time = 1.6548e+09)
[2022-06-09 19:34:30,962][root][INFO] - Step 66790400 @ 3070.6 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 2.1234e+04, step = 66790400, mean_episode_return = 53.902, mean_episode_step = 1909.1, total_loss = -72.169, pg_loss = -87.698, baseline_loss = 29.552, entropy_loss = -14.024, learner_queue_size = 64, _tick = 10411, _time = 1.6548e+09)
[2022-06-09 19:34:35,969][root][INFO] - Step 66805760 @ 3067.7 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 2.1239e+04, step = 66805760, mean_episode_return = None, mean_episode_step = 2065.0, total_loss = -52.348, pg_loss = -59.183, baseline_loss = 21.017, entropy_loss = -14.182, learner_queue_size = 64, _tick = 10412, _time = 1.6548e+09)
[2022-06-09 19:34:40,974][root][INFO] - Step 66821120 @ 3068.9 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 2.1244e+04, step = 66821120, mean_episode_return = 20.42, mean_episode_step = 1733.8, total_loss = 150.93, pg_loss = 116.25, baseline_loss = 48.829, entropy_loss = -14.155, learner_queue_size = 64, _tick = 10415, _time = 1.6548e+09)
[2022-06-09 19:34:45,978][root][INFO] - Step 66831360 @ 2046.4 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 2.1249e+04, step = 66831360, mean_episode_return = None, mean_episode_step = 1673.6, total_loss = -81.515, pg_loss = -83.877, baseline_loss = 16.544, entropy_loss = -14.182, learner_queue_size = 64, _tick = 10416, _time = 1.6548e+09)
[2022-06-09 19:34:50,982][root][INFO] - Step 66846720 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 2.1254e+04, step = 66846720, mean_episode_return = None, mean_episode_step = 2046.4, total_loss = 90.466, pg_loss = 60.108, baseline_loss = 44.501, entropy_loss = -14.142, learner_queue_size = 64, _tick = 10418, _time = 1.6548e+09)
[2022-06-09 19:34:55,986][root][INFO] - Step 66862080 @ 3069.6 SPS. Inference batcher size: 72. Learner queue size: 64. Other stats: (train_seconds = 2.1259e+04, step = 66862080, mean_episode_return = 61.939, mean_episode_step = 2043.9, total_loss = 64.474, pg_loss = 39.213, baseline_loss = 39.418, entropy_loss = -14.156, learner_queue_size = 64, _tick = 10420, _time = 1.6548e+09)
[2022-06-09 19:35:00,990][root][INFO] - Step 66877440 @ 3069.5 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 2.1264e+04, step = 66877440, mean_episode_return = 16.33, mean_episode_step = 1912.7, total_loss = -165.17, pg_loss = -168.36, baseline_loss = 17.155, entropy_loss = -13.97, learner_queue_size = 64, _tick = 10422, _time = 1.6548e+09)
[2022-06-09 19:35:05,994][root][INFO] - Step 66887680 @ 2046.3 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 2.1269e+04, step = 66887680, mean_episode_return = 93.36, mean_episode_step = 2059.7, total_loss = 164.1, pg_loss = 151.78, baseline_loss = 26.403, entropy_loss = -14.084, learner_queue_size = 64, _tick = 10424, _time = 1.6548e+09)
[2022-06-09 19:35:10,998][root][INFO] - Step 66903040 @ 3069.6 SPS. Inference batcher size: 2. Learner queue size: 64. Other stats: (train_seconds = 2.1274e+04, step = 66903040, mean_episode_return = -0.25047, mean_episode_step = 1757.1, total_loss = 41.788, pg_loss = 17.011, baseline_loss = 38.988, entropy_loss = -14.211, learner_queue_size = 64, _tick = 10427, _time = 1.6548e+09)
[2022-06-09 19:35:16,007][root][INFO] - Step 66918400 @ 3066.6 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 2.1279e+04, step = 66918400, mean_episode_return = None, mean_episode_step = 2186.2, total_loss = -214.51, pg_loss = -207.86, baseline_loss = 7.6439, entropy_loss = -14.286, learner_queue_size = 64, _tick = 10429, _time = 1.6548e+09)
[2022-06-09 19:35:21,014][root][INFO] - Step 66933760 @ 3067.6 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 2.1284e+04, step = 66933760, mean_episode_return = 31.36, mean_episode_step = 2117.5, total_loss = -59.625, pg_loss = -76.833, baseline_loss = 31.472, entropy_loss = -14.265, learner_queue_size = 64, _tick = 10432, _time = 1.6548e+09)
[2022-06-09 19:35:26,018][root][INFO] - Step 66949120 @ 3069.5 SPS. Inference batcher size: 12. Learner queue size: 64. Other stats: (train_seconds = 2.1289e+04, step = 66949120, mean_episode_return = 23.527, mean_episode_step = 1845.1, total_loss = -87.383, pg_loss = -100.41, baseline_loss = 27.364, entropy_loss = -14.342, learner_queue_size = 64, _tick = 10435, _time = 1.6548e+09)
[2022-06-09 19:35:31,022][root][INFO] - Step 66964480 @ 3069.5 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 2.1294e+04, step = 66964480, mean_episode_return = 50.634, mean_episode_step = 1989.7, total_loss = 400.38, pg_loss = 317.76, baseline_loss = 97.038, entropy_loss = -14.419, learner_queue_size = 64, _tick = 10438, _time = 1.6548e+09)
[2022-06-09 19:35:36,026][root][INFO] - Step 66979840 @ 3069.6 SPS. Inference batcher size: 37. Learner queue size: 26. Other stats: (train_seconds = 2.1299e+04, step = 66979840, mean_episode_return = 49.929, mean_episode_step = 2126.3, total_loss = -58.309, pg_loss = -75.025, baseline_loss = 31.224, entropy_loss = -14.508, learner_queue_size = 64, _tick = 10441, _time = 1.6548e+09)
[2022-06-09 19:35:41,030][root][INFO] - Step 66990080 @ 2046.3 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 2.1304e+04, step = 66990080, mean_episode_return = 34.718, mean_episode_step = 2158.4, total_loss = -31.332, pg_loss = -58.317, baseline_loss = 41.527, entropy_loss = -14.542, learner_queue_size = 64, _tick = 10442, _time = 1.6548e+09)
[2022-06-09 19:35:46,034][root][INFO] - Step 67005440 @ 3069.6 SPS. Inference batcher size: 7. Learner queue size: 64. Other stats: (train_seconds = 2.1309e+04, step = 67005440, mean_episode_return = 68.021, mean_episode_step = 1698.2, total_loss = -26.412, pg_loss = -40.878, baseline_loss = 29.24, entropy_loss = -14.775, learner_queue_size = 64, _tick = 10445, _time = 1.6548e+09)
[2022-06-09 19:35:51,038][root][INFO] - Step 67020800 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 2.1314e+04, step = 67020800, mean_episode_return = 45.015, mean_episode_step = 1864.5, total_loss = -11.978, pg_loss = -25.406, baseline_loss = 28.36, entropy_loss = -14.931, learner_queue_size = 64, _tick = 10447, _time = 1.6548e+09)
[2022-06-09 19:35:56,042][root][INFO] - Step 67036160 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 2.1319e+04, step = 67036160, mean_episode_return = -11.396, mean_episode_step = 1804.1, total_loss = 242.04, pg_loss = 179.26, baseline_loss = 77.618, entropy_loss = -14.836, learner_queue_size = 64, _tick = 10450, _time = 1.6548e+09)
[2022-06-09 19:36:01,046][root][INFO] - Step 67051520 @ 3069.7 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 2.1324e+04, step = 67051520, mean_episode_return = 67.479, mean_episode_step = 1850.4, total_loss = -81.189, pg_loss = -94.373, baseline_loss = 28.044, entropy_loss = -14.861, learner_queue_size = 64, _tick = 10453, _time = 1.6548e+09)
[2022-06-09 19:36:06,050][root][INFO] - Step 67061760 @ 2046.4 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 2.1329e+04, step = 67061760, mean_episode_return = 31.872, mean_episode_step = 1885.6, total_loss = 196.2, pg_loss = 174.5, baseline_loss = 36.637, entropy_loss = -14.931, learner_queue_size = 64, _tick = 10455, _time = 1.6548e+09)
[2022-06-09 19:36:11,054][root][INFO] - Step 67077120 @ 3069.4 SPS. Inference batcher size: 10. Learner queue size: 64. Other stats: (train_seconds = 2.1334e+04, step = 67077120, mean_episode_return = 44.701, mean_episode_step = 1742.7, total_loss = 627.75, pg_loss = 549.6, baseline_loss = 92.998, entropy_loss = -14.851, learner_queue_size = 64, _tick = 10458, _time = 1.6548e+09)
[2022-06-09 19:36:16,062][root][INFO] - Step 67092480 @ 3067.2 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 2.1339e+04, step = 67092480, mean_episode_return = -1.2103, mean_episode_step = 1775.7, total_loss = -16.579, pg_loss = -23.514, baseline_loss = 21.883, entropy_loss = -14.949, learner_queue_size = 64, _tick = 10460, _time = 1.6548e+09)
[2022-06-09 19:36:21,066][root][INFO] - Step 67107840 @ 3069.5 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 2.1344e+04, step = 67107840, mean_episode_return = -42.339, mean_episode_step = 1912.4, total_loss = -4.4827, pg_loss = -19.264, baseline_loss = 29.575, entropy_loss = -14.793, learner_queue_size = 64, _tick = 10463, _time = 1.6548e+09)
[2022-06-09 19:36:26,070][root][INFO] - Step 67123200 @ 3069.6 SPS. Inference batcher size: 7. Learner queue size: 64. Other stats: (train_seconds = 2.1349e+04, step = 67123200, mean_episode_return = nan, mean_episode_step = 1782.6, total_loss = 20.209, pg_loss = -8.532, baseline_loss = 43.538, entropy_loss = -14.797, learner_queue_size = 64, _tick = 10465, _time = 1.6548e+09)
[2022-06-09 19:36:31,074][root][INFO] - Step 67133440 @ 2046.3 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 2.1354e+04, step = 67133440, mean_episode_return = 99.874, mean_episode_step = 2040.0, total_loss = 86.656, pg_loss = 67.553, baseline_loss = 33.859, entropy_loss = -14.757, learner_queue_size = 64, _tick = 10467, _time = 1.6548e+09)
[2022-06-09 19:36:36,078][root][INFO] - Step 67148800 @ 3069.4 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 2.1359e+04, step = 67148800, mean_episode_return = 61.79, mean_episode_step = 1932.1, total_loss = -324.72, pg_loss = -320.36, baseline_loss = 10.358, entropy_loss = -14.726, learner_queue_size = 64, _tick = 10469, _time = 1.6548e+09)
[2022-06-09 19:36:41,082][root][INFO] - Step 67164160 @ 3069.6 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 2.1364e+04, step = 67164160, mean_episode_return = 64.961, mean_episode_step = 1961.3, total_loss = 457.1, pg_loss = 305.49, baseline_loss = 166.26, entropy_loss = -14.658, learner_queue_size = 64, _tick = 10470, _time = 1.6548e+09)
[2022-06-09 19:36:46,086][root][INFO] - Step 67179520 @ 3069.6 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 2.1369e+04, step = 67179520, mean_episode_return = 41.776, mean_episode_step = 1852.2, total_loss = -10.961, pg_loss = -31.139, baseline_loss = 34.802, entropy_loss = -14.625, learner_queue_size = 64, _tick = 10473, _time = 1.6548e+09)
[2022-06-09 19:36:51,090][root][INFO] - Step 67189760 @ 2046.3 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 2.1374e+04, step = 67189760, mean_episode_return = None, mean_episode_step = 1988.3, total_loss = -89.664, pg_loss = -88.899, baseline_loss = 13.957, entropy_loss = -14.722, learner_queue_size = 64, _tick = 10474, _time = 1.6548e+09)
[2022-06-09 19:36:56,094][root][INFO] - Step 67205120 @ 3069.6 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 2.1379e+04, step = 67205120, mean_episode_return = 31.547, mean_episode_step = 1828.2, total_loss = 371.52, pg_loss = 308.93, baseline_loss = 77.328, entropy_loss = -14.743, learner_queue_size = 64, _tick = 10477, _time = 1.6548e+09)
[2022-06-09 19:37:01,098][root][INFO] - Step 67220480 @ 3069.6 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 2.1384e+04, step = 67220480, mean_episode_return = 16.05, mean_episode_step = 1800.7, total_loss = 192.31, pg_loss = 126.62, baseline_loss = 80.381, entropy_loss = -14.693, learner_queue_size = 64, _tick = 10480, _time = 1.6548e+09)
[2022-06-09 19:37:06,102][root][INFO] - Step 67235840 @ 3069.5 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 2.1389e+04, step = 67235840, mean_episode_return = None, mean_episode_step = 1778.7, total_loss = 13.14, pg_loss = 2.6442, baseline_loss = 25.126, entropy_loss = -14.631, learner_queue_size = 64, _tick = 10482, _time = 1.6548e+09)
[2022-06-09 19:37:11,108][root][INFO] - Step 67251200 @ 3068.3 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 2.1394e+04, step = 67251200, mean_episode_return = 17.45, mean_episode_step = 1751.2, total_loss = 572.21, pg_loss = 388.16, baseline_loss = 198.59, entropy_loss = -14.527, learner_queue_size = 64, _tick = 10485, _time = 1.6548e+09)
[2022-06-09 19:37:16,114][root][INFO] - Step 67261440 @ 2045.5 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 2.1399e+04, step = 67261440, mean_episode_return = 55.504, mean_episode_step = 1768.1, total_loss = 75.631, pg_loss = 58.946, baseline_loss = 31.189, entropy_loss = -14.504, learner_queue_size = 64, _tick = 10487, _time = 1.6548e+09)
[2022-06-09 19:37:21,118][root][INFO] - Step 67276800 @ 3069.6 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 2.1404e+04, step = 67276800, mean_episode_return = None, mean_episode_step = 2134.4, total_loss = -48.692, pg_loss = -49.289, baseline_loss = 14.896, entropy_loss = -14.299, learner_queue_size = 64, _tick = 10489, _time = 1.6548e+09)
[2022-06-09 19:37:26,122][root][INFO] - Step 67292160 @ 3069.6 SPS. Inference batcher size: 11. Learner queue size: 64. Other stats: (train_seconds = 2.1409e+04, step = 67292160, mean_episode_return = 65.079, mean_episode_step = 1753.7, total_loss = 165.61, pg_loss = 111.81, baseline_loss = 68.283, entropy_loss = -14.483, learner_queue_size = 64, _tick = 10491, _time = 1.6548e+09)
[2022-06-09 19:37:31,126][root][INFO] - Step 67307520 @ 3069.5 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 2.1414e+04, step = 67307520, mean_episode_return = 50.667, mean_episode_step = 1877.5, total_loss = 29.369, pg_loss = 3.1292, baseline_loss = 40.675, entropy_loss = -14.436, learner_queue_size = 64, _tick = 10494, _time = 1.6548e+09)
[2022-06-09 19:37:36,130][root][INFO] - Step 67322880 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 2.1419e+04, step = 67322880, mean_episode_return = 77.456, mean_episode_step = 2043.3, total_loss = -27.466, pg_loss = -51.133, baseline_loss = 38.176, entropy_loss = -14.51, learner_queue_size = 64, _tick = 10497, _time = 1.6548e+09)
[2022-06-09 19:37:41,132][root][INFO] - Step 67333120 @ 2047.3 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 2.1424e+04, step = 67333120, mean_episode_return = 5.0497, mean_episode_step = 1684.6, total_loss = -42.507, pg_loss = -48.962, baseline_loss = 20.802, entropy_loss = -14.347, learner_queue_size = 64, _tick = 10499, _time = 1.6548e+09)
[2022-06-09 19:37:46,134][root][INFO] - Step 67348480 @ 3070.6 SPS. Inference batcher size: 2. Learner queue size: 64. Other stats: (train_seconds = 2.1429e+04, step = 67348480, mean_episode_return = None, mean_episode_step = 1581.9, total_loss = 76.276, pg_loss = 61.831, baseline_loss = 28.967, entropy_loss = -14.522, learner_queue_size = 64, _tick = 10500, _time = 1.6548e+09)
[2022-06-09 19:37:51,138][root][INFO] - Step 67363840 @ 3069.5 SPS. Inference batcher size: 79. Learner queue size: 64. Other stats: (train_seconds = 2.1434e+04, step = 67363840, mean_episode_return = 46.67, mean_episode_step = 2075.1, total_loss = -95.621, pg_loss = -114.22, baseline_loss = 32.938, entropy_loss = -14.339, learner_queue_size = 64, _tick = 10501, _time = 1.6548e+09)
[2022-06-09 19:37:56,142][root][INFO] - Step 67379200 @ 3069.6 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 2.1439e+04, step = 67379200, mean_episode_return = 42.164, mean_episode_step = 1533.0, total_loss = -135.33, pg_loss = -151.78, baseline_loss = 30.835, entropy_loss = -14.386, learner_queue_size = 64, _tick = 10504, _time = 1.6548e+09)
[2022-06-09 19:38:01,146][root][INFO] - Step 67394560 @ 3069.5 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 2.1444e+04, step = 67394560, mean_episode_return = None, mean_episode_step = 2021.2, total_loss = -188.97, pg_loss = -186.21, baseline_loss = 11.548, entropy_loss = -14.304, learner_queue_size = 64, _tick = 10504, _time = 1.6548e+09)
[2022-06-09 19:38:06,150][root][INFO] - Step 67404800 @ 2046.4 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 2.1449e+04, step = 67404800, mean_episode_return = None, mean_episode_step = 1867.8, total_loss = -48.686, pg_loss = -47.885, baseline_loss = 13.547, entropy_loss = -14.349, learner_queue_size = 64, _tick = 10505, _time = 1.6548e+09)
[2022-06-09 19:38:11,154][root][INFO] - Step 67420160 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 2.1454e+04, step = 67420160, mean_episode_return = 114.61, mean_episode_step = 1867.5, total_loss = -18.838, pg_loss = -35.764, baseline_loss = 31.395, entropy_loss = -14.469, learner_queue_size = 64, _tick = 10507, _time = 1.6548e+09)
[2022-06-09 19:38:16,161][root][INFO] - Step 67435520 @ 3067.6 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 2.1459e+04, step = 67435520, mean_episode_return = 1.0646, mean_episode_step = 2177.2, total_loss = -196.74, pg_loss = -200.88, baseline_loss = 18.6, entropy_loss = -14.458, learner_queue_size = 64, _tick = 10510, _time = 1.6548e+09)
[2022-06-09 19:38:21,166][root][INFO] - Step 67450880 @ 3069.0 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 2.1464e+04, step = 67450880, mean_episode_return = 48.132, mean_episode_step = 1766.4, total_loss = 377.38, pg_loss = 303.74, baseline_loss = 88.149, entropy_loss = -14.505, learner_queue_size = 64, _tick = 10513, _time = 1.6548e+09)
[2022-06-09 19:38:26,170][root][INFO] - Step 67461120 @ 2046.3 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 2.1469e+04, step = 67461120, mean_episode_return = 32.278, mean_episode_step = 1622.3, total_loss = -9.9483, pg_loss = -44.562, baseline_loss = 49.092, entropy_loss = -14.478, learner_queue_size = 64, _tick = 10515, _time = 1.6548e+09)
[2022-06-09 19:38:31,174][root][INFO] - Step 67476480 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 2.1474e+04, step = 67476480, mean_episode_return = 61.609, mean_episode_step = 1925.0, total_loss = 146.04, pg_loss = 100.38, baseline_loss = 60.113, entropy_loss = -14.449, learner_queue_size = 64, _tick = 10518, _time = 1.6548e+09)
[2022-06-09 19:38:36,178][root][INFO] - Step 67491840 @ 3069.6 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 2.1479e+04, step = 67491840, mean_episode_return = 62.643, mean_episode_step = 1911.7, total_loss = -263.53, pg_loss = -277.29, baseline_loss = 28.193, entropy_loss = -14.436, learner_queue_size = 64, _tick = 10521, _time = 1.6548e+09)
[2022-06-09 19:38:41,182][root][INFO] - Step 67507200 @ 3069.6 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 2.1484e+04, step = 67507200, mean_episode_return = None, mean_episode_step = 1824.0, total_loss = -30.319, pg_loss = -34.222, baseline_loss = 18.271, entropy_loss = -14.367, learner_queue_size = 64, _tick = 10523, _time = 1.6548e+09)
[2022-06-09 19:38:46,186][root][INFO] - Step 67517440 @ 2046.4 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 2.1489e+04, step = 67517440, mean_episode_return = None, mean_episode_step = 1964.2, total_loss = -170.84, pg_loss = -160.17, baseline_loss = 3.7619, entropy_loss = -14.436, learner_queue_size = 64, _tick = 10524, _time = 1.6548e+09)
[2022-06-09 19:38:51,190][root][INFO] - Step 67532800 @ 3069.5 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 2.1494e+04, step = 67532800, mean_episode_return = 62.378, mean_episode_step = 2040.9, total_loss = 84.332, pg_loss = 54.585, baseline_loss = 44.077, entropy_loss = -14.331, learner_queue_size = 64, _tick = 10527, _time = 1.6548e+09)
[2022-06-09 19:38:56,194][root][INFO] - Step 67548160 @ 3069.5 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 2.1499e+04, step = 67548160, mean_episode_return = None, mean_episode_step = 1958.5, total_loss = 114.86, pg_loss = 99.108, baseline_loss = 30.136, entropy_loss = -14.381, learner_queue_size = 64, _tick = 10528, _time = 1.6548e+09)
[2022-06-09 19:39:01,200][root][INFO] - Step 67563520 @ 3068.5 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 2.1504e+04, step = 67563520, mean_episode_return = 20.657, mean_episode_step = 1808.1, total_loss = -201.88, pg_loss = -205.86, baseline_loss = 18.244, entropy_loss = -14.259, learner_queue_size = 64, _tick = 10530, _time = 1.6548e+09)
[2022-06-09 19:39:06,202][root][INFO] - Step 67578880 @ 3070.3 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 2.1509e+04, step = 67578880, mean_episode_return = 145.3, mean_episode_step = 1871.9, total_loss = 109.3, pg_loss = 92.939, baseline_loss = 30.695, entropy_loss = -14.33, learner_queue_size = 64, _tick = 10533, _time = 1.6548e+09)
[2022-06-09 19:39:11,210][root][INFO] - Step 67594240 @ 3067.1 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 2.1514e+04, step = 67594240, mean_episode_return = 43.41, mean_episode_step = 1932.5, total_loss = 106.57, pg_loss = 73.238, baseline_loss = 47.608, entropy_loss = -14.273, learner_queue_size = 64, _tick = 10536, _time = 1.6548e+09)
[2022-06-09 19:39:16,217][root][INFO] - Step 67604480 @ 2045.4 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 2.1519e+04, step = 67604480, mean_episode_return = 35.98, mean_episode_step = 1760.9, total_loss = 113.29, pg_loss = 77.17, baseline_loss = 50.385, entropy_loss = -14.268, learner_queue_size = 64, _tick = 10537, _time = 1.6548e+09)
[2022-06-09 19:39:21,222][root][INFO] - Step 67619840 @ 3068.8 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 2.1524e+04, step = 67619840, mean_episode_return = None, mean_episode_step = 2044.3, total_loss = -101.75, pg_loss = -103.03, baseline_loss = 15.605, entropy_loss = -14.317, learner_queue_size = 64, _tick = 10539, _time = 1.6548e+09)
[2022-06-09 19:39:26,226][root][INFO] - Step 67635200 @ 3069.6 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 2.1529e+04, step = 67635200, mean_episode_return = 54.11, mean_episode_step = 1941.3, total_loss = -139.45, pg_loss = -148.1, baseline_loss = 22.974, entropy_loss = -14.332, learner_queue_size = 64, _tick = 10542, _time = 1.6548e+09)
[2022-06-09 19:39:31,230][root][INFO] - Step 67650560 @ 3069.5 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 2.1534e+04, step = 67650560, mean_episode_return = 64.028, mean_episode_step = 1732.8, total_loss = -41.789, pg_loss = -51.754, baseline_loss = 24.258, entropy_loss = -14.294, learner_queue_size = 64, _tick = 10543, _time = 1.6548e+09)
[2022-06-09 19:39:36,234][root][INFO] - Step 67665920 @ 3069.3 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 2.1539e+04, step = 67665920, mean_episode_return = 37.082, mean_episode_step = 2000.1, total_loss = -77.296, pg_loss = -86.467, baseline_loss = 23.638, entropy_loss = -14.467, learner_queue_size = 64, _tick = 10544, _time = 1.6548e+09)
[2022-06-09 19:39:41,238][root][INFO] - Step 67676160 @ 2046.5 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 2.1544e+04, step = 67676160, mean_episode_return = 59.879, mean_episode_step = 2194.9, total_loss = -115.94, pg_loss = -137.66, baseline_loss = 36.177, entropy_loss = -14.462, learner_queue_size = 64, _tick = 10546, _time = 1.6548e+09)
[2022-06-09 19:39:46,242][root][INFO] - Step 67691520 @ 3069.5 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 2.1549e+04, step = 67691520, mean_episode_return = None, mean_episode_step = 2015.1, total_loss = -153.08, pg_loss = -147.51, baseline_loss = 8.7831, entropy_loss = -14.354, learner_queue_size = 64, _tick = 10547, _time = 1.6548e+09)
[2022-06-09 19:39:51,250][root][INFO] - Step 67706880 @ 3067.2 SPS. Inference batcher size: 127. Learner queue size: 64. Other stats: (train_seconds = 2.1554e+04, step = 67706880, mean_episode_return = 28.349, mean_episode_step = 2020.9, total_loss = 183.91, pg_loss = 133.88, baseline_loss = 64.339, entropy_loss = -14.314, learner_queue_size = 64, _tick = 10549, _time = 1.6548e+09)
[2022-06-09 19:39:56,254][root][INFO] - Step 67722240 @ 3069.3 SPS. Inference batcher size: 75. Learner queue size: 64. Other stats: (train_seconds = 2.1559e+04, step = 67722240, mean_episode_return = None, mean_episode_step = 2358.4, total_loss = 168.49, pg_loss = 142.21, baseline_loss = 40.622, entropy_loss = -14.337, learner_queue_size = 64, _tick = 10551, _time = 1.6548e+09)
[2022-06-09 19:40:01,258][root][INFO] - Step 67732480 @ 2046.4 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 2.1564e+04, step = 67732480, mean_episode_return = 70.27, mean_episode_step = 2016.0, total_loss = 140.04, pg_loss = 117.36, baseline_loss = 36.997, entropy_loss = -14.315, learner_queue_size = 64, _tick = 10553, _time = 1.6548e+09)
[2022-06-09 19:40:06,262][root][INFO] - Step 67747840 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 2.1569e+04, step = 67747840, mean_episode_return = 11.515, mean_episode_step = 2354.9, total_loss = -245.49, pg_loss = -243.18, baseline_loss = 12.011, entropy_loss = -14.323, learner_queue_size = 64, _tick = 10555, _time = 1.6548e+09)
[2022-06-09 19:40:11,266][root][INFO] - Step 67763200 @ 3069.5 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 2.1574e+04, step = 67763200, mean_episode_return = 120.24, mean_episode_step = 1959.0, total_loss = -19.415, pg_loss = -30.168, baseline_loss = 25.015, entropy_loss = -14.262, learner_queue_size = 64, _tick = 10558, _time = 1.6548e+09)
[2022-06-09 19:40:16,270][root][INFO] - Step 67778560 @ 3069.6 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 2.1579e+04, step = 67778560, mean_episode_return = 28.894, mean_episode_step = 2183.0, total_loss = -27.79, pg_loss = -42.57, baseline_loss = 29.035, entropy_loss = -14.254, learner_queue_size = 64, _tick = 10561, _time = 1.6548e+09)
[2022-06-09 19:40:21,274][root][INFO] - Step 67793920 @ 3069.5 SPS. Inference batcher size: 91. Learner queue size: 64. Other stats: (train_seconds = 2.1584e+04, step = 67793920, mean_episode_return = 58.13, mean_episode_step = 1763.5, total_loss = 43.188, pg_loss = 30.703, baseline_loss = 26.827, entropy_loss = -14.342, learner_queue_size = 64, _tick = 10564, _time = 1.6548e+09)
[2022-06-09 19:40:26,278][root][INFO] - Step 67804160 @ 2046.4 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 2.1589e+04, step = 67804160, mean_episode_return = -7.5606, mean_episode_step = 1782.9, total_loss = -78.451, pg_loss = -83.599, baseline_loss = 19.458, entropy_loss = -14.31, learner_queue_size = 64, _tick = 10565, _time = 1.6548e+09)
[2022-06-09 19:40:31,282][root][INFO] - Step 67819520 @ 3069.6 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 2.1594e+04, step = 67819520, mean_episode_return = 15.761, mean_episode_step = 1749.8, total_loss = -146.05, pg_loss = -148.52, baseline_loss = 16.833, entropy_loss = -14.356, learner_queue_size = 64, _tick = 10568, _time = 1.6548e+09)
[2022-06-09 19:40:36,286][root][INFO] - Step 67834880 @ 3069.5 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 2.1599e+04, step = 67834880, mean_episode_return = None, mean_episode_step = 1960.0, total_loss = 562.04, pg_loss = 477.85, baseline_loss = 98.749, entropy_loss = -14.564, learner_queue_size = 64, _tick = 10569, _time = 1.6548e+09)
[2022-06-09 19:40:41,290][root][INFO] - Step 67850240 @ 3069.6 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 2.1604e+04, step = 67850240, mean_episode_return = None, mean_episode_step = 1904.1, total_loss = -49.078, pg_loss = -52.717, baseline_loss = 18.284, entropy_loss = -14.644, learner_queue_size = 64, _tick = 10571, _time = 1.6548e+09)
[2022-06-09 19:40:46,294][root][INFO] - Step 67860480 @ 2046.4 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 2.1609e+04, step = 67860480, mean_episode_return = 79.985, mean_episode_step = 1652.5, total_loss = -186.92, pg_loss = -184.0, baseline_loss = 11.806, entropy_loss = -14.717, learner_queue_size = 64, _tick = 10573, _time = 1.6548e+09)
[2022-06-09 19:40:51,298][root][INFO] - Step 67875840 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 2.1614e+04, step = 67875840, mean_episode_return = 81.458, mean_episode_step = 1973.9, total_loss = 326.44, pg_loss = 268.05, baseline_loss = 73.055, entropy_loss = -14.668, learner_queue_size = 64, _tick = 10576, _time = 1.6548e+09)
[2022-06-09 19:40:56,302][root][INFO] - Step 67891200 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 2.1619e+04, step = 67891200, mean_episode_return = 20.561, mean_episode_step = 1919.5, total_loss = -39.9, pg_loss = -44.598, baseline_loss = 19.345, entropy_loss = -14.646, learner_queue_size = 64, _tick = 10579, _time = 1.6548e+09)
[2022-06-09 19:41:01,306][root][INFO] - Step 67906560 @ 3069.5 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 2.1624e+04, step = 67906560, mean_episode_return = 22.63, mean_episode_step = 1724.7, total_loss = 291.55, pg_loss = 250.24, baseline_loss = 56.006, entropy_loss = -14.697, learner_queue_size = 64, _tick = 10582, _time = 1.6548e+09)
[2022-06-09 19:41:06,310][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 19:41:06,552][root][INFO] - Step 67921920 @ 3069.6 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 2.1629e+04, step = 67921920, mean_episode_return = 48.671, mean_episode_step = 1745.5, total_loss = 82.313, pg_loss = 54.533, baseline_loss = 42.443, entropy_loss = -14.664, learner_queue_size = 64, _tick = 10585, _time = 1.6548e+09)
[2022-06-09 19:41:11,558][root][INFO] - Step 67932160 @ 1951.2 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 2.1634e+04, step = 67932160, mean_episode_return = 23.157, mean_episode_step = 1743.2, total_loss = 42.005, pg_loss = 10.74, baseline_loss = 45.892, entropy_loss = -14.627, learner_queue_size = 64, _tick = 10587, _time = 1.6548e+09)
[2022-06-09 19:41:16,562][root][INFO] - Step 67947520 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 2.164e+04, step = 67947520, mean_episode_return = 22.935, mean_episode_step = 1849.0, total_loss = -62.884, pg_loss = -78.825, baseline_loss = 30.317, entropy_loss = -14.376, learner_queue_size = 64, _tick = 10590, _time = 1.6548e+09)
[2022-06-09 19:41:21,566][root][INFO] - Step 67962880 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 2.1644e+04, step = 67962880, mean_episode_return = 93.013, mean_episode_step = 1716.3, total_loss = 157.5, pg_loss = 103.74, baseline_loss = 68.04, entropy_loss = -14.273, learner_queue_size = 64, _tick = 10593, _time = 1.6548e+09)
[2022-06-09 19:41:26,570][root][INFO] - Step 67978240 @ 3069.5 SPS. Inference batcher size: 88. Learner queue size: 64. Other stats: (train_seconds = 2.165e+04, step = 67978240, mean_episode_return = 102.69, mean_episode_step = 1566.5, total_loss = 309.58, pg_loss = 254.9, baseline_loss = 68.897, entropy_loss = -14.209, learner_queue_size = 64, _tick = 10596, _time = 1.6548e+09)
[2022-06-09 19:41:31,576][root][INFO] - Step 67993600 @ 3068.0 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 2.1654e+04, step = 67993600, mean_episode_return = 47.761, mean_episode_step = 1660.5, total_loss = 19.497, pg_loss = 1.9072, baseline_loss = 31.678, entropy_loss = -14.088, learner_queue_size = 64, _tick = 10599, _time = 1.6548e+09)
[2022-06-09 19:41:36,582][root][INFO] - Step 68008960 @ 3068.6 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 2.166e+04, step = 68008960, mean_episode_return = 44.672, mean_episode_step = 1452.4, total_loss = 576.56, pg_loss = 493.82, baseline_loss = 96.958, entropy_loss = -14.211, learner_queue_size = 64, _tick = 10602, _time = 1.6548e+09)
[2022-06-09 19:41:41,586][root][INFO] - Step 68019200 @ 2046.3 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 2.1664e+04, step = 68019200, mean_episode_return = 36.245, mean_episode_step = 1416.7, total_loss = 87.133, pg_loss = 62.336, baseline_loss = 38.872, entropy_loss = -14.076, learner_queue_size = 64, _tick = 10604, _time = 1.6548e+09)
[2022-06-09 19:41:46,590][root][INFO] - Step 68034560 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 2.167e+04, step = 68034560, mean_episode_return = 48.16, mean_episode_step = 1265.2, total_loss = -44.397, pg_loss = -57.236, baseline_loss = 27.206, entropy_loss = -14.368, learner_queue_size = 64, _tick = 10607, _time = 1.6548e+09)
[2022-06-09 19:41:51,594][root][INFO] - Step 68049920 @ 3069.6 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 2.1674e+04, step = 68049920, mean_episode_return = 85.27, mean_episode_step = 1740.0, total_loss = -96.874, pg_loss = -112.24, baseline_loss = 29.564, entropy_loss = -14.199, learner_queue_size = 64, _tick = 10610, _time = 1.6548e+09)
[2022-06-09 19:41:56,598][root][INFO] - Step 68065280 @ 3069.6 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 2.168e+04, step = 68065280, mean_episode_return = -19.925, mean_episode_step = 1659.4, total_loss = 270.17, pg_loss = 209.27, baseline_loss = 75.058, entropy_loss = -14.157, learner_queue_size = 64, _tick = 10613, _time = 1.6548e+09)
[2022-06-09 19:42:01,602][root][INFO] - Step 68075520 @ 2046.4 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 2.1684e+04, step = 68075520, mean_episode_return = 82.945, mean_episode_step = 1357.1, total_loss = -55.821, pg_loss = -65.314, baseline_loss = 23.642, entropy_loss = -14.149, learner_queue_size = 64, _tick = 10615, _time = 1.6548e+09)
[2022-06-09 19:42:06,606][root][INFO] - Step 68090880 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 2.169e+04, step = 68090880, mean_episode_return = 80.04, mean_episode_step = 1520.3, total_loss = 192.1, pg_loss = 168.69, baseline_loss = 37.639, entropy_loss = -14.229, learner_queue_size = 64, _tick = 10618, _time = 1.6548e+09)
[2022-06-09 19:42:11,610][root][INFO] - Step 68106240 @ 3069.5 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 2.1694e+04, step = 68106240, mean_episode_return = 54.866, mean_episode_step = 1375.2, total_loss = 254.12, pg_loss = 213.28, baseline_loss = 55.025, entropy_loss = -14.183, learner_queue_size = 64, _tick = 10620, _time = 1.6548e+09)
[2022-06-09 19:42:16,614][root][INFO] - Step 68121600 @ 3069.5 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 2.17e+04, step = 68121600, mean_episode_return = 13.863, mean_episode_step = 1439.5, total_loss = 80.938, pg_loss = 35.791, baseline_loss = 59.282, entropy_loss = -14.135, learner_queue_size = 64, _tick = 10623, _time = 1.6548e+09)
[2022-06-09 19:42:21,618][root][INFO] - Step 68136960 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 2.1705e+04, step = 68136960, mean_episode_return = 32.32, mean_episode_step = 1266.3, total_loss = 62.312, pg_loss = 39.605, baseline_loss = 36.874, entropy_loss = -14.166, learner_queue_size = 64, _tick = 10626, _time = 1.6548e+09)
[2022-06-09 19:42:26,622][root][INFO] - Step 68152320 @ 3069.5 SPS. Inference batcher size: 78. Learner queue size: 64. Other stats: (train_seconds = 2.171e+04, step = 68152320, mean_episode_return = None, mean_episode_step = 1800.2, total_loss = -138.8, pg_loss = -138.36, baseline_loss = 13.861, entropy_loss = -14.294, learner_queue_size = 64, _tick = 10628, _time = 1.6548e+09)
[2022-06-09 19:42:31,626][root][INFO] - Step 68167680 @ 3069.6 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 2.1715e+04, step = 68167680, mean_episode_return = 88.159, mean_episode_step = 1731.7, total_loss = 122.51, pg_loss = 92.153, baseline_loss = 44.835, entropy_loss = -14.474, learner_queue_size = 64, _tick = 10631, _time = 1.6548e+09)
[2022-06-09 19:42:36,630][root][INFO] - Step 68177920 @ 2046.4 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 2.172e+04, step = 68177920, mean_episode_return = 47.676, mean_episode_step = 1620.2, total_loss = -171.99, pg_loss = -182.6, baseline_loss = 25.027, entropy_loss = -14.42, learner_queue_size = 64, _tick = 10633, _time = 1.6548e+09)
[2022-06-09 19:42:41,634][root][INFO] - Step 68193280 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 2.1725e+04, step = 68193280, mean_episode_return = 74.258, mean_episode_step = 1410.1, total_loss = 353.55, pg_loss = 309.23, baseline_loss = 58.789, entropy_loss = -14.461, learner_queue_size = 64, _tick = 10636, _time = 1.6548e+09)
[2022-06-09 19:42:46,638][root][INFO] - Step 68208640 @ 3069.4 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 2.173e+04, step = 68208640, mean_episode_return = None, mean_episode_step = 1714.6, total_loss = 11.701, pg_loss = -4.9885, baseline_loss = 31.063, entropy_loss = -14.374, learner_queue_size = 64, _tick = 10637, _time = 1.6548e+09)
[2022-06-09 19:42:51,642][root][INFO] - Step 68224000 @ 3069.7 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 2.1735e+04, step = 68224000, mean_episode_return = None, mean_episode_step = 1369.1, total_loss = 187.06, pg_loss = 156.54, baseline_loss = 44.82, entropy_loss = -14.301, learner_queue_size = 64, _tick = 10638, _time = 1.6548e+09)
[2022-06-09 19:42:56,646][root][INFO] - Step 68239360 @ 3069.4 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 2.174e+04, step = 68239360, mean_episode_return = 23.77, mean_episode_step = 1701.7, total_loss = -176.96, pg_loss = -176.77, baseline_loss = 14.159, entropy_loss = -14.343, learner_queue_size = 64, _tick = 10641, _time = 1.6548e+09)
[2022-06-09 19:43:01,650][root][INFO] - Step 68249600 @ 2046.4 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 2.1745e+04, step = 68249600, mean_episode_return = 12.331, mean_episode_step = 1554.4, total_loss = 27.663, pg_loss = -25.237, baseline_loss = 67.21, entropy_loss = -14.31, learner_queue_size = 64, _tick = 10642, _time = 1.6548e+09)
[2022-06-09 19:43:06,654][root][INFO] - Step 68264960 @ 3069.6 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 2.175e+04, step = 68264960, mean_episode_return = 26.53, mean_episode_step = 1493.0, total_loss = -120.12, pg_loss = -132.78, baseline_loss = 26.973, entropy_loss = -14.319, learner_queue_size = 64, _tick = 10645, _time = 1.6548e+09)
[2022-06-09 19:43:11,659][root][INFO] - Step 68280320 @ 3068.9 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 2.1755e+04, step = 68280320, mean_episode_return = 33.203, mean_episode_step = 1621.1, total_loss = -98.075, pg_loss = -119.46, baseline_loss = 35.617, entropy_loss = -14.231, learner_queue_size = 64, _tick = 10648, _time = 1.6548e+09)
[2022-06-09 19:43:16,662][root][INFO] - Step 68295680 @ 3070.2 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 2.176e+04, step = 68295680, mean_episode_return = 76.909, mean_episode_step = 1875.0, total_loss = -238.8, pg_loss = -236.48, baseline_loss = 11.766, entropy_loss = -14.09, learner_queue_size = 64, _tick = 10651, _time = 1.6548e+09)
[2022-06-09 19:43:21,666][root][INFO] - Step 68311040 @ 3069.3 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 2.1765e+04, step = 68311040, mean_episode_return = 69.519, mean_episode_step = 1584.8, total_loss = 128.84, pg_loss = 88.714, baseline_loss = 54.139, entropy_loss = -14.01, learner_queue_size = 64, _tick = 10653, _time = 1.6548e+09)
[2022-06-09 19:43:26,670][root][INFO] - Step 68321280 @ 2046.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 2.177e+04, step = 68321280, mean_episode_return = 58.955, mean_episode_step = 1628.1, total_loss = 173.31, pg_loss = 138.52, baseline_loss = 48.826, entropy_loss = -14.039, learner_queue_size = 64, _tick = 10654, _time = 1.6548e+09)
[2022-06-09 19:43:31,674][root][INFO] - Step 68336640 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 2.1775e+04, step = 68336640, mean_episode_return = 48.505, mean_episode_step = 1599.9, total_loss = 607.47, pg_loss = 512.87, baseline_loss = 108.74, entropy_loss = -14.133, learner_queue_size = 64, _tick = 10655, _time = 1.6548e+09)
[2022-06-09 19:43:36,678][root][INFO] - Step 68352000 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 2.178e+04, step = 68352000, mean_episode_return = -10.201, mean_episode_step = 1765.0, total_loss = -262.08, pg_loss = -257.69, baseline_loss = 9.654, entropy_loss = -14.047, learner_queue_size = 64, _tick = 10657, _time = 1.6548e+09)
[2022-06-09 19:43:41,734][root][INFO] - Step 68367360 @ 3038.1 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 2.1785e+04, step = 68367360, mean_episode_return = 55.93, mean_episode_step = 1572.5, total_loss = 60.859, pg_loss = 28.898, baseline_loss = 46.0, entropy_loss = -14.039, learner_queue_size = 64, _tick = 10660, _time = 1.6548e+09)
[2022-06-09 19:43:46,738][root][INFO] - Step 68382720 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 2.179e+04, step = 68382720, mean_episode_return = 31.27, mean_episode_step = 1596.2, total_loss = -65.886, pg_loss = -75.249, baseline_loss = 23.228, entropy_loss = -13.865, learner_queue_size = 64, _tick = 10663, _time = 1.6548e+09)
[2022-06-09 19:43:51,742][root][INFO] - Step 68398080 @ 3069.5 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 2.1795e+04, step = 68398080, mean_episode_return = None, mean_episode_step = 1671.6, total_loss = 1234.6, pg_loss = 850.85, baseline_loss = 397.81, entropy_loss = -14.056, learner_queue_size = 64, _tick = 10664, _time = 1.6548e+09)
[2022-06-09 19:43:56,746][root][INFO] - Step 68408320 @ 2046.3 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 2.18e+04, step = 68408320, mean_episode_return = 42.053, mean_episode_step = 1996.6, total_loss = 155.5, pg_loss = 127.71, baseline_loss = 41.925, entropy_loss = -14.135, learner_queue_size = 64, _tick = 10666, _time = 1.6548e+09)
[2022-06-09 19:44:01,750][root][INFO] - Step 68423680 @ 3069.7 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 2.1805e+04, step = 68423680, mean_episode_return = 30.59, mean_episode_step = 1748.2, total_loss = -246.73, pg_loss = -253.3, baseline_loss = 20.64, entropy_loss = -14.063, learner_queue_size = 64, _tick = 10669, _time = 1.6548e+09)
[2022-06-09 19:44:06,755][root][INFO] - Step 68439040 @ 3069.1 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 2.181e+04, step = 68439040, mean_episode_return = 25.93, mean_episode_step = 2000.5, total_loss = 81.659, pg_loss = 58.774, baseline_loss = 37.176, entropy_loss = -14.291, learner_queue_size = 64, _tick = 10672, _time = 1.6548e+09)
[2022-06-09 19:44:11,760][root][INFO] - Step 68454400 @ 3069.0 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 2.1815e+04, step = 68454400, mean_episode_return = 93.641, mean_episode_step = 1740.2, total_loss = 83.047, pg_loss = 58.487, baseline_loss = 38.726, entropy_loss = -14.166, learner_queue_size = 64, _tick = 10675, _time = 1.6548e+09)
[2022-06-09 19:44:16,762][root][INFO] - Step 68469760 @ 3070.5 SPS. Inference batcher size: 2. Learner queue size: 64. Other stats: (train_seconds = 2.182e+04, step = 68469760, mean_episode_return = None, mean_episode_step = 1776.5, total_loss = -21.676, pg_loss = -32.602, baseline_loss = 25.24, entropy_loss = -14.314, learner_queue_size = 64, _tick = 10677, _time = 1.6548e+09)
[2022-06-09 19:44:21,766][root][INFO] - Step 68480000 @ 2046.3 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 2.1825e+04, step = 68480000, mean_episode_return = 85.78, mean_episode_step = 1871.7, total_loss = -17.568, pg_loss = -84.923, baseline_loss = 81.619, entropy_loss = -14.263, learner_queue_size = 64, _tick = 10679, _time = 1.6548e+09)
[2022-06-09 19:44:26,770][root][INFO] - Step 68495360 @ 3069.5 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 2.183e+04, step = 68495360, mean_episode_return = 34.326, mean_episode_step = 1870.4, total_loss = 9.4467, pg_loss = -25.645, baseline_loss = 49.373, entropy_loss = -14.281, learner_queue_size = 64, _tick = 10682, _time = 1.6548e+09)
[2022-06-09 19:44:31,774][root][INFO] - Step 68510720 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 2.1835e+04, step = 68510720, mean_episode_return = None, mean_episode_step = 1942.9, total_loss = 3.1189, pg_loss = -15.757, baseline_loss = 33.104, entropy_loss = -14.228, learner_queue_size = 64, _tick = 10684, _time = 1.6548e+09)
[2022-06-09 19:44:36,778][root][INFO] - Step 68520960 @ 2046.4 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 2.184e+04, step = 68520960, mean_episode_return = 42.755, mean_episode_step = 1851.7, total_loss = -107.96, pg_loss = -115.64, baseline_loss = 21.91, entropy_loss = -14.226, learner_queue_size = 64, _tick = 10686, _time = 1.6548e+09)
[2022-06-09 19:44:41,784][root][INFO] - Step 68536320 @ 3068.3 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 2.1845e+04, step = 68536320, mean_episode_return = 68.845, mean_episode_step = 1756.0, total_loss = -72.763, pg_loss = -92.554, baseline_loss = 34.135, entropy_loss = -14.345, learner_queue_size = 64, _tick = 10689, _time = 1.6548e+09)
[2022-06-09 19:44:46,790][root][INFO] - Step 68551680 @ 3068.4 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 2.185e+04, step = 68551680, mean_episode_return = 125.63, mean_episode_step = 1717.0, total_loss = 27.178, pg_loss = 13.518, baseline_loss = 28.081, entropy_loss = -14.421, learner_queue_size = 64, _tick = 10692, _time = 1.6548e+09)
[2022-06-09 19:44:51,794][root][INFO] - Step 68567040 @ 3069.5 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 2.1855e+04, step = 68567040, mean_episode_return = 50.597, mean_episode_step = 2040.5, total_loss = -97.317, pg_loss = -120.74, baseline_loss = 37.706, entropy_loss = -14.284, learner_queue_size = 64, _tick = 10695, _time = 1.6548e+09)
[2022-06-09 19:44:56,798][root][INFO] - Step 68582400 @ 3069.6 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 2.186e+04, step = 68582400, mean_episode_return = 62.162, mean_episode_step = 1668.0, total_loss = -58.014, pg_loss = -64.288, baseline_loss = 20.471, entropy_loss = -14.197, learner_queue_size = 64, _tick = 10698, _time = 1.6548e+09)
[2022-06-09 19:45:01,802][root][INFO] - Step 68597760 @ 3069.6 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 2.1865e+04, step = 68597760, mean_episode_return = 66.752, mean_episode_step = 1791.7, total_loss = 158.22, pg_loss = 125.4, baseline_loss = 46.99, entropy_loss = -14.169, learner_queue_size = 64, _tick = 10701, _time = 1.6548e+09)
[2022-06-09 19:45:06,806][root][INFO] - Step 68608000 @ 2046.4 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 2.187e+04, step = 68608000, mean_episode_return = 10.054, mean_episode_step = 1423.4, total_loss = 74.677, pg_loss = 56.501, baseline_loss = 32.19, entropy_loss = -14.014, learner_queue_size = 64, _tick = 10703, _time = 1.6548e+09)
[2022-06-09 19:45:11,810][root][INFO] - Step 68623360 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 2.1875e+04, step = 68623360, mean_episode_return = 126.58, mean_episode_step = 1565.0, total_loss = 61.931, pg_loss = 47.782, baseline_loss = 28.199, entropy_loss = -14.049, learner_queue_size = 64, _tick = 10706, _time = 1.6548e+09)
[2022-06-09 19:45:16,827][root][INFO] - Step 68638720 @ 3061.8 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 2.188e+04, step = 68638720, mean_episode_return = None, mean_episode_step = 1663.9, total_loss = -53.421, pg_loss = -56.968, baseline_loss = 17.627, entropy_loss = -14.08, learner_queue_size = 64, _tick = 10707, _time = 1.6548e+09)
[2022-06-09 19:45:21,830][root][INFO] - Step 68654080 @ 3070.0 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 2.1885e+04, step = 68654080, mean_episode_return = 75.517, mean_episode_step = 1858.9, total_loss = -141.31, pg_loss = -164.27, baseline_loss = 37.115, entropy_loss = -14.157, learner_queue_size = 64, _tick = 10710, _time = 1.6548e+09)
[2022-06-09 19:45:26,834][root][INFO] - Step 68669440 @ 3069.6 SPS. Inference batcher size: 85. Learner queue size: 64. Other stats: (train_seconds = 2.189e+04, step = 68669440, mean_episode_return = 66.509, mean_episode_step = 1903.8, total_loss = 214.92, pg_loss = 177.83, baseline_loss = 51.073, entropy_loss = -13.982, learner_queue_size = 64, _tick = 10713, _time = 1.6548e+09)
[2022-06-09 19:45:31,838][root][INFO] - Step 68679680 @ 2046.4 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 2.1895e+04, step = 68679680, mean_episode_return = 36.773, mean_episode_step = 1928.7, total_loss = -192.35, pg_loss = -197.24, baseline_loss = 18.805, entropy_loss = -13.92, learner_queue_size = 64, _tick = 10715, _time = 1.6548e+09)
[2022-06-09 19:45:36,842][root][INFO] - Step 68695040 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 2.19e+04, step = 68695040, mean_episode_return = 27.147, mean_episode_step = 1674.9, total_loss = 86.687, pg_loss = 54.818, baseline_loss = 45.781, entropy_loss = -13.912, learner_queue_size = 64, _tick = 10717, _time = 1.6548e+09)
[2022-06-09 19:45:41,847][root][INFO] - Step 68710400 @ 3069.1 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 2.1905e+04, step = 68710400, mean_episode_return = 44.98, mean_episode_step = 1754.5, total_loss = -34.543, pg_loss = -52.376, baseline_loss = 31.764, entropy_loss = -13.931, learner_queue_size = 64, _tick = 10720, _time = 1.6548e+09)
[2022-06-09 19:45:46,850][root][INFO] - Step 68725760 @ 3069.8 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 2.191e+04, step = 68725760, mean_episode_return = 4.4195, mean_episode_step = 2091.3, total_loss = 194.51, pg_loss = 156.24, baseline_loss = 52.33, entropy_loss = -14.055, learner_queue_size = 64, _tick = 10722, _time = 1.6548e+09)
[2022-06-09 19:45:51,854][root][INFO] - Step 68741120 @ 3069.7 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 2.1915e+04, step = 68741120, mean_episode_return = None, mean_episode_step = 1793.9, total_loss = -18.989, pg_loss = -21.41, baseline_loss = 16.294, entropy_loss = -13.873, learner_queue_size = 64, _tick = 10724, _time = 1.6548e+09)
[2022-06-09 19:45:56,862][root][INFO] - Step 68756480 @ 3067.1 SPS. Inference batcher size: 82. Learner queue size: 64. Other stats: (train_seconds = 2.192e+04, step = 68756480, mean_episode_return = None, mean_episode_step = 1590.7, total_loss = -24.24, pg_loss = -38.886, baseline_loss = 28.846, entropy_loss = -14.201, learner_queue_size = 64, _tick = 10726, _time = 1.6548e+09)
[2022-06-09 19:46:01,866][root][INFO] - Step 68766720 @ 2046.4 SPS. Inference batcher size: 15. Learner queue size: 64. Other stats: (train_seconds = 2.1925e+04, step = 68766720, mean_episode_return = 59.599, mean_episode_step = 1665.9, total_loss = 124.82, pg_loss = 82.555, baseline_loss = 56.344, entropy_loss = -14.084, learner_queue_size = 64, _tick = 10728, _time = 1.6548e+09)
[2022-06-09 19:46:06,870][root][INFO] - Step 68782080 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 2.193e+04, step = 68782080, mean_episode_return = 67.851, mean_episode_step = 2033.2, total_loss = 15.295, pg_loss = -5.3404, baseline_loss = 34.835, entropy_loss = -14.199, learner_queue_size = 64, _tick = 10731, _time = 1.6548e+09)
[2022-06-09 19:46:11,874][root][INFO] - Step 68797440 @ 3069.5 SPS. Inference batcher size: 4. Learner queue size: 64. Other stats: (train_seconds = 2.1935e+04, step = 68797440, mean_episode_return = 32.791, mean_episode_step = 1741.8, total_loss = 106.74, pg_loss = 68.805, baseline_loss = 52.231, entropy_loss = -14.301, learner_queue_size = 64, _tick = 10734, _time = 1.6548e+09)
[2022-06-09 19:46:16,878][root][INFO] - Step 68812800 @ 3069.6 SPS. Inference batcher size: 67. Learner queue size: 64. Other stats: (train_seconds = 2.194e+04, step = 68812800, mean_episode_return = 37.952, mean_episode_step = 1771.0, total_loss = -83.882, pg_loss = -86.762, baseline_loss = 17.179, entropy_loss = -14.299, learner_queue_size = 64, _tick = 10737, _time = 1.6548e+09)
[2022-06-09 19:46:21,882][root][INFO] - Step 68828160 @ 3069.5 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 2.1945e+04, step = 68828160, mean_episode_return = -3.5605, mean_episode_step = 1819.5, total_loss = 165.16, pg_loss = 128.04, baseline_loss = 51.545, entropy_loss = -14.418, learner_queue_size = 64, _tick = 10740, _time = 1.6548e+09)
[2022-06-09 19:46:26,886][root][INFO] - Step 68838400 @ 2046.3 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 2.195e+04, step = 68838400, mean_episode_return = 48.271, mean_episode_step = 1757.7, total_loss = -23.999, pg_loss = -43.885, baseline_loss = 34.435, entropy_loss = -14.55, learner_queue_size = 64, _tick = 10742, _time = 1.6548e+09)
[2022-06-09 19:46:31,890][root][INFO] - Step 68853760 @ 3069.6 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 2.1955e+04, step = 68853760, mean_episode_return = 98.216, mean_episode_step = 1739.0, total_loss = -42.763, pg_loss = -70.115, baseline_loss = 42.029, entropy_loss = -14.676, learner_queue_size = 64, _tick = 10744, _time = 1.6548e+09)
[2022-06-09 19:46:36,896][root][INFO] - Step 68869120 @ 3068.7 SPS. Inference batcher size: 78. Learner queue size: 64. Other stats: (train_seconds = 2.196e+04, step = 68869120, mean_episode_return = 32.871, mean_episode_step = 2125.6, total_loss = -200.93, pg_loss = -191.63, baseline_loss = 5.2636, entropy_loss = -14.568, learner_queue_size = 64, _tick = 10746, _time = 1.6548e+09)
[2022-06-09 19:46:41,902][root][INFO] - Step 68884480 @ 3068.1 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 2.1965e+04, step = 68884480, mean_episode_return = None, mean_episode_step = 1999.4, total_loss = -101.73, pg_loss = -107.27, baseline_loss = 20.082, entropy_loss = -14.542, learner_queue_size = 64, _tick = 10746, _time = 1.6548e+09)
[2022-06-09 19:46:46,906][root][INFO] - Step 68894720 @ 2046.3 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 2.197e+04, step = 68894720, mean_episode_return = 31.115, mean_episode_step = 1888.6, total_loss = -50.732, pg_loss = -65.553, baseline_loss = 29.311, entropy_loss = -14.49, learner_queue_size = 64, _tick = 10748, _time = 1.6548e+09)
[2022-06-09 19:46:51,910][root][INFO] - Step 68910080 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 2.1975e+04, step = 68910080, mean_episode_return = 61.814, mean_episode_step = 2413.4, total_loss = 221.05, pg_loss = 170.72, baseline_loss = 64.869, entropy_loss = -14.542, learner_queue_size = 64, _tick = 10750, _time = 1.6548e+09)
[2022-06-09 19:46:56,914][root][INFO] - Step 68925440 @ 3069.6 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 2.198e+04, step = 68925440, mean_episode_return = 62.929, mean_episode_step = 2005.1, total_loss = -170.55, pg_loss = -172.87, baseline_loss = 17.065, entropy_loss = -14.746, learner_queue_size = 64, _tick = 10752, _time = 1.6548e+09)
[2022-06-09 19:47:01,918][root][INFO] - Step 68940800 @ 3069.5 SPS. Inference batcher size: 103. Learner queue size: 64. Other stats: (train_seconds = 2.1985e+04, step = 68940800, mean_episode_return = 63.55, mean_episode_step = 2045.9, total_loss = -208.2, pg_loss = -214.03, baseline_loss = 20.576, entropy_loss = -14.747, learner_queue_size = 64, _tick = 10755, _time = 1.6548e+09)
[2022-06-09 19:47:06,922][root][INFO] - Step 68956160 @ 3069.5 SPS. Inference batcher size: 86. Learner queue size: 64. Other stats: (train_seconds = 2.199e+04, step = 68956160, mean_episode_return = 32.791, mean_episode_step = 1816.9, total_loss = -110.03, pg_loss = -121.97, baseline_loss = 26.724, entropy_loss = -14.784, learner_queue_size = 64, _tick = 10758, _time = 1.6548e+09)
[2022-06-09 19:47:11,926][root][INFO] - Step 68966400 @ 2046.4 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 2.1995e+04, step = 68966400, mean_episode_return = 19.494, mean_episode_step = 2145.1, total_loss = -326.0, pg_loss = -319.43, baseline_loss = 8.1937, entropy_loss = -14.771, learner_queue_size = 64, _tick = 10760, _time = 1.6548e+09)
[2022-06-09 19:47:16,930][root][INFO] - Step 68981760 @ 3069.5 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 2.2e+04, step = 68981760, mean_episode_return = 67.1, mean_episode_step = 2075.9, total_loss = 60.059, pg_loss = 46.61, baseline_loss = 28.126, entropy_loss = -14.677, learner_queue_size = 64, _tick = 10762, _time = 1.6548e+09)
[2022-06-09 19:47:21,934][root][INFO] - Step 68997120 @ 3069.6 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 2.2005e+04, step = 68997120, mean_episode_return = None, mean_episode_step = 2167.5, total_loss = 77.014, pg_loss = 66.691, baseline_loss = 25.01, entropy_loss = -14.686, learner_queue_size = 64, _tick = 10764, _time = 1.6548e+09)
[2022-06-09 19:47:26,938][root][INFO] - Step 69012480 @ 3069.5 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 2.201e+04, step = 69012480, mean_episode_return = 2.4359, mean_episode_step = 1955.1, total_loss = -149.0, pg_loss = -160.46, baseline_loss = 26.104, entropy_loss = -14.648, learner_queue_size = 64, _tick = 10767, _time = 1.6548e+09)
[2022-06-09 19:47:31,942][root][INFO] - Step 69027840 @ 3069.5 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 2.2015e+04, step = 69027840, mean_episode_return = 89.709, mean_episode_step = 1978.3, total_loss = -31.91, pg_loss = -45.387, baseline_loss = 28.153, entropy_loss = -14.676, learner_queue_size = 64, _tick = 10770, _time = 1.6548e+09)
[2022-06-09 19:47:36,946][root][INFO] - Step 69043200 @ 3069.6 SPS. Inference batcher size: 87. Learner queue size: 64. Other stats: (train_seconds = 2.202e+04, step = 69043200, mean_episode_return = 70.032, mean_episode_step = 2189.6, total_loss = -391.71, pg_loss = -384.9, baseline_loss = 7.8269, entropy_loss = -14.64, learner_queue_size = 64, _tick = 10773, _time = 1.6548e+09)
[2022-06-09 19:47:41,950][root][INFO] - Step 69053440 @ 2046.3 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 2.2025e+04, step = 69053440, mean_episode_return = 67.662, mean_episode_step = 2156.1, total_loss = 291.52, pg_loss = 244.9, baseline_loss = 61.252, entropy_loss = -14.634, learner_queue_size = 64, _tick = 10775, _time = 1.6548e+09)
[2022-06-09 19:47:46,956][root][INFO] - Step 69068800 @ 3068.3 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 2.203e+04, step = 69068800, mean_episode_return = None, mean_episode_step = 2081.0, total_loss = 399.19, pg_loss = 318.88, baseline_loss = 94.907, entropy_loss = -14.594, learner_queue_size = 64, _tick = 10776, _time = 1.6548e+09)
[2022-06-09 19:47:51,962][root][INFO] - Step 69084160 @ 3068.3 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 2.2035e+04, step = 69084160, mean_episode_return = 53.039, mean_episode_step = 1879.2, total_loss = 166.11, pg_loss = 129.85, baseline_loss = 50.786, entropy_loss = -14.523, learner_queue_size = 64, _tick = 10778, _time = 1.6548e+09)
[2022-06-09 19:47:56,964][root][INFO] - Step 69094400 @ 2047.1 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 2.204e+04, step = 69094400, mean_episode_return = 37.186, mean_episode_step = 2110.2, total_loss = -168.23, pg_loss = -170.98, baseline_loss = 17.348, entropy_loss = -14.594, learner_queue_size = 64, _tick = 10780, _time = 1.6548e+09)
[2022-06-09 19:48:01,970][root][INFO] - Step 69109760 @ 3068.5 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 2.2045e+04, step = 69109760, mean_episode_return = 74.16, mean_episode_step = 2024.0, total_loss = -74.305, pg_loss = -89.859, baseline_loss = 30.13, entropy_loss = -14.576, learner_queue_size = 64, _tick = 10783, _time = 1.6548e+09)
[2022-06-09 19:48:06,974][root][INFO] - Step 69125120 @ 3069.5 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 2.205e+04, step = 69125120, mean_episode_return = -2.2539, mean_episode_step = 1778.8, total_loss = -138.71, pg_loss = -144.31, baseline_loss = 20.177, entropy_loss = -14.574, learner_queue_size = 64, _tick = 10785, _time = 1.6548e+09)
[2022-06-09 19:48:11,978][root][INFO] - Step 69140480 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 2.2055e+04, step = 69140480, mean_episode_return = 12.894, mean_episode_step = 1884.7, total_loss = 15.186, pg_loss = -11.671, baseline_loss = 41.498, entropy_loss = -14.64, learner_queue_size = 64, _tick = 10788, _time = 1.6548e+09)
[2022-06-09 19:48:16,982][root][INFO] - Step 69150720 @ 2046.4 SPS. Inference batcher size: 14. Learner queue size: 64. Other stats: (train_seconds = 2.206e+04, step = 69150720, mean_episode_return = 47.992, mean_episode_step = 1728.6, total_loss = -78.305, pg_loss = -84.279, baseline_loss = 20.536, entropy_loss = -14.561, learner_queue_size = 64, _tick = 10790, _time = 1.6548e+09)
[2022-06-09 19:48:21,986][root][INFO] - Step 69166080 @ 3069.6 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 2.2065e+04, step = 69166080, mean_episode_return = 72.23, mean_episode_step = 2097.0, total_loss = 328.85, pg_loss = 282.82, baseline_loss = 60.838, entropy_loss = -14.799, learner_queue_size = 64, _tick = 10793, _time = 1.6548e+09)
[2022-06-09 19:48:26,990][root][INFO] - Step 69181440 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 2.207e+04, step = 69181440, mean_episode_return = 0.99, mean_episode_step = 2087.6, total_loss = 165.47, pg_loss = 131.95, baseline_loss = 48.334, entropy_loss = -14.817, learner_queue_size = 64, _tick = 10796, _time = 1.6548e+09)
[2022-06-09 19:48:31,994][root][INFO] - Step 69196800 @ 3069.6 SPS. Inference batcher size: 67. Learner queue size: 64. Other stats: (train_seconds = 2.2075e+04, step = 69196800, mean_episode_return = 82.705, mean_episode_step = 1863.4, total_loss = -244.18, pg_loss = -249.32, baseline_loss = 19.806, entropy_loss = -14.658, learner_queue_size = 64, _tick = 10799, _time = 1.6548e+09)
[2022-06-09 19:48:36,998][root][INFO] - Step 69212160 @ 3069.3 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 2.208e+04, step = 69212160, mean_episode_return = 57.461, mean_episode_step = 1692.9, total_loss = 34.936, pg_loss = 19.765, baseline_loss = 29.91, entropy_loss = -14.739, learner_queue_size = 64, _tick = 10802, _time = 1.6548e+09)
[2022-06-09 19:48:42,002][root][INFO] - Step 69222400 @ 2046.5 SPS. Inference batcher size: 2. Learner queue size: 64. Other stats: (train_seconds = 2.2085e+04, step = 69222400, mean_episode_return = 21.585, mean_episode_step = 1894.7, total_loss = -61.04, pg_loss = -79.905, baseline_loss = 33.654, entropy_loss = -14.789, learner_queue_size = 64, _tick = 10804, _time = 1.6548e+09)
[2022-06-09 19:48:47,006][root][INFO] - Step 69237760 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 2.209e+04, step = 69237760, mean_episode_return = 71.71, mean_episode_step = 1608.4, total_loss = -119.34, pg_loss = -116.52, baseline_loss = 12.082, entropy_loss = -14.897, learner_queue_size = 64, _tick = 10806, _time = 1.6548e+09)
[2022-06-09 19:48:52,010][root][INFO] - Step 69253120 @ 3069.5 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 2.2095e+04, step = 69253120, mean_episode_return = 31.67, mean_episode_step = 1561.7, total_loss = 90.933, pg_loss = 65.889, baseline_loss = 39.968, entropy_loss = -14.924, learner_queue_size = 64, _tick = 10809, _time = 1.6548e+09)
[2022-06-09 19:48:57,014][root][INFO] - Step 69268480 @ 3069.6 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 2.21e+04, step = 69268480, mean_episode_return = 76.475, mean_episode_step = 1862.0, total_loss = 73.532, pg_loss = 48.024, baseline_loss = 40.325, entropy_loss = -14.816, learner_queue_size = 64, _tick = 10812, _time = 1.6548e+09)
[2022-06-09 19:49:02,018][root][INFO] - Step 69278720 @ 2046.4 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 2.2105e+04, step = 69278720, mean_episode_return = 5.08, mean_episode_step = 2200.0, total_loss = -182.69, pg_loss = -179.42, baseline_loss = 11.552, entropy_loss = -14.819, learner_queue_size = 64, _tick = 10814, _time = 1.6548e+09)
[2022-06-09 19:49:07,022][root][INFO] - Step 69294080 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 2.211e+04, step = 69294080, mean_episode_return = 78.239, mean_episode_step = 1937.2, total_loss = 60.636, pg_loss = 51.842, baseline_loss = 23.668, entropy_loss = -14.874, learner_queue_size = 64, _tick = 10817, _time = 1.6548e+09)
[2022-06-09 19:49:12,026][root][INFO] - Step 69309440 @ 3069.4 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 2.2115e+04, step = 69309440, mean_episode_return = 63.459, mean_episode_step = 1778.9, total_loss = 34.642, pg_loss = 24.062, baseline_loss = 25.331, entropy_loss = -14.75, learner_queue_size = 64, _tick = 10819, _time = 1.6548e+09)
[2022-06-09 19:49:17,031][root][INFO] - Step 69324800 @ 3069.2 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 2.212e+04, step = 69324800, mean_episode_return = 55.024, mean_episode_step = 1779.1, total_loss = 1.3402, pg_loss = -17.229, baseline_loss = 33.173, entropy_loss = -14.603, learner_queue_size = 64, _tick = 10821, _time = 1.6548e+09)
[2022-06-09 19:49:22,036][root][INFO] - Step 69340160 @ 3068.7 SPS. Inference batcher size: 12. Learner queue size: 64. Other stats: (train_seconds = 2.2125e+04, step = 69340160, mean_episode_return = 46.089, mean_episode_step = 2092.0, total_loss = -231.24, pg_loss = -233.23, baseline_loss = 16.687, entropy_loss = -14.704, learner_queue_size = 64, _tick = 10824, _time = 1.6548e+09)
[2022-06-09 19:49:27,038][root][INFO] - Step 69350400 @ 2047.2 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 2.213e+04, step = 69350400, mean_episode_return = 103.49, mean_episode_step = 2178.9, total_loss = 31.616, pg_loss = -2.3373, baseline_loss = 48.65, entropy_loss = -14.696, learner_queue_size = 64, _tick = 10825, _time = 1.6548e+09)
[2022-06-09 19:49:32,042][root][INFO] - Step 69365760 @ 3069.6 SPS. Inference batcher size: 80. Learner queue size: 64. Other stats: (train_seconds = 2.2135e+04, step = 69365760, mean_episode_return = 52.951, mean_episode_step = 1861.5, total_loss = 404.9, pg_loss = 335.12, baseline_loss = 84.605, entropy_loss = -14.819, learner_queue_size = 64, _tick = 10828, _time = 1.6548e+09)
[2022-06-09 19:49:37,046][root][INFO] - Step 69381120 @ 3069.5 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 2.214e+04, step = 69381120, mean_episode_return = 60.595, mean_episode_step = 1985.7, total_loss = 32.533, pg_loss = -2.5719, baseline_loss = 49.912, entropy_loss = -14.808, learner_queue_size = 64, _tick = 10831, _time = 1.6548e+09)
[2022-06-09 19:49:42,050][root][INFO] - Step 69396480 @ 3069.5 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 2.2145e+04, step = 69396480, mean_episode_return = 24.722, mean_episode_step = 2051.5, total_loss = 228.59, pg_loss = 157.69, baseline_loss = 85.633, entropy_loss = -14.736, learner_queue_size = 64, _tick = 10834, _time = 1.6548e+09)
[2022-06-09 19:49:47,054][root][INFO] - Step 69411840 @ 3069.6 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 2.215e+04, step = 69411840, mean_episode_return = None, mean_episode_step = 2035.8, total_loss = -25.948, pg_loss = -28.452, baseline_loss = 17.291, entropy_loss = -14.786, learner_queue_size = 64, _tick = 10834, _time = 1.6548e+09)
[2022-06-09 19:49:52,058][root][INFO] - Step 69422080 @ 2046.4 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 2.2155e+04, step = 69422080, mean_episode_return = 42.12, mean_episode_step = 2081.1, total_loss = -231.12, pg_loss = -222.94, baseline_loss = 6.675, entropy_loss = -14.858, learner_queue_size = 64, _tick = 10836, _time = 1.6548e+09)
[2022-06-09 19:49:57,062][root][INFO] - Step 69437440 @ 3069.6 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 2.216e+04, step = 69437440, mean_episode_return = 6.3697, mean_episode_step = 1782.1, total_loss = -32.472, pg_loss = -50.276, baseline_loss = 32.597, entropy_loss = -14.793, learner_queue_size = 64, _tick = 10839, _time = 1.6548e+09)
[2022-06-09 19:50:02,070][root][INFO] - Step 69452800 @ 3066.9 SPS. Inference batcher size: 75. Learner queue size: 64. Other stats: (train_seconds = 2.2165e+04, step = 69452800, mean_episode_return = 120.21, mean_episode_step = 1964.8, total_loss = 4.1314, pg_loss = -2.8306, baseline_loss = 21.716, entropy_loss = -14.754, learner_queue_size = 64, _tick = 10841, _time = 1.6548e+09)
[2022-06-09 19:50:07,074][root][INFO] - Step 69468160 @ 3069.8 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 2.217e+04, step = 69468160, mean_episode_return = 25.541, mean_episode_step = 1971.6, total_loss = -199.37, pg_loss = -198.03, baseline_loss = 13.351, entropy_loss = -14.694, learner_queue_size = 64, _tick = 10844, _time = 1.6548e+09)
[2022-06-09 19:50:12,078][root][INFO] - Step 69483520 @ 3069.5 SPS. Inference batcher size: 81. Learner queue size: 64. Other stats: (train_seconds = 2.2175e+04, step = 69483520, mean_episode_return = None, mean_episode_step = 1702.3, total_loss = -46.89, pg_loss = -59.342, baseline_loss = 27.111, entropy_loss = -14.659, learner_queue_size = 64, _tick = 10846, _time = 1.6548e+09)
[2022-06-09 19:50:17,088][root][INFO] - Step 69493760 @ 2043.9 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 2.218e+04, step = 69493760, mean_episode_return = 44.264, mean_episode_step = 2104.3, total_loss = -232.81, pg_loss = -245.92, baseline_loss = 27.841, entropy_loss = -14.722, learner_queue_size = 64, _tick = 10848, _time = 1.6548e+09)
[2022-06-09 19:50:22,090][root][INFO] - Step 69509120 @ 3070.8 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 2.2185e+04, step = 69509120, mean_episode_return = 1.9497, mean_episode_step = 2058.8, total_loss = -62.758, pg_loss = -61.875, baseline_loss = 14.077, entropy_loss = -14.961, learner_queue_size = 64, _tick = 10851, _time = 1.6548e+09)
[2022-06-09 19:50:27,094][root][INFO] - Step 69524480 @ 3069.6 SPS. Inference batcher size: 54. Learner queue size: 64. Other stats: (train_seconds = 2.219e+04, step = 69524480, mean_episode_return = 38.351, mean_episode_step = 1932.2, total_loss = 98.386, pg_loss = 78.794, baseline_loss = 34.481, entropy_loss = -14.888, learner_queue_size = 64, _tick = 10854, _time = 1.6548e+09)
[2022-06-09 19:50:32,098][root][INFO] - Step 69539840 @ 3069.5 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 2.2195e+04, step = 69539840, mean_episode_return = 53.234, mean_episode_step = 1835.8, total_loss = -19.841, pg_loss = -48.603, baseline_loss = 43.617, entropy_loss = -14.855, learner_queue_size = 64, _tick = 10856, _time = 1.6548e+09)
[2022-06-09 19:50:37,102][root][INFO] - Step 69550080 @ 2046.4 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 2.22e+04, step = 69550080, mean_episode_return = 57.428, mean_episode_step = 1767.0, total_loss = -43.666, pg_loss = -60.175, baseline_loss = 31.137, entropy_loss = -14.628, learner_queue_size = 64, _tick = 10857, _time = 1.6548e+09)
[2022-06-09 19:50:42,106][root][INFO] - Step 69565440 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 2.2205e+04, step = 69565440, mean_episode_return = 25.849, mean_episode_step = 1945.3, total_loss = -100.34, pg_loss = -105.85, baseline_loss = 20.117, entropy_loss = -14.604, learner_queue_size = 64, _tick = 10860, _time = 1.6548e+09)
[2022-06-09 19:50:47,110][root][INFO] - Step 69575680 @ 2046.4 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 2.221e+04, step = 69575680, mean_episode_return = 47.963, mean_episode_step = 1742.6, total_loss = 339.66, pg_loss = 302.22, baseline_loss = 51.986, entropy_loss = -14.546, learner_queue_size = 64, _tick = 10862, _time = 1.6548e+09)
[2022-06-09 19:50:52,114][root][INFO] - Step 69591040 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 2.2215e+04, step = 69591040, mean_episode_return = None, mean_episode_step = 1949.5, total_loss = 100.71, pg_loss = 79.458, baseline_loss = 35.58, entropy_loss = -14.327, learner_queue_size = 64, _tick = 10862, _time = 1.6548e+09)
[2022-06-09 19:50:57,118][root][INFO] - Step 69606400 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 2.222e+04, step = 69606400, mean_episode_return = None, mean_episode_step = 2117.7, total_loss = -76.506, pg_loss = -83.371, baseline_loss = 21.137, entropy_loss = -14.271, learner_queue_size = 64, _tick = 10863, _time = 1.6548e+09)
[2022-06-09 19:51:02,122][root][INFO] - Step 69621760 @ 3069.4 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 2.2225e+04, step = 69621760, mean_episode_return = 36.721, mean_episode_step = 1695.5, total_loss = 195.11, pg_loss = 139.51, baseline_loss = 69.858, entropy_loss = -14.259, learner_queue_size = 64, _tick = 10865, _time = 1.6548e+09)
[2022-06-09 19:51:07,126][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 19:51:07,375][root][INFO] - Step 69632000 @ 2046.4 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 2.223e+04, step = 69632000, mean_episode_return = 44.58, mean_episode_step = 1859.0, total_loss = 151.84, pg_loss = 130.65, baseline_loss = 35.374, entropy_loss = -14.184, learner_queue_size = 64, _tick = 10866, _time = 1.6548e+09)
[2022-06-09 19:51:12,378][root][INFO] - Step 69647360 @ 2924.6 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 2.2235e+04, step = 69647360, mean_episode_return = 13.655, mean_episode_step = 2422.8, total_loss = -61.675, pg_loss = -86.085, baseline_loss = 38.696, entropy_loss = -14.287, learner_queue_size = 64, _tick = 10867, _time = 1.6548e+09)
[2022-06-09 19:51:17,382][root][INFO] - Step 69662720 @ 3069.4 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 2.224e+04, step = 69662720, mean_episode_return = 66.234, mean_episode_step = 1872.1, total_loss = -47.294, pg_loss = -64.489, baseline_loss = 31.445, entropy_loss = -14.25, learner_queue_size = 64, _tick = 10870, _time = 1.6548e+09)
[2022-06-09 19:51:22,390][root][INFO] - Step 69678080 @ 3067.2 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 2.2245e+04, step = 69678080, mean_episode_return = 53.959, mean_episode_step = 1939.5, total_loss = -152.41, pg_loss = -177.57, baseline_loss = 39.533, entropy_loss = -14.369, learner_queue_size = 64, _tick = 10873, _time = 1.6548e+09)
[2022-06-09 19:51:27,394][root][INFO] - Step 69693440 @ 3069.5 SPS. Inference batcher size: 67. Learner queue size: 64. Other stats: (train_seconds = 2.225e+04, step = 69693440, mean_episode_return = 47.44, mean_episode_step = 2184.1, total_loss = -304.8, pg_loss = -295.62, baseline_loss = 5.2085, entropy_loss = -14.385, learner_queue_size = 64, _tick = 10875, _time = 1.6548e+09)
[2022-06-09 19:51:32,398][root][INFO] - Step 69708800 @ 3069.6 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 2.2255e+04, step = 69708800, mean_episode_return = 66.286, mean_episode_step = 1876.9, total_loss = -191.15, pg_loss = -201.15, baseline_loss = 24.366, entropy_loss = -14.358, learner_queue_size = 64, _tick = 10878, _time = 1.6548e+09)
[2022-06-09 19:51:37,402][root][INFO] - Step 69719040 @ 2046.3 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 2.226e+04, step = 69719040, mean_episode_return = None, mean_episode_step = 2081.2, total_loss = 89.729, pg_loss = 64.066, baseline_loss = 39.928, entropy_loss = -14.265, learner_queue_size = 64, _tick = 10879, _time = 1.6548e+09)
[2022-06-09 19:51:42,406][root][INFO] - Step 69734400 @ 3069.6 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 2.2265e+04, step = 69734400, mean_episode_return = None, mean_episode_step = 2171.2, total_loss = 208.82, pg_loss = 140.48, baseline_loss = 82.617, entropy_loss = -14.281, learner_queue_size = 64, _tick = 10881, _time = 1.6548e+09)
[2022-06-09 19:51:47,410][root][INFO] - Step 69749760 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 2.227e+04, step = 69749760, mean_episode_return = 167.95, mean_episode_step = 2128.0, total_loss = 13.131, pg_loss = 0.34739, baseline_loss = 27.152, entropy_loss = -14.369, learner_queue_size = 64, _tick = 10884, _time = 1.6548e+09)
[2022-06-09 19:51:52,414][root][INFO] - Step 69765120 @ 3069.5 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 2.2275e+04, step = 69765120, mean_episode_return = 42.577, mean_episode_step = 2499.4, total_loss = -83.169, pg_loss = -108.37, baseline_loss = 39.531, entropy_loss = -14.335, learner_queue_size = 64, _tick = 10886, _time = 1.6548e+09)
[2022-06-09 19:51:57,418][root][INFO] - Step 69780480 @ 3069.7 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 2.228e+04, step = 69780480, mean_episode_return = 39.184, mean_episode_step = 2003.5, total_loss = 254.43, pg_loss = 211.94, baseline_loss = 56.943, entropy_loss = -14.453, learner_queue_size = 64, _tick = 10889, _time = 1.6548e+09)
[2022-06-09 19:52:02,422][root][INFO] - Step 69795840 @ 3069.3 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 2.2285e+04, step = 69795840, mean_episode_return = 29.511, mean_episode_step = 2031.7, total_loss = 99.768, pg_loss = 76.523, baseline_loss = 37.689, entropy_loss = -14.445, learner_queue_size = 64, _tick = 10892, _time = 1.6548e+09)
[2022-06-09 19:52:07,429][root][INFO] - Step 69806080 @ 2045.4 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 2.229e+04, step = 69806080, mean_episode_return = 17.746, mean_episode_step = 1938.1, total_loss = 62.385, pg_loss = 20.001, baseline_loss = 56.877, entropy_loss = -14.493, learner_queue_size = 64, _tick = 10894, _time = 1.6548e+09)
[2022-06-09 19:52:12,434][root][INFO] - Step 69821440 @ 3068.7 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 2.2295e+04, step = 69821440, mean_episode_return = 108.12, mean_episode_step = 2070.9, total_loss = 27.443, pg_loss = 12.428, baseline_loss = 29.594, entropy_loss = -14.579, learner_queue_size = 64, _tick = 10896, _time = 1.6548e+09)
[2022-06-09 19:52:17,438][root][INFO] - Step 69836800 @ 3069.6 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 2.23e+04, step = 69836800, mean_episode_return = None, mean_episode_step = 2310.4, total_loss = 189.71, pg_loss = 143.8, baseline_loss = 60.241, entropy_loss = -14.329, learner_queue_size = 64, _tick = 10897, _time = 1.6548e+09)
[2022-06-09 19:52:22,442][root][INFO] - Step 69852160 @ 3069.5 SPS. Inference batcher size: 78. Learner queue size: 64. Other stats: (train_seconds = 2.2305e+04, step = 69852160, mean_episode_return = None, mean_episode_step = 2442.5, total_loss = 393.02, pg_loss = 335.96, baseline_loss = 71.55, entropy_loss = -14.491, learner_queue_size = 64, _tick = 10898, _time = 1.6548e+09)
[2022-06-09 19:52:27,446][root][INFO] - Step 69867520 @ 3069.5 SPS. Inference batcher size: 57. Learner queue size: 64. Other stats: (train_seconds = 2.231e+04, step = 69867520, mean_episode_return = 62.171, mean_episode_step = 2127.4, total_loss = -104.78, pg_loss = -118.19, baseline_loss = 27.887, entropy_loss = -14.475, learner_queue_size = 64, _tick = 10900, _time = 1.6548e+09)
[2022-06-09 19:52:32,450][root][INFO] - Step 69877760 @ 2046.4 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 2.2315e+04, step = 69877760, mean_episode_return = None, mean_episode_step = 2149.8, total_loss = 43.382, pg_loss = 34.37, baseline_loss = 23.569, entropy_loss = -14.557, learner_queue_size = 64, _tick = 10901, _time = 1.6548e+09)
[2022-06-09 19:52:37,454][root][INFO] - Step 69893120 @ 3069.6 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 2.232e+04, step = 69893120, mean_episode_return = 52.891, mean_episode_step = 2442.5, total_loss = -271.36, pg_loss = -284.73, baseline_loss = 27.787, entropy_loss = -14.417, learner_queue_size = 64, _tick = 10904, _time = 1.6548e+09)
[2022-06-09 19:52:42,458][root][INFO] - Step 69908480 @ 3069.6 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 2.2325e+04, step = 69908480, mean_episode_return = 58.324, mean_episode_step = 2380.6, total_loss = -213.7, pg_loss = -222.2, baseline_loss = 23.043, entropy_loss = -14.534, learner_queue_size = 64, _tick = 10907, _time = 1.6548e+09)
[2022-06-09 19:52:47,462][root][INFO] - Step 69923840 @ 3069.5 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 2.233e+04, step = 69923840, mean_episode_return = None, mean_episode_step = 2034.1, total_loss = 206.32, pg_loss = 174.27, baseline_loss = 46.497, entropy_loss = -14.442, learner_queue_size = 64, _tick = 10908, _time = 1.6548e+09)
[2022-06-09 19:52:52,466][root][INFO] - Step 69939200 @ 3069.6 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 2.2335e+04, step = 69939200, mean_episode_return = 34.536, mean_episode_step = 2238.5, total_loss = 91.101, pg_loss = 64.068, baseline_loss = 41.264, entropy_loss = -14.231, learner_queue_size = 64, _tick = 10911, _time = 1.6548e+09)
[2022-06-09 19:52:57,470][root][INFO] - Step 69954560 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 2.234e+04, step = 69954560, mean_episode_return = None, mean_episode_step = 2201.0, total_loss = 32.309, pg_loss = 7.3453, baseline_loss = 38.988, entropy_loss = -14.025, learner_queue_size = 64, _tick = 10913, _time = 1.6548e+09)
[2022-06-09 19:53:02,474][root][INFO] - Step 69964800 @ 2046.4 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 2.2345e+04, step = 69964800, mean_episode_return = -1.51, mean_episode_step = 2166.2, total_loss = 465.37, pg_loss = 410.82, baseline_loss = 68.579, entropy_loss = -14.03, learner_queue_size = 64, _tick = 10914, _time = 1.6548e+09)
[2022-06-09 19:53:07,478][root][INFO] - Step 69980160 @ 3069.5 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 2.235e+04, step = 69980160, mean_episode_return = 21.56, mean_episode_step = 2173.8, total_loss = 83.407, pg_loss = 41.316, baseline_loss = 56.274, entropy_loss = -14.183, learner_queue_size = 64, _tick = 10916, _time = 1.6548e+09)
[2022-06-09 19:53:12,486][root][INFO] - Step 69995520 @ 3067.1 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 2.2355e+04, step = 69995520, mean_episode_return = None, mean_episode_step = 2350.6, total_loss = 100.63, pg_loss = 74.813, baseline_loss = 39.952, entropy_loss = -14.135, learner_queue_size = 64, _tick = 10918, _time = 1.6548e+09)
[2022-06-09 19:53:17,490][root][INFO] - Step 70010880 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 2.236e+04, step = 70010880, mean_episode_return = 74.81, mean_episode_step = 2293.1, total_loss = 169.42, pg_loss = 122.83, baseline_loss = 60.502, entropy_loss = -13.917, learner_queue_size = 64, _tick = 10921, _time = 1.6548e+09)
[2022-06-09 19:53:22,492][root][INFO] - Step 70026240 @ 3071.0 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 2.2365e+04, step = 70026240, mean_episode_return = 55.99, mean_episode_step = 2261.4, total_loss = -119.68, pg_loss = -133.19, baseline_loss = 27.431, entropy_loss = -13.918, learner_queue_size = 64, _tick = 10924, _time = 1.6548e+09)
[2022-06-09 19:53:27,494][root][INFO] - Step 70036480 @ 2047.0 SPS. Inference batcher size: 15. Learner queue size: 64. Other stats: (train_seconds = 2.237e+04, step = 70036480, mean_episode_return = 83.355, mean_episode_step = 2211.8, total_loss = -157.69, pg_loss = -164.82, baseline_loss = 20.969, entropy_loss = -13.842, learner_queue_size = 64, _tick = 10926, _time = 1.6548e+09)
[2022-06-09 19:53:32,498][root][INFO] - Step 70051840 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 2.2375e+04, step = 70051840, mean_episode_return = 77.096, mean_episode_step = 2092.8, total_loss = -205.78, pg_loss = -208.45, baseline_loss = 16.563, entropy_loss = -13.892, learner_queue_size = 64, _tick = 10929, _time = 1.6548e+09)
[2022-06-09 19:53:37,502][root][INFO] - Step 70067200 @ 3069.3 SPS. Inference batcher size: 78. Learner queue size: 64. Other stats: (train_seconds = 2.238e+04, step = 70067200, mean_episode_return = 70.085, mean_episode_step = 2148.7, total_loss = 36.338, pg_loss = -39.981, baseline_loss = 90.302, entropy_loss = -13.983, learner_queue_size = 64, _tick = 10932, _time = 1.6548e+09)
[2022-06-09 19:53:42,506][root][INFO] - Step 70082560 @ 3069.8 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 2.2385e+04, step = 70082560, mean_episode_return = None, mean_episode_step = 2184.4, total_loss = 239.7, pg_loss = 203.67, baseline_loss = 49.985, entropy_loss = -13.959, learner_queue_size = 64, _tick = 10933, _time = 1.6548e+09)
[2022-06-09 19:53:47,510][root][INFO] - Step 70092800 @ 2046.3 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 2.239e+04, step = 70092800, mean_episode_return = 17.1, mean_episode_step = 1951.8, total_loss = 60.803, pg_loss = 39.042, baseline_loss = 35.781, entropy_loss = -14.019, learner_queue_size = 64, _tick = 10935, _time = 1.6548e+09)
[2022-06-09 19:53:52,516][root][INFO] - Step 70108160 @ 3068.3 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 2.2396e+04, step = 70108160, mean_episode_return = -13.764, mean_episode_step = 1961.2, total_loss = -158.31, pg_loss = -164.59, baseline_loss = 20.272, entropy_loss = -13.99, learner_queue_size = 64, _tick = 10938, _time = 1.6548e+09)
[2022-06-09 19:53:57,522][root][INFO] - Step 70123520 @ 3068.2 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 2.24e+04, step = 70123520, mean_episode_return = 96.626, mean_episode_step = 1797.0, total_loss = 306.73, pg_loss = 272.62, baseline_loss = 48.175, entropy_loss = -14.071, learner_queue_size = 64, _tick = 10941, _time = 1.6548e+09)
[2022-06-09 19:54:02,526][root][INFO] - Step 70133760 @ 2046.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 2.2406e+04, step = 70133760, mean_episode_return = 45.943, mean_episode_step = 2305.0, total_loss = 105.46, pg_loss = 74.885, baseline_loss = 44.657, entropy_loss = -14.085, learner_queue_size = 64, _tick = 10943, _time = 1.6548e+09)
[2022-06-09 19:54:07,530][root][INFO] - Step 70149120 @ 3069.6 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 2.241e+04, step = 70149120, mean_episode_return = 31.859, mean_episode_step = 1868.5, total_loss = 131.03, pg_loss = 79.931, baseline_loss = 65.148, entropy_loss = -14.045, learner_queue_size = 64, _tick = 10945, _time = 1.6548e+09)
[2022-06-09 19:54:12,534][root][INFO] - Step 70164480 @ 3069.5 SPS. Inference batcher size: 80. Learner queue size: 64. Other stats: (train_seconds = 2.2416e+04, step = 70164480, mean_episode_return = 51.334, mean_episode_step = 1848.2, total_loss = -12.161, pg_loss = -35.398, baseline_loss = 37.261, entropy_loss = -14.023, learner_queue_size = 64, _tick = 10948, _time = 1.6548e+09)
[2022-06-09 19:54:17,538][root][INFO] - Step 70179840 @ 3069.3 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 2.242e+04, step = 70179840, mean_episode_return = 54.206, mean_episode_step = 2309.9, total_loss = 19.511, pg_loss = 3.7016, baseline_loss = 29.917, entropy_loss = -14.108, learner_queue_size = 64, _tick = 10951, _time = 1.6548e+09)
[2022-06-09 19:54:22,542][root][INFO] - Step 70190080 @ 2046.4 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 2.2426e+04, step = 70190080, mean_episode_return = 14.723, mean_episode_step = 1962.1, total_loss = 309.61, pg_loss = 253.11, baseline_loss = 70.705, entropy_loss = -14.205, learner_queue_size = 64, _tick = 10952, _time = 1.6548e+09)
[2022-06-09 19:54:27,546][root][INFO] - Step 70205440 @ 3069.8 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 2.243e+04, step = 70205440, mean_episode_return = 21.21, mean_episode_step = 1756.2, total_loss = 69.631, pg_loss = 51.132, baseline_loss = 32.644, entropy_loss = -14.145, learner_queue_size = 64, _tick = 10954, _time = 1.6548e+09)
[2022-06-09 19:54:32,550][root][INFO] - Step 70220800 @ 3069.5 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 2.2436e+04, step = 70220800, mean_episode_return = 66.912, mean_episode_step = 1811.7, total_loss = 26.705, pg_loss = 14.655, baseline_loss = 26.185, entropy_loss = -14.135, learner_queue_size = 64, _tick = 10957, _time = 1.6548e+09)
[2022-06-09 19:54:37,554][root][INFO] - Step 70236160 @ 3069.6 SPS. Inference batcher size: 82. Learner queue size: 64. Other stats: (train_seconds = 2.244e+04, step = 70236160, mean_episode_return = 31.963, mean_episode_step = 2175.3, total_loss = -240.48, pg_loss = -234.0, baseline_loss = 7.6292, entropy_loss = -14.103, learner_queue_size = 64, _tick = 10960, _time = 1.6548e+09)
[2022-06-09 19:54:42,558][root][INFO] - Step 70251520 @ 3069.5 SPS. Inference batcher size: 81. Learner queue size: 64. Other stats: (train_seconds = 2.2446e+04, step = 70251520, mean_episode_return = 41.772, mean_episode_step = 2026.0, total_loss = -145.1, pg_loss = -157.66, baseline_loss = 26.615, entropy_loss = -14.059, learner_queue_size = 64, _tick = 10962, _time = 1.6548e+09)
[2022-06-09 19:54:47,562][root][INFO] - Step 70261760 @ 2046.4 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 2.245e+04, step = 70261760, mean_episode_return = 46.45, mean_episode_step = 2152.9, total_loss = 300.93, pg_loss = 238.7, baseline_loss = 76.353, entropy_loss = -14.119, learner_queue_size = 64, _tick = 10964, _time = 1.6548e+09)
[2022-06-09 19:54:52,566][root][INFO] - Step 70277120 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 2.2456e+04, step = 70277120, mean_episode_return = 64.92, mean_episode_step = 2530.9, total_loss = -47.213, pg_loss = -64.376, baseline_loss = 31.233, entropy_loss = -14.07, learner_queue_size = 64, _tick = 10967, _time = 1.6548e+09)
[2022-06-09 19:54:57,570][root][INFO] - Step 70292480 @ 3069.5 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 2.246e+04, step = 70292480, mean_episode_return = 53.87, mean_episode_step = 1944.9, total_loss = 38.004, pg_loss = 40.323, baseline_loss = 11.849, entropy_loss = -14.169, learner_queue_size = 64, _tick = 10970, _time = 1.6548e+09)
[2022-06-09 19:55:02,574][root][INFO] - Step 70307840 @ 3069.6 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 2.2466e+04, step = 70307840, mean_episode_return = 108.05, mean_episode_step = 1641.7, total_loss = 166.25, pg_loss = 127.43, baseline_loss = 53.029, entropy_loss = -14.206, learner_queue_size = 64, _tick = 10973, _time = 1.6548e+09)
[2022-06-09 19:55:07,578][root][INFO] - Step 70323200 @ 3069.5 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 2.247e+04, step = 70323200, mean_episode_return = 78.71, mean_episode_step = 1731.5, total_loss = -92.784, pg_loss = -114.24, baseline_loss = 35.558, entropy_loss = -14.104, learner_queue_size = 64, _tick = 10976, _time = 1.6548e+09)
[2022-06-09 19:55:12,582][root][INFO] - Step 70338560 @ 3069.6 SPS. Inference batcher size: 80. Learner queue size: 64. Other stats: (train_seconds = 2.2476e+04, step = 70338560, mean_episode_return = 29.436, mean_episode_step = 1835.0, total_loss = 10.938, pg_loss = -3.6453, baseline_loss = 28.669, entropy_loss = -14.086, learner_queue_size = 64, _tick = 10978, _time = 1.6548e+09)
[2022-06-09 19:55:17,586][root][INFO] - Step 70348800 @ 2046.4 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 2.248e+04, step = 70348800, mean_episode_return = None, mean_episode_step = 2128.8, total_loss = 166.69, pg_loss = 136.4, baseline_loss = 44.343, entropy_loss = -14.05, learner_queue_size = 64, _tick = 10979, _time = 1.6548e+09)
[2022-06-09 19:55:22,590][root][INFO] - Step 70364160 @ 3069.5 SPS. Inference batcher size: 62. Learner queue size: 64. Other stats: (train_seconds = 2.2486e+04, step = 70364160, mean_episode_return = 51.123, mean_episode_step = 1958.2, total_loss = 158.62, pg_loss = 131.71, baseline_loss = 40.91, entropy_loss = -14.001, learner_queue_size = 64, _tick = 10982, _time = 1.6548e+09)
[2022-06-09 19:55:27,594][root][INFO] - Step 70379520 @ 3069.6 SPS. Inference batcher size: 5. Learner queue size: 64. Other stats: (train_seconds = 2.249e+04, step = 70379520, mean_episode_return = 58.811, mean_episode_step = 1890.1, total_loss = -168.22, pg_loss = -168.15, baseline_loss = 13.899, entropy_loss = -13.96, learner_queue_size = 64, _tick = 10984, _time = 1.6548e+09)
[2022-06-09 19:55:32,598][root][INFO] - Step 70394880 @ 3069.5 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 2.2496e+04, step = 70394880, mean_episode_return = 73.475, mean_episode_step = 2166.0, total_loss = -142.27, pg_loss = -158.29, baseline_loss = 29.901, entropy_loss = -13.884, learner_queue_size = 64, _tick = 10987, _time = 1.6548e+09)
[2022-06-09 19:55:37,604][root][INFO] - Step 70410240 @ 3068.6 SPS. Inference batcher size: 82. Learner queue size: 64. Other stats: (train_seconds = 2.25e+04, step = 70410240, mean_episode_return = 34.215, mean_episode_step = 1589.2, total_loss = 166.11, pg_loss = 122.28, baseline_loss = 57.694, entropy_loss = -13.865, learner_queue_size = 64, _tick = 10989, _time = 1.6548e+09)
[2022-06-09 19:55:42,610][root][INFO] - Step 70420480 @ 2045.4 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 2.2506e+04, step = 70420480, mean_episode_return = 38.4, mean_episode_step = 1909.1, total_loss = -151.63, pg_loss = -161.3, baseline_loss = 23.446, entropy_loss = -13.782, learner_queue_size = 64, _tick = 10991, _time = 1.6548e+09)
[2022-06-09 19:55:47,614][root][INFO] - Step 70435840 @ 3069.3 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 2.2511e+04, step = 70435840, mean_episode_return = -16.19, mean_episode_step = 1994.7, total_loss = -225.24, pg_loss = -227.0, baseline_loss = 15.657, entropy_loss = -13.897, learner_queue_size = 64, _tick = 10992, _time = 1.6548e+09)
[2022-06-09 19:55:52,618][root][INFO] - Step 70451200 @ 3069.7 SPS. Inference batcher size: 79. Learner queue size: 64. Other stats: (train_seconds = 2.2516e+04, step = 70451200, mean_episode_return = None, mean_episode_step = 1708.8, total_loss = 636.15, pg_loss = 565.53, baseline_loss = 84.572, entropy_loss = -13.953, learner_queue_size = 64, _tick = 10994, _time = 1.6548e+09)
[2022-06-09 19:55:57,622][root][INFO] - Step 70466560 @ 3069.6 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 2.2521e+04, step = 70466560, mean_episode_return = 141.88, mean_episode_step = 1656.4, total_loss = -171.52, pg_loss = -167.88, baseline_loss = 10.389, entropy_loss = -14.026, learner_queue_size = 64, _tick = 10996, _time = 1.6548e+09)
[2022-06-09 19:56:02,626][root][INFO] - Step 70481920 @ 3069.5 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 2.2526e+04, step = 70481920, mean_episode_return = None, mean_episode_step = 1924.7, total_loss = 309.69, pg_loss = 279.35, baseline_loss = 44.454, entropy_loss = -14.111, learner_queue_size = 64, _tick = 10998, _time = 1.6548e+09)
[2022-06-09 19:56:07,630][root][INFO] - Step 70492160 @ 2046.4 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 2.2531e+04, step = 70492160, mean_episode_return = 108.29, mean_episode_step = 2364.6, total_loss = 66.2, pg_loss = 45.987, baseline_loss = 34.256, entropy_loss = -14.043, learner_queue_size = 64, _tick = 11000, _time = 1.6548e+09)
[2022-06-09 19:56:12,634][root][INFO] - Step 70507520 @ 3069.4 SPS. Inference batcher size: 9. Learner queue size: 64. Other stats: (train_seconds = 2.2536e+04, step = 70507520, mean_episode_return = None, mean_episode_step = 1889.4, total_loss = -93.747, pg_loss = -109.64, baseline_loss = 29.87, entropy_loss = -13.977, learner_queue_size = 64, _tick = 11002, _time = 1.6548e+09)
[2022-06-09 19:56:17,638][root][INFO] - Step 70522880 @ 3069.6 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 2.2541e+04, step = 70522880, mean_episode_return = 0.88743, mean_episode_step = 1746.8, total_loss = 22.397, pg_loss = 5.4318, baseline_loss = 30.828, entropy_loss = -13.863, learner_queue_size = 64, _tick = 11005, _time = 1.6548e+09)
[2022-06-09 19:56:22,642][root][INFO] - Step 70538240 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 2.2546e+04, step = 70538240, mean_episode_return = 9.8094, mean_episode_step = 2220.2, total_loss = -70.433, pg_loss = -75.693, baseline_loss = 19.117, entropy_loss = -13.857, learner_queue_size = 64, _tick = 11007, _time = 1.6548e+09)
[2022-06-09 19:56:27,646][root][INFO] - Step 70553600 @ 3069.6 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 2.2551e+04, step = 70553600, mean_episode_return = 47.305, mean_episode_step = 1857.1, total_loss = 183.51, pg_loss = 144.42, baseline_loss = 53.144, entropy_loss = -14.054, learner_queue_size = 64, _tick = 11010, _time = 1.6548e+09)
[2022-06-09 19:56:32,650][root][INFO] - Step 70563840 @ 2046.4 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 2.2556e+04, step = 70563840, mean_episode_return = None, mean_episode_step = 2031.1, total_loss = 305.9, pg_loss = 258.84, baseline_loss = 61.041, entropy_loss = -13.984, learner_queue_size = 64, _tick = 11011, _time = 1.6548e+09)
[2022-06-09 19:56:37,654][root][INFO] - Step 70579200 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 2.2561e+04, step = 70579200, mean_episode_return = 64.15, mean_episode_step = 1876.6, total_loss = 334.51, pg_loss = 275.62, baseline_loss = 72.839, entropy_loss = -13.954, learner_queue_size = 64, _tick = 11014, _time = 1.6548e+09)
[2022-06-09 19:56:42,658][root][INFO] - Step 70594560 @ 3069.5 SPS. Inference batcher size: 18. Learner queue size: 64. Other stats: (train_seconds = 2.2566e+04, step = 70594560, mean_episode_return = 3.0231, mean_episode_step = 1845.7, total_loss = -99.276, pg_loss = -115.6, baseline_loss = 30.331, entropy_loss = -14.006, learner_queue_size = 64, _tick = 11017, _time = 1.6548e+09)
[2022-06-09 19:56:47,662][root][INFO] - Step 70609920 @ 3069.6 SPS. Inference batcher size: 51. Learner queue size: 64. Other stats: (train_seconds = 2.2571e+04, step = 70609920, mean_episode_return = -18.401, mean_episode_step = 2153.5, total_loss = 78.171, pg_loss = 52.241, baseline_loss = 39.9, entropy_loss = -13.97, learner_queue_size = 64, _tick = 11020, _time = 1.6548e+09)
[2022-06-09 19:56:52,666][root][INFO] - Step 70625280 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 2.2576e+04, step = 70625280, mean_episode_return = 38.184, mean_episode_step = 2019.3, total_loss = 434.55, pg_loss = 379.89, baseline_loss = 68.645, entropy_loss = -13.989, learner_queue_size = 64, _tick = 11022, _time = 1.6548e+09)
[2022-06-09 19:56:57,670][root][INFO] - Step 70640640 @ 3069.3 SPS. Inference batcher size: 67. Learner queue size: 64. Other stats: (train_seconds = 2.2581e+04, step = 70640640, mean_episode_return = None, mean_episode_step = 1683.4, total_loss = 11.906, pg_loss = 0.20439, baseline_loss = 25.763, entropy_loss = -14.062, learner_queue_size = 64, _tick = 11023, _time = 1.6548e+09)
[2022-06-09 19:57:02,674][root][INFO] - Step 70650880 @ 2046.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 2.2586e+04, step = 70650880, mean_episode_return = 48.33, mean_episode_step = 1878.3, total_loss = 83.472, pg_loss = 55.693, baseline_loss = 41.755, entropy_loss = -13.976, learner_queue_size = 64, _tick = 11025, _time = 1.6548e+09)
[2022-06-09 19:57:07,680][root][INFO] - Step 70666240 @ 3068.6 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 2.2591e+04, step = 70666240, mean_episode_return = None, mean_episode_step = 1934.4, total_loss = -263.39, pg_loss = -251.6, baseline_loss = 2.317, entropy_loss = -14.099, learner_queue_size = 64, _tick = 11027, _time = 1.6548e+09)
[2022-06-09 19:57:12,682][root][INFO] - Step 70681600 @ 3070.5 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 2.2596e+04, step = 70681600, mean_episode_return = 45.221, mean_episode_step = 2005.0, total_loss = 228.12, pg_loss = 187.83, baseline_loss = 54.281, entropy_loss = -13.989, learner_queue_size = 64, _tick = 11030, _time = 1.6548e+09)
[2022-06-09 19:57:17,686][root][INFO] - Step 70696960 @ 3069.5 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 2.2601e+04, step = 70696960, mean_episode_return = 68.564, mean_episode_step = 2240.3, total_loss = 66.158, pg_loss = 40.399, baseline_loss = 39.694, entropy_loss = -13.935, learner_queue_size = 64, _tick = 11032, _time = 1.6548e+09)
[2022-06-09 19:57:22,690][root][INFO] - Step 70712320 @ 3069.5 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 2.2606e+04, step = 70712320, mean_episode_return = 46.43, mean_episode_step = 2063.1, total_loss = 151.03, pg_loss = 117.01, baseline_loss = 47.95, entropy_loss = -13.926, learner_queue_size = 64, _tick = 11035, _time = 1.6548e+09)
[2022-06-09 19:57:27,694][root][INFO] - Step 70727680 @ 3069.6 SPS. Inference batcher size: 80. Learner queue size: 64. Other stats: (train_seconds = 2.2611e+04, step = 70727680, mean_episode_return = 26.531, mean_episode_step = 2217.0, total_loss = -84.651, pg_loss = -93.523, baseline_loss = 22.963, entropy_loss = -14.092, learner_queue_size = 64, _tick = 11038, _time = 1.6548e+09)
[2022-06-09 19:57:32,699][root][INFO] - Step 70737920 @ 2045.9 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 2.2616e+04, step = 70737920, mean_episode_return = 77.569, mean_episode_step = 1805.0, total_loss = 311.8, pg_loss = 261.46, baseline_loss = 64.601, entropy_loss = -14.256, learner_queue_size = 64, _tick = 11039, _time = 1.6548e+09)
[2022-06-09 19:57:37,702][root][INFO] - Step 70753280 @ 3070.3 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 2.2621e+04, step = 70753280, mean_episode_return = 108.41, mean_episode_step = 1924.2, total_loss = -173.27, pg_loss = -175.83, baseline_loss = 16.839, entropy_loss = -14.274, learner_queue_size = 64, _tick = 11041, _time = 1.6548e+09)
[2022-06-09 19:57:42,706][root][INFO] - Step 70768640 @ 3069.5 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 2.2626e+04, step = 70768640, mean_episode_return = 53.56, mean_episode_step = 2310.2, total_loss = 73.016, pg_loss = -6.6843, baseline_loss = 94.013, entropy_loss = -14.313, learner_queue_size = 64, _tick = 11043, _time = 1.6548e+09)
[2022-06-09 19:57:47,710][root][INFO] - Step 70784000 @ 3069.6 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 2.2631e+04, step = 70784000, mean_episode_return = None, mean_episode_step = 2840.5, total_loss = -219.24, pg_loss = -211.65, baseline_loss = 6.6787, entropy_loss = -14.268, learner_queue_size = 64, _tick = 11045, _time = 1.6548e+09)
[2022-06-09 19:57:52,714][root][INFO] - Step 70794240 @ 2046.3 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 2.2636e+04, step = 70794240, mean_episode_return = 70.471, mean_episode_step = 2055.5, total_loss = 10.787, pg_loss = -3.3646, baseline_loss = 28.42, entropy_loss = -14.268, learner_queue_size = 64, _tick = 11047, _time = 1.6548e+09)
[2022-06-09 19:57:57,718][root][INFO] - Step 70809600 @ 3069.5 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 2.2641e+04, step = 70809600, mean_episode_return = 88.924, mean_episode_step = 1953.4, total_loss = 119.53, pg_loss = 84.589, baseline_loss = 49.159, entropy_loss = -14.219, learner_queue_size = 64, _tick = 11050, _time = 1.6548e+09)
[2022-06-09 19:58:02,722][root][INFO] - Step 70824960 @ 3069.6 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 2.2646e+04, step = 70824960, mean_episode_return = 100.18, mean_episode_step = 2741.7, total_loss = 242.26, pg_loss = 195.17, baseline_loss = 61.364, entropy_loss = -14.283, learner_queue_size = 64, _tick = 11053, _time = 1.6548e+09)
[2022-06-09 19:58:07,726][root][INFO] - Step 70840320 @ 3069.5 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 2.2651e+04, step = 70840320, mean_episode_return = 39.309, mean_episode_step = 2153.9, total_loss = -17.878, pg_loss = -28.095, baseline_loss = 24.648, entropy_loss = -14.431, learner_queue_size = 64, _tick = 11056, _time = 1.6548e+09)
[2022-06-09 19:58:12,730][root][INFO] - Step 70855680 @ 3069.5 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 2.2656e+04, step = 70855680, mean_episode_return = 29.53, mean_episode_step = 1910.2, total_loss = 69.944, pg_loss = 48.316, baseline_loss = 36.173, entropy_loss = -14.545, learner_queue_size = 64, _tick = 11059, _time = 1.6548e+09)
[2022-06-09 19:58:17,734][root][INFO] - Step 70871040 @ 3069.5 SPS. Inference batcher size: 72. Learner queue size: 64. Other stats: (train_seconds = 2.2661e+04, step = 70871040, mean_episode_return = -12.79, mean_episode_step = 2035.8, total_loss = 242.28, pg_loss = 207.18, baseline_loss = 49.672, entropy_loss = -14.569, learner_queue_size = 64, _tick = 11061, _time = 1.6548e+09)
[2022-06-09 19:58:22,738][root][INFO] - Step 70881280 @ 2046.5 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 2.2666e+04, step = 70881280, mean_episode_return = None, mean_episode_step = 1844.0, total_loss = -2.586, pg_loss = -19.142, baseline_loss = 31.092, entropy_loss = -14.536, learner_queue_size = 64, _tick = 11061, _time = 1.6548e+09)
[2022-06-09 19:58:27,742][root][INFO] - Step 70896640 @ 3069.6 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 2.2671e+04, step = 70896640, mean_episode_return = 108.7, mean_episode_step = 2381.7, total_loss = 25.068, pg_loss = 9.8224, baseline_loss = 29.635, entropy_loss = -14.389, learner_queue_size = 64, _tick = 11064, _time = 1.6548e+09)
[2022-06-09 19:58:32,746][root][INFO] - Step 70912000 @ 3069.5 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 2.2676e+04, step = 70912000, mean_episode_return = None, mean_episode_step = 2526.6, total_loss = -0.97019, pg_loss = -10.961, baseline_loss = 24.475, entropy_loss = -14.485, learner_queue_size = 64, _tick = 11066, _time = 1.6548e+09)
[2022-06-09 19:58:37,750][root][INFO] - Step 70927360 @ 3069.5 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 2.2681e+04, step = 70927360, mean_episode_return = None, mean_episode_step = 2187.6, total_loss = 168.2, pg_loss = 144.55, baseline_loss = 38.401, entropy_loss = -14.75, learner_queue_size = 64, _tick = 11068, _time = 1.6548e+09)
[2022-06-09 19:58:42,754][root][INFO] - Step 70942720 @ 3069.6 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 2.2686e+04, step = 70942720, mean_episode_return = 38.772, mean_episode_step = 2461.8, total_loss = -0.3399, pg_loss = -18.616, baseline_loss = 33.148, entropy_loss = -14.872, learner_queue_size = 64, _tick = 11070, _time = 1.6548e+09)
[2022-06-09 19:58:47,759][root][INFO] - Step 70958080 @ 3069.2 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 2.2691e+04, step = 70958080, mean_episode_return = 29.013, mean_episode_step = 2382.2, total_loss = -12.602, pg_loss = -38.265, baseline_loss = 40.431, entropy_loss = -14.768, learner_queue_size = 64, _tick = 11073, _time = 1.6548e+09)
[2022-06-09 19:58:52,762][root][INFO] - Step 70968320 @ 2046.6 SPS. Inference batcher size: 63. Learner queue size: 64. Other stats: (train_seconds = 2.2696e+04, step = 70968320, mean_episode_return = 19.652, mean_episode_step = 1812.4, total_loss = 152.02, pg_loss = 116.03, baseline_loss = 50.766, entropy_loss = -14.776, learner_queue_size = 64, _tick = 11075, _time = 1.6548e+09)
[2022-06-09 19:58:57,767][root][INFO] - Step 70983680 @ 3069.0 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 2.2701e+04, step = 70983680, mean_episode_return = 68.879, mean_episode_step = 2483.3, total_loss = 213.95, pg_loss = 187.69, baseline_loss = 40.82, entropy_loss = -14.556, learner_queue_size = 64, _tick = 11078, _time = 1.6548e+09)
[2022-06-09 19:59:02,778][root][INFO] - Step 70999040 @ 3065.1 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 2.2706e+04, step = 70999040, mean_episode_return = 28.112, mean_episode_step = 1853.0, total_loss = -36.92, pg_loss = -83.218, baseline_loss = 60.839, entropy_loss = -14.54, learner_queue_size = 64, _tick = 11081, _time = 1.6548e+09)
[2022-06-09 19:59:07,790][root][INFO] - Step 71014400 @ 3064.7 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 2.2711e+04, step = 71014400, mean_episode_return = None, mean_episode_step = 2215.4, total_loss = -36.307, pg_loss = -35.011, baseline_loss = 13.153, entropy_loss = -14.45, learner_queue_size = 64, _tick = 11083, _time = 1.6548e+09)
[2022-06-09 19:59:12,794][root][INFO] - Step 71029760 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 2.2716e+04, step = 71029760, mean_episode_return = 112.99, mean_episode_step = 1775.7, total_loss = 138.76, pg_loss = 115.03, baseline_loss = 38.202, entropy_loss = -14.476, learner_queue_size = 64, _tick = 11086, _time = 1.6548e+09)
[2022-06-09 19:59:17,798][root][INFO] - Step 71040000 @ 2046.4 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 2.2721e+04, step = 71040000, mean_episode_return = 46.891, mean_episode_step = 2101.6, total_loss = 310.13, pg_loss = 272.8, baseline_loss = 51.714, entropy_loss = -14.384, learner_queue_size = 64, _tick = 11088, _time = 1.6548e+09)
[2022-06-09 19:59:22,802][root][INFO] - Step 71055360 @ 3069.6 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 2.2726e+04, step = 71055360, mean_episode_return = 33.783, mean_episode_step = 1812.4, total_loss = -301.51, pg_loss = -314.45, baseline_loss = 27.435, entropy_loss = -14.501, learner_queue_size = 64, _tick = 11091, _time = 1.6548e+09)
[2022-06-09 19:59:27,806][root][INFO] - Step 71070720 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 2.2731e+04, step = 71070720, mean_episode_return = 36.18, mean_episode_step = 1721.4, total_loss = -209.96, pg_loss = -208.13, baseline_loss = 12.6, entropy_loss = -14.427, learner_queue_size = 64, _tick = 11094, _time = 1.6548e+09)
[2022-06-09 19:59:32,810][root][INFO] - Step 71086080 @ 3069.6 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 2.2736e+04, step = 71086080, mean_episode_return = 22.354, mean_episode_step = 1864.2, total_loss = 122.22, pg_loss = 91.68, baseline_loss = 45.063, entropy_loss = -14.525, learner_queue_size = 64, _tick = 11097, _time = 1.6548e+09)
[2022-06-09 19:59:37,814][root][INFO] - Step 71101440 @ 3069.5 SPS. Inference batcher size: 71. Learner queue size: 64. Other stats: (train_seconds = 2.2741e+04, step = 71101440, mean_episode_return = 60.03, mean_episode_step = 1500.6, total_loss = 134.96, pg_loss = 107.0, baseline_loss = 42.61, entropy_loss = -14.653, learner_queue_size = 64, _tick = 11100, _time = 1.6548e+09)
[2022-06-09 19:59:42,818][root][INFO] - Step 71116800 @ 3069.6 SPS. Inference batcher size: 91. Learner queue size: 64. Other stats: (train_seconds = 2.2746e+04, step = 71116800, mean_episode_return = -14.819, mean_episode_step = 1463.5, total_loss = 56.821, pg_loss = 29.356, baseline_loss = 41.938, entropy_loss = -14.474, learner_queue_size = 64, _tick = 11103, _time = 1.6548e+09)
[2022-06-09 19:59:47,822][root][INFO] - Step 71127040 @ 2046.4 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 2.2751e+04, step = 71127040, mean_episode_return = 50.066, mean_episode_step = 1863.9, total_loss = 157.76, pg_loss = 124.1, baseline_loss = 48.219, entropy_loss = -14.566, learner_queue_size = 64, _tick = 11105, _time = 1.6548e+09)
[2022-06-09 19:59:52,830][root][INFO] - Step 71142400 @ 3066.8 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 2.2756e+04, step = 71142400, mean_episode_return = None, mean_episode_step = 1635.7, total_loss = 212.13, pg_loss = 182.31, baseline_loss = 44.374, entropy_loss = -14.554, learner_queue_size = 64, _tick = 11106, _time = 1.6548e+09)
[2022-06-09 19:59:57,834][root][INFO] - Step 71152640 @ 2046.6 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 2.2761e+04, step = 71152640, mean_episode_return = 83.551, mean_episode_step = 1870.4, total_loss = -41.902, pg_loss = -55.55, baseline_loss = 28.099, entropy_loss = -14.45, learner_queue_size = 64, _tick = 11108, _time = 1.6548e+09)
[2022-06-09 20:00:02,838][root][INFO] - Step 71168000 @ 3069.5 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 2.2766e+04, step = 71168000, mean_episode_return = -9.4406, mean_episode_step = 1847.8, total_loss = -82.807, pg_loss = -85.023, baseline_loss = 16.48, entropy_loss = -14.264, learner_queue_size = 64, _tick = 11110, _time = 1.6548e+09)
[2022-06-09 20:00:07,842][root][INFO] - Step 71183360 @ 3069.5 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 2.2771e+04, step = 71183360, mean_episode_return = 79.199, mean_episode_step = 1721.2, total_loss = -81.232, pg_loss = -93.584, baseline_loss = 26.834, entropy_loss = -14.482, learner_queue_size = 64, _tick = 11113, _time = 1.6548e+09)
[2022-06-09 20:00:12,846][root][INFO] - Step 71193600 @ 2046.4 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 2.2776e+04, step = 71193600, mean_episode_return = 29.787, mean_episode_step = 1647.5, total_loss = -210.42, pg_loss = -226.61, baseline_loss = 30.658, entropy_loss = -14.465, learner_queue_size = 64, _tick = 11115, _time = 1.6548e+09)
[2022-06-09 20:00:17,850][root][INFO] - Step 71208960 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 2.2781e+04, step = 71208960, mean_episode_return = -8.6355, mean_episode_step = 1852.8, total_loss = -15.687, pg_loss = -31.303, baseline_loss = 30.143, entropy_loss = -14.527, learner_queue_size = 64, _tick = 11118, _time = 1.6548e+09)
[2022-06-09 20:00:22,854][root][INFO] - Step 71224320 @ 3069.6 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 2.2786e+04, step = 71224320, mean_episode_return = None, mean_episode_step = 1615.6, total_loss = 344.43, pg_loss = 312.79, baseline_loss = 46.139, entropy_loss = -14.504, learner_queue_size = 64, _tick = 11120, _time = 1.6548e+09)
[2022-06-09 20:00:27,863][root][INFO] - Step 71239680 @ 3066.8 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 2.2791e+04, step = 71239680, mean_episode_return = 81.739, mean_episode_step = 1522.2, total_loss = -49.78, pg_loss = -57.652, baseline_loss = 22.31, entropy_loss = -14.438, learner_queue_size = 64, _tick = 11123, _time = 1.6548e+09)
[2022-06-09 20:00:32,866][root][INFO] - Step 71255040 @ 3069.9 SPS. Inference batcher size: 56. Learner queue size: 64. Other stats: (train_seconds = 2.2796e+04, step = 71255040, mean_episode_return = 47.362, mean_episode_step = 1706.2, total_loss = 275.56, pg_loss = 243.84, baseline_loss = 46.087, entropy_loss = -14.364, learner_queue_size = 64, _tick = 11126, _time = 1.6548e+09)
[2022-06-09 20:00:37,870][root][INFO] - Step 71270400 @ 3069.6 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 2.2801e+04, step = 71270400, mean_episode_return = 8.9345, mean_episode_step = 1419.2, total_loss = -104.48, pg_loss = -119.0, baseline_loss = 29.01, entropy_loss = -14.494, learner_queue_size = 64, _tick = 11129, _time = 1.6548e+09)
[2022-06-09 20:00:42,875][root][INFO] - Step 71285760 @ 3069.1 SPS. Inference batcher size: 116. Learner queue size: 64. Other stats: (train_seconds = 2.2806e+04, step = 71285760, mean_episode_return = 15.14, mean_episode_step = 1569.6, total_loss = -3.8434, pg_loss = -21.511, baseline_loss = 32.145, entropy_loss = -14.477, learner_queue_size = 64, _tick = 11132, _time = 1.6548e+09)
[2022-06-09 20:00:47,878][root][INFO] - Step 71301120 @ 3070.0 SPS. Inference batcher size: 96. Learner queue size: 64. Other stats: (train_seconds = 2.2811e+04, step = 71301120, mean_episode_return = 52.395, mean_episode_step = 1701.1, total_loss = -326.53, pg_loss = -318.78, baseline_loss = 6.5921, entropy_loss = -14.346, learner_queue_size = 64, _tick = 11134, _time = 1.6548e+09)
[2022-06-09 20:00:52,882][root][INFO] - Step 71311360 @ 2046.4 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 2.2816e+04, step = 71311360, mean_episode_return = 70.714, mean_episode_step = 1744.3, total_loss = -209.08, pg_loss = -209.12, baseline_loss = 14.449, entropy_loss = -14.401, learner_queue_size = 64, _tick = 11136, _time = 1.6548e+09)
[2022-06-09 20:00:57,886][root][INFO] - Step 71326720 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 2.2821e+04, step = 71326720, mean_episode_return = -1.51, mean_episode_step = 1709.6, total_loss = 533.24, pg_loss = 483.35, baseline_loss = 64.277, entropy_loss = -14.384, learner_queue_size = 64, _tick = 11139, _time = 1.6548e+09)
[2022-06-09 20:01:02,890][root][INFO] - Step 71342080 @ 3069.5 SPS. Inference batcher size: 0. Learner queue size: 64. Other stats: (train_seconds = 2.2826e+04, step = 71342080, mean_episode_return = 91.945, mean_episode_step = 1805.2, total_loss = -13.381, pg_loss = -37.933, baseline_loss = 38.908, entropy_loss = -14.356, learner_queue_size = 64, _tick = 11141, _time = 1.6548e+09)
[2022-06-09 20:01:07,894][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 20:01:08,170][root][INFO] - Step 71357440 @ 3069.6 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 2.2831e+04, step = 71357440, mean_episode_return = 81.297, mean_episode_step = 1878.8, total_loss = 3.56, pg_loss = -33.71, baseline_loss = 51.66, entropy_loss = -14.391, learner_queue_size = 64, _tick = 11144, _time = 1.6548e+09)
[2022-06-09 20:01:13,174][root][INFO] - Step 71367680 @ 1939.4 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 2.2836e+04, step = 71367680, mean_episode_return = 67.96, mean_episode_step = 1620.8, total_loss = -251.56, pg_loss = -259.41, baseline_loss = 22.011, entropy_loss = -14.163, learner_queue_size = 64, _tick = 11146, _time = 1.6548e+09)
[2022-06-09 20:01:18,178][root][INFO] - Step 71383040 @ 3069.5 SPS. Inference batcher size: 21. Learner queue size: 64. Other stats: (train_seconds = 2.2841e+04, step = 71383040, mean_episode_return = 63.814, mean_episode_step = 1710.4, total_loss = 20.411, pg_loss = 3.1686, baseline_loss = 31.366, entropy_loss = -14.124, learner_queue_size = 64, _tick = 11149, _time = 1.6548e+09)
[2022-06-09 20:01:23,182][root][INFO] - Step 71398400 @ 3069.6 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 2.2846e+04, step = 71398400, mean_episode_return = 70.287, mean_episode_step = 1602.1, total_loss = 85.875, pg_loss = 51.872, baseline_loss = 47.932, entropy_loss = -13.93, learner_queue_size = 64, _tick = 11152, _time = 1.6548e+09)
[2022-06-09 20:01:28,186][root][INFO] - Step 71413760 @ 3069.5 SPS. Inference batcher size: 48. Learner queue size: 64. Other stats: (train_seconds = 2.2851e+04, step = 71413760, mean_episode_return = 49.002, mean_episode_step = 1645.6, total_loss = -41.07, pg_loss = -69.825, baseline_loss = 42.741, entropy_loss = -13.985, learner_queue_size = 64, _tick = 11155, _time = 1.6548e+09)
[2022-06-09 20:01:33,190][root][INFO] - Step 71429120 @ 3069.4 SPS. Inference batcher size: 74. Learner queue size: 64. Other stats: (train_seconds = 2.2856e+04, step = 71429120, mean_episode_return = None, mean_episode_step = 1737.2, total_loss = 369.28, pg_loss = 323.55, baseline_loss = 59.763, entropy_loss = -14.03, learner_queue_size = 64, _tick = 11157, _time = 1.6548e+09)
[2022-06-09 20:01:38,194][root][INFO] - Step 71439360 @ 2046.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 2.2861e+04, step = 71439360, mean_episode_return = 68.601, mean_episode_step = 1600.9, total_loss = -16.455, pg_loss = -30.919, baseline_loss = 28.469, entropy_loss = -14.005, learner_queue_size = 64, _tick = 11159, _time = 1.6548e+09)
[2022-06-09 20:01:43,198][root][INFO] - Step 71454720 @ 3069.6 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 2.2866e+04, step = 71454720, mean_episode_return = 69.713, mean_episode_step = 1548.7, total_loss = -6.6349, pg_loss = -24.852, baseline_loss = 32.33, entropy_loss = -14.114, learner_queue_size = 64, _tick = 11161, _time = 1.6548e+09)
[2022-06-09 20:01:48,202][root][INFO] - Step 71470080 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 2.2871e+04, step = 71470080, mean_episode_return = 36.926, mean_episode_step = 1609.3, total_loss = 148.26, pg_loss = 111.13, baseline_loss = 51.152, entropy_loss = -14.026, learner_queue_size = 64, _tick = 11164, _time = 1.6548e+09)
[2022-06-09 20:01:53,206][root][INFO] - Step 71485440 @ 3069.5 SPS. Inference batcher size: 72. Learner queue size: 64. Other stats: (train_seconds = 2.2876e+04, step = 71485440, mean_episode_return = 25.577, mean_episode_step = 1596.6, total_loss = -35.341, pg_loss = -74.367, baseline_loss = 53.015, entropy_loss = -13.989, learner_queue_size = 64, _tick = 11167, _time = 1.6548e+09)
[2022-06-09 20:01:58,210][root][INFO] - Step 71495680 @ 2046.4 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 2.2881e+04, step = 71495680, mean_episode_return = 15.485, mean_episode_step = 1497.3, total_loss = 109.94, pg_loss = 67.096, baseline_loss = 56.772, entropy_loss = -13.928, learner_queue_size = 64, _tick = 11169, _time = 1.6548e+09)
[2022-06-09 20:02:03,214][root][INFO] - Step 71511040 @ 3069.4 SPS. Inference batcher size: 14. Learner queue size: 64. Other stats: (train_seconds = 2.2886e+04, step = 71511040, mean_episode_return = 60.123, mean_episode_step = 1293.3, total_loss = 38.299, pg_loss = -15.078, baseline_loss = 67.202, entropy_loss = -13.825, learner_queue_size = 64, _tick = 11172, _time = 1.6548e+09)
[2022-06-09 20:02:08,222][root][INFO] - Step 71526400 @ 3067.1 SPS. Inference batcher size: 18. Learner queue size: 64. Other stats: (train_seconds = 2.2891e+04, step = 71526400, mean_episode_return = None, mean_episode_step = 1796.4, total_loss = 498.37, pg_loss = 440.98, baseline_loss = 71.204, entropy_loss = -13.81, learner_queue_size = 64, _tick = 11173, _time = 1.6548e+09)
[2022-06-09 20:02:13,226][root][INFO] - Step 71541760 @ 3069.6 SPS. Inference batcher size: 12. Learner queue size: 64. Other stats: (train_seconds = 2.2896e+04, step = 71541760, mean_episode_return = None, mean_episode_step = 1992.4, total_loss = 102.96, pg_loss = 83.501, baseline_loss = 33.216, entropy_loss = -13.759, learner_queue_size = 64, _tick = 11175, _time = 1.6548e+09)
[2022-06-09 20:02:18,230][root][INFO] - Step 71557120 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 2.2901e+04, step = 71557120, mean_episode_return = 136.14, mean_episode_step = 1507.6, total_loss = 184.07, pg_loss = 159.96, baseline_loss = 37.93, entropy_loss = -13.823, learner_queue_size = 64, _tick = 11178, _time = 1.6548e+09)
[2022-06-09 20:02:23,234][root][INFO] - Step 71572480 @ 3069.6 SPS. Inference batcher size: 58. Learner queue size: 64. Other stats: (train_seconds = 2.2906e+04, step = 71572480, mean_episode_return = 34.439, mean_episode_step = 1823.5, total_loss = -173.51, pg_loss = -190.59, baseline_loss = 31.081, entropy_loss = -14.001, learner_queue_size = 64, _tick = 11181, _time = 1.6548e+09)
[2022-06-09 20:02:28,239][root][INFO] - Step 71582720 @ 2046.0 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 2.2911e+04, step = 71582720, mean_episode_return = None, mean_episode_step = 1753.0, total_loss = -27.652, pg_loss = -43.079, baseline_loss = 29.444, entropy_loss = -14.017, learner_queue_size = 64, _tick = 11182, _time = 1.6548e+09)
[2022-06-09 20:02:33,242][root][INFO] - Step 71598080 @ 3070.1 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 2.2916e+04, step = 71598080, mean_episode_return = 59.079, mean_episode_step = 1769.3, total_loss = -85.933, pg_loss = -105.38, baseline_loss = 33.445, entropy_loss = -14.001, learner_queue_size = 64, _tick = 11185, _time = 1.6548e+09)
[2022-06-09 20:02:38,246][root][INFO] - Step 71613440 @ 3069.5 SPS. Inference batcher size: 65. Learner queue size: 64. Other stats: (train_seconds = 2.2921e+04, step = 71613440, mean_episode_return = 39.196, mean_episode_step = 1761.0, total_loss = -83.593, pg_loss = -103.47, baseline_loss = 33.925, entropy_loss = -14.051, learner_queue_size = 64, _tick = 11186, _time = 1.6548e+09)
[2022-06-09 20:02:43,250][root][INFO] - Step 71628800 @ 3069.6 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 2.2926e+04, step = 71628800, mean_episode_return = 80.764, mean_episode_step = 1800.8, total_loss = -146.35, pg_loss = -165.43, baseline_loss = 33.178, entropy_loss = -14.102, learner_queue_size = 64, _tick = 11188, _time = 1.6548e+09)
[2022-06-09 20:02:48,254][root][INFO] - Step 71644160 @ 3069.5 SPS. Inference batcher size: 79. Learner queue size: 64. Other stats: (train_seconds = 2.2931e+04, step = 71644160, mean_episode_return = 20.99, mean_episode_step = 1805.2, total_loss = -104.62, pg_loss = -111.19, baseline_loss = 20.495, entropy_loss = -13.918, learner_queue_size = 64, _tick = 11191, _time = 1.6548e+09)
[2022-06-09 20:02:53,258][root][INFO] - Step 71654400 @ 2046.4 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 2.2936e+04, step = 71654400, mean_episode_return = 28.309, mean_episode_step = 1853.9, total_loss = 8.5569, pg_loss = -3.6677, baseline_loss = 26.197, entropy_loss = -13.972, learner_queue_size = 64, _tick = 11193, _time = 1.6548e+09)
[2022-06-09 20:02:58,262][root][INFO] - Step 71669760 @ 3069.6 SPS. Inference batcher size: 7. Learner queue size: 64. Other stats: (train_seconds = 2.2941e+04, step = 71669760, mean_episode_return = 93.448, mean_episode_step = 1719.8, total_loss = -137.17, pg_loss = -141.78, baseline_loss = 18.558, entropy_loss = -13.94, learner_queue_size = 64, _tick = 11196, _time = 1.6548e+09)
[2022-06-09 20:03:03,266][root][INFO] - Step 71685120 @ 3069.5 SPS. Inference batcher size: 17. Learner queue size: 64. Other stats: (train_seconds = 2.2946e+04, step = 71685120, mean_episode_return = None, mean_episode_step = 1796.8, total_loss = -89.869, pg_loss = -89.892, baseline_loss = 13.963, entropy_loss = -13.941, learner_queue_size = 64, _tick = 11198, _time = 1.6548e+09)
[2022-06-09 20:03:08,270][root][INFO] - Step 71700480 @ 3069.5 SPS. Inference batcher size: 94. Learner queue size: 64. Other stats: (train_seconds = 2.2951e+04, step = 71700480, mean_episode_return = 64.746, mean_episode_step = 1732.1, total_loss = 126.98, pg_loss = 103.41, baseline_loss = 37.64, entropy_loss = -14.072, learner_queue_size = 64, _tick = 11200, _time = 1.6548e+09)
[2022-06-09 20:03:13,274][root][INFO] - Step 71710720 @ 2046.3 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 2.2956e+04, step = 71710720, mean_episode_return = 39.711, mean_episode_step = 1828.5, total_loss = -74.119, pg_loss = -83.37, baseline_loss = 23.356, entropy_loss = -14.105, learner_queue_size = 64, _tick = 11202, _time = 1.6548e+09)
[2022-06-09 20:03:18,280][root][INFO] - Step 71726080 @ 3068.3 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 2.2961e+04, step = 71726080, mean_episode_return = 30.301, mean_episode_step = 1719.0, total_loss = -203.12, pg_loss = -214.04, baseline_loss = 25.094, entropy_loss = -14.167, learner_queue_size = 64, _tick = 11205, _time = 1.6548e+09)
[2022-06-09 20:03:23,286][root][INFO] - Step 71741440 @ 3068.4 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 2.2966e+04, step = 71741440, mean_episode_return = 83.374, mean_episode_step = 1693.9, total_loss = -265.12, pg_loss = -263.88, baseline_loss = 12.98, entropy_loss = -14.211, learner_queue_size = 64, _tick = 11208, _time = 1.6548e+09)
[2022-06-09 20:03:28,290][root][INFO] - Step 71756800 @ 3069.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 2.2971e+04, step = 71756800, mean_episode_return = 10.776, mean_episode_step = 1735.8, total_loss = 40.366, pg_loss = 24.656, baseline_loss = 29.849, entropy_loss = -14.138, learner_queue_size = 64, _tick = 11211, _time = 1.6548e+09)
[2022-06-09 20:03:33,294][root][INFO] - Step 71772160 @ 3069.6 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 2.2976e+04, step = 71772160, mean_episode_return = 105.64, mean_episode_step = 1573.6, total_loss = -121.38, pg_loss = -135.85, baseline_loss = 28.562, entropy_loss = -14.089, learner_queue_size = 64, _tick = 11213, _time = 1.6548e+09)
[2022-06-09 20:03:38,298][root][INFO] - Step 71782400 @ 2046.4 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 2.2981e+04, step = 71782400, mean_episode_return = 23.334, mean_episode_step = 1683.6, total_loss = -147.02, pg_loss = -162.68, baseline_loss = 29.742, entropy_loss = -14.085, learner_queue_size = 64, _tick = 11215, _time = 1.6548e+09)
[2022-06-09 20:03:43,302][root][INFO] - Step 71797760 @ 3069.5 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 2.2986e+04, step = 71797760, mean_episode_return = 28.741, mean_episode_step = 1791.8, total_loss = 63.224, pg_loss = 43.648, baseline_loss = 33.741, entropy_loss = -14.166, learner_queue_size = 64, _tick = 11218, _time = 1.6548e+09)
[2022-06-09 20:03:48,306][root][INFO] - Step 71813120 @ 3069.6 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 2.2991e+04, step = 71813120, mean_episode_return = 50.567, mean_episode_step = 1640.0, total_loss = -180.27, pg_loss = -185.13, baseline_loss = 18.916, entropy_loss = -14.06, learner_queue_size = 64, _tick = 11220, _time = 1.6548e+09)
[2022-06-09 20:03:53,310][root][INFO] - Step 71828480 @ 3069.5 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 2.2996e+04, step = 71828480, mean_episode_return = None, mean_episode_step = 1259.8, total_loss = 137.9, pg_loss = 118.04, baseline_loss = 33.909, entropy_loss = -14.052, learner_queue_size = 64, _tick = 11222, _time = 1.6548e+09)
[2022-06-09 20:03:58,314][root][INFO] - Step 71843840 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 2.3001e+04, step = 71843840, mean_episode_return = 58.971, mean_episode_step = 1601.5, total_loss = -92.847, pg_loss = -105.43, baseline_loss = 26.539, entropy_loss = -13.96, learner_queue_size = 64, _tick = 11225, _time = 1.6548e+09)
[2022-06-09 20:04:03,318][root][INFO] - Step 71854080 @ 2046.4 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 2.3006e+04, step = 71854080, mean_episode_return = 44.598, mean_episode_step = 1525.3, total_loss = -146.42, pg_loss = -155.1, baseline_loss = 22.738, entropy_loss = -14.056, learner_queue_size = 64, _tick = 11227, _time = 1.6548e+09)
[2022-06-09 20:04:08,322][root][INFO] - Step 71869440 @ 3069.5 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 2.3011e+04, step = 71869440, mean_episode_return = 50.726, mean_episode_step = 1413.0, total_loss = -198.22, pg_loss = -209.91, baseline_loss = 25.628, entropy_loss = -13.931, learner_queue_size = 64, _tick = 11230, _time = 1.6548e+09)
[2022-06-09 20:04:13,326][root][INFO] - Step 71884800 @ 3069.6 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 2.3016e+04, step = 71884800, mean_episode_return = 47.671, mean_episode_step = 1780.6, total_loss = 129.8, pg_loss = 99.073, baseline_loss = 44.613, entropy_loss = -13.891, learner_queue_size = 64, _tick = 11233, _time = 1.6548e+09)
[2022-06-09 20:04:18,336][root][INFO] - Step 71900160 @ 3065.6 SPS. Inference batcher size: 74. Learner queue size: 64. Other stats: (train_seconds = 2.3021e+04, step = 71900160, mean_episode_return = 28.245, mean_episode_step = 1484.6, total_loss = -76.401, pg_loss = -96.503, baseline_loss = 34.21, entropy_loss = -14.108, learner_queue_size = 64, _tick = 11236, _time = 1.6548e+09)
[2022-06-09 20:04:23,342][root][INFO] - Step 71915520 @ 3068.4 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 2.3026e+04, step = 71915520, mean_episode_return = 69.962, mean_episode_step = 1764.3, total_loss = -40.474, pg_loss = -55.592, baseline_loss = 29.178, entropy_loss = -14.061, learner_queue_size = 64, _tick = 11239, _time = 1.6548e+09)
[2022-06-09 20:04:28,346][root][INFO] - Step 71930880 @ 3069.7 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 2.3031e+04, step = 71930880, mean_episode_return = 66.34, mean_episode_step = 1663.7, total_loss = 355.31, pg_loss = 299.38, baseline_loss = 70.02, entropy_loss = -14.096, learner_queue_size = 64, _tick = 11242, _time = 1.6548e+09)
[2022-06-09 20:04:33,350][root][INFO] - Step 71941120 @ 2046.4 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 2.3036e+04, step = 71941120, mean_episode_return = 91.489, mean_episode_step = 1552.6, total_loss = -274.37, pg_loss = -270.77, baseline_loss = 10.46, entropy_loss = -14.057, learner_queue_size = 64, _tick = 11244, _time = 1.6548e+09)
[2022-06-09 20:04:38,355][root][INFO] - Step 71956480 @ 3069.0 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 2.3041e+04, step = 71956480, mean_episode_return = -11.91, mean_episode_step = 1594.4, total_loss = -57.794, pg_loss = -62.024, baseline_loss = 18.158, entropy_loss = -13.927, learner_queue_size = 64, _tick = 11247, _time = 1.6548e+09)
[2022-06-09 20:04:43,362][root][INFO] - Step 71971840 @ 3067.6 SPS. Inference batcher size: 10. Learner queue size: 64. Other stats: (train_seconds = 2.3046e+04, step = 71971840, mean_episode_return = None, mean_episode_step = 1860.6, total_loss = 241.8, pg_loss = 213.53, baseline_loss = 42.185, entropy_loss = -13.91, learner_queue_size = 64, _tick = 11248, _time = 1.6548e+09)
[2022-06-09 20:04:48,366][root][INFO] - Step 71987200 @ 3069.5 SPS. Inference batcher size: 45. Learner queue size: 64. Other stats: (train_seconds = 2.3051e+04, step = 71987200, mean_episode_return = 39.54, mean_episode_step = 1646.0, total_loss = 83.979, pg_loss = 47.819, baseline_loss = 50.069, entropy_loss = -13.909, learner_queue_size = 64, _tick = 11250, _time = 1.6548e+09)
[2022-06-09 20:04:53,373][root][INFO] - Step 72002560 @ 3067.7 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 2.3056e+04, step = 72002560, mean_episode_return = 104.14, mean_episode_step = 1839.3, total_loss = 146.07, pg_loss = 90.281, baseline_loss = 69.731, entropy_loss = -13.939, learner_queue_size = 64, _tick = 11253, _time = 1.6548e+09)
[2022-06-09 20:04:58,378][root][INFO] - Step 72017920 @ 3069.0 SPS. Inference batcher size: 88. Learner queue size: 64. Other stats: (train_seconds = 2.3061e+04, step = 72017920, mean_episode_return = 56.901, mean_episode_step = 1776.1, total_loss = -67.927, pg_loss = -75.26, baseline_loss = 21.397, entropy_loss = -14.065, learner_queue_size = 64, _tick = 11256, _time = 1.6548e+09)
[2022-06-09 20:05:03,382][root][INFO] - Step 72028160 @ 2046.4 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 2.3066e+04, step = 72028160, mean_episode_return = 63.009, mean_episode_step = 1914.9, total_loss = -123.79, pg_loss = -125.98, baseline_loss = 16.289, entropy_loss = -14.104, learner_queue_size = 64, _tick = 11258, _time = 1.6548e+09)
[2022-06-09 20:05:08,386][root][INFO] - Step 72043520 @ 3069.4 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 2.3071e+04, step = 72043520, mean_episode_return = 45.154, mean_episode_step = 1688.2, total_loss = -79.932, pg_loss = -98.646, baseline_loss = 32.899, entropy_loss = -14.185, learner_queue_size = 64, _tick = 11261, _time = 1.6548e+09)
[2022-06-09 20:05:13,390][root][INFO] - Step 72058880 @ 3069.7 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 2.3076e+04, step = 72058880, mean_episode_return = 14.065, mean_episode_step = 1670.4, total_loss = 280.99, pg_loss = 245.81, baseline_loss = 49.312, entropy_loss = -14.13, learner_queue_size = 64, _tick = 11263, _time = 1.6548e+09)
[2022-06-09 20:05:18,394][root][INFO] - Step 72074240 @ 3069.5 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 2.3081e+04, step = 72074240, mean_episode_return = 42.649, mean_episode_step = 1782.6, total_loss = -84.287, pg_loss = -105.59, baseline_loss = 35.399, entropy_loss = -14.093, learner_queue_size = 64, _tick = 11266, _time = 1.6548e+09)
[2022-06-09 20:05:23,398][root][INFO] - Step 72089600 @ 3069.5 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 2.3086e+04, step = 72089600, mean_episode_return = 42.312, mean_episode_step = 1704.4, total_loss = -325.73, pg_loss = -346.83, baseline_loss = 34.873, entropy_loss = -13.783, learner_queue_size = 64, _tick = 11269, _time = 1.6548e+09)
[2022-06-09 20:05:28,402][root][INFO] - Step 72099840 @ 2046.3 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 2.3091e+04, step = 72099840, mean_episode_return = 11.328, mean_episode_step = 1838.6, total_loss = -182.3, pg_loss = -216.18, baseline_loss = 47.987, entropy_loss = -14.111, learner_queue_size = 64, _tick = 11271, _time = 1.6548e+09)
[2022-06-09 20:05:33,406][root][INFO] - Step 72115200 @ 3069.5 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 2.3096e+04, step = 72115200, mean_episode_return = 45.071, mean_episode_step = 1711.9, total_loss = 144.83, pg_loss = 90.2, baseline_loss = 68.546, entropy_loss = -13.911, learner_queue_size = 64, _tick = 11274, _time = 1.6548e+09)
[2022-06-09 20:05:38,410][root][INFO] - Step 72130560 @ 3069.6 SPS. Inference batcher size: 60. Learner queue size: 64. Other stats: (train_seconds = 2.3101e+04, step = 72130560, mean_episode_return = 62.73, mean_episode_step = 1798.5, total_loss = 13.473, pg_loss = -4.066, baseline_loss = 31.376, entropy_loss = -13.836, learner_queue_size = 64, _tick = 11277, _time = 1.6548e+09)
[2022-06-09 20:05:43,416][root][INFO] - Step 72145920 @ 3068.2 SPS. Inference batcher size: 11. Learner queue size: 64. Other stats: (train_seconds = 2.3106e+04, step = 72145920, mean_episode_return = 92.421, mean_episode_step = 1682.1, total_loss = -16.598, pg_loss = -53.955, baseline_loss = 51.106, entropy_loss = -13.749, learner_queue_size = 64, _tick = 11280, _time = 1.6548e+09)
[2022-06-09 20:05:48,422][root][INFO] - Step 72156160 @ 2045.6 SPS. Inference batcher size: 19. Learner queue size: 64. Other stats: (train_seconds = 2.3111e+04, step = 72156160, mean_episode_return = 48.902, mean_episode_step = 1545.7, total_loss = -42.168, pg_loss = -59.221, baseline_loss = 30.634, entropy_loss = -13.582, learner_queue_size = 64, _tick = 11281, _time = 1.6548e+09)
[2022-06-09 20:05:53,427][root][INFO] - Step 72171520 @ 3069.2 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 2.3116e+04, step = 72171520, mean_episode_return = 54.211, mean_episode_step = 1820.0, total_loss = -2.782, pg_loss = -19.269, baseline_loss = 29.982, entropy_loss = -13.495, learner_queue_size = 64, _tick = 11284, _time = 1.6548e+09)
[2022-06-09 20:05:58,430][root][INFO] - Step 72186880 @ 3069.9 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 2.3121e+04, step = 72186880, mean_episode_return = 44.827, mean_episode_step = 1590.0, total_loss = -180.82, pg_loss = -191.62, baseline_loss = 24.294, entropy_loss = -13.496, learner_queue_size = 64, _tick = 11286, _time = 1.6548e+09)
[2022-06-09 20:06:03,434][root][INFO] - Step 72202240 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 2.3126e+04, step = 72202240, mean_episode_return = 55.566, mean_episode_step = 1614.7, total_loss = -46.37, pg_loss = -72.794, baseline_loss = 39.997, entropy_loss = -13.573, learner_queue_size = 64, _tick = 11288, _time = 1.6548e+09)
[2022-06-09 20:06:08,438][root][INFO] - Step 72217600 @ 3069.6 SPS. Inference batcher size: 53. Learner queue size: 64. Other stats: (train_seconds = 2.3131e+04, step = 72217600, mean_episode_return = 62.286, mean_episode_step = 1601.2, total_loss = 64.947, pg_loss = 28.936, baseline_loss = 49.52, entropy_loss = -13.51, learner_queue_size = 64, _tick = 11291, _time = 1.6548e+09)
[2022-06-09 20:06:13,443][root][INFO] - Step 72232960 @ 3068.6 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 2.3136e+04, step = 72232960, mean_episode_return = 65.061, mean_episode_step = 1668.7, total_loss = 138.54, pg_loss = 109.36, baseline_loss = 42.751, entropy_loss = -13.57, learner_queue_size = 64, _tick = 11293, _time = 1.6548e+09)
[2022-06-09 20:06:18,446][root][INFO] - Step 72248320 @ 3070.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 2.3141e+04, step = 72248320, mean_episode_return = None, mean_episode_step = 1992.3, total_loss = -116.8, pg_loss = -117.3, baseline_loss = 13.891, entropy_loss = -13.398, learner_queue_size = 64, _tick = 11295, _time = 1.6548e+09)
[2022-06-09 20:06:23,451][root][INFO] - Step 72258560 @ 2046.2 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 2.3146e+04, step = 72258560, mean_episode_return = 64.393, mean_episode_step = 1930.5, total_loss = -93.474, pg_loss = -124.59, baseline_loss = 44.538, entropy_loss = -13.422, learner_queue_size = 64, _tick = 11297, _time = 1.6548e+09)
[2022-06-09 20:06:28,454][root][INFO] - Step 72273920 @ 3069.8 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 2.3151e+04, step = 72273920, mean_episode_return = 50.095, mean_episode_step = 1711.8, total_loss = 12.108, pg_loss = -13.908, baseline_loss = 39.49, entropy_loss = -13.474, learner_queue_size = 64, _tick = 11300, _time = 1.6548e+09)
[2022-06-09 20:06:33,458][root][INFO] - Step 72289280 @ 3069.6 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 2.3156e+04, step = 72289280, mean_episode_return = 19.025, mean_episode_step = 1681.9, total_loss = -36.399, pg_loss = -51.97, baseline_loss = 29.026, entropy_loss = -13.455, learner_queue_size = 64, _tick = 11303, _time = 1.6548e+09)
[2022-06-09 20:06:38,462][root][INFO] - Step 72304640 @ 3069.5 SPS. Inference batcher size: 73. Learner queue size: 64. Other stats: (train_seconds = 2.3161e+04, step = 72304640, mean_episode_return = 159.68, mean_episode_step = 1846.3, total_loss = -189.09, pg_loss = -186.24, baseline_loss = 10.616, entropy_loss = -13.467, learner_queue_size = 64, _tick = 11306, _time = 1.6548e+09)
[2022-06-09 20:06:43,466][root][INFO] - Step 72320000 @ 3069.5 SPS. Inference batcher size: 94. Learner queue size: 64. Other stats: (train_seconds = 2.3166e+04, step = 72320000, mean_episode_return = 78.838, mean_episode_step = 1657.6, total_loss = -137.82, pg_loss = -165.07, baseline_loss = 40.813, entropy_loss = -13.558, learner_queue_size = 64, _tick = 11308, _time = 1.6548e+09)
[2022-06-09 20:06:48,470][root][INFO] - Step 72335360 @ 3069.5 SPS. Inference batcher size: 6. Learner queue size: 64. Other stats: (train_seconds = 2.3171e+04, step = 72335360, mean_episode_return = 43.794, mean_episode_step = 1959.3, total_loss = 33.92, pg_loss = 5.027, baseline_loss = 42.634, entropy_loss = -13.742, learner_queue_size = 64, _tick = 11310, _time = 1.6548e+09)
[2022-06-09 20:06:53,474][root][INFO] - Step 72345600 @ 2046.3 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 2.3176e+04, step = 72345600, mean_episode_return = 54.265, mean_episode_step = 1648.0, total_loss = 219.17, pg_loss = 187.31, baseline_loss = 45.587, entropy_loss = -13.733, learner_queue_size = 64, _tick = 11312, _time = 1.6548e+09)
[2022-06-09 20:06:58,478][root][INFO] - Step 72360960 @ 3069.6 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 2.3181e+04, step = 72360960, mean_episode_return = 6.6569, mean_episode_step = 1641.4, total_loss = -14.476, pg_loss = -50.584, baseline_loss = 49.945, entropy_loss = -13.836, learner_queue_size = 64, _tick = 11313, _time = 1.6548e+09)
[2022-06-09 20:07:03,482][root][INFO] - Step 72376320 @ 3069.6 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 2.3186e+04, step = 72376320, mean_episode_return = 28.931, mean_episode_step = 1569.4, total_loss = 533.75, pg_loss = 309.51, baseline_loss = 238.08, entropy_loss = -13.845, learner_queue_size = 64, _tick = 11315, _time = 1.6548e+09)
[2022-06-09 20:07:08,486][root][INFO] - Step 72391680 @ 3069.5 SPS. Inference batcher size: 84. Learner queue size: 64. Other stats: (train_seconds = 2.3191e+04, step = 72391680, mean_episode_return = 57.176, mean_episode_step = 1743.6, total_loss = -196.89, pg_loss = -191.37, baseline_loss = 8.3291, entropy_loss = -13.845, learner_queue_size = 64, _tick = 11318, _time = 1.6548e+09)
[2022-06-09 20:07:13,490][root][INFO] - Step 72407040 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 2.3196e+04, step = 72407040, mean_episode_return = 23.681, mean_episode_step = 1831.7, total_loss = 136.16, pg_loss = 117.42, baseline_loss = 32.546, entropy_loss = -13.806, learner_queue_size = 64, _tick = 11320, _time = 1.6548e+09)
[2022-06-09 20:07:18,494][root][INFO] - Step 72422400 @ 3069.6 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 2.3201e+04, step = 72422400, mean_episode_return = 63.418, mean_episode_step = 1719.2, total_loss = 187.37, pg_loss = 140.04, baseline_loss = 61.164, entropy_loss = -13.836, learner_queue_size = 64, _tick = 11322, _time = 1.6548e+09)
[2022-06-09 20:07:23,498][root][INFO] - Step 72437760 @ 3069.5 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 2.3206e+04, step = 72437760, mean_episode_return = 34.019, mean_episode_step = 1840.1, total_loss = 73.492, pg_loss = 43.951, baseline_loss = 43.393, entropy_loss = -13.852, learner_queue_size = 64, _tick = 11325, _time = 1.6548e+09)
[2022-06-09 20:07:28,502][root][INFO] - Step 72453120 @ 3069.5 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 2.3211e+04, step = 72453120, mean_episode_return = 35.92, mean_episode_step = 1795.8, total_loss = 16.562, pg_loss = -15.75, baseline_loss = 46.12, entropy_loss = -13.808, learner_queue_size = 64, _tick = 11328, _time = 1.6548e+09)
[2022-06-09 20:07:33,506][root][INFO] - Step 72468480 @ 3069.5 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 2.3216e+04, step = 72468480, mean_episode_return = 25.705, mean_episode_step = 1853.8, total_loss = -173.08, pg_loss = -178.57, baseline_loss = 19.276, entropy_loss = -13.783, learner_queue_size = 64, _tick = 11331, _time = 1.6548e+09)
[2022-06-09 20:07:38,510][root][INFO] - Step 72488960 @ 4092.8 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 2.3221e+04, step = 72488960, mean_episode_return = 50.756, mean_episode_step = 1791.5, total_loss = -182.1, pg_loss = -182.14, baseline_loss = 13.804, entropy_loss = -13.774, learner_queue_size = 64, _tick = 11335, _time = 1.6548e+09)
[2022-06-09 20:07:43,514][root][INFO] - Step 72504320 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 2.3226e+04, step = 72504320, mean_episode_return = 40.419, mean_episode_step = 1893.1, total_loss = 188.14, pg_loss = 132.95, baseline_loss = 68.83, entropy_loss = -13.632, learner_queue_size = 64, _tick = 11338, _time = 1.6548e+09)
[2022-06-09 20:07:48,518][root][INFO] - Step 72519680 @ 3069.5 SPS. Inference batcher size: 81. Learner queue size: 64. Other stats: (train_seconds = 2.3232e+04, step = 72519680, mean_episode_return = 46.486, mean_episode_step = 2017.7, total_loss = -203.19, pg_loss = -201.46, baseline_loss = 11.824, entropy_loss = -13.559, learner_queue_size = 64, _tick = 11341, _time = 1.6548e+09)
[2022-06-09 20:07:53,522][root][INFO] - Step 72535040 @ 3069.5 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 2.3236e+04, step = 72535040, mean_episode_return = 4.9596, mean_episode_step = 1649.0, total_loss = 118.34, pg_loss = 105.55, baseline_loss = 26.488, entropy_loss = -13.694, learner_queue_size = 64, _tick = 11344, _time = 1.6548e+09)
[2022-06-09 20:07:58,526][root][INFO] - Step 72550400 @ 3069.6 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 2.3242e+04, step = 72550400, mean_episode_return = 34.924, mean_episode_step = 1792.1, total_loss = 75.328, pg_loss = 58.482, baseline_loss = 30.598, entropy_loss = -13.752, learner_queue_size = 64, _tick = 11347, _time = 1.6548e+09)
[2022-06-09 20:08:03,530][root][INFO] - Step 72565760 @ 3069.4 SPS. Inference batcher size: 88. Learner queue size: 64. Other stats: (train_seconds = 2.3246e+04, step = 72565760, mean_episode_return = 8.4397, mean_episode_step = 1762.1, total_loss = -27.583, pg_loss = -35.601, baseline_loss = 21.796, entropy_loss = -13.779, learner_queue_size = 64, _tick = 11350, _time = 1.6548e+09)
[2022-06-09 20:08:08,534][root][INFO] - Step 72576000 @ 2046.3 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 2.3252e+04, step = 72576000, mean_episode_return = 22.407, mean_episode_step = 1441.7, total_loss = 255.11, pg_loss = 195.56, baseline_loss = 73.36, entropy_loss = -13.809, learner_queue_size = 64, _tick = 11351, _time = 1.6548e+09)
[2022-06-09 20:08:13,538][root][INFO] - Step 72591360 @ 3069.7 SPS. Inference batcher size: 66. Learner queue size: 64. Other stats: (train_seconds = 2.3256e+04, step = 72591360, mean_episode_return = 70.757, mean_episode_step = 1717.5, total_loss = 312.76, pg_loss = 252.68, baseline_loss = 73.987, entropy_loss = -13.907, learner_queue_size = 64, _tick = 11354, _time = 1.6548e+09)
[2022-06-09 20:08:18,542][root][INFO] - Step 72606720 @ 3069.5 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 2.3262e+04, step = 72606720, mean_episode_return = 101.18, mean_episode_step = 1710.7, total_loss = -15.333, pg_loss = -25.206, baseline_loss = 23.766, entropy_loss = -13.894, learner_queue_size = 64, _tick = 11357, _time = 1.6548e+09)
[2022-06-09 20:08:23,546][root][INFO] - Step 72622080 @ 3069.5 SPS. Inference batcher size: 98. Learner queue size: 64. Other stats: (train_seconds = 2.3266e+04, step = 72622080, mean_episode_return = 13.18, mean_episode_step = 1596.7, total_loss = 269.36, pg_loss = 203.23, baseline_loss = 80.131, entropy_loss = -14.001, learner_queue_size = 64, _tick = 11360, _time = 1.6548e+09)
[2022-06-09 20:08:28,550][root][INFO] - Step 72632320 @ 2046.3 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 2.3272e+04, step = 72632320, mean_episode_return = 42.538, mean_episode_step = 1700.7, total_loss = 49.621, pg_loss = 27.593, baseline_loss = 35.963, entropy_loss = -13.935, learner_queue_size = 64, _tick = 11362, _time = 1.6548e+09)
[2022-06-09 20:08:33,554][root][INFO] - Step 72647680 @ 3069.6 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 2.3276e+04, step = 72647680, mean_episode_return = 58.273, mean_episode_step = 1594.4, total_loss = -9.8897, pg_loss = -41.175, baseline_loss = 45.321, entropy_loss = -14.035, learner_queue_size = 64, _tick = 11365, _time = 1.6548e+09)
[2022-06-09 20:08:38,558][root][INFO] - Step 72663040 @ 3069.5 SPS. Inference batcher size: 52. Learner queue size: 64. Other stats: (train_seconds = 2.3282e+04, step = 72663040, mean_episode_return = 22.1, mean_episode_step = 1654.8, total_loss = 189.46, pg_loss = 154.38, baseline_loss = 48.92, entropy_loss = -13.84, learner_queue_size = 64, _tick = 11367, _time = 1.6548e+09)
[2022-06-09 20:08:43,562][root][INFO] - Step 72678400 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 2.3286e+04, step = 72678400, mean_episode_return = 57.563, mean_episode_step = 1629.9, total_loss = 451.55, pg_loss = 261.76, baseline_loss = 203.63, entropy_loss = -13.846, learner_queue_size = 64, _tick = 11369, _time = 1.6548e+09)
[2022-06-09 20:08:48,566][root][INFO] - Step 72693760 @ 3069.5 SPS. Inference batcher size: 95. Learner queue size: 64. Other stats: (train_seconds = 2.3292e+04, step = 72693760, mean_episode_return = None, mean_episode_step = 1860.5, total_loss = 140.18, pg_loss = 96.364, baseline_loss = 57.702, entropy_loss = -13.885, learner_queue_size = 64, _tick = 11371, _time = 1.6548e+09)
[2022-06-09 20:08:53,570][root][INFO] - Step 72704000 @ 2046.4 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 2.3296e+04, step = 72704000, mean_episode_return = 56.521, mean_episode_step = 1728.7, total_loss = -82.5, pg_loss = -109.2, baseline_loss = 40.523, entropy_loss = -13.82, learner_queue_size = 64, _tick = 11373, _time = 1.6548e+09)
[2022-06-09 20:08:58,574][root][INFO] - Step 72719360 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 2.3302e+04, step = 72719360, mean_episode_return = 26.423, mean_episode_step = 1869.9, total_loss = -205.11, pg_loss = -200.35, baseline_loss = 9.1114, entropy_loss = -13.869, learner_queue_size = 64, _tick = 11376, _time = 1.6548e+09)
[2022-06-09 20:09:03,579][root][INFO] - Step 72734720 @ 3069.5 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 2.3306e+04, step = 72734720, mean_episode_return = 49.591, mean_episode_step = 1613.3, total_loss = 90.5, pg_loss = 58.665, baseline_loss = 45.825, entropy_loss = -13.99, learner_queue_size = 64, _tick = 11378, _time = 1.6548e+09)
[2022-06-09 20:09:08,593][root][INFO] - Step 72750080 @ 3063.0 SPS. Inference batcher size: 68. Learner queue size: 64. Other stats: (train_seconds = 2.3312e+04, step = 72750080, mean_episode_return = None, mean_episode_step = 1731.5, total_loss = 235.59, pg_loss = 165.12, baseline_loss = 84.606, entropy_loss = -14.133, learner_queue_size = 64, _tick = 11380, _time = 1.6548e+09)
[2022-06-09 20:09:13,598][root][INFO] - Step 72765440 @ 3068.8 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 2.3316e+04, step = 72765440, mean_episode_return = 37.09, mean_episode_step = 1516.3, total_loss = 581.45, pg_loss = 365.62, baseline_loss = 229.9, entropy_loss = -14.063, learner_queue_size = 64, _tick = 11383, _time = 1.6548e+09)
[2022-06-09 20:09:18,602][root][INFO] - Step 72780800 @ 3069.3 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 2.3322e+04, step = 72780800, mean_episode_return = None, mean_episode_step = 1795.5, total_loss = -105.83, pg_loss = -116.96, baseline_loss = 25.165, entropy_loss = -14.036, learner_queue_size = 64, _tick = 11385, _time = 1.6548e+09)
[2022-06-09 20:09:23,606][root][INFO] - Step 72791040 @ 2046.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 2.3326e+04, step = 72791040, mean_episode_return = 44.693, mean_episode_step = 1654.8, total_loss = 79.67, pg_loss = 53.06, baseline_loss = 40.633, entropy_loss = -14.023, learner_queue_size = 64, _tick = 11387, _time = 1.6548e+09)
[2022-06-09 20:09:28,610][root][INFO] - Step 72806400 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 2.3332e+04, step = 72806400, mean_episode_return = 52.405, mean_episode_step = 1675.2, total_loss = 362.18, pg_loss = 298.43, baseline_loss = 77.809, entropy_loss = -14.059, learner_queue_size = 64, _tick = 11389, _time = 1.6548e+09)
[2022-06-09 20:09:33,614][root][INFO] - Step 72821760 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 2.3336e+04, step = 72821760, mean_episode_return = 44.68, mean_episode_step = 1738.6, total_loss = 251.91, pg_loss = 201.76, baseline_loss = 64.289, entropy_loss = -14.139, learner_queue_size = 64, _tick = 11392, _time = 1.6548e+09)
[2022-06-09 20:09:38,618][root][INFO] - Step 72837120 @ 3069.5 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 2.3342e+04, step = 72837120, mean_episode_return = 41.547, mean_episode_step = 1904.1, total_loss = 228.74, pg_loss = 189.07, baseline_loss = 53.818, entropy_loss = -14.143, learner_queue_size = 64, _tick = 11394, _time = 1.6548e+09)
[2022-06-09 20:09:43,623][root][INFO] - Step 72852480 @ 3068.9 SPS. Inference batcher size: 20. Learner queue size: 64. Other stats: (train_seconds = 2.3347e+04, step = 72852480, mean_episode_return = 35.883, mean_episode_step = 1584.7, total_loss = 208.84, pg_loss = 121.03, baseline_loss = 102.05, entropy_loss = -14.244, learner_queue_size = 64, _tick = 11397, _time = 1.6548e+09)
[2022-06-09 20:09:48,626][root][INFO] - Step 72862720 @ 2046.7 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 2.3352e+04, step = 72862720, mean_episode_return = 75.739, mean_episode_step = 1955.2, total_loss = -6.4849, pg_loss = -40.556, baseline_loss = 48.207, entropy_loss = -14.137, learner_queue_size = 64, _tick = 11398, _time = 1.6548e+09)
[2022-06-09 20:09:53,630][root][INFO] - Step 72878080 @ 3069.6 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 2.3357e+04, step = 72878080, mean_episode_return = 54.199, mean_episode_step = 1990.4, total_loss = 288.17, pg_loss = 205.76, baseline_loss = 96.561, entropy_loss = -14.156, learner_queue_size = 64, _tick = 11401, _time = 1.6548e+09)
[2022-06-09 20:09:58,635][root][INFO] - Step 72893440 @ 3069.2 SPS. Inference batcher size: 16. Learner queue size: 64. Other stats: (train_seconds = 2.3362e+04, step = 72893440, mean_episode_return = None, mean_episode_step = 1809.2, total_loss = -163.98, pg_loss = -158.99, baseline_loss = 9.3042, entropy_loss = -14.294, learner_queue_size = 64, _tick = 11403, _time = 1.6548e+09)
[2022-06-09 20:10:03,638][root][INFO] - Step 72908800 @ 3069.7 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 2.3367e+04, step = 72908800, mean_episode_return = 58.969, mean_episode_step = 1738.8, total_loss = -136.86, pg_loss = -148.79, baseline_loss = 26.293, entropy_loss = -14.363, learner_queue_size = 64, _tick = 11406, _time = 1.6548e+09)
[2022-06-09 20:10:08,642][root][INFO] - Step 72924160 @ 3069.6 SPS. Inference batcher size: 46. Learner queue size: 64. Other stats: (train_seconds = 2.3372e+04, step = 72924160, mean_episode_return = 11.58, mean_episode_step = 1595.0, total_loss = 233.42, pg_loss = 154.88, baseline_loss = 92.866, entropy_loss = -14.327, learner_queue_size = 64, _tick = 11409, _time = 1.6548e+09)
[2022-06-09 20:10:13,646][root][INFO] - Step 72934400 @ 2046.4 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 2.3377e+04, step = 72934400, mean_episode_return = 46.081, mean_episode_step = 1783.4, total_loss = 107.35, pg_loss = 72.809, baseline_loss = 48.988, entropy_loss = -14.447, learner_queue_size = 64, _tick = 11411, _time = 1.6548e+09)
[2022-06-09 20:10:18,650][root][INFO] - Step 72949760 @ 3069.5 SPS. Inference batcher size: 24. Learner queue size: 64. Other stats: (train_seconds = 2.3382e+04, step = 72949760, mean_episode_return = 87.789, mean_episode_step = 1691.8, total_loss = -35.716, pg_loss = -52.527, baseline_loss = 31.599, entropy_loss = -14.788, learner_queue_size = 64, _tick = 11414, _time = 1.6548e+09)
[2022-06-09 20:10:23,655][root][INFO] - Step 72965120 @ 3068.7 SPS. Inference batcher size: 11. Learner queue size: 64. Other stats: (train_seconds = 2.3387e+04, step = 72965120, mean_episode_return = -38.23, mean_episode_step = 1711.6, total_loss = 2.5537, pg_loss = -8.1616, baseline_loss = 25.675, entropy_loss = -14.959, learner_queue_size = 64, _tick = 11416, _time = 1.6548e+09)
[2022-06-09 20:10:28,659][root][INFO] - Step 72980480 @ 3070.0 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 2.3392e+04, step = 72980480, mean_episode_return = 59.414, mean_episode_step = 1697.7, total_loss = -98.926, pg_loss = -126.7, baseline_loss = 42.528, entropy_loss = -14.75, learner_queue_size = 64, _tick = 11419, _time = 1.6548e+09)
[2022-06-09 20:10:33,662][root][INFO] - Step 72995840 @ 3069.9 SPS. Inference batcher size: 80. Learner queue size: 64. Other stats: (train_seconds = 2.3397e+04, step = 72995840, mean_episode_return = 46.75, mean_episode_step = 1876.0, total_loss = -188.98, pg_loss = -188.27, baseline_loss = 13.94, entropy_loss = -14.656, learner_queue_size = 64, _tick = 11422, _time = 1.6548e+09)
[2022-06-09 20:10:38,666][root][INFO] - Step 73011200 @ 3069.6 SPS. Inference batcher size: 80. Learner queue size: 64. Other stats: (train_seconds = 2.3402e+04, step = 73011200, mean_episode_return = 37.345, mean_episode_step = 1730.6, total_loss = -166.68, pg_loss = -172.52, baseline_loss = 20.547, entropy_loss = -14.711, learner_queue_size = 64, _tick = 11424, _time = 1.6548e+09)
[2022-06-09 20:10:43,670][root][INFO] - Step 73021440 @ 2046.4 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 2.3407e+04, step = 73021440, mean_episode_return = 43.474, mean_episode_step = 1727.9, total_loss = -188.49, pg_loss = -190.9, baseline_loss = 17.174, entropy_loss = -14.762, learner_queue_size = 64, _tick = 11426, _time = 1.6548e+09)
[2022-06-09 20:10:48,674][root][INFO] - Step 73036800 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 2.3412e+04, step = 73036800, mean_episode_return = 91.744, mean_episode_step = 1854.7, total_loss = -249.68, pg_loss = -249.49, baseline_loss = 14.641, entropy_loss = -14.824, learner_queue_size = 64, _tick = 11429, _time = 1.6548e+09)
[2022-06-09 20:10:53,678][root][INFO] - Step 73052160 @ 3069.5 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 2.3417e+04, step = 73052160, mean_episode_return = 120.57, mean_episode_step = 1660.1, total_loss = -273.71, pg_loss = -262.34, baseline_loss = 3.2048, entropy_loss = -14.575, learner_queue_size = 64, _tick = 11432, _time = 1.6548e+09)
[2022-06-09 20:10:58,682][root][INFO] - Step 73062400 @ 2046.4 SPS. Inference batcher size: 12. Learner queue size: 64. Other stats: (train_seconds = 2.3422e+04, step = 73062400, mean_episode_return = 92.803, mean_episode_step = 1542.5, total_loss = -29.07, pg_loss = -48.581, baseline_loss = 34.139, entropy_loss = -14.629, learner_queue_size = 64, _tick = 11434, _time = 1.6548e+09)
[2022-06-09 20:11:03,686][root][INFO] - Step 73077760 @ 3069.5 SPS. Inference batcher size: 93. Learner queue size: 64. Other stats: (train_seconds = 2.3427e+04, step = 73077760, mean_episode_return = 15.18, mean_episode_step = 1872.9, total_loss = 373.53, pg_loss = 316.88, baseline_loss = 71.155, entropy_loss = -14.51, learner_queue_size = 64, _tick = 11437, _time = 1.6548e+09)
[2022-06-09 20:11:08,690][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/13-40-28/checkpoint.tar
[2022-06-09 20:11:08,901][root][INFO] - Step 73093120 @ 3069.5 SPS. Inference batcher size: 44. Learner queue size: 64. Other stats: (train_seconds = 2.3432e+04, step = 73093120, mean_episode_return = 19.28, mean_episode_step = 1822.1, total_loss = 201.05, pg_loss = 167.48, baseline_loss = 47.989, entropy_loss = -14.412, learner_queue_size = 64, _tick = 11440, _time = 1.6548e+09)
[2022-06-09 20:11:13,906][root][INFO] - Step 73108480 @ 2944.9 SPS. Inference batcher size: 38. Learner queue size: 64. Other stats: (train_seconds = 2.3437e+04, step = 73108480, mean_episode_return = 15.544, mean_episode_step = 1777.0, total_loss = -125.45, pg_loss = -132.73, baseline_loss = 21.511, entropy_loss = -14.23, learner_queue_size = 64, _tick = 11443, _time = 1.6548e+09)
[2022-06-09 20:11:18,911][root][INFO] - Step 73118720 @ 2046.0 SPS. Inference batcher size: 15. Learner queue size: 64. Other stats: (train_seconds = 2.3442e+04, step = 73118720, mean_episode_return = 59.673, mean_episode_step = 1891.5, total_loss = -75.981, pg_loss = -88.614, baseline_loss = 26.768, entropy_loss = -14.135, learner_queue_size = 64, _tick = 11445, _time = 1.6548e+09)
[2022-06-09 20:11:23,918][root][INFO] - Step 73134080 @ 3067.6 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 2.3447e+04, step = 73134080, mean_episode_return = 29.942, mean_episode_step = 1428.9, total_loss = 246.39, pg_loss = 178.24, baseline_loss = 82.269, entropy_loss = -14.124, learner_queue_size = 64, _tick = 11448, _time = 1.6548e+09)
[2022-06-09 20:11:28,922][root][INFO] - Step 73149440 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 2.3452e+04, step = 73149440, mean_episode_return = 103.71, mean_episode_step = 1371.3, total_loss = 10.412, pg_loss = 4.2643, baseline_loss = 20.187, entropy_loss = -14.039, learner_queue_size = 64, _tick = 11451, _time = 1.6548e+09)
[2022-06-09 20:11:33,926][root][INFO] - Step 73164800 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 2.3457e+04, step = 73164800, mean_episode_return = 53.76, mean_episode_step = 1426.9, total_loss = 140.49, pg_loss = 114.19, baseline_loss = 40.287, entropy_loss = -13.988, learner_queue_size = 64, _tick = 11453, _time = 1.6548e+09)
[2022-06-09 20:11:38,930][root][INFO] - Step 73180160 @ 3069.6 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 2.3462e+04, step = 73180160, mean_episode_return = 49.174, mean_episode_step = 1752.4, total_loss = 70.904, pg_loss = 51.682, baseline_loss = 33.223, entropy_loss = -14.0, learner_queue_size = 64, _tick = 11456, _time = 1.6548e+09)
[2022-06-09 20:11:43,934][root][INFO] - Step 73195520 @ 3069.5 SPS. Inference batcher size: 55. Learner queue size: 64. Other stats: (train_seconds = 2.3467e+04, step = 73195520, mean_episode_return = 186.55, mean_episode_step = 1716.2, total_loss = 176.41, pg_loss = 148.81, baseline_loss = 41.529, entropy_loss = -13.93, learner_queue_size = 64, _tick = 11459, _time = 1.6548e+09)
[2022-06-09 20:11:48,938][root][INFO] - Step 73205760 @ 2046.4 SPS. Inference batcher size: 27. Learner queue size: 64. Other stats: (train_seconds = 2.3472e+04, step = 73205760, mean_episode_return = 10.415, mean_episode_step = 1576.0, total_loss = 195.29, pg_loss = 149.88, baseline_loss = 59.217, entropy_loss = -13.813, learner_queue_size = 64, _tick = 11461, _time = 1.6548e+09)
[2022-06-09 20:11:53,942][root][INFO] - Step 73221120 @ 3069.5 SPS. Inference batcher size: 9. Learner queue size: 64. Other stats: (train_seconds = 2.3477e+04, step = 73221120, mean_episode_return = 18.33, mean_episode_step = 1737.2, total_loss = -293.2, pg_loss = -286.94, baseline_loss = 7.4848, entropy_loss = -13.742, learner_queue_size = 64, _tick = 11464, _time = 1.6548e+09)
[2022-06-09 20:11:58,946][root][INFO] - Step 73236480 @ 3069.5 SPS. Inference batcher size: 26. Learner queue size: 64. Other stats: (train_seconds = 2.3482e+04, step = 73236480, mean_episode_return = -16.035, mean_episode_step = 1847.2, total_loss = -132.88, pg_loss = -152.8, baseline_loss = 33.651, entropy_loss = -13.729, learner_queue_size = 64, _tick = 11467, _time = 1.6548e+09)
[2022-06-09 20:12:03,950][root][INFO] - Step 73251840 @ 3069.6 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (train_seconds = 2.3487e+04, step = 73251840, mean_episode_return = None, mean_episode_step = 1843.5, total_loss = 164.58, pg_loss = 138.39, baseline_loss = 39.987, entropy_loss = -13.8, learner_queue_size = 64, _tick = 11469, _time = 1.6548e+09)
[2022-06-09 20:12:08,955][root][INFO] - Step 73267200 @ 3069.3 SPS. Inference batcher size: 89. Learner queue size: 64. Other stats: (train_seconds = 2.3492e+04, step = 73267200, mean_episode_return = 42.085, mean_episode_step = 1771.4, total_loss = -58.568, pg_loss = -78.751, baseline_loss = 33.983, entropy_loss = -13.8, learner_queue_size = 64, _tick = 11472, _time = 1.6548e+09)
[2022-06-09 20:12:13,958][root][INFO] - Step 73277440 @ 2046.5 SPS. Inference batcher size: 1. Learner queue size: 64. Other stats: (train_seconds = 2.3497e+04, step = 73277440, mean_episode_return = 26.113, mean_episode_step = 1891.2, total_loss = -129.97, pg_loss = -144.84, baseline_loss = 28.561, entropy_loss = -13.691, learner_queue_size = 64, _tick = 11474, _time = 1.6548e+09)
[2022-06-09 20:12:18,962][root][INFO] - Step 73292800 @ 3069.5 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 2.3502e+04, step = 73292800, mean_episode_return = 148.75, mean_episode_step = 1929.8, total_loss = 162.75, pg_loss = 134.96, baseline_loss = 41.6, entropy_loss = -13.813, learner_queue_size = 64, _tick = 11477, _time = 1.6548e+09)
[2022-06-09 20:12:23,966][root][INFO] - Step 73308160 @ 3069.6 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 2.3507e+04, step = 73308160, mean_episode_return = 13.295, mean_episode_step = 1804.1, total_loss = -23.338, pg_loss = -42.315, baseline_loss = 32.821, entropy_loss = -13.844, learner_queue_size = 64, _tick = 11480, _time = 1.6548e+09)
[2022-06-09 20:12:28,970][root][INFO] - Step 73323520 @ 3069.6 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 2.3512e+04, step = 73323520, mean_episode_return = -11.25, mean_episode_step = 1703.2, total_loss = 123.16, pg_loss = 95.648, baseline_loss = 41.561, entropy_loss = -14.045, learner_queue_size = 64, _tick = 11482, _time = 1.6548e+09)
[2022-06-09 20:12:33,974][root][INFO] - Step 73338880 @ 3069.4 SPS. Inference batcher size: 43. Learner queue size: 64. Other stats: (train_seconds = 2.3517e+04, step = 73338880, mean_episode_return = 14.034, mean_episode_step = 1809.8, total_loss = 103.41, pg_loss = 65.968, baseline_loss = 51.571, entropy_loss = -14.124, learner_queue_size = 64, _tick = 11485, _time = 1.6548e+09)
[2022-06-09 20:12:38,978][root][INFO] - Step 73349120 @ 2046.5 SPS. Inference batcher size: 18. Learner queue size: 64. Other stats: (train_seconds = 2.3522e+04, step = 73349120, mean_episode_return = 152.71, mean_episode_step = 1867.9, total_loss = 35.511, pg_loss = 8.964, baseline_loss = 40.572, entropy_loss = -14.025, learner_queue_size = 64, _tick = 11487, _time = 1.6548e+09)
[2022-06-09 20:12:43,982][root][INFO] - Step 73364480 @ 3069.5 SPS. Inference batcher size: 23. Learner queue size: 64. Other stats: (train_seconds = 2.3527e+04, step = 73364480, mean_episode_return = 31.541, mean_episode_step = 1906.1, total_loss = 35.322, pg_loss = 12.785, baseline_loss = 36.552, entropy_loss = -14.014, learner_queue_size = 64, _tick = 11489, _time = 1.6548e+09)
[2022-06-09 20:12:48,986][root][INFO] - Step 73379840 @ 3069.6 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 2.3532e+04, step = 73379840, mean_episode_return = 54.306, mean_episode_step = 1949.8, total_loss = -80.401, pg_loss = -92.584, baseline_loss = 26.388, entropy_loss = -14.205, learner_queue_size = 64, _tick = 11492, _time = 1.6548e+09)
[2022-06-09 20:12:53,990][root][INFO] - Step 73395200 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 2.3537e+04, step = 73395200, mean_episode_return = 29.651, mean_episode_step = 1883.8, total_loss = 85.989, pg_loss = 49.319, baseline_loss = 51.12, entropy_loss = -14.451, learner_queue_size = 64, _tick = 11495, _time = 1.6548e+09)
[2022-06-09 20:12:58,994][root][INFO] - Step 73410560 @ 3069.5 SPS. Inference batcher size: 33. Learner queue size: 64. Other stats: (train_seconds = 2.3542e+04, step = 73410560, mean_episode_return = 32.338, mean_episode_step = 1662.3, total_loss = -32.08, pg_loss = -60.28, baseline_loss = 42.725, entropy_loss = -14.525, learner_queue_size = 64, _tick = 11498, _time = 1.6548e+09)
[2022-06-09 20:13:03,998][root][INFO] - Step 73420800 @ 2046.4 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 2.3547e+04, step = 73420800, mean_episode_return = 90.465, mean_episode_step = 1920.6, total_loss = -74.589, pg_loss = -85.097, baseline_loss = 25.121, entropy_loss = -14.613, learner_queue_size = 64, _tick = 11500, _time = 1.6548e+09)
[2022-06-09 20:13:09,002][root][INFO] - Step 73436160 @ 3069.5 SPS. Inference batcher size: 41. Learner queue size: 64. Other stats: (train_seconds = 2.3552e+04, step = 73436160, mean_episode_return = 180.37, mean_episode_step = 1585.9, total_loss = 114.5, pg_loss = 99.307, baseline_loss = 29.755, entropy_loss = -14.561, learner_queue_size = 64, _tick = 11502, _time = 1.6548e+09)
[2022-06-09 20:13:14,006][root][INFO] - Step 73451520 @ 3069.6 SPS. Inference batcher size: 74. Learner queue size: 64. Other stats: (train_seconds = 2.3557e+04, step = 73451520, mean_episode_return = 43.376, mean_episode_step = 1806.5, total_loss = 730.14, pg_loss = 155.0, baseline_loss = 589.73, entropy_loss = -14.591, learner_queue_size = 64, _tick = 11504, _time = 1.6548e+09)
[2022-06-09 20:13:19,010][root][INFO] - Step 73466880 @ 3069.5 SPS. Inference batcher size: 50. Learner queue size: 64. Other stats: (train_seconds = 2.3562e+04, step = 73466880, mean_episode_return = 11.429, mean_episode_step = 1868.6, total_loss = -21.934, pg_loss = -39.827, baseline_loss = 32.474, entropy_loss = -14.582, learner_queue_size = 64, _tick = 11507, _time = 1.6548e+09)
[2022-06-09 20:13:24,014][root][INFO] - Step 73482240 @ 3069.5 SPS. Inference batcher size: 83. Learner queue size: 64. Other stats: (train_seconds = 2.3567e+04, step = 73482240, mean_episode_return = 29.159, mean_episode_step = 1779.7, total_loss = -118.0, pg_loss = -124.07, baseline_loss = 20.673, entropy_loss = -14.606, learner_queue_size = 64, _tick = 11510, _time = 1.6548e+09)
[2022-06-09 20:13:29,020][root][INFO] - Step 73492480 @ 2045.7 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 2.3572e+04, step = 73492480, mean_episode_return = None, mean_episode_step = 1871.3, total_loss = 324.25, pg_loss = 280.81, baseline_loss = 58.091, entropy_loss = -14.658, learner_queue_size = 64, _tick = 11511, _time = 1.6548e+09)
[2022-06-09 20:13:34,026][root][INFO] - Step 73507840 @ 3068.1 SPS. Inference batcher size: 28. Learner queue size: 64. Other stats: (train_seconds = 2.3577e+04, step = 73507840, mean_episode_return = 14.817, mean_episode_step = 1780.7, total_loss = 212.8, pg_loss = 166.41, baseline_loss = 60.979, entropy_loss = -14.594, learner_queue_size = 64, _tick = 11514, _time = 1.6548e+09)
[2022-06-09 20:13:39,030][root][INFO] - Step 73523200 @ 3069.5 SPS. Inference batcher size: 59. Learner queue size: 64. Other stats: (train_seconds = 2.3582e+04, step = 73523200, mean_episode_return = 0.12953, mean_episode_step = 1797.9, total_loss = 622.98, pg_loss = 548.68, baseline_loss = 88.862, entropy_loss = -14.563, learner_queue_size = 64, _tick = 11517, _time = 1.6548e+09)
[2022-06-09 20:13:44,034][root][INFO] - Step 73538560 @ 3069.6 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 2.3587e+04, step = 73538560, mean_episode_return = None, mean_episode_step = 1682.0, total_loss = 202.31, pg_loss = 169.74, baseline_loss = 47.169, entropy_loss = -14.6, learner_queue_size = 64, _tick = 11519, _time = 1.6548e+09)
[2022-06-09 20:13:49,038][root][INFO] - Step 73553920 @ 3069.6 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 2.3592e+04, step = 73553920, mean_episode_return = 32.735, mean_episode_step = 1537.3, total_loss = 710.65, pg_loss = 476.95, baseline_loss = 248.28, entropy_loss = -14.58, learner_queue_size = 64, _tick = 11522, _time = 1.6548e+09)
[2022-06-09 20:13:54,042][root][INFO] - Step 73564160 @ 2046.4 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 2.3597e+04, step = 73564160, mean_episode_return = 53.121, mean_episode_step = 1587.2, total_loss = 54.342, pg_loss = 16.751, baseline_loss = 52.135, entropy_loss = -14.544, learner_queue_size = 64, _tick = 11524, _time = 1.6548e+09)
[2022-06-09 20:13:59,046][root][INFO] - Step 73579520 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 64. Other stats: (train_seconds = 2.3602e+04, step = 73579520, mean_episode_return = 35.141, mean_episode_step = 1621.6, total_loss = -180.74, pg_loss = -195.88, baseline_loss = 29.431, entropy_loss = -14.298, learner_queue_size = 64, _tick = 11527, _time = 1.6548e+09)
[2022-06-09 20:14:04,050][root][INFO] - Step 73594880 @ 3069.5 SPS. Inference batcher size: 37. Learner queue size: 64. Other stats: (train_seconds = 2.3607e+04, step = 73594880, mean_episode_return = 223.39, mean_episode_step = 1747.5, total_loss = -119.91, pg_loss = -133.32, baseline_loss = 27.547, entropy_loss = -14.144, learner_queue_size = 64, _tick = 11530, _time = 1.6548e+09)
[2022-06-09 20:14:09,054][root][INFO] - Step 73610240 @ 3069.6 SPS. Inference batcher size: 35. Learner queue size: 64. Other stats: (train_seconds = 2.3612e+04, step = 73610240, mean_episode_return = None, mean_episode_step = 1786.3, total_loss = -176.22, pg_loss = -169.68, baseline_loss = 7.6956, entropy_loss = -14.234, learner_queue_size = 64, _tick = 11531, _time = 1.6548e+09)
[2022-06-09 20:14:14,058][root][INFO] - Step 73620480 @ 2046.4 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 2.3617e+04, step = 73620480, mean_episode_return = 38.68, mean_episode_step = 2076.3, total_loss = -160.78, pg_loss = -177.3, baseline_loss = 30.799, entropy_loss = -14.281, learner_queue_size = 64, _tick = 11533, _time = 1.6548e+09)
[2022-06-09 20:14:19,062][root][INFO] - Step 73635840 @ 3069.5 SPS. Inference batcher size: 49. Learner queue size: 64. Other stats: (train_seconds = 2.3622e+04, step = 73635840, mean_episode_return = 53.494, mean_episode_step = 1929.0, total_loss = -89.496, pg_loss = -113.64, baseline_loss = 38.439, entropy_loss = -14.294, learner_queue_size = 64, _tick = 11536, _time = 1.6548e+09)
[2022-06-09 20:14:24,066][root][INFO] - Step 73651200 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 64. Other stats: (train_seconds = 2.3627e+04, step = 73651200, mean_episode_return = None, mean_episode_step = 1926.7, total_loss = -201.7, pg_loss = -195.8, baseline_loss = 8.4002, entropy_loss = -14.293, learner_queue_size = 64, _tick = 11537, _time = 1.6548e+09)
[2022-06-09 20:14:29,070][root][INFO] - Step 73666560 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 64. Other stats: (train_seconds = 2.3632e+04, step = 73666560, mean_episode_return = 40.417, mean_episode_step = 1901.8, total_loss = -64.407, pg_loss = -76.212, baseline_loss = 26.122, entropy_loss = -14.316, learner_queue_size = 64, _tick = 11540, _time = 1.6548e+09)
[2022-06-09 20:14:34,074][root][INFO] - Step 73681920 @ 3069.5 SPS. Inference batcher size: 81. Learner queue size: 64. Other stats: (train_seconds = 2.3637e+04, step = 73681920, mean_episode_return = 0.86994, mean_episode_step = 1838.4, total_loss = 36.702, pg_loss = 19.81, baseline_loss = 31.397, entropy_loss = -14.505, learner_queue_size = 64, _tick = 11543, _time = 1.6548e+09)
[2022-06-09 20:14:39,078][root][INFO] - Step 73697280 @ 3069.6 SPS. Inference batcher size: 73. Learner queue size: 64. Other stats: (train_seconds = 2.3642e+04, step = 73697280, mean_episode_return = 90.395, mean_episode_step = 1814.7, total_loss = 412.78, pg_loss = 374.33, baseline_loss = 52.989, entropy_loss = -14.536, learner_queue_size = 64, _tick = 11545, _time = 1.6548e+09)
[2022-06-09 20:14:44,082][root][INFO] - Step 73707520 @ 2046.4 SPS. Inference batcher size: 42. Learner queue size: 64. Other stats: (train_seconds = 2.3647e+04, step = 73707520, mean_episode_return = 86.167, mean_episode_step = 1781.0, total_loss = -163.81, pg_loss = -166.82, baseline_loss = 17.564, entropy_loss = -14.549, learner_queue_size = 64, _tick = 11547, _time = 1.6548e+09)
[2022-06-09 20:14:49,086][root][INFO] - Step 73722880 @ 3069.5 SPS. Inference batcher size: 67. Learner queue size: 64. Other stats: (train_seconds = 2.3652e+04, step = 73722880, mean_episode_return = 69.76, mean_episode_step = 2021.6, total_loss = -47.155, pg_loss = -60.831, baseline_loss = 28.217, entropy_loss = -14.541, learner_queue_size = 64, _tick = 11549, _time = 1.6548e+09)
[2022-06-09 20:14:54,090][root][INFO] - Step 73738240 @ 3069.6 SPS. Inference batcher size: 69. Learner queue size: 64. Other stats: (train_seconds = 2.3657e+04, step = 73738240, mean_episode_return = 89.446, mean_episode_step = 1807.8, total_loss = 15.308, pg_loss = 9.6547, baseline_loss = 20.413, entropy_loss = -14.76, learner_queue_size = 64, _tick = 11552, _time = 1.6548e+09)
[2022-06-09 20:14:59,094][root][INFO] - Step 73753600 @ 3069.5 SPS. Inference batcher size: 75. Learner queue size: 64. Other stats: (train_seconds = 2.3662e+04, step = 73753600, mean_episode_return = 34.999, mean_episode_step = 1820.1, total_loss = -346.93, pg_loss = -360.99, baseline_loss = 28.955, entropy_loss = -14.894, learner_queue_size = 64, _tick = 11555, _time = 1.6548e+09)
[2022-06-09 20:15:04,098][root][INFO] - Step 73763840 @ 2046.3 SPS. Inference batcher size: 29. Learner queue size: 64. Other stats: (train_seconds = 2.3667e+04, step = 73763840, mean_episode_return = 85.918, mean_episode_step = 1923.7, total_loss = 9.0793, pg_loss = -7.4319, baseline_loss = 31.479, entropy_loss = -14.968, learner_queue_size = 64, _tick = 11557, _time = 1.6548e+09)
[2022-06-09 20:15:09,102][root][INFO] - Step 73779200 @ 3069.5 SPS. Inference batcher size: 30. Learner queue size: 64. Other stats: (train_seconds = 2.3672e+04, step = 73779200, mean_episode_return = 54.55, mean_episode_step = 1880.2, total_loss = 117.54, pg_loss = 90.02, baseline_loss = 42.225, entropy_loss = -14.707, learner_queue_size = 64, _tick = 11559, _time = 1.6548e+09)
[2022-06-09 20:15:14,106][root][INFO] - Step 73794560 @ 3069.6 SPS. Inference batcher size: 70. Learner queue size: 64. Other stats: (train_seconds = 2.3677e+04, step = 73794560, mean_episode_return = 175.12, mean_episode_step = 1844.9, total_loss = 17.03, pg_loss = 4.6521, baseline_loss = 27.081, entropy_loss = -14.703, learner_queue_size = 64, _tick = 11562, _time = 1.6548e+09)
[2022-06-09 20:15:19,110][root][INFO] - Step 73809920 @ 3069.5 SPS. Inference batcher size: 2. Learner queue size: 64. Other stats: (train_seconds = 2.3682e+04, step = 73809920, mean_episode_return = 34.033, mean_episode_step = 1991.9, total_loss = -333.89, pg_loss = -327.83, baseline_loss = 8.7787, entropy_loss = -14.832, learner_queue_size = 64, _tick = 11564, _time = 1.6548e+09)
[2022-06-09 20:15:24,114][root][INFO] - Step 73825280 @ 3069.5 SPS. Inference batcher size: 64. Learner queue size: 64. Other stats: (train_seconds = 2.3687e+04, step = 73825280, mean_episode_return = None, mean_episode_step = 2040.6, total_loss = -15.512, pg_loss = -18.446, baseline_loss = 17.751, entropy_loss = -14.817, learner_queue_size = 64, _tick = 11565, _time = 1.6548e+09)
[2022-06-09 20:15:29,118][root][INFO] - Step 73835520 @ 2046.4 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 2.3692e+04, step = 73835520, mean_episode_return = 23.448, mean_episode_step = 2012.4, total_loss = 318.78, pg_loss = 259.24, baseline_loss = 74.235, entropy_loss = -14.695, learner_queue_size = 64, _tick = 11567, _time = 1.6548e+09)
[2022-06-09 20:15:34,122][root][INFO] - Step 73850880 @ 3069.5 SPS. Inference batcher size: 25. Learner queue size: 64. Other stats: (train_seconds = 2.3697e+04, step = 73850880, mean_episode_return = 66.764, mean_episode_step = 1863.2, total_loss = 361.05, pg_loss = 294.11, baseline_loss = 81.614, entropy_loss = -14.676, learner_queue_size = 64, _tick = 11569, _time = 1.6548e+09)
[2022-06-09 20:15:39,126][root][INFO] - Step 73866240 @ 3069.6 SPS. Inference batcher size: 11. Learner queue size: 64. Other stats: (train_seconds = 2.3702e+04, step = 73866240, mean_episode_return = 68.276, mean_episode_step = 1455.1, total_loss = -166.38, pg_loss = -185.56, baseline_loss = 33.823, entropy_loss = -14.644, learner_queue_size = 64, _tick = 11572, _time = 1.6548e+09)
[2022-06-09 20:15:44,130][root][INFO] - Step 73881600 @ 3069.5 SPS. Inference batcher size: 61. Learner queue size: 64. Other stats: (train_seconds = 2.3707e+04, step = 73881600, mean_episode_return = None, mean_episode_step = 1839.2, total_loss = 51.298, pg_loss = 32.049, baseline_loss = 33.902, entropy_loss = -14.653, learner_queue_size = 64, _tick = 11574, _time = 1.6548e+09)
[2022-06-09 20:15:49,134][root][INFO] - Step 73896960 @ 3069.5 SPS. Inference batcher size: 34. Learner queue size: 64. Other stats: (train_seconds = 2.3712e+04, step = 73896960, mean_episode_return = -29.801, mean_episode_step = 1669.8, total_loss = 128.4, pg_loss = 108.55, baseline_loss = 34.499, entropy_loss = -14.651, learner_queue_size = 64, _tick = 11577, _time = 1.6548e+09)
[2022-06-09 20:15:54,138][root][INFO] - Step 73907200 @ 2046.4 SPS. Inference batcher size: 32. Learner queue size: 64. Other stats: (train_seconds = 2.3717e+04, step = 73907200, mean_episode_return = 94.15, mean_episode_step = 1956.9, total_loss = -206.67, pg_loss = -214.47, baseline_loss = 22.408, entropy_loss = -14.608, learner_queue_size = 64, _tick = 11579, _time = 1.6548e+09)
[2022-06-09 20:15:59,142][root][INFO] - Step 73922560 @ 3069.5 SPS. Inference batcher size: 39. Learner queue size: 64. Other stats: (train_seconds = 2.3722e+04, step = 73922560, mean_episode_return = 13.355, mean_episode_step = 1784.6, total_loss = -310.42, pg_loss = -300.49, baseline_loss = 4.6654, entropy_loss = -14.594, learner_queue_size = 64, _tick = 11582, _time = 1.6548e+09)
[2022-06-09 20:16:04,146][root][INFO] - Step 73937920 @ 3069.5 SPS. Inference batcher size: 22. Learner queue size: 64. Other stats: (train_seconds = 2.3727e+04, step = 73937920, mean_episode_return = 20.86, mean_episode_step = 1603.1, total_loss = -105.88, pg_loss = -124.64, baseline_loss = 33.319, entropy_loss = -14.555, learner_queue_size = 64, _tick = 11585, _time = 1.6548e+09)
[2022-06-09 20:16:09,150][root][INFO] - Step 73953280 @ 3069.6 SPS. Inference batcher size: 47. Learner queue size: 64. Other stats: (