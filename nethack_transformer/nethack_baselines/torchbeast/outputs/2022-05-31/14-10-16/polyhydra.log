[2022-05-31 14:10:16,806][root][INFO] - name: null
wandb: false
project: nethack_challenge
entity: user1
group: group1
mock: false
single_ttyrec: true
num_seeds: 0
write_profiler_trace: false
fn_penalty_step: constant
penalty_time: 0.0
penalty_step: -0.01
reward_lose: 0
reward_win: 100
state_counter: none
character: mon-hum-neu-mal
mode: train
env: challenge
num_actors: 256
total_steps: 1000000000.0
batch_size: 32
unroll_length: 80
num_learner_threads: 1
num_inference_threads: 1
disable_cuda: false
learner_device: cuda:0
actor_device: cuda:0
learning_rate: 0.0002
grad_norm_clipping: 40
alpha: 0.99
momentum: 0
epsilon: 1.0e-06
entropy_cost: 0.001
baseline_cost: 0.5
discounting: 0.999
normalize_reward: true
model: baseline
use_lstm: true
hidden_dim: 256
embedding_dim: 64
layers: 5
crop_dim: 9
use_index_select: true
restrict_action_space: true
msg:
  hidden_dim: 64
  embedding_dim: 32
load_dir: null

[2022-05-31 14:10:16,817][root][INFO] - Symlinked log directory: /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/latest
[2022-05-31 14:10:16,820][root][INFO] - Creating archive directory: /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/archives
[2022-05-31 14:10:16,820][root][INFO] - Logging results to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16
[2022-05-31 14:10:17,765][palaas/out][INFO] - Found log directory: /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16
[2022-05-31 14:10:17,766][palaas/out][INFO] - Saving arguments to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/meta.json
[2022-05-31 14:10:17,768][palaas/out][INFO] - Saving messages to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/out.log
[2022-05-31 14:10:17,768][palaas/out][INFO] - Saving logs data to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/logs.csv
[2022-05-31 14:10:17,769][palaas/out][INFO] - Saving logs' fields to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/fields.csv
[2022-05-31 14:10:17,806][root][INFO] - Using CUDA.
[2022-05-31 14:10:17,838][root][INFO] - Using model baseline
[2022-05-31 14:10:17,838][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,267][root][INFO] - Number of model parameters: 4437610
[2022-05-31 14:10:21,268][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,322][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,322][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,323][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,323][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,323][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,323][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,324][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,324][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,324][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,325][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,328][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,324][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,327][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,329][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,329][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,329][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,329][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,329][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,329][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,329][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,328][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,330][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,329][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,329][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,329][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,330][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,330][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,327][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,328][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,330][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,330][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,330][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,331][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,330][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,330][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,332][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,332][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,333][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,333][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,333][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,336][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,329][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,345][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,345][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,345][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,345][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,345][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,345][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,345][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,346][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,346][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,347][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,351][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,351][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,351][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,352][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,351][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,352][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,352][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,352][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,353][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,353][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,353][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,354][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,354][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,354][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,354][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,363][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,363][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,401][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,402][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,402][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,402][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,402][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,403][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,402][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,403][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,403][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,403][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,403][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,403][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,404][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,404][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,404][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,404][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,404][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,404][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,404][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,404][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,404][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,404][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,406][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,406][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,404][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,404][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,403][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,406][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,409][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,410][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,410][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,410][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,410][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,411][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,404][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,410][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,410][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,405][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,406][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,411][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,410][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,412][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,410][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,409][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,413][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,408][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,408][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,409][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,409][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,413][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,413][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,410][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,409][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,409][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,412][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,415][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,415][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,409][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,404][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,416][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,406][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,410][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,411][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,412][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,412][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,412][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,418][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,418][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,419][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,412][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,411][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,412][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,413][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,413][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,422][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,428][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,428][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,428][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,448][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,448][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,448][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,448][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,448][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,452][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,448][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,450][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,448][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,448][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,452][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,448][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,448][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,448][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,448][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,448][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,457][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,457][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,457][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,457][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,457][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,454][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,457][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,457][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,457][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,458][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,450][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,448][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,458][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,458][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,451][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,448][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,450][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,458][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,451][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,451][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,450][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,451][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,450][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,450][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,450][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,460][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,450][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,453][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,460][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,453][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,450][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,453][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,453][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,453][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,451][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,448][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,448][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,451][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,451][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,451][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,448][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,451][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,448][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,448][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,451][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,451][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,454][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,448][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,454][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,454][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,454][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,454][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,454][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,454][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,454][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,451][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,455][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,455][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,455][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,454][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,455][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,455][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,448][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,448][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,452][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,452][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,449][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,452][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,449][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,448][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,452][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,449][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,452][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,449][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,449][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,452][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,449][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,452][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,449][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,449][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,476][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,451][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,450][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,455][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,455][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,450][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,455][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,455][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,450][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,454][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,478][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,495][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:21,495][nle.env.base][INFO] - Not saving any NLE data.
[2022-05-31 14:10:24,476][palaas/out][INFO] - Updated log fields: ['_tick', '_time', 'step', 'mean_episode_return', 'mean_episode_step', 'total_loss', 'pg_loss', 'baseline_loss', 'entropy_loss', 'learner_queue_size']
[2022-05-31 14:10:26,318][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint_0.tar
[2022-05-31 14:10:26,383][root][INFO] - Step 20480 @ 4093.5 SPS. Inference batcher size: 197. Learner queue size: 7. Other stats: (step = 20480, mean_episode_return = None, mean_episode_step = 40.5, total_loss = -87.194, pg_loss = -86.105, baseline_loss = 9.0929, entropy_loss = -10.182, learner_queue_size = 7, _tick = 3, _time = 1.654e+09, train_seconds = 5.0)
[2022-05-31 14:10:27,960][palaas/out][INFO] - Updated log fields: ['_tick', '_time', 'step', 'mean_episode_return', 'mean_episode_step', 'total_loss', 'pg_loss', 'baseline_loss', 'entropy_loss', 'learner_queue_size', 'train_seconds']
[2022-05-31 14:10:31,386][root][INFO] - Step 53760 @ 6566.6 SPS. Inference batcher size: 144. Learner queue size: 30. Other stats: (step = 53760, mean_episode_return = None, mean_episode_step = 200.5, total_loss = -25.666, pg_loss = -15.283, baseline_loss = 0.0077268, entropy_loss = -10.39, learner_queue_size = 23, _tick = 6, _time = 1.654e+09, train_seconds = 10.1)
[2022-05-31 14:10:36,390][root][INFO] - Step 87040 @ 6650.7 SPS. Inference batcher size: 138. Learner queue size: 22. Other stats: (step = 87040, mean_episode_return = None, mean_episode_step = 360.5, total_loss = 189.94, pg_loss = 185.42, baseline_loss = 15.064, entropy_loss = -10.545, learner_queue_size = 5, _tick = 9, _time = 1.654e+09, train_seconds = 15.1)
[2022-05-31 14:10:41,396][root][INFO] - Step 120320 @ 6648.0 SPS. Inference batcher size: 148. Learner queue size: 10. Other stats: (step = 120320, mean_episode_return = None, mean_episode_step = 408.75, total_loss = -147.62, pg_loss = -156.43, baseline_loss = 19.435, entropy_loss = -10.623, learner_queue_size = 29, _tick = 11, _time = 1.654e+09, train_seconds = 20.1)
[2022-05-31 14:10:46,402][root][INFO] - Step 156160 @ 7158.9 SPS. Inference batcher size: 38. Learner queue size: 3. Other stats: (step = 156160, mean_episode_return = None, mean_episode_step = 579.09, total_loss = -30.255, pg_loss = -19.548, baseline_loss = 0.0048804, entropy_loss = -10.712, learner_queue_size = 32, _tick = 16, _time = 1.654e+09, train_seconds = 25.1)
[2022-05-31 14:10:51,409][root][INFO] - Step 189440 @ 6647.1 SPS. Inference batcher size: 132. Learner queue size: 25. Other stats: (step = 189440, mean_episode_return = None, mean_episode_step = 751.31, total_loss = -14.266, pg_loss = -3.3927, baseline_loss = 0.004221, entropy_loss = -10.878, learner_queue_size = 7, _tick = 17, _time = 1.654e+09, train_seconds = 30.1)
[2022-05-31 14:10:56,414][root][INFO] - Step 222720 @ 6649.4 SPS. Inference batcher size: 134. Learner queue size: 8. Other stats: (step = 222720, mean_episode_return = -8.5601, mean_episode_step = 785.0, total_loss = 414.72, pg_loss = 359.61, baseline_loss = 66.009, entropy_loss = -10.903, learner_queue_size = 22, _tick = 20, _time = 1.654e+09, train_seconds = 35.1)
[2022-05-31 14:11:01,420][root][INFO] - Step 256000 @ 6648.0 SPS. Inference batcher size: 106. Learner queue size: 23. Other stats: (step = 256000, mean_episode_return = None, mean_episode_step = 934.03, total_loss = 461.13, pg_loss = 325.17, baseline_loss = 146.85, entropy_loss = -10.894, learner_queue_size = 32, _tick = 22, _time = 1.654e+09, train_seconds = 40.1)
[2022-05-31 14:11:06,426][root][INFO] - Step 291840 @ 7159.5 SPS. Inference batcher size: 104. Learner queue size: 11. Other stats: (step = 291840, mean_episode_return = None, mean_episode_step = 1151.3, total_loss = -58.36, pg_loss = -47.501, baseline_loss = 0.01714, entropy_loss = -10.876, learner_queue_size = 11, _tick = 24, _time = 1.654e+09, train_seconds = 45.1)
[2022-05-31 14:11:11,432][root][INFO] - Step 325120 @ 6648.0 SPS. Inference batcher size: 48. Learner queue size: 4. Other stats: (step = 325120, mean_episode_return = None, mean_episode_step = 1209.3, total_loss = -21.024, pg_loss = -10.113, baseline_loss = 0.013696, entropy_loss = -10.925, learner_queue_size = 25, _tick = 25, _time = 1.654e+09, train_seconds = 50.1)
[2022-05-31 14:11:16,438][root][INFO] - Step 358400 @ 6648.0 SPS. Inference batcher size: 129. Learner queue size: 15. Other stats: (step = 358400, mean_episode_return = None, mean_episode_step = 1266.0, total_loss = 303.6, pg_loss = 286.84, baseline_loss = 27.66, entropy_loss = -10.906, learner_queue_size = 23, _tick = 25, _time = 1.654e+09, train_seconds = 55.1)
[2022-05-31 14:11:21,442][root][INFO] - Step 391680 @ 6650.8 SPS. Inference batcher size: 47. Learner queue size: 6. Other stats: (step = 391680, mean_episode_return = None, mean_episode_step = 1536.3, total_loss = 33.386, pg_loss = 39.95, baseline_loss = 4.2438, entropy_loss = -10.808, learner_queue_size = 20, _tick = 28, _time = 1.654e+09, train_seconds = 60.1)
[2022-05-31 14:11:26,446][root][INFO] - Step 424960 @ 6650.6 SPS. Inference batcher size: 102. Learner queue size: 11. Other stats: (step = 424960, mean_episode_return = None, mean_episode_step = 1621.3, total_loss = -98.934, pg_loss = -88.233, baseline_loss = 0.059613, entropy_loss = -10.761, learner_queue_size = 32, _tick = 29, _time = 1.654e+09, train_seconds = 65.1)
[2022-05-31 14:11:31,450][root][INFO] - Step 458240 @ 6650.8 SPS. Inference batcher size: 136. Learner queue size: 26. Other stats: (step = 458240, mean_episode_return = None, mean_episode_step = 1800.3, total_loss = 43.749, pg_loss = 48.405, baseline_loss = 5.883, entropy_loss = -10.539, learner_queue_size = 21, _tick = 29, _time = 1.654e+09, train_seconds = 70.1)
[2022-05-31 14:11:36,454][root][INFO] - Step 494080 @ 7162.2 SPS. Inference batcher size: 141. Learner queue size: 23. Other stats: (step = 494080, mean_episode_return = None, mean_episode_step = 1898.3, total_loss = -75.52, pg_loss = -65.389, baseline_loss = 0.35341, entropy_loss = -10.485, learner_queue_size = 16, _tick = 30, _time = 1.654e+09, train_seconds = 75.1)
[2022-05-31 14:11:41,460][root][INFO] - Step 527360 @ 6647.7 SPS. Inference batcher size: 133. Learner queue size: 28. Other stats: (step = 527360, mean_episode_return = None, mean_episode_step = 1912.4, total_loss = -95.214, pg_loss = -84.844, baseline_loss = 0.064434, entropy_loss = -10.435, learner_queue_size = 27, _tick = 34, _time = 1.654e+09, train_seconds = 80.1)
[2022-05-31 14:11:46,467][root][INFO] - Step 558080 @ 6136.4 SPS. Inference batcher size: 133. Learner queue size: 25. Other stats: (step = 558080, mean_episode_return = None, mean_episode_step = 2069.9, total_loss = -95.279, pg_loss = -85.018, baseline_loss = 0.083852, entropy_loss = -10.345, learner_queue_size = 10, _tick = 35, _time = 1.654e+09, train_seconds = 85.2)
[2022-05-31 14:11:51,470][root][INFO] - Step 593920 @ 7163.0 SPS. Inference batcher size: 120. Learner queue size: 11. Other stats: (step = 593920, mean_episode_return = -22.2, mean_episode_step = 2234.7, total_loss = 1292.5, pg_loss = 746.81, baseline_loss = 555.96, entropy_loss = -10.296, learner_queue_size = 23, _tick = 36, _time = 1.654e+09, train_seconds = 90.2)
[2022-05-31 14:11:56,473][root][INFO] - Step 627200 @ 6651.4 SPS. Inference batcher size: 133. Learner queue size: 21. Other stats: (step = 627200, mean_episode_return = None, mean_episode_step = 2346.8, total_loss = 31.918, pg_loss = 34.607, baseline_loss = 7.5137, entropy_loss = -10.202, learner_queue_size = 25, _tick = 39, _time = 1.654e+09, train_seconds = 95.2)
[2022-05-31 14:12:01,479][root][INFO] - Step 660480 @ 6648.0 SPS. Inference batcher size: 118. Learner queue size: 2. Other stats: (step = 660480, mean_episode_return = None, mean_episode_step = 2382.1, total_loss = -239.72, pg_loss = -230.02, baseline_loss = 0.50034, entropy_loss = -10.198, learner_queue_size = 10, _tick = 41, _time = 1.654e+09, train_seconds = 100.2)
[2022-05-31 14:12:06,485][root][INFO] - Step 693760 @ 6648.0 SPS. Inference batcher size: 125. Learner queue size: 18. Other stats: (step = 693760, mean_episode_return = None, mean_episode_step = 2504.9, total_loss = -192.3, pg_loss = -182.34, baseline_loss = 0.27107, entropy_loss = -10.224, learner_queue_size = 20, _tick = 41, _time = 1.654e+09, train_seconds = 105.2)
[2022-05-31 14:12:11,490][root][INFO] - Step 727040 @ 6650.0 SPS. Inference batcher size: 147. Learner queue size: 26. Other stats: (step = 727040, mean_episode_return = None, mean_episode_step = 2654.7, total_loss = 3723.2, pg_loss = 2439.6, baseline_loss = 1293.9, entropy_loss = -10.208, learner_queue_size = 32, _tick = 46, _time = 1.654e+09, train_seconds = 110.2)
[2022-05-31 14:12:16,494][root][INFO] - Step 762880 @ 7162.2 SPS. Inference batcher size: 80. Learner queue size: 26. Other stats: (step = 762880, mean_episode_return = None, mean_episode_step = 2616.4, total_loss = -161.62, pg_loss = -159.6, baseline_loss = 8.1542, entropy_loss = -10.18, learner_queue_size = 13, _tick = 48, _time = 1.654e+09, train_seconds = 115.2)
[2022-05-31 14:12:21,498][root][INFO] - Step 796160 @ 6650.8 SPS. Inference batcher size: 161. Learner queue size: 16. Other stats: (step = 796160, mean_episode_return = None, mean_episode_step = 2594.4, total_loss = -62.029, pg_loss = -62.247, baseline_loss = 10.323, entropy_loss = -10.105, learner_queue_size = 29, _tick = 50, _time = 1.654e+09, train_seconds = 120.2)
[2022-05-31 14:12:26,502][root][INFO] - Step 829440 @ 6650.6 SPS. Inference batcher size: 107. Learner queue size: 18. Other stats: (step = 829440, mean_episode_return = None, mean_episode_step = 3032.0, total_loss = 237.92, pg_loss = 207.33, baseline_loss = 40.684, entropy_loss = -10.089, learner_queue_size = 23, _tick = 51, _time = 1.654e+09, train_seconds = 125.2)
[2022-05-31 14:12:31,508][root][INFO] - Step 862720 @ 6648.0 SPS. Inference batcher size: 91. Learner queue size: 12. Other stats: (step = 862720, mean_episode_return = None, mean_episode_step = 3057.5, total_loss = 110.29, pg_loss = 101.67, baseline_loss = 18.698, entropy_loss = -10.08, learner_queue_size = 13, _tick = 52, _time = 1.654e+09, train_seconds = 130.2)
[2022-05-31 14:12:36,514][root][INFO] - Step 898560 @ 7159.5 SPS. Inference batcher size: 57. Learner queue size: 30. Other stats: (step = 898560, mean_episode_return = 34.299, mean_episode_step = 3071.8, total_loss = 517.37, pg_loss = 449.38, baseline_loss = 78.027, entropy_loss = -10.036, learner_queue_size = 18, _tick = 56, _time = 1.654e+09, train_seconds = 135.2)
[2022-05-31 14:12:41,518][root][INFO] - Step 931840 @ 6650.3 SPS. Inference batcher size: 144. Learner queue size: 26. Other stats: (step = 931840, mean_episode_return = -34.73, mean_episode_step = 3335.7, total_loss = 1917.6, pg_loss = 1530.2, baseline_loss = 397.35, entropy_loss = -9.9606, learner_queue_size = 16, _tick = 61, _time = 1.654e+09, train_seconds = 140.2)
[2022-05-31 14:12:46,522][root][INFO] - Step 965120 @ 6651.1 SPS. Inference batcher size: 145. Learner queue size: 31. Other stats: (step = 965120, mean_episode_return = None, mean_episode_step = 3350.1, total_loss = 1027.8, pg_loss = 798.03, baseline_loss = 239.94, entropy_loss = -10.135, learner_queue_size = 16, _tick = 62, _time = 1.654e+09, train_seconds = 145.2)
[2022-05-31 14:12:51,526][root][INFO] - Step 998400 @ 6650.7 SPS. Inference batcher size: 107. Learner queue size: 3. Other stats: (step = 998400, mean_episode_return = None, mean_episode_step = 3420.2, total_loss = -246.63, pg_loss = -237.53, baseline_loss = 0.96264, entropy_loss = -10.064, learner_queue_size = 20, _tick = 64, _time = 1.654e+09, train_seconds = 150.2)
[2022-05-31 14:12:56,530][root][INFO] - Step 1031680 @ 6650.6 SPS. Inference batcher size: 123. Learner queue size: 5. Other stats: (step = 1031680, mean_episode_return = None, mean_episode_step = 3629.7, total_loss = 840.77, pg_loss = 646.49, baseline_loss = 204.24, entropy_loss = -9.9474, learner_queue_size = 15, _tick = 65, _time = 1.654e+09, train_seconds = 155.2)
[2022-05-31 14:13:01,536][root][INFO] - Step 1064960 @ 6648.1 SPS. Inference batcher size: 89. Learner queue size: 20. Other stats: (step = 1064960, mean_episode_return = None, mean_episode_step = 3622.3, total_loss = -238.73, pg_loss = -230.17, baseline_loss = 1.3702, entropy_loss = -9.9281, learner_queue_size = 20, _tick = 69, _time = 1.654e+09, train_seconds = 160.2)
[2022-05-31 14:13:06,538][root][INFO] - Step 1100800 @ 7165.1 SPS. Inference batcher size: 129. Learner queue size: 29. Other stats: (step = 1100800, mean_episode_return = None, mean_episode_step = 3363.5, total_loss = 75.004, pg_loss = 55.767, baseline_loss = 29.168, entropy_loss = -9.931, learner_queue_size = 27, _tick = 74, _time = 1.654e+09, train_seconds = 165.2)
[2022-05-31 14:13:11,544][root][INFO] - Step 1131520 @ 6136.6 SPS. Inference batcher size: 170. Learner queue size: 16. Other stats: (step = 1131520, mean_episode_return = None, mean_episode_step = 3509.3, total_loss = 89.501, pg_loss = 58.931, baseline_loss = 40.388, entropy_loss = -9.8185, learner_queue_size = 12, _tick = 75, _time = 1.654e+09, train_seconds = 170.2)
[2022-05-31 14:13:16,550][root][INFO] - Step 1167360 @ 7159.6 SPS. Inference batcher size: 108. Learner queue size: 8. Other stats: (step = 1167360, mean_episode_return = -38.16, mean_episode_step = 3960.7, total_loss = 166.33, pg_loss = 132.7, baseline_loss = 43.231, entropy_loss = -9.5972, learner_queue_size = 21, _tick = 78, _time = 1.654e+09, train_seconds = 175.2)
[2022-05-31 14:13:21,556][root][INFO] - Step 1200640 @ 6647.9 SPS. Inference batcher size: 28. Learner queue size: 5. Other stats: (step = 1200640, mean_episode_return = None, mean_episode_step = 4051.6, total_loss = 299.33, pg_loss = 248.59, baseline_loss = 60.303, entropy_loss = -9.5539, learner_queue_size = 22, _tick = 81, _time = 1.654e+09, train_seconds = 180.2)
[2022-05-31 14:13:26,562][root][INFO] - Step 1233920 @ 6648.0 SPS. Inference batcher size: 188. Learner queue size: 2. Other stats: (step = 1233920, mean_episode_return = -38.789, mean_episode_step = 3494.2, total_loss = 936.95, pg_loss = 638.54, baseline_loss = 308.0, entropy_loss = -9.5906, learner_queue_size = 18, _tick = 89, _time = 1.654e+09, train_seconds = 185.2)
[2022-05-31 14:13:31,568][root][INFO] - Step 1267200 @ 6648.1 SPS. Inference batcher size: 114. Learner queue size: 16. Other stats: (step = 1267200, mean_episode_return = None, mean_episode_step = 3884.2, total_loss = -346.78, pg_loss = -358.94, baseline_loss = 21.669, entropy_loss = -9.5183, learner_queue_size = 19, _tick = 93, _time = 1.654e+09, train_seconds = 190.3)
[2022-05-31 14:13:36,574][root][INFO] - Step 1300480 @ 6648.1 SPS. Inference batcher size: 128. Learner queue size: 21. Other stats: (step = 1300480, mean_episode_return = None, mean_episode_step = 4616.5, total_loss = -638.46, pg_loss = -632.54, baseline_loss = 3.5338, entropy_loss = -9.4517, learner_queue_size = 23, _tick = 96, _time = 1.654e+09, train_seconds = 195.3)
[2022-05-31 14:13:41,580][root][INFO] - Step 1333760 @ 6647.9 SPS. Inference batcher size: 105. Learner queue size: 19. Other stats: (step = 1333760, mean_episode_return = None, mean_episode_step = 4281.4, total_loss = -72.626, pg_loss = -97.148, baseline_loss = 33.905, entropy_loss = -9.3841, learner_queue_size = 19, _tick = 99, _time = 1.654e+09, train_seconds = 200.3)
[2022-05-31 14:13:46,586][root][INFO] - Step 1369600 @ 7159.6 SPS. Inference batcher size: 105. Learner queue size: 25. Other stats: (step = 1369600, mean_episode_return = None, mean_episode_step = 3697.6, total_loss = 133.08, pg_loss = 75.371, baseline_loss = 67.056, entropy_loss = -9.3465, learner_queue_size = 20, _tick = 101, _time = 1.654e+09, train_seconds = 205.3)
[2022-05-31 14:13:51,590][root][INFO] - Step 1402880 @ 6650.7 SPS. Inference batcher size: 210. Learner queue size: 21. Other stats: (step = 1402880, mean_episode_return = None, mean_episode_step = 4882.6, total_loss = 11.886, pg_loss = -13.316, baseline_loss = 34.41, entropy_loss = -9.208, learner_queue_size = 20, _tick = 104, _time = 1.654e+09, train_seconds = 210.3)
[2022-05-31 14:13:56,594][root][INFO] - Step 1436160 @ 6650.6 SPS. Inference batcher size: 135. Learner queue size: 12. Other stats: (step = 1436160, mean_episode_return = None, mean_episode_step = 4689.4, total_loss = 1.3125e+04, pg_loss = 6771.8, baseline_loss = 6362.3, entropy_loss = -9.226, learner_queue_size = 12, _tick = 106, _time = 1.654e+09, train_seconds = 215.3)
[2022-05-31 14:14:01,598][root][INFO] - Step 1469440 @ 6650.7 SPS. Inference batcher size: 206. Learner queue size: 4. Other stats: (step = 1469440, mean_episode_return = None, mean_episode_step = 3975.4, total_loss = 2692.2, pg_loss = 1753.2, baseline_loss = 948.21, entropy_loss = -9.2026, learner_queue_size = 18, _tick = 109, _time = 1.654e+09, train_seconds = 220.3)
[2022-05-31 14:14:06,602][root][INFO] - Step 1502720 @ 6650.7 SPS. Inference batcher size: 135. Learner queue size: 5. Other stats: (step = 1502720, mean_episode_return = None, mean_episode_step = 4623.7, total_loss = 66.934, pg_loss = -88.919, baseline_loss = 165.01, entropy_loss = -9.1534, learner_queue_size = 16, _tick = 113, _time = 1.654e+09, train_seconds = 225.3)
[2022-05-31 14:14:11,606][root][INFO] - Step 1536000 @ 6650.7 SPS. Inference batcher size: 167. Learner queue size: 12. Other stats: (step = 1536000, mean_episode_return = None, mean_episode_step = 4453.6, total_loss = 393.11, pg_loss = 195.26, baseline_loss = 206.92, entropy_loss = -9.0613, learner_queue_size = 13, _tick = 115, _time = 1.654e+09, train_seconds = 230.3)
[2022-05-31 14:14:16,610][root][INFO] - Step 1569280 @ 6650.8 SPS. Inference batcher size: 55. Learner queue size: 9. Other stats: (step = 1569280, mean_episode_return = None, mean_episode_step = 5436.3, total_loss = 228.26, pg_loss = 144.23, baseline_loss = 92.961, entropy_loss = -8.9328, learner_queue_size = 24, _tick = 120, _time = 1.654e+09, train_seconds = 235.3)
[2022-05-31 14:14:21,616][root][INFO] - Step 1602560 @ 6647.9 SPS. Inference batcher size: 111. Learner queue size: 10. Other stats: (step = 1602560, mean_episode_return = None, mean_episode_step = 4388.5, total_loss = -251.24, pg_loss = -268.2, baseline_loss = 25.952, entropy_loss = -8.9956, learner_queue_size = 17, _tick = 125, _time = 1.654e+09, train_seconds = 240.3)
[2022-05-31 14:14:26,622][root][INFO] - Step 1635840 @ 6647.9 SPS. Inference batcher size: 110. Learner queue size: 14. Other stats: (step = 1635840, mean_episode_return = None, mean_episode_step = 4081.2, total_loss = 1418.3, pg_loss = 1062.0, baseline_loss = 365.38, entropy_loss = -9.0275, learner_queue_size = 23, _tick = 132, _time = 1.654e+09, train_seconds = 245.3)
[2022-05-31 14:14:31,630][root][INFO] - Step 1669120 @ 6645.4 SPS. Inference batcher size: 164. Learner queue size: 8. Other stats: (step = 1669120, mean_episode_return = -3.02, mean_episode_step = 4859.7, total_loss = 1998.8, pg_loss = 1310.8, baseline_loss = 696.93, entropy_loss = -8.9655, learner_queue_size = 21, _tick = 140, _time = 1.654e+09, train_seconds = 250.3)
[2022-05-31 14:14:36,636][root][INFO] - Step 1702400 @ 6647.9 SPS. Inference batcher size: 150. Learner queue size: 13. Other stats: (step = 1702400, mean_episode_return = -48.457, mean_episode_step = 4459.6, total_loss = 271.45, pg_loss = 211.76, baseline_loss = 68.654, entropy_loss = -8.9617, learner_queue_size = 21, _tick = 149, _time = 1.654e+09, train_seconds = 255.3)
[2022-05-31 14:14:41,642][root][INFO] - Step 1735680 @ 6648.0 SPS. Inference batcher size: 135. Learner queue size: 21. Other stats: (step = 1735680, mean_episode_return = None, mean_episode_step = 5031.8, total_loss = -538.58, pg_loss = -533.89, baseline_loss = 4.2122, entropy_loss = -8.9011, learner_queue_size = 29, _tick = 158, _time = 1.654e+09, train_seconds = 260.3)
[2022-05-31 14:14:46,649][root][INFO] - Step 1768960 @ 6647.4 SPS. Inference batcher size: 19. Learner queue size: 9. Other stats: (step = 1768960, mean_episode_return = 72.149, mean_episode_step = 4497.6, total_loss = 2631.2, pg_loss = 1467.0, baseline_loss = 1173.2, entropy_loss = -8.9777, learner_queue_size = 13, _tick = 167, _time = 1.654e+09, train_seconds = 265.3)
[2022-05-31 14:14:51,655][root][INFO] - Step 1802240 @ 6647.5 SPS. Inference batcher size: 84. Learner queue size: 13. Other stats: (step = 1802240, mean_episode_return = None, mean_episode_step = 3976.7, total_loss = 61.444, pg_loss = 32.234, baseline_loss = 38.167, entropy_loss = -8.9575, learner_queue_size = 24, _tick = 173, _time = 1.654e+09, train_seconds = 270.3)
[2022-05-31 14:14:56,661][root][INFO] - Step 1835520 @ 6648.2 SPS. Inference batcher size: 112. Learner queue size: 21. Other stats: (step = 1835520, mean_episode_return = -49.717, mean_episode_step = 3821.5, total_loss = 966.01, pg_loss = 668.37, baseline_loss = 306.59, entropy_loss = -8.9418, learner_queue_size = 19, _tick = 183, _time = 1.654e+09, train_seconds = 275.3)
[2022-05-31 14:15:01,667][root][INFO] - Step 1868800 @ 6648.0 SPS. Inference batcher size: 98. Learner queue size: 18. Other stats: (step = 1868800, mean_episode_return = None, mean_episode_step = 3281.6, total_loss = -156.96, pg_loss = -167.74, baseline_loss = 19.652, entropy_loss = -8.876, learner_queue_size = 27, _tick = 190, _time = 1.654e+09, train_seconds = 280.4)
[2022-05-31 14:15:06,673][root][INFO] - Step 1902080 @ 6648.1 SPS. Inference batcher size: 119. Learner queue size: 7. Other stats: (step = 1902080, mean_episode_return = None, mean_episode_step = 3585.9, total_loss = 1154.0, pg_loss = 802.84, baseline_loss = 359.93, entropy_loss = -8.8126, learner_queue_size = 19, _tick = 199, _time = 1.654e+09, train_seconds = 285.4)
[2022-05-31 14:15:11,678][root][INFO] - Step 1935360 @ 6649.5 SPS. Inference batcher size: 61. Learner queue size: 13. Other stats: (step = 1935360, mean_episode_return = 9.0488, mean_episode_step = 3743.3, total_loss = -321.63, pg_loss = -315.49, baseline_loss = 2.8334, entropy_loss = -8.973, learner_queue_size = 17, _tick = 208, _time = 1.654e+09, train_seconds = 290.4)
[2022-05-31 14:15:16,682][root][INFO] - Step 1968640 @ 6650.6 SPS. Inference batcher size: 86. Learner queue size: 16. Other stats: (step = 1968640, mean_episode_return = None, mean_episode_step = 2517.9, total_loss = 2385.6, pg_loss = 1608.1, baseline_loss = 786.6, entropy_loss = -9.0462, learner_queue_size = 12, _tick = 216, _time = 1.654e+09, train_seconds = 295.4)
[2022-05-31 14:15:21,686][root][INFO] - Step 2001920 @ 6650.7 SPS. Inference batcher size: 84. Learner queue size: 13. Other stats: (step = 2001920, mean_episode_return = None, mean_episode_step = 2685.7, total_loss = -129.32, pg_loss = -146.28, baseline_loss = 25.995, entropy_loss = -9.0339, learner_queue_size = 17, _tick = 222, _time = 1.654e+09, train_seconds = 300.4)
[2022-05-31 14:15:26,690][root][INFO] - Step 2035200 @ 6650.8 SPS. Inference batcher size: 107. Learner queue size: 0. Other stats: (step = 2035200, mean_episode_return = -30.391, mean_episode_step = 2811.2, total_loss = 1323.3, pg_loss = 883.86, baseline_loss = 448.44, entropy_loss = -8.9564, learner_queue_size = 19, _tick = 232, _time = 1.654e+09, train_seconds = 305.4)
[2022-05-31 14:15:31,693][root][INFO] - Step 2068480 @ 6651.8 SPS. Inference batcher size: 100. Learner queue size: 3. Other stats: (step = 2068480, mean_episode_return = None, mean_episode_step = 3366.0, total_loss = -359.69, pg_loss = -363.71, baseline_loss = 12.967, entropy_loss = -8.9488, learner_queue_size = 17, _tick = 241, _time = 1.654e+09, train_seconds = 310.4)
[2022-05-31 14:15:36,698][root][INFO] - Step 2101760 @ 6649.5 SPS. Inference batcher size: 95. Learner queue size: 2. Other stats: (step = 2101760, mean_episode_return = -7.5002, mean_episode_step = 1710.0, total_loss = 586.3, pg_loss = 214.38, baseline_loss = 380.84, entropy_loss = -8.9231, learner_queue_size = 23, _tick = 248, _time = 1.654e+09, train_seconds = 315.4)
[2022-05-31 14:15:41,702][root][INFO] - Step 2135040 @ 6650.6 SPS. Inference batcher size: 111. Learner queue size: 4. Other stats: (step = 2135040, mean_episode_return = None, mean_episode_step = 2626.7, total_loss = 1705.4, pg_loss = 1149.0, baseline_loss = 565.27, entropy_loss = -8.785, learner_queue_size = 15, _tick = 253, _time = 1.654e+09, train_seconds = 320.4)
[2022-05-31 14:15:46,708][root][INFO] - Step 2168320 @ 6647.9 SPS. Inference batcher size: 163. Learner queue size: 6. Other stats: (step = 2168320, mean_episode_return = None, mean_episode_step = 2792.2, total_loss = -522.3, pg_loss = -516.91, baseline_loss = 3.3695, entropy_loss = -8.758, learner_queue_size = 14, _tick = 258, _time = 1.654e+09, train_seconds = 325.4)
[2022-05-31 14:15:51,714][root][INFO] - Step 2201600 @ 6648.0 SPS. Inference batcher size: 60. Learner queue size: 3. Other stats: (step = 2201600, mean_episode_return = None, mean_episode_step = 2668.7, total_loss = 124.22, pg_loss = 87.065, baseline_loss = 45.963, entropy_loss = -8.8069, learner_queue_size = 18, _tick = 263, _time = 1.654e+09, train_seconds = 330.4)
[2022-05-31 14:15:56,718][root][INFO] - Step 2234880 @ 6650.9 SPS. Inference batcher size: 114. Learner queue size: 7. Other stats: (step = 2234880, mean_episode_return = None, mean_episode_step = 2378.6, total_loss = 40.275, pg_loss = -21.634, baseline_loss = 70.626, entropy_loss = -8.7176, learner_queue_size = 19, _tick = 270, _time = 1.654e+09, train_seconds = 335.4)
[2022-05-31 14:16:01,722][root][INFO] - Step 2268160 @ 6650.6 SPS. Inference batcher size: 138. Learner queue size: 25. Other stats: (step = 2268160, mean_episode_return = None, mean_episode_step = 2696.4, total_loss = -610.48, pg_loss = -605.57, baseline_loss = 3.753, entropy_loss = -8.6599, learner_queue_size = 18, _tick = 276, _time = 1.654e+09, train_seconds = 340.4)
[2022-05-31 14:16:06,726][root][INFO] - Step 2301440 @ 6650.9 SPS. Inference batcher size: 98. Learner queue size: 24. Other stats: (step = 2301440, mean_episode_return = None, mean_episode_step = 2027.2, total_loss = -572.06, pg_loss = -573.14, baseline_loss = 9.7081, entropy_loss = -8.6295, learner_queue_size = 22, _tick = 283, _time = 1.654e+09, train_seconds = 345.4)
[2022-05-31 14:16:11,730][root][INFO] - Step 2334720 @ 6650.6 SPS. Inference batcher size: 107. Learner queue size: 31. Other stats: (step = 2334720, mean_episode_return = 54.392, mean_episode_step = 2611.2, total_loss = 2836.6, pg_loss = 1181.1, baseline_loss = 1664.2, entropy_loss = -8.732, learner_queue_size = 28, _tick = 293, _time = 1.654e+09, train_seconds = 350.4)
[2022-05-31 14:16:16,736][root][INFO] - Step 2365440 @ 6136.5 SPS. Inference batcher size: 114. Learner queue size: 21. Other stats: (step = 2365440, mean_episode_return = None, mean_episode_step = 1962.9, total_loss = -33.143, pg_loss = -60.581, baseline_loss = 36.197, entropy_loss = -8.7588, learner_queue_size = 13, _tick = 295, _time = 1.654e+09, train_seconds = 355.4)
[2022-05-31 14:16:21,742][root][INFO] - Step 2398720 @ 6648.2 SPS. Inference batcher size: 115. Learner queue size: 16. Other stats: (step = 2398720, mean_episode_return = None, mean_episode_step = 2839.2, total_loss = 103.93, pg_loss = -32.655, baseline_loss = 145.33, entropy_loss = -8.7449, learner_queue_size = 21, _tick = 301, _time = 1.654e+09, train_seconds = 360.4)
[2022-05-31 14:16:26,746][root][INFO] - Step 2432000 @ 6650.7 SPS. Inference batcher size: 76. Learner queue size: 18. Other stats: (step = 2432000, mean_episode_return = None, mean_episode_step = 2123.2, total_loss = -532.61, pg_loss = -527.38, baseline_loss = 3.4373, entropy_loss = -8.662, learner_queue_size = 17, _tick = 304, _time = 1.654e+09, train_seconds = 365.4)
[2022-05-31 14:16:31,752][root][INFO] - Step 2465280 @ 6648.3 SPS. Inference batcher size: 144. Learner queue size: 17. Other stats: (step = 2465280, mean_episode_return = None, mean_episode_step = 2341.7, total_loss = 1766.2, pg_loss = 1148.6, baseline_loss = 626.0, entropy_loss = -8.4637, learner_queue_size = 20, _tick = 309, _time = 1.654e+09, train_seconds = 370.4)
[2022-05-31 14:16:36,754][root][INFO] - Step 2498560 @ 6653.1 SPS. Inference batcher size: 83. Learner queue size: 16. Other stats: (step = 2498560, mean_episode_return = None, mean_episode_step = 3055.8, total_loss = 885.45, pg_loss = 573.08, baseline_loss = 320.88, entropy_loss = -8.5058, learner_queue_size = 24, _tick = 315, _time = 1.654e+09, train_seconds = 375.4)
[2022-05-31 14:16:41,758][root][INFO] - Step 2531840 @ 6650.6 SPS. Inference batcher size: 87. Learner queue size: 15. Other stats: (step = 2531840, mean_episode_return = None, mean_episode_step = 2301.9, total_loss = 570.57, pg_loss = 351.47, baseline_loss = 227.63, entropy_loss = -8.5259, learner_queue_size = 24, _tick = 322, _time = 1.654e+09, train_seconds = 380.4)
[2022-05-31 14:16:46,762][root][INFO] - Step 2567680 @ 7162.3 SPS. Inference batcher size: 97. Learner queue size: 25. Other stats: (step = 2567680, mean_episode_return = None, mean_episode_step = 2597.0, total_loss = 679.79, pg_loss = 390.97, baseline_loss = 297.29, entropy_loss = -8.4624, learner_queue_size = 16, _tick = 329, _time = 1.654e+09, train_seconds = 385.4)
[2022-05-31 14:16:51,766][root][INFO] - Step 2600960 @ 6650.8 SPS. Inference batcher size: 31. Learner queue size: 28. Other stats: (step = 2600960, mean_episode_return = None, mean_episode_step = 2617.1, total_loss = -412.12, pg_loss = -418.67, baseline_loss = 14.978, entropy_loss = -8.428, learner_queue_size = 27, _tick = 338, _time = 1.654e+09, train_seconds = 390.5)
[2022-05-31 14:16:56,771][root][INFO] - Step 2634240 @ 6650.0 SPS. Inference batcher size: 21. Learner queue size: 3. Other stats: (step = 2634240, mean_episode_return = None, mean_episode_step = 2156.3, total_loss = -230.88, pg_loss = -254.23, baseline_loss = 31.669, entropy_loss = -8.3167, learner_queue_size = 19, _tick = 348, _time = 1.654e+09, train_seconds = 395.5)
[2022-05-31 14:17:01,774][root][INFO] - Step 2667520 @ 6651.0 SPS. Inference batcher size: 51. Learner queue size: 27. Other stats: (step = 2667520, mean_episode_return = None, mean_episode_step = 2210.9, total_loss = -27.974, pg_loss = -190.27, baseline_loss = 170.62, entropy_loss = -8.3302, learner_queue_size = 19, _tick = 353, _time = 1.654e+09, train_seconds = 400.5)
[2022-05-31 14:17:06,778][root][INFO] - Step 2698240 @ 6139.3 SPS. Inference batcher size: 43. Learner queue size: 21. Other stats: (step = 2698240, mean_episode_return = None, mean_episode_step = 2604.8, total_loss = -297.78, pg_loss = -304.27, baseline_loss = 14.658, entropy_loss = -8.163, learner_queue_size = 14, _tick = 360, _time = 1.654e+09, train_seconds = 405.5)
[2022-05-31 14:17:11,782][root][INFO] - Step 2734080 @ 7162.2 SPS. Inference batcher size: 118. Learner queue size: 22. Other stats: (step = 2734080, mean_episode_return = None, mean_episode_step = 2364.2, total_loss = -43.368, pg_loss = -93.72, baseline_loss = 58.507, entropy_loss = -8.1543, learner_queue_size = 21, _tick = 368, _time = 1.654e+09, train_seconds = 410.5)
[2022-05-31 14:17:16,786][root][INFO] - Step 2764800 @ 6139.1 SPS. Inference batcher size: 103. Learner queue size: 15. Other stats: (step = 2764800, mean_episode_return = None, mean_episode_step = 2795.1, total_loss = 548.95, pg_loss = 338.78, baseline_loss = 218.29, entropy_loss = -8.1183, learner_queue_size = 32, _tick = 372, _time = 1.654e+09, train_seconds = 415.5)
[2022-05-31 14:17:21,792][root][INFO] - Step 2795520 @ 6137.0 SPS. Inference batcher size: 168. Learner queue size: 16. Other stats: (step = 2795520, mean_episode_return = -21.531, mean_episode_step = 3028.1, total_loss = -470.45, pg_loss = -479.37, baseline_loss = 17.027, entropy_loss = -8.1022, learner_queue_size = 13, _tick = 382, _time = 1.654e+09, train_seconds = 420.5)
[2022-05-31 14:17:26,798][root][INFO] - Step 2828800 @ 6647.9 SPS. Inference batcher size: 140. Learner queue size: 12. Other stats: (step = 2828800, mean_episode_return = None, mean_episode_step = 2563.4, total_loss = -558.93, pg_loss = -554.48, baseline_loss = 3.7019, entropy_loss = -8.1529, learner_queue_size = 22, _tick = 393, _time = 1.654e+09, train_seconds = 425.5)
[2022-05-31 14:17:31,802][root][INFO] - Step 2862080 @ 6650.3 SPS. Inference batcher size: 133. Learner queue size: 16. Other stats: (step = 2862080, mean_episode_return = -3.1404, mean_episode_step = 2241.2, total_loss = 261.08, pg_loss = 67.907, baseline_loss = 201.43, entropy_loss = -8.2524, learner_queue_size = 21, _tick = 404, _time = 1.654e+09, train_seconds = 430.5)
[2022-05-31 14:17:36,808][root][INFO] - Step 2895360 @ 6648.0 SPS. Inference batcher size: 96. Learner queue size: 0. Other stats: (step = 2895360, mean_episode_return = None, mean_episode_step = 1784.3, total_loss = -150.99, pg_loss = -176.59, baseline_loss = 33.8, entropy_loss = -8.1974, learner_queue_size = 17, _tick = 412, _time = 1.654e+09, train_seconds = 435.5)
[2022-05-31 14:17:41,814][root][INFO] - Step 2928640 @ 6648.2 SPS. Inference batcher size: 136. Learner queue size: 1. Other stats: (step = 2928640, mean_episode_return = 219.36, mean_episode_step = 2018.8, total_loss = -218.74, pg_loss = -317.14, baseline_loss = 106.49, entropy_loss = -8.0915, learner_queue_size = 29, _tick = 422, _time = 1.654e+09, train_seconds = 440.5)
[2022-05-31 14:17:46,821][root][INFO] - Step 2961920 @ 6647.3 SPS. Inference batcher size: 72. Learner queue size: 2. Other stats: (step = 2961920, mean_episode_return = None, mean_episode_step = 1885.3, total_loss = 632.97, pg_loss = 456.24, baseline_loss = 184.85, entropy_loss = -8.1221, learner_queue_size = 27, _tick = 431, _time = 1.654e+09, train_seconds = 445.5)
[2022-05-31 14:17:51,826][root][INFO] - Step 2995200 @ 6648.7 SPS. Inference batcher size: 129. Learner queue size: 3. Other stats: (step = 2995200, mean_episode_return = -12.32, mean_episode_step = 1873.4, total_loss = 2277.8, pg_loss = 1128.8, baseline_loss = 1157.1, entropy_loss = -8.1141, learner_queue_size = 18, _tick = 439, _time = 1.654e+09, train_seconds = 450.5)
[2022-05-31 14:17:56,830][root][INFO] - Step 3028480 @ 6650.7 SPS. Inference batcher size: 122. Learner queue size: 1. Other stats: (step = 3028480, mean_episode_return = None, mean_episode_step = 1576.6, total_loss = 5833.5, pg_loss = 3266.7, baseline_loss = 2574.9, entropy_loss = -8.1213, learner_queue_size = 13, _tick = 446, _time = 1.654e+09, train_seconds = 455.5)
[2022-05-31 14:18:01,834][root][INFO] - Step 3061760 @ 6650.6 SPS. Inference batcher size: 91. Learner queue size: 1. Other stats: (step = 3061760, mean_episode_return = None, mean_episode_step = 1790.2, total_loss = 4052.0, pg_loss = 1901.5, baseline_loss = 2158.4, entropy_loss = -7.9743, learner_queue_size = 26, _tick = 456, _time = 1.654e+09, train_seconds = 460.5)
[2022-05-31 14:18:06,837][root][INFO] - Step 3095040 @ 6651.8 SPS. Inference batcher size: 75. Learner queue size: 4. Other stats: (step = 3095040, mean_episode_return = 87.868, mean_episode_step = 1792.4, total_loss = -396.56, pg_loss = -412.02, baseline_loss = 23.521, entropy_loss = -8.0611, learner_queue_size = 15, _tick = 463, _time = 1.654e+09, train_seconds = 465.5)
[2022-05-31 14:18:11,842][root][INFO] - Step 3128320 @ 6649.6 SPS. Inference batcher size: 111. Learner queue size: 3. Other stats: (step = 3128320, mean_episode_return = None, mean_episode_step = 1453.2, total_loss = -563.43, pg_loss = -559.01, baseline_loss = 3.6548, entropy_loss = -8.0806, learner_queue_size = 21, _tick = 474, _time = 1.654e+09, train_seconds = 470.5)
[2022-05-31 14:18:16,846][root][INFO] - Step 3161600 @ 6650.7 SPS. Inference batcher size: 131. Learner queue size: 23. Other stats: (step = 3161600, mean_episode_return = None, mean_episode_step = 1430.6, total_loss = -457.39, pg_loss = -472.63, baseline_loss = 23.321, entropy_loss = -8.0739, learner_queue_size = 23, _tick = 483, _time = 1.654e+09, train_seconds = 475.5)
[2022-05-31 14:18:21,852][root][INFO] - Step 3192320 @ 6136.6 SPS. Inference batcher size: 128. Learner queue size: 17. Other stats: (step = 3192320, mean_episode_return = None, mean_episode_step = 1677.2, total_loss = 28.449, pg_loss = -27.628, baseline_loss = 64.224, entropy_loss = -8.1469, learner_queue_size = 15, _tick = 488, _time = 1.654e+09, train_seconds = 480.5)
[2022-05-31 14:18:26,858][root][INFO] - Step 3225600 @ 6648.0 SPS. Inference batcher size: 129. Learner queue size: 14. Other stats: (step = 3225600, mean_episode_return = None, mean_episode_step = 1856.2, total_loss = 1623.6, pg_loss = 1098.0, baseline_loss = 533.78, entropy_loss = -8.2333, learner_queue_size = 18, _tick = 494, _time = 1.654e+09, train_seconds = 485.5)
[2022-05-31 14:18:31,862][root][INFO] - Step 3261440 @ 7162.0 SPS. Inference batcher size: 170. Learner queue size: 10. Other stats: (step = 3261440, mean_episode_return = 6.1299, mean_episode_step = 1356.3, total_loss = -259.45, pg_loss = -295.94, baseline_loss = 44.712, entropy_loss = -8.2216, learner_queue_size = 7, _tick = 506, _time = 1.654e+09, train_seconds = 490.5)
[2022-05-31 14:18:36,866][root][INFO] - Step 3294720 @ 6651.0 SPS. Inference batcher size: 38. Learner queue size: 21. Other stats: (step = 3294720, mean_episode_return = 16.017, mean_episode_step = 1657.0, total_loss = -436.68, pg_loss = -467.62, baseline_loss = 39.028, entropy_loss = -8.0834, learner_queue_size = 16, _tick = 515, _time = 1.654e+09, train_seconds = 495.6)
[2022-05-31 14:18:41,870][root][INFO] - Step 3328000 @ 6650.7 SPS. Inference batcher size: 128. Learner queue size: 23. Other stats: (step = 3328000, mean_episode_return = 1.1898, mean_episode_step = 1520.8, total_loss = 1176.3, pg_loss = 418.04, baseline_loss = 766.36, entropy_loss = -8.1017, learner_queue_size = 19, _tick = 523, _time = 1.654e+09, train_seconds = 500.6)
[2022-05-31 14:18:46,874][root][INFO] - Step 3361280 @ 6650.7 SPS. Inference batcher size: 23. Learner queue size: 26. Other stats: (step = 3361280, mean_episode_return = None, mean_episode_step = 1617.8, total_loss = -741.57, pg_loss = -740.58, baseline_loss = 7.0996, entropy_loss = -8.0911, learner_queue_size = 16, _tick = 533, _time = 1.654e+09, train_seconds = 505.6)
[2022-05-31 14:18:51,878][root][INFO] - Step 3392000 @ 6139.0 SPS. Inference batcher size: 110. Learner queue size: 19. Other stats: (step = 3392000, mean_episode_return = -3.0903, mean_episode_step = 1756.7, total_loss = 642.78, pg_loss = 351.9, baseline_loss = 298.97, entropy_loss = -8.0841, learner_queue_size = 17, _tick = 540, _time = 1.654e+09, train_seconds = 510.6)
[2022-05-31 14:18:56,882][root][INFO] - Step 3427840 @ 7162.1 SPS. Inference batcher size: 83. Learner queue size: 21. Other stats: (step = 3427840, mean_episode_return = 42.451, mean_episode_step = 1568.2, total_loss = 851.25, pg_loss = 437.0, baseline_loss = 422.37, entropy_loss = -8.1252, learner_queue_size = 17, _tick = 552, _time = 1.654e+09, train_seconds = 515.6)
[2022-05-31 14:19:01,888][root][INFO] - Step 3458560 @ 6136.2 SPS. Inference batcher size: 94. Learner queue size: 22. Other stats: (step = 3458560, mean_episode_return = None, mean_episode_step = 1683.3, total_loss = -264.66, pg_loss = -278.63, baseline_loss = 22.028, entropy_loss = -8.0617, learner_queue_size = 16, _tick = 561, _time = 1.654e+09, train_seconds = 520.6)
[2022-05-31 14:19:06,894][root][INFO] - Step 3494400 @ 7159.4 SPS. Inference batcher size: 76. Learner queue size: 19. Other stats: (step = 3494400, mean_episode_return = -12.42, mean_episode_step = 1739.3, total_loss = 219.47, pg_loss = -340.35, baseline_loss = 567.89, entropy_loss = -8.073, learner_queue_size = 16, _tick = 572, _time = 1.654e+09, train_seconds = 525.6)
[2022-05-31 14:19:11,900][root][INFO] - Step 3525120 @ 6136.6 SPS. Inference batcher size: 88. Learner queue size: 17. Other stats: (step = 3525120, mean_episode_return = None, mean_episode_step = 1451.5, total_loss = -622.82, pg_loss = -646.25, baseline_loss = 31.521, entropy_loss = -8.0924, learner_queue_size = 20, _tick = 582, _time = 1.654e+09, train_seconds = 530.6)
[2022-05-31 14:19:16,906][root][INFO] - Step 3558400 @ 6648.7 SPS. Inference batcher size: 155. Learner queue size: 16. Other stats: (step = 3558400, mean_episode_return = 2.9974, mean_episode_step = 1513.0, total_loss = 840.14, pg_loss = 495.56, baseline_loss = 352.72, entropy_loss = -8.1384, learner_queue_size = 26, _tick = 589, _time = 1.654e+09, train_seconds = 535.6)
[2022-05-31 14:19:21,910][root][INFO] - Step 3591680 @ 6650.7 SPS. Inference batcher size: 97. Learner queue size: 14. Other stats: (step = 3591680, mean_episode_return = 81.788, mean_episode_step = 1272.7, total_loss = -402.95, pg_loss = -405.68, baseline_loss = 10.732, entropy_loss = -7.9998, learner_queue_size = 16, _tick = 597, _time = 1.654e+09, train_seconds = 540.6)
[2022-05-31 14:19:26,915][root][INFO] - Step 3624960 @ 6649.8 SPS. Inference batcher size: 101. Learner queue size: 12. Other stats: (step = 3624960, mean_episode_return = -53.077, mean_episode_step = 1273.5, total_loss = 3441.2, pg_loss = 2288.1, baseline_loss = 1161.1, entropy_loss = -7.9376, learner_queue_size = 12, _tick = 609, _time = 1.654e+09, train_seconds = 545.6)
[2022-05-31 14:19:31,918][root][INFO] - Step 3658240 @ 6651.6 SPS. Inference batcher size: 32. Learner queue size: 18. Other stats: (step = 3658240, mean_episode_return = 26.847, mean_episode_step = 1429.4, total_loss = -294.97, pg_loss = -311.17, baseline_loss = 24.104, entropy_loss = -7.9064, learner_queue_size = 23, _tick = 620, _time = 1.654e+09, train_seconds = 550.6)
[2022-05-31 14:19:36,922][root][INFO] - Step 3691520 @ 6650.5 SPS. Inference batcher size: 117. Learner queue size: 17. Other stats: (step = 3691520, mean_episode_return = 41.96, mean_episode_step = 1376.0, total_loss = 2378.8, pg_loss = 1292.9, baseline_loss = 1093.7, entropy_loss = -7.8077, learner_queue_size = 24, _tick = 631, _time = 1.654e+09, train_seconds = 555.6)
[2022-05-31 14:19:41,926][root][INFO] - Step 3724800 @ 6650.8 SPS. Inference batcher size: 142. Learner queue size: 21. Other stats: (step = 3724800, mean_episode_return = None, mean_episode_step = 1408.1, total_loss = 310.91, pg_loss = 180.92, baseline_loss = 137.75, entropy_loss = -7.755, learner_queue_size = 13, _tick = 641, _time = 1.654e+09, train_seconds = 560.6)
[2022-05-31 14:19:46,930][root][INFO] - Step 3758080 @ 6650.5 SPS. Inference batcher size: 77. Learner queue size: 10. Other stats: (step = 3758080, mean_episode_return = None, mean_episode_step = 1123.1, total_loss = 969.03, pg_loss = 627.84, baseline_loss = 348.99, entropy_loss = -7.7907, learner_queue_size = 12, _tick = 650, _time = 1.654e+09, train_seconds = 565.6)
[2022-05-31 14:19:51,934][root][INFO] - Step 3791360 @ 6650.8 SPS. Inference batcher size: 146. Learner queue size: 10. Other stats: (step = 3791360, mean_episode_return = 1.8948, mean_episode_step = 1150.4, total_loss = -205.35, pg_loss = -226.77, baseline_loss = 29.102, entropy_loss = -7.6891, learner_queue_size = 17, _tick = 659, _time = 1.654e+09, train_seconds = 570.6)
[2022-05-31 14:19:56,938][root][INFO] - Step 3824640 @ 6650.6 SPS. Inference batcher size: 147. Learner queue size: 6. Other stats: (step = 3824640, mean_episode_return = 27.14, mean_episode_step = 1409.5, total_loss = -0.28043, pg_loss = -48.86, baseline_loss = 56.309, entropy_loss = -7.7293, learner_queue_size = 23, _tick = 668, _time = 1.654e+09, train_seconds = 575.6)
[2022-05-31 14:20:01,942][root][INFO] - Step 3857920 @ 6650.6 SPS. Inference batcher size: 77. Learner queue size: 4. Other stats: (step = 3857920, mean_episode_return = None, mean_episode_step = 1591.5, total_loss = 38.673, pg_loss = -50.57, baseline_loss = 96.952, entropy_loss = -7.7092, learner_queue_size = 17, _tick = 676, _time = 1.654e+09, train_seconds = 580.6)
[2022-05-31 14:20:06,946][root][INFO] - Step 3891200 @ 6650.8 SPS. Inference batcher size: 59. Learner queue size: 2. Other stats: (step = 3891200, mean_episode_return = None, mean_episode_step = 1441.9, total_loss = -252.64, pg_loss = -354.89, baseline_loss = 110.06, entropy_loss = -7.8099, learner_queue_size = 23, _tick = 681, _time = 1.654e+09, train_seconds = 585.6)
[2022-05-31 14:20:11,950][root][INFO] - Step 3924480 @ 6650.6 SPS. Inference batcher size: 130. Learner queue size: 23. Other stats: (step = 3924480, mean_episode_return = 34.33, mean_episode_step = 1497.8, total_loss = -114.24, pg_loss = -130.62, baseline_loss = 24.145, entropy_loss = -7.7662, learner_queue_size = 17, _tick = 689, _time = 1.654e+09, train_seconds = 590.6)
[2022-05-31 14:20:16,956][root][INFO] - Step 3955200 @ 6136.5 SPS. Inference batcher size: 100. Learner queue size: 16. Other stats: (step = 3955200, mean_episode_return = None, mean_episode_step = 1320.6, total_loss = 318.59, pg_loss = 192.15, baseline_loss = 134.21, entropy_loss = -7.7635, learner_queue_size = 22, _tick = 694, _time = 1.654e+09, train_seconds = 595.6)
[2022-05-31 14:20:21,962][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 14:20:22,043][root][INFO] - Step 3988480 @ 6648.2 SPS. Inference batcher size: 27. Learner queue size: 16. Other stats: (step = 3991040, mean_episode_return = None, mean_episode_step = 1633.8, total_loss = 3116.8, pg_loss = 1768.5, baseline_loss = 1356.1, entropy_loss = -7.7715, learner_queue_size = 16, _tick = 705, _time = 1.654e+09, train_seconds = 600.6)
[2022-05-31 14:20:27,046][root][INFO] - Step 4024320 @ 7049.6 SPS. Inference batcher size: 35. Learner queue size: 13. Other stats: (step = 4024320, mean_episode_return = 18.81, mean_episode_step = 1595.6, total_loss = -219.15, pg_loss = -313.71, baseline_loss = 102.4, entropy_loss = -7.8447, learner_queue_size = 13, _tick = 716, _time = 1.654e+09, train_seconds = 605.7)
[2022-05-31 14:20:32,050][root][INFO] - Step 4055040 @ 6139.1 SPS. Inference batcher size: 174. Learner queue size: 17. Other stats: (step = 4055040, mean_episode_return = 16.255, mean_episode_step = 1054.4, total_loss = 1014.1, pg_loss = 545.84, baseline_loss = 476.08, entropy_loss = -7.8304, learner_queue_size = 21, _tick = 723, _time = 1.654e+09, train_seconds = 610.7)
[2022-05-31 14:20:37,056][root][INFO] - Step 4088320 @ 6648.0 SPS. Inference batcher size: 133. Learner queue size: 12. Other stats: (step = 4088320, mean_episode_return = -10.735, mean_episode_step = 1326.2, total_loss = 2227.1, pg_loss = 994.44, baseline_loss = 1240.6, entropy_loss = -7.8604, learner_queue_size = 19, _tick = 735, _time = 1.654e+09, train_seconds = 615.7)
[2022-05-31 14:20:42,062][root][INFO] - Step 4124160 @ 7159.5 SPS. Inference batcher size: 85. Learner queue size: 24. Other stats: (step = 4124160, mean_episode_return = None, mean_episode_step = 1392.2, total_loss = 506.87, pg_loss = 328.53, baseline_loss = 186.23, entropy_loss = -7.8854, learner_queue_size = 17, _tick = 744, _time = 1.654e+09, train_seconds = 620.7)
[2022-05-31 14:20:47,066][root][INFO] - Step 4154880 @ 6138.9 SPS. Inference batcher size: 133. Learner queue size: 20. Other stats: (step = 4154880, mean_episode_return = -6.3602, mean_episode_step = 1157.6, total_loss = 1323.3, pg_loss = 918.15, baseline_loss = 413.15, entropy_loss = -7.9607, learner_queue_size = 20, _tick = 753, _time = 1.654e+09, train_seconds = 625.8)
[2022-05-31 14:20:52,072][root][INFO] - Step 4188160 @ 6647.8 SPS. Inference batcher size: 87. Learner queue size: 17. Other stats: (step = 4188160, mean_episode_return = -23.38, mean_episode_step = 1507.2, total_loss = -560.59, pg_loss = -565.06, baseline_loss = 12.461, entropy_loss = -7.9896, learner_queue_size = 17, _tick = 761, _time = 1.654e+09, train_seconds = 630.8)
[2022-05-31 14:20:57,078][root][INFO] - Step 4221440 @ 6648.4 SPS. Inference batcher size: 85. Learner queue size: 14. Other stats: (step = 4221440, mean_episode_return = 11.85, mean_episode_step = 1573.8, total_loss = 31.702, pg_loss = -92.348, baseline_loss = 132.04, entropy_loss = -7.9928, learner_queue_size = 18, _tick = 768, _time = 1.654e+09, train_seconds = 635.8)
[2022-05-31 14:21:02,082][root][INFO] - Step 4254720 @ 6650.6 SPS. Inference batcher size: 92. Learner queue size: 8. Other stats: (step = 4254720, mean_episode_return = 3.5898, mean_episode_step = 1347.4, total_loss = 117.31, pg_loss = -171.13, baseline_loss = 296.37, entropy_loss = -7.9219, learner_queue_size = 16, _tick = 777, _time = 1.654e+09, train_seconds = 640.8)
[2022-05-31 14:21:07,087][root][INFO] - Step 4288000 @ 6650.2 SPS. Inference batcher size: 34. Learner queue size: 29. Other stats: (step = 4288000, mean_episode_return = None, mean_episode_step = 1319.8, total_loss = 252.37, pg_loss = 26.459, baseline_loss = 233.89, entropy_loss = -7.9828, learner_queue_size = 18, _tick = 786, _time = 1.654e+09, train_seconds = 645.8)
[2022-05-31 14:21:12,094][root][INFO] - Step 4318720 @ 6134.5 SPS. Inference batcher size: 60. Learner queue size: 19. Other stats: (step = 4318720, mean_episode_return = 13.78, mean_episode_step = 1310.0, total_loss = -146.58, pg_loss = -250.95, baseline_loss = 112.34, entropy_loss = -7.9676, learner_queue_size = 20, _tick = 795, _time = 1.654e+09, train_seconds = 650.8)
[2022-05-31 14:21:17,098][root][INFO] - Step 4352000 @ 6650.9 SPS. Inference batcher size: 118. Learner queue size: 12. Other stats: (step = 4352000, mean_episode_return = 2.1898, mean_episode_step = 1334.3, total_loss = 2893.6, pg_loss = 1462.2, baseline_loss = 1439.4, entropy_loss = -8.0373, learner_queue_size = 16, _tick = 803, _time = 1.654e+09, train_seconds = 655.8)
[2022-05-31 14:21:22,102][root][INFO] - Step 4385280 @ 6650.7 SPS. Inference batcher size: 62. Learner queue size: 16. Other stats: (step = 4385280, mean_episode_return = 14.81, mean_episode_step = 1486.3, total_loss = -522.21, pg_loss = -542.19, baseline_loss = 28.016, entropy_loss = -8.04, learner_queue_size = 23, _tick = 813, _time = 1.654e+09, train_seconds = 660.8)
[2022-05-31 14:21:27,106][root][INFO] - Step 4418560 @ 6650.7 SPS. Inference batcher size: 110. Learner queue size: 16. Other stats: (step = 4418560, mean_episode_return = -4.9601, mean_episode_step = 1162.1, total_loss = -144.65, pg_loss = -203.51, baseline_loss = 66.926, entropy_loss = -8.0699, learner_queue_size = 28, _tick = 820, _time = 1.654e+09, train_seconds = 665.8)
[2022-05-31 14:21:32,110][root][INFO] - Step 4451840 @ 6650.7 SPS. Inference batcher size: 109. Learner queue size: 20. Other stats: (step = 4451840, mean_episode_return = 10.79, mean_episode_step = 1074.7, total_loss = 260.48, pg_loss = 112.18, baseline_loss = 156.39, entropy_loss = -8.0914, learner_queue_size = 23, _tick = 831, _time = 1.654e+09, train_seconds = 670.8)
[2022-05-31 14:21:37,114][root][INFO] - Step 4485120 @ 6650.8 SPS. Inference batcher size: 101. Learner queue size: 19. Other stats: (step = 4485120, mean_episode_return = 0.61469, mean_episode_step = 1418.1, total_loss = -509.97, pg_loss = -561.45, baseline_loss = 59.551, entropy_loss = -8.0674, learner_queue_size = 25, _tick = 841, _time = 1.654e+09, train_seconds = 675.8)
[2022-05-31 14:21:42,118][root][INFO] - Step 4518400 @ 6650.6 SPS. Inference batcher size: 134. Learner queue size: 11. Other stats: (step = 4518400, mean_episode_return = 15.63, mean_episode_step = 1558.5, total_loss = 48.496, pg_loss = -3.0968, baseline_loss = 59.658, entropy_loss = -8.0653, learner_queue_size = 15, _tick = 845, _time = 1.654e+09, train_seconds = 680.8)
[2022-05-31 14:21:47,122][root][INFO] - Step 4551680 @ 6650.7 SPS. Inference batcher size: 86. Learner queue size: 13. Other stats: (step = 4551680, mean_episode_return = -15.12, mean_episode_step = 1601.0, total_loss = 22.569, pg_loss = -64.282, baseline_loss = 94.812, entropy_loss = -7.9603, learner_queue_size = 22, _tick = 853, _time = 1.654e+09, train_seconds = 685.8)
[2022-05-31 14:21:52,128][root][INFO] - Step 4584960 @ 6647.9 SPS. Inference batcher size: 90. Learner queue size: 16. Other stats: (step = 4584960, mean_episode_return = 67.09, mean_episode_step = 1411.1, total_loss = -714.57, pg_loss = -730.01, baseline_loss = 23.185, entropy_loss = -7.7516, learner_queue_size = 18, _tick = 863, _time = 1.654e+09, train_seconds = 690.8)
[2022-05-31 14:21:57,134][root][INFO] - Step 4618240 @ 6647.9 SPS. Inference batcher size: 102. Learner queue size: 10. Other stats: (step = 4618240, mean_episode_return = -21.41, mean_episode_step = 1163.5, total_loss = -64.72, pg_loss = -148.05, baseline_loss = 91.244, entropy_loss = -7.9139, learner_queue_size = 19, _tick = 871, _time = 1.654e+09, train_seconds = 695.8)
[2022-05-31 14:22:02,138][root][INFO] - Step 4651520 @ 6651.1 SPS. Inference batcher size: 43. Learner queue size: 23. Other stats: (step = 4651520, mean_episode_return = -18.821, mean_episode_step = 1234.9, total_loss = 298.23, pg_loss = 123.03, baseline_loss = 183.17, entropy_loss = -7.9763, learner_queue_size = 17, _tick = 879, _time = 1.654e+09, train_seconds = 700.8)
[2022-05-31 14:22:07,142][root][INFO] - Step 4684800 @ 6650.7 SPS. Inference batcher size: 131. Learner queue size: 13. Other stats: (step = 4684800, mean_episode_return = 31.81, mean_episode_step = 1191.6, total_loss = -416.78, pg_loss = -440.11, baseline_loss = 31.296, entropy_loss = -7.9626, learner_queue_size = 16, _tick = 889, _time = 1.654e+09, train_seconds = 705.8)
[2022-05-31 14:22:12,146][root][INFO] - Step 4718080 @ 6650.6 SPS. Inference batcher size: 180. Learner queue size: 12. Other stats: (step = 4718080, mean_episode_return = 2.733, mean_episode_step = 1518.8, total_loss = -63.236, pg_loss = -233.7, baseline_loss = 178.47, entropy_loss = -8.0115, learner_queue_size = 17, _tick = 897, _time = 1.654e+09, train_seconds = 710.8)
[2022-05-31 14:22:17,150][root][INFO] - Step 4751360 @ 6650.8 SPS. Inference batcher size: 114. Learner queue size: 15. Other stats: (step = 4751360, mean_episode_return = None, mean_episode_step = 1456.1, total_loss = 2686.0, pg_loss = 1711.3, baseline_loss = 982.59, entropy_loss = -7.9402, learner_queue_size = 24, _tick = 904, _time = 1.654e+09, train_seconds = 715.8)
[2022-05-31 14:22:22,154][root][INFO] - Step 4784640 @ 6650.7 SPS. Inference batcher size: 60. Learner queue size: 10. Other stats: (step = 4784640, mean_episode_return = 2.6696, mean_episode_step = 1411.4, total_loss = 452.88, pg_loss = 207.93, baseline_loss = 252.83, entropy_loss = -7.8889, learner_queue_size = 23, _tick = 911, _time = 1.654e+09, train_seconds = 720.8)
[2022-05-31 14:22:27,158][root][INFO] - Step 4817920 @ 6650.6 SPS. Inference batcher size: 160. Learner queue size: 12. Other stats: (step = 4817920, mean_episode_return = -10.68, mean_episode_step = 1350.2, total_loss = -654.97, pg_loss = -681.77, baseline_loss = 34.785, entropy_loss = -7.9868, learner_queue_size = 24, _tick = 919, _time = 1.654e+09, train_seconds = 725.8)
[2022-05-31 14:22:32,162][root][INFO] - Step 4851200 @ 6650.7 SPS. Inference batcher size: 177. Learner queue size: 15. Other stats: (step = 4851200, mean_episode_return = 5.8548, mean_episode_step = 1449.4, total_loss = 895.21, pg_loss = 330.45, baseline_loss = 572.8, entropy_loss = -8.0421, learner_queue_size = 25, _tick = 927, _time = 1.654e+09, train_seconds = 730.8)
[2022-05-31 14:22:37,166][root][INFO] - Step 4884480 @ 6650.7 SPS. Inference batcher size: 118. Learner queue size: 7. Other stats: (step = 4884480, mean_episode_return = 22.715, mean_episode_step = 1787.9, total_loss = -40.655, pg_loss = -315.0, baseline_loss = 282.44, entropy_loss = -8.0912, learner_queue_size = 19, _tick = 935, _time = 1.654e+09, train_seconds = 735.9)
[2022-05-31 14:22:42,170][root][INFO] - Step 4917760 @ 6650.7 SPS. Inference batcher size: 114. Learner queue size: 15. Other stats: (step = 4917760, mean_episode_return = None, mean_episode_step = 1355.6, total_loss = 34.21, pg_loss = -109.64, baseline_loss = 151.99, entropy_loss = -8.1395, learner_queue_size = 16, _tick = 945, _time = 1.654e+09, train_seconds = 740.9)
[2022-05-31 14:22:47,174][root][INFO] - Step 4951040 @ 6650.8 SPS. Inference batcher size: 74. Learner queue size: 12. Other stats: (step = 4951040, mean_episode_return = 44.141, mean_episode_step = 1353.6, total_loss = -663.54, pg_loss = -696.65, baseline_loss = 41.275, entropy_loss = -8.1642, learner_queue_size = 22, _tick = 954, _time = 1.654e+09, train_seconds = 745.9)
[2022-05-31 14:22:52,180][root][INFO] - Step 4984320 @ 6648.2 SPS. Inference batcher size: 89. Learner queue size: 2. Other stats: (step = 4984320, mean_episode_return = None, mean_episode_step = 1327.5, total_loss = 2649.1, pg_loss = 1511.5, baseline_loss = 1145.8, entropy_loss = -8.1983, learner_queue_size = 20, _tick = 962, _time = 1.654e+09, train_seconds = 750.9)
[2022-05-31 14:22:57,182][root][INFO] - Step 5017600 @ 6653.1 SPS. Inference batcher size: 122. Learner queue size: 21. Other stats: (step = 5017600, mean_episode_return = 7.58, mean_episode_step = 1509.5, total_loss = 36.253, pg_loss = -98.51, baseline_loss = 142.91, entropy_loss = -8.1421, learner_queue_size = 14, _tick = 972, _time = 1.654e+09, train_seconds = 755.9)
[2022-05-31 14:23:02,190][root][INFO] - Step 5048320 @ 6134.4 SPS. Inference batcher size: 119. Learner queue size: 19. Other stats: (step = 5048320, mean_episode_return = -14.24, mean_episode_step = 1173.4, total_loss = 857.4, pg_loss = 436.58, baseline_loss = 429.01, entropy_loss = -8.1874, learner_queue_size = 22, _tick = 983, _time = 1.654e+09, train_seconds = 760.9)
[2022-05-31 14:23:07,194][root][INFO] - Step 5084160 @ 7161.9 SPS. Inference batcher size: 127. Learner queue size: 23. Other stats: (step = 5084160, mean_episode_return = -5.36, mean_episode_step = 1298.8, total_loss = -361.65, pg_loss = -435.47, baseline_loss = 82.251, entropy_loss = -8.4403, learner_queue_size = 10, _tick = 994, _time = 1.654e+09, train_seconds = 765.9)
[2022-05-31 14:23:12,198][root][INFO] - Step 5114880 @ 6139.2 SPS. Inference batcher size: 79. Learner queue size: 24. Other stats: (step = 5114880, mean_episode_return = 19.384, mean_episode_step = 1327.4, total_loss = 581.48, pg_loss = -480.12, baseline_loss = 1070.0, entropy_loss = -8.3588, learner_queue_size = 20, _tick = 1003, _time = 1.654e+09, train_seconds = 770.9)
[2022-05-31 14:23:17,202][root][INFO] - Step 5148160 @ 6650.6 SPS. Inference batcher size: 73. Learner queue size: 30. Other stats: (step = 5148160, mean_episode_return = 10.87, mean_episode_step = 1276.5, total_loss = 295.86, pg_loss = 125.15, baseline_loss = 179.1, entropy_loss = -8.3824, learner_queue_size = 19, _tick = 1011, _time = 1.654e+09, train_seconds = 775.9)
[2022-05-31 14:23:22,206][root][INFO] - Step 5184000 @ 7162.3 SPS. Inference batcher size: 93. Learner queue size: 15. Other stats: (step = 5184000, mean_episode_return = 3.7048, mean_episode_step = 1340.3, total_loss = 1204.6, pg_loss = 672.67, baseline_loss = 540.2, entropy_loss = -8.2589, learner_queue_size = 12, _tick = 1022, _time = 1.654e+09, train_seconds = 780.9)
[2022-05-31 14:23:27,210][root][INFO] - Step 5214720 @ 6139.1 SPS. Inference batcher size: 134. Learner queue size: 15. Other stats: (step = 5214720, mean_episode_return = 65.81, mean_episode_step = 1257.5, total_loss = 2548.5, pg_loss = 1275.1, baseline_loss = 1281.7, entropy_loss = -8.2434, learner_queue_size = 27, _tick = 1029, _time = 1.654e+09, train_seconds = 785.9)
[2022-05-31 14:23:32,216][root][INFO] - Step 5248000 @ 6648.0 SPS. Inference batcher size: 116. Learner queue size: 18. Other stats: (step = 5248000, mean_episode_return = None, mean_episode_step = 1632.6, total_loss = 803.68, pg_loss = 584.12, baseline_loss = 227.74, entropy_loss = -8.1703, learner_queue_size = 13, _tick = 1037, _time = 1.654e+09, train_seconds = 790.9)
[2022-05-31 14:23:37,222][root][INFO] - Step 5281280 @ 6647.9 SPS. Inference batcher size: 60. Learner queue size: 13. Other stats: (step = 5281280, mean_episode_return = 4.6999, mean_episode_step = 1407.5, total_loss = 3685.9, pg_loss = 1805.9, baseline_loss = 1888.1, entropy_loss = -8.0836, learner_queue_size = 23, _tick = 1047, _time = 1.654e+09, train_seconds = 795.9)
[2022-05-31 14:23:42,226][root][INFO] - Step 5314560 @ 6650.8 SPS. Inference batcher size: 88. Learner queue size: 13. Other stats: (step = 5314560, mean_episode_return = -9.9954, mean_episode_step = 1187.9, total_loss = -811.63, pg_loss = -952.08, baseline_loss = 148.52, entropy_loss = -8.0757, learner_queue_size = 12, _tick = 1056, _time = 1.654e+09, train_seconds = 800.9)
[2022-05-31 14:23:47,232][root][INFO] - Step 5347840 @ 6647.9 SPS. Inference batcher size: 129. Learner queue size: 16. Other stats: (step = 5347840, mean_episode_return = -9.8503, mean_episode_step = 1220.0, total_loss = 345.19, pg_loss = 183.36, baseline_loss = 169.98, entropy_loss = -8.1475, learner_queue_size = 24, _tick = 1064, _time = 1.654e+09, train_seconds = 805.9)
[2022-05-31 14:23:52,238][root][INFO] - Step 5381120 @ 6647.9 SPS. Inference batcher size: 108. Learner queue size: 21. Other stats: (step = 5381120, mean_episode_return = None, mean_episode_step = 1292.4, total_loss = 134.87, pg_loss = 15.659, baseline_loss = 127.26, entropy_loss = -8.0502, learner_queue_size = 21, _tick = 1071, _time = 1.654e+09, train_seconds = 810.9)
[2022-05-31 14:23:57,244][root][INFO] - Step 5414400 @ 6648.0 SPS. Inference batcher size: 162. Learner queue size: 13. Other stats: (step = 5414400, mean_episode_return = 11.219, mean_episode_step = 1473.2, total_loss = 501.16, pg_loss = 152.87, baseline_loss = 356.35, entropy_loss = -8.0545, learner_queue_size = 19, _tick = 1082, _time = 1.654e+09, train_seconds = 815.9)
[2022-05-31 14:24:02,250][root][INFO] - Step 5450240 @ 7159.6 SPS. Inference batcher size: 169. Learner queue size: 18. Other stats: (step = 5450240, mean_episode_return = 13.376, mean_episode_step = 1227.4, total_loss = -5.7854, pg_loss = -233.95, baseline_loss = 236.23, entropy_loss = -8.0682, learner_queue_size = 13, _tick = 1090, _time = 1.654e+09, train_seconds = 820.9)
[2022-05-31 14:24:07,255][root][INFO] - Step 5480960 @ 6137.8 SPS. Inference batcher size: 149. Learner queue size: 16. Other stats: (step = 5480960, mean_episode_return = -19.13, mean_episode_step = 1425.3, total_loss = 285.2, pg_loss = 171.91, baseline_loss = 121.2, entropy_loss = -7.9153, learner_queue_size = 30, _tick = 1097, _time = 1.654e+09, train_seconds = 825.9)
[2022-05-31 14:24:12,258][root][INFO] - Step 5514240 @ 6652.1 SPS. Inference batcher size: 161. Learner queue size: 17. Other stats: (step = 5514240, mean_episode_return = None, mean_episode_step = 1131.8, total_loss = 281.76, pg_loss = 170.69, baseline_loss = 119.02, entropy_loss = -7.9446, learner_queue_size = 24, _tick = 1107, _time = 1.654e+09, train_seconds = 830.9)
[2022-05-31 14:24:17,262][root][INFO] - Step 5550080 @ 7162.1 SPS. Inference batcher size: 70. Learner queue size: 19. Other stats: (step = 5550080, mean_episode_return = None, mean_episode_step = 1248.0, total_loss = -219.13, pg_loss = -235.98, baseline_loss = 26.239, entropy_loss = -9.3902, learner_queue_size = 19, _tick = 1118, _time = 1.654e+09, train_seconds = 835.9)
[2022-05-31 14:24:22,266][root][INFO] - Step 5580800 @ 6139.1 SPS. Inference batcher size: 129. Learner queue size: 22. Other stats: (step = 5580800, mean_episode_return = 39.015, mean_episode_step = 1131.3, total_loss = 1093.9, pg_loss = 901.48, baseline_loss = 200.82, entropy_loss = -8.3571, learner_queue_size = 11, _tick = 1123, _time = 1.654e+09, train_seconds = 841.0)
[2022-05-31 14:24:27,270][root][INFO] - Step 5614080 @ 6650.8 SPS. Inference batcher size: 140. Learner queue size: 18. Other stats: (step = 5614080, mean_episode_return = 23.01, mean_episode_step = 1341.8, total_loss = 274.65, pg_loss = 230.02, baseline_loss = 53.246, entropy_loss = -8.6154, learner_queue_size = 14, _tick = 1132, _time = 1.654e+09, train_seconds = 846.0)
[2022-05-31 14:24:32,276][root][INFO] - Step 5647360 @ 6647.9 SPS. Inference batcher size: 102. Learner queue size: 26. Other stats: (step = 5647360, mean_episode_return = None, mean_episode_step = 1420.4, total_loss = -55.529, pg_loss = -94.863, baseline_loss = 48.074, entropy_loss = -8.741, learner_queue_size = 20, _tick = 1140, _time = 1.654e+09, train_seconds = 851.0)
[2022-05-31 14:24:37,282][root][INFO] - Step 5680640 @ 6647.9 SPS. Inference batcher size: 102. Learner queue size: 12. Other stats: (step = 5680640, mean_episode_return = None, mean_episode_step = 1010.0, total_loss = 1437.6, pg_loss = 882.78, baseline_loss = 563.65, entropy_loss = -8.8715, learner_queue_size = 26, _tick = 1148, _time = 1.654e+09, train_seconds = 856.0)
[2022-05-31 14:24:42,288][root][INFO] - Step 5713920 @ 6648.0 SPS. Inference batcher size: 124. Learner queue size: 10. Other stats: (step = 5713920, mean_episode_return = None, mean_episode_step = 1402.4, total_loss = 638.14, pg_loss = 501.1, baseline_loss = 145.81, entropy_loss = -8.7655, learner_queue_size = 21, _tick = 1154, _time = 1.654e+09, train_seconds = 861.0)
[2022-05-31 14:24:47,294][root][INFO] - Step 5747200 @ 6648.2 SPS. Inference batcher size: 145. Learner queue size: 20. Other stats: (step = 5747200, mean_episode_return = 18.14, mean_episode_step = 1440.3, total_loss = -463.14, pg_loss = -466.76, baseline_loss = 12.161, entropy_loss = -8.5476, learner_queue_size = 15, _tick = 1162, _time = 1.654e+09, train_seconds = 866.0)
[2022-05-31 14:24:52,300][root][INFO] - Step 5780480 @ 6648.5 SPS. Inference batcher size: 101. Learner queue size: 2. Other stats: (step = 5780480, mean_episode_return = None, mean_episode_step = 1468.1, total_loss = 3142.7, pg_loss = 1808.7, baseline_loss = 1342.6, entropy_loss = -8.5093, learner_queue_size = 30, _tick = 1168, _time = 1.654e+09, train_seconds = 871.0)
[2022-05-31 14:24:57,306][root][INFO] - Step 5813760 @ 6647.1 SPS. Inference batcher size: 48. Learner queue size: 8. Other stats: (step = 5813760, mean_episode_return = None, mean_episode_step = 1447.1, total_loss = 472.84, pg_loss = 338.04, baseline_loss = 143.31, entropy_loss = -8.5074, learner_queue_size = 15, _tick = 1176, _time = 1.654e+09, train_seconds = 876.0)
[2022-05-31 14:25:02,310][root][INFO] - Step 5847040 @ 6651.2 SPS. Inference batcher size: 112. Learner queue size: 25. Other stats: (step = 5847040, mean_episode_return = 120.37, mean_episode_step = 1436.7, total_loss = -395.48, pg_loss = -417.8, baseline_loss = 30.762, entropy_loss = -8.4484, learner_queue_size = 18, _tick = 1183, _time = 1.654e+09, train_seconds = 881.0)
[2022-05-31 14:25:07,314][root][INFO] - Step 5880320 @ 6650.7 SPS. Inference batcher size: 39. Learner queue size: 16. Other stats: (step = 5880320, mean_episode_return = -8.3201, mean_episode_step = 1543.5, total_loss = 43.772, pg_loss = -63.393, baseline_loss = 115.54, entropy_loss = -8.3765, learner_queue_size = 14, _tick = 1192, _time = 1.654e+09, train_seconds = 886.0)
[2022-05-31 14:25:12,321][root][INFO] - Step 5911040 @ 6134.8 SPS. Inference batcher size: 163. Learner queue size: 23. Other stats: (step = 5911040, mean_episode_return = 104.91, mean_episode_step = 1662.7, total_loss = 1559.4, pg_loss = 897.44, baseline_loss = 670.25, entropy_loss = -8.245, learner_queue_size = 19, _tick = 1198, _time = 1.654e+09, train_seconds = 891.0)
[2022-05-31 14:25:17,327][root][INFO] - Step 5944320 @ 6648.0 SPS. Inference batcher size: 141. Learner queue size: 13. Other stats: (step = 5944320, mean_episode_return = None, mean_episode_step = 1416.8, total_loss = 744.02, pg_loss = 466.92, baseline_loss = 285.24, entropy_loss = -8.1414, learner_queue_size = 26, _tick = 1204, _time = 1.654e+09, train_seconds = 896.0)
[2022-05-31 14:25:22,333][root][INFO] - Step 5977600 @ 6648.0 SPS. Inference batcher size: 102. Learner queue size: 9. Other stats: (step = 5977600, mean_episode_return = None, mean_episode_step = 1633.7, total_loss = 553.55, pg_loss = 279.61, baseline_loss = 282.15, entropy_loss = -8.2174, learner_queue_size = 17, _tick = 1211, _time = 1.654e+09, train_seconds = 901.0)
[2022-05-31 14:25:27,338][root][INFO] - Step 6010880 @ 6650.0 SPS. Inference batcher size: 33. Learner queue size: 16. Other stats: (step = 6010880, mean_episode_return = 73.86, mean_episode_step = 1456.2, total_loss = -866.23, pg_loss = -890.97, baseline_loss = 33.072, entropy_loss = -8.3313, learner_queue_size = 24, _tick = 1218, _time = 1.654e+09, train_seconds = 906.0)
[2022-05-31 14:25:32,344][root][INFO] - Step 6044160 @ 6647.5 SPS. Inference batcher size: 136. Learner queue size: 18. Other stats: (step = 6044160, mean_episode_return = None, mean_episode_step = 1536.9, total_loss = 308.69, pg_loss = 158.56, baseline_loss = 158.54, entropy_loss = -8.414, learner_queue_size = 22, _tick = 1226, _time = 1.654e+09, train_seconds = 911.0)
[2022-05-31 14:25:37,351][root][INFO] - Step 6077440 @ 6647.9 SPS. Inference batcher size: 146. Learner queue size: 18. Other stats: (step = 6077440, mean_episode_return = 31.865, mean_episode_step = 1737.3, total_loss = -561.75, pg_loss = -658.37, baseline_loss = 105.03, entropy_loss = -8.417, learner_queue_size = 31, _tick = 1236, _time = 1.654e+09, train_seconds = 916.0)
[2022-05-31 14:25:42,355][root][INFO] - Step 6110720 @ 6650.4 SPS. Inference batcher size: 88. Learner queue size: 21. Other stats: (step = 6110720, mean_episode_return = 5.3622, mean_episode_step = 1524.1, total_loss = -429.66, pg_loss = -450.19, baseline_loss = 28.934, entropy_loss = -8.4059, learner_queue_size = 16, _tick = 1248, _time = 1.654e+09, train_seconds = 921.0)
[2022-05-31 14:25:47,358][root][INFO] - Step 6144000 @ 6651.7 SPS. Inference batcher size: 74. Learner queue size: 13. Other stats: (step = 6144000, mean_episode_return = -13.85, mean_episode_step = 1457.4, total_loss = 960.82, pg_loss = 665.06, baseline_loss = 304.28, entropy_loss = -8.521, learner_queue_size = 20, _tick = 1260, _time = 1.654e+09, train_seconds = 926.0)
[2022-05-31 14:25:52,364][root][INFO] - Step 6177280 @ 6647.4 SPS. Inference batcher size: 94. Learner queue size: 11. Other stats: (step = 6177280, mean_episode_return = 45.496, mean_episode_step = 1473.6, total_loss = 1360.3, pg_loss = 845.09, baseline_loss = 523.65, entropy_loss = -8.4355, learner_queue_size = 22, _tick = 1269, _time = 1.654e+09, train_seconds = 931.0)
[2022-05-31 14:25:57,371][root][INFO] - Step 6210560 @ 6647.9 SPS. Inference batcher size: 157. Learner queue size: 3. Other stats: (step = 6210560, mean_episode_return = 41.84, mean_episode_step = 1590.2, total_loss = 307.49, pg_loss = 132.72, baseline_loss = 183.09, entropy_loss = -8.3274, learner_queue_size = 18, _tick = 1276, _time = 1.654e+09, train_seconds = 936.1)
[2022-05-31 14:26:02,374][root][INFO] - Step 6243840 @ 6651.4 SPS. Inference batcher size: 114. Learner queue size: 8. Other stats: (step = 6243840, mean_episode_return = 21.228, mean_episode_step = 1242.8, total_loss = 267.7, pg_loss = -26.477, baseline_loss = 302.57, entropy_loss = -8.3943, learner_queue_size = 22, _tick = 1287, _time = 1.654e+09, train_seconds = 941.1)
[2022-05-31 14:26:07,382][root][INFO] - Step 6277120 @ 6645.5 SPS. Inference batcher size: 109. Learner queue size: 9. Other stats: (step = 6277120, mean_episode_return = None, mean_episode_step = 1390.2, total_loss = -445.29, pg_loss = -447.94, baseline_loss = 10.926, entropy_loss = -8.2769, learner_queue_size = 24, _tick = 1297, _time = 1.654e+09, train_seconds = 946.1)
[2022-05-31 14:26:12,388][root][INFO] - Step 6310400 @ 6647.9 SPS. Inference batcher size: 77. Learner queue size: 0. Other stats: (step = 6310400, mean_episode_return = -4.87, mean_episode_step = 1449.9, total_loss = -175.7, pg_loss = -304.59, baseline_loss = 137.17, entropy_loss = -8.2696, learner_queue_size = 12, _tick = 1308, _time = 1.654e+09, train_seconds = 951.1)
[2022-05-31 14:26:17,394][root][INFO] - Step 6343680 @ 6647.8 SPS. Inference batcher size: 73. Learner queue size: 10. Other stats: (step = 6343680, mean_episode_return = 87.64, mean_episode_step = 1326.2, total_loss = -583.45, pg_loss = -588.63, baseline_loss = 13.418, entropy_loss = -8.2375, learner_queue_size = 20, _tick = 1320, _time = 1.654e+09, train_seconds = 956.1)
[2022-05-31 14:26:22,398][root][INFO] - Step 6376960 @ 6650.4 SPS. Inference batcher size: 2. Learner queue size: 20. Other stats: (step = 6376960, mean_episode_return = 49.843, mean_episode_step = 932.79, total_loss = 1010.4, pg_loss = 634.19, baseline_loss = 384.5, entropy_loss = -8.2706, learner_queue_size = 14, _tick = 1331, _time = 1.654e+09, train_seconds = 961.1)
[2022-05-31 14:26:27,402][root][INFO] - Step 6410240 @ 6651.2 SPS. Inference batcher size: 32. Learner queue size: 4. Other stats: (step = 6410240, mean_episode_return = None, mean_episode_step = 1330.0, total_loss = 53.647, pg_loss = -94.932, baseline_loss = 156.71, entropy_loss = -8.1329, learner_queue_size = 19, _tick = 1337, _time = 1.654e+09, train_seconds = 966.1)
[2022-05-31 14:26:32,406][root][INFO] - Step 6443520 @ 6650.6 SPS. Inference batcher size: 38. Learner queue size: 7. Other stats: (step = 6443520, mean_episode_return = -21.15, mean_episode_step = 1673.3, total_loss = 4049.0, pg_loss = 2152.1, baseline_loss = 1904.9, entropy_loss = -7.9748, learner_queue_size = 20, _tick = 1347, _time = 1.654e+09, train_seconds = 971.1)
[2022-05-31 14:26:37,410][root][INFO] - Step 6476800 @ 6650.7 SPS. Inference batcher size: 182. Learner queue size: 2. Other stats: (step = 6476800, mean_episode_return = None, mean_episode_step = 1194.7, total_loss = 33.31, pg_loss = -90.375, baseline_loss = 131.77, entropy_loss = -8.0811, learner_queue_size = 19, _tick = 1354, _time = 1.654e+09, train_seconds = 976.1)
[2022-05-31 14:26:42,414][root][INFO] - Step 6510080 @ 6650.7 SPS. Inference batcher size: 121. Learner queue size: 0. Other stats: (step = 6510080, mean_episode_return = 18.9, mean_episode_step = 1372.0, total_loss = -47.043, pg_loss = -127.92, baseline_loss = 88.922, entropy_loss = -8.0407, learner_queue_size = 17, _tick = 1359, _time = 1.654e+09, train_seconds = 981.1)
[2022-05-31 14:26:47,418][root][INFO] - Step 6543360 @ 6650.7 SPS. Inference batcher size: 6. Learner queue size: 28. Other stats: (step = 6543360, mean_episode_return = 78.86, mean_episode_step = 1220.5, total_loss = 213.94, pg_loss = 48.676, baseline_loss = 173.5, entropy_loss = -8.2438, learner_queue_size = 25, _tick = 1366, _time = 1.654e+09, train_seconds = 986.1)
[2022-05-31 14:26:52,425][root][INFO] - Step 6574080 @ 6135.5 SPS. Inference batcher size: 61. Learner queue size: 12. Other stats: (step = 6574080, mean_episode_return = None, mean_episode_step = 1616.3, total_loss = 636.19, pg_loss = 518.68, baseline_loss = 125.61, entropy_loss = -8.0995, learner_queue_size = 13, _tick = 1374, _time = 1.654e+09, train_seconds = 991.1)
[2022-05-31 14:26:57,430][root][INFO] - Step 6607360 @ 6649.2 SPS. Inference batcher size: 149. Learner queue size: 17. Other stats: (step = 6607360, mean_episode_return = -0.40038, mean_episode_step = 1207.2, total_loss = 494.25, pg_loss = 326.92, baseline_loss = 174.72, entropy_loss = -7.3949, learner_queue_size = 18, _tick = 1384, _time = 1.654e+09, train_seconds = 996.1)
[2022-05-31 14:27:02,436][root][INFO] - Step 6640640 @ 6648.0 SPS. Inference batcher size: 111. Learner queue size: 17. Other stats: (step = 6640640, mean_episode_return = None, mean_episode_step = 1256.7, total_loss = -385.13, pg_loss = -388.44, baseline_loss = 10.437, entropy_loss = -7.1214, learner_queue_size = 24, _tick = 1390, _time = 1.654e+09, train_seconds = 1001.1)
[2022-05-31 14:27:07,442][root][INFO] - Step 6673920 @ 6648.1 SPS. Inference batcher size: 165. Learner queue size: 15. Other stats: (step = 6673920, mean_episode_return = 4.0295, mean_episode_step = 1425.5, total_loss = 142.37, pg_loss = 46.86, baseline_loss = 102.34, entropy_loss = -6.8284, learner_queue_size = 11, _tick = 1399, _time = 1.654e+09, train_seconds = 1006.1)
[2022-05-31 14:27:12,447][root][INFO] - Step 6707200 @ 6649.5 SPS. Inference batcher size: 107. Learner queue size: 21. Other stats: (step = 6707200, mean_episode_return = 41.636, mean_episode_step = 1212.8, total_loss = 1325.6, pg_loss = 932.23, baseline_loss = 400.63, entropy_loss = -7.2372, learner_queue_size = 25, _tick = 1407, _time = 1.654e+09, train_seconds = 1011.1)
[2022-05-31 14:27:17,450][root][INFO] - Step 6740480 @ 6651.8 SPS. Inference batcher size: 76. Learner queue size: 9. Other stats: (step = 6740480, mean_episode_return = None, mean_episode_step = 1478.1, total_loss = 99.439, pg_loss = -89.475, baseline_loss = 196.24, entropy_loss = -7.3245, learner_queue_size = 14, _tick = 1416, _time = 1.654e+09, train_seconds = 1016.1)
[2022-05-31 14:27:22,456][root][INFO] - Step 6773760 @ 6647.4 SPS. Inference batcher size: 181. Learner queue size: 13. Other stats: (step = 6773760, mean_episode_return = None, mean_episode_step = 1544.8, total_loss = 392.88, pg_loss = 161.98, baseline_loss = 238.15, entropy_loss = -7.2439, learner_queue_size = 17, _tick = 1425, _time = 1.654e+09, train_seconds = 1021.1)
[2022-05-31 14:27:27,462][root][INFO] - Step 6807040 @ 6648.1 SPS. Inference batcher size: 166. Learner queue size: 22. Other stats: (step = 6807040, mean_episode_return = 40.142, mean_episode_step = 1224.1, total_loss = 265.99, pg_loss = 57.458, baseline_loss = 215.57, entropy_loss = -7.0363, learner_queue_size = 28, _tick = 1435, _time = 1.654e+09, train_seconds = 1026.1)
[2022-05-31 14:27:32,468][root][INFO] - Step 6840320 @ 6648.0 SPS. Inference batcher size: 160. Learner queue size: 18. Other stats: (step = 6840320, mean_episode_return = None, mean_episode_step = 1744.4, total_loss = 130.18, pg_loss = 80.049, baseline_loss = 56.96, entropy_loss = -6.8277, learner_queue_size = 17, _tick = 1443, _time = 1.654e+09, train_seconds = 1031.2)
[2022-05-31 14:27:37,474][root][INFO] - Step 6876160 @ 7160.1 SPS. Inference batcher size: 71. Learner queue size: 24. Other stats: (step = 6876160, mean_episode_return = 30.3, mean_episode_step = 1477.8, total_loss = -171.94, pg_loss = -171.41, baseline_loss = 6.1306, entropy_loss = -6.6605, learner_queue_size = 20, _tick = 1455, _time = 1.654e+09, train_seconds = 1036.2)
[2022-05-31 14:27:42,478][root][INFO] - Step 6909440 @ 6650.6 SPS. Inference batcher size: 66. Learner queue size: 13. Other stats: (step = 6909440, mean_episode_return = -1.3351, mean_episode_step = 1208.4, total_loss = 1244.5, pg_loss = 842.72, baseline_loss = 408.19, entropy_loss = -6.401, learner_queue_size = 11, _tick = 1463, _time = 1.654e+09, train_seconds = 1041.2)
[2022-05-31 14:27:47,482][root][INFO] - Step 6942720 @ 6650.6 SPS. Inference batcher size: 113. Learner queue size: 22. Other stats: (step = 6942720, mean_episode_return = 45.22, mean_episode_step = 1095.1, total_loss = 817.31, pg_loss = 544.58, baseline_loss = 279.57, entropy_loss = -6.8424, learner_queue_size = 17, _tick = 1474, _time = 1.654e+09, train_seconds = 1046.2)
[2022-05-31 14:27:52,486][root][INFO] - Step 6973440 @ 6139.1 SPS. Inference batcher size: 86. Learner queue size: 13. Other stats: (step = 6973440, mean_episode_return = 23.57, mean_episode_step = 1096.8, total_loss = 1280.0, pg_loss = 862.16, baseline_loss = 424.62, entropy_loss = -6.8129, learner_queue_size = 20, _tick = 1482, _time = 1.654e+09, train_seconds = 1051.2)
[2022-05-31 14:27:57,492][root][INFO] - Step 7006720 @ 6647.7 SPS. Inference batcher size: 130. Learner queue size: 11. Other stats: (step = 7006720, mean_episode_return = None, mean_episode_step = 1369.2, total_loss = -359.15, pg_loss = -371.28, baseline_loss = 19.004, entropy_loss = -6.8763, learner_queue_size = 15, _tick = 1490, _time = 1.654e+09, train_seconds = 1056.2)
[2022-05-31 14:28:02,498][root][INFO] - Step 7040000 @ 6648.0 SPS. Inference batcher size: 132. Learner queue size: 18. Other stats: (step = 7040000, mean_episode_return = 17.54, mean_episode_step = 1435.8, total_loss = 23.276, pg_loss = -63.484, baseline_loss = 93.598, entropy_loss = -6.8378, learner_queue_size = 12, _tick = 1499, _time = 1.654e+09, train_seconds = 1061.2)
[2022-05-31 14:28:07,504][root][INFO] - Step 7073280 @ 6648.0 SPS. Inference batcher size: 147. Learner queue size: 16. Other stats: (step = 7073280, mean_episode_return = 23.59, mean_episode_step = 1065.6, total_loss = 116.32, pg_loss = -28.857, baseline_loss = 152.11, entropy_loss = -6.9295, learner_queue_size = 25, _tick = 1509, _time = 1.654e+09, train_seconds = 1066.2)
[2022-05-31 14:28:12,510][root][INFO] - Step 7106560 @ 6647.9 SPS. Inference batcher size: 120. Learner queue size: 15. Other stats: (step = 7106560, mean_episode_return = 119.11, mean_episode_step = 1245.8, total_loss = 533.21, pg_loss = 327.11, baseline_loss = 212.97, entropy_loss = -6.8745, learner_queue_size = 16, _tick = 1517, _time = 1.654e+09, train_seconds = 1071.2)
[2022-05-31 14:28:17,517][root][INFO] - Step 7139840 @ 6648.0 SPS. Inference batcher size: 129. Learner queue size: 22. Other stats: (step = 7139840, mean_episode_return = None, mean_episode_step = 1410.9, total_loss = 377.16, pg_loss = 217.18, baseline_loss = 166.84, entropy_loss = -6.8515, learner_queue_size = 18, _tick = 1525, _time = 1.654e+09, train_seconds = 1076.2)
[2022-05-31 14:28:22,523][root][INFO] - Step 7173120 @ 6647.4 SPS. Inference batcher size: 123. Learner queue size: 20. Other stats: (step = 7173120, mean_episode_return = 111.97, mean_episode_step = 1251.2, total_loss = 490.65, pg_loss = 286.1, baseline_loss = 211.42, entropy_loss = -6.8699, learner_queue_size = 19, _tick = 1535, _time = 1.654e+09, train_seconds = 1081.2)
[2022-05-31 14:28:27,526][root][INFO] - Step 7206400 @ 6651.9 SPS. Inference batcher size: 74. Learner queue size: 11. Other stats: (step = 7206400, mean_episode_return = 60.17, mean_episode_step = 1492.4, total_loss = 949.25, pg_loss = 330.25, baseline_loss = 625.74, entropy_loss = -6.7285, learner_queue_size = 19, _tick = 1544, _time = 1.654e+09, train_seconds = 1086.2)
[2022-05-31 14:28:32,531][root][INFO] - Step 7239680 @ 6649.8 SPS. Inference batcher size: 130. Learner queue size: 5. Other stats: (step = 7239680, mean_episode_return = 91.83, mean_episode_step = 1383.9, total_loss = 556.78, pg_loss = 43.4, baseline_loss = 520.06, entropy_loss = -6.6841, learner_queue_size = 17, _tick = 1551, _time = 1.654e+09, train_seconds = 1091.2)
[2022-05-31 14:28:37,534][root][INFO] - Step 7272960 @ 6651.4 SPS. Inference batcher size: 91. Learner queue size: 7. Other stats: (step = 7272960, mean_episode_return = None, mean_episode_step = 1349.5, total_loss = 1782.9, pg_loss = 1164.2, baseline_loss = 625.51, entropy_loss = -6.7925, learner_queue_size = 23, _tick = 1561, _time = 1.654e+09, train_seconds = 1096.2)
[2022-05-31 14:28:42,540][root][INFO] - Step 7306240 @ 6647.9 SPS. Inference batcher size: 116. Learner queue size: 18. Other stats: (step = 7306240, mean_episode_return = 71.14, mean_episode_step = 1060.5, total_loss = 788.95, pg_loss = 363.43, baseline_loss = 432.37, entropy_loss = -6.8631, learner_queue_size = 20, _tick = 1572, _time = 1.654e+09, train_seconds = 1101.2)
[2022-05-31 14:28:47,546][root][INFO] - Step 7339520 @ 6648.2 SPS. Inference batcher size: 129. Learner queue size: 11. Other stats: (step = 7339520, mean_episode_return = 8.4298, mean_episode_step = 1151.0, total_loss = -458.55, pg_loss = -543.01, baseline_loss = 91.127, entropy_loss = -6.662, learner_queue_size = 20, _tick = 1580, _time = 1.654e+09, train_seconds = 1106.2)
[2022-05-31 14:28:52,550][root][INFO] - Step 7372800 @ 6650.8 SPS. Inference batcher size: 79. Learner queue size: 4. Other stats: (step = 7372800, mean_episode_return = None, mean_episode_step = 1090.3, total_loss = 2284.7, pg_loss = 1635.0, baseline_loss = 656.34, entropy_loss = -6.6075, learner_queue_size = 14, _tick = 1591, _time = 1.654e+09, train_seconds = 1111.2)
[2022-05-31 14:28:57,556][root][INFO] - Step 7406080 @ 6647.9 SPS. Inference batcher size: 48. Learner queue size: 4. Other stats: (step = 7406080, mean_episode_return = None, mean_episode_step = 1069.5, total_loss = 1595.2, pg_loss = 1063.3, baseline_loss = 538.34, entropy_loss = -6.4182, learner_queue_size = 17, _tick = 1599, _time = 1.654e+09, train_seconds = 1116.2)
[2022-05-31 14:29:02,562][root][INFO] - Step 7439360 @ 6648.0 SPS. Inference batcher size: 123. Learner queue size: 3. Other stats: (step = 7439360, mean_episode_return = None, mean_episode_step = 1448.9, total_loss = 1628.0, pg_loss = 637.58, baseline_loss = 996.69, entropy_loss = -6.2871, learner_queue_size = 23, _tick = 1605, _time = 1.654e+09, train_seconds = 1121.2)
[2022-05-31 14:29:07,566][root][INFO] - Step 7472640 @ 6650.7 SPS. Inference batcher size: 131. Learner queue size: 7. Other stats: (step = 7472640, mean_episode_return = 75.89, mean_episode_step = 1456.8, total_loss = -41.901, pg_loss = -172.96, baseline_loss = 137.48, entropy_loss = -6.4211, learner_queue_size = 25, _tick = 1614, _time = 1.654e+09, train_seconds = 1126.3)
[2022-05-31 14:29:12,571][root][INFO] - Step 7505920 @ 6649.9 SPS. Inference batcher size: 9. Learner queue size: 8. Other stats: (step = 7505920, mean_episode_return = None, mean_episode_step = 1123.6, total_loss = 63.765, pg_loss = -17.982, baseline_loss = 87.987, entropy_loss = -6.2398, learner_queue_size = 18, _tick = 1625, _time = 1.654e+09, train_seconds = 1131.3)
[2022-05-31 14:29:17,574][root][INFO] - Step 7539200 @ 6651.5 SPS. Inference batcher size: 90. Learner queue size: 7. Other stats: (step = 7539200, mean_episode_return = 44.311, mean_episode_step = 1250.8, total_loss = 21.016, pg_loss = -104.14, baseline_loss = 131.78, entropy_loss = -6.6244, learner_queue_size = 14, _tick = 1635, _time = 1.654e+09, train_seconds = 1136.3)
[2022-05-31 14:29:22,578][root][INFO] - Step 7572480 @ 6650.7 SPS. Inference batcher size: 105. Learner queue size: 17. Other stats: (step = 7572480, mean_episode_return = 6.9947, mean_episode_step = 1248.2, total_loss = 253.64, pg_loss = 84.535, baseline_loss = 175.28, entropy_loss = -6.1771, learner_queue_size = 16, _tick = 1642, _time = 1.654e+09, train_seconds = 1141.3)
[2022-05-31 14:29:27,582][root][INFO] - Step 7605760 @ 6650.7 SPS. Inference batcher size: 138. Learner queue size: 8. Other stats: (step = 7605760, mean_episode_return = 47.96, mean_episode_step = 1268.1, total_loss = -344.9, pg_loss = -414.54, baseline_loss = 75.667, entropy_loss = -6.0243, learner_queue_size = 18, _tick = 1652, _time = 1.654e+09, train_seconds = 1146.3)
[2022-05-31 14:29:32,588][root][INFO] - Step 7639040 @ 6648.0 SPS. Inference batcher size: 35. Learner queue size: 4. Other stats: (step = 7639040, mean_episode_return = 240.46, mean_episode_step = 1418.9, total_loss = -273.2, pg_loss = -346.5, baseline_loss = 79.145, entropy_loss = -5.8442, learner_queue_size = 13, _tick = 1661, _time = 1.654e+09, train_seconds = 1151.3)
[2022-05-31 14:29:37,594][root][INFO] - Step 7672320 @ 6647.8 SPS. Inference batcher size: 11. Learner queue size: 11. Other stats: (step = 7672320, mean_episode_return = 130.43, mean_episode_step = 1179.0, total_loss = 1959.0, pg_loss = 1146.8, baseline_loss = 818.21, entropy_loss = -6.009, learner_queue_size = 22, _tick = 1672, _time = 1.654e+09, train_seconds = 1156.3)
[2022-05-31 14:29:42,598][root][INFO] - Step 7705600 @ 6651.0 SPS. Inference batcher size: 175. Learner queue size: 8. Other stats: (step = 7705600, mean_episode_return = 49.142, mean_episode_step = 1323.4, total_loss = 170.11, pg_loss = 38.496, baseline_loss = 137.76, entropy_loss = -6.1411, learner_queue_size = 27, _tick = 1682, _time = 1.654e+09, train_seconds = 1161.3)
[2022-05-31 14:29:47,604][root][INFO] - Step 7738880 @ 6647.8 SPS. Inference batcher size: 137. Learner queue size: 1. Other stats: (step = 7738880, mean_episode_return = None, mean_episode_step = 1442.7, total_loss = 155.01, pg_loss = 28.13, baseline_loss = 132.98, entropy_loss = -6.1005, learner_queue_size = 18, _tick = 1693, _time = 1.654e+09, train_seconds = 1166.3)
[2022-05-31 14:29:52,606][root][INFO] - Step 7772160 @ 6653.5 SPS. Inference batcher size: 157. Learner queue size: 31. Other stats: (step = 7772160, mean_episode_return = None, mean_episode_step = 1098.5, total_loss = 186.23, pg_loss = 80.509, baseline_loss = 111.69, entropy_loss = -5.9707, learner_queue_size = 11, _tick = 1701, _time = 1.654e+09, train_seconds = 1171.3)
[2022-05-31 14:29:57,610][root][INFO] - Step 7805440 @ 6650.8 SPS. Inference batcher size: 111. Learner queue size: 4. Other stats: (step = 7805440, mean_episode_return = None, mean_episode_step = 1304.1, total_loss = 1168.0, pg_loss = 819.33, baseline_loss = 354.96, entropy_loss = -6.2453, learner_queue_size = 18, _tick = 1707, _time = 1.654e+09, train_seconds = 1176.3)
[2022-05-31 14:30:02,614][root][INFO] - Step 7838720 @ 6650.6 SPS. Inference batcher size: 128. Learner queue size: 27. Other stats: (step = 7838720, mean_episode_return = -17.4, mean_episode_step = 1408.2, total_loss = -448.12, pg_loss = -481.95, baseline_loss = 40.132, entropy_loss = -6.2982, learner_queue_size = 16, _tick = 1716, _time = 1.654e+09, train_seconds = 1181.3)
[2022-05-31 14:30:07,620][root][INFO] - Step 7869440 @ 6136.3 SPS. Inference batcher size: 19. Learner queue size: 20. Other stats: (step = 7869440, mean_episode_return = 125.61, mean_episode_step = 1393.4, total_loss = 2247.2, pg_loss = 1208.6, baseline_loss = 1045.0, entropy_loss = -6.3079, learner_queue_size = 30, _tick = 1726, _time = 1.654e+09, train_seconds = 1186.3)
[2022-05-31 14:30:12,628][root][INFO] - Step 7902720 @ 6646.1 SPS. Inference batcher size: 64. Learner queue size: 19. Other stats: (step = 7902720, mean_episode_return = 50.451, mean_episode_step = 1122.9, total_loss = 264.84, pg_loss = 92.791, baseline_loss = 178.06, entropy_loss = -6.0133, learner_queue_size = 15, _tick = 1735, _time = 1.654e+09, train_seconds = 1191.3)
[2022-05-31 14:30:17,634][root][INFO] - Step 7936000 @ 6648.0 SPS. Inference batcher size: 118. Learner queue size: 17. Other stats: (step = 7936000, mean_episode_return = 53.393, mean_episode_step = 1219.3, total_loss = 622.39, pg_loss = 201.96, baseline_loss = 426.46, entropy_loss = -6.0362, learner_queue_size = 19, _tick = 1744, _time = 1.654e+09, train_seconds = 1196.3)
[2022-05-31 14:30:22,638][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 14:30:22,812][root][INFO] - Step 7969280 @ 6650.3 SPS. Inference batcher size: 2. Learner queue size: 24. Other stats: (step = 7971840, mean_episode_return = None, mean_episode_step = 1272.9, total_loss = 1388.3, pg_loss = 943.92, baseline_loss = 450.49, entropy_loss = -6.0941, learner_queue_size = 19, _tick = 1755, _time = 1.654e+09, train_seconds = 1201.3)
[2022-05-31 14:30:27,814][root][INFO] - Step 8002560 @ 6429.3 SPS. Inference batcher size: 156. Learner queue size: 23. Other stats: (step = 8002560, mean_episode_return = -4.6903, mean_episode_step = 1072.8, total_loss = -125.78, pg_loss = -232.23, baseline_loss = 112.1, entropy_loss = -5.6469, learner_queue_size = 19, _tick = 1763, _time = 1.654e+09, train_seconds = 1206.5)
[2022-05-31 14:30:32,818][root][INFO] - Step 8035840 @ 6650.9 SPS. Inference batcher size: 38. Learner queue size: 25. Other stats: (step = 8035840, mean_episode_return = 49.422, mean_episode_step = 1238.1, total_loss = 263.46, pg_loss = 106.71, baseline_loss = 162.8, entropy_loss = -6.0497, learner_queue_size = 17, _tick = 1773, _time = 1.654e+09, train_seconds = 1211.5)
[2022-05-31 14:30:37,822][root][INFO] - Step 8069120 @ 6650.5 SPS. Inference batcher size: 12. Learner queue size: 15. Other stats: (step = 8069120, mean_episode_return = 21.31, mean_episode_step = 1460.2, total_loss = 293.37, pg_loss = -42.481, baseline_loss = 341.8, entropy_loss = -5.9528, learner_queue_size = 17, _tick = 1782, _time = 1.654e+09, train_seconds = 1216.5)
[2022-05-31 14:30:42,827][root][INFO] - Step 8104960 @ 7162.0 SPS. Inference batcher size: 68. Learner queue size: 28. Other stats: (step = 8104960, mean_episode_return = 52.976, mean_episode_step = 1337.4, total_loss = 547.22, pg_loss = 213.7, baseline_loss = 339.42, entropy_loss = -5.9045, learner_queue_size = 17, _tick = 1792, _time = 1.654e+09, train_seconds = 1221.5)
[2022-05-31 14:30:47,830][root][INFO] - Step 8138240 @ 6651.1 SPS. Inference batcher size: 34. Learner queue size: 25. Other stats: (step = 8138240, mean_episode_return = 58.31, mean_episode_step = 1349.3, total_loss = 316.28, pg_loss = 85.202, baseline_loss = 236.94, entropy_loss = -5.8565, learner_queue_size = 19, _tick = 1797, _time = 1.654e+09, train_seconds = 1226.5)
[2022-05-31 14:30:52,834][root][INFO] - Step 8171520 @ 6650.9 SPS. Inference batcher size: 125. Learner queue size: 0. Other stats: (step = 8171520, mean_episode_return = 73.86, mean_episode_step = 1266.6, total_loss = 3.15, pg_loss = -221.08, baseline_loss = 229.94, entropy_loss = -5.7058, learner_queue_size = 13, _tick = 1805, _time = 1.654e+09, train_seconds = 1231.5)
[2022-05-31 14:30:57,840][root][INFO] - Step 8204800 @ 6647.6 SPS. Inference batcher size: 137. Learner queue size: 4. Other stats: (step = 8204800, mean_episode_return = None, mean_episode_step = 1572.8, total_loss = -11.628, pg_loss = -98.807, baseline_loss = 93.018, entropy_loss = -5.8395, learner_queue_size = 18, _tick = 1812, _time = 1.654e+09, train_seconds = 1236.5)
[2022-05-31 14:31:02,846][root][INFO] - Step 8238080 @ 6648.4 SPS. Inference batcher size: 168. Learner queue size: 5. Other stats: (step = 8238080, mean_episode_return = None, mean_episode_step = 1315.2, total_loss = 100.24, pg_loss = -83.292, baseline_loss = 189.41, entropy_loss = -5.875, learner_queue_size = 24, _tick = 1820, _time = 1.654e+09, train_seconds = 1241.5)
[2022-05-31 14:31:07,850][root][INFO] - Step 8271360 @ 6650.5 SPS. Inference batcher size: 68. Learner queue size: 2. Other stats: (step = 8271360, mean_episode_return = None, mean_episode_step = 1450.9, total_loss = 811.99, pg_loss = 503.04, baseline_loss = 314.81, entropy_loss = -5.861, learner_queue_size = 18, _tick = 1825, _time = 1.654e+09, train_seconds = 1246.5)
[2022-05-31 14:31:12,858][root][INFO] - Step 8304640 @ 6645.5 SPS. Inference batcher size: 132. Learner queue size: 14. Other stats: (step = 8304640, mean_episode_return = 18.7, mean_episode_step = 1600.1, total_loss = 691.26, pg_loss = 373.98, baseline_loss = 323.15, entropy_loss = -5.8569, learner_queue_size = 25, _tick = 1834, _time = 1.654e+09, train_seconds = 1251.5)
[2022-05-31 14:31:17,862][root][INFO] - Step 8337920 @ 6650.7 SPS. Inference batcher size: 54. Learner queue size: 10. Other stats: (step = 8337920, mean_episode_return = 125.96, mean_episode_step = 968.75, total_loss = -278.66, pg_loss = -555.85, baseline_loss = 283.03, entropy_loss = -5.8351, learner_queue_size = 17, _tick = 1843, _time = 1.654e+09, train_seconds = 1256.5)
[2022-05-31 14:31:22,866][root][INFO] - Step 8371200 @ 6650.6 SPS. Inference batcher size: 46. Learner queue size: 12. Other stats: (step = 8371200, mean_episode_return = None, mean_episode_step = 1488.1, total_loss = 2466.0, pg_loss = 1682.0, baseline_loss = 789.88, entropy_loss = -5.8984, learner_queue_size = 13, _tick = 1850, _time = 1.654e+09, train_seconds = 1261.6)
[2022-05-31 14:31:27,870][root][INFO] - Step 8404480 @ 6650.6 SPS. Inference batcher size: 102. Learner queue size: 14. Other stats: (step = 8404480, mean_episode_return = 81.819, mean_episode_step = 1458.2, total_loss = 446.6, pg_loss = 217.72, baseline_loss = 234.71, entropy_loss = -5.8397, learner_queue_size = 21, _tick = 1858, _time = 1.654e+09, train_seconds = 1266.6)
[2022-05-31 14:31:32,874][root][INFO] - Step 8437760 @ 6650.8 SPS. Inference batcher size: 29. Learner queue size: 11. Other stats: (step = 8437760, mean_episode_return = 82.4, mean_episode_step = 1476.9, total_loss = 496.15, pg_loss = 180.28, baseline_loss = 321.82, entropy_loss = -5.9548, learner_queue_size = 12, _tick = 1866, _time = 1.654e+09, train_seconds = 1271.6)
[2022-05-31 14:31:37,881][root][INFO] - Step 8471040 @ 6646.8 SPS. Inference batcher size: 72. Learner queue size: 11. Other stats: (step = 8471040, mean_episode_return = 23.07, mean_episode_step = 1719.5, total_loss = 162.5, pg_loss = -22.798, baseline_loss = 191.34, entropy_loss = -6.0326, learner_queue_size = 24, _tick = 1875, _time = 1.654e+09, train_seconds = 1276.6)
[2022-05-31 14:31:42,886][root][INFO] - Step 8504320 @ 6649.2 SPS. Inference batcher size: 21. Learner queue size: 1. Other stats: (step = 8504320, mean_episode_return = 136.77, mean_episode_step = 1757.0, total_loss = -287.34, pg_loss = -498.34, baseline_loss = 216.95, entropy_loss = -5.9446, learner_queue_size = 27, _tick = 1885, _time = 1.654e+09, train_seconds = 1281.6)
[2022-05-31 14:31:47,892][root][INFO] - Step 8537600 @ 6647.8 SPS. Inference batcher size: 160. Learner queue size: 4. Other stats: (step = 8537600, mean_episode_return = 50.951, mean_episode_step = 1437.9, total_loss = -71.542, pg_loss = -278.73, baseline_loss = 213.1, entropy_loss = -5.9116, learner_queue_size = 22, _tick = 1894, _time = 1.654e+09, train_seconds = 1286.6)
[2022-05-31 14:31:52,898][root][INFO] - Step 8570880 @ 6648.2 SPS. Inference batcher size: 93. Learner queue size: 13. Other stats: (step = 8570880, mean_episode_return = 98.14, mean_episode_step = 1399.2, total_loss = 199.74, pg_loss = -2.8191, baseline_loss = 208.62, entropy_loss = -6.0567, learner_queue_size = 23, _tick = 1903, _time = 1.654e+09, train_seconds = 1291.6)
[2022-05-31 14:31:57,902][root][INFO] - Step 8604160 @ 6650.7 SPS. Inference batcher size: 113. Learner queue size: 5. Other stats: (step = 8604160, mean_episode_return = 89.407, mean_episode_step = 1341.8, total_loss = 395.49, pg_loss = 177.27, baseline_loss = 224.23, entropy_loss = -6.0047, learner_queue_size = 16, _tick = 1914, _time = 1.654e+09, train_seconds = 1296.6)
[2022-05-31 14:32:02,906][root][INFO] - Step 8637440 @ 6650.6 SPS. Inference batcher size: 61. Learner queue size: 27. Other stats: (step = 8637440, mean_episode_return = 2.4496, mean_episode_step = 1823.2, total_loss = 334.43, pg_loss = 20.557, baseline_loss = 319.87, entropy_loss = -5.9981, learner_queue_size = 16, _tick = 1924, _time = 1.654e+09, train_seconds = 1301.6)
[2022-05-31 14:32:07,910][root][INFO] - Step 8670720 @ 6650.7 SPS. Inference batcher size: 81. Learner queue size: 8. Other stats: (step = 8670720, mean_episode_return = 95.779, mean_episode_step = 1473.6, total_loss = 189.56, pg_loss = -129.48, baseline_loss = 324.9, entropy_loss = -5.8656, learner_queue_size = 17, _tick = 1936, _time = 1.654e+09, train_seconds = 1306.6)
[2022-05-31 14:32:12,914][root][INFO] - Step 8704000 @ 6650.6 SPS. Inference batcher size: 101. Learner queue size: 22. Other stats: (step = 8704000, mean_episode_return = None, mean_episode_step = 1332.0, total_loss = 336.67, pg_loss = 206.66, baseline_loss = 135.87, entropy_loss = -5.8638, learner_queue_size = 13, _tick = 1946, _time = 1.654e+09, train_seconds = 1311.6)
[2022-05-31 14:32:17,918][root][INFO] - Step 8737280 @ 6650.7 SPS. Inference batcher size: 33. Learner queue size: 31. Other stats: (step = 8737280, mean_episode_return = None, mean_episode_step = 1397.3, total_loss = 261.08, pg_loss = 128.92, baseline_loss = 137.93, entropy_loss = -5.7692, learner_queue_size = 18, _tick = 1957, _time = 1.654e+09, train_seconds = 1316.6)
[2022-05-31 14:32:22,922][root][INFO] - Step 8770560 @ 6650.7 SPS. Inference batcher size: 66. Learner queue size: 1. Other stats: (step = 8770560, mean_episode_return = None, mean_episode_step = 1458.3, total_loss = 221.95, pg_loss = 50.046, baseline_loss = 177.63, entropy_loss = -5.7233, learner_queue_size = 27, _tick = 1963, _time = 1.654e+09, train_seconds = 1321.6)
[2022-05-31 14:32:27,926][root][INFO] - Step 8803840 @ 6650.7 SPS. Inference batcher size: 86. Learner queue size: 19. Other stats: (step = 8803840, mean_episode_return = 60.002, mean_episode_step = 1110.2, total_loss = -463.13, pg_loss = -485.98, baseline_loss = 28.601, entropy_loss = -5.7555, learner_queue_size = 16, _tick = 1970, _time = 1.654e+09, train_seconds = 1326.6)
[2022-05-31 14:32:32,930][root][INFO] - Step 8837120 @ 6650.7 SPS. Inference batcher size: 100. Learner queue size: 0. Other stats: (step = 8837120, mean_episode_return = 35.205, mean_episode_step = 1472.4, total_loss = 475.82, pg_loss = 95.892, baseline_loss = 385.55, entropy_loss = -5.62, learner_queue_size = 18, _tick = 1977, _time = 1.654e+09, train_seconds = 1331.6)
[2022-05-31 14:32:37,934][root][INFO] - Step 8870400 @ 6650.8 SPS. Inference batcher size: 114. Learner queue size: 22. Other stats: (step = 8870400, mean_episode_return = 67.118, mean_episode_step = 1518.4, total_loss = -435.18, pg_loss = -462.08, baseline_loss = 32.406, entropy_loss = -5.5141, learner_queue_size = 17, _tick = 1989, _time = 1.654e+09, train_seconds = 1336.6)
[2022-05-31 14:32:42,938][root][INFO] - Step 8903680 @ 6650.6 SPS. Inference batcher size: 155. Learner queue size: 27. Other stats: (step = 8903680, mean_episode_return = None, mean_episode_step = 1433.7, total_loss = -124.37, pg_loss = -167.62, baseline_loss = 48.687, entropy_loss = -5.4402, learner_queue_size = 13, _tick = 1994, _time = 1.654e+09, train_seconds = 1341.6)
[2022-05-31 14:32:47,942][root][INFO] - Step 8936960 @ 6650.6 SPS. Inference batcher size: 121. Learner queue size: 2. Other stats: (step = 8936960, mean_episode_return = 48.18, mean_episode_step = 1721.3, total_loss = -373.62, pg_loss = -482.91, baseline_loss = 114.79, entropy_loss = -5.4918, learner_queue_size = 11, _tick = 2003, _time = 1.654e+09, train_seconds = 1346.6)
[2022-05-31 14:32:52,946][root][INFO] - Step 8970240 @ 6650.8 SPS. Inference batcher size: 169. Learner queue size: 1. Other stats: (step = 8970240, mean_episode_return = None, mean_episode_step = 1368.9, total_loss = 20.391, pg_loss = -107.26, baseline_loss = 132.99, entropy_loss = -5.3408, learner_queue_size = 20, _tick = 2010, _time = 1.654e+09, train_seconds = 1351.6)
[2022-05-31 14:32:57,950][root][INFO] - Step 9003520 @ 6650.4 SPS. Inference batcher size: 78. Learner queue size: 4. Other stats: (step = 9003520, mean_episode_return = None, mean_episode_step = 1677.7, total_loss = -102.71, pg_loss = -151.25, baseline_loss = 53.862, entropy_loss = -5.3268, learner_queue_size = 19, _tick = 2016, _time = 1.654e+09, train_seconds = 1356.6)
[2022-05-31 14:33:02,954][root][INFO] - Step 9036800 @ 6650.9 SPS. Inference batcher size: 85. Learner queue size: 8. Other stats: (step = 9036800, mean_episode_return = 142.35, mean_episode_step = 1575.3, total_loss = -343.3, pg_loss = -441.05, baseline_loss = 103.15, entropy_loss = -5.392, learner_queue_size = 26, _tick = 2024, _time = 1.654e+09, train_seconds = 1361.6)
[2022-05-31 14:33:07,960][root][INFO] - Step 9070080 @ 6648.4 SPS. Inference batcher size: 183. Learner queue size: 7. Other stats: (step = 9070080, mean_episode_return = 117.44, mean_episode_step = 1572.0, total_loss = 43.181, pg_loss = -195.25, baseline_loss = 243.85, entropy_loss = -5.4191, learner_queue_size = 14, _tick = 2033, _time = 1.654e+09, train_seconds = 1366.6)
[2022-05-31 14:33:12,966][root][INFO] - Step 9103360 @ 6647.5 SPS. Inference batcher size: 82. Learner queue size: 12. Other stats: (step = 9103360, mean_episode_return = None, mean_episode_step = 1383.3, total_loss = 357.43, pg_loss = 187.5, baseline_loss = 175.35, entropy_loss = -5.4225, learner_queue_size = 17, _tick = 2040, _time = 1.654e+09, train_seconds = 1371.7)
[2022-05-31 14:33:17,970][root][INFO] - Step 9136640 @ 6650.7 SPS. Inference batcher size: 127. Learner queue size: 16. Other stats: (step = 9136640, mean_episode_return = 127.67, mean_episode_step = 1283.7, total_loss = 899.47, pg_loss = 490.7, baseline_loss = 414.27, entropy_loss = -5.5025, learner_queue_size = 14, _tick = 2049, _time = 1.654e+09, train_seconds = 1376.7)
[2022-05-31 14:33:22,976][root][INFO] - Step 9169920 @ 6647.9 SPS. Inference batcher size: 146. Learner queue size: 14. Other stats: (step = 9169920, mean_episode_return = None, mean_episode_step = 1634.2, total_loss = -187.06, pg_loss = -254.82, baseline_loss = 73.34, entropy_loss = -5.5795, learner_queue_size = 18, _tick = 2056, _time = 1.654e+09, train_seconds = 1381.7)
[2022-05-31 14:33:27,982][root][INFO] - Step 9203200 @ 6648.0 SPS. Inference batcher size: 96. Learner queue size: 13. Other stats: (step = 9203200, mean_episode_return = 15.72, mean_episode_step = 1583.9, total_loss = 595.25, pg_loss = 209.79, baseline_loss = 390.99, entropy_loss = -5.5298, learner_queue_size = 20, _tick = 2067, _time = 1.654e+09, train_seconds = 1386.7)
[2022-05-31 14:33:32,986][root][INFO] - Step 9236480 @ 6650.8 SPS. Inference batcher size: 162. Learner queue size: 13. Other stats: (step = 9236480, mean_episode_return = 40.176, mean_episode_step = 1528.8, total_loss = 476.34, pg_loss = 160.87, baseline_loss = 321.08, entropy_loss = -5.6114, learner_queue_size = 16, _tick = 2074, _time = 1.654e+09, train_seconds = 1391.7)
[2022-05-31 14:33:37,992][root][INFO] - Step 9269760 @ 6647.7 SPS. Inference batcher size: 57. Learner queue size: 14. Other stats: (step = 9269760, mean_episode_return = 22.5, mean_episode_step = 1415.0, total_loss = 40.392, pg_loss = -99.552, baseline_loss = 145.72, entropy_loss = -5.7743, learner_queue_size = 21, _tick = 2084, _time = 1.654e+09, train_seconds = 1396.7)
[2022-05-31 14:33:42,999][root][INFO] - Step 9303040 @ 6646.9 SPS. Inference batcher size: 12. Learner queue size: 13. Other stats: (step = 9303040, mean_episode_return = None, mean_episode_step = 1587.8, total_loss = 137.71, pg_loss = 53.642, baseline_loss = 89.852, entropy_loss = -5.7874, learner_queue_size = 21, _tick = 2091, _time = 1.654e+09, train_seconds = 1401.7)
[2022-05-31 14:33:48,006][root][INFO] - Step 9336320 @ 6646.9 SPS. Inference batcher size: 74. Learner queue size: 19. Other stats: (step = 9336320, mean_episode_return = None, mean_episode_step = 1411.6, total_loss = 19.258, pg_loss = -74.562, baseline_loss = 99.549, entropy_loss = -5.7292, learner_queue_size = 8, _tick = 2102, _time = 1.654e+09, train_seconds = 1406.7)
[2022-05-31 14:33:53,007][root][INFO] - Step 9369600 @ 6654.4 SPS. Inference batcher size: 144. Learner queue size: 17. Other stats: (step = 9369600, mean_episode_return = None, mean_episode_step = 1668.1, total_loss = -167.31, pg_loss = -230.72, baseline_loss = 69.074, entropy_loss = -5.665, learner_queue_size = 16, _tick = 2112, _time = 1.654e+09, train_seconds = 1411.7)
[2022-05-31 14:33:58,010][root][INFO] - Step 9402880 @ 6652.2 SPS. Inference batcher size: 195. Learner queue size: 18. Other stats: (step = 9402880, mean_episode_return = 169.92, mean_episode_step = 1491.9, total_loss = 323.44, pg_loss = 36.366, baseline_loss = 292.84, entropy_loss = -5.7705, learner_queue_size = 12, _tick = 2118, _time = 1.654e+09, train_seconds = 1416.7)
[2022-05-31 14:34:03,014][root][INFO] - Step 9438720 @ 7162.4 SPS. Inference batcher size: 141. Learner queue size: 21. Other stats: (step = 9438720, mean_episode_return = 4.1896, mean_episode_step = 1306.3, total_loss = -118.28, pg_loss = -250.14, baseline_loss = 137.67, entropy_loss = -5.803, learner_queue_size = 17, _tick = 2130, _time = 1.654e+09, train_seconds = 1421.7)
[2022-05-31 14:34:08,021][root][INFO] - Step 9472000 @ 6646.2 SPS. Inference batcher size: 78. Learner queue size: 22. Other stats: (step = 9472000, mean_episode_return = 45.484, mean_episode_step = 1128.7, total_loss = -104.46, pg_loss = -295.13, baseline_loss = 196.41, entropy_loss = -5.7436, learner_queue_size = 22, _tick = 2139, _time = 1.654e+09, train_seconds = 1426.7)
[2022-05-31 14:34:13,028][root][INFO] - Step 9502720 @ 6136.3 SPS. Inference batcher size: 115. Learner queue size: 15. Other stats: (step = 9502720, mean_episode_return = None, mean_episode_step = 1559.9, total_loss = 50.967, pg_loss = -52.557, baseline_loss = 109.32, entropy_loss = -5.7985, learner_queue_size = 21, _tick = 2146, _time = 1.654e+09, train_seconds = 1431.7)
[2022-05-31 14:34:18,030][root][INFO] - Step 9536000 @ 6652.8 SPS. Inference batcher size: 83. Learner queue size: 23. Other stats: (step = 9536000, mean_episode_return = None, mean_episode_step = 1335.2, total_loss = -174.29, pg_loss = -228.97, baseline_loss = 60.337, entropy_loss = -5.6539, learner_queue_size = 16, _tick = 2153, _time = 1.654e+09, train_seconds = 1436.7)
[2022-05-31 14:34:23,036][root][INFO] - Step 9569280 @ 6648.5 SPS. Inference batcher size: 73. Learner queue size: 16. Other stats: (step = 9569280, mean_episode_return = None, mean_episode_step = 1248.2, total_loss = -130.17, pg_loss = -164.75, baseline_loss = 40.294, entropy_loss = -5.7202, learner_queue_size = 27, _tick = 2161, _time = 1.654e+09, train_seconds = 1441.7)
[2022-05-31 14:34:28,042][root][INFO] - Step 9602560 @ 6648.1 SPS. Inference batcher size: 126. Learner queue size: 14. Other stats: (step = 9602560, mean_episode_return = -1.0704, mean_episode_step = 1462.4, total_loss = -220.6, pg_loss = -276.55, baseline_loss = 61.787, entropy_loss = -5.8318, learner_queue_size = 13, _tick = 2173, _time = 1.654e+09, train_seconds = 1446.7)
[2022-05-31 14:34:33,046][root][INFO] - Step 9638400 @ 7161.8 SPS. Inference batcher size: 81. Learner queue size: 17. Other stats: (step = 9638400, mean_episode_return = 15.54, mean_episode_step = 1218.8, total_loss = 1502.0, pg_loss = 1012.6, baseline_loss = 495.07, entropy_loss = -5.6605, learner_queue_size = 13, _tick = 2186, _time = 1.654e+09, train_seconds = 1451.7)
[2022-05-31 14:34:38,052][root][INFO] - Step 9669120 @ 6136.4 SPS. Inference batcher size: 165. Learner queue size: 23. Other stats: (step = 9669120, mean_episode_return = -0.67004, mean_episode_step = 1221.0, total_loss = 143.02, pg_loss = -1.6628, baseline_loss = 150.28, entropy_loss = -5.5988, learner_queue_size = 20, _tick = 2195, _time = 1.654e+09, train_seconds = 1456.7)
[2022-05-31 14:34:43,058][root][INFO] - Step 9704960 @ 7159.7 SPS. Inference batcher size: 41. Learner queue size: 1. Other stats: (step = 9704960, mean_episode_return = 18.04, mean_episode_step = 1485.4, total_loss = 586.18, pg_loss = 262.07, baseline_loss = 329.71, entropy_loss = -5.5998, learner_queue_size = 29, _tick = 2205, _time = 1.654e+09, train_seconds = 1461.7)
[2022-05-31 14:34:48,062][root][INFO] - Step 9738240 @ 6650.7 SPS. Inference batcher size: 128. Learner queue size: 31. Other stats: (step = 9738240, mean_episode_return = 84.359, mean_episode_step = 1201.0, total_loss = 365.34, pg_loss = 138.12, baseline_loss = 232.9, entropy_loss = -5.6834, learner_queue_size = 21, _tick = 2214, _time = 1.654e+09, train_seconds = 1466.7)
[2022-05-31 14:34:53,066][root][INFO] - Step 9771520 @ 6650.6 SPS. Inference batcher size: 136. Learner queue size: 29. Other stats: (step = 9771520, mean_episode_return = 209.26, mean_episode_step = 1065.4, total_loss = 418.6, pg_loss = 134.46, baseline_loss = 289.73, entropy_loss = -5.5885, learner_queue_size = 14, _tick = 2226, _time = 1.654e+09, train_seconds = 1471.8)
[2022-05-31 14:34:58,070][root][INFO] - Step 9804800 @ 6650.7 SPS. Inference batcher size: 148. Learner queue size: 1. Other stats: (step = 9804800, mean_episode_return = None, mean_episode_step = 1296.6, total_loss = 491.99, pg_loss = 296.58, baseline_loss = 201.02, entropy_loss = -5.612, learner_queue_size = 19, _tick = 2233, _time = 1.654e+09, train_seconds = 1476.8)
[2022-05-31 14:35:03,074][root][INFO] - Step 9838080 @ 6650.8 SPS. Inference batcher size: 38. Learner queue size: 23. Other stats: (step = 9838080, mean_episode_return = nan, mean_episode_step = 1101.4, total_loss = 404.38, pg_loss = 164.45, baseline_loss = 245.45, entropy_loss = -5.5226, learner_queue_size = 28, _tick = 2239, _time = 1.654e+09, train_seconds = 1481.8)
[2022-05-31 14:35:08,079][root][INFO] - Step 9868800 @ 6137.9 SPS. Inference batcher size: 191. Learner queue size: 20. Other stats: (step = 9868800, mean_episode_return = None, mean_episode_step = 1459.8, total_loss = 633.26, pg_loss = 317.81, baseline_loss = 320.91, entropy_loss = -5.4593, learner_queue_size = 21, _tick = 2249, _time = 1.654e+09, train_seconds = 1486.8)
[2022-05-31 14:35:13,082][root][INFO] - Step 9904640 @ 7163.5 SPS. Inference batcher size: 80. Learner queue size: 22. Other stats: (step = 9904640, mean_episode_return = None, mean_episode_step = 1262.4, total_loss = -214.83, pg_loss = -225.87, baseline_loss = 16.549, entropy_loss = -5.5032, learner_queue_size = 18, _tick = 2260, _time = 1.654e+09, train_seconds = 1491.8)
[2022-05-31 14:35:18,088][root][INFO] - Step 9935360 @ 6136.9 SPS. Inference batcher size: 144. Learner queue size: 22. Other stats: (step = 9935360, mean_episode_return = None, mean_episode_step = 1396.5, total_loss = -122.86, pg_loss = -141.99, baseline_loss = 24.687, entropy_loss = -5.5498, learner_queue_size = 13, _tick = 2268, _time = 1.654e+09, train_seconds = 1496.8)
[2022-05-31 14:35:23,090][root][INFO] - Step 9971200 @ 7165.0 SPS. Inference batcher size: 131. Learner queue size: 21. Other stats: (step = 9971200, mean_episode_return = None, mean_episode_step = 1363.1, total_loss = 538.81, pg_loss = 324.87, baseline_loss = 219.58, entropy_loss = -5.639, learner_queue_size = 18, _tick = 2277, _time = 1.654e+09, train_seconds = 1501.8)
[2022-05-31 14:35:28,094][root][INFO] - Step 10001920 @ 6139.0 SPS. Inference batcher size: 104. Learner queue size: 20. Other stats: (step = 10001920, mean_episode_return = 21.1, mean_episode_step = 1475.2, total_loss = 1024.6, pg_loss = 617.47, baseline_loss = 412.91, entropy_loss = -5.7433, learner_queue_size = 18, _tick = 2286, _time = 1.654e+09, train_seconds = 1506.8)
[2022-05-31 14:35:33,098][root][INFO] - Step 10035200 @ 6650.6 SPS. Inference batcher size: 121. Learner queue size: 11. Other stats: (step = 10035200, mean_episode_return = 20.83, mean_episode_step = 1293.0, total_loss = -286.07, pg_loss = -374.87, baseline_loss = 94.403, entropy_loss = -5.6002, learner_queue_size = 18, _tick = 2298, _time = 1.654e+09, train_seconds = 1511.8)
[2022-05-31 14:35:38,104][root][INFO] - Step 10068480 @ 6647.9 SPS. Inference batcher size: 107. Learner queue size: 18. Other stats: (step = 10068480, mean_episode_return = 64.33, mean_episode_step = 1196.8, total_loss = 701.5, pg_loss = 431.52, baseline_loss = 275.36, entropy_loss = -5.3784, learner_queue_size = 21, _tick = 2307, _time = 1.654e+09, train_seconds = 1516.8)
[2022-05-31 14:35:43,110][root][INFO] - Step 10101760 @ 6648.4 SPS. Inference batcher size: 43. Learner queue size: 16. Other stats: (step = 10101760, mean_episode_return = None, mean_episode_step = 1743.1, total_loss = -174.35, pg_loss = -203.63, baseline_loss = 34.762, entropy_loss = -5.4879, learner_queue_size = 18, _tick = 2314, _time = 1.654e+09, train_seconds = 1521.8)
[2022-05-31 14:35:48,114][root][INFO] - Step 10135040 @ 6650.6 SPS. Inference batcher size: 178. Learner queue size: 14. Other stats: (step = 10135040, mean_episode_return = 31.26, mean_episode_step = 1090.5, total_loss = 431.84, pg_loss = 243.28, baseline_loss = 193.96, entropy_loss = -5.3907, learner_queue_size = 16, _tick = 2325, _time = 1.654e+09, train_seconds = 1526.8)
[2022-05-31 14:35:53,120][root][INFO] - Step 10168320 @ 6648.5 SPS. Inference batcher size: 132. Learner queue size: 21. Other stats: (step = 10168320, mean_episode_return = 59.521, mean_episode_step = 1137.9, total_loss = 74.755, pg_loss = -132.02, baseline_loss = 212.24, entropy_loss = -5.4698, learner_queue_size = 18, _tick = 2333, _time = 1.654e+09, train_seconds = 1531.8)
[2022-05-31 14:35:58,122][root][INFO] - Step 10201600 @ 6652.9 SPS. Inference batcher size: 117. Learner queue size: 13. Other stats: (step = 10201600, mean_episode_return = 12.7, mean_episode_step = 1679.7, total_loss = -751.7, pg_loss = -875.61, baseline_loss = 129.48, entropy_loss = -5.5759, learner_queue_size = 25, _tick = 2340, _time = 1.654e+09, train_seconds = 1536.8)
[2022-05-31 14:36:03,126][root][INFO] - Step 10234880 @ 6650.7 SPS. Inference batcher size: 113. Learner queue size: 9. Other stats: (step = 10234880, mean_episode_return = 50.425, mean_episode_step = 1208.1, total_loss = 764.84, pg_loss = 372.03, baseline_loss = 398.37, entropy_loss = -5.555, learner_queue_size = 20, _tick = 2351, _time = 1.654e+09, train_seconds = 1541.8)
[2022-05-31 14:36:08,130][root][INFO] - Step 10268160 @ 6650.7 SPS. Inference batcher size: 182. Learner queue size: 6. Other stats: (step = 10268160, mean_episode_return = 86.275, mean_episode_step = 1097.6, total_loss = -343.94, pg_loss = -488.1, baseline_loss = 149.79, entropy_loss = -5.6237, learner_queue_size = 23, _tick = 2361, _time = 1.654e+09, train_seconds = 1546.8)
[2022-05-31 14:36:13,134][root][INFO] - Step 10301440 @ 6650.5 SPS. Inference batcher size: 142. Learner queue size: 13. Other stats: (step = 10301440, mean_episode_return = None, mean_episode_step = 1273.4, total_loss = -32.035, pg_loss = -127.66, baseline_loss = 101.05, entropy_loss = -5.4203, learner_queue_size = 19, _tick = 2368, _time = 1.654e+09, train_seconds = 1551.8)
[2022-05-31 14:36:18,140][root][INFO] - Step 10334720 @ 6648.3 SPS. Inference batcher size: 52. Learner queue size: 1. Other stats: (step = 10334720, mean_episode_return = 71.828, mean_episode_step = 1459.0, total_loss = 136.03, pg_loss = -261.53, baseline_loss = 403.07, entropy_loss = -5.5191, learner_queue_size = 15, _tick = 2378, _time = 1.654e+09, train_seconds = 1556.8)
[2022-05-31 14:36:23,146][root][INFO] - Step 10368000 @ 6647.5 SPS. Inference batcher size: 89. Learner queue size: 8. Other stats: (step = 10368000, mean_episode_return = None, mean_episode_step = 1296.1, total_loss = 447.92, pg_loss = 232.69, baseline_loss = 220.79, entropy_loss = -5.5592, learner_queue_size = 14, _tick = 2385, _time = 1.654e+09, train_seconds = 1561.8)
[2022-05-31 14:36:28,150][root][INFO] - Step 10401280 @ 6650.9 SPS. Inference batcher size: 87. Learner queue size: 18. Other stats: (step = 10401280, mean_episode_return = None, mean_episode_step = 1659.8, total_loss = -69.428, pg_loss = -128.96, baseline_loss = 65.054, entropy_loss = -5.5258, learner_queue_size = 29, _tick = 2393, _time = 1.654e+09, train_seconds = 1566.8)
[2022-05-31 14:36:33,154][root][INFO] - Step 10434560 @ 6650.7 SPS. Inference batcher size: 102. Learner queue size: 19. Other stats: (step = 10434560, mean_episode_return = 19.46, mean_episode_step = 1572.6, total_loss = 247.67, pg_loss = 76.753, baseline_loss = 176.56, entropy_loss = -5.6459, learner_queue_size = 19, _tick = 2398, _time = 1.654e+09, train_seconds = 1571.8)
[2022-05-31 14:36:38,160][root][INFO] - Step 10467840 @ 6647.9 SPS. Inference batcher size: 120. Learner queue size: 7. Other stats: (step = 10467840, mean_episode_return = None, mean_episode_step = 1758.8, total_loss = -303.73, pg_loss = -316.52, baseline_loss = 18.578, entropy_loss = -5.7877, learner_queue_size = 15, _tick = 2407, _time = 1.654e+09, train_seconds = 1576.8)
[2022-05-31 14:36:43,166][root][INFO] - Step 10501120 @ 6648.0 SPS. Inference batcher size: 132. Learner queue size: 17. Other stats: (step = 10501120, mean_episode_return = 3.8497, mean_episode_step = 1627.3, total_loss = 72.177, pg_loss = -91.214, baseline_loss = 169.12, entropy_loss = -5.7238, learner_queue_size = 25, _tick = 2418, _time = 1.654e+09, train_seconds = 1581.9)
[2022-05-31 14:36:48,170][root][INFO] - Step 10534400 @ 6651.4 SPS. Inference batcher size: 120. Learner queue size: 11. Other stats: (step = 10534400, mean_episode_return = 29.082, mean_episode_step = 1294.3, total_loss = 498.28, pg_loss = 235.36, baseline_loss = 268.7, entropy_loss = -5.7751, learner_queue_size = 22, _tick = 2427, _time = 1.654e+09, train_seconds = 1586.9)
[2022-05-31 14:36:53,174][root][INFO] - Step 10567680 @ 6650.2 SPS. Inference batcher size: 156. Learner queue size: 16. Other stats: (step = 10567680, mean_episode_return = None, mean_episode_step = 1464.2, total_loss = 86.011, pg_loss = 1.0704, baseline_loss = 90.592, entropy_loss = -5.652, learner_queue_size = 19, _tick = 2432, _time = 1.654e+09, train_seconds = 1591.9)
[2022-05-31 14:36:58,178][root][INFO] - Step 10600960 @ 6650.7 SPS. Inference batcher size: 145. Learner queue size: 18. Other stats: (step = 10600960, mean_episode_return = None, mean_episode_step = 1384.5, total_loss = -242.75, pg_loss = -269.06, baseline_loss = 31.872, entropy_loss = -5.5556, learner_queue_size = 23, _tick = 2441, _time = 1.654e+09, train_seconds = 1596.9)
[2022-05-31 14:37:03,182][root][INFO] - Step 10634240 @ 6650.5 SPS. Inference batcher size: 31. Learner queue size: 8. Other stats: (step = 10634240, mean_episode_return = None, mean_episode_step = 1210.7, total_loss = 137.83, pg_loss = 50.254, baseline_loss = 93.363, entropy_loss = -5.7905, learner_queue_size = 22, _tick = 2447, _time = 1.654e+09, train_seconds = 1601.9)
[2022-05-31 14:37:08,186][root][INFO] - Step 10667520 @ 6650.7 SPS. Inference batcher size: 135. Learner queue size: 14. Other stats: (step = 10667520, mean_episode_return = 158.67, mean_episode_step = 1688.4, total_loss = 925.74, pg_loss = 562.46, baseline_loss = 368.95, entropy_loss = -5.6718, learner_queue_size = 16, _tick = 2457, _time = 1.654e+09, train_seconds = 1606.9)
[2022-05-31 14:37:13,190][root][INFO] - Step 10700800 @ 6650.5 SPS. Inference batcher size: 140. Learner queue size: 9. Other stats: (step = 10700800, mean_episode_return = 105.53, mean_episode_step = 1165.5, total_loss = -516.97, pg_loss = -548.65, baseline_loss = 37.197, entropy_loss = -5.5121, learner_queue_size = 23, _tick = 2466, _time = 1.654e+09, train_seconds = 1611.9)
[2022-05-31 14:37:18,192][root][INFO] - Step 10734080 @ 6653.6 SPS. Inference batcher size: 100. Learner queue size: 3. Other stats: (step = 10734080, mean_episode_return = None, mean_episode_step = 1576.6, total_loss = 50.74, pg_loss = -55.596, baseline_loss = 111.89, entropy_loss = -5.553, learner_queue_size = 11, _tick = 2474, _time = 1.654e+09, train_seconds = 1616.9)
[2022-05-31 14:37:23,198][root][INFO] - Step 10767360 @ 6648.1 SPS. Inference batcher size: 111. Learner queue size: 1. Other stats: (step = 10767360, mean_episode_return = 29.267, mean_episode_step = 1658.5, total_loss = -397.29, pg_loss = -467.79, baseline_loss = 76.101, entropy_loss = -5.5999, learner_queue_size = 21, _tick = 2483, _time = 1.654e+09, train_seconds = 1621.9)
[2022-05-31 14:37:28,204][root][INFO] - Step 10798080 @ 6136.7 SPS. Inference batcher size: 77. Learner queue size: 19. Other stats: (step = 10798080, mean_episode_return = 162.44, mean_episode_step = 1594.4, total_loss = 129.34, pg_loss = -6.4266, baseline_loss = 141.34, entropy_loss = -5.5753, learner_queue_size = 17, _tick = 2489, _time = 1.654e+09, train_seconds = 1626.9)
[2022-05-31 14:37:33,210][root][INFO] - Step 10831360 @ 6648.0 SPS. Inference batcher size: 122. Learner queue size: 8. Other stats: (step = 10831360, mean_episode_return = 40.74, mean_episode_step = 1814.4, total_loss = -201.95, pg_loss = -339.39, baseline_loss = 142.78, entropy_loss = -5.34, learner_queue_size = 9, _tick = 2499, _time = 1.654e+09, train_seconds = 1631.9)
[2022-05-31 14:37:38,216][root][INFO] - Step 10864640 @ 6648.0 SPS. Inference batcher size: 71. Learner queue size: 8. Other stats: (step = 10864640, mean_episode_return = 40.975, mean_episode_step = 1260.3, total_loss = -133.02, pg_loss = -202.72, baseline_loss = 75.174, entropy_loss = -5.4742, learner_queue_size = 15, _tick = 2509, _time = 1.654e+09, train_seconds = 1636.9)
[2022-05-31 14:37:43,222][root][INFO] - Step 10897920 @ 6647.8 SPS. Inference batcher size: 123. Learner queue size: 5. Other stats: (step = 10897920, mean_episode_return = 72.463, mean_episode_step = 1370.1, total_loss = -461.17, pg_loss = -504.03, baseline_loss = 48.422, entropy_loss = -5.5686, learner_queue_size = 17, _tick = 2518, _time = 1.654e+09, train_seconds = 1641.9)
[2022-05-31 14:37:48,228][root][INFO] - Step 10931200 @ 6648.0 SPS. Inference batcher size: 105. Learner queue size: 8. Other stats: (step = 10931200, mean_episode_return = 98.719, mean_episode_step = 1315.5, total_loss = -315.63, pg_loss = -480.72, baseline_loss = 170.57, entropy_loss = -5.487, learner_queue_size = 20, _tick = 2523, _time = 1.654e+09, train_seconds = 1646.9)
[2022-05-31 14:37:53,234][root][INFO] - Step 10964480 @ 6648.3 SPS. Inference batcher size: 69. Learner queue size: 3. Other stats: (step = 10964480, mean_episode_return = None, mean_episode_step = 1304.0, total_loss = 419.44, pg_loss = 205.9, baseline_loss = 218.85, entropy_loss = -5.3107, learner_queue_size = 19, _tick = 2533, _time = 1.654e+09, train_seconds = 1651.9)
[2022-05-31 14:37:58,238][root][INFO] - Step 10997760 @ 6650.6 SPS. Inference batcher size: 134. Learner queue size: 28. Other stats: (step = 10997760, mean_episode_return = 62.509, mean_episode_step = 1395.7, total_loss = 164.39, pg_loss = 2.4688, baseline_loss = 167.08, entropy_loss = -5.1517, learner_queue_size = 20, _tick = 2541, _time = 1.654e+09, train_seconds = 1656.9)
[2022-05-31 14:38:03,242][root][INFO] - Step 11031040 @ 6650.7 SPS. Inference batcher size: 137. Learner queue size: 5. Other stats: (step = 11031040, mean_episode_return = 17.42, mean_episode_step = 1305.0, total_loss = 959.46, pg_loss = 576.13, baseline_loss = 388.63, entropy_loss = -5.2937, learner_queue_size = 24, _tick = 2552, _time = 1.654e+09, train_seconds = 1661.9)
[2022-05-31 14:38:08,246][root][INFO] - Step 11061760 @ 6139.0 SPS. Inference batcher size: 106. Learner queue size: 17. Other stats: (step = 11061760, mean_episode_return = 87.206, mean_episode_step = 1320.9, total_loss = -195.27, pg_loss = -388.01, baseline_loss = 197.99, entropy_loss = -5.2555, learner_queue_size = 20, _tick = 2561, _time = 1.654e+09, train_seconds = 1666.9)
[2022-05-31 14:38:13,250][root][INFO] - Step 11095040 @ 6650.8 SPS. Inference batcher size: 171. Learner queue size: 18. Other stats: (step = 11095040, mean_episode_return = None, mean_episode_step = 1398.4, total_loss = 335.05, pg_loss = 156.78, baseline_loss = 183.49, entropy_loss = -5.2157, learner_queue_size = 24, _tick = 2570, _time = 1.654e+09, train_seconds = 1671.9)
[2022-05-31 14:38:18,254][root][INFO] - Step 11128320 @ 6650.5 SPS. Inference batcher size: 71. Learner queue size: 16. Other stats: (step = 11128320, mean_episode_return = 33.431, mean_episode_step = 1607.4, total_loss = -5.1459, pg_loss = -161.73, baseline_loss = 161.86, entropy_loss = -5.2695, learner_queue_size = 16, _tick = 2579, _time = 1.654e+09, train_seconds = 1676.9)
[2022-05-31 14:38:23,258][root][INFO] - Step 11161600 @ 6650.8 SPS. Inference batcher size: 117. Learner queue size: 14. Other stats: (step = 11161600, mean_episode_return = None, mean_episode_step = 987.09, total_loss = 279.26, pg_loss = 130.63, baseline_loss = 153.85, entropy_loss = -5.2196, learner_queue_size = 13, _tick = 2589, _time = 1.654e+09, train_seconds = 1681.9)
[2022-05-31 14:38:28,264][root][INFO] - Step 11194880 @ 6648.0 SPS. Inference batcher size: 97. Learner queue size: 14. Other stats: (step = 11194880, mean_episode_return = None, mean_episode_step = 1496.9, total_loss = -285.17, pg_loss = -326.48, baseline_loss = 46.515, entropy_loss = -5.1987, learner_queue_size = 22, _tick = 2598, _time = 1.654e+09, train_seconds = 1686.9)
[2022-05-31 14:38:33,270][root][INFO] - Step 11228160 @ 6648.1 SPS. Inference batcher size: 120. Learner queue size: 12. Other stats: (step = 11228160, mean_episode_return = None, mean_episode_step = 1367.3, total_loss = 592.55, pg_loss = 395.57, baseline_loss = 202.21, entropy_loss = -5.2312, learner_queue_size = 13, _tick = 2607, _time = 1.654e+09, train_seconds = 1692.0)
[2022-05-31 14:38:38,274][root][INFO] - Step 11261440 @ 6650.7 SPS. Inference batcher size: 155. Learner queue size: 14. Other stats: (step = 11261440, mean_episode_return = 135.21, mean_episode_step = 1462.1, total_loss = -108.72, pg_loss = -170.5, baseline_loss = 66.883, entropy_loss = -5.0956, learner_queue_size = 17, _tick = 2616, _time = 1.654e+09, train_seconds = 1697.0)
[2022-05-31 14:38:43,278][root][INFO] - Step 11294720 @ 6650.6 SPS. Inference batcher size: 100. Learner queue size: 9. Other stats: (step = 11294720, mean_episode_return = 30.31, mean_episode_step = 1413.8, total_loss = 512.93, pg_loss = 238.99, baseline_loss = 279.41, entropy_loss = -5.4698, learner_queue_size = 17, _tick = 2623, _time = 1.654e+09, train_seconds = 1702.0)
[2022-05-31 14:38:48,282][root][INFO] - Step 11328000 @ 6650.8 SPS. Inference batcher size: 58. Learner queue size: 7. Other stats: (step = 11328000, mean_episode_return = 48.303, mean_episode_step = 1316.5, total_loss = -280.6, pg_loss = -319.25, baseline_loss = 44.321, entropy_loss = -5.6713, learner_queue_size = 20, _tick = 2627, _time = 1.654e+09, train_seconds = 1707.0)
[2022-05-31 14:38:53,286][root][INFO] - Step 11361280 @ 6650.7 SPS. Inference batcher size: 52. Learner queue size: 15. Other stats: (step = 11361280, mean_episode_return = 73.035, mean_episode_step = 1515.2, total_loss = 783.3, pg_loss = 298.69, baseline_loss = 490.27, entropy_loss = -5.6511, learner_queue_size = 24, _tick = 2636, _time = 1.654e+09, train_seconds = 1712.0)
[2022-05-31 14:38:58,292][root][INFO] - Step 11394560 @ 6647.6 SPS. Inference batcher size: 125. Learner queue size: 3. Other stats: (step = 11394560, mean_episode_return = 20.05, mean_episode_step = 1430.6, total_loss = -6.7397, pg_loss = -51.259, baseline_loss = 50.231, entropy_loss = -5.7114, learner_queue_size = 23, _tick = 2646, _time = 1.654e+09, train_seconds = 1717.0)
[2022-05-31 14:39:03,298][root][INFO] - Step 11427840 @ 6648.1 SPS. Inference batcher size: 127. Learner queue size: 4. Other stats: (step = 11427840, mean_episode_return = None, mean_episode_step = 1502.1, total_loss = -136.02, pg_loss = -197.26, baseline_loss = 66.992, entropy_loss = -5.7531, learner_queue_size = 23, _tick = 2656, _time = 1.654e+09, train_seconds = 1722.0)
[2022-05-31 14:39:08,302][root][INFO] - Step 11461120 @ 6650.8 SPS. Inference batcher size: 77. Learner queue size: 27. Other stats: (step = 11461120, mean_episode_return = None, mean_episode_step = 1115.8, total_loss = 177.59, pg_loss = 24.601, baseline_loss = 158.63, entropy_loss = -5.641, learner_queue_size = 18, _tick = 2666, _time = 1.654e+09, train_seconds = 1727.0)
[2022-05-31 14:39:13,309][root][INFO] - Step 11491840 @ 6135.3 SPS. Inference batcher size: 116. Learner queue size: 16. Other stats: (step = 11491840, mean_episode_return = 73.28, mean_episode_step = 1168.6, total_loss = -66.107, pg_loss = -159.54, baseline_loss = 99.033, entropy_loss = -5.5979, learner_queue_size = 20, _tick = 2677, _time = 1.654e+09, train_seconds = 1732.0)
[2022-05-31 14:39:18,315][root][INFO] - Step 11525120 @ 6648.1 SPS. Inference batcher size: 123. Learner queue size: 10. Other stats: (step = 11525120, mean_episode_return = 26.11, mean_episode_step = 1125.2, total_loss = -21.392, pg_loss = -87.946, baseline_loss = 72.014, entropy_loss = -5.4599, learner_queue_size = 27, _tick = 2685, _time = 1.654e+09, train_seconds = 1737.0)
[2022-05-31 14:39:23,321][root][INFO] - Step 11558400 @ 6648.1 SPS. Inference batcher size: 114. Learner queue size: 19. Other stats: (step = 11558400, mean_episode_return = None, mean_episode_step = 1060.5, total_loss = -87.736, pg_loss = -155.16, baseline_loss = 72.947, entropy_loss = -5.5229, learner_queue_size = 16, _tick = 2692, _time = 1.654e+09, train_seconds = 1742.0)
[2022-05-31 14:39:28,327][root][INFO] - Step 11591680 @ 6648.2 SPS. Inference batcher size: 123. Learner queue size: 13. Other stats: (step = 11591680, mean_episode_return = None, mean_episode_step = 1366.0, total_loss = 390.2, pg_loss = 227.05, baseline_loss = 168.83, entropy_loss = -5.678, learner_queue_size = 17, _tick = 2700, _time = 1.654e+09, train_seconds = 1747.0)
[2022-05-31 14:39:33,330][root][INFO] - Step 11624960 @ 6651.9 SPS. Inference batcher size: 77. Learner queue size: 5. Other stats: (step = 11624960, mean_episode_return = 7.3797, mean_episode_step = 1156.0, total_loss = 58.114, pg_loss = -101.28, baseline_loss = 165.0, entropy_loss = -5.5988, learner_queue_size = 28, _tick = 2710, _time = 1.654e+09, train_seconds = 1752.0)
[2022-05-31 14:39:38,334][root][INFO] - Step 11658240 @ 6650.8 SPS. Inference batcher size: 81. Learner queue size: 3. Other stats: (step = 11658240, mean_episode_return = None, mean_episode_step = 1292.9, total_loss = 438.72, pg_loss = 305.42, baseline_loss = 138.78, entropy_loss = -5.4872, learner_queue_size = 18, _tick = 2715, _time = 1.654e+09, train_seconds = 1757.0)
[2022-05-31 14:39:43,338][root][INFO] - Step 11691520 @ 6650.7 SPS. Inference batcher size: 125. Learner queue size: 6. Other stats: (step = 11691520, mean_episode_return = 59.513, mean_episode_step = 1356.6, total_loss = -280.69, pg_loss = -371.54, baseline_loss = 96.59, entropy_loss = -5.7412, learner_queue_size = 14, _tick = 2727, _time = 1.654e+09, train_seconds = 1762.0)
[2022-05-31 14:39:48,342][root][INFO] - Step 11722240 @ 6139.0 SPS. Inference batcher size: 150. Learner queue size: 24. Other stats: (step = 11722240, mean_episode_return = None, mean_episode_step = 1278.1, total_loss = 437.58, pg_loss = 281.07, baseline_loss = 162.17, entropy_loss = -5.6511, learner_queue_size = 15, _tick = 2737, _time = 1.654e+09, train_seconds = 1767.0)
[2022-05-31 14:39:53,348][root][INFO] - Step 11755520 @ 6647.9 SPS. Inference batcher size: 147. Learner queue size: 23. Other stats: (step = 11755520, mean_episode_return = 29.36, mean_episode_step = 1288.8, total_loss = -252.44, pg_loss = -316.46, baseline_loss = 69.722, entropy_loss = -5.7086, learner_queue_size = 18, _tick = 2748, _time = 1.654e+09, train_seconds = 1772.0)
[2022-05-31 14:39:58,354][root][INFO] - Step 11788800 @ 6648.5 SPS. Inference batcher size: 149. Learner queue size: 16. Other stats: (step = 11788800, mean_episode_return = 11.84, mean_episode_step = 1343.8, total_loss = -393.65, pg_loss = -485.2, baseline_loss = 97.377, entropy_loss = -5.8213, learner_queue_size = 23, _tick = 2760, _time = 1.654e+09, train_seconds = 1777.0)
[2022-05-31 14:40:03,360][root][INFO] - Step 11822080 @ 6648.0 SPS. Inference batcher size: 103. Learner queue size: 14. Other stats: (step = 11822080, mean_episode_return = 43.105, mean_episode_step = 1042.6, total_loss = 4.3854e+04, pg_loss = 4084.4, baseline_loss = 3.9775e+04, entropy_loss = -5.5881, learner_queue_size = 21, _tick = 2769, _time = 1.654e+09, train_seconds = 1782.0)
[2022-05-31 14:40:08,366][root][INFO] - Step 11857920 @ 7159.4 SPS. Inference batcher size: 110. Learner queue size: 27. Other stats: (step = 11857920, mean_episode_return = 114.34, mean_episode_step = 1159.6, total_loss = -215.59, pg_loss = -322.04, baseline_loss = 112.21, entropy_loss = -5.758, learner_queue_size = 19, _tick = 2780, _time = 1.654e+09, train_seconds = 1787.1)
[2022-05-31 14:40:13,372][root][INFO] - Step 11888640 @ 6136.6 SPS. Inference batcher size: 112. Learner queue size: 8. Other stats: (step = 11888640, mean_episode_return = 96.197, mean_episode_step = 1209.6, total_loss = -76.365, pg_loss = -147.3, baseline_loss = 76.634, entropy_loss = -5.7028, learner_queue_size = 15, _tick = 2791, _time = 1.654e+09, train_seconds = 1792.1)
[2022-05-31 14:40:18,374][root][INFO] - Step 11921920 @ 6653.1 SPS. Inference batcher size: 126. Learner queue size: 20. Other stats: (step = 11921920, mean_episode_return = None, mean_episode_step = 1031.6, total_loss = -251.53, pg_loss = -267.41, baseline_loss = 21.645, entropy_loss = -5.7595, learner_queue_size = 18, _tick = 2799, _time = 1.654e+09, train_seconds = 1797.1)
[2022-05-31 14:40:23,378][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 14:40:23,568][root][INFO] - Step 11955200 @ 6650.7 SPS. Inference batcher size: 29. Learner queue size: 17. Other stats: (step = 11957760, mean_episode_return = 21.884, mean_episode_step = 1251.5, total_loss = 186.08, pg_loss = 58.85, baseline_loss = 133.0, entropy_loss = -5.7686, learner_queue_size = 16, _tick = 2811, _time = 1.654e+09, train_seconds = 1802.1)
[2022-05-31 14:40:28,574][root][INFO] - Step 11988480 @ 6405.3 SPS. Inference batcher size: 109. Learner queue size: 19. Other stats: (step = 11988480, mean_episode_return = 93.831, mean_episode_step = 1185.0, total_loss = 1225.0, pg_loss = 825.56, baseline_loss = 405.2, entropy_loss = -5.813, learner_queue_size = 13, _tick = 2821, _time = 1.654e+09, train_seconds = 1807.3)
[2022-05-31 14:40:33,578][root][INFO] - Step 12024320 @ 7161.9 SPS. Inference batcher size: 158. Learner queue size: 26. Other stats: (step = 12024320, mean_episode_return = 81.159, mean_episode_step = 978.29, total_loss = 643.98, pg_loss = 312.69, baseline_loss = 337.0, entropy_loss = -5.7037, learner_queue_size = 19, _tick = 2832, _time = 1.654e+09, train_seconds = 1812.3)
[2022-05-31 14:40:38,584][root][INFO] - Step 12055040 @ 6136.2 SPS. Inference batcher size: 75. Learner queue size: 20. Other stats: (step = 12055040, mean_episode_return = None, mean_episode_step = 1164.8, total_loss = -115.0, pg_loss = -221.0, baseline_loss = 111.75, entropy_loss = -5.751, learner_queue_size = 17, _tick = 2842, _time = 1.654e+09, train_seconds = 1817.3)
[2022-05-31 14:40:43,590][root][INFO] - Step 12088320 @ 6648.5 SPS. Inference batcher size: 32. Learner queue size: 11. Other stats: (step = 12088320, mean_episode_return = 115.63, mean_episode_step = 1164.0, total_loss = 164.94, pg_loss = 69.307, baseline_loss = 101.41, entropy_loss = -5.7754, learner_queue_size = 12, _tick = 2853, _time = 1.654e+09, train_seconds = 1822.3)
[2022-05-31 14:40:48,594][root][INFO] - Step 12121600 @ 6650.1 SPS. Inference batcher size: 82. Learner queue size: 8. Other stats: (step = 12121600, mean_episode_return = 38.95, mean_episode_step = 1219.4, total_loss = -16.01, pg_loss = -58.544, baseline_loss = 48.291, entropy_loss = -5.7568, learner_queue_size = 14, _tick = 2862, _time = 1.654e+09, train_seconds = 1827.3)
[2022-05-31 14:40:53,598][root][INFO] - Step 12154880 @ 6651.3 SPS. Inference batcher size: 39. Learner queue size: 2. Other stats: (step = 12154880, mean_episode_return = 17.02, mean_episode_step = 989.7, total_loss = 467.38, pg_loss = 259.61, baseline_loss = 213.54, entropy_loss = -5.7725, learner_queue_size = 26, _tick = 2874, _time = 1.654e+09, train_seconds = 1832.3)
[2022-05-31 14:40:58,602][root][INFO] - Step 12188160 @ 6650.6 SPS. Inference batcher size: 129. Learner queue size: 2. Other stats: (step = 12188160, mean_episode_return = -8.1802, mean_episode_step = 1095.2, total_loss = 28.607, pg_loss = -34.316, baseline_loss = 68.777, entropy_loss = -5.8532, learner_queue_size = 25, _tick = 2882, _time = 1.654e+09, train_seconds = 1837.3)
[2022-05-31 14:41:03,606][root][INFO] - Step 12221440 @ 6650.6 SPS. Inference batcher size: 117. Learner queue size: 0. Other stats: (step = 12221440, mean_episode_return = 2.37, mean_episode_step = 855.71, total_loss = 580.6, pg_loss = 240.23, baseline_loss = 346.09, entropy_loss = -5.7188, learner_queue_size = 23, _tick = 2892, _time = 1.654e+09, train_seconds = 1842.3)
[2022-05-31 14:41:08,610][root][INFO] - Step 12252160 @ 6139.2 SPS. Inference batcher size: 106. Learner queue size: 20. Other stats: (step = 12252160, mean_episode_return = 98.528, mean_episode_step = 1061.4, total_loss = -212.16, pg_loss = -227.34, baseline_loss = 20.731, entropy_loss = -5.5547, learner_queue_size = 10, _tick = 2903, _time = 1.654e+09, train_seconds = 1847.3)
[2022-05-31 14:41:13,614][root][INFO] - Step 12288000 @ 7162.2 SPS. Inference batcher size: 8. Learner queue size: 22. Other stats: (step = 12288000, mean_episode_return = 44.621, mean_episode_step = 1003.9, total_loss = 34.422, pg_loss = -36.931, baseline_loss = 77.059, entropy_loss = -5.7061, learner_queue_size = 17, _tick = 2914, _time = 1.654e+09, train_seconds = 1852.3)
[2022-05-31 14:41:18,618][root][INFO] - Step 12321280 @ 6650.8 SPS. Inference batcher size: 83. Learner queue size: 22. Other stats: (step = 12321280, mean_episode_return = 1064.6, mean_episode_step = 1009.1, total_loss = -49.0, pg_loss = -91.966, baseline_loss = 48.758, entropy_loss = -5.7918, learner_queue_size = 20, _tick = 2925, _time = 1.654e+09, train_seconds = 1857.3)
[2022-05-31 14:41:23,622][root][INFO] - Step 12354560 @ 6650.7 SPS. Inference batcher size: 118. Learner queue size: 15. Other stats: (step = 12354560, mean_episode_return = 47.934, mean_episode_step = 999.83, total_loss = -208.11, pg_loss = -254.71, baseline_loss = 52.263, entropy_loss = -5.6702, learner_queue_size = 11, _tick = 2937, _time = 1.654e+09, train_seconds = 1862.3)
[2022-05-31 14:41:28,628][root][INFO] - Step 12385280 @ 6136.5 SPS. Inference batcher size: 98. Learner queue size: 15. Other stats: (step = 12385280, mean_episode_return = 67.899, mean_episode_step = 855.05, total_loss = 76.023, pg_loss = 4.6269, baseline_loss = 77.294, entropy_loss = -5.8977, learner_queue_size = 28, _tick = 2947, _time = 1.654e+09, train_seconds = 1867.3)
[2022-05-31 14:41:33,634][root][INFO] - Step 12418560 @ 6648.1 SPS. Inference batcher size: 32. Learner queue size: 11. Other stats: (step = 12418560, mean_episode_return = 69.915, mean_episode_step = 1203.9, total_loss = 34.62, pg_loss = -111.27, baseline_loss = 151.56, entropy_loss = -5.675, learner_queue_size = 22, _tick = 2957, _time = 1.654e+09, train_seconds = 1872.3)
[2022-05-31 14:41:38,640][root][INFO] - Step 12451840 @ 6647.3 SPS. Inference batcher size: 141. Learner queue size: 19. Other stats: (step = 12451840, mean_episode_return = 60.229, mean_episode_step = 1021.9, total_loss = -430.58, pg_loss = -540.92, baseline_loss = 115.91, entropy_loss = -5.5708, learner_queue_size = 12, _tick = 2968, _time = 1.654e+09, train_seconds = 1877.3)
[2022-05-31 14:41:43,646][root][INFO] - Step 12485120 @ 6648.6 SPS. Inference batcher size: 118. Learner queue size: 9. Other stats: (step = 12485120, mean_episode_return = 19.27, mean_episode_step = 968.13, total_loss = 494.02, pg_loss = 333.92, baseline_loss = 166.01, entropy_loss = -5.9135, learner_queue_size = 17, _tick = 2978, _time = 1.654e+09, train_seconds = 1882.3)
[2022-05-31 14:41:48,652][root][INFO] - Step 12518400 @ 6647.9 SPS. Inference batcher size: 117. Learner queue size: 4. Other stats: (step = 12518400, mean_episode_return = 18.86, mean_episode_step = 990.32, total_loss = 699.42, pg_loss = 456.87, baseline_loss = 248.57, entropy_loss = -6.0149, learner_queue_size = 13, _tick = 2989, _time = 1.654e+09, train_seconds = 1887.3)
[2022-05-31 14:41:53,658][root][INFO] - Step 12551680 @ 6648.3 SPS. Inference batcher size: 51. Learner queue size: 5. Other stats: (step = 12551680, mean_episode_return = 52.207, mean_episode_step = 1042.3, total_loss = 27.058, pg_loss = -26.864, baseline_loss = 59.803, entropy_loss = -5.8809, learner_queue_size = 18, _tick = 3001, _time = 1.654e+09, train_seconds = 1892.3)
[2022-05-31 14:41:58,662][root][INFO] - Step 12584960 @ 6650.6 SPS. Inference batcher size: 105. Learner queue size: 28. Other stats: (step = 12584960, mean_episode_return = None, mean_episode_step = 1230.0, total_loss = 519.09, pg_loss = 347.81, baseline_loss = 177.05, entropy_loss = -5.7706, learner_queue_size = 16, _tick = 3011, _time = 1.654e+09, train_seconds = 1897.3)
[2022-05-31 14:42:03,668][root][INFO] - Step 12618240 @ 6647.9 SPS. Inference batcher size: 54. Learner queue size: 1. Other stats: (step = 12618240, mean_episode_return = 48.418, mean_episode_step = 863.19, total_loss = -258.95, pg_loss = -268.55, baseline_loss = 15.388, entropy_loss = -5.7956, learner_queue_size = 20, _tick = 3021, _time = 1.654e+09, train_seconds = 1902.4)
[2022-05-31 14:42:08,674][root][INFO] - Step 12651520 @ 6648.2 SPS. Inference batcher size: 83. Learner queue size: 30. Other stats: (step = 12651520, mean_episode_return = 43.551, mean_episode_step = 962.13, total_loss = 252.14, pg_loss = 125.16, baseline_loss = 132.82, entropy_loss = -5.8415, learner_queue_size = 25, _tick = 3027, _time = 1.654e+09, train_seconds = 1907.4)
[2022-05-31 14:42:13,678][root][INFO] - Step 12682240 @ 6139.0 SPS. Inference batcher size: 40. Learner queue size: 15. Other stats: (step = 12682240, mean_episode_return = 27.265, mean_episode_step = 965.67, total_loss = -76.597, pg_loss = -141.77, baseline_loss = 71.004, entropy_loss = -5.834, learner_queue_size = 17, _tick = 3038, _time = 1.654e+09, train_seconds = 1912.4)
[2022-05-31 14:42:18,682][root][INFO] - Step 12718080 @ 7162.4 SPS. Inference batcher size: 80. Learner queue size: 26. Other stats: (step = 12718080, mean_episode_return = 18.77, mean_episode_step = 982.48, total_loss = 383.11, pg_loss = 201.94, baseline_loss = 187.13, entropy_loss = -5.9521, learner_queue_size = 23, _tick = 3049, _time = 1.654e+09, train_seconds = 1917.4)
[2022-05-31 14:42:23,686][root][INFO] - Step 12751360 @ 6650.5 SPS. Inference batcher size: 17. Learner queue size: 17. Other stats: (step = 12751360, mean_episode_return = 40.195, mean_episode_step = 1090.9, total_loss = 57.96, pg_loss = -96.958, baseline_loss = 160.78, entropy_loss = -5.8594, learner_queue_size = 10, _tick = 3061, _time = 1.654e+09, train_seconds = 1922.4)
[2022-05-31 14:42:28,692][root][INFO] - Step 12782080 @ 6136.2 SPS. Inference batcher size: 155. Learner queue size: 16. Other stats: (step = 12782080, mean_episode_return = None, mean_episode_step = 1065.6, total_loss = 528.28, pg_loss = 389.13, baseline_loss = 145.03, entropy_loss = -5.8817, learner_queue_size = 14, _tick = 3070, _time = 1.654e+09, train_seconds = 1927.4)
[2022-05-31 14:42:33,698][root][INFO] - Step 12815360 @ 6648.0 SPS. Inference batcher size: 45. Learner queue size: 14. Other stats: (step = 12815360, mean_episode_return = -1.55, mean_episode_step = 1070.9, total_loss = 264.62, pg_loss = 55.787, baseline_loss = 214.68, entropy_loss = -5.8524, learner_queue_size = 23, _tick = 3081, _time = 1.654e+09, train_seconds = 1932.4)
[2022-05-31 14:42:38,702][root][INFO] - Step 12848640 @ 6651.3 SPS. Inference batcher size: 134. Learner queue size: 17. Other stats: (step = 12848640, mean_episode_return = 35.785, mean_episode_step = 1066.2, total_loss = -178.03, pg_loss = -363.51, baseline_loss = 191.3, entropy_loss = -5.816, learner_queue_size = 23, _tick = 3092, _time = 1.654e+09, train_seconds = 1937.4)
[2022-05-31 14:42:43,708][root][INFO] - Step 12884480 @ 7159.3 SPS. Inference batcher size: 35. Learner queue size: 15. Other stats: (step = 12884480, mean_episode_return = None, mean_episode_step = 1129.6, total_loss = 396.38, pg_loss = 224.89, baseline_loss = 177.23, entropy_loss = -5.7402, learner_queue_size = 12, _tick = 3102, _time = 1.654e+09, train_seconds = 1942.4)
[2022-05-31 14:42:48,714][root][INFO] - Step 12915200 @ 6136.6 SPS. Inference batcher size: 144. Learner queue size: 21. Other stats: (step = 12915200, mean_episode_return = 67.84, mean_episode_step = 1099.2, total_loss = 48.747, pg_loss = -42.386, baseline_loss = 96.839, entropy_loss = -5.7069, learner_queue_size = 24, _tick = 3113, _time = 1.654e+09, train_seconds = 1947.4)
[2022-05-31 14:42:53,720][root][INFO] - Step 12948480 @ 6648.0 SPS. Inference batcher size: 166. Learner queue size: 18. Other stats: (step = 12948480, mean_episode_return = None, mean_episode_step = 900.12, total_loss = -104.75, pg_loss = -154.77, baseline_loss = 55.63, entropy_loss = -5.606, learner_queue_size = 12, _tick = 3120, _time = 1.654e+09, train_seconds = 1952.4)
[2022-05-31 14:42:58,726][root][INFO] - Step 12981760 @ 6648.0 SPS. Inference batcher size: 151. Learner queue size: 17. Other stats: (step = 12981760, mean_episode_return = 35.241, mean_episode_step = 1157.8, total_loss = 20.904, pg_loss = -78.534, baseline_loss = 105.13, entropy_loss = -5.6951, learner_queue_size = 21, _tick = 3129, _time = 1.654e+09, train_seconds = 1957.4)
[2022-05-31 14:43:03,732][root][INFO] - Step 13015040 @ 6648.0 SPS. Inference batcher size: 99. Learner queue size: 15. Other stats: (step = 13015040, mean_episode_return = 12.48, mean_episode_step = 1267.0, total_loss = 86.801, pg_loss = 17.925, baseline_loss = 74.462, entropy_loss = -5.5855, learner_queue_size = 17, _tick = 3139, _time = 1.654e+09, train_seconds = 1962.4)
[2022-05-31 14:43:08,738][root][INFO] - Step 13048320 @ 6648.0 SPS. Inference batcher size: 201. Learner queue size: 23. Other stats: (step = 13048320, mean_episode_return = 68.304, mean_episode_step = 1155.2, total_loss = 171.4, pg_loss = 11.178, baseline_loss = 165.7, entropy_loss = -5.4823, learner_queue_size = 16, _tick = 3149, _time = 1.654e+09, train_seconds = 1967.4)
[2022-05-31 14:43:13,744][root][INFO] - Step 13081600 @ 6648.0 SPS. Inference batcher size: 83. Learner queue size: 14. Other stats: (step = 13081600, mean_episode_return = 22.855, mean_episode_step = 1047.8, total_loss = 152.6, pg_loss = 3.809, baseline_loss = 154.39, entropy_loss = -5.5977, learner_queue_size = 15, _tick = 3161, _time = 1.654e+09, train_seconds = 1972.4)
[2022-05-31 14:43:18,751][root][INFO] - Step 13114880 @ 6647.7 SPS. Inference batcher size: 14. Learner queue size: 9. Other stats: (step = 13114880, mean_episode_return = None, mean_episode_step = 890.34, total_loss = 23.486, pg_loss = -40.608, baseline_loss = 69.734, entropy_loss = -5.6402, learner_queue_size = 28, _tick = 3168, _time = 1.654e+09, train_seconds = 1977.4)
[2022-05-31 14:43:23,754][root][INFO] - Step 13148160 @ 6651.3 SPS. Inference batcher size: 134. Learner queue size: 14. Other stats: (step = 13148160, mean_episode_return = None, mean_episode_step = 1257.9, total_loss = 440.53, pg_loss = 362.98, baseline_loss = 83.279, entropy_loss = -5.7294, learner_queue_size = 28, _tick = 3176, _time = 1.654e+09, train_seconds = 1982.4)
[2022-05-31 14:43:28,760][root][INFO] - Step 13181440 @ 6648.0 SPS. Inference batcher size: 97. Learner queue size: 6. Other stats: (step = 13181440, mean_episode_return = None, mean_episode_step = 1057.7, total_loss = 776.65, pg_loss = 580.32, baseline_loss = 202.18, entropy_loss = -5.854, learner_queue_size = 17, _tick = 3186, _time = 1.654e+09, train_seconds = 1987.4)
[2022-05-31 14:43:33,766][root][INFO] - Step 13214720 @ 6648.1 SPS. Inference batcher size: 184. Learner queue size: 17. Other stats: (step = 13214720, mean_episode_return = 111.31, mean_episode_step = 1121.4, total_loss = 145.52, pg_loss = 86.393, baseline_loss = 64.97, entropy_loss = -5.8411, learner_queue_size = 30, _tick = 3197, _time = 1.654e+09, train_seconds = 1992.5)
[2022-05-31 14:43:38,770][root][INFO] - Step 13248000 @ 6650.8 SPS. Inference batcher size: 235. Learner queue size: 12. Other stats: (step = 13248000, mean_episode_return = None, mean_episode_step = 1216.3, total_loss = 82.718, pg_loss = 4.5922, baseline_loss = 83.824, entropy_loss = -5.6978, learner_queue_size = 22, _tick = 3206, _time = 1.654e+09, train_seconds = 1997.5)
[2022-05-31 14:43:43,774][root][INFO] - Step 13281280 @ 6650.7 SPS. Inference batcher size: 157. Learner queue size: 20. Other stats: (step = 13281280, mean_episode_return = None, mean_episode_step = 1127.1, total_loss = 380.43, pg_loss = 290.73, baseline_loss = 95.349, entropy_loss = -5.6519, learner_queue_size = 17, _tick = 3216, _time = 1.654e+09, train_seconds = 2002.5)
[2022-05-31 14:43:48,778][root][INFO] - Step 13314560 @ 6650.6 SPS. Inference batcher size: 102. Learner queue size: 21. Other stats: (step = 13314560, mean_episode_return = 76.499, mean_episode_step = 1160.0, total_loss = 785.31, pg_loss = 608.41, baseline_loss = 182.58, entropy_loss = -5.6831, learner_queue_size = 18, _tick = 3227, _time = 1.654e+09, train_seconds = 2007.5)
[2022-05-31 14:43:53,782][root][INFO] - Step 13347840 @ 6650.6 SPS. Inference batcher size: 109. Learner queue size: 14. Other stats: (step = 13347840, mean_episode_return = 66.449, mean_episode_step = 1147.1, total_loss = -99.497, pg_loss = -127.0, baseline_loss = 33.263, entropy_loss = -5.7634, learner_queue_size = 9, _tick = 3239, _time = 1.654e+09, train_seconds = 2012.5)
[2022-05-31 14:43:58,788][root][INFO] - Step 13381120 @ 6648.4 SPS. Inference batcher size: 103. Learner queue size: 19. Other stats: (step = 13381120, mean_episode_return = 176.76, mean_episode_step = 1257.6, total_loss = 416.83, pg_loss = 278.99, baseline_loss = 143.72, entropy_loss = -5.8745, learner_queue_size = 20, _tick = 3249, _time = 1.654e+09, train_seconds = 2017.5)
[2022-05-31 14:44:03,794][root][INFO] - Step 13414400 @ 6648.0 SPS. Inference batcher size: 126. Learner queue size: 17. Other stats: (step = 13414400, mean_episode_return = 21.56, mean_episode_step = 1095.1, total_loss = 316.96, pg_loss = 196.21, baseline_loss = 126.66, entropy_loss = -5.9128, learner_queue_size = 18, _tick = 3258, _time = 1.654e+09, train_seconds = 2022.5)
[2022-05-31 14:44:08,799][root][INFO] - Step 13447680 @ 6649.5 SPS. Inference batcher size: 171. Learner queue size: 18. Other stats: (step = 13447680, mean_episode_return = 43.527, mean_episode_step = 1030.2, total_loss = -133.27, pg_loss = -250.58, baseline_loss = 123.18, entropy_loss = -5.874, learner_queue_size = 15, _tick = 3267, _time = 1.654e+09, train_seconds = 2027.5)
[2022-05-31 14:44:13,802][root][INFO] - Step 13480960 @ 6651.6 SPS. Inference batcher size: 52. Learner queue size: 16. Other stats: (step = 13480960, mean_episode_return = None, mean_episode_step = 1413.7, total_loss = 624.94, pg_loss = 446.96, baseline_loss = 183.98, entropy_loss = -5.9941, learner_queue_size = 16, _tick = 3274, _time = 1.654e+09, train_seconds = 2032.5)
[2022-05-31 14:44:18,808][root][INFO] - Step 13514240 @ 6647.6 SPS. Inference batcher size: 85. Learner queue size: 5. Other stats: (step = 13514240, mean_episode_return = 69.015, mean_episode_step = 1006.5, total_loss = 621.12, pg_loss = 438.22, baseline_loss = 188.77, entropy_loss = -5.8631, learner_queue_size = 13, _tick = 3285, _time = 1.654e+09, train_seconds = 2037.5)
[2022-05-31 14:44:23,814][root][INFO] - Step 13547520 @ 6648.5 SPS. Inference batcher size: 103. Learner queue size: 6. Other stats: (step = 13547520, mean_episode_return = None, mean_episode_step = 1257.9, total_loss = -90.922, pg_loss = -126.03, baseline_loss = 41.039, entropy_loss = -5.9284, learner_queue_size = 24, _tick = 3295, _time = 1.654e+09, train_seconds = 2042.5)
[2022-05-31 14:44:28,820][root][INFO] - Step 13580800 @ 6647.9 SPS. Inference batcher size: 113. Learner queue size: 2. Other stats: (step = 13580800, mean_episode_return = 47.197, mean_episode_step = 1370.7, total_loss = -112.84, pg_loss = -212.11, baseline_loss = 105.3, entropy_loss = -6.0342, learner_queue_size = 11, _tick = 3302, _time = 1.654e+09, train_seconds = 2047.5)
[2022-05-31 14:44:33,826][root][INFO] - Step 13614080 @ 6648.0 SPS. Inference batcher size: 88. Learner queue size: 3. Other stats: (step = 13614080, mean_episode_return = 132.01, mean_episode_step = 1185.4, total_loss = 937.0, pg_loss = 628.93, baseline_loss = 314.04, entropy_loss = -5.9714, learner_queue_size = 12, _tick = 3307, _time = 1.654e+09, train_seconds = 2052.5)
[2022-05-31 14:44:38,830][root][INFO] - Step 13647360 @ 6650.8 SPS. Inference batcher size: 80. Learner queue size: 4. Other stats: (step = 13647360, mean_episode_return = 57.887, mean_episode_step = 1185.4, total_loss = 275.23, pg_loss = 135.25, baseline_loss = 146.0, entropy_loss = -6.0176, learner_queue_size = 23, _tick = 3315, _time = 1.654e+09, train_seconds = 2057.5)
[2022-05-31 14:44:43,834][root][INFO] - Step 13680640 @ 6650.7 SPS. Inference batcher size: 159. Learner queue size: 4. Other stats: (step = 13680640, mean_episode_return = 58.521, mean_episode_step = 1135.1, total_loss = -201.28, pg_loss = -265.67, baseline_loss = 69.771, entropy_loss = -5.3848, learner_queue_size = 30, _tick = 3320, _time = 1.654e+09, train_seconds = 2062.5)
[2022-05-31 14:44:48,838][root][INFO] - Step 13713920 @ 6650.6 SPS. Inference batcher size: 58. Learner queue size: 3. Other stats: (step = 13713920, mean_episode_return = 72.707, mean_episode_step = 1104.9, total_loss = 616.31, pg_loss = 393.02, baseline_loss = 229.23, entropy_loss = -5.9285, learner_queue_size = 24, _tick = 3332, _time = 1.654e+09, train_seconds = 2067.5)
[2022-05-31 14:44:53,843][root][INFO] - Step 13747200 @ 6650.2 SPS. Inference batcher size: 16. Learner queue size: 27. Other stats: (step = 13747200, mean_episode_return = 55.101, mean_episode_step = 1132.5, total_loss = 130.0, pg_loss = 6.4147, baseline_loss = 129.35, entropy_loss = -5.7615, learner_queue_size = 13, _tick = 3341, _time = 1.654e+09, train_seconds = 2072.5)
[2022-05-31 14:44:58,846][root][INFO] - Step 13780480 @ 6651.2 SPS. Inference batcher size: 98. Learner queue size: 30. Other stats: (step = 13780480, mean_episode_return = 81.558, mean_episode_step = 1353.9, total_loss = -2.4393, pg_loss = -76.888, baseline_loss = 80.396, entropy_loss = -5.9465, learner_queue_size = 12, _tick = 3353, _time = 1.654e+09, train_seconds = 2077.5)
[2022-05-31 14:45:03,850][root][INFO] - Step 13813760 @ 6650.7 SPS. Inference batcher size: 83. Learner queue size: 21. Other stats: (step = 13813760, mean_episode_return = 49.69, mean_episode_step = 1148.4, total_loss = 430.11, pg_loss = 219.85, baseline_loss = 215.97, entropy_loss = -5.7117, learner_queue_size = 12, _tick = 3361, _time = 1.654e+09, train_seconds = 2082.5)
[2022-05-31 14:45:08,854][root][INFO] - Step 13847040 @ 6650.7 SPS. Inference batcher size: 118. Learner queue size: 28. Other stats: (step = 13847040, mean_episode_return = 91.681, mean_episode_step = 1001.3, total_loss = 5.5893, pg_loss = -31.503, baseline_loss = 42.864, entropy_loss = -5.7716, learner_queue_size = 17, _tick = 3370, _time = 1.654e+09, train_seconds = 2087.5)
[2022-05-31 14:45:13,858][root][INFO] - Step 13880320 @ 6650.8 SPS. Inference batcher size: 92. Learner queue size: 18. Other stats: (step = 13880320, mean_episode_return = 95.223, mean_episode_step = 1016.8, total_loss = 253.15, pg_loss = 131.15, baseline_loss = 127.91, entropy_loss = -5.9146, learner_queue_size = 14, _tick = 3380, _time = 1.654e+09, train_seconds = 2092.5)
[2022-05-31 14:45:18,864][root][INFO] - Step 13911040 @ 6136.4 SPS. Inference batcher size: 76. Learner queue size: 22. Other stats: (step = 13911040, mean_episode_return = 25.384, mean_episode_step = 1325.0, total_loss = 701.08, pg_loss = 551.42, baseline_loss = 155.59, entropy_loss = -5.9347, learner_queue_size = 18, _tick = 3389, _time = 1.654e+09, train_seconds = 2097.5)
[2022-05-31 14:45:23,870][root][INFO] - Step 13944320 @ 6648.0 SPS. Inference batcher size: 117. Learner queue size: 12. Other stats: (step = 13944320, mean_episode_return = None, mean_episode_step = 1109.1, total_loss = -93.086, pg_loss = -115.3, baseline_loss = 27.656, entropy_loss = -5.4388, learner_queue_size = 20, _tick = 3398, _time = 1.654e+09, train_seconds = 2102.6)
[2022-05-31 14:45:28,876][root][INFO] - Step 13977600 @ 6647.9 SPS. Inference batcher size: 86. Learner queue size: 16. Other stats: (step = 13977600, mean_episode_return = 63.437, mean_episode_step = 1093.7, total_loss = 77.927, pg_loss = 8.0724, baseline_loss = 75.597, entropy_loss = -5.7421, learner_queue_size = 23, _tick = 3410, _time = 1.654e+09, train_seconds = 2107.6)
[2022-05-31 14:45:33,882][root][INFO] - Step 14010880 @ 6647.9 SPS. Inference batcher size: 102. Learner queue size: 4. Other stats: (step = 14010880, mean_episode_return = 40.201, mean_episode_step = 1185.8, total_loss = 11.286, pg_loss = -71.639, baseline_loss = 88.56, entropy_loss = -5.6347, learner_queue_size = 20, _tick = 3419, _time = 1.654e+09, train_seconds = 2112.6)
[2022-05-31 14:45:38,886][root][INFO] - Step 14044160 @ 6651.0 SPS. Inference batcher size: 136. Learner queue size: 6. Other stats: (step = 14044160, mean_episode_return = None, mean_episode_step = 930.91, total_loss = 258.48, pg_loss = 153.93, baseline_loss = 110.17, entropy_loss = -5.6269, learner_queue_size = 22, _tick = 3428, _time = 1.654e+09, train_seconds = 2117.6)
[2022-05-31 14:45:43,891][root][INFO] - Step 14077440 @ 6649.5 SPS. Inference batcher size: 110. Learner queue size: 10. Other stats: (step = 14077440, mean_episode_return = 83.696, mean_episode_step = 961.3, total_loss = -64.261, pg_loss = -143.62, baseline_loss = 84.927, entropy_loss = -5.5724, learner_queue_size = 17, _tick = 3439, _time = 1.654e+09, train_seconds = 2122.6)
[2022-05-31 14:45:48,894][root][INFO] - Step 14110720 @ 6652.0 SPS. Inference batcher size: 87. Learner queue size: 10. Other stats: (step = 14110720, mean_episode_return = None, mean_episode_step = 1231.4, total_loss = -101.84, pg_loss = -155.24, baseline_loss = 58.887, entropy_loss = -5.4934, learner_queue_size = 20, _tick = 3447, _time = 1.654e+09, train_seconds = 2127.6)
[2022-05-31 14:45:53,898][root][INFO] - Step 14144000 @ 6650.6 SPS. Inference batcher size: 119. Learner queue size: 10. Other stats: (step = 14144000, mean_episode_return = 30.08, mean_episode_step = 1136.6, total_loss = -211.07, pg_loss = -251.01, baseline_loss = 45.537, entropy_loss = -5.5996, learner_queue_size = 26, _tick = 3455, _time = 1.654e+09, train_seconds = 2132.6)
[2022-05-31 14:45:58,902][root][INFO] - Step 14177280 @ 6650.7 SPS. Inference batcher size: 123. Learner queue size: 3. Other stats: (step = 14177280, mean_episode_return = None, mean_episode_step = 1088.1, total_loss = 388.8, pg_loss = 282.38, baseline_loss = 112.13, entropy_loss = -5.7017, learner_queue_size = 21, _tick = 3464, _time = 1.654e+09, train_seconds = 2137.6)
[2022-05-31 14:46:03,908][root][INFO] - Step 14210560 @ 6647.9 SPS. Inference batcher size: 85. Learner queue size: 0. Other stats: (step = 14210560, mean_episode_return = 53.86, mean_episode_step = 1186.7, total_loss = 252.28, pg_loss = 153.65, baseline_loss = 104.24, entropy_loss = -5.6099, learner_queue_size = 12, _tick = 3473, _time = 1.654e+09, train_seconds = 2142.6)
[2022-05-31 14:46:08,914][root][INFO] - Step 14243840 @ 6648.4 SPS. Inference batcher size: 166. Learner queue size: 3. Other stats: (step = 14243840, mean_episode_return = 41.091, mean_episode_step = 1184.3, total_loss = -210.21, pg_loss = -270.98, baseline_loss = 66.551, entropy_loss = -5.7781, learner_queue_size = 28, _tick = 3481, _time = 1.654e+09, train_seconds = 2147.6)
[2022-05-31 14:46:13,918][root][INFO] - Step 14277120 @ 6650.4 SPS. Inference batcher size: 128. Learner queue size: 26. Other stats: (step = 14277120, mean_episode_return = 93.76, mean_episode_step = 1244.9, total_loss = -48.374, pg_loss = -121.98, baseline_loss = 79.24, entropy_loss = -5.6302, learner_queue_size = 18, _tick = 3492, _time = 1.654e+09, train_seconds = 2152.6)
[2022-05-31 14:46:18,923][root][INFO] - Step 14310400 @ 6650.2 SPS. Inference batcher size: 146. Learner queue size: 23. Other stats: (step = 14310400, mean_episode_return = 100.71, mean_episode_step = 912.88, total_loss = 15.824, pg_loss = -93.068, baseline_loss = 114.42, entropy_loss = -5.5266, learner_queue_size = 19, _tick = 3505, _time = 1.654e+09, train_seconds = 2157.6)
[2022-05-31 14:46:23,930][root][INFO] - Step 14343680 @ 6645.8 SPS. Inference batcher size: 98. Learner queue size: 10. Other stats: (step = 14343680, mean_episode_return = 57.897, mean_episode_step = 956.71, total_loss = 107.29, pg_loss = 13.325, baseline_loss = 99.342, entropy_loss = -5.3735, learner_queue_size = 9, _tick = 3517, _time = 1.654e+09, train_seconds = 2162.6)
[2022-05-31 14:46:28,934][root][INFO] - Step 14374400 @ 6139.1 SPS. Inference batcher size: 96. Learner queue size: 21. Other stats: (step = 14374400, mean_episode_return = 46.333, mean_episode_step = 1184.7, total_loss = 252.13, pg_loss = 139.67, baseline_loss = 117.83, entropy_loss = -5.3699, learner_queue_size = 21, _tick = 3527, _time = 1.654e+09, train_seconds = 2167.6)
[2022-05-31 14:46:33,938][root][INFO] - Step 14407680 @ 6650.8 SPS. Inference batcher size: 144. Learner queue size: 16. Other stats: (step = 14407680, mean_episode_return = 79.675, mean_episode_step = 967.71, total_loss = 159.59, pg_loss = -18.835, baseline_loss = 183.9, entropy_loss = -5.4748, learner_queue_size = 14, _tick = 3535, _time = 1.654e+09, train_seconds = 2172.6)
[2022-05-31 14:46:38,942][root][INFO] - Step 14440960 @ 6650.6 SPS. Inference batcher size: 138. Learner queue size: 10. Other stats: (step = 14440960, mean_episode_return = 76.125, mean_episode_step = 1113.0, total_loss = -132.09, pg_loss = -211.81, baseline_loss = 85.451, entropy_loss = -5.7302, learner_queue_size = 20, _tick = 3544, _time = 1.654e+09, train_seconds = 2177.6)
[2022-05-31 14:46:43,946][root][INFO] - Step 14474240 @ 6650.8 SPS. Inference batcher size: 84. Learner queue size: 9. Other stats: (step = 14474240, mean_episode_return = 126.6, mean_episode_step = 982.33, total_loss = -166.37, pg_loss = -221.02, baseline_loss = 60.207, entropy_loss = -5.5528, learner_queue_size = 27, _tick = 3553, _time = 1.654e+09, train_seconds = 2182.6)
[2022-05-31 14:46:48,950][root][INFO] - Step 14507520 @ 6650.6 SPS. Inference batcher size: 102. Learner queue size: 5. Other stats: (step = 14507520, mean_episode_return = None, mean_episode_step = 1012.6, total_loss = 797.01, pg_loss = 557.92, baseline_loss = 244.74, entropy_loss = -5.6417, learner_queue_size = 13, _tick = 3563, _time = 1.654e+09, train_seconds = 2187.6)
[2022-05-31 14:46:53,954][root][INFO] - Step 14540800 @ 6650.7 SPS. Inference batcher size: 117. Learner queue size: 21. Other stats: (step = 14540800, mean_episode_return = None, mean_episode_step = 818.53, total_loss = 690.57, pg_loss = 503.95, baseline_loss = 192.23, entropy_loss = -5.6136, learner_queue_size = 20, _tick = 3574, _time = 1.654e+09, train_seconds = 2192.6)
[2022-05-31 14:46:58,958][root][INFO] - Step 14571520 @ 6139.1 SPS. Inference batcher size: 114. Learner queue size: 26. Other stats: (step = 14571520, mean_episode_return = 152.81, mean_episode_step = 756.8, total_loss = -310.79, pg_loss = -322.47, baseline_loss = 17.307, entropy_loss = -5.6282, learner_queue_size = 21, _tick = 3582, _time = 1.654e+09, train_seconds = 2197.6)
[2022-05-31 14:47:03,965][root][INFO] - Step 14604800 @ 6647.2 SPS. Inference batcher size: 150. Learner queue size: 18. Other stats: (step = 14604800, mean_episode_return = 54.441, mean_episode_step = 1060.5, total_loss = -257.84, pg_loss = -292.22, baseline_loss = 40.111, entropy_loss = -5.7312, learner_queue_size = 25, _tick = 3592, _time = 1.654e+09, train_seconds = 2202.6)
[2022-05-31 14:47:08,971][root][INFO] - Step 14640640 @ 7159.3 SPS. Inference batcher size: 86. Learner queue size: 13. Other stats: (step = 14640640, mean_episode_return = None, mean_episode_step = 1123.1, total_loss = -253.25, pg_loss = -281.98, baseline_loss = 34.387, entropy_loss = -5.654, learner_queue_size = 12, _tick = 3602, _time = 1.654e+09, train_seconds = 2207.7)
[2022-05-31 14:47:13,974][root][INFO] - Step 14671360 @ 6139.5 SPS. Inference batcher size: 11. Learner queue size: 4. Other stats: (step = 14671360, mean_episode_return = 56.636, mean_episode_step = 943.4, total_loss = 263.49, pg_loss = 171.37, baseline_loss = 97.836, entropy_loss = -5.7174, learner_queue_size = 11, _tick = 3610, _time = 1.654e+09, train_seconds = 2212.7)
[2022-05-31 14:47:18,987][root][INFO] - Step 14704640 @ 6639.8 SPS. Inference batcher size: 13. Learner queue size: 20. Other stats: (step = 14704640, mean_episode_return = 56.58, mean_episode_step = 1105.6, total_loss = 892.71, pg_loss = 681.02, baseline_loss = 217.37, entropy_loss = -5.68, learner_queue_size = 12, _tick = 3622, _time = 1.654e+09, train_seconds = 2217.7)
[2022-05-31 14:47:23,994][root][INFO] - Step 14737920 @ 6645.9 SPS. Inference batcher size: 174. Learner queue size: 19. Other stats: (step = 14737920, mean_episode_return = 112.79, mean_episode_step = 1164.1, total_loss = -207.32, pg_loss = -332.54, baseline_loss = 130.85, entropy_loss = -5.626, learner_queue_size = 30, _tick = 3630, _time = 1.654e+09, train_seconds = 2222.7)
[2022-05-31 14:47:28,998][root][INFO] - Step 14771200 @ 6650.7 SPS. Inference batcher size: 217. Learner queue size: 2. Other stats: (step = 14771200, mean_episode_return = 59.42, mean_episode_step = 978.14, total_loss = 262.7, pg_loss = -19.715, baseline_loss = 288.23, entropy_loss = -5.8111, learner_queue_size = 14, _tick = 3640, _time = 1.654e+09, train_seconds = 2227.7)
[2022-05-31 14:47:34,005][root][INFO] - Step 14804480 @ 6647.5 SPS. Inference batcher size: 25. Learner queue size: 9. Other stats: (step = 14804480, mean_episode_return = 33.066, mean_episode_step = 1229.3, total_loss = -21.382, pg_loss = -83.149, baseline_loss = 67.408, entropy_loss = -5.6409, learner_queue_size = 21, _tick = 3649, _time = 1.654e+09, train_seconds = 2232.7)
[2022-05-31 14:47:39,010][root][INFO] - Step 14837760 @ 6648.6 SPS. Inference batcher size: 137. Learner queue size: 28. Other stats: (step = 14837760, mean_episode_return = None, mean_episode_step = 1058.3, total_loss = -150.22, pg_loss = -200.12, baseline_loss = 55.535, entropy_loss = -5.6399, learner_queue_size = 13, _tick = 3654, _time = 1.654e+09, train_seconds = 2237.7)
[2022-05-31 14:47:44,014][root][INFO] - Step 14871040 @ 6650.8 SPS. Inference batcher size: 102. Learner queue size: 0. Other stats: (step = 14871040, mean_episode_return = 28.07, mean_episode_step = 1075.5, total_loss = 3.2182e+04, pg_loss = 5676.0, baseline_loss = 2.6511e+04, entropy_loss = -5.6449, learner_queue_size = 16, _tick = 3665, _time = 1.654e+09, train_seconds = 2242.7)
[2022-05-31 14:47:49,020][root][INFO] - Step 14901760 @ 6137.0 SPS. Inference batcher size: 77. Learner queue size: 27. Other stats: (step = 14901760, mean_episode_return = -6.9901, mean_episode_step = 1318.0, total_loss = -253.15, pg_loss = -275.68, baseline_loss = 28.243, entropy_loss = -5.7156, learner_queue_size = 19, _tick = 3674, _time = 1.654e+09, train_seconds = 2247.7)
[2022-05-31 14:47:54,026][root][INFO] - Step 14935040 @ 6647.9 SPS. Inference batcher size: 133. Learner queue size: 16. Other stats: (step = 14935040, mean_episode_return = 61.79, mean_episode_step = 1177.4, total_loss = 314.27, pg_loss = 172.12, baseline_loss = 147.83, entropy_loss = -5.6809, learner_queue_size = 20, _tick = 3684, _time = 1.654e+09, train_seconds = 2252.7)
[2022-05-31 14:47:59,031][root][INFO] - Step 14968320 @ 6649.4 SPS. Inference batcher size: 149. Learner queue size: 15. Other stats: (step = 14968320, mean_episode_return = 44.15, mean_episode_step = 971.16, total_loss = -423.42, pg_loss = -438.76, baseline_loss = 20.869, entropy_loss = -5.5262, learner_queue_size = 18, _tick = 3694, _time = 1.654e+09, train_seconds = 2257.7)
[2022-05-31 14:48:04,037][root][INFO] - Step 15001600 @ 6647.9 SPS. Inference batcher size: 149. Learner queue size: 9. Other stats: (step = 15001600, mean_episode_return = 40.07, mean_episode_step = 1299.2, total_loss = -381.04, pg_loss = -468.19, baseline_loss = 92.77, entropy_loss = -5.6172, learner_queue_size = 21, _tick = 3705, _time = 1.654e+09, train_seconds = 2262.7)
[2022-05-31 14:48:09,043][root][INFO] - Step 15034880 @ 6647.9 SPS. Inference batcher size: 156. Learner queue size: 20. Other stats: (step = 15034880, mean_episode_return = 126.52, mean_episode_step = 1281.5, total_loss = 693.6, pg_loss = 512.99, baseline_loss = 186.29, entropy_loss = -5.6679, learner_queue_size = 25, _tick = 3717, _time = 1.654e+09, train_seconds = 2267.7)
[2022-05-31 14:48:14,046][root][INFO] - Step 15068160 @ 6651.8 SPS. Inference batcher size: 71. Learner queue size: 26. Other stats: (step = 15068160, mean_episode_return = 16.095, mean_episode_step = 990.44, total_loss = 173.26, pg_loss = 73.901, baseline_loss = 104.92, entropy_loss = -5.5552, learner_queue_size = 28, _tick = 3729, _time = 1.654e+09, train_seconds = 2272.7)
[2022-05-31 14:48:19,050][root][INFO] - Step 15101440 @ 6650.6 SPS. Inference batcher size: 165. Learner queue size: 11. Other stats: (step = 15101440, mean_episode_return = None, mean_episode_step = 814.03, total_loss = 115.92, pg_loss = 52.602, baseline_loss = 68.652, entropy_loss = -5.3346, learner_queue_size = 11, _tick = 3736, _time = 1.654e+09, train_seconds = 2277.7)
[2022-05-31 14:48:24,054][root][INFO] - Step 15134720 @ 6650.7 SPS. Inference batcher size: 129. Learner queue size: 17. Other stats: (step = 15134720, mean_episode_return = 81.938, mean_episode_step = 957.96, total_loss = -291.02, pg_loss = -376.49, baseline_loss = 90.749, entropy_loss = -5.2801, learner_queue_size = 19, _tick = 3748, _time = 1.654e+09, train_seconds = 2282.7)
[2022-05-31 14:48:29,058][root][INFO] - Step 15168000 @ 6650.7 SPS. Inference batcher size: 156. Learner queue size: 10. Other stats: (step = 15168000, mean_episode_return = None, mean_episode_step = 1100.9, total_loss = 872.56, pg_loss = 654.31, baseline_loss = 223.64, entropy_loss = -5.3806, learner_queue_size = 19, _tick = 3756, _time = 1.654e+09, train_seconds = 2287.7)
[2022-05-31 14:48:34,062][root][INFO] - Step 15201280 @ 6650.6 SPS. Inference batcher size: 37. Learner queue size: 10. Other stats: (step = 15201280, mean_episode_return = 67.27, mean_episode_step = 1064.0, total_loss = 132.11, pg_loss = 53.178, baseline_loss = 84.479, entropy_loss = -5.5477, learner_queue_size = 23, _tick = 3765, _time = 1.654e+09, train_seconds = 2292.7)
[2022-05-31 14:48:39,066][root][INFO] - Step 15234560 @ 6650.7 SPS. Inference batcher size: 94. Learner queue size: 15. Other stats: (step = 15234560, mean_episode_return = 18.607, mean_episode_step = 978.45, total_loss = 857.29, pg_loss = 615.86, baseline_loss = 247.17, entropy_loss = -5.732, learner_queue_size = 16, _tick = 3775, _time = 1.654e+09, train_seconds = 2297.8)
[2022-05-31 14:48:44,070][root][INFO] - Step 15267840 @ 6650.7 SPS. Inference batcher size: 174. Learner queue size: 31. Other stats: (step = 15267840, mean_episode_return = 45.1, mean_episode_step = 1065.7, total_loss = -556.19, pg_loss = -599.09, baseline_loss = 48.442, entropy_loss = -5.5452, learner_queue_size = 14, _tick = 3785, _time = 1.654e+09, train_seconds = 2302.8)
[2022-05-31 14:48:49,074][root][INFO] - Step 15301120 @ 6650.6 SPS. Inference batcher size: 88. Learner queue size: 25. Other stats: (step = 15301120, mean_episode_return = 25.97, mean_episode_step = 987.35, total_loss = 296.72, pg_loss = 167.31, baseline_loss = 134.96, entropy_loss = -5.5552, learner_queue_size = 20, _tick = 3796, _time = 1.654e+09, train_seconds = 2307.8)
[2022-05-31 14:48:54,078][root][INFO] - Step 15331840 @ 6139.2 SPS. Inference batcher size: 89. Learner queue size: 16. Other stats: (step = 15331840, mean_episode_return = 82.986, mean_episode_step = 932.23, total_loss = 486.88, pg_loss = 259.61, baseline_loss = 232.86, entropy_loss = -5.5828, learner_queue_size = 21, _tick = 3806, _time = 1.654e+09, train_seconds = 2312.8)
[2022-05-31 14:48:59,082][root][INFO] - Step 15365120 @ 6650.5 SPS. Inference batcher size: 136. Learner queue size: 20. Other stats: (step = 15365120, mean_episode_return = 32.805, mean_episode_step = 899.03, total_loss = -498.86, pg_loss = -581.82, baseline_loss = 88.389, entropy_loss = -5.4247, learner_queue_size = 21, _tick = 3813, _time = 1.654e+09, train_seconds = 2317.8)
[2022-05-31 14:49:04,088][root][INFO] - Step 15398400 @ 6647.8 SPS. Inference batcher size: 133. Learner queue size: 16. Other stats: (step = 15398400, mean_episode_return = 84.239, mean_episode_step = 1365.7, total_loss = 165.92, pg_loss = 102.68, baseline_loss = 68.801, entropy_loss = -5.5595, learner_queue_size = 29, _tick = 3824, _time = 1.654e+09, train_seconds = 2322.8)
[2022-05-31 14:49:09,094][root][INFO] - Step 15431680 @ 6648.0 SPS. Inference batcher size: 128. Learner queue size: 16. Other stats: (step = 15431680, mean_episode_return = 55.291, mean_episode_step = 1075.6, total_loss = 586.17, pg_loss = 382.51, baseline_loss = 209.17, entropy_loss = -5.5146, learner_queue_size = 13, _tick = 3834, _time = 1.654e+09, train_seconds = 2327.8)
[2022-05-31 14:49:14,098][root][INFO] - Step 15464960 @ 6651.1 SPS. Inference batcher size: 83. Learner queue size: 8. Other stats: (step = 15464960, mean_episode_return = 74.1, mean_episode_step = 1161.4, total_loss = -213.82, pg_loss = -258.78, baseline_loss = 50.452, entropy_loss = -5.4918, learner_queue_size = 13, _tick = 3845, _time = 1.654e+09, train_seconds = 2332.8)
[2022-05-31 14:49:19,102][root][INFO] - Step 15498240 @ 6650.6 SPS. Inference batcher size: 161. Learner queue size: 6. Other stats: (step = 15498240, mean_episode_return = None, mean_episode_step = 1255.3, total_loss = 79.457, pg_loss = 23.171, baseline_loss = 61.851, entropy_loss = -5.5639, learner_queue_size = 25, _tick = 3856, _time = 1.654e+09, train_seconds = 2337.8)
[2022-05-31 14:49:24,106][root][INFO] - Step 15531520 @ 6650.2 SPS. Inference batcher size: 12. Learner queue size: 2. Other stats: (step = 15531520, mean_episode_return = 37.72, mean_episode_step = 1051.9, total_loss = 105.8, pg_loss = 54.081, baseline_loss = 57.278, entropy_loss = -5.5602, learner_queue_size = 16, _tick = 3866, _time = 1.654e+09, train_seconds = 2342.8)
[2022-05-31 14:49:29,113][root][INFO] - Step 15564800 @ 6647.4 SPS. Inference batcher size: 116. Learner queue size: 4. Other stats: (step = 15564800, mean_episode_return = 86.96, mean_episode_step = 760.01, total_loss = -256.46, pg_loss = -297.72, baseline_loss = 46.638, entropy_loss = -5.3786, learner_queue_size = 24, _tick = 3876, _time = 1.654e+09, train_seconds = 2347.8)
[2022-05-31 14:49:34,118][root][INFO] - Step 15598080 @ 6649.1 SPS. Inference batcher size: 78. Learner queue size: 24. Other stats: (step = 15598080, mean_episode_return = None, mean_episode_step = 1146.4, total_loss = 617.65, pg_loss = 457.68, baseline_loss = 165.55, entropy_loss = -5.5857, learner_queue_size = 19, _tick = 3887, _time = 1.654e+09, train_seconds = 2352.8)
[2022-05-31 14:49:39,122][root][INFO] - Step 15631360 @ 6650.6 SPS. Inference batcher size: 125. Learner queue size: 25. Other stats: (step = 15631360, mean_episode_return = 157.55, mean_episode_step = 1147.3, total_loss = 16.559, pg_loss = -37.55, baseline_loss = 59.616, entropy_loss = -5.5068, learner_queue_size = 24, _tick = 3900, _time = 1.654e+09, train_seconds = 2357.8)
[2022-05-31 14:49:44,124][root][INFO] - Step 15662080 @ 6141.4 SPS. Inference batcher size: 139. Learner queue size: 13. Other stats: (step = 15662080, mean_episode_return = 102.39, mean_episode_step = 1197.0, total_loss = -372.43, pg_loss = -391.43, baseline_loss = 24.386, entropy_loss = -5.3875, learner_queue_size = 15, _tick = 3911, _time = 1.654e+09, train_seconds = 2362.8)
[2022-05-31 14:49:49,130][root][INFO] - Step 15695360 @ 6648.0 SPS. Inference batcher size: 122. Learner queue size: 20. Other stats: (step = 15695360, mean_episode_return = 50.879, mean_episode_step = 986.61, total_loss = -142.58, pg_loss = -215.84, baseline_loss = 78.833, entropy_loss = -5.5684, learner_queue_size = 21, _tick = 3922, _time = 1.654e+09, train_seconds = 2367.8)
[2022-05-31 14:49:54,134][root][INFO] - Step 15728640 @ 6651.0 SPS. Inference batcher size: 78. Learner queue size: 7. Other stats: (step = 15728640, mean_episode_return = 41.131, mean_episode_step = 972.66, total_loss = -122.84, pg_loss = -169.95, baseline_loss = 52.647, entropy_loss = -5.5438, learner_queue_size = 15, _tick = 3930, _time = 1.654e+09, train_seconds = 2372.8)
[2022-05-31 14:49:59,138][root][INFO] - Step 15761920 @ 6650.6 SPS. Inference batcher size: 3. Learner queue size: 8. Other stats: (step = 15761920, mean_episode_return = None, mean_episode_step = 1255.7, total_loss = 73.29, pg_loss = 12.001, baseline_loss = 66.807, entropy_loss = -5.5178, learner_queue_size = 12, _tick = 3939, _time = 1.654e+09, train_seconds = 2377.8)
[2022-05-31 14:50:04,142][root][INFO] - Step 15795200 @ 6650.7 SPS. Inference batcher size: 123. Learner queue size: 31. Other stats: (step = 15795200, mean_episode_return = 65.751, mean_episode_step = 973.13, total_loss = -70.759, pg_loss = -151.11, baseline_loss = 85.925, entropy_loss = -5.5707, learner_queue_size = 17, _tick = 3949, _time = 1.654e+09, train_seconds = 2382.8)
[2022-05-31 14:50:09,147][root][INFO] - Step 15828480 @ 6648.9 SPS. Inference batcher size: 6. Learner queue size: 4. Other stats: (step = 15828480, mean_episode_return = 53.641, mean_episode_step = 1039.3, total_loss = 206.4, pg_loss = 110.23, baseline_loss = 101.91, entropy_loss = -5.7348, learner_queue_size = 28, _tick = 3960, _time = 1.654e+09, train_seconds = 2387.8)
[2022-05-31 14:50:14,150][root][INFO] - Step 15861760 @ 6652.4 SPS. Inference batcher size: 86. Learner queue size: 29. Other stats: (step = 15861760, mean_episode_return = 39.39, mean_episode_step = 1286.7, total_loss = 213.15, pg_loss = 120.6, baseline_loss = 98.429, entropy_loss = -5.8823, learner_queue_size = 22, _tick = 3968, _time = 1.654e+09, train_seconds = 2392.8)
[2022-05-31 14:50:19,154][root][INFO] - Step 15895040 @ 6650.7 SPS. Inference batcher size: 116. Learner queue size: 1. Other stats: (step = 15895040, mean_episode_return = 112.46, mean_episode_step = 1240.4, total_loss = -204.86, pg_loss = -263.99, baseline_loss = 64.943, entropy_loss = -5.8106, learner_queue_size = 10, _tick = 3977, _time = 1.654e+09, train_seconds = 2397.8)
[2022-05-31 14:50:24,160][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 14:50:24,260][root][INFO] - Step 15928320 @ 6647.9 SPS. Inference batcher size: 78. Learner queue size: 30. Other stats: (step = 15928320, mean_episode_return = None, mean_episode_step = 1034.2, total_loss = 65.701, pg_loss = -80.548, baseline_loss = 152.2, entropy_loss = -5.9547, learner_queue_size = 18, _tick = 3987, _time = 1.654e+09, train_seconds = 2402.8)
[2022-05-31 14:50:29,266][root][INFO] - Step 15961600 @ 6517.4 SPS. Inference batcher size: 118. Learner queue size: 5. Other stats: (step = 15961600, mean_episode_return = 30.78, mean_episode_step = 952.91, total_loss = 502.89, pg_loss = 304.44, baseline_loss = 204.4, entropy_loss = -5.9492, learner_queue_size = 17, _tick = 3997, _time = 1.654e+09, train_seconds = 2408.0)
[2022-05-31 14:50:34,270][root][INFO] - Step 15994880 @ 6650.9 SPS. Inference batcher size: 21. Learner queue size: 5. Other stats: (step = 15994880, mean_episode_return = 94.085, mean_episode_step = 1069.6, total_loss = 908.24, pg_loss = 238.43, baseline_loss = 675.41, entropy_loss = -5.6039, learner_queue_size = 26, _tick = 4008, _time = 1.654e+09, train_seconds = 2413.0)
[2022-05-31 14:50:39,274][root][INFO] - Step 16028160 @ 6650.4 SPS. Inference batcher size: 75. Learner queue size: 1. Other stats: (step = 16028160, mean_episode_return = 121.15, mean_episode_step = 1102.5, total_loss = 79.81, pg_loss = 9.4453, baseline_loss = 76.286, entropy_loss = -5.9212, learner_queue_size = 22, _tick = 4019, _time = 1.654e+09, train_seconds = 2418.0)
[2022-05-31 14:50:44,281][root][INFO] - Step 16061440 @ 6648.0 SPS. Inference batcher size: 156. Learner queue size: 1. Other stats: (step = 16061440, mean_episode_return = 80.161, mean_episode_step = 1012.5, total_loss = 199.0, pg_loss = 116.52, baseline_loss = 88.691, entropy_loss = -6.2084, learner_queue_size = 24, _tick = 4030, _time = 1.654e+09, train_seconds = 2423.0)
[2022-05-31 14:50:49,286][root][INFO] - Step 16094720 @ 6648.7 SPS. Inference batcher size: 0. Learner queue size: 29. Other stats: (step = 16094720, mean_episode_return = -6.9501, mean_episode_step = 864.39, total_loss = -166.34, pg_loss = -219.24, baseline_loss = 58.857, entropy_loss = -5.9619, learner_queue_size = 25, _tick = 4043, _time = 1.654e+09, train_seconds = 2428.0)
[2022-05-31 14:50:54,290][root][INFO] - Step 16125440 @ 6139.1 SPS. Inference batcher size: 143. Learner queue size: 17. Other stats: (step = 16125440, mean_episode_return = 15.977, mean_episode_step = 995.61, total_loss = 383.91, pg_loss = 129.76, baseline_loss = 260.14, entropy_loss = -5.9841, learner_queue_size = 18, _tick = 4050, _time = 1.654e+09, train_seconds = 2433.0)
[2022-05-31 14:50:59,296][root][INFO] - Step 16158720 @ 6647.9 SPS. Inference batcher size: 85. Learner queue size: 17. Other stats: (step = 16158720, mean_episode_return = 72.019, mean_episode_step = 1027.6, total_loss = -261.01, pg_loss = -360.03, baseline_loss = 105.07, entropy_loss = -6.0602, learner_queue_size = 25, _tick = 4059, _time = 1.654e+09, train_seconds = 2438.0)
[2022-05-31 14:51:04,302][root][INFO] - Step 16192000 @ 6648.0 SPS. Inference batcher size: 93. Learner queue size: 15. Other stats: (step = 16192000, mean_episode_return = 112.59, mean_episode_step = 1366.4, total_loss = -81.518, pg_loss = -113.82, baseline_loss = 38.54, entropy_loss = -6.2365, learner_queue_size = 22, _tick = 4068, _time = 1.654e+09, train_seconds = 2443.0)
[2022-05-31 14:51:09,306][root][INFO] - Step 16225280 @ 6650.8 SPS. Inference batcher size: 64. Learner queue size: 15. Other stats: (step = 16225280, mean_episode_return = -5.4001, mean_episode_step = 1054.0, total_loss = -59.182, pg_loss = -115.5, baseline_loss = 62.593, entropy_loss = -6.275, learner_queue_size = 8, _tick = 4078, _time = 1.654e+09, train_seconds = 2448.0)
[2022-05-31 14:51:14,310][root][INFO] - Step 16258560 @ 6650.7 SPS. Inference batcher size: 95. Learner queue size: 12. Other stats: (step = 16258560, mean_episode_return = 69.178, mean_episode_step = 796.91, total_loss = -113.29, pg_loss = -180.01, baseline_loss = 73.039, entropy_loss = -6.3188, learner_queue_size = 23, _tick = 4090, _time = 1.654e+09, train_seconds = 2453.0)
[2022-05-31 14:51:19,314][root][INFO] - Step 16291840 @ 6650.6 SPS. Inference batcher size: 104. Learner queue size: 10. Other stats: (step = 16291840, mean_episode_return = None, mean_episode_step = 1229.1, total_loss = -92.376, pg_loss = -114.42, baseline_loss = 28.358, entropy_loss = -6.3167, learner_queue_size = 14, _tick = 4098, _time = 1.654e+09, train_seconds = 2458.0)
[2022-05-31 14:51:24,320][root][INFO] - Step 16325120 @ 6647.9 SPS. Inference batcher size: 98. Learner queue size: 14. Other stats: (step = 16325120, mean_episode_return = 11.64, mean_episode_step = 961.5, total_loss = -69.126, pg_loss = -116.94, baseline_loss = 53.902, entropy_loss = -6.086, learner_queue_size = 25, _tick = 4108, _time = 1.654e+09, train_seconds = 2463.0)
[2022-05-31 14:51:29,326][root][INFO] - Step 16358400 @ 6648.0 SPS. Inference batcher size: 112. Learner queue size: 14. Other stats: (step = 16358400, mean_episode_return = None, mean_episode_step = 1376.5, total_loss = 43.301, pg_loss = -20.234, baseline_loss = 69.642, entropy_loss = -6.1058, learner_queue_size = 26, _tick = 4116, _time = 1.654e+09, train_seconds = 2468.0)
[2022-05-31 14:51:34,330][root][INFO] - Step 16391680 @ 6650.9 SPS. Inference batcher size: 29. Learner queue size: 9. Other stats: (step = 16391680, mean_episode_return = 108.56, mean_episode_step = 888.0, total_loss = -729.65, pg_loss = -768.9, baseline_loss = 45.004, entropy_loss = -5.7499, learner_queue_size = 29, _tick = 4126, _time = 1.654e+09, train_seconds = 2473.0)
[2022-05-31 14:51:39,336][root][INFO] - Step 16424960 @ 6647.8 SPS. Inference batcher size: 63. Learner queue size: 4. Other stats: (step = 16424960, mean_episode_return = 148.77, mean_episode_step = 1028.0, total_loss = 157.56, pg_loss = 57.804, baseline_loss = 105.8, entropy_loss = -6.0403, learner_queue_size = 14, _tick = 4132, _time = 1.654e+09, train_seconds = 2478.0)
[2022-05-31 14:51:44,342][root][INFO] - Step 16458240 @ 6647.7 SPS. Inference batcher size: 99. Learner queue size: 3. Other stats: (step = 16458240, mean_episode_return = 30.824, mean_episode_step = 893.54, total_loss = 219.7, pg_loss = 16.508, baseline_loss = 208.83, entropy_loss = -5.6329, learner_queue_size = 23, _tick = 4141, _time = 1.654e+09, train_seconds = 2483.0)
[2022-05-31 14:51:49,346][root][INFO] - Step 16491520 @ 6651.2 SPS. Inference batcher size: 122. Learner queue size: 28. Other stats: (step = 16491520, mean_episode_return = 90.495, mean_episode_step = 949.93, total_loss = -360.14, pg_loss = -392.28, baseline_loss = 38.015, entropy_loss = -5.867, learner_queue_size = 9, _tick = 4151, _time = 1.654e+09, train_seconds = 2488.0)
[2022-05-31 14:51:54,350][root][INFO] - Step 16524800 @ 6650.6 SPS. Inference batcher size: 104. Learner queue size: 25. Other stats: (step = 16524800, mean_episode_return = 54.869, mean_episode_step = 1391.7, total_loss = -432.03, pg_loss = -497.88, baseline_loss = 71.813, entropy_loss = -5.9565, learner_queue_size = 22, _tick = 4160, _time = 1.654e+09, train_seconds = 2493.0)
[2022-05-31 14:51:59,356][root][INFO] - Step 16555520 @ 6137.1 SPS. Inference batcher size: 123. Learner queue size: 26. Other stats: (step = 16555520, mean_episode_return = 49.94, mean_episode_step = 1091.5, total_loss = -383.62, pg_loss = -427.42, baseline_loss = 49.591, entropy_loss = -5.7871, learner_queue_size = 24, _tick = 4169, _time = 1.654e+09, train_seconds = 2498.0)
[2022-05-31 14:52:04,362][root][INFO] - Step 16588800 @ 6648.0 SPS. Inference batcher size: 169. Learner queue size: 18. Other stats: (step = 16588800, mean_episode_return = None, mean_episode_step = 1335.8, total_loss = -206.58, pg_loss = -223.83, baseline_loss = 23.164, entropy_loss = -5.9096, learner_queue_size = 15, _tick = 4178, _time = 1.654e+09, train_seconds = 2503.0)
[2022-05-31 14:52:09,368][root][INFO] - Step 16622080 @ 6648.0 SPS. Inference batcher size: 125. Learner queue size: 15. Other stats: (step = 16622080, mean_episode_return = 89.418, mean_episode_step = 1288.4, total_loss = 199.76, pg_loss = 44.599, baseline_loss = 160.89, entropy_loss = -5.7348, learner_queue_size = 20, _tick = 4188, _time = 1.654e+09, train_seconds = 2508.1)
[2022-05-31 14:52:14,370][root][INFO] - Step 16655360 @ 6652.9 SPS. Inference batcher size: 110. Learner queue size: 10. Other stats: (step = 16655360, mean_episode_return = 74.812, mean_episode_step = 1057.1, total_loss = 483.72, pg_loss = 276.69, baseline_loss = 212.62, entropy_loss = -5.5811, learner_queue_size = 22, _tick = 4199, _time = 1.654e+09, train_seconds = 2513.1)
[2022-05-31 14:52:19,374][root][INFO] - Step 16688640 @ 6650.6 SPS. Inference batcher size: 125. Learner queue size: 17. Other stats: (step = 16688640, mean_episode_return = 27.77, mean_episode_step = 1114.6, total_loss = 554.67, pg_loss = 314.91, baseline_loss = 245.33, entropy_loss = -5.5758, learner_queue_size = 17, _tick = 4208, _time = 1.654e+09, train_seconds = 2518.1)
[2022-05-31 14:52:24,378][root][INFO] - Step 16721920 @ 6650.8 SPS. Inference batcher size: 114. Learner queue size: 19. Other stats: (step = 16721920, mean_episode_return = 25.107, mean_episode_step = 1250.2, total_loss = -524.95, pg_loss = -595.71, baseline_loss = 76.436, entropy_loss = -5.6747, learner_queue_size = 24, _tick = 4218, _time = 1.654e+09, train_seconds = 2523.1)
[2022-05-31 14:52:29,384][root][INFO] - Step 16755200 @ 6647.8 SPS. Inference batcher size: 132. Learner queue size: 22. Other stats: (step = 16755200, mean_episode_return = 16.4, mean_episode_step = 1028.8, total_loss = -301.02, pg_loss = -336.01, baseline_loss = 40.573, entropy_loss = -5.5759, learner_queue_size = 25, _tick = 4229, _time = 1.654e+09, train_seconds = 2528.1)
[2022-05-31 14:52:34,390][root][INFO] - Step 16788480 @ 6648.2 SPS. Inference batcher size: 181. Learner queue size: 14. Other stats: (step = 16788480, mean_episode_return = 15.69, mean_episode_step = 1053.3, total_loss = 997.91, pg_loss = 712.17, baseline_loss = 291.33, entropy_loss = -5.5934, learner_queue_size = 15, _tick = 4238, _time = 1.654e+09, train_seconds = 2533.1)
[2022-05-31 14:52:39,394][root][INFO] - Step 16821760 @ 6650.6 SPS. Inference batcher size: 50. Learner queue size: 6. Other stats: (step = 16821760, mean_episode_return = 91.789, mean_episode_step = 1477.9, total_loss = 976.47, pg_loss = 662.77, baseline_loss = 319.33, entropy_loss = -5.6284, learner_queue_size = 13, _tick = 4247, _time = 1.654e+09, train_seconds = 2538.1)
[2022-05-31 14:52:44,398][root][INFO] - Step 16855040 @ 6650.7 SPS. Inference batcher size: 195. Learner queue size: 11. Other stats: (step = 16855040, mean_episode_return = 29.0, mean_episode_step = 821.82, total_loss = 110.9, pg_loss = 34.398, baseline_loss = 81.832, entropy_loss = -5.3278, learner_queue_size = 26, _tick = 4257, _time = 1.654e+09, train_seconds = 2543.1)
[2022-05-31 14:52:49,402][root][INFO] - Step 16888320 @ 6650.4 SPS. Inference batcher size: 44. Learner queue size: 1. Other stats: (step = 16888320, mean_episode_return = 60.655, mean_episode_step = 1146.0, total_loss = 222.59, pg_loss = 82.293, baseline_loss = 145.6, entropy_loss = -5.3102, learner_queue_size = 17, _tick = 4267, _time = 1.654e+09, train_seconds = 2548.1)
[2022-05-31 14:52:54,409][root][INFO] - Step 16921600 @ 6646.6 SPS. Inference batcher size: 48. Learner queue size: 2. Other stats: (step = 16921600, mean_episode_return = 115.35, mean_episode_step = 1429.5, total_loss = -250.37, pg_loss = -256.93, baseline_loss = 12.046, entropy_loss = -5.4831, learner_queue_size = 21, _tick = 4276, _time = 1.654e+09, train_seconds = 2553.1)
[2022-05-31 14:52:59,420][root][INFO] - Step 16954880 @ 6642.3 SPS. Inference batcher size: 120. Learner queue size: 2. Other stats: (step = 16954880, mean_episode_return = 35.98, mean_episode_step = 1089.5, total_loss = -105.84, pg_loss = -187.72, baseline_loss = 87.415, entropy_loss = -5.5317, learner_queue_size = 13, _tick = 4287, _time = 1.654e+09, train_seconds = 2558.1)
[2022-05-31 14:53:04,422][root][INFO] - Step 16988160 @ 6652.8 SPS. Inference batcher size: 150. Learner queue size: 6. Other stats: (step = 16988160, mean_episode_return = None, mean_episode_step = 1388.3, total_loss = 351.1, pg_loss = 253.54, baseline_loss = 103.24, entropy_loss = -5.6827, learner_queue_size = 14, _tick = 4299, _time = 1.654e+09, train_seconds = 2563.1)
[2022-05-31 14:53:09,426][root][INFO] - Step 17021440 @ 6650.6 SPS. Inference batcher size: 161. Learner queue size: 27. Other stats: (step = 17021440, mean_episode_return = None, mean_episode_step = 910.12, total_loss = 489.61, pg_loss = 394.43, baseline_loss = 100.83, entropy_loss = -5.6514, learner_queue_size = 19, _tick = 4310, _time = 1.654e+09, train_seconds = 2568.1)
[2022-05-31 14:53:14,429][root][INFO] - Step 17052160 @ 6140.7 SPS. Inference batcher size: 66. Learner queue size: 23. Other stats: (step = 17052160, mean_episode_return = 18.31, mean_episode_step = 907.12, total_loss = 55.114, pg_loss = -71.177, baseline_loss = 131.97, entropy_loss = -5.6752, learner_queue_size = 18, _tick = 4316, _time = 1.654e+09, train_seconds = 2573.1)
[2022-05-31 14:53:19,434][root][INFO] - Step 17085440 @ 6649.3 SPS. Inference batcher size: 86. Learner queue size: 15. Other stats: (step = 17085440, mean_episode_return = None, mean_episode_step = 976.0, total_loss = 911.57, pg_loss = 706.96, baseline_loss = 210.35, entropy_loss = -5.7355, learner_queue_size = 20, _tick = 4326, _time = 1.654e+09, train_seconds = 2578.1)
[2022-05-31 14:53:24,440][root][INFO] - Step 17118720 @ 6647.9 SPS. Inference batcher size: 90. Learner queue size: 21. Other stats: (step = 17118720, mean_episode_return = 93.845, mean_episode_step = 1100.1, total_loss = 56.049, pg_loss = -34.717, baseline_loss = 96.252, entropy_loss = -5.4862, learner_queue_size = 14, _tick = 4335, _time = 1.654e+09, train_seconds = 2583.1)
[2022-05-31 14:53:29,446][root][INFO] - Step 17152000 @ 6648.0 SPS. Inference batcher size: 130. Learner queue size: 21. Other stats: (step = 17152000, mean_episode_return = None, mean_episode_step = 1233.8, total_loss = -231.49, pg_loss = -239.3, baseline_loss = 13.388, entropy_loss = -5.5733, learner_queue_size = 24, _tick = 4343, _time = 1.654e+09, train_seconds = 2588.1)
[2022-05-31 14:53:34,452][root][INFO] - Step 17185280 @ 6647.9 SPS. Inference batcher size: 72. Learner queue size: 9. Other stats: (step = 17185280, mean_episode_return = 70.973, mean_episode_step = 1395.3, total_loss = -353.48, pg_loss = -553.01, baseline_loss = 205.33, entropy_loss = -5.804, learner_queue_size = 14, _tick = 4352, _time = 1.654e+09, train_seconds = 2593.1)
[2022-05-31 14:53:39,454][root][INFO] - Step 17218560 @ 6652.9 SPS. Inference batcher size: 67. Learner queue size: 8. Other stats: (step = 17218560, mean_episode_return = 77.009, mean_episode_step = 970.07, total_loss = 191.7, pg_loss = 133.84, baseline_loss = 63.674, entropy_loss = -5.8126, learner_queue_size = 15, _tick = 4363, _time = 1.654e+09, train_seconds = 2598.1)
[2022-05-31 14:53:44,458][root][INFO] - Step 17251840 @ 6650.6 SPS. Inference batcher size: 117. Learner queue size: 8. Other stats: (step = 17251840, mean_episode_return = None, mean_episode_step = 992.16, total_loss = 365.1, pg_loss = 246.45, baseline_loss = 124.51, entropy_loss = -5.8536, learner_queue_size = 21, _tick = 4371, _time = 1.654e+09, train_seconds = 2603.1)
[2022-05-31 14:53:49,462][root][INFO] - Step 17285120 @ 6651.1 SPS. Inference batcher size: 155. Learner queue size: 9. Other stats: (step = 17285120, mean_episode_return = 49.213, mean_episode_step = 986.01, total_loss = -373.08, pg_loss = -432.06, baseline_loss = 64.651, entropy_loss = -5.6646, learner_queue_size = 22, _tick = 4380, _time = 1.654e+09, train_seconds = 2608.1)
[2022-05-31 14:53:54,467][root][INFO] - Step 17318400 @ 6649.0 SPS. Inference batcher size: 32. Learner queue size: 2. Other stats: (step = 17318400, mean_episode_return = None, mean_episode_step = 1440.3, total_loss = 1099.7, pg_loss = 871.9, baseline_loss = 233.77, entropy_loss = -5.9403, learner_queue_size = 18, _tick = 4391, _time = 1.654e+09, train_seconds = 2613.2)
[2022-05-31 14:53:59,470][root][INFO] - Step 17351680 @ 6652.2 SPS. Inference batcher size: 70. Learner queue size: 4. Other stats: (step = 17351680, mean_episode_return = 6.6897, mean_episode_step = 901.37, total_loss = 177.01, pg_loss = -0.86366, baseline_loss = 183.57, entropy_loss = -5.6966, learner_queue_size = 20, _tick = 4402, _time = 1.654e+09, train_seconds = 2618.2)
[2022-05-31 14:54:04,474][root][INFO] - Step 17384960 @ 6650.8 SPS. Inference batcher size: 56. Learner queue size: 0. Other stats: (step = 17384960, mean_episode_return = None, mean_episode_step = 978.5, total_loss = 93.784, pg_loss = 27.106, baseline_loss = 72.189, entropy_loss = -5.511, learner_queue_size = 21, _tick = 4414, _time = 1.654e+09, train_seconds = 2623.2)
[2022-05-31 14:54:09,478][root][INFO] - Step 17418240 @ 6650.6 SPS. Inference batcher size: 167. Learner queue size: 6. Other stats: (step = 17418240, mean_episode_return = 64.051, mean_episode_step = 1093.3, total_loss = -215.27, pg_loss = -299.5, baseline_loss = 89.743, entropy_loss = -5.5119, learner_queue_size = 19, _tick = 4424, _time = 1.654e+09, train_seconds = 2628.2)
[2022-05-31 14:54:14,482][root][INFO] - Step 17448960 @ 6139.2 SPS. Inference batcher size: 83. Learner queue size: 23. Other stats: (step = 17448960, mean_episode_return = 54.94, mean_episode_step = 999.31, total_loss = 644.1, pg_loss = 426.44, baseline_loss = 223.25, entropy_loss = -5.5899, learner_queue_size = 28, _tick = 4434, _time = 1.654e+09, train_seconds = 2633.2)
[2022-05-31 14:54:19,488][root][INFO] - Step 17482240 @ 6647.5 SPS. Inference batcher size: 144. Learner queue size: 15. Other stats: (step = 17482240, mean_episode_return = 71.974, mean_episode_step = 1453.6, total_loss = 52.731, pg_loss = -39.451, baseline_loss = 97.876, entropy_loss = -5.6952, learner_queue_size = 19, _tick = 4447, _time = 1.654e+09, train_seconds = 2638.2)
[2022-05-31 14:54:24,494][root][INFO] - Step 17518080 @ 7159.9 SPS. Inference batcher size: 101. Learner queue size: 24. Other stats: (step = 17518080, mean_episode_return = 131.91, mean_episode_step = 986.52, total_loss = 117.24, pg_loss = 52.711, baseline_loss = 70.331, entropy_loss = -5.8027, learner_queue_size = 10, _tick = 4459, _time = 1.654e+09, train_seconds = 2643.2)
[2022-05-31 14:54:29,500][root][INFO] - Step 17548800 @ 6136.6 SPS. Inference batcher size: 121. Learner queue size: 26. Other stats: (step = 17548800, mean_episode_return = 257.05, mean_episode_step = 1093.8, total_loss = 289.89, pg_loss = 147.69, baseline_loss = 148.05, entropy_loss = -5.8493, learner_queue_size = 15, _tick = 4471, _time = 1.654e+09, train_seconds = 2648.2)
[2022-05-31 14:54:34,506][root][INFO] - Step 17582080 @ 6648.0 SPS. Inference batcher size: 84. Learner queue size: 18. Other stats: (step = 17582080, mean_episode_return = None, mean_episode_step = 1230.5, total_loss = 3.3359, pg_loss = -50.375, baseline_loss = 59.418, entropy_loss = -5.7064, learner_queue_size = 18, _tick = 4481, _time = 1.654e+09, train_seconds = 2653.2)
[2022-05-31 14:54:39,512][root][INFO] - Step 17615360 @ 6648.0 SPS. Inference batcher size: 103. Learner queue size: 20. Other stats: (step = 17615360, mean_episode_return = 52.61, mean_episode_step = 738.48, total_loss = -456.21, pg_loss = -494.07, baseline_loss = 43.521, entropy_loss = -5.6613, learner_queue_size = 21, _tick = 4493, _time = 1.654e+09, train_seconds = 2658.2)
[2022-05-31 14:54:44,518][root][INFO] - Step 17648640 @ 6648.1 SPS. Inference batcher size: 69. Learner queue size: 11. Other stats: (step = 17648640, mean_episode_return = 73.328, mean_episode_step = 1004.4, total_loss = 2418.8, pg_loss = 1370.0, baseline_loss = 1054.6, entropy_loss = -5.7278, learner_queue_size = 20, _tick = 4504, _time = 1.654e+09, train_seconds = 2663.2)
[2022-05-31 14:54:49,522][root][INFO] - Step 17681920 @ 6650.7 SPS. Inference batcher size: 169. Learner queue size: 16. Other stats: (step = 17681920, mean_episode_return = None, mean_episode_step = 1376.4, total_loss = 590.89, pg_loss = 428.48, baseline_loss = 168.39, entropy_loss = -5.9816, learner_queue_size = 14, _tick = 4515, _time = 1.654e+09, train_seconds = 2668.2)
[2022-05-31 14:54:54,526][root][INFO] - Step 17715200 @ 6650.8 SPS. Inference batcher size: 117. Learner queue size: 6. Other stats: (step = 17715200, mean_episode_return = 23.19, mean_episode_step = 869.63, total_loss = 218.28, pg_loss = 57.091, baseline_loss = 166.94, entropy_loss = -5.7571, learner_queue_size = 17, _tick = 4526, _time = 1.654e+09, train_seconds = 2673.2)
[2022-05-31 14:54:59,530][root][INFO] - Step 17748480 @ 6650.6 SPS. Inference batcher size: 170. Learner queue size: 29. Other stats: (step = 17748480, mean_episode_return = 22.465, mean_episode_step = 871.18, total_loss = -187.93, pg_loss = -240.34, baseline_loss = 58.469, entropy_loss = -6.0586, learner_queue_size = 13, _tick = 4536, _time = 1.654e+09, train_seconds = 2678.2)
[2022-05-31 14:55:04,534][root][INFO] - Step 17781760 @ 6650.8 SPS. Inference batcher size: 135. Learner queue size: 2. Other stats: (step = 17781760, mean_episode_return = None, mean_episode_step = 1029.8, total_loss = -38.58, pg_loss = -92.459, baseline_loss = 59.999, entropy_loss = -6.1201, learner_queue_size = 23, _tick = 4546, _time = 1.654e+09, train_seconds = 2683.2)
[2022-05-31 14:55:09,540][root][INFO] - Step 17812480 @ 6136.6 SPS. Inference batcher size: 106. Learner queue size: 18. Other stats: (step = 17812480, mean_episode_return = 39.485, mean_episode_step = 1047.4, total_loss = -115.44, pg_loss = -197.14, baseline_loss = 87.695, entropy_loss = -5.9907, learner_queue_size = 14, _tick = 4555, _time = 1.654e+09, train_seconds = 2688.2)
[2022-05-31 14:55:14,546][root][INFO] - Step 17845760 @ 6647.8 SPS. Inference batcher size: 90. Learner queue size: 21. Other stats: (step = 17845760, mean_episode_return = 51.104, mean_episode_step = 1125.9, total_loss = -153.74, pg_loss = -275.16, baseline_loss = 127.49, entropy_loss = -6.0719, learner_queue_size = 24, _tick = 4564, _time = 1.654e+09, train_seconds = 2693.2)
[2022-05-31 14:55:19,550][root][INFO] - Step 17879040 @ 6650.9 SPS. Inference batcher size: 120. Learner queue size: 9. Other stats: (step = 17879040, mean_episode_return = 123.08, mean_episode_step = 935.34, total_loss = 565.1, pg_loss = 373.4, baseline_loss = 197.5, entropy_loss = -5.8039, learner_queue_size = 24, _tick = 4576, _time = 1.654e+09, train_seconds = 2698.2)
[2022-05-31 14:55:24,554][root][INFO] - Step 17912320 @ 6650.7 SPS. Inference batcher size: 80. Learner queue size: 29. Other stats: (step = 17912320, mean_episode_return = None, mean_episode_step = 1091.8, total_loss = 119.64, pg_loss = 23.441, baseline_loss = 102.17, entropy_loss = -5.9669, learner_queue_size = 21, _tick = 4583, _time = 1.654e+09, train_seconds = 2703.2)
[2022-05-31 14:55:29,558][root][INFO] - Step 17945600 @ 6650.7 SPS. Inference batcher size: 152. Learner queue size: 28. Other stats: (step = 17945600, mean_episode_return = None, mean_episode_step = 1132.8, total_loss = -104.17, pg_loss = -123.58, baseline_loss = 25.298, entropy_loss = -5.8878, learner_queue_size = 19, _tick = 4592, _time = 1.654e+09, train_seconds = 2708.2)
[2022-05-31 14:55:34,564][root][INFO] - Step 17976320 @ 6136.5 SPS. Inference batcher size: 74. Learner queue size: 9. Other stats: (step = 17976320, mean_episode_return = None, mean_episode_step = 1124.6, total_loss = 214.69, pg_loss = 121.23, baseline_loss = 99.279, entropy_loss = -5.8252, learner_queue_size = 23, _tick = 4599, _time = 1.654e+09, train_seconds = 2713.2)
[2022-05-31 14:55:39,570][root][INFO] - Step 18009600 @ 6648.2 SPS. Inference batcher size: 112. Learner queue size: 11. Other stats: (step = 18009600, mean_episode_return = 22.54, mean_episode_step = 806.47, total_loss = -264.99, pg_loss = -294.88, baseline_loss = 35.55, entropy_loss = -5.6597, learner_queue_size = 25, _tick = 4611, _time = 1.654e+09, train_seconds = 2718.3)
[2022-05-31 14:55:44,574][root][INFO] - Step 18042880 @ 6650.5 SPS. Inference batcher size: 80. Learner queue size: 11. Other stats: (step = 18042880, mean_episode_return = None, mean_episode_step = 998.66, total_loss = 922.93, pg_loss = 671.14, baseline_loss = 257.69, entropy_loss = -5.8891, learner_queue_size = 20, _tick = 4620, _time = 1.654e+09, train_seconds = 2723.3)
[2022-05-31 14:55:49,578][root][INFO] - Step 18076160 @ 6650.6 SPS. Inference batcher size: 130. Learner queue size: 8. Other stats: (step = 18076160, mean_episode_return = 57.75, mean_episode_step = 1216.3, total_loss = 136.4, pg_loss = 53.241, baseline_loss = 89.19, entropy_loss = -6.03, learner_queue_size = 15, _tick = 4627, _time = 1.654e+09, train_seconds = 2728.3)
[2022-05-31 14:55:54,585][root][INFO] - Step 18109440 @ 6647.4 SPS. Inference batcher size: 97. Learner queue size: 4. Other stats: (step = 18109440, mean_episode_return = None, mean_episode_step = 1113.0, total_loss = 636.65, pg_loss = 492.52, baseline_loss = 150.24, entropy_loss = -6.1113, learner_queue_size = 20, _tick = 4635, _time = 1.654e+09, train_seconds = 2733.3)
[2022-05-31 14:55:59,591][root][INFO] - Step 18142720 @ 6648.2 SPS. Inference batcher size: 122. Learner queue size: 24. Other stats: (step = 18142720, mean_episode_return = None, mean_episode_step = 1088.3, total_loss = 396.34, pg_loss = 241.09, baseline_loss = 161.15, entropy_loss = -5.9013, learner_queue_size = 11, _tick = 4646, _time = 1.654e+09, train_seconds = 2738.3)
[2022-05-31 14:56:04,594][root][INFO] - Step 18176000 @ 6651.3 SPS. Inference batcher size: 48. Learner queue size: 23. Other stats: (step = 18176000, mean_episode_return = 103.09, mean_episode_step = 1149.9, total_loss = 1591.7, pg_loss = 674.39, baseline_loss = 923.06, entropy_loss = -5.7507, learner_queue_size = 18, _tick = 4658, _time = 1.654e+09, train_seconds = 2743.3)
[2022-05-31 14:56:09,598][root][INFO] - Step 18206720 @ 6139.2 SPS. Inference batcher size: 195. Learner queue size: 22. Other stats: (step = 18206720, mean_episode_return = 15.73, mean_episode_step = 966.05, total_loss = -226.66, pg_loss = -304.4, baseline_loss = 83.572, entropy_loss = -5.836, learner_queue_size = 21, _tick = 4667, _time = 1.654e+09, train_seconds = 2748.3)
[2022-05-31 14:56:14,604][root][INFO] - Step 18240000 @ 6647.9 SPS. Inference batcher size: 114. Learner queue size: 8. Other stats: (step = 18240000, mean_episode_return = 11.673, mean_episode_step = 983.6, total_loss = -235.18, pg_loss = -278.44, baseline_loss = 49.038, entropy_loss = -5.7852, learner_queue_size = 16, _tick = 4674, _time = 1.654e+09, train_seconds = 2753.3)
[2022-05-31 14:56:19,610][root][INFO] - Step 18273280 @ 6648.0 SPS. Inference batcher size: 45. Learner queue size: 12. Other stats: (step = 18273280, mean_episode_return = 70.505, mean_episode_step = 993.53, total_loss = -255.79, pg_loss = -329.96, baseline_loss = 79.98, entropy_loss = -5.8107, learner_queue_size = 32, _tick = 4684, _time = 1.654e+09, train_seconds = 2758.3)
[2022-05-31 14:56:24,615][root][INFO] - Step 18306560 @ 6649.3 SPS. Inference batcher size: 89. Learner queue size: 11. Other stats: (step = 18306560, mean_episode_return = 107.14, mean_episode_step = 1242.3, total_loss = -197.18, pg_loss = -208.52, baseline_loss = 16.957, entropy_loss = -5.6209, learner_queue_size = 24, _tick = 4693, _time = 1.654e+09, train_seconds = 2763.3)
[2022-05-31 14:56:29,619][root][INFO] - Step 18339840 @ 6650.8 SPS. Inference batcher size: 134. Learner queue size: 13. Other stats: (step = 18339840, mean_episode_return = 60.652, mean_episode_step = 982.48, total_loss = -325.41, pg_loss = -390.38, baseline_loss = 70.844, entropy_loss = -5.8774, learner_queue_size = 22, _tick = 4702, _time = 1.654e+09, train_seconds = 2768.3)
[2022-05-31 14:56:34,622][root][INFO] - Step 18373120 @ 6652.1 SPS. Inference batcher size: 142. Learner queue size: 15. Other stats: (step = 18373120, mean_episode_return = None, mean_episode_step = 1125.7, total_loss = 3.7116, pg_loss = -22.103, baseline_loss = 31.845, entropy_loss = -6.0303, learner_queue_size = 23, _tick = 4711, _time = 1.654e+09, train_seconds = 2773.3)
[2022-05-31 14:56:39,626][root][INFO] - Step 18406400 @ 6650.6 SPS. Inference batcher size: 148. Learner queue size: 20. Other stats: (step = 18406400, mean_episode_return = 98.07, mean_episode_step = 1068.2, total_loss = 38.308, pg_loss = -30.99, baseline_loss = 75.228, entropy_loss = -5.9299, learner_queue_size = 22, _tick = 4720, _time = 1.654e+09, train_seconds = 2778.3)
[2022-05-31 14:56:44,632][root][INFO] - Step 18439680 @ 6647.9 SPS. Inference batcher size: 138. Learner queue size: 1. Other stats: (step = 18439680, mean_episode_return = 24.671, mean_episode_step = 1142.2, total_loss = -69.034, pg_loss = -105.81, baseline_loss = 42.711, entropy_loss = -5.9345, learner_queue_size = 22, _tick = 4731, _time = 1.654e+09, train_seconds = 2783.3)
[2022-05-31 14:56:49,638][root][INFO] - Step 18472960 @ 6648.2 SPS. Inference batcher size: 64. Learner queue size: 29. Other stats: (step = 18472960, mean_episode_return = 89.208, mean_episode_step = 897.27, total_loss = 90.895, pg_loss = 31.818, baseline_loss = 65.278, entropy_loss = -6.2013, learner_queue_size = 24, _tick = 4741, _time = 1.654e+09, train_seconds = 2788.3)
[2022-05-31 14:56:54,645][root][INFO] - Step 18506240 @ 6647.3 SPS. Inference batcher size: 25. Learner queue size: 24. Other stats: (step = 18506240, mean_episode_return = 19.93, mean_episode_step = 1142.8, total_loss = 4.1788, pg_loss = -69.238, baseline_loss = 79.459, entropy_loss = -6.0428, learner_queue_size = 10, _tick = 4750, _time = 1.654e+09, train_seconds = 2793.3)
[2022-05-31 14:56:59,651][root][INFO] - Step 18539520 @ 6647.5 SPS. Inference batcher size: 114. Learner queue size: 3. Other stats: (step = 18539520, mean_episode_return = 19.16, mean_episode_step = 1014.5, total_loss = 138.55, pg_loss = -56.154, baseline_loss = 200.66, entropy_loss = -5.9532, learner_queue_size = 21, _tick = 4761, _time = 1.654e+09, train_seconds = 2798.3)
[2022-05-31 14:57:04,657][root][INFO] - Step 18570240 @ 6136.6 SPS. Inference batcher size: 93. Learner queue size: 26. Other stats: (step = 18570240, mean_episode_return = 47.62, mean_episode_step = 1140.8, total_loss = 982.64, pg_loss = 705.58, baseline_loss = 283.05, entropy_loss = -5.981, learner_queue_size = 11, _tick = 4770, _time = 1.654e+09, train_seconds = 2803.3)
[2022-05-31 14:57:09,662][root][INFO] - Step 18606080 @ 7160.8 SPS. Inference batcher size: 131. Learner queue size: 24. Other stats: (step = 18606080, mean_episode_return = None, mean_episode_step = 1020.8, total_loss = -205.23, pg_loss = -222.79, baseline_loss = 23.568, entropy_loss = -6.0066, learner_queue_size = 20, _tick = 4780, _time = 1.654e+09, train_seconds = 2808.3)
[2022-05-31 14:57:14,668][root][INFO] - Step 18636800 @ 6136.6 SPS. Inference batcher size: 191. Learner queue size: 15. Other stats: (step = 18636800, mean_episode_return = 69.625, mean_episode_step = 965.77, total_loss = 188.98, pg_loss = 84.091, baseline_loss = 111.08, entropy_loss = -6.1899, learner_queue_size = 13, _tick = 4790, _time = 1.654e+09, train_seconds = 2813.4)
[2022-05-31 14:57:19,674][root][INFO] - Step 18670080 @ 6648.0 SPS. Inference batcher size: 134. Learner queue size: 19. Other stats: (step = 18670080, mean_episode_return = 36.377, mean_episode_step = 1034.3, total_loss = 263.03, pg_loss = 139.46, baseline_loss = 129.47, entropy_loss = -5.8985, learner_queue_size = 17, _tick = 4802, _time = 1.654e+09, train_seconds = 2818.4)
[2022-05-31 14:57:24,678][root][INFO] - Step 18703360 @ 6650.6 SPS. Inference batcher size: 154. Learner queue size: 0. Other stats: (step = 18703360, mean_episode_return = 25.265, mean_episode_step = 1140.5, total_loss = 404.43, pg_loss = 317.87, baseline_loss = 92.516, entropy_loss = -5.9482, learner_queue_size = 26, _tick = 4812, _time = 1.654e+09, train_seconds = 2823.4)
[2022-05-31 14:57:29,684][root][INFO] - Step 18736640 @ 6647.8 SPS. Inference batcher size: 131. Learner queue size: 3. Other stats: (step = 18736640, mean_episode_return = None, mean_episode_step = 1044.4, total_loss = 81.584, pg_loss = 6.2347, baseline_loss = 81.332, entropy_loss = -5.9824, learner_queue_size = 21, _tick = 4824, _time = 1.654e+09, train_seconds = 2828.4)
[2022-05-31 14:57:34,691][root][INFO] - Step 18769920 @ 6647.8 SPS. Inference batcher size: 17. Learner queue size: 3. Other stats: (step = 18769920, mean_episode_return = 117.58, mean_episode_step = 1235.0, total_loss = 79.405, pg_loss = -66.244, baseline_loss = 151.83, entropy_loss = -6.1842, learner_queue_size = 23, _tick = 4833, _time = 1.654e+09, train_seconds = 2833.4)
[2022-05-31 14:57:39,697][root][INFO] - Step 18803200 @ 6647.3 SPS. Inference batcher size: 45. Learner queue size: 3. Other stats: (step = 18803200, mean_episode_return = None, mean_episode_step = 1106.5, total_loss = -112.83, pg_loss = -153.91, baseline_loss = 47.281, entropy_loss = -6.2055, learner_queue_size = 16, _tick = 4842, _time = 1.654e+09, train_seconds = 2838.4)
[2022-05-31 14:57:44,702][root][INFO] - Step 18836480 @ 6649.3 SPS. Inference batcher size: 82. Learner queue size: 0. Other stats: (step = 18836480, mean_episode_return = 22.981, mean_episode_step = 1156.1, total_loss = 46.603, pg_loss = 4.5936, baseline_loss = 48.216, entropy_loss = -6.2058, learner_queue_size = 19, _tick = 4851, _time = 1.654e+09, train_seconds = 2843.4)
[2022-05-31 14:57:49,706][root][INFO] - Step 18869760 @ 6650.7 SPS. Inference batcher size: 105. Learner queue size: 26. Other stats: (step = 18869760, mean_episode_return = None, mean_episode_step = 1369.2, total_loss = -83.475, pg_loss = -144.08, baseline_loss = 66.834, entropy_loss = -6.2251, learner_queue_size = 21, _tick = 4860, _time = 1.654e+09, train_seconds = 2848.4)
[2022-05-31 14:57:54,710][root][INFO] - Step 18903040 @ 6650.6 SPS. Inference batcher size: 86. Learner queue size: 20. Other stats: (step = 18903040, mean_episode_return = 159.95, mean_episode_step = 972.01, total_loss = -83.728, pg_loss = -125.28, baseline_loss = 47.45, entropy_loss = -5.8975, learner_queue_size = 19, _tick = 4868, _time = 1.654e+09, train_seconds = 2853.4)
[2022-05-31 14:57:59,716][root][INFO] - Step 18933760 @ 6136.5 SPS. Inference batcher size: 53. Learner queue size: 15. Other stats: (step = 18933760, mean_episode_return = None, mean_episode_step = 1041.3, total_loss = -142.56, pg_loss = -198.04, baseline_loss = 61.429, entropy_loss = -5.9506, learner_queue_size = 18, _tick = 4873, _time = 1.654e+09, train_seconds = 2858.4)
[2022-05-31 14:58:04,722][root][INFO] - Step 18967040 @ 6648.2 SPS. Inference batcher size: 132. Learner queue size: 11. Other stats: (step = 18967040, mean_episode_return = 34.121, mean_episode_step = 1366.3, total_loss = -278.98, pg_loss = -349.16, baseline_loss = 76.029, entropy_loss = -5.8497, learner_queue_size = 23, _tick = 4882, _time = 1.654e+09, train_seconds = 2863.4)
[2022-05-31 14:58:09,728][root][INFO] - Step 19002880 @ 7159.2 SPS. Inference batcher size: 178. Learner queue size: 16. Other stats: (step = 19002880, mean_episode_return = 108.74, mean_episode_step = 1155.4, total_loss = -210.92, pg_loss = -235.4, baseline_loss = 30.228, entropy_loss = -5.7492, learner_queue_size = 14, _tick = 4891, _time = 1.654e+09, train_seconds = 2868.4)
[2022-05-31 14:58:14,735][root][INFO] - Step 19033600 @ 6135.5 SPS. Inference batcher size: 160. Learner queue size: 18. Other stats: (step = 19033600, mean_episode_return = 104.12, mean_episode_step = 1424.3, total_loss = 330.59, pg_loss = 160.13, baseline_loss = 176.41, entropy_loss = -5.9527, learner_queue_size = 26, _tick = 4898, _time = 1.654e+09, train_seconds = 2873.4)
[2022-05-31 14:58:19,738][root][INFO] - Step 19069440 @ 7163.8 SPS. Inference batcher size: 128. Learner queue size: 15. Other stats: (step = 19069440, mean_episode_return = 80.799, mean_episode_step = 1034.9, total_loss = 680.64, pg_loss = 518.01, baseline_loss = 168.77, entropy_loss = -6.1411, learner_queue_size = 7, _tick = 4910, _time = 1.654e+09, train_seconds = 2878.4)
[2022-05-31 14:58:24,742][root][INFO] - Step 19100160 @ 6139.0 SPS. Inference batcher size: 120. Learner queue size: 11. Other stats: (step = 19100160, mean_episode_return = None, mean_episode_step = 1108.7, total_loss = -68.211, pg_loss = -102.92, baseline_loss = 40.818, entropy_loss = -6.1048, learner_queue_size = 16, _tick = 4919, _time = 1.654e+09, train_seconds = 2883.4)
[2022-05-31 14:58:29,747][root][INFO] - Step 19133440 @ 6649.6 SPS. Inference batcher size: 175. Learner queue size: 6. Other stats: (step = 19133440, mean_episode_return = None, mean_episode_step = 1325.1, total_loss = 258.71, pg_loss = 142.77, baseline_loss = 122.07, entropy_loss = -6.1301, learner_queue_size = 17, _tick = 4929, _time = 1.654e+09, train_seconds = 2888.4)
[2022-05-31 14:58:34,750][root][INFO] - Step 19166720 @ 6651.9 SPS. Inference batcher size: 65. Learner queue size: 5. Other stats: (step = 19166720, mean_episode_return = 33.665, mean_episode_step = 1123.4, total_loss = -100.35, pg_loss = -210.14, baseline_loss = 115.81, entropy_loss = -6.0303, learner_queue_size = 16, _tick = 4941, _time = 1.654e+09, train_seconds = 2893.4)
[2022-05-31 14:58:39,754][root][INFO] - Step 19200000 @ 6650.6 SPS. Inference batcher size: 125. Learner queue size: 2. Other stats: (step = 19200000, mean_episode_return = 27.931, mean_episode_step = 943.32, total_loss = -206.44, pg_loss = -238.57, baseline_loss = 38.157, entropy_loss = -6.0282, learner_queue_size = 11, _tick = 4951, _time = 1.654e+09, train_seconds = 2898.4)
[2022-05-31 14:58:44,758][root][INFO] - Step 19233280 @ 6650.7 SPS. Inference batcher size: 103. Learner queue size: 2. Other stats: (step = 19233280, mean_episode_return = 59.853, mean_episode_step = 1178.8, total_loss = -24.902, pg_loss = -149.99, baseline_loss = 131.29, entropy_loss = -6.2033, learner_queue_size = 16, _tick = 4963, _time = 1.654e+09, train_seconds = 2903.4)
[2022-05-31 14:58:49,762][root][INFO] - Step 19266560 @ 6650.7 SPS. Inference batcher size: 114. Learner queue size: 23. Other stats: (step = 19266560, mean_episode_return = 22.403, mean_episode_step = 796.49, total_loss = -417.66, pg_loss = -617.84, baseline_loss = 206.05, entropy_loss = -5.8671, learner_queue_size = 15, _tick = 4972, _time = 1.654e+09, train_seconds = 2908.4)
[2022-05-31 14:58:54,766][root][INFO] - Step 19299840 @ 6650.7 SPS. Inference batcher size: 122. Learner queue size: 19. Other stats: (step = 19299840, mean_episode_return = 15.84, mean_episode_step = 1109.3, total_loss = -10.84, pg_loss = -83.819, baseline_loss = 79.026, entropy_loss = -6.0475, learner_queue_size = 16, _tick = 4983, _time = 1.654e+09, train_seconds = 2913.5)
[2022-05-31 14:58:59,770][root][INFO] - Step 19333120 @ 6650.7 SPS. Inference batcher size: 1. Learner queue size: 30. Other stats: (step = 19333120, mean_episode_return = 91.399, mean_episode_step = 1234.5, total_loss = 226.67, pg_loss = 127.72, baseline_loss = 105.13, entropy_loss = -6.1786, learner_queue_size = 25, _tick = 4992, _time = 1.654e+09, train_seconds = 2918.5)
[2022-05-31 14:59:04,777][root][INFO] - Step 19363840 @ 6135.8 SPS. Inference batcher size: 119. Learner queue size: 22. Other stats: (step = 19363840, mean_episode_return = 104.87, mean_episode_step = 978.82, total_loss = -303.49, pg_loss = -454.89, baseline_loss = 157.33, entropy_loss = -5.9305, learner_queue_size = 13, _tick = 5001, _time = 1.654e+09, train_seconds = 2923.5)
[2022-05-31 14:59:09,782][root][INFO] - Step 19399680 @ 7160.3 SPS. Inference batcher size: 25. Learner queue size: 18. Other stats: (step = 19399680, mean_episode_return = 71.632, mean_episode_step = 1058.1, total_loss = -4.8116, pg_loss = -59.008, baseline_loss = 60.312, entropy_loss = -6.1152, learner_queue_size = 14, _tick = 5011, _time = 1.654e+09, train_seconds = 2928.5)
[2022-05-31 14:59:14,789][root][INFO] - Step 19430400 @ 6135.4 SPS. Inference batcher size: 95. Learner queue size: 21. Other stats: (step = 19430400, mean_episode_return = 92.469, mean_episode_step = 974.45, total_loss = -238.81, pg_loss = -309.84, baseline_loss = 77.262, entropy_loss = -6.2341, learner_queue_size = 20, _tick = 5022, _time = 1.654e+09, train_seconds = 2933.5)
[2022-05-31 14:59:19,795][root][INFO] - Step 19463680 @ 6648.1 SPS. Inference batcher size: 94. Learner queue size: 8. Other stats: (step = 19463680, mean_episode_return = 94.176, mean_episode_step = 1024.8, total_loss = -141.32, pg_loss = -238.86, baseline_loss = 103.73, entropy_loss = -6.1884, learner_queue_size = 19, _tick = 5033, _time = 1.654e+09, train_seconds = 2938.5)
[2022-05-31 14:59:24,798][root][INFO] - Step 19496960 @ 6652.1 SPS. Inference batcher size: 105. Learner queue size: 7. Other stats: (step = 19496960, mean_episode_return = 43.016, mean_episode_step = 908.83, total_loss = 5.3322, pg_loss = -68.451, baseline_loss = 79.914, entropy_loss = -6.1313, learner_queue_size = 23, _tick = 5041, _time = 1.654e+09, train_seconds = 2943.5)
[2022-05-31 14:59:29,804][root][INFO] - Step 19530240 @ 6648.0 SPS. Inference batcher size: 98. Learner queue size: 5. Other stats: (step = 19530240, mean_episode_return = 58.56, mean_episode_step = 1267.0, total_loss = -268.2, pg_loss = -338.35, baseline_loss = 76.658, entropy_loss = -6.5124, learner_queue_size = 15, _tick = 5052, _time = 1.654e+09, train_seconds = 2948.5)
[2022-05-31 14:59:34,806][root][INFO] - Step 19563520 @ 6653.4 SPS. Inference batcher size: 50. Learner queue size: 2. Other stats: (step = 19563520, mean_episode_return = 19.13, mean_episode_step = 943.55, total_loss = 122.09, pg_loss = 72.286, baseline_loss = 56.399, entropy_loss = -6.5948, learner_queue_size = 19, _tick = 5064, _time = 1.654e+09, train_seconds = 2953.5)
[2022-05-31 14:59:39,812][root][INFO] - Step 19596800 @ 6648.0 SPS. Inference batcher size: 101. Learner queue size: 5. Other stats: (step = 19596800, mean_episode_return = 20.24, mean_episode_step = 983.08, total_loss = -32.527, pg_loss = -263.1, baseline_loss = 236.91, entropy_loss = -6.3299, learner_queue_size = 22, _tick = 5074, _time = 1.654e+09, train_seconds = 2958.5)
[2022-05-31 14:59:44,814][root][INFO] - Step 19630080 @ 6653.4 SPS. Inference batcher size: 124. Learner queue size: 1. Other stats: (step = 19630080, mean_episode_return = None, mean_episode_step = 897.81, total_loss = -11.097, pg_loss = -91.896, baseline_loss = 86.943, entropy_loss = -6.1445, learner_queue_size = 22, _tick = 5083, _time = 1.654e+09, train_seconds = 2963.5)
[2022-05-31 14:59:49,818][root][INFO] - Step 19663360 @ 6650.5 SPS. Inference batcher size: 138. Learner queue size: 23. Other stats: (step = 19663360, mean_episode_return = 11.6, mean_episode_step = 939.29, total_loss = 297.15, pg_loss = 147.85, baseline_loss = 155.85, entropy_loss = -6.5504, learner_queue_size = 23, _tick = 5092, _time = 1.654e+09, train_seconds = 2968.5)
[2022-05-31 14:59:54,824][root][INFO] - Step 19694080 @ 6136.5 SPS. Inference batcher size: 163. Learner queue size: 19. Other stats: (step = 19694080, mean_episode_return = 32.013, mean_episode_step = 1145.0, total_loss = 477.54, pg_loss = 337.98, baseline_loss = 146.29, entropy_loss = -6.7341, learner_queue_size = 18, _tick = 5102, _time = 1.654e+09, train_seconds = 2973.5)
[2022-05-31 14:59:59,830][root][INFO] - Step 19727360 @ 6648.3 SPS. Inference batcher size: 155. Learner queue size: 18. Other stats: (step = 19727360, mean_episode_return = 55.19, mean_episode_step = 907.04, total_loss = 471.6, pg_loss = 294.97, baseline_loss = 182.67, entropy_loss = -6.0432, learner_queue_size = 22, _tick = 5111, _time = 1.654e+09, train_seconds = 2978.5)
[2022-05-31 15:00:04,834][root][INFO] - Step 19763200 @ 7162.2 SPS. Inference batcher size: 81. Learner queue size: 17. Other stats: (step = 19763200, mean_episode_return = 90.47, mean_episode_step = 1025.9, total_loss = -373.15, pg_loss = -377.71, baseline_loss = 11.004, entropy_loss = -6.4445, learner_queue_size = 16, _tick = 5121, _time = 1.654e+09, train_seconds = 2983.5)
[2022-05-31 15:00:09,838][root][INFO] - Step 19793920 @ 6139.1 SPS. Inference batcher size: 140. Learner queue size: 12. Other stats: (step = 19793920, mean_episode_return = 51.215, mean_episode_step = 895.62, total_loss = -10.308, pg_loss = -99.134, baseline_loss = 95.447, entropy_loss = -6.6208, learner_queue_size = 11, _tick = 5131, _time = 1.654e+09, train_seconds = 2988.5)
[2022-05-31 15:00:14,842][root][INFO] - Step 19827200 @ 6650.6 SPS. Inference batcher size: 84. Learner queue size: 13. Other stats: (step = 19827200, mean_episode_return = None, mean_episode_step = 1009.6, total_loss = 734.36, pg_loss = 564.43, baseline_loss = 176.66, entropy_loss = -6.7283, learner_queue_size = 26, _tick = 5142, _time = 1.654e+09, train_seconds = 2993.5)
[2022-05-31 15:00:19,846][root][INFO] - Step 19860480 @ 6650.6 SPS. Inference batcher size: 86. Learner queue size: 11. Other stats: (step = 19860480, mean_episode_return = 92.24, mean_episode_step = 688.48, total_loss = -32.435, pg_loss = -106.28, baseline_loss = 80.108, entropy_loss = -6.2661, learner_queue_size = 25, _tick = 5153, _time = 1.654e+09, train_seconds = 2998.5)
[2022-05-31 15:00:24,850][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 15:00:25,047][root][INFO] - Step 19893760 @ 6650.8 SPS. Inference batcher size: 54. Learner queue size: 28. Other stats: (step = 19893760, mean_episode_return = 84.201, mean_episode_step = 918.41, total_loss = 223.74, pg_loss = 67.134, baseline_loss = 162.78, entropy_loss = -6.1751, learner_queue_size = 20, _tick = 5164, _time = 1.654e+09, train_seconds = 3003.5)
[2022-05-31 15:00:30,050][root][INFO] - Step 19929600 @ 6892.3 SPS. Inference batcher size: 132. Learner queue size: 26. Other stats: (step = 19929600, mean_episode_return = 56.866, mean_episode_step = 992.83, total_loss = -260.9, pg_loss = -292.13, baseline_loss = 37.966, entropy_loss = -6.7339, learner_queue_size = 15, _tick = 5176, _time = 1.654e+09, train_seconds = 3008.7)
[2022-05-31 15:00:35,056][root][INFO] - Step 19960320 @ 6136.6 SPS. Inference batcher size: 108. Learner queue size: 19. Other stats: (step = 19960320, mean_episode_return = 47.4, mean_episode_step = 803.89, total_loss = 511.77, pg_loss = 418.15, baseline_loss = 100.06, entropy_loss = -6.4414, learner_queue_size = 12, _tick = 5184, _time = 1.654e+09, train_seconds = 3013.7)
[2022-05-31 15:00:40,062][root][INFO] - Step 19993600 @ 6648.0 SPS. Inference batcher size: 114. Learner queue size: 18. Other stats: (step = 19993600, mean_episode_return = 72.41, mean_episode_step = 759.25, total_loss = 313.93, pg_loss = 26.503, baseline_loss = 293.81, entropy_loss = -6.3853, learner_queue_size = 20, _tick = 5195, _time = 1.654e+09, train_seconds = 3018.7)
[2022-05-31 15:00:45,066][root][INFO] - Step 20026880 @ 6650.7 SPS. Inference batcher size: 123. Learner queue size: 20. Other stats: (step = 20026880, mean_episode_return = 94.3, mean_episode_step = 746.38, total_loss = 50.633, pg_loss = -21.451, baseline_loss = 78.018, entropy_loss = -5.9339, learner_queue_size = 25, _tick = 5206, _time = 1.654e+09, train_seconds = 3023.8)
[2022-05-31 15:00:50,070][root][INFO] - Step 20060160 @ 6650.7 SPS. Inference batcher size: 109. Learner queue size: 11. Other stats: (step = 20060160, mean_episode_return = 3.8496, mean_episode_step = 1063.5, total_loss = 6.3045, pg_loss = -164.16, baseline_loss = 176.41, entropy_loss = -5.954, learner_queue_size = 26, _tick = 5215, _time = 1.654e+09, train_seconds = 3028.8)
[2022-05-31 15:00:55,075][root][INFO] - Step 20093440 @ 6648.8 SPS. Inference batcher size: 7. Learner queue size: 7. Other stats: (step = 20093440, mean_episode_return = 70.633, mean_episode_step = 893.64, total_loss = -345.41, pg_loss = -388.66, baseline_loss = 49.309, entropy_loss = -6.0571, learner_queue_size = 15, _tick = 5223, _time = 1.654e+09, train_seconds = 3033.8)
[2022-05-31 15:01:00,082][root][INFO] - Step 20126720 @ 6647.7 SPS. Inference batcher size: 85. Learner queue size: 25. Other stats: (step = 20126720, mean_episode_return = 123.08, mean_episode_step = 994.74, total_loss = 498.7, pg_loss = 343.47, baseline_loss = 160.86, entropy_loss = -5.6325, learner_queue_size = 15, _tick = 5233, _time = 1.654e+09, train_seconds = 3038.8)
[2022-05-31 15:01:05,086][root][INFO] - Step 20160000 @ 6650.2 SPS. Inference batcher size: 155. Learner queue size: 20. Other stats: (step = 20160000, mean_episode_return = None, mean_episode_step = 1157.3, total_loss = 529.76, pg_loss = 372.2, baseline_loss = 163.72, entropy_loss = -6.1597, learner_queue_size = 18, _tick = 5243, _time = 1.654e+09, train_seconds = 3043.8)
[2022-05-31 15:01:10,090][root][INFO] - Step 20193280 @ 6650.7 SPS. Inference batcher size: 137. Learner queue size: 22. Other stats: (step = 20193280, mean_episode_return = 32.99, mean_episode_step = 923.72, total_loss = 357.54, pg_loss = 215.68, baseline_loss = 147.56, entropy_loss = -5.7139, learner_queue_size = 20, _tick = 5253, _time = 1.654e+09, train_seconds = 3048.8)
[2022-05-31 15:01:15,097][root][INFO] - Step 20224000 @ 6135.8 SPS. Inference batcher size: 76. Learner queue size: 15. Other stats: (step = 20224000, mean_episode_return = 44.593, mean_episode_step = 981.86, total_loss = 955.67, pg_loss = 505.78, baseline_loss = 455.49, entropy_loss = -5.6017, learner_queue_size = 21, _tick = 5263, _time = 1.654e+09, train_seconds = 3053.8)
[2022-05-31 15:01:20,103][root][INFO] - Step 20257280 @ 6648.0 SPS. Inference batcher size: 127. Learner queue size: 18. Other stats: (step = 20257280, mean_episode_return = 61.121, mean_episode_step = 850.58, total_loss = 209.28, pg_loss = 132.41, baseline_loss = 82.971, entropy_loss = -6.1044, learner_queue_size = 23, _tick = 5272, _time = 1.654e+09, train_seconds = 3058.8)
[2022-05-31 15:01:25,109][root][INFO] - Step 20290560 @ 6647.9 SPS. Inference batcher size: 140. Learner queue size: 20. Other stats: (step = 20290560, mean_episode_return = 81.65, mean_episode_step = 1046.7, total_loss = 730.29, pg_loss = 543.18, baseline_loss = 193.43, entropy_loss = -6.3138, learner_queue_size = 23, _tick = 5281, _time = 1.654e+09, train_seconds = 3063.8)
[2022-05-31 15:01:30,115][root][INFO] - Step 20323840 @ 6647.9 SPS. Inference batcher size: 101. Learner queue size: 20. Other stats: (step = 20323840, mean_episode_return = None, mean_episode_step = 721.03, total_loss = 237.7, pg_loss = 154.92, baseline_loss = 88.775, entropy_loss = -5.9983, learner_queue_size = 19, _tick = 5290, _time = 1.654e+09, train_seconds = 3068.8)
[2022-05-31 15:01:35,122][root][INFO] - Step 20357120 @ 6647.3 SPS. Inference batcher size: 169. Learner queue size: 19. Other stats: (step = 20357120, mean_episode_return = None, mean_episode_step = 938.47, total_loss = 202.21, pg_loss = 83.998, baseline_loss = 124.64, entropy_loss = -6.4293, learner_queue_size = 28, _tick = 5299, _time = 1.654e+09, train_seconds = 3073.8)
[2022-05-31 15:01:40,128][root][INFO] - Step 20390400 @ 6646.8 SPS. Inference batcher size: 97. Learner queue size: 15. Other stats: (step = 20390400, mean_episode_return = 153.0, mean_episode_step = 834.12, total_loss = 170.15, pg_loss = 106.08, baseline_loss = 70.202, entropy_loss = -6.1344, learner_queue_size = 8, _tick = 5311, _time = 1.654e+09, train_seconds = 3078.8)
[2022-05-31 15:01:45,134][root][INFO] - Step 20423680 @ 6648.6 SPS. Inference batcher size: 86. Learner queue size: 16. Other stats: (step = 20423680, mean_episode_return = 83.551, mean_episode_step = 1043.5, total_loss = -243.74, pg_loss = -294.87, baseline_loss = 57.351, entropy_loss = -6.2222, learner_queue_size = 14, _tick = 5321, _time = 1.654e+09, train_seconds = 3083.8)
[2022-05-31 15:01:50,140][root][INFO] - Step 20456960 @ 6647.4 SPS. Inference batcher size: 134. Learner queue size: 13. Other stats: (step = 20456960, mean_episode_return = 40.74, mean_episode_step = 978.05, total_loss = 975.4, pg_loss = 714.2, baseline_loss = 267.54, entropy_loss = -6.3422, learner_queue_size = 16, _tick = 5332, _time = 1.654e+09, train_seconds = 3088.8)
[2022-05-31 15:01:55,146][root][INFO] - Step 20490240 @ 6648.2 SPS. Inference batcher size: 110. Learner queue size: 9. Other stats: (step = 20490240, mean_episode_return = 118.42, mean_episode_step = 757.74, total_loss = 65.048, pg_loss = -16.512, baseline_loss = 87.17, entropy_loss = -5.6096, learner_queue_size = 21, _tick = 5345, _time = 1.654e+09, train_seconds = 3093.8)
[2022-05-31 15:02:00,151][root][INFO] - Step 20523520 @ 6650.4 SPS. Inference batcher size: 95. Learner queue size: 12. Other stats: (step = 20523520, mean_episode_return = 48.416, mean_episode_step = 942.66, total_loss = 411.36, pg_loss = 317.5, baseline_loss = 99.96, entropy_loss = -6.094, learner_queue_size = 18, _tick = 5355, _time = 1.654e+09, train_seconds = 3098.8)
[2022-05-31 15:02:05,154][root][INFO] - Step 20556800 @ 6651.3 SPS. Inference batcher size: 148. Learner queue size: 8. Other stats: (step = 20556800, mean_episode_return = 20.36, mean_episode_step = 994.46, total_loss = 159.03, pg_loss = 100.25, baseline_loss = 64.747, entropy_loss = -5.9686, learner_queue_size = 23, _tick = 5364, _time = 1.654e+09, train_seconds = 3103.8)
[2022-05-31 15:02:10,158][root][INFO] - Step 20590080 @ 6650.7 SPS. Inference batcher size: 71. Learner queue size: 15. Other stats: (step = 20590080, mean_episode_return = 34.861, mean_episode_step = 826.77, total_loss = -415.28, pg_loss = -446.64, baseline_loss = 37.023, entropy_loss = -5.6608, learner_queue_size = 14, _tick = 5376, _time = 1.654e+09, train_seconds = 3108.8)
[2022-05-31 15:02:15,162][root][INFO] - Step 20623360 @ 6650.7 SPS. Inference batcher size: 120. Learner queue size: 20. Other stats: (step = 20623360, mean_episode_return = 18.26, mean_episode_step = 888.84, total_loss = 498.13, pg_loss = 315.7, baseline_loss = 188.49, entropy_loss = -6.065, learner_queue_size = 30, _tick = 5385, _time = 1.654e+09, train_seconds = 3113.8)
[2022-05-31 15:02:20,166][root][INFO] - Step 20656640 @ 6650.6 SPS. Inference batcher size: 52. Learner queue size: 4. Other stats: (step = 20656640, mean_episode_return = 61.879, mean_episode_step = 894.07, total_loss = 1154.8, pg_loss = 832.19, baseline_loss = 328.62, entropy_loss = -5.9681, learner_queue_size = 21, _tick = 5394, _time = 1.654e+09, train_seconds = 3118.9)
[2022-05-31 15:02:25,172][root][INFO] - Step 20689920 @ 6647.9 SPS. Inference batcher size: 53. Learner queue size: 2. Other stats: (step = 20689920, mean_episode_return = 67.515, mean_episode_step = 918.24, total_loss = 60.459, pg_loss = 2.3938, baseline_loss = 63.638, entropy_loss = -5.5725, learner_queue_size = 24, _tick = 5406, _time = 1.654e+09, train_seconds = 3123.9)
[2022-05-31 15:02:30,178][root][INFO] - Step 20723200 @ 6648.3 SPS. Inference batcher size: 16. Learner queue size: 3. Other stats: (step = 20723200, mean_episode_return = 50.205, mean_episode_step = 1001.2, total_loss = 348.0, pg_loss = 216.83, baseline_loss = 137.46, entropy_loss = -6.2807, learner_queue_size = 19, _tick = 5413, _time = 1.654e+09, train_seconds = 3128.9)
[2022-05-31 15:02:35,184][root][INFO] - Step 20756480 @ 6648.2 SPS. Inference batcher size: 88. Learner queue size: 6. Other stats: (step = 20756480, mean_episode_return = 19.09, mean_episode_step = 1076.2, total_loss = -88.883, pg_loss = -171.28, baseline_loss = 88.229, entropy_loss = -5.8277, learner_queue_size = 19, _tick = 5424, _time = 1.654e+09, train_seconds = 3133.9)
[2022-05-31 15:02:40,190][root][INFO] - Step 20789760 @ 6648.1 SPS. Inference batcher size: 91. Learner queue size: 4. Other stats: (step = 20789760, mean_episode_return = 22.16, mean_episode_step = 1033.5, total_loss = -206.33, pg_loss = -286.56, baseline_loss = 86.597, entropy_loss = -6.3672, learner_queue_size = 24, _tick = 5434, _time = 1.654e+09, train_seconds = 3138.9)
[2022-05-31 15:02:45,194][root][INFO] - Step 20823040 @ 6650.4 SPS. Inference batcher size: 31. Learner queue size: 0. Other stats: (step = 20823040, mean_episode_return = 77.98, mean_episode_step = 1074.1, total_loss = -132.92, pg_loss = -191.22, baseline_loss = 64.372, entropy_loss = -6.0647, learner_queue_size = 26, _tick = 5443, _time = 1.654e+09, train_seconds = 3143.9)
[2022-05-31 15:02:50,198][root][INFO] - Step 20856320 @ 6650.5 SPS. Inference batcher size: 130. Learner queue size: 3. Other stats: (step = 20856320, mean_episode_return = 93.555, mean_episode_step = 936.19, total_loss = -159.81, pg_loss = -200.78, baseline_loss = 47.364, entropy_loss = -6.3925, learner_queue_size = 15, _tick = 5455, _time = 1.654e+09, train_seconds = 3148.9)
[2022-05-31 15:02:55,202][root][INFO] - Step 20889600 @ 6650.7 SPS. Inference batcher size: 96. Learner queue size: 24. Other stats: (step = 20889600, mean_episode_return = 59.034, mean_episode_step = 982.74, total_loss = -21.199, pg_loss = -60.483, baseline_loss = 45.224, entropy_loss = -5.9406, learner_queue_size = 20, _tick = 5466, _time = 1.654e+09, train_seconds = 3153.9)
[2022-05-31 15:03:00,208][root][INFO] - Step 20920320 @ 6136.4 SPS. Inference batcher size: 182. Learner queue size: 18. Other stats: (step = 20920320, mean_episode_return = 54.06, mean_episode_step = 1028.5, total_loss = 36.167, pg_loss = -84.633, baseline_loss = 126.66, entropy_loss = -5.8644, learner_queue_size = 12, _tick = 5477, _time = 1.654e+09, train_seconds = 3158.9)
[2022-05-31 15:03:05,214][root][INFO] - Step 20953600 @ 6648.3 SPS. Inference batcher size: 128. Learner queue size: 21. Other stats: (step = 20953600, mean_episode_return = 63.7, mean_episode_step = 693.7, total_loss = 233.74, pg_loss = 145.35, baseline_loss = 94.079, entropy_loss = -5.6896, learner_queue_size = 26, _tick = 5489, _time = 1.654e+09, train_seconds = 3163.9)
[2022-05-31 15:03:10,220][root][INFO] - Step 20986880 @ 6648.0 SPS. Inference batcher size: 142. Learner queue size: 23. Other stats: (step = 20986880, mean_episode_return = 15.13, mean_episode_step = 946.09, total_loss = -212.55, pg_loss = -269.28, baseline_loss = 62.941, entropy_loss = -6.2068, learner_queue_size = 23, _tick = 5500, _time = 1.654e+09, train_seconds = 3168.9)
[2022-05-31 15:03:15,226][root][INFO] - Step 21020160 @ 6648.0 SPS. Inference batcher size: 135. Learner queue size: 12. Other stats: (step = 21020160, mean_episode_return = 28.958, mean_episode_step = 1000.4, total_loss = 671.69, pg_loss = 327.88, baseline_loss = 350.1, entropy_loss = -6.2809, learner_queue_size = 18, _tick = 5510, _time = 1.654e+09, train_seconds = 3173.9)
[2022-05-31 15:03:20,230][root][INFO] - Step 21053440 @ 6650.7 SPS. Inference batcher size: 109. Learner queue size: 16. Other stats: (step = 21053440, mean_episode_return = None, mean_episode_step = 963.88, total_loss = -129.56, pg_loss = -159.74, baseline_loss = 35.873, entropy_loss = -5.6942, learner_queue_size = 23, _tick = 5521, _time = 1.654e+09, train_seconds = 3178.9)
[2022-05-31 15:03:25,234][root][INFO] - Step 21086720 @ 6650.8 SPS. Inference batcher size: 101. Learner queue size: 4. Other stats: (step = 21086720, mean_episode_return = 77.235, mean_episode_step = 950.95, total_loss = -82.321, pg_loss = -132.04, baseline_loss = 56.009, entropy_loss = -6.2914, learner_queue_size = 18, _tick = 5532, _time = 1.654e+09, train_seconds = 3183.9)
[2022-05-31 15:03:30,238][root][INFO] - Step 21120000 @ 6651.1 SPS. Inference batcher size: 120. Learner queue size: 7. Other stats: (step = 21120000, mean_episode_return = 59.197, mean_episode_step = 859.87, total_loss = -38.615, pg_loss = -95.971, baseline_loss = 63.57, entropy_loss = -6.2148, learner_queue_size = 13, _tick = 5543, _time = 1.654e+09, train_seconds = 3188.9)
[2022-05-31 15:03:35,242][root][INFO] - Step 21153280 @ 6650.2 SPS. Inference batcher size: 119. Learner queue size: 2. Other stats: (step = 21153280, mean_episode_return = 118.7, mean_episode_step = 947.04, total_loss = 35.317, pg_loss = -67.37, baseline_loss = 108.42, entropy_loss = -5.7346, learner_queue_size = 17, _tick = 5553, _time = 1.654e+09, train_seconds = 3193.9)
[2022-05-31 15:03:40,246][root][INFO] - Step 21186560 @ 6650.2 SPS. Inference batcher size: 52. Learner queue size: 22. Other stats: (step = 21186560, mean_episode_return = 114.7, mean_episode_step = 781.32, total_loss = 253.75, pg_loss = 143.61, baseline_loss = 116.49, entropy_loss = -6.3512, learner_queue_size = 18, _tick = 5563, _time = 1.654e+09, train_seconds = 3198.9)
[2022-05-31 15:03:45,250][root][INFO] - Step 21219840 @ 6651.2 SPS. Inference batcher size: 125. Learner queue size: 23. Other stats: (step = 21219840, mean_episode_return = 78.835, mean_episode_step = 1049.7, total_loss = -3.4831, pg_loss = -113.57, baseline_loss = 116.31, entropy_loss = -6.2241, learner_queue_size = 20, _tick = 5573, _time = 1.654e+09, train_seconds = 3203.9)
[2022-05-31 15:03:50,256][root][INFO] - Step 21250560 @ 6136.3 SPS. Inference batcher size: 116. Learner queue size: 20. Other stats: (step = 21250560, mean_episode_return = None, mean_episode_step = 847.5, total_loss = 135.23, pg_loss = 79.67, baseline_loss = 60.271, entropy_loss = -4.7091, learner_queue_size = 17, _tick = 5582, _time = 1.654e+09, train_seconds = 3208.9)
[2022-05-31 15:03:55,262][root][INFO] - Step 21286400 @ 7159.5 SPS. Inference batcher size: 124. Learner queue size: 20. Other stats: (step = 21286400, mean_episode_return = 33.28, mean_episode_step = 871.44, total_loss = -137.44, pg_loss = -147.08, baseline_loss = 15.223, entropy_loss = -5.5851, learner_queue_size = 19, _tick = 5589, _time = 1.654e+09, train_seconds = 3213.9)
[2022-05-31 15:04:00,266][root][INFO] - Step 21317120 @ 6139.4 SPS. Inference batcher size: 100. Learner queue size: 13. Other stats: (step = 21317120, mean_episode_return = 45.671, mean_episode_step = 1013.0, total_loss = 171.2, pg_loss = 134.64, baseline_loss = 42.985, entropy_loss = -6.4252, learner_queue_size = 16, _tick = 5598, _time = 1.654e+09, train_seconds = 3219.0)
[2022-05-31 15:04:05,272][root][INFO] - Step 21350400 @ 6648.0 SPS. Inference batcher size: 123. Learner queue size: 17. Other stats: (step = 21350400, mean_episode_return = 37.05, mean_episode_step = 1137.3, total_loss = 360.68, pg_loss = 208.57, baseline_loss = 158.71, entropy_loss = -6.5916, learner_queue_size = 13, _tick = 5609, _time = 1.654e+09, train_seconds = 3224.0)
[2022-05-31 15:04:10,278][root][INFO] - Step 21383680 @ 6647.8 SPS. Inference batcher size: 72. Learner queue size: 22. Other stats: (step = 21383680, mean_episode_return = None, mean_episode_step = 784.44, total_loss = 290.97, pg_loss = 184.0, baseline_loss = 113.29, entropy_loss = -6.3189, learner_queue_size = 17, _tick = 5618, _time = 1.654e+09, train_seconds = 3229.0)
[2022-05-31 15:04:15,282][root][INFO] - Step 21416960 @ 6650.9 SPS. Inference batcher size: 2. Learner queue size: 15. Other stats: (step = 21416960, mean_episode_return = None, mean_episode_step = 944.56, total_loss = 379.17, pg_loss = 294.41, baseline_loss = 91.455, entropy_loss = -6.6952, learner_queue_size = 22, _tick = 5628, _time = 1.654e+09, train_seconds = 3234.0)
[2022-05-31 15:04:20,287][root][INFO] - Step 21450240 @ 6648.5 SPS. Inference batcher size: 123. Learner queue size: 1. Other stats: (step = 21450240, mean_episode_return = 46.22, mean_episode_step = 973.57, total_loss = 377.74, pg_loss = 269.87, baseline_loss = 114.39, entropy_loss = -6.5159, learner_queue_size = 25, _tick = 5639, _time = 1.654e+09, train_seconds = 3239.0)
[2022-05-31 15:04:25,290][root][INFO] - Step 21483520 @ 6652.9 SPS. Inference batcher size: 22. Learner queue size: 1. Other stats: (step = 21483520, mean_episode_return = None, mean_episode_step = 717.44, total_loss = 68.927, pg_loss = 30.13, baseline_loss = 45.378, entropy_loss = -6.5811, learner_queue_size = 24, _tick = 5649, _time = 1.654e+09, train_seconds = 3244.0)
[2022-05-31 15:04:30,296][root][INFO] - Step 21516800 @ 6647.5 SPS. Inference batcher size: 100. Learner queue size: 21. Other stats: (step = 21516800, mean_episode_return = None, mean_episode_step = 1175.0, total_loss = 23.414, pg_loss = -20.017, baseline_loss = 50.282, entropy_loss = -6.8511, learner_queue_size = 21, _tick = 5659, _time = 1.654e+09, train_seconds = 3249.0)
[2022-05-31 15:04:35,302][root][INFO] - Step 21547520 @ 6136.6 SPS. Inference batcher size: 100. Learner queue size: 23. Other stats: (step = 21547520, mean_episode_return = 155.01, mean_episode_step = 876.55, total_loss = 299.28, pg_loss = 230.91, baseline_loss = 75.203, entropy_loss = -6.8384, learner_queue_size = 18, _tick = 5669, _time = 1.654e+09, train_seconds = 3254.0)
[2022-05-31 15:04:40,306][root][INFO] - Step 21580800 @ 6651.1 SPS. Inference batcher size: 99. Learner queue size: 24. Other stats: (step = 21580800, mean_episode_return = None, mean_episode_step = 936.19, total_loss = 600.29, pg_loss = 495.39, baseline_loss = 112.25, entropy_loss = -7.3479, learner_queue_size = 14, _tick = 5678, _time = 1.654e+09, train_seconds = 3259.0)
[2022-05-31 15:04:45,310][root][INFO] - Step 21614080 @ 6650.9 SPS. Inference batcher size: 159. Learner queue size: 19. Other stats: (step = 21614080, mean_episode_return = 91.667, mean_episode_step = 948.26, total_loss = 281.4, pg_loss = 144.71, baseline_loss = 143.63, entropy_loss = -6.9391, learner_queue_size = 19, _tick = 5687, _time = 1.654e+09, train_seconds = 3264.0)
[2022-05-31 15:04:50,316][root][INFO] - Step 21647360 @ 6647.7 SPS. Inference batcher size: 98. Learner queue size: 22. Other stats: (step = 21647360, mean_episode_return = None, mean_episode_step = 947.66, total_loss = 419.88, pg_loss = 336.05, baseline_loss = 90.571, entropy_loss = -6.7398, learner_queue_size = 19, _tick = 5696, _time = 1.654e+09, train_seconds = 3269.0)
[2022-05-31 15:04:55,322][root][INFO] - Step 21680640 @ 6648.2 SPS. Inference batcher size: 100. Learner queue size: 21. Other stats: (step = 21680640, mean_episode_return = 41.728, mean_episode_step = 894.39, total_loss = 3673.0, pg_loss = 1446.3, baseline_loss = 2233.3, entropy_loss = -6.5801, learner_queue_size = 24, _tick = 5705, _time = 1.654e+09, train_seconds = 3274.0)
[2022-05-31 15:05:00,326][root][INFO] - Step 21713920 @ 6650.7 SPS. Inference batcher size: 120. Learner queue size: 13. Other stats: (step = 21713920, mean_episode_return = None, mean_episode_step = 851.09, total_loss = 702.29, pg_loss = 489.68, baseline_loss = 219.36, entropy_loss = -6.7403, learner_queue_size = 18, _tick = 5717, _time = 1.654e+09, train_seconds = 3279.0)
[2022-05-31 15:05:05,330][root][INFO] - Step 21747200 @ 6650.7 SPS. Inference batcher size: 57. Learner queue size: 13. Other stats: (step = 21747200, mean_episode_return = 119.84, mean_episode_step = 894.3, total_loss = 32.46, pg_loss = -37.777, baseline_loss = 76.517, entropy_loss = -6.2801, learner_queue_size = 21, _tick = 5727, _time = 1.654e+09, train_seconds = 3284.0)
[2022-05-31 15:05:10,334][root][INFO] - Step 21780480 @ 6650.7 SPS. Inference batcher size: 104. Learner queue size: 4. Other stats: (step = 21780480, mean_episode_return = None, mean_episode_step = 1113.7, total_loss = 272.57, pg_loss = 215.06, baseline_loss = 64.135, entropy_loss = -6.6269, learner_queue_size = 11, _tick = 5736, _time = 1.654e+09, train_seconds = 3289.0)
[2022-05-31 15:05:15,338][root][INFO] - Step 21813760 @ 6650.4 SPS. Inference batcher size: 186. Learner queue size: 1. Other stats: (step = 21813760, mean_episode_return = None, mean_episode_step = 964.44, total_loss = 98.555, pg_loss = 7.7848, baseline_loss = 96.932, entropy_loss = -6.1613, learner_queue_size = 27, _tick = 5745, _time = 1.654e+09, train_seconds = 3294.0)
[2022-05-31 15:05:20,342][root][INFO] - Step 21847040 @ 6651.1 SPS. Inference batcher size: 49. Learner queue size: 30. Other stats: (step = 21847040, mean_episode_return = None, mean_episode_step = 774.06, total_loss = 218.83, pg_loss = 170.96, baseline_loss = 54.499, entropy_loss = -6.6247, learner_queue_size = 27, _tick = 5754, _time = 1.654e+09, train_seconds = 3299.0)
[2022-05-31 15:05:25,346][root][INFO] - Step 21880320 @ 6650.6 SPS. Inference batcher size: 32. Learner queue size: 19. Other stats: (step = 21880320, mean_episode_return = 27.83, mean_episode_step = 1029.6, total_loss = 1017.0, pg_loss = 21.506, baseline_loss = 1002.0, entropy_loss = -6.512, learner_queue_size = 14, _tick = 5765, _time = 1.654e+09, train_seconds = 3304.0)
[2022-05-31 15:05:30,352][root][INFO] - Step 21911040 @ 6136.0 SPS. Inference batcher size: 99. Learner queue size: 15. Other stats: (step = 21911040, mean_episode_return = None, mean_episode_step = 890.88, total_loss = 299.9, pg_loss = 206.61, baseline_loss = 99.78, entropy_loss = -6.4896, learner_queue_size = 10, _tick = 5774, _time = 1.654e+09, train_seconds = 3309.0)
[2022-05-31 15:05:35,358][root][INFO] - Step 21944320 @ 6648.7 SPS. Inference batcher size: 130. Learner queue size: 11. Other stats: (step = 21944320, mean_episode_return = 42.27, mean_episode_step = 895.75, total_loss = -70.126, pg_loss = -86.349, baseline_loss = 22.463, entropy_loss = -6.2406, learner_queue_size = 23, _tick = 5784, _time = 1.654e+09, train_seconds = 3314.0)
[2022-05-31 15:05:40,362][root][INFO] - Step 21977600 @ 6650.7 SPS. Inference batcher size: 33. Learner queue size: 15. Other stats: (step = 21977600, mean_episode_return = 105.07, mean_episode_step = 897.32, total_loss = -159.88, pg_loss = -186.57, baseline_loss = 33.203, entropy_loss = -6.5107, learner_queue_size = 17, _tick = 5795, _time = 1.654e+09, train_seconds = 3319.0)
[2022-05-31 15:05:45,366][root][INFO] - Step 22010880 @ 6650.2 SPS. Inference batcher size: 57. Learner queue size: 16. Other stats: (step = 22010880, mean_episode_return = 62.56, mean_episode_step = 1132.3, total_loss = 226.41, pg_loss = 179.58, baseline_loss = 53.751, entropy_loss = -6.9203, learner_queue_size = 23, _tick = 5807, _time = 1.654e+09, train_seconds = 3324.1)
[2022-05-31 15:05:50,374][root][INFO] - Step 22044160 @ 6646.3 SPS. Inference batcher size: 81. Learner queue size: 2. Other stats: (step = 22044160, mean_episode_return = 63.86, mean_episode_step = 938.03, total_loss = -235.94, pg_loss = -317.55, baseline_loss = 88.392, entropy_loss = -6.7868, learner_queue_size = 17, _tick = 5817, _time = 1.654e+09, train_seconds = 3329.1)
[2022-05-31 15:05:55,380][root][INFO] - Step 22077440 @ 6647.3 SPS. Inference batcher size: 115. Learner queue size: 0. Other stats: (step = 22077440, mean_episode_return = 67.793, mean_episode_step = 955.67, total_loss = 167.76, pg_loss = 66.286, baseline_loss = 108.22, entropy_loss = -6.7533, learner_queue_size = 21, _tick = 5829, _time = 1.654e+09, train_seconds = 3334.1)
[2022-05-31 15:06:00,386][root][INFO] - Step 22110720 @ 6648.4 SPS. Inference batcher size: 140. Learner queue size: 0. Other stats: (step = 22110720, mean_episode_return = 80.208, mean_episode_step = 947.17, total_loss = -74.154, pg_loss = -138.37, baseline_loss = 70.399, entropy_loss = -6.1878, learner_queue_size = 29, _tick = 5840, _time = 1.654e+09, train_seconds = 3339.1)
[2022-05-31 15:06:05,392][root][INFO] - Step 22144000 @ 6647.9 SPS. Inference batcher size: 88. Learner queue size: 3. Other stats: (step = 22144000, mean_episode_return = None, mean_episode_step = 893.28, total_loss = 240.77, pg_loss = 163.23, baseline_loss = 83.806, entropy_loss = -6.2637, learner_queue_size = 18, _tick = 5849, _time = 1.654e+09, train_seconds = 3344.1)
[2022-05-31 15:06:10,398][root][INFO] - Step 22177280 @ 6648.0 SPS. Inference batcher size: 101. Learner queue size: 20. Other stats: (step = 22177280, mean_episode_return = None, mean_episode_step = 1015.8, total_loss = 319.59, pg_loss = 239.14, baseline_loss = 86.987, entropy_loss = -6.5351, learner_queue_size = 12, _tick = 5856, _time = 1.654e+09, train_seconds = 3349.1)
[2022-05-31 15:06:15,402][root][INFO] - Step 22210560 @ 6650.4 SPS. Inference batcher size: 6. Learner queue size: 13. Other stats: (step = 22210560, mean_episode_return = 98.159, mean_episode_step = 1052.2, total_loss = -1.5489, pg_loss = -67.467, baseline_loss = 72.671, entropy_loss = -6.7525, learner_queue_size = 11, _tick = 5865, _time = 1.654e+09, train_seconds = 3354.1)
[2022-05-31 15:06:20,406][root][INFO] - Step 22243840 @ 6651.2 SPS. Inference batcher size: 101. Learner queue size: 18. Other stats: (step = 22243840, mean_episode_return = 11.66, mean_episode_step = 1205.2, total_loss = 46.483, pg_loss = 9.1176, baseline_loss = 43.848, entropy_loss = -6.482, learner_queue_size = 15, _tick = 5874, _time = 1.654e+09, train_seconds = 3359.1)
[2022-05-31 15:06:25,412][root][INFO] - Step 22274560 @ 6136.6 SPS. Inference batcher size: 163. Learner queue size: 25. Other stats: (step = 22274560, mean_episode_return = 69.33, mean_episode_step = 902.01, total_loss = 166.56, pg_loss = 115.65, baseline_loss = 57.687, entropy_loss = -6.77, learner_queue_size = 26, _tick = 5885, _time = 1.654e+09, train_seconds = 3364.1)
[2022-05-31 15:06:30,418][root][INFO] - Step 22307840 @ 6648.0 SPS. Inference batcher size: 119. Learner queue size: 11. Other stats: (step = 22307840, mean_episode_return = 35.25, mean_episode_step = 1244.0, total_loss = 716.26, pg_loss = 573.77, baseline_loss = 149.61, entropy_loss = -7.1106, learner_queue_size = 16, _tick = 5897, _time = 1.654e+09, train_seconds = 3369.1)
[2022-05-31 15:06:35,422][root][INFO] - Step 22341120 @ 6650.7 SPS. Inference batcher size: 97. Learner queue size: 6. Other stats: (step = 22341120, mean_episode_return = 66.206, mean_episode_step = 1083.5, total_loss = -153.44, pg_loss = -217.66, baseline_loss = 70.464, entropy_loss = -6.2397, learner_queue_size = 11, _tick = 5907, _time = 1.654e+09, train_seconds = 3374.1)
[2022-05-31 15:06:40,430][root][INFO] - Step 22374400 @ 6645.3 SPS. Inference batcher size: 129. Learner queue size: 12. Other stats: (step = 22374400, mean_episode_return = 13.74, mean_episode_step = 837.11, total_loss = -127.43, pg_loss = -173.12, baseline_loss = 51.988, entropy_loss = -6.3025, learner_queue_size = 17, _tick = 5916, _time = 1.654e+09, train_seconds = 3379.1)
[2022-05-31 15:06:45,434][root][INFO] - Step 22407680 @ 6650.8 SPS. Inference batcher size: 150. Learner queue size: 11. Other stats: (step = 22407680, mean_episode_return = 68.227, mean_episode_step = 884.84, total_loss = -342.47, pg_loss = -457.06, baseline_loss = 121.5, entropy_loss = -6.9098, learner_queue_size = 24, _tick = 5927, _time = 1.654e+09, train_seconds = 3384.1)
[2022-05-31 15:06:50,441][root][INFO] - Step 22440960 @ 6646.4 SPS. Inference batcher size: 196. Learner queue size: 8. Other stats: (step = 22440960, mean_episode_return = 36.86, mean_episode_step = 974.57, total_loss = 419.71, pg_loss = 329.14, baseline_loss = 97.586, entropy_loss = -7.0115, learner_queue_size = 24, _tick = 5939, _time = 1.654e+09, train_seconds = 3389.1)
[2022-05-31 15:06:55,446][root][INFO] - Step 22474240 @ 6649.6 SPS. Inference batcher size: 66. Learner queue size: 1. Other stats: (step = 22474240, mean_episode_return = 46.32, mean_episode_step = 850.74, total_loss = 351.41, pg_loss = 272.04, baseline_loss = 85.02, entropy_loss = -5.6406, learner_queue_size = 17, _tick = 5951, _time = 1.654e+09, train_seconds = 3394.1)
[2022-05-31 15:07:00,450][root][INFO] - Step 22507520 @ 6650.7 SPS. Inference batcher size: 95. Learner queue size: 15. Other stats: (step = 22507520, mean_episode_return = 85.955, mean_episode_step = 733.64, total_loss = -174.23, pg_loss = -207.23, baseline_loss = 39.638, entropy_loss = -6.6389, learner_queue_size = 17, _tick = 5962, _time = 1.654e+09, train_seconds = 3399.1)
[2022-05-31 15:07:05,454][root][INFO] - Step 22540800 @ 6650.4 SPS. Inference batcher size: 138. Learner queue size: 7. Other stats: (step = 22540800, mean_episode_return = None, mean_episode_step = 1205.1, total_loss = -68.89, pg_loss = -135.53, baseline_loss = 73.166, entropy_loss = -6.523, learner_queue_size = 19, _tick = 5971, _time = 1.654e+09, train_seconds = 3404.1)
[2022-05-31 15:07:10,458][root][INFO] - Step 22574080 @ 6651.0 SPS. Inference batcher size: 84. Learner queue size: 5. Other stats: (step = 22574080, mean_episode_return = 145.39, mean_episode_step = 904.84, total_loss = -8.0756, pg_loss = -73.269, baseline_loss = 71.679, entropy_loss = -6.486, learner_queue_size = 20, _tick = 5982, _time = 1.654e+09, train_seconds = 3409.1)
[2022-05-31 15:07:15,462][root][INFO] - Step 22607360 @ 6650.6 SPS. Inference batcher size: 106. Learner queue size: 2. Other stats: (step = 22607360, mean_episode_return = 15.313, mean_episode_step = 866.58, total_loss = -11.622, pg_loss = -104.28, baseline_loss = 99.377, entropy_loss = -6.7153, learner_queue_size = 15, _tick = 5992, _time = 1.654e+09, train_seconds = 3414.1)
[2022-05-31 15:07:20,466][root][INFO] - Step 22640640 @ 6650.8 SPS. Inference batcher size: 95. Learner queue size: 27. Other stats: (step = 22640640, mean_episode_return = 89.984, mean_episode_step = 965.61, total_loss = -145.42, pg_loss = -195.92, baseline_loss = 56.735, entropy_loss = -6.2342, learner_queue_size = 23, _tick = 6003, _time = 1.654e+09, train_seconds = 3419.2)
[2022-05-31 15:07:25,470][root][INFO] - Step 22673920 @ 6650.6 SPS. Inference batcher size: 105. Learner queue size: 3. Other stats: (step = 22673920, mean_episode_return = 19.691, mean_episode_step = 799.13, total_loss = -57.092, pg_loss = -74.291, baseline_loss = 24.259, entropy_loss = -7.0598, learner_queue_size = 32, _tick = 6014, _time = 1.654e+09, train_seconds = 3424.2)
[2022-05-31 15:07:30,474][root][INFO] - Step 22707200 @ 6650.8 SPS. Inference batcher size: 91. Learner queue size: 27. Other stats: (step = 22707200, mean_episode_return = 3.0497, mean_episode_step = 785.43, total_loss = -26.971, pg_loss = -117.7, baseline_loss = 97.592, entropy_loss = -6.868, learner_queue_size = 23, _tick = 6024, _time = 1.654e+09, train_seconds = 3429.2)
[2022-05-31 15:07:35,478][root][INFO] - Step 22740480 @ 6650.5 SPS. Inference batcher size: 31. Learner queue size: 20. Other stats: (step = 22740480, mean_episode_return = 96.381, mean_episode_step = 975.25, total_loss = 289.84, pg_loss = 148.29, baseline_loss = 148.49, entropy_loss = -6.9483, learner_queue_size = 17, _tick = 6032, _time = 1.654e+09, train_seconds = 3434.2)
[2022-05-31 15:07:40,485][root][INFO] - Step 22771200 @ 6136.0 SPS. Inference batcher size: 134. Learner queue size: 28. Other stats: (step = 22771200, mean_episode_return = None, mean_episode_step = 852.19, total_loss = 55.038, pg_loss = 19.918, baseline_loss = 41.652, entropy_loss = -6.532, learner_queue_size = 12, _tick = 6041, _time = 1.654e+09, train_seconds = 3439.2)
[2022-05-31 15:07:45,491][root][INFO] - Step 22804480 @ 6648.1 SPS. Inference batcher size: 157. Learner queue size: 20. Other stats: (step = 22804480, mean_episode_return = 102.48, mean_episode_step = 1124.7, total_loss = -195.86, pg_loss = -237.61, baseline_loss = 48.621, entropy_loss = -6.8779, learner_queue_size = 19, _tick = 6051, _time = 1.654e+09, train_seconds = 3444.2)
[2022-05-31 15:07:50,496][root][INFO] - Step 22837760 @ 6648.1 SPS. Inference batcher size: 195. Learner queue size: 18. Other stats: (step = 22837760, mean_episode_return = None, mean_episode_step = 829.12, total_loss = 845.01, pg_loss = 645.51, baseline_loss = 206.05, entropy_loss = -6.5557, learner_queue_size = 30, _tick = 6060, _time = 1.654e+09, train_seconds = 3449.2)
[2022-05-31 15:07:55,502][root][INFO] - Step 22871040 @ 6648.8 SPS. Inference batcher size: 103. Learner queue size: 15. Other stats: (step = 22871040, mean_episode_return = 63.051, mean_episode_step = 1008.7, total_loss = -83.622, pg_loss = -111.5, baseline_loss = 34.945, entropy_loss = -7.0651, learner_queue_size = 30, _tick = 6072, _time = 1.654e+09, train_seconds = 3454.2)
[2022-05-31 15:08:00,506][root][INFO] - Step 22904320 @ 6650.6 SPS. Inference batcher size: 119. Learner queue size: 17. Other stats: (step = 22904320, mean_episode_return = 97.64, mean_episode_step = 1058.8, total_loss = 79.707, pg_loss = 18.953, baseline_loss = 66.762, entropy_loss = -6.0075, learner_queue_size = 24, _tick = 6082, _time = 1.654e+09, train_seconds = 3459.2)
[2022-05-31 15:08:05,512][root][INFO] - Step 22937600 @ 6647.9 SPS. Inference batcher size: 122. Learner queue size: 16. Other stats: (step = 22937600, mean_episode_return = 26.86, mean_episode_step = 881.41, total_loss = -181.23, pg_loss = -204.98, baseline_loss = 30.363, entropy_loss = -6.6106, learner_queue_size = 31, _tick = 6094, _time = 1.654e+09, train_seconds = 3464.2)
[2022-05-31 15:08:10,518][root][INFO] - Step 22970880 @ 6648.2 SPS. Inference batcher size: 122. Learner queue size: 4. Other stats: (step = 22970880, mean_episode_return = 59.735, mean_episode_step = 859.51, total_loss = 23.48, pg_loss = -46.35, baseline_loss = 76.358, entropy_loss = -6.5288, learner_queue_size = 17, _tick = 6105, _time = 1.654e+09, train_seconds = 3469.2)
[2022-05-31 15:08:15,524][root][INFO] - Step 23004160 @ 6647.9 SPS. Inference batcher size: 129. Learner queue size: 2. Other stats: (step = 23004160, mean_episode_return = 155.78, mean_episode_step = 988.52, total_loss = 151.0, pg_loss = 38.953, baseline_loss = 118.79, entropy_loss = -6.7486, learner_queue_size = 20, _tick = 6117, _time = 1.654e+09, train_seconds = 3474.2)
[2022-05-31 15:08:20,530][root][INFO] - Step 23037440 @ 6648.3 SPS. Inference batcher size: 120. Learner queue size: 7. Other stats: (step = 23037440, mean_episode_return = 71.816, mean_episode_step = 897.77, total_loss = -69.693, pg_loss = -139.69, baseline_loss = 76.386, entropy_loss = -6.3886, learner_queue_size = 22, _tick = 6127, _time = 1.654e+09, train_seconds = 3479.2)
[2022-05-31 15:08:25,534][root][INFO] - Step 23070720 @ 6650.4 SPS. Inference batcher size: 131. Learner queue size: 27. Other stats: (step = 23070720, mean_episode_return = 78.62, mean_episode_step = 974.57, total_loss = -126.87, pg_loss = -153.42, baseline_loss = 33.145, entropy_loss = -6.5963, learner_queue_size = 9, _tick = 6136, _time = 1.654e+09, train_seconds = 3484.2)
[2022-05-31 15:08:30,538][root][INFO] - Step 23104000 @ 6650.7 SPS. Inference batcher size: 154. Learner queue size: 1. Other stats: (step = 23104000, mean_episode_return = None, mean_episode_step = 1028.6, total_loss = 73.173, pg_loss = 26.286, baseline_loss = 53.898, entropy_loss = -7.0111, learner_queue_size = 21, _tick = 6147, _time = 1.654e+09, train_seconds = 3489.2)
[2022-05-31 15:08:35,542][root][INFO] - Step 23137280 @ 6650.8 SPS. Inference batcher size: 172. Learner queue size: 31. Other stats: (step = 23137280, mean_episode_return = 30.88, mean_episode_step = 903.55, total_loss = -39.589, pg_loss = -78.155, baseline_loss = 45.407, entropy_loss = -6.8409, learner_queue_size = 24, _tick = 6156, _time = 1.654e+09, train_seconds = 3494.2)
[2022-05-31 15:08:40,548][root][INFO] - Step 23170560 @ 6648.0 SPS. Inference batcher size: 162. Learner queue size: 1. Other stats: (step = 23170560, mean_episode_return = 35.65, mean_episode_step = 1184.1, total_loss = -212.87, pg_loss = -297.18, baseline_loss = 91.203, entropy_loss = -6.8916, learner_queue_size = 20, _tick = 6166, _time = 1.654e+09, train_seconds = 3499.2)
[2022-05-31 15:08:45,554][root][INFO] - Step 23203840 @ 6648.1 SPS. Inference batcher size: 43. Learner queue size: 26. Other stats: (step = 23203840, mean_episode_return = 181.33, mean_episode_step = 1047.7, total_loss = 695.66, pg_loss = 491.72, baseline_loss = 210.68, entropy_loss = -6.738, learner_queue_size = 20, _tick = 6176, _time = 1.654e+09, train_seconds = 3504.2)
[2022-05-31 15:08:50,560][root][INFO] - Step 23234560 @ 6136.3 SPS. Inference batcher size: 87. Learner queue size: 14. Other stats: (step = 23234560, mean_episode_return = 64.653, mean_episode_step = 979.08, total_loss = 368.37, pg_loss = 262.02, baseline_loss = 112.81, entropy_loss = -6.4548, learner_queue_size = 13, _tick = 6185, _time = 1.654e+09, train_seconds = 3509.2)
[2022-05-31 15:08:55,566][root][INFO] - Step 23267840 @ 6648.0 SPS. Inference batcher size: 122. Learner queue size: 19. Other stats: (step = 23267840, mean_episode_return = 105.8, mean_episode_step = 1068.1, total_loss = 145.05, pg_loss = 47.2, baseline_loss = 103.38, entropy_loss = -5.5332, learner_queue_size = 7, _tick = 6196, _time = 1.654e+09, train_seconds = 3514.3)
[2022-05-31 15:09:00,570][root][INFO] - Step 23301120 @ 6651.0 SPS. Inference batcher size: 158. Learner queue size: 16. Other stats: (step = 23301120, mean_episode_return = 8.2797, mean_episode_step = 902.45, total_loss = -87.484, pg_loss = -102.36, baseline_loss = 19.933, entropy_loss = -5.0526, learner_queue_size = 26, _tick = 6204, _time = 1.654e+09, train_seconds = 3519.3)
[2022-05-31 15:09:05,576][root][INFO] - Step 23334400 @ 6648.0 SPS. Inference batcher size: 127. Learner queue size: 4. Other stats: (step = 23334400, mean_episode_return = 63.579, mean_episode_step = 1245.3, total_loss = 318.56, pg_loss = 189.01, baseline_loss = 136.38, entropy_loss = -6.8333, learner_queue_size = 16, _tick = 6213, _time = 1.654e+09, train_seconds = 3524.3)
[2022-05-31 15:09:10,582][root][INFO] - Step 23367680 @ 6648.1 SPS. Inference batcher size: 88. Learner queue size: 9. Other stats: (step = 23367680, mean_episode_return = None, mean_episode_step = 923.09, total_loss = 50.76, pg_loss = 7.0953, baseline_loss = 50.471, entropy_loss = -6.8062, learner_queue_size = 19, _tick = 6222, _time = 1.654e+09, train_seconds = 3529.3)
[2022-05-31 15:09:15,586][root][INFO] - Step 23400960 @ 6650.7 SPS. Inference batcher size: 119. Learner queue size: 4. Other stats: (step = 23400960, mean_episode_return = 21.21, mean_episode_step = 1047.5, total_loss = -70.983, pg_loss = -75.828, baseline_loss = 12.074, entropy_loss = -7.2288, learner_queue_size = 25, _tick = 6233, _time = 1.654e+09, train_seconds = 3534.3)
[2022-05-31 15:09:20,592][root][INFO] - Step 23434240 @ 6647.9 SPS. Inference batcher size: 69. Learner queue size: 1. Other stats: (step = 23434240, mean_episode_return = 105.76, mean_episode_step = 1123.0, total_loss = 182.15, pg_loss = 159.01, baseline_loss = 29.898, entropy_loss = -6.7512, learner_queue_size = 24, _tick = 6245, _time = 1.654e+09, train_seconds = 3539.3)
[2022-05-31 15:09:25,598][root][INFO] - Step 23467520 @ 6648.0 SPS. Inference batcher size: 176. Learner queue size: 15. Other stats: (step = 23467520, mean_episode_return = 117.24, mean_episode_step = 875.07, total_loss = 224.65, pg_loss = 154.09, baseline_loss = 75.894, entropy_loss = -5.3273, learner_queue_size = 19, _tick = 6254, _time = 1.654e+09, train_seconds = 3544.3)
[2022-05-31 15:09:30,602][root][INFO] - Step 23500800 @ 6650.2 SPS. Inference batcher size: 87. Learner queue size: 8. Other stats: (step = 23500800, mean_episode_return = None, mean_episode_step = 886.0, total_loss = 357.15, pg_loss = 236.1, baseline_loss = 127.79, entropy_loss = -6.7487, learner_queue_size = 19, _tick = 6264, _time = 1.654e+09, train_seconds = 3549.3)
[2022-05-31 15:09:35,606][root][INFO] - Step 23534080 @ 6651.2 SPS. Inference batcher size: 131. Learner queue size: 4. Other stats: (step = 23534080, mean_episode_return = None, mean_episode_step = 972.56, total_loss = 217.55, pg_loss = 113.23, baseline_loss = 110.92, entropy_loss = -6.5898, learner_queue_size = 22, _tick = 6275, _time = 1.654e+09, train_seconds = 3554.3)
[2022-05-31 15:09:40,610][root][INFO] - Step 23567360 @ 6650.7 SPS. Inference batcher size: 54. Learner queue size: 6. Other stats: (step = 23567360, mean_episode_return = 9.2597, mean_episode_step = 969.67, total_loss = 269.8, pg_loss = 124.27, baseline_loss = 152.19, entropy_loss = -6.6638, learner_queue_size = 22, _tick = 6285, _time = 1.654e+09, train_seconds = 3559.3)
[2022-05-31 15:09:45,614][root][INFO] - Step 23600640 @ 6650.6 SPS. Inference batcher size: 134. Learner queue size: 9. Other stats: (step = 23600640, mean_episode_return = 152.13, mean_episode_step = 976.04, total_loss = -172.97, pg_loss = -195.6, baseline_loss = 29.872, entropy_loss = -7.2482, learner_queue_size = 20, _tick = 6298, _time = 1.654e+09, train_seconds = 3564.3)
[2022-05-31 15:09:50,618][root][INFO] - Step 23633920 @ 6650.7 SPS. Inference batcher size: 144. Learner queue size: 2. Other stats: (step = 23633920, mean_episode_return = 104.15, mean_episode_step = 886.97, total_loss = 645.65, pg_loss = 551.1, baseline_loss = 100.94, entropy_loss = -6.3958, learner_queue_size = 18, _tick = 6309, _time = 1.654e+09, train_seconds = 3569.3)
[2022-05-31 15:09:55,622][root][INFO] - Step 23667200 @ 6650.7 SPS. Inference batcher size: 94. Learner queue size: 5. Other stats: (step = 23667200, mean_episode_return = 147.54, mean_episode_step = 885.8, total_loss = -33.595, pg_loss = -74.865, baseline_loss = 48.172, entropy_loss = -6.9032, learner_queue_size = 28, _tick = 6320, _time = 1.654e+09, train_seconds = 3574.3)
[2022-05-31 15:10:00,628][root][INFO] - Step 23700480 @ 6647.8 SPS. Inference batcher size: 107. Learner queue size: 3. Other stats: (step = 23700480, mean_episode_return = 77.991, mean_episode_step = 721.75, total_loss = -260.21, pg_loss = -326.85, baseline_loss = 73.394, entropy_loss = -6.7615, learner_queue_size = 16, _tick = 6328, _time = 1.654e+09, train_seconds = 3579.3)
[2022-05-31 15:10:05,634][root][INFO] - Step 23733760 @ 6648.0 SPS. Inference batcher size: 86. Learner queue size: 4. Other stats: (step = 23733760, mean_episode_return = None, mean_episode_step = 997.97, total_loss = 199.35, pg_loss = 129.04, baseline_loss = 77.247, entropy_loss = -6.9298, learner_queue_size = 24, _tick = 6336, _time = 1.654e+09, train_seconds = 3584.3)
[2022-05-31 15:10:10,638][root][INFO] - Step 23767040 @ 6651.0 SPS. Inference batcher size: 114. Learner queue size: 30. Other stats: (step = 23767040, mean_episode_return = None, mean_episode_step = 1157.6, total_loss = -48.354, pg_loss = -83.252, baseline_loss = 41.8, entropy_loss = -6.9027, learner_queue_size = 11, _tick = 6345, _time = 1.654e+09, train_seconds = 3589.3)
[2022-05-31 15:10:15,642][root][INFO] - Step 23800320 @ 6650.6 SPS. Inference batcher size: 14. Learner queue size: 29. Other stats: (step = 23800320, mean_episode_return = 61.493, mean_episode_step = 893.71, total_loss = 22.875, pg_loss = -17.094, baseline_loss = 47.006, entropy_loss = -7.0372, learner_queue_size = 26, _tick = 6356, _time = 1.654e+09, train_seconds = 3594.3)
[2022-05-31 15:10:20,648][root][INFO] - Step 23833600 @ 6647.4 SPS. Inference batcher size: 130. Learner queue size: 2. Other stats: (step = 23833600, mean_episode_return = 33.71, mean_episode_step = 907.05, total_loss = -48.483, pg_loss = -75.604, baseline_loss = 33.982, entropy_loss = -6.8616, learner_queue_size = 25, _tick = 6369, _time = 1.654e+09, train_seconds = 3599.3)
[2022-05-31 15:10:25,655][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 15:10:25,751][root][INFO] - Step 23866880 @ 6647.8 SPS. Inference batcher size: 29. Learner queue size: 27. Other stats: (step = 23866880, mean_episode_return = None, mean_episode_step = 923.09, total_loss = 996.25, pg_loss = 770.19, baseline_loss = 233.13, entropy_loss = -7.0692, learner_queue_size = 18, _tick = 6380, _time = 1.654e+09, train_seconds = 3604.3)
[2022-05-31 15:10:30,755][root][INFO] - Step 23900160 @ 6525.6 SPS. Inference batcher size: 4. Learner queue size: 22. Other stats: (step = 23900160, mean_episode_return = 145.47, mean_episode_step = 895.54, total_loss = -266.46, pg_loss = -286.51, baseline_loss = 26.748, entropy_loss = -6.6969, learner_queue_size = 16, _tick = 6390, _time = 1.654e+09, train_seconds = 3609.4)
[2022-05-31 15:10:35,758][root][INFO] - Step 23933440 @ 6651.5 SPS. Inference batcher size: 174. Learner queue size: 18. Other stats: (step = 23933440, mean_episode_return = 128.72, mean_episode_step = 1001.1, total_loss = 223.8, pg_loss = 120.72, baseline_loss = 110.18, entropy_loss = -7.0946, learner_queue_size = 16, _tick = 6401, _time = 1.654e+09, train_seconds = 3614.4)
[2022-05-31 15:10:40,764][root][INFO] - Step 23964160 @ 6136.4 SPS. Inference batcher size: 113. Learner queue size: 15. Other stats: (step = 23964160, mean_episode_return = None, mean_episode_step = 968.5, total_loss = 554.76, pg_loss = 442.26, baseline_loss = 119.37, entropy_loss = -6.8661, learner_queue_size = 16, _tick = 6410, _time = 1.654e+09, train_seconds = 3619.4)
[2022-05-31 15:10:45,770][root][INFO] - Step 23997440 @ 6648.3 SPS. Inference batcher size: 117. Learner queue size: 13. Other stats: (step = 23997440, mean_episode_return = 109.91, mean_episode_step = 841.23, total_loss = -291.0, pg_loss = -345.74, baseline_loss = 61.403, entropy_loss = -6.6722, learner_queue_size = 15, _tick = 6422, _time = 1.654e+09, train_seconds = 3624.5)
[2022-05-31 15:10:50,774][root][INFO] - Step 24030720 @ 6650.6 SPS. Inference batcher size: 147. Learner queue size: 18. Other stats: (step = 24030720, mean_episode_return = 34.9, mean_episode_step = 822.72, total_loss = 255.04, pg_loss = 161.55, baseline_loss = 98.992, entropy_loss = -5.4974, learner_queue_size = 25, _tick = 6434, _time = 1.654e+09, train_seconds = 3629.5)
[2022-05-31 15:10:55,778][root][INFO] - Step 24064000 @ 6650.7 SPS. Inference batcher size: 65. Learner queue size: 18. Other stats: (step = 24064000, mean_episode_return = 36.84, mean_episode_step = 903.17, total_loss = -53.76, pg_loss = -73.231, baseline_loss = 26.328, entropy_loss = -6.8574, learner_queue_size = 20, _tick = 6442, _time = 1.654e+09, train_seconds = 3634.5)
[2022-05-31 15:11:00,782][root][INFO] - Step 24097280 @ 6650.8 SPS. Inference batcher size: 131. Learner queue size: 12. Other stats: (step = 24097280, mean_episode_return = 62.065, mean_episode_step = 902.81, total_loss = -26.887, pg_loss = -65.195, baseline_loss = 44.76, entropy_loss = -6.4522, learner_queue_size = 18, _tick = 6454, _time = 1.654e+09, train_seconds = 3639.5)
[2022-05-31 15:11:05,786][root][INFO] - Step 24130560 @ 6650.7 SPS. Inference batcher size: 68. Learner queue size: 2. Other stats: (step = 24130560, mean_episode_return = 59.251, mean_episode_step = 970.32, total_loss = -82.523, pg_loss = -118.78, baseline_loss = 42.93, entropy_loss = -6.6728, learner_queue_size = 19, _tick = 6466, _time = 1.654e+09, train_seconds = 3644.5)
[2022-05-31 15:11:10,790][root][INFO] - Step 24163840 @ 6650.6 SPS. Inference batcher size: 62. Learner queue size: 2. Other stats: (step = 24163840, mean_episode_return = 65.59, mean_episode_step = 930.0, total_loss = 3.3843, pg_loss = -24.969, baseline_loss = 35.553, entropy_loss = -7.1989, learner_queue_size = 7, _tick = 6475, _time = 1.654e+09, train_seconds = 3649.5)
[2022-05-31 15:11:15,794][root][INFO] - Step 24197120 @ 6650.8 SPS. Inference batcher size: 104. Learner queue size: 30. Other stats: (step = 24197120, mean_episode_return = 77.443, mean_episode_step = 1005.9, total_loss = 254.51, pg_loss = 134.88, baseline_loss = 126.65, entropy_loss = -7.0271, learner_queue_size = 26, _tick = 6487, _time = 1.654e+09, train_seconds = 3654.5)
[2022-05-31 15:11:20,798][root][INFO] - Step 24230400 @ 6650.7 SPS. Inference batcher size: 117. Learner queue size: 0. Other stats: (step = 24230400, mean_episode_return = 87.457, mean_episode_step = 709.29, total_loss = 58.838, pg_loss = 13.399, baseline_loss = 51.128, entropy_loss = -5.6889, learner_queue_size = 25, _tick = 6497, _time = 1.654e+09, train_seconds = 3659.5)
[2022-05-31 15:11:25,803][root][INFO] - Step 24261120 @ 6137.7 SPS. Inference batcher size: 204. Learner queue size: 29. Other stats: (step = 24261120, mean_episode_return = 53.87, mean_episode_step = 952.03, total_loss = -414.85, pg_loss = -460.16, baseline_loss = 51.842, entropy_loss = -6.5281, learner_queue_size = 16, _tick = 6507, _time = 1.654e+09, train_seconds = 3664.5)
[2022-05-31 15:11:30,806][root][INFO] - Step 24296960 @ 7163.9 SPS. Inference batcher size: 113. Learner queue size: 30. Other stats: (step = 24296960, mean_episode_return = 102.37, mean_episode_step = 826.75, total_loss = -33.327, pg_loss = -51.764, baseline_loss = 24.704, entropy_loss = -6.2674, learner_queue_size = 25, _tick = 6518, _time = 1.654e+09, train_seconds = 3669.5)
[2022-05-31 15:11:35,810][root][INFO] - Step 24330240 @ 6650.6 SPS. Inference batcher size: 84. Learner queue size: 22. Other stats: (step = 24330240, mean_episode_return = 59.387, mean_episode_step = 1041.2, total_loss = -29.809, pg_loss = -62.766, baseline_loss = 38.565, entropy_loss = -5.6082, learner_queue_size = 17, _tick = 6527, _time = 1.654e+09, train_seconds = 3674.5)
[2022-05-31 15:11:40,816][root][INFO] - Step 24360960 @ 6136.6 SPS. Inference batcher size: 132. Learner queue size: 14. Other stats: (step = 24360960, mean_episode_return = 50.712, mean_episode_step = 971.44, total_loss = 177.84, pg_loss = 115.75, baseline_loss = 69.181, entropy_loss = -7.0876, learner_queue_size = 14, _tick = 6537, _time = 1.654e+09, train_seconds = 3679.5)
[2022-05-31 15:11:45,822][root][INFO] - Step 24394240 @ 6648.0 SPS. Inference batcher size: 105. Learner queue size: 14. Other stats: (step = 24394240, mean_episode_return = 86.741, mean_episode_step = 810.96, total_loss = 215.68, pg_loss = 93.898, baseline_loss = 128.23, entropy_loss = -6.4517, learner_queue_size = 13, _tick = 6549, _time = 1.654e+09, train_seconds = 3684.5)
[2022-05-31 15:11:50,826][root][INFO] - Step 24427520 @ 6650.8 SPS. Inference batcher size: 112. Learner queue size: 14. Other stats: (step = 24427520, mean_episode_return = 76.14, mean_episode_step = 897.84, total_loss = 331.69, pg_loss = 241.6, baseline_loss = 96.729, entropy_loss = -6.6358, learner_queue_size = 22, _tick = 6561, _time = 1.654e+09, train_seconds = 3689.5)
[2022-05-31 15:11:55,830][root][INFO] - Step 24460800 @ 6650.7 SPS. Inference batcher size: 171. Learner queue size: 7. Other stats: (step = 24460800, mean_episode_return = 102.24, mean_episode_step = 980.56, total_loss = 150.17, pg_loss = 46.365, baseline_loss = 110.27, entropy_loss = -6.465, learner_queue_size = 17, _tick = 6572, _time = 1.654e+09, train_seconds = 3694.5)
[2022-05-31 15:12:00,834][root][INFO] - Step 24494080 @ 6650.8 SPS. Inference batcher size: 113. Learner queue size: 9. Other stats: (step = 24494080, mean_episode_return = 95.884, mean_episode_step = 836.46, total_loss = 34.502, pg_loss = 0.8126, baseline_loss = 39.96, entropy_loss = -6.2702, learner_queue_size = 15, _tick = 6583, _time = 1.654e+09, train_seconds = 3699.5)
[2022-05-31 15:12:05,838][root][INFO] - Step 24527360 @ 6650.6 SPS. Inference batcher size: 64. Learner queue size: 29. Other stats: (step = 24527360, mean_episode_return = 93.084, mean_episode_step = 815.83, total_loss = 484.23, pg_loss = 351.2, baseline_loss = 139.97, entropy_loss = -6.9305, learner_queue_size = 13, _tick = 6594, _time = 1.654e+09, train_seconds = 3704.5)
[2022-05-31 15:12:10,842][root][INFO] - Step 24560640 @ 6650.7 SPS. Inference batcher size: 127. Learner queue size: 29. Other stats: (step = 24560640, mean_episode_return = None, mean_episode_step = 725.31, total_loss = -23.341, pg_loss = -54.188, baseline_loss = 37.222, entropy_loss = -6.3743, learner_queue_size = 26, _tick = 6604, _time = 1.654e+09, train_seconds = 3709.5)
[2022-05-31 15:12:15,848][root][INFO] - Step 24593920 @ 6648.1 SPS. Inference batcher size: 161. Learner queue size: 1. Other stats: (step = 24593920, mean_episode_return = 28.12, mean_episode_step = 922.8, total_loss = 22.221, pg_loss = -3.167, baseline_loss = 31.833, entropy_loss = -6.4447, learner_queue_size = 15, _tick = 6617, _time = 1.654e+09, train_seconds = 3714.5)
[2022-05-31 15:12:20,854][root][INFO] - Step 24624640 @ 6136.9 SPS. Inference batcher size: 145. Learner queue size: 24. Other stats: (step = 24624640, mean_episode_return = 102.95, mean_episode_step = 974.38, total_loss = -119.6, pg_loss = -153.98, baseline_loss = 41.049, entropy_loss = -6.6652, learner_queue_size = 15, _tick = 6627, _time = 1.654e+09, train_seconds = 3719.5)
[2022-05-31 15:12:25,858][root][INFO] - Step 24657920 @ 6650.2 SPS. Inference batcher size: 101. Learner queue size: 11. Other stats: (step = 24657920, mean_episode_return = 68.38, mean_episode_step = 949.57, total_loss = -128.07, pg_loss = -148.96, baseline_loss = 26.177, entropy_loss = -5.2921, learner_queue_size = 11, _tick = 6636, _time = 1.654e+09, train_seconds = 3724.5)
[2022-05-31 15:12:30,865][root][INFO] - Step 24691200 @ 6647.2 SPS. Inference batcher size: 33. Learner queue size: 13. Other stats: (step = 24691200, mean_episode_return = 84.46, mean_episode_step = 886.5, total_loss = 579.34, pg_loss = 438.38, baseline_loss = 147.8, entropy_loss = -6.8366, learner_queue_size = 21, _tick = 6648, _time = 1.654e+09, train_seconds = 3729.5)
[2022-05-31 15:12:35,871][root][INFO] - Step 24724480 @ 6647.9 SPS. Inference batcher size: 64. Learner queue size: 3. Other stats: (step = 24724480, mean_episode_return = 110.25, mean_episode_step = 878.71, total_loss = 86.79, pg_loss = 51.979, baseline_loss = 41.031, entropy_loss = -6.2204, learner_queue_size = 19, _tick = 6660, _time = 1.654e+09, train_seconds = 3734.6)
[2022-05-31 15:12:40,874][root][INFO] - Step 24757760 @ 6651.7 SPS. Inference batcher size: 44. Learner queue size: 3. Other stats: (step = 24757760, mean_episode_return = 101.11, mean_episode_step = 1118.8, total_loss = 5.1316, pg_loss = -51.988, baseline_loss = 63.656, entropy_loss = -6.5362, learner_queue_size = 19, _tick = 6669, _time = 1.654e+09, train_seconds = 3739.6)
[2022-05-31 15:12:45,878][root][INFO] - Step 24791040 @ 6650.7 SPS. Inference batcher size: 170. Learner queue size: 6. Other stats: (step = 24791040, mean_episode_return = 152.99, mean_episode_step = 981.46, total_loss = -72.636, pg_loss = -95.787, baseline_loss = 30.373, entropy_loss = -7.2218, learner_queue_size = 22, _tick = 6681, _time = 1.654e+09, train_seconds = 3744.6)
[2022-05-31 15:12:50,882][root][INFO] - Step 24824320 @ 6650.7 SPS. Inference batcher size: 141. Learner queue size: 0. Other stats: (step = 24824320, mean_episode_return = 68.967, mean_episode_step = 940.79, total_loss = -35.513, pg_loss = -97.938, baseline_loss = 69.437, entropy_loss = -7.0116, learner_queue_size = 6, _tick = 6691, _time = 1.654e+09, train_seconds = 3749.6)
[2022-05-31 15:12:55,886][root][INFO] - Step 24857600 @ 6650.6 SPS. Inference batcher size: 104. Learner queue size: 6. Other stats: (step = 24857600, mean_episode_return = None, mean_episode_step = 1101.8, total_loss = 0.76628, pg_loss = -32.418, baseline_loss = 39.427, entropy_loss = -6.2426, learner_queue_size = 16, _tick = 6702, _time = 1.654e+09, train_seconds = 3754.6)
[2022-05-31 15:13:00,892][root][INFO] - Step 24888320 @ 6136.8 SPS. Inference batcher size: 40. Learner queue size: 30. Other stats: (step = 24888320, mean_episode_return = 37.821, mean_episode_step = 838.98, total_loss = 174.62, pg_loss = 122.73, baseline_loss = 58.76, entropy_loss = -6.8757, learner_queue_size = 19, _tick = 6710, _time = 1.654e+09, train_seconds = 3759.6)
[2022-05-31 15:13:05,894][root][INFO] - Step 24924160 @ 7165.0 SPS. Inference batcher size: 120. Learner queue size: 31. Other stats: (step = 24924160, mean_episode_return = None, mean_episode_step = 1002.8, total_loss = -202.02, pg_loss = -245.81, baseline_loss = 50.53, entropy_loss = -6.7438, learner_queue_size = 14, _tick = 6719, _time = 1.654e+09, train_seconds = 3764.6)
[2022-05-31 15:13:10,900][root][INFO] - Step 24954880 @ 6137.0 SPS. Inference batcher size: 137. Learner queue size: 12. Other stats: (step = 24954880, mean_episode_return = None, mean_episode_step = 914.34, total_loss = 304.07, pg_loss = 234.76, baseline_loss = 75.989, entropy_loss = -6.6749, learner_queue_size = 27, _tick = 6728, _time = 1.654e+09, train_seconds = 3769.6)
[2022-05-31 15:13:15,902][root][INFO] - Step 24988160 @ 6652.9 SPS. Inference batcher size: 155. Learner queue size: 16. Other stats: (step = 24988160, mean_episode_return = None, mean_episode_step = 894.88, total_loss = 153.61, pg_loss = 110.37, baseline_loss = 50.242, entropy_loss = -7.0, learner_queue_size = 13, _tick = 6740, _time = 1.654e+09, train_seconds = 3774.6)
[2022-05-31 15:13:20,906][root][INFO] - Step 25021440 @ 6650.6 SPS. Inference batcher size: 77. Learner queue size: 16. Other stats: (step = 25021440, mean_episode_return = 59.262, mean_episode_step = 964.98, total_loss = 711.86, pg_loss = 583.25, baseline_loss = 135.38, entropy_loss = -6.7744, learner_queue_size = 18, _tick = 6751, _time = 1.654e+09, train_seconds = 3779.6)
[2022-05-31 15:13:25,907][root][INFO] - Step 25054720 @ 6654.4 SPS. Inference batcher size: 108. Learner queue size: 15. Other stats: (step = 25054720, mean_episode_return = 30.56, mean_episode_step = 986.64, total_loss = -173.0, pg_loss = -224.98, baseline_loss = 58.985, entropy_loss = -7.0095, learner_queue_size = 15, _tick = 6762, _time = 1.654e+09, train_seconds = 3784.6)
[2022-05-31 15:13:30,913][root][INFO] - Step 25088000 @ 6648.0 SPS. Inference batcher size: 116. Learner queue size: 17. Other stats: (step = 25088000, mean_episode_return = 144.12, mean_episode_step = 912.74, total_loss = -41.639, pg_loss = -78.334, baseline_loss = 43.894, entropy_loss = -7.1991, learner_queue_size = 17, _tick = 6775, _time = 1.654e+09, train_seconds = 3789.6)
[2022-05-31 15:13:35,918][root][INFO] - Step 25121280 @ 6649.7 SPS. Inference batcher size: 82. Learner queue size: 14. Other stats: (step = 25121280, mean_episode_return = 33.276, mean_episode_step = 1001.7, total_loss = -294.61, pg_loss = -303.55, baseline_loss = 16.425, entropy_loss = -7.4832, learner_queue_size = 27, _tick = 6786, _time = 1.654e+09, train_seconds = 3794.6)
[2022-05-31 15:13:40,922][root][INFO] - Step 25154560 @ 6650.7 SPS. Inference batcher size: 108. Learner queue size: 3. Other stats: (step = 25154560, mean_episode_return = None, mean_episode_step = 951.53, total_loss = 1126.3, pg_loss = 941.27, baseline_loss = 191.98, entropy_loss = -6.9312, learner_queue_size = 9, _tick = 6795, _time = 1.654e+09, train_seconds = 3799.6)
[2022-05-31 15:13:45,926][root][INFO] - Step 25187840 @ 6650.7 SPS. Inference batcher size: 102. Learner queue size: 9. Other stats: (step = 25187840, mean_episode_return = 36.8, mean_episode_step = 1117.5, total_loss = -36.966, pg_loss = -89.749, baseline_loss = 59.76, entropy_loss = -6.9765, learner_queue_size = 17, _tick = 6807, _time = 1.654e+09, train_seconds = 3804.6)
[2022-05-31 15:13:50,930][root][INFO] - Step 25221120 @ 6650.7 SPS. Inference batcher size: 118. Learner queue size: 2. Other stats: (step = 25221120, mean_episode_return = 32.231, mean_episode_step = 1239.3, total_loss = -285.5, pg_loss = -292.04, baseline_loss = 13.7, entropy_loss = -7.1535, learner_queue_size = 24, _tick = 6817, _time = 1.654e+09, train_seconds = 3809.6)
[2022-05-31 15:13:55,934][root][INFO] - Step 25254400 @ 6650.7 SPS. Inference batcher size: 33. Learner queue size: 1. Other stats: (step = 25254400, mean_episode_return = 92.216, mean_episode_step = 1040.8, total_loss = 29.273, pg_loss = -13.141, baseline_loss = 49.577, entropy_loss = -7.1637, learner_queue_size = 18, _tick = 6828, _time = 1.654e+09, train_seconds = 3814.6)
[2022-05-31 15:14:00,938][root][INFO] - Step 25287680 @ 6650.7 SPS. Inference batcher size: 100. Learner queue size: 0. Other stats: (step = 25287680, mean_episode_return = None, mean_episode_step = 1007.2, total_loss = 596.47, pg_loss = 412.45, baseline_loss = 191.36, entropy_loss = -7.3394, learner_queue_size = 26, _tick = 6840, _time = 1.654e+09, train_seconds = 3819.6)
[2022-05-31 15:14:05,942][root][INFO] - Step 25320960 @ 6650.7 SPS. Inference batcher size: 151. Learner queue size: 1. Other stats: (step = 25320960, mean_episode_return = None, mean_episode_step = 884.5, total_loss = 29.972, pg_loss = 15.781, baseline_loss = 20.954, entropy_loss = -6.7628, learner_queue_size = 21, _tick = 6850, _time = 1.654e+09, train_seconds = 3824.6)
[2022-05-31 15:14:10,950][root][INFO] - Step 25354240 @ 6645.5 SPS. Inference batcher size: 90. Learner queue size: 3. Other stats: (step = 25354240, mean_episode_return = 196.37, mean_episode_step = 1063.4, total_loss = 343.29, pg_loss = 245.0, baseline_loss = 106.03, entropy_loss = -7.739, learner_queue_size = 21, _tick = 6859, _time = 1.654e+09, train_seconds = 3829.6)
[2022-05-31 15:14:15,954][root][INFO] - Step 25387520 @ 6650.5 SPS. Inference batcher size: 77. Learner queue size: 2. Other stats: (step = 25387520, mean_episode_return = None, mean_episode_step = 938.44, total_loss = 186.0, pg_loss = 155.37, baseline_loss = 37.693, entropy_loss = -7.06, learner_queue_size = 20, _tick = 6870, _time = 1.654e+09, train_seconds = 3834.6)
[2022-05-31 15:14:20,958][root][INFO] - Step 25420800 @ 6650.5 SPS. Inference batcher size: 132. Learner queue size: 24. Other stats: (step = 25420800, mean_episode_return = None, mean_episode_step = 954.75, total_loss = 265.04, pg_loss = 160.26, baseline_loss = 112.11, entropy_loss = -7.3278, learner_queue_size = 17, _tick = 6878, _time = 1.654e+09, train_seconds = 3839.6)
[2022-05-31 15:14:25,962][root][INFO] - Step 25454080 @ 6650.6 SPS. Inference batcher size: 50. Learner queue size: 21. Other stats: (step = 25454080, mean_episode_return = 110.94, mean_episode_step = 983.54, total_loss = -10.033, pg_loss = -28.385, baseline_loss = 25.087, entropy_loss = -6.7349, learner_queue_size = 19, _tick = 6886, _time = 1.654e+09, train_seconds = 3844.6)
[2022-05-31 15:14:30,967][root][INFO] - Step 25487360 @ 6650.3 SPS. Inference batcher size: 40. Learner queue size: 29. Other stats: (step = 25487360, mean_episode_return = 138.12, mean_episode_step = 1123.5, total_loss = -554.36, pg_loss = -592.57, baseline_loss = 45.612, entropy_loss = -7.4015, learner_queue_size = 18, _tick = 6895, _time = 1.654e+09, train_seconds = 3849.7)
[2022-05-31 15:14:35,970][root][INFO] - Step 25520640 @ 6651.1 SPS. Inference batcher size: 95. Learner queue size: 31. Other stats: (step = 25520640, mean_episode_return = 70.52, mean_episode_step = 1163.3, total_loss = -156.63, pg_loss = -235.23, baseline_loss = 86.098, entropy_loss = -7.5043, learner_queue_size = 21, _tick = 6903, _time = 1.654e+09, train_seconds = 3854.7)
[2022-05-31 15:14:40,974][root][INFO] - Step 25553920 @ 6650.9 SPS. Inference batcher size: 1. Learner queue size: 27. Other stats: (step = 25553920, mean_episode_return = 91.099, mean_episode_step = 1359.5, total_loss = 768.41, pg_loss = 526.85, baseline_loss = 248.82, entropy_loss = -7.2601, learner_queue_size = 20, _tick = 6914, _time = 1.654e+09, train_seconds = 3859.7)
[2022-05-31 15:14:45,978][root][INFO] - Step 25584640 @ 6139.2 SPS. Inference batcher size: 116. Learner queue size: 18. Other stats: (step = 25584640, mean_episode_return = 97.869, mean_episode_step = 1127.6, total_loss = 301.29, pg_loss = 221.96, baseline_loss = 86.647, entropy_loss = -7.3158, learner_queue_size = 13, _tick = 6923, _time = 1.654e+09, train_seconds = 3864.7)
[2022-05-31 15:14:50,982][root][INFO] - Step 25620480 @ 7162.2 SPS. Inference batcher size: 139. Learner queue size: 22. Other stats: (step = 25620480, mean_episode_return = 47.007, mean_episode_step = 1015.0, total_loss = 124.26, pg_loss = 85.3, baseline_loss = 44.92, entropy_loss = -5.9607, learner_queue_size = 11, _tick = 6932, _time = 1.654e+09, train_seconds = 3869.7)
[2022-05-31 15:14:55,986][root][INFO] - Step 25653760 @ 6650.3 SPS. Inference batcher size: 102. Learner queue size: 21. Other stats: (step = 25653760, mean_episode_return = 107.57, mean_episode_step = 814.74, total_loss = -177.42, pg_loss = -180.73, baseline_loss = 10.454, entropy_loss = -7.1479, learner_queue_size = 21, _tick = 6944, _time = 1.654e+09, train_seconds = 3874.7)
[2022-05-31 15:15:00,996][root][INFO] - Step 25684480 @ 6132.2 SPS. Inference batcher size: 96. Learner queue size: 21. Other stats: (step = 25684480, mean_episode_return = 82.467, mean_episode_step = 1163.9, total_loss = -89.657, pg_loss = -135.71, baseline_loss = 52.833, entropy_loss = -6.7823, learner_queue_size = 13, _tick = 6955, _time = 1.654e+09, train_seconds = 3879.7)
[2022-05-31 15:15:05,998][root][INFO] - Step 25717760 @ 6653.3 SPS. Inference batcher size: 109. Learner queue size: 12. Other stats: (step = 25717760, mean_episode_return = 80.02, mean_episode_step = 861.95, total_loss = -35.681, pg_loss = -86.32, baseline_loss = 57.427, entropy_loss = -6.7882, learner_queue_size = 18, _tick = 6965, _time = 1.654e+09, train_seconds = 3884.7)
[2022-05-31 15:15:11,004][root][INFO] - Step 25751040 @ 6647.9 SPS. Inference batcher size: 87. Learner queue size: 7. Other stats: (step = 25751040, mean_episode_return = 86.776, mean_episode_step = 1092.4, total_loss = -242.52, pg_loss = -262.23, baseline_loss = 26.497, entropy_loss = -6.7788, learner_queue_size = 19, _tick = 6973, _time = 1.654e+09, train_seconds = 3889.7)
[2022-05-31 15:15:16,010][root][INFO] - Step 25784320 @ 6647.9 SPS. Inference batcher size: 188. Learner queue size: 6. Other stats: (step = 25784320, mean_episode_return = 126.37, mean_episode_step = 996.34, total_loss = -4.8576, pg_loss = -47.717, baseline_loss = 49.923, entropy_loss = -7.0635, learner_queue_size = 21, _tick = 6984, _time = 1.654e+09, train_seconds = 3894.7)
[2022-05-31 15:15:21,015][root][INFO] - Step 25815040 @ 6138.4 SPS. Inference batcher size: 68. Learner queue size: 8. Other stats: (step = 25815040, mean_episode_return = 92.623, mean_episode_step = 1017.6, total_loss = 174.39, pg_loss = 9.3077, baseline_loss = 171.88, entropy_loss = -6.796, learner_queue_size = 14, _tick = 6991, _time = 1.654e+09, train_seconds = 3899.7)
[2022-05-31 15:15:26,019][root][INFO] - Step 25850880 @ 7162.6 SPS. Inference batcher size: 17. Learner queue size: 21. Other stats: (step = 25850880, mean_episode_return = 74.272, mean_episode_step = 978.03, total_loss = 38.801, pg_loss = -13.092, baseline_loss = 59.425, entropy_loss = -7.532, learner_queue_size = 16, _tick = 7003, _time = 1.654e+09, train_seconds = 3904.7)
[2022-05-31 15:15:31,026][root][INFO] - Step 25881600 @ 6135.4 SPS. Inference batcher size: 127. Learner queue size: 19. Other stats: (step = 25881600, mean_episode_return = None, mean_episode_step = 1048.6, total_loss = 421.98, pg_loss = 317.51, baseline_loss = 111.54, entropy_loss = -7.0813, learner_queue_size = 28, _tick = 7012, _time = 1.654e+09, train_seconds = 3909.7)
[2022-05-31 15:15:36,030][root][INFO] - Step 25914880 @ 6649.7 SPS. Inference batcher size: 60. Learner queue size: 9. Other stats: (step = 25914880, mean_episode_return = None, mean_episode_step = 769.94, total_loss = 115.95, pg_loss = -25.962, baseline_loss = 148.79, entropy_loss = -6.8759, learner_queue_size = 18, _tick = 7022, _time = 1.654e+09, train_seconds = 3914.7)
[2022-05-31 15:15:41,034][root][INFO] - Step 25948160 @ 6651.1 SPS. Inference batcher size: 123. Learner queue size: 22. Other stats: (step = 25948160, mean_episode_return = 100.99, mean_episode_step = 863.93, total_loss = 74.807, pg_loss = 32.156, baseline_loss = 48.141, entropy_loss = -5.4899, learner_queue_size = 20, _tick = 7032, _time = 1.654e+09, train_seconds = 3919.7)
[2022-05-31 15:15:46,038][root][INFO] - Step 25981440 @ 6650.7 SPS. Inference batcher size: 123. Learner queue size: 13. Other stats: (step = 25981440, mean_episode_return = None, mean_episode_step = 1084.7, total_loss = 45.52, pg_loss = 21.324, baseline_loss = 31.267, entropy_loss = -7.07, learner_queue_size = 16, _tick = 7039, _time = 1.654e+09, train_seconds = 3924.7)
[2022-05-31 15:15:51,042][root][INFO] - Step 26014720 @ 6650.7 SPS. Inference batcher size: 91. Learner queue size: 7. Other stats: (step = 26014720, mean_episode_return = None, mean_episode_step = 862.62, total_loss = 147.44, pg_loss = 106.18, baseline_loss = 48.413, entropy_loss = -7.1534, learner_queue_size = 21, _tick = 7049, _time = 1.654e+09, train_seconds = 3929.7)
[2022-05-31 15:15:56,046][root][INFO] - Step 26048000 @ 6650.5 SPS. Inference batcher size: 157. Learner queue size: 16. Other stats: (step = 26048000, mean_episode_return = 102.86, mean_episode_step = 881.68, total_loss = -34.577, pg_loss = -62.201, baseline_loss = 34.252, entropy_loss = -6.6291, learner_queue_size = 21, _tick = 7061, _time = 1.654e+09, train_seconds = 3934.7)
[2022-05-31 15:16:01,050][root][INFO] - Step 26081280 @ 6650.8 SPS. Inference batcher size: 155. Learner queue size: 5. Other stats: (step = 26081280, mean_episode_return = 116.07, mean_episode_step = 1002.0, total_loss = 208.88, pg_loss = 68.206, baseline_loss = 146.59, entropy_loss = -5.9158, learner_queue_size = 11, _tick = 7072, _time = 1.654e+09, train_seconds = 3939.7)
[2022-05-31 15:16:06,054][root][INFO] - Step 26114560 @ 6650.7 SPS. Inference batcher size: 68. Learner queue size: 1. Other stats: (step = 26114560, mean_episode_return = 88.95, mean_episode_step = 1153.8, total_loss = 17.448, pg_loss = -34.331, baseline_loss = 58.751, entropy_loss = -6.9721, learner_queue_size = 32, _tick = 7083, _time = 1.654e+09, train_seconds = 3944.7)
[2022-05-31 15:16:11,058][root][INFO] - Step 26147840 @ 6650.6 SPS. Inference batcher size: 90. Learner queue size: 30. Other stats: (step = 26147840, mean_episode_return = 138.23, mean_episode_step = 1138.0, total_loss = 288.96, pg_loss = 223.81, baseline_loss = 71.85, entropy_loss = -6.7024, learner_queue_size = 15, _tick = 7094, _time = 1.654e+09, train_seconds = 3949.7)
[2022-05-31 15:16:16,064][root][INFO] - Step 26181120 @ 6647.6 SPS. Inference batcher size: 16. Learner queue size: 24. Other stats: (step = 26181120, mean_episode_return = None, mean_episode_step = 939.22, total_loss = 364.2, pg_loss = 267.75, baseline_loss = 103.0, entropy_loss = -6.5577, learner_queue_size = 21, _tick = 7104, _time = 1.654e+09, train_seconds = 3954.7)
[2022-05-31 15:16:21,070][root][INFO] - Step 26211840 @ 6137.1 SPS. Inference batcher size: 29. Learner queue size: 18. Other stats: (step = 26211840, mean_episode_return = 9.1998, mean_episode_step = 920.34, total_loss = -7.6813, pg_loss = -30.683, baseline_loss = 29.728, entropy_loss = -6.7263, learner_queue_size = 24, _tick = 7113, _time = 1.654e+09, train_seconds = 3959.8)
[2022-05-31 15:16:26,074][root][INFO] - Step 26245120 @ 6650.6 SPS. Inference batcher size: 128. Learner queue size: 25. Other stats: (step = 26245120, mean_episode_return = 167.88, mean_episode_step = 715.92, total_loss = -23.728, pg_loss = -39.105, baseline_loss = 21.656, entropy_loss = -6.2799, learner_queue_size = 18, _tick = 7125, _time = 1.654e+09, train_seconds = 3964.8)
[2022-05-31 15:16:31,076][root][INFO] - Step 26278400 @ 6653.6 SPS. Inference batcher size: 99. Learner queue size: 15. Other stats: (step = 26278400, mean_episode_return = 86.315, mean_episode_step = 1098.1, total_loss = 87.474, pg_loss = 61.935, baseline_loss = 32.28, entropy_loss = -6.7402, learner_queue_size = 17, _tick = 7136, _time = 1.654e+09, train_seconds = 3969.8)
[2022-05-31 15:16:36,078][root][INFO] - Step 26311680 @ 6653.2 SPS. Inference batcher size: 115. Learner queue size: 24. Other stats: (step = 26311680, mean_episode_return = 15.1, mean_episode_step = 1199.8, total_loss = 83.826, pg_loss = 44.329, baseline_loss = 46.429, entropy_loss = -6.9327, learner_queue_size = 21, _tick = 7145, _time = 1.654e+09, train_seconds = 3974.8)
[2022-05-31 15:16:41,082][root][INFO] - Step 26344960 @ 6650.5 SPS. Inference batcher size: 58. Learner queue size: 3. Other stats: (step = 26344960, mean_episode_return = 70.666, mean_episode_step = 798.63, total_loss = 152.53, pg_loss = 32.073, baseline_loss = 126.74, entropy_loss = -6.2908, learner_queue_size = 11, _tick = 7157, _time = 1.654e+09, train_seconds = 3979.8)
[2022-05-31 15:16:46,088][root][INFO] - Step 26378240 @ 6647.9 SPS. Inference batcher size: 92. Learner queue size: 9. Other stats: (step = 26378240, mean_episode_return = 111.42, mean_episode_step = 851.44, total_loss = 63.943, pg_loss = 16.672, baseline_loss = 54.016, entropy_loss = -6.7452, learner_queue_size = 17, _tick = 7167, _time = 1.654e+09, train_seconds = 3984.8)
[2022-05-31 15:16:51,091][root][INFO] - Step 26411520 @ 6651.5 SPS. Inference batcher size: 80. Learner queue size: 5. Other stats: (step = 26411520, mean_episode_return = None, mean_episode_step = 969.47, total_loss = 349.84, pg_loss = 308.82, baseline_loss = 47.345, entropy_loss = -6.3314, learner_queue_size = 20, _tick = 7177, _time = 1.654e+09, train_seconds = 3989.8)
[2022-05-31 15:16:56,094][root][INFO] - Step 26444800 @ 6652.8 SPS. Inference batcher size: 118. Learner queue size: 0. Other stats: (step = 26444800, mean_episode_return = None, mean_episode_step = 909.97, total_loss = -197.58, pg_loss = -255.06, baseline_loss = 63.983, entropy_loss = -6.5101, learner_queue_size = 14, _tick = 7188, _time = 1.654e+09, train_seconds = 3994.8)
[2022-05-31 15:17:01,098][root][INFO] - Step 26478080 @ 6650.7 SPS. Inference batcher size: 161. Learner queue size: 31. Other stats: (step = 26478080, mean_episode_return = 125.49, mean_episode_step = 857.36, total_loss = -245.96, pg_loss = -286.14, baseline_loss = 46.792, entropy_loss = -6.6084, learner_queue_size = 22, _tick = 7198, _time = 1.654e+09, train_seconds = 3999.8)
[2022-05-31 15:17:06,102][root][INFO] - Step 26511360 @ 6650.5 SPS. Inference batcher size: 112. Learner queue size: 26. Other stats: (step = 26511360, mean_episode_return = None, mean_episode_step = 768.88, total_loss = -181.77, pg_loss = -189.7, baseline_loss = 14.42, entropy_loss = -6.4914, learner_queue_size = 12, _tick = 7209, _time = 1.654e+09, train_seconds = 4004.8)
[2022-05-31 15:17:11,110][root][INFO] - Step 26544640 @ 6645.5 SPS. Inference batcher size: 127. Learner queue size: 2. Other stats: (step = 26544640, mean_episode_return = 76.466, mean_episode_step = 1106.1, total_loss = 225.48, pg_loss = 97.898, baseline_loss = 134.11, entropy_loss = -6.5338, learner_queue_size = 32, _tick = 7218, _time = 1.654e+09, train_seconds = 4009.8)
[2022-05-31 15:17:16,114][root][INFO] - Step 26577920 @ 6650.7 SPS. Inference batcher size: 160. Learner queue size: 23. Other stats: (step = 26577920, mean_episode_return = 29.17, mean_episode_step = 870.76, total_loss = 36.809, pg_loss = -14.813, baseline_loss = 58.635, entropy_loss = -7.0129, learner_queue_size = 18, _tick = 7228, _time = 1.654e+09, train_seconds = 4014.8)
[2022-05-31 15:17:21,119][root][INFO] - Step 26608640 @ 6137.3 SPS. Inference batcher size: 110. Learner queue size: 10. Other stats: (step = 26608640, mean_episode_return = 56.11, mean_episode_step = 751.84, total_loss = -226.01, pg_loss = -284.41, baseline_loss = 65.393, entropy_loss = -6.994, learner_queue_size = 21, _tick = 7237, _time = 1.654e+09, train_seconds = 4019.8)
[2022-05-31 15:17:26,122][root][INFO] - Step 26641920 @ 6652.6 SPS. Inference batcher size: 125. Learner queue size: 14. Other stats: (step = 26641920, mean_episode_return = 187.0, mean_episode_step = 836.24, total_loss = 132.71, pg_loss = 79.71, baseline_loss = 59.755, entropy_loss = -6.7499, learner_queue_size = 29, _tick = 7248, _time = 1.654e+09, train_seconds = 4024.8)
[2022-05-31 15:17:31,127][root][INFO] - Step 26675200 @ 6649.5 SPS. Inference batcher size: 96. Learner queue size: 16. Other stats: (step = 26675200, mean_episode_return = None, mean_episode_step = 753.22, total_loss = -50.333, pg_loss = -82.52, baseline_loss = 38.916, entropy_loss = -6.7296, learner_queue_size = 13, _tick = 7255, _time = 1.654e+09, train_seconds = 4029.8)
[2022-05-31 15:17:36,133][root][INFO] - Step 26708480 @ 6647.9 SPS. Inference batcher size: 181. Learner queue size: 9. Other stats: (step = 26708480, mean_episode_return = 155.98, mean_episode_step = 1131.3, total_loss = 22.921, pg_loss = -40.02, baseline_loss = 69.785, entropy_loss = -6.8432, learner_queue_size = 19, _tick = 7266, _time = 1.654e+09, train_seconds = 4034.8)
[2022-05-31 15:17:41,138][root][INFO] - Step 26741760 @ 6649.2 SPS. Inference batcher size: 135. Learner queue size: 15. Other stats: (step = 26741760, mean_episode_return = 81.861, mean_episode_step = 1034.0, total_loss = -115.89, pg_loss = -167.35, baseline_loss = 58.376, entropy_loss = -6.9153, learner_queue_size = 24, _tick = 7275, _time = 1.654e+09, train_seconds = 4039.8)
[2022-05-31 15:17:46,144][root][INFO] - Step 26775040 @ 6648.0 SPS. Inference batcher size: 107. Learner queue size: 15. Other stats: (step = 26775040, mean_episode_return = 65.641, mean_episode_step = 1153.4, total_loss = -56.781, pg_loss = -84.922, baseline_loss = 35.57, entropy_loss = -7.4292, learner_queue_size = 14, _tick = 7286, _time = 1.654e+09, train_seconds = 4044.8)
[2022-05-31 15:17:51,150][root][INFO] - Step 26808320 @ 6648.2 SPS. Inference batcher size: 123. Learner queue size: 11. Other stats: (step = 26808320, mean_episode_return = 156.2, mean_episode_step = 984.31, total_loss = -87.262, pg_loss = -159.09, baseline_loss = 78.517, entropy_loss = -6.6895, learner_queue_size = 23, _tick = 7297, _time = 1.654e+09, train_seconds = 4049.8)
[2022-05-31 15:17:56,156][root][INFO] - Step 26841600 @ 6648.0 SPS. Inference batcher size: 109. Learner queue size: 2. Other stats: (step = 26841600, mean_episode_return = 43.127, mean_episode_step = 893.5, total_loss = -148.1, pg_loss = -174.22, baseline_loss = 33.094, entropy_loss = -6.9763, learner_queue_size = 18, _tick = 7309, _time = 1.654e+09, train_seconds = 4054.8)
[2022-05-31 15:18:01,162][root][INFO] - Step 26872320 @ 6136.6 SPS. Inference batcher size: 108. Learner queue size: 16. Other stats: (step = 26872320, mean_episode_return = 89.459, mean_episode_step = 1001.4, total_loss = 27.378, pg_loss = -23.593, baseline_loss = 57.869, entropy_loss = -6.8976, learner_queue_size = 16, _tick = 7317, _time = 1.654e+09, train_seconds = 4059.8)
[2022-05-31 15:18:06,168][root][INFO] - Step 26908160 @ 7159.3 SPS. Inference batcher size: 88. Learner queue size: 13. Other stats: (step = 26908160, mean_episode_return = None, mean_episode_step = 774.75, total_loss = 106.91, pg_loss = 52.087, baseline_loss = 61.776, entropy_loss = -6.9533, learner_queue_size = 13, _tick = 7328, _time = 1.654e+09, train_seconds = 4064.9)
[2022-05-31 15:18:11,174][root][INFO] - Step 26938880 @ 6136.6 SPS. Inference batcher size: 82. Learner queue size: 19. Other stats: (step = 26938880, mean_episode_return = 77.1, mean_episode_step = 784.52, total_loss = -185.64, pg_loss = -223.98, baseline_loss = 44.749, entropy_loss = -6.4131, learner_queue_size = 11, _tick = 7338, _time = 1.654e+09, train_seconds = 4069.9)
[2022-05-31 15:18:16,178][root][INFO] - Step 26972160 @ 6650.8 SPS. Inference batcher size: 97. Learner queue size: 18. Other stats: (step = 26972160, mean_episode_return = None, mean_episode_step = 870.91, total_loss = -565.29, pg_loss = -597.84, baseline_loss = 39.258, entropy_loss = -6.7066, learner_queue_size = 20, _tick = 7348, _time = 1.654e+09, train_seconds = 4074.9)
[2022-05-31 15:18:21,183][root][INFO] - Step 27005440 @ 6650.0 SPS. Inference batcher size: 9. Learner queue size: 10. Other stats: (step = 27005440, mean_episode_return = 124.38, mean_episode_step = 867.16, total_loss = 608.26, pg_loss = 490.47, baseline_loss = 123.84, entropy_loss = -6.0495, learner_queue_size = 20, _tick = 7360, _time = 1.654e+09, train_seconds = 4079.9)
[2022-05-31 15:18:26,186][root][INFO] - Step 27038720 @ 6651.4 SPS. Inference batcher size: 146. Learner queue size: 4. Other stats: (step = 27038720, mean_episode_return = 97.106, mean_episode_step = 925.57, total_loss = 116.7, pg_loss = 33.409, baseline_loss = 90.336, entropy_loss = -7.0498, learner_queue_size = 30, _tick = 7371, _time = 1.654e+09, train_seconds = 4084.9)
[2022-05-31 15:18:31,190][root][INFO] - Step 27072000 @ 6650.6 SPS. Inference batcher size: 131. Learner queue size: 4. Other stats: (step = 27072000, mean_episode_return = 9.1498, mean_episode_step = 803.37, total_loss = 156.0, pg_loss = 88.614, baseline_loss = 73.946, entropy_loss = -6.5619, learner_queue_size = 12, _tick = 7383, _time = 1.654e+09, train_seconds = 4089.9)
[2022-05-31 15:18:36,194][root][INFO] - Step 27105280 @ 6650.7 SPS. Inference batcher size: 124. Learner queue size: 0. Other stats: (step = 27105280, mean_episode_return = None, mean_episode_step = 789.38, total_loss = -172.54, pg_loss = -187.9, baseline_loss = 22.421, entropy_loss = -7.0573, learner_queue_size = 18, _tick = 7395, _time = 1.654e+09, train_seconds = 4094.9)
[2022-05-31 15:18:41,198][root][INFO] - Step 27138560 @ 6650.7 SPS. Inference batcher size: 78. Learner queue size: 30. Other stats: (step = 27138560, mean_episode_return = 87.045, mean_episode_step = 731.61, total_loss = 481.96, pg_loss = 371.86, baseline_loss = 116.9, entropy_loss = -6.7985, learner_queue_size = 19, _tick = 7407, _time = 1.654e+09, train_seconds = 4099.9)
[2022-05-31 15:18:46,202][root][INFO] - Step 27171840 @ 6650.5 SPS. Inference batcher size: 139. Learner queue size: 30. Other stats: (step = 27171840, mean_episode_return = None, mean_episode_step = 877.78, total_loss = -11.131, pg_loss = -48.868, baseline_loss = 44.355, entropy_loss = -6.6186, learner_queue_size = 24, _tick = 7419, _time = 1.654e+09, train_seconds = 4104.9)
[2022-05-31 15:18:51,206][root][INFO] - Step 27205120 @ 6650.8 SPS. Inference batcher size: 126. Learner queue size: 2. Other stats: (step = 27205120, mean_episode_return = 92.573, mean_episode_step = 730.61, total_loss = -247.62, pg_loss = -396.9, baseline_loss = 155.44, entropy_loss = -6.1543, learner_queue_size = 14, _tick = 7432, _time = 1.654e+09, train_seconds = 4109.9)
[2022-05-31 15:18:56,210][root][INFO] - Step 27238400 @ 6650.8 SPS. Inference batcher size: 78. Learner queue size: 0. Other stats: (step = 27238400, mean_episode_return = 126.27, mean_episode_step = 805.6, total_loss = 15.363, pg_loss = -114.4, baseline_loss = 136.19, entropy_loss = -6.4312, learner_queue_size = 18, _tick = 7443, _time = 1.654e+09, train_seconds = 4114.9)
[2022-05-31 15:19:01,214][root][INFO] - Step 27271680 @ 6650.6 SPS. Inference batcher size: 122. Learner queue size: 31. Other stats: (step = 27271680, mean_episode_return = 85.755, mean_episode_step = 798.14, total_loss = 373.78, pg_loss = 264.11, baseline_loss = 116.19, entropy_loss = -6.5253, learner_queue_size = 17, _tick = 7451, _time = 1.654e+09, train_seconds = 4119.9)
[2022-05-31 15:19:06,218][root][INFO] - Step 27304960 @ 6650.6 SPS. Inference batcher size: 126. Learner queue size: 31. Other stats: (step = 27304960, mean_episode_return = 64.24, mean_episode_step = 1045.9, total_loss = -162.21, pg_loss = -197.72, baseline_loss = 42.141, entropy_loss = -6.6264, learner_queue_size = 13, _tick = 7460, _time = 1.654e+09, train_seconds = 4124.9)
[2022-05-31 15:19:11,222][root][INFO] - Step 27338240 @ 6650.8 SPS. Inference batcher size: 149. Learner queue size: 20. Other stats: (step = 27338240, mean_episode_return = 44.444, mean_episode_step = 888.89, total_loss = 20.826, pg_loss = -11.243, baseline_loss = 38.311, entropy_loss = -6.2416, learner_queue_size = 17, _tick = 7471, _time = 1.654e+09, train_seconds = 4129.9)
[2022-05-31 15:19:16,228][root][INFO] - Step 27368960 @ 6136.1 SPS. Inference batcher size: 121. Learner queue size: 16. Other stats: (step = 27368960, mean_episode_return = None, mean_episode_step = 949.25, total_loss = 111.59, pg_loss = 84.403, baseline_loss = 33.213, entropy_loss = -6.0309, learner_queue_size = 14, _tick = 7480, _time = 1.654e+09, train_seconds = 4134.9)
[2022-05-31 15:19:21,234][root][INFO] - Step 27402240 @ 6648.0 SPS. Inference batcher size: 81. Learner queue size: 20. Other stats: (step = 27402240, mean_episode_return = 91.986, mean_episode_step = 910.03, total_loss = -39.549, pg_loss = -228.41, baseline_loss = 195.15, entropy_loss = -6.2908, learner_queue_size = 18, _tick = 7491, _time = 1.654e+09, train_seconds = 4139.9)
[2022-05-31 15:19:26,241][root][INFO] - Step 27435520 @ 6647.9 SPS. Inference batcher size: 153. Learner queue size: 12. Other stats: (step = 27435520, mean_episode_return = 11.52, mean_episode_step = 851.42, total_loss = 185.07, pg_loss = 128.28, baseline_loss = 63.646, entropy_loss = -6.8564, learner_queue_size = 18, _tick = 7503, _time = 1.654e+09, train_seconds = 4144.9)
[2022-05-31 15:19:31,247][root][INFO] - Step 27468800 @ 6647.9 SPS. Inference batcher size: 75. Learner queue size: 16. Other stats: (step = 27468800, mean_episode_return = 118.57, mean_episode_step = 846.33, total_loss = -346.79, pg_loss = -379.97, baseline_loss = 39.577, entropy_loss = -6.3971, learner_queue_size = 18, _tick = 7514, _time = 1.654e+09, train_seconds = 4149.9)
[2022-05-31 15:19:36,250][root][INFO] - Step 27502080 @ 6651.5 SPS. Inference batcher size: 59. Learner queue size: 5. Other stats: (step = 27502080, mean_episode_return = 80.394, mean_episode_step = 966.74, total_loss = -141.82, pg_loss = -270.17, baseline_loss = 134.76, entropy_loss = -6.4083, learner_queue_size = 17, _tick = 7524, _time = 1.654e+09, train_seconds = 4154.9)
[2022-05-31 15:19:41,256][root][INFO] - Step 27535360 @ 6647.9 SPS. Inference batcher size: 36. Learner queue size: 21. Other stats: (step = 27535360, mean_episode_return = 46.39, mean_episode_step = 852.55, total_loss = 232.54, pg_loss = 176.54, baseline_loss = 62.577, entropy_loss = -6.5782, learner_queue_size = 19, _tick = 7535, _time = 1.654e+09, train_seconds = 4159.9)
[2022-05-31 15:19:46,262][root][INFO] - Step 27568640 @ 6648.2 SPS. Inference batcher size: 1. Learner queue size: 21. Other stats: (step = 27568640, mean_episode_return = 67.79, mean_episode_step = 868.0, total_loss = 4.6341, pg_loss = -30.339, baseline_loss = 41.163, entropy_loss = -6.1891, learner_queue_size = 21, _tick = 7547, _time = 1.654e+09, train_seconds = 4164.9)
[2022-05-31 15:19:51,268][root][INFO] - Step 27599360 @ 6136.2 SPS. Inference batcher size: 113. Learner queue size: 20. Other stats: (step = 27599360, mean_episode_return = 83.936, mean_episode_step = 910.01, total_loss = -137.14, pg_loss = -261.73, baseline_loss = 130.74, entropy_loss = -6.1535, learner_queue_size = 22, _tick = 7557, _time = 1.654e+09, train_seconds = 4170.0)
[2022-05-31 15:19:56,274][root][INFO] - Step 27632640 @ 6648.0 SPS. Inference batcher size: 129. Learner queue size: 22. Other stats: (step = 27632640, mean_episode_return = 114.21, mean_episode_step = 1138.2, total_loss = -152.0, pg_loss = -189.67, baseline_loss = 44.118, entropy_loss = -6.4424, learner_queue_size = 17, _tick = 7567, _time = 1.654e+09, train_seconds = 4175.0)
[2022-05-31 15:20:01,278][root][INFO] - Step 27665920 @ 6651.3 SPS. Inference batcher size: 102. Learner queue size: 15. Other stats: (step = 27665920, mean_episode_return = 67.616, mean_episode_step = 815.88, total_loss = -82.146, pg_loss = -119.08, baseline_loss = 42.382, entropy_loss = -5.4455, learner_queue_size = 14, _tick = 7579, _time = 1.654e+09, train_seconds = 4180.0)
[2022-05-31 15:20:06,282][root][INFO] - Step 27699200 @ 6651.1 SPS. Inference batcher size: 60. Learner queue size: 18. Other stats: (step = 27699200, mean_episode_return = 158.3, mean_episode_step = 776.73, total_loss = 104.12, pg_loss = -4.2079, baseline_loss = 114.6, entropy_loss = -6.2766, learner_queue_size = 12, _tick = 7591, _time = 1.654e+09, train_seconds = 4185.0)
[2022-05-31 15:20:11,286][root][INFO] - Step 27732480 @ 6650.2 SPS. Inference batcher size: 77. Learner queue size: 13. Other stats: (step = 27732480, mean_episode_return = 39.815, mean_episode_step = 705.87, total_loss = 106.25, pg_loss = 57.153, baseline_loss = 55.714, entropy_loss = -6.6203, learner_queue_size = 20, _tick = 7603, _time = 1.654e+09, train_seconds = 4190.0)
[2022-05-31 15:20:16,290][root][INFO] - Step 27765760 @ 6650.7 SPS. Inference batcher size: 80. Learner queue size: 4. Other stats: (step = 27765760, mean_episode_return = 156.66, mean_episode_step = 763.12, total_loss = 105.35, pg_loss = 69.481, baseline_loss = 42.921, entropy_loss = -7.0506, learner_queue_size = 16, _tick = 7614, _time = 1.654e+09, train_seconds = 4195.0)
[2022-05-31 15:20:21,294][root][INFO] - Step 27799040 @ 6650.7 SPS. Inference batcher size: 63. Learner queue size: 24. Other stats: (step = 27799040, mean_episode_return = 26.44, mean_episode_step = 865.12, total_loss = -106.18, pg_loss = -148.25, baseline_loss = 48.518, entropy_loss = -6.4564, learner_queue_size = 19, _tick = 7624, _time = 1.654e+09, train_seconds = 4200.0)
[2022-05-31 15:20:26,300][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 15:20:26,426][root][INFO] - Step 27829760 @ 6136.6 SPS. Inference batcher size: 185. Learner queue size: 30. Other stats: (step = 27832320, mean_episode_return = 55.091, mean_episode_step = 859.49, total_loss = 112.15, pg_loss = 84.308, baseline_loss = 34.566, entropy_loss = -6.7228, learner_queue_size = 26, _tick = 7635, _time = 1.654e+09, train_seconds = 4205.0)
[2022-05-31 15:20:31,430][root][INFO] - Step 27865600 @ 6986.3 SPS. Inference batcher size: 49. Learner queue size: 2. Other stats: (step = 27865600, mean_episode_return = None, mean_episode_step = 703.34, total_loss = -8.0862, pg_loss = -32.4, baseline_loss = 30.716, entropy_loss = -6.4029, learner_queue_size = 25, _tick = 7646, _time = 1.654e+09, train_seconds = 4210.1)
[2022-05-31 15:20:36,434][root][INFO] - Step 27898880 @ 6650.7 SPS. Inference batcher size: 71. Learner queue size: 31. Other stats: (step = 27898880, mean_episode_return = 97.067, mean_episode_step = 806.63, total_loss = 271.5, pg_loss = 228.59, baseline_loss = 48.758, entropy_loss = -5.8456, learner_queue_size = 20, _tick = 7656, _time = 1.654e+09, train_seconds = 4215.1)
[2022-05-31 15:20:41,439][root][INFO] - Step 27929600 @ 6138.3 SPS. Inference batcher size: 98. Learner queue size: 12. Other stats: (step = 27929600, mean_episode_return = None, mean_episode_step = 1138.5, total_loss = -30.066, pg_loss = -63.572, baseline_loss = 39.679, entropy_loss = -6.1736, learner_queue_size = 19, _tick = 7666, _time = 1.654e+09, train_seconds = 4220.1)
[2022-05-31 15:20:46,445][root][INFO] - Step 27962880 @ 6648.1 SPS. Inference batcher size: 154. Learner queue size: 10. Other stats: (step = 27962880, mean_episode_return = None, mean_episode_step = 946.88, total_loss = 30.927, pg_loss = 8.1435, baseline_loss = 28.901, entropy_loss = -6.117, learner_queue_size = 25, _tick = 7675, _time = 1.654e+09, train_seconds = 4225.1)
[2022-05-31 15:20:51,450][root][INFO] - Step 27996160 @ 6648.8 SPS. Inference batcher size: 42. Learner queue size: 18. Other stats: (step = 27996160, mean_episode_return = 77.629, mean_episode_step = 899.59, total_loss = 555.9, pg_loss = 402.29, baseline_loss = 159.97, entropy_loss = -6.352, learner_queue_size = 12, _tick = 7686, _time = 1.654e+09, train_seconds = 4230.1)
[2022-05-31 15:20:56,454][root][INFO] - Step 28029440 @ 6650.6 SPS. Inference batcher size: 141. Learner queue size: 11. Other stats: (step = 28029440, mean_episode_return = 121.37, mean_episode_step = 867.6, total_loss = -55.854, pg_loss = -86.087, baseline_loss = 36.785, entropy_loss = -6.5515, learner_queue_size = 24, _tick = 7699, _time = 1.654e+09, train_seconds = 4235.1)
[2022-05-31 15:21:01,458][root][INFO] - Step 28062720 @ 6650.7 SPS. Inference batcher size: 110. Learner queue size: 8. Other stats: (step = 28062720, mean_episode_return = None, mean_episode_step = 799.53, total_loss = 318.25, pg_loss = 248.97, baseline_loss = 75.879, entropy_loss = -6.5952, learner_queue_size = 20, _tick = 7711, _time = 1.654e+09, train_seconds = 4240.1)
[2022-05-31 15:21:06,462][root][INFO] - Step 28096000 @ 6650.8 SPS. Inference batcher size: 142. Learner queue size: 29. Other stats: (step = 28096000, mean_episode_return = 94.184, mean_episode_step = 691.86, total_loss = 77.4, pg_loss = -3.3808, baseline_loss = 86.997, entropy_loss = -6.2161, learner_queue_size = 22, _tick = 7722, _time = 1.654e+09, train_seconds = 4245.1)
[2022-05-31 15:21:11,468][root][INFO] - Step 28129280 @ 6648.0 SPS. Inference batcher size: 132. Learner queue size: 3. Other stats: (step = 28129280, mean_episode_return = 78.638, mean_episode_step = 843.0, total_loss = -37.925, pg_loss = -90.906, baseline_loss = 59.865, entropy_loss = -6.8838, learner_queue_size = 30, _tick = 7731, _time = 1.654e+09, train_seconds = 4250.2)
[2022-05-31 15:21:16,471][root][INFO] - Step 28162560 @ 6652.7 SPS. Inference batcher size: 87. Learner queue size: 25. Other stats: (step = 28162560, mean_episode_return = 90.151, mean_episode_step = 786.98, total_loss = 330.74, pg_loss = 218.06, baseline_loss = 119.22, entropy_loss = -6.5368, learner_queue_size = 13, _tick = 7743, _time = 1.654e+09, train_seconds = 4255.2)
[2022-05-31 15:21:21,474][root][INFO] - Step 28195840 @ 6651.4 SPS. Inference batcher size: 88. Learner queue size: 25. Other stats: (step = 28195840, mean_episode_return = 50.765, mean_episode_step = 735.36, total_loss = -189.06, pg_loss = -197.35, baseline_loss = 14.888, entropy_loss = -6.6001, learner_queue_size = 15, _tick = 7753, _time = 1.654e+09, train_seconds = 4260.2)
[2022-05-31 15:21:26,480][root][INFO] - Step 28226560 @ 6136.0 SPS. Inference batcher size: 106. Learner queue size: 18. Other stats: (step = 28226560, mean_episode_return = 140.04, mean_episode_step = 904.16, total_loss = 20.498, pg_loss = 1.6218, baseline_loss = 24.794, entropy_loss = -5.9174, learner_queue_size = 19, _tick = 7762, _time = 1.654e+09, train_seconds = 4265.2)
[2022-05-31 15:21:31,486][root][INFO] - Step 28259840 @ 6648.0 SPS. Inference batcher size: 94. Learner queue size: 16. Other stats: (step = 28259840, mean_episode_return = 73.34, mean_episode_step = 923.84, total_loss = 166.36, pg_loss = 106.48, baseline_loss = 66.997, entropy_loss = -7.1207, learner_queue_size = 16, _tick = 7773, _time = 1.654e+09, train_seconds = 4270.2)
[2022-05-31 15:21:36,492][root][INFO] - Step 28293120 @ 6648.2 SPS. Inference batcher size: 76. Learner queue size: 23. Other stats: (step = 28293120, mean_episode_return = 49.461, mean_episode_step = 909.99, total_loss = 170.44, pg_loss = 124.12, baseline_loss = 51.041, entropy_loss = -4.7244, learner_queue_size = 21, _tick = 7783, _time = 1.654e+09, train_seconds = 4275.2)
[2022-05-31 15:21:41,498][root][INFO] - Step 28326400 @ 6648.0 SPS. Inference batcher size: 109. Learner queue size: 20. Other stats: (step = 28326400, mean_episode_return = 119.15, mean_episode_step = 901.55, total_loss = -27.442, pg_loss = -75.835, baseline_loss = 54.605, entropy_loss = -6.2115, learner_queue_size = 19, _tick = 7794, _time = 1.654e+09, train_seconds = 4280.2)
[2022-05-31 15:21:46,502][root][INFO] - Step 28359680 @ 6651.4 SPS. Inference batcher size: 109. Learner queue size: 9. Other stats: (step = 28359680, mean_episode_return = 107.43, mean_episode_step = 903.44, total_loss = 910.51, pg_loss = 711.69, baseline_loss = 205.61, entropy_loss = -6.7884, learner_queue_size = 16, _tick = 7805, _time = 1.654e+09, train_seconds = 4285.2)
[2022-05-31 15:21:51,506][root][INFO] - Step 28392960 @ 6650.2 SPS. Inference batcher size: 93. Learner queue size: 8. Other stats: (step = 28392960, mean_episode_return = 79.653, mean_episode_step = 789.6, total_loss = 172.09, pg_loss = 38.586, baseline_loss = 140.17, entropy_loss = -6.6619, learner_queue_size = 11, _tick = 7817, _time = 1.654e+09, train_seconds = 4290.2)
[2022-05-31 15:21:56,510][root][INFO] - Step 28426240 @ 6651.1 SPS. Inference batcher size: 25. Learner queue size: 12. Other stats: (step = 28426240, mean_episode_return = 78.81, mean_episode_step = 864.62, total_loss = -129.38, pg_loss = -157.11, baseline_loss = 34.644, entropy_loss = -6.9147, learner_queue_size = 19, _tick = 7827, _time = 1.654e+09, train_seconds = 4295.2)
[2022-05-31 15:22:01,514][root][INFO] - Step 28459520 @ 6650.7 SPS. Inference batcher size: 104. Learner queue size: 9. Other stats: (step = 28459520, mean_episode_return = None, mean_episode_step = 989.84, total_loss = -47.855, pg_loss = -66.178, baseline_loss = 25.121, entropy_loss = -6.7976, learner_queue_size = 17, _tick = 7835, _time = 1.654e+09, train_seconds = 4300.2)
[2022-05-31 15:22:06,520][root][INFO] - Step 28492800 @ 6647.8 SPS. Inference batcher size: 101. Learner queue size: 4. Other stats: (step = 28492800, mean_episode_return = 68.764, mean_episode_step = 755.87, total_loss = 184.93, pg_loss = 122.99, baseline_loss = 68.407, entropy_loss = -6.4725, learner_queue_size = 24, _tick = 7846, _time = 1.654e+09, train_seconds = 4305.2)
[2022-05-31 15:22:11,527][root][INFO] - Step 28526080 @ 6647.6 SPS. Inference batcher size: 64. Learner queue size: 22. Other stats: (step = 28526080, mean_episode_return = 12.09, mean_episode_step = 753.68, total_loss = -76.775, pg_loss = -98.162, baseline_loss = 28.128, entropy_loss = -6.7411, learner_queue_size = 19, _tick = 7858, _time = 1.654e+09, train_seconds = 4310.2)
[2022-05-31 15:22:16,533][root][INFO] - Step 28556800 @ 6136.0 SPS. Inference batcher size: 97. Learner queue size: 16. Other stats: (step = 28556800, mean_episode_return = 60.052, mean_episode_step = 752.97, total_loss = 214.08, pg_loss = 165.29, baseline_loss = 54.904, entropy_loss = -6.1129, learner_queue_size = 12, _tick = 7867, _time = 1.654e+09, train_seconds = 4315.2)
[2022-05-31 15:22:21,538][root][INFO] - Step 28592640 @ 7160.9 SPS. Inference batcher size: 79. Learner queue size: 21. Other stats: (step = 28592640, mean_episode_return = 129.01, mean_episode_step = 832.5, total_loss = -173.71, pg_loss = -217.43, baseline_loss = 50.302, entropy_loss = -6.581, learner_queue_size = 21, _tick = 7881, _time = 1.654e+09, train_seconds = 4320.2)
[2022-05-31 15:22:26,544][root][INFO] - Step 28623360 @ 6136.3 SPS. Inference batcher size: 126. Learner queue size: 12. Other stats: (step = 28623360, mean_episode_return = 96.887, mean_episode_step = 853.54, total_loss = 125.33, pg_loss = 88.978, baseline_loss = 42.646, entropy_loss = -6.2975, learner_queue_size = 28, _tick = 7891, _time = 1.654e+09, train_seconds = 4325.2)
[2022-05-31 15:22:31,550][root][INFO] - Step 28656640 @ 6648.4 SPS. Inference batcher size: 73. Learner queue size: 4. Other stats: (step = 28656640, mean_episode_return = None, mean_episode_step = 771.0, total_loss = -147.06, pg_loss = -168.25, baseline_loss = 27.423, entropy_loss = -6.24, learner_queue_size = 24, _tick = 7899, _time = 1.654e+09, train_seconds = 4330.2)
[2022-05-31 15:22:36,554][root][INFO] - Step 28689920 @ 6650.7 SPS. Inference batcher size: 176. Learner queue size: 5. Other stats: (step = 28689920, mean_episode_return = 203.38, mean_episode_step = 856.76, total_loss = 390.0, pg_loss = 293.1, baseline_loss = 102.24, entropy_loss = -5.348, learner_queue_size = 25, _tick = 7911, _time = 1.654e+09, train_seconds = 4335.2)
[2022-05-31 15:22:41,558][root][INFO] - Step 28723200 @ 6650.6 SPS. Inference batcher size: 79. Learner queue size: 29. Other stats: (step = 28723200, mean_episode_return = 99.884, mean_episode_step = 665.97, total_loss = 289.31, pg_loss = 193.69, baseline_loss = 102.03, entropy_loss = -6.4145, learner_queue_size = 17, _tick = 7923, _time = 1.654e+09, train_seconds = 4340.2)
[2022-05-31 15:22:46,562][root][INFO] - Step 28756480 @ 6650.3 SPS. Inference batcher size: 58. Learner queue size: 25. Other stats: (step = 28756480, mean_episode_return = 54.24, mean_episode_step = 951.37, total_loss = 117.82, pg_loss = 24.731, baseline_loss = 99.418, entropy_loss = -6.3311, learner_queue_size = 17, _tick = 7935, _time = 1.654e+09, train_seconds = 4345.2)
[2022-05-31 15:22:51,569][root][INFO] - Step 28789760 @ 6647.5 SPS. Inference batcher size: 152. Learner queue size: 2. Other stats: (step = 28789760, mean_episode_return = 67.625, mean_episode_step = 985.54, total_loss = 24.042, pg_loss = -5.8904, baseline_loss = 36.451, entropy_loss = -6.519, learner_queue_size = 18, _tick = 7945, _time = 1.654e+09, train_seconds = 4350.3)
[2022-05-31 15:22:56,574][root][INFO] - Step 28823040 @ 6649.0 SPS. Inference batcher size: 87. Learner queue size: 4. Other stats: (step = 28823040, mean_episode_return = 74.674, mean_episode_step = 894.95, total_loss = 268.99, pg_loss = 173.59, baseline_loss = 102.07, entropy_loss = -6.6738, learner_queue_size = 20, _tick = 7956, _time = 1.654e+09, train_seconds = 4355.3)
[2022-05-31 15:23:01,578][root][INFO] - Step 28856320 @ 6650.8 SPS. Inference batcher size: 61. Learner queue size: 3. Other stats: (step = 28856320, mean_episode_return = 62.989, mean_episode_step = 684.48, total_loss = 241.47, pg_loss = 180.62, baseline_loss = 67.37, entropy_loss = -6.5127, learner_queue_size = 18, _tick = 7967, _time = 1.654e+09, train_seconds = 4360.3)
[2022-05-31 15:23:06,582][root][INFO] - Step 28889600 @ 6650.7 SPS. Inference batcher size: 181. Learner queue size: 26. Other stats: (step = 28889600, mean_episode_return = 114.65, mean_episode_step = 786.93, total_loss = -193.82, pg_loss = -206.95, baseline_loss = 20.132, entropy_loss = -7.0014, learner_queue_size = 26, _tick = 7977, _time = 1.654e+09, train_seconds = 4365.3)
[2022-05-31 15:23:11,586][root][INFO] - Step 28922880 @ 6650.7 SPS. Inference batcher size: 65. Learner queue size: 27. Other stats: (step = 28922880, mean_episode_return = 51.534, mean_episode_step = 665.46, total_loss = -210.25, pg_loss = -235.56, baseline_loss = 31.914, entropy_loss = -6.6102, learner_queue_size = 15, _tick = 7987, _time = 1.654e+09, train_seconds = 4370.3)
[2022-05-31 15:23:16,590][root][INFO] - Step 28956160 @ 6650.7 SPS. Inference batcher size: 154. Learner queue size: 0. Other stats: (step = 28956160, mean_episode_return = 103.75, mean_episode_step = 980.29, total_loss = -81.608, pg_loss = -105.66, baseline_loss = 31.288, entropy_loss = -7.2351, learner_queue_size = 19, _tick = 7997, _time = 1.654e+09, train_seconds = 4375.3)
[2022-05-31 15:23:21,596][root][INFO] - Step 28986880 @ 6136.5 SPS. Inference batcher size: 191. Learner queue size: 17. Other stats: (step = 28986880, mean_episode_return = 119.51, mean_episode_step = 862.59, total_loss = 253.89, pg_loss = 190.43, baseline_loss = 70.47, entropy_loss = -7.0107, learner_queue_size = 19, _tick = 8008, _time = 1.654e+09, train_seconds = 4380.3)
[2022-05-31 15:23:26,602][root][INFO] - Step 29022720 @ 7159.6 SPS. Inference batcher size: 166. Learner queue size: 17. Other stats: (step = 29022720, mean_episode_return = 99.539, mean_episode_step = 814.49, total_loss = 296.51, pg_loss = 224.28, baseline_loss = 79.4, entropy_loss = -7.169, learner_queue_size = 17, _tick = 8022, _time = 1.654e+09, train_seconds = 4385.3)
[2022-05-31 15:23:31,606][root][INFO] - Step 29056000 @ 6650.5 SPS. Inference batcher size: 88. Learner queue size: 19. Other stats: (step = 29056000, mean_episode_return = 95.882, mean_episode_step = 703.67, total_loss = 251.14, pg_loss = 117.31, baseline_loss = 140.78, entropy_loss = -6.9498, learner_queue_size = 19, _tick = 8034, _time = 1.654e+09, train_seconds = 4390.3)
[2022-05-31 15:23:36,610][root][INFO] - Step 29086720 @ 6139.2 SPS. Inference batcher size: 120. Learner queue size: 19. Other stats: (step = 29086720, mean_episode_return = 148.28, mean_episode_step = 831.5, total_loss = -223.34, pg_loss = -244.83, baseline_loss = 28.436, entropy_loss = -6.9434, learner_queue_size = 14, _tick = 8045, _time = 1.654e+09, train_seconds = 4395.3)
[2022-05-31 15:23:41,616][root][INFO] - Step 29120000 @ 6647.9 SPS. Inference batcher size: 128. Learner queue size: 15. Other stats: (step = 29120000, mean_episode_return = -3.9504, mean_episode_step = 846.13, total_loss = -165.36, pg_loss = -185.27, baseline_loss = 26.62, entropy_loss = -6.7144, learner_queue_size = 17, _tick = 8054, _time = 1.654e+09, train_seconds = 4400.3)
[2022-05-31 15:23:46,622][root][INFO] - Step 29153280 @ 6647.9 SPS. Inference batcher size: 51. Learner queue size: 17. Other stats: (step = 29153280, mean_episode_return = 117.21, mean_episode_step = 790.43, total_loss = -125.55, pg_loss = -185.31, baseline_loss = 66.001, entropy_loss = -6.2423, learner_queue_size = 10, _tick = 8064, _time = 1.654e+09, train_seconds = 4405.3)
[2022-05-31 15:23:51,626][root][INFO] - Step 29186560 @ 6650.8 SPS. Inference batcher size: 213. Learner queue size: 10. Other stats: (step = 29186560, mean_episode_return = 130.13, mean_episode_step = 747.83, total_loss = 198.67, pg_loss = 21.749, baseline_loss = 183.4, entropy_loss = -6.4858, learner_queue_size = 21, _tick = 8076, _time = 1.654e+09, train_seconds = 4410.3)
[2022-05-31 15:23:56,630][root][INFO] - Step 29219840 @ 6650.6 SPS. Inference batcher size: 150. Learner queue size: 17. Other stats: (step = 29219840, mean_episode_return = 5.6197, mean_episode_step = 874.86, total_loss = -93.293, pg_loss = -91.742, baseline_loss = 4.9822, entropy_loss = -6.5338, learner_queue_size = 23, _tick = 8089, _time = 1.654e+09, train_seconds = 4415.3)
[2022-05-31 15:24:01,636][root][INFO] - Step 29253120 @ 6648.0 SPS. Inference batcher size: 88. Learner queue size: 4. Other stats: (step = 29253120, mean_episode_return = None, mean_episode_step = 932.31, total_loss = -14.41, pg_loss = -42.826, baseline_loss = 34.781, entropy_loss = -6.3652, learner_queue_size = 22, _tick = 8099, _time = 1.654e+09, train_seconds = 4420.3)
[2022-05-31 15:24:06,642][root][INFO] - Step 29286400 @ 6648.2 SPS. Inference batcher size: 1. Learner queue size: 14. Other stats: (step = 29286400, mean_episode_return = 25.185, mean_episode_step = 677.49, total_loss = 108.18, pg_loss = 59.108, baseline_loss = 55.523, entropy_loss = -6.4525, learner_queue_size = 19, _tick = 8108, _time = 1.654e+09, train_seconds = 4425.3)
[2022-05-31 15:24:11,646][root][INFO] - Step 29319680 @ 6650.6 SPS. Inference batcher size: 123. Learner queue size: 9. Other stats: (step = 29319680, mean_episode_return = 179.2, mean_episode_step = 622.76, total_loss = 291.97, pg_loss = 160.93, baseline_loss = 137.51, entropy_loss = -6.4667, learner_queue_size = 19, _tick = 8120, _time = 1.654e+09, train_seconds = 4430.3)
[2022-05-31 15:24:16,650][root][INFO] - Step 29352960 @ 6650.7 SPS. Inference batcher size: 97. Learner queue size: 5. Other stats: (step = 29352960, mean_episode_return = None, mean_episode_step = 995.56, total_loss = -332.23, pg_loss = -340.77, baseline_loss = 15.305, entropy_loss = -6.7686, learner_queue_size = 19, _tick = 8130, _time = 1.654e+09, train_seconds = 4435.3)
[2022-05-31 15:24:21,656][root][INFO] - Step 29386240 @ 6648.4 SPS. Inference batcher size: 95. Learner queue size: 5. Other stats: (step = 29386240, mean_episode_return = 84.929, mean_episode_step = 820.75, total_loss = 218.69, pg_loss = 114.84, baseline_loss = 110.49, entropy_loss = -6.6391, learner_queue_size = 19, _tick = 8140, _time = 1.654e+09, train_seconds = 4440.3)
[2022-05-31 15:24:26,658][root][INFO] - Step 29419520 @ 6653.0 SPS. Inference batcher size: 62. Learner queue size: 31. Other stats: (step = 29419520, mean_episode_return = 87.989, mean_episode_step = 792.31, total_loss = 62.431, pg_loss = -65.366, baseline_loss = 134.11, entropy_loss = -6.3167, learner_queue_size = 20, _tick = 8152, _time = 1.654e+09, train_seconds = 4445.3)
[2022-05-31 15:24:31,662][root][INFO] - Step 29452800 @ 6650.5 SPS. Inference batcher size: 119. Learner queue size: 20. Other stats: (step = 29452800, mean_episode_return = 83.099, mean_episode_step = 725.3, total_loss = 58.377, pg_loss = -5.4883, baseline_loss = 70.706, entropy_loss = -6.8403, learner_queue_size = 19, _tick = 8163, _time = 1.654e+09, train_seconds = 4450.3)
[2022-05-31 15:24:36,666][root][INFO] - Step 29483520 @ 6139.1 SPS. Inference batcher size: 128. Learner queue size: 17. Other stats: (step = 29483520, mean_episode_return = 151.5, mean_episode_step = 734.3, total_loss = -207.73, pg_loss = -250.1, baseline_loss = 49.13, entropy_loss = -6.7686, learner_queue_size = 13, _tick = 8175, _time = 1.654e+09, train_seconds = 4455.4)
[2022-05-31 15:24:41,670][root][INFO] - Step 29516800 @ 6650.8 SPS. Inference batcher size: 170. Learner queue size: 17. Other stats: (step = 29516800, mean_episode_return = 161.51, mean_episode_step = 742.52, total_loss = -96.034, pg_loss = -122.57, baseline_loss = 33.28, entropy_loss = -6.7484, learner_queue_size = 14, _tick = 8186, _time = 1.654e+09, train_seconds = 4460.4)
[2022-05-31 15:24:46,674][root][INFO] - Step 29550080 @ 6650.6 SPS. Inference batcher size: 92. Learner queue size: 20. Other stats: (step = 29550080, mean_episode_return = 105.72, mean_episode_step = 714.38, total_loss = -314.18, pg_loss = -329.99, baseline_loss = 22.506, entropy_loss = -6.6981, learner_queue_size = 26, _tick = 8198, _time = 1.654e+09, train_seconds = 4465.4)
[2022-05-31 15:24:51,678][root][INFO] - Step 29583360 @ 6650.7 SPS. Inference batcher size: 150. Learner queue size: 19. Other stats: (step = 29583360, mean_episode_return = 119.73, mean_episode_step = 883.27, total_loss = 80.824, pg_loss = 50.519, baseline_loss = 36.915, entropy_loss = -6.6095, learner_queue_size = 18, _tick = 8209, _time = 1.654e+09, train_seconds = 4470.4)
[2022-05-31 15:24:56,682][root][INFO] - Step 29616640 @ 6650.7 SPS. Inference batcher size: 120. Learner queue size: 15. Other stats: (step = 29616640, mean_episode_return = 164.54, mean_episode_step = 591.96, total_loss = 186.33, pg_loss = 99.138, baseline_loss = 92.005, entropy_loss = -4.81, learner_queue_size = 14, _tick = 8219, _time = 1.654e+09, train_seconds = 4475.4)
[2022-05-31 15:25:01,686][root][INFO] - Step 29649920 @ 6650.7 SPS. Inference batcher size: 127. Learner queue size: 13. Other stats: (step = 29649920, mean_episode_return = 200.37, mean_episode_step = 808.65, total_loss = -126.54, pg_loss = -159.24, baseline_loss = 39.595, entropy_loss = -6.8943, learner_queue_size = 16, _tick = 8231, _time = 1.654e+09, train_seconds = 4480.4)
[2022-05-31 15:25:06,690][root][INFO] - Step 29683200 @ 6650.5 SPS. Inference batcher size: 108. Learner queue size: 5. Other stats: (step = 29683200, mean_episode_return = 84.015, mean_episode_step = 711.52, total_loss = 413.96, pg_loss = 314.72, baseline_loss = 106.35, entropy_loss = -7.1149, learner_queue_size = 14, _tick = 8242, _time = 1.654e+09, train_seconds = 4485.4)
[2022-05-31 15:25:11,694][root][INFO] - Step 29716480 @ 6650.8 SPS. Inference batcher size: 142. Learner queue size: 7. Other stats: (step = 29716480, mean_episode_return = None, mean_episode_step = 707.28, total_loss = 178.44, pg_loss = 140.08, baseline_loss = 45.738, entropy_loss = -7.3852, learner_queue_size = 31, _tick = 8252, _time = 1.654e+09, train_seconds = 4490.4)
[2022-05-31 15:25:16,698][root][INFO] - Step 29749760 @ 6650.7 SPS. Inference batcher size: 55. Learner queue size: 16. Other stats: (step = 29749760, mean_episode_return = 155.0, mean_episode_step = 959.25, total_loss = 346.07, pg_loss = 270.36, baseline_loss = 82.12, entropy_loss = -6.4032, learner_queue_size = 15, _tick = 8261, _time = 1.654e+09, train_seconds = 4495.4)
[2022-05-31 15:25:21,702][root][INFO] - Step 29780480 @ 6139.1 SPS. Inference batcher size: 97. Learner queue size: 12. Other stats: (step = 29780480, mean_episode_return = 49.55, mean_episode_step = 1045.7, total_loss = -14.329, pg_loss = -26.447, baseline_loss = 18.311, entropy_loss = -6.1934, learner_queue_size = 11, _tick = 8270, _time = 1.654e+09, train_seconds = 4500.4)
[2022-05-31 15:25:26,709][root][INFO] - Step 29813760 @ 6647.3 SPS. Inference batcher size: 65. Learner queue size: 25. Other stats: (step = 29813760, mean_episode_return = 101.62, mean_episode_step = 781.06, total_loss = -89.615, pg_loss = -124.91, baseline_loss = 41.979, entropy_loss = -6.6829, learner_queue_size = 17, _tick = 8281, _time = 1.654e+09, train_seconds = 4505.4)
[2022-05-31 15:25:31,715][root][INFO] - Step 29847040 @ 6647.3 SPS. Inference batcher size: 175. Learner queue size: 20. Other stats: (step = 29847040, mean_episode_return = 113.57, mean_episode_step = 886.19, total_loss = -103.55, pg_loss = -114.29, baseline_loss = 16.441, entropy_loss = -5.7012, learner_queue_size = 16, _tick = 8293, _time = 1.654e+09, train_seconds = 4510.4)
[2022-05-31 15:25:36,721][root][INFO] - Step 29880320 @ 6648.0 SPS. Inference batcher size: 126. Learner queue size: 17. Other stats: (step = 29880320, mean_episode_return = 34.563, mean_episode_step = 820.98, total_loss = -70.619, pg_loss = -107.34, baseline_loss = 43.953, entropy_loss = -7.2346, learner_queue_size = 29, _tick = 8304, _time = 1.654e+09, train_seconds = 4515.4)
[2022-05-31 15:25:41,727][root][INFO] - Step 29913600 @ 6648.7 SPS. Inference batcher size: 40. Learner queue size: 11. Other stats: (step = 29913600, mean_episode_return = 66.034, mean_episode_step = 857.91, total_loss = -66.351, pg_loss = -75.501, baseline_loss = 15.462, entropy_loss = -6.3124, learner_queue_size = 15, _tick = 8314, _time = 1.654e+09, train_seconds = 4520.4)
[2022-05-31 15:25:46,730][root][INFO] - Step 29946880 @ 6651.6 SPS. Inference batcher size: 106. Learner queue size: 2. Other stats: (step = 29946880, mean_episode_return = 60.94, mean_episode_step = 922.46, total_loss = -61.264, pg_loss = -93.657, baseline_loss = 39.264, entropy_loss = -6.8714, learner_queue_size = 14, _tick = 8323, _time = 1.654e+09, train_seconds = 4525.4)
[2022-05-31 15:25:51,734][root][INFO] - Step 29980160 @ 6650.7 SPS. Inference batcher size: 152. Learner queue size: 8. Other stats: (step = 29980160, mean_episode_return = 28.63, mean_episode_step = 861.99, total_loss = 161.53, pg_loss = 38.014, baseline_loss = 130.59, entropy_loss = -7.0743, learner_queue_size = 25, _tick = 8333, _time = 1.654e+09, train_seconds = 4530.4)
[2022-05-31 15:25:56,738][root][INFO] - Step 30013440 @ 6650.7 SPS. Inference batcher size: 25. Learner queue size: 29. Other stats: (step = 30013440, mean_episode_return = 87.601, mean_episode_step = 911.75, total_loss = 45.122, pg_loss = -58.09, baseline_loss = 110.27, entropy_loss = -7.0599, learner_queue_size = 22, _tick = 8344, _time = 1.654e+09, train_seconds = 4535.4)
[2022-05-31 15:26:01,744][root][INFO] - Step 30046720 @ 6648.4 SPS. Inference batcher size: 135. Learner queue size: 1. Other stats: (step = 30046720, mean_episode_return = None, mean_episode_step = 853.75, total_loss = -39.442, pg_loss = -69.547, baseline_loss = 36.781, entropy_loss = -6.6763, learner_queue_size = 21, _tick = 8353, _time = 1.654e+09, train_seconds = 4540.4)
[2022-05-31 15:26:06,746][root][INFO] - Step 30080000 @ 6652.8 SPS. Inference batcher size: 130. Learner queue size: 25. Other stats: (step = 30080000, mean_episode_return = 76.26, mean_episode_step = 725.9, total_loss = -150.28, pg_loss = -217.21, baseline_loss = 73.406, entropy_loss = -6.4781, learner_queue_size = 18, _tick = 8364, _time = 1.654e+09, train_seconds = 4545.4)
[2022-05-31 15:26:11,750][root][INFO] - Step 30110720 @ 6139.1 SPS. Inference batcher size: 190. Learner queue size: 20. Other stats: (step = 30110720, mean_episode_return = 25.43, mean_episode_step = 812.88, total_loss = 437.03, pg_loss = 358.27, baseline_loss = 85.674, entropy_loss = -6.9147, learner_queue_size = 11, _tick = 8373, _time = 1.654e+09, train_seconds = 4550.4)
[2022-05-31 15:26:16,754][root][INFO] - Step 30144000 @ 6650.7 SPS. Inference batcher size: 95. Learner queue size: 19. Other stats: (step = 30144000, mean_episode_return = 138.24, mean_episode_step = 930.1, total_loss = 78.153, pg_loss = -55.804, baseline_loss = 141.17, entropy_loss = -7.2173, learner_queue_size = 18, _tick = 8385, _time = 1.654e+09, train_seconds = 4555.4)
[2022-05-31 15:26:21,758][root][INFO] - Step 30177280 @ 6650.8 SPS. Inference batcher size: 150. Learner queue size: 6. Other stats: (step = 30177280, mean_episode_return = 120.34, mean_episode_step = 790.59, total_loss = -557.29, pg_loss = -606.41, baseline_loss = 56.011, entropy_loss = -6.8927, learner_queue_size = 18, _tick = 8396, _time = 1.654e+09, train_seconds = 4560.4)
[2022-05-31 15:26:26,762][root][INFO] - Step 30210560 @ 6650.5 SPS. Inference batcher size: 124. Learner queue size: 9. Other stats: (step = 30210560, mean_episode_return = 165.44, mean_episode_step = 766.1, total_loss = 181.28, pg_loss = 139.23, baseline_loss = 48.982, entropy_loss = -6.9359, learner_queue_size = 22, _tick = 8405, _time = 1.654e+09, train_seconds = 4565.4)
[2022-05-31 15:26:31,768][root][INFO] - Step 30243840 @ 6648.0 SPS. Inference batcher size: 143. Learner queue size: 13. Other stats: (step = 30243840, mean_episode_return = 48.576, mean_episode_step = 810.51, total_loss = 11.345, pg_loss = -15.796, baseline_loss = 33.888, entropy_loss = -6.7472, learner_queue_size = 31, _tick = 8417, _time = 1.654e+09, train_seconds = 4570.5)
[2022-05-31 15:26:36,774][root][INFO] - Step 30277120 @ 6648.1 SPS. Inference batcher size: 114. Learner queue size: 2. Other stats: (step = 30277120, mean_episode_return = 83.202, mean_episode_step = 1131.1, total_loss = -51.124, pg_loss = -59.339, baseline_loss = 15.641, entropy_loss = -7.4261, learner_queue_size = 15, _tick = 8428, _time = 1.654e+09, train_seconds = 4575.5)
[2022-05-31 15:26:41,780][root][INFO] - Step 30310400 @ 6647.9 SPS. Inference batcher size: 130. Learner queue size: 3. Other stats: (step = 30310400, mean_episode_return = 47.444, mean_episode_step = 704.65, total_loss = 102.22, pg_loss = 70.959, baseline_loss = 38.234, entropy_loss = -6.9774, learner_queue_size = 26, _tick = 8438, _time = 1.654e+09, train_seconds = 4580.5)
[2022-05-31 15:26:46,786][root][INFO] - Step 30343680 @ 6648.2 SPS. Inference batcher size: 132. Learner queue size: 31. Other stats: (step = 30343680, mean_episode_return = 77.549, mean_episode_step = 721.49, total_loss = -121.01, pg_loss = -134.74, baseline_loss = 20.811, entropy_loss = -7.0779, learner_queue_size = 25, _tick = 8449, _time = 1.654e+09, train_seconds = 4585.5)
[2022-05-31 15:26:51,792][root][INFO] - Step 30376960 @ 6647.4 SPS. Inference batcher size: 48. Learner queue size: 3. Other stats: (step = 30376960, mean_episode_return = 115.34, mean_episode_step = 835.34, total_loss = 93.321, pg_loss = 76.253, baseline_loss = 24.119, entropy_loss = -7.0504, learner_queue_size = 24, _tick = 8461, _time = 1.654e+09, train_seconds = 4590.5)
[2022-05-31 15:26:56,798][root][INFO] - Step 30410240 @ 6648.6 SPS. Inference batcher size: 144. Learner queue size: 6. Other stats: (step = 30410240, mean_episode_return = 185.15, mean_episode_step = 625.51, total_loss = 367.07, pg_loss = 278.81, baseline_loss = 95.307, entropy_loss = -7.0529, learner_queue_size = 21, _tick = 8471, _time = 1.654e+09, train_seconds = 4595.5)
[2022-05-31 15:27:01,802][root][INFO] - Step 30443520 @ 6650.7 SPS. Inference batcher size: 53. Learner queue size: 24. Other stats: (step = 30443520, mean_episode_return = 89.12, mean_episode_step = 926.91, total_loss = -29.96, pg_loss = -51.522, baseline_loss = 28.717, entropy_loss = -7.1554, learner_queue_size = 9, _tick = 8483, _time = 1.654e+09, train_seconds = 4600.5)
[2022-05-31 15:27:06,806][root][INFO] - Step 30476800 @ 6650.8 SPS. Inference batcher size: 0. Learner queue size: 26. Other stats: (step = 30476800, mean_episode_return = 13.74, mean_episode_step = 897.74, total_loss = -2.0969, pg_loss = -12.648, baseline_loss = 17.119, entropy_loss = -6.5675, learner_queue_size = 21, _tick = 8492, _time = 1.654e+09, train_seconds = 4605.5)
[2022-05-31 15:27:11,809][root][INFO] - Step 30507520 @ 6139.7 SPS. Inference batcher size: 141. Learner queue size: 19. Other stats: (step = 30507520, mean_episode_return = None, mean_episode_step = 1035.1, total_loss = -41.152, pg_loss = -59.411, baseline_loss = 24.956, entropy_loss = -6.6964, learner_queue_size = 17, _tick = 8500, _time = 1.654e+09, train_seconds = 4610.5)
[2022-05-31 15:27:16,814][root][INFO] - Step 30540800 @ 6650.0 SPS. Inference batcher size: 7. Learner queue size: 14. Other stats: (step = 30540800, mean_episode_return = 65.771, mean_episode_step = 957.16, total_loss = -313.79, pg_loss = -317.52, baseline_loss = 10.946, entropy_loss = -7.2106, learner_queue_size = 20, _tick = 8511, _time = 1.654e+09, train_seconds = 4615.5)
[2022-05-31 15:27:21,818][root][INFO] - Step 30574080 @ 6650.7 SPS. Inference batcher size: 147. Learner queue size: 10. Other stats: (step = 30574080, mean_episode_return = 50.041, mean_episode_step = 1000.9, total_loss = 165.96, pg_loss = 147.44, baseline_loss = 25.841, entropy_loss = -7.3161, learner_queue_size = 19, _tick = 8520, _time = 1.654e+09, train_seconds = 4620.5)
[2022-05-31 15:27:26,822][root][INFO] - Step 30607360 @ 6650.5 SPS. Inference batcher size: 63. Learner queue size: 3. Other stats: (step = 30607360, mean_episode_return = None, mean_episode_step = 920.16, total_loss = 790.36, pg_loss = 682.22, baseline_loss = 114.95, entropy_loss = -6.8137, learner_queue_size = 21, _tick = 8530, _time = 1.654e+09, train_seconds = 4625.5)
[2022-05-31 15:27:31,826][root][INFO] - Step 30640640 @ 6650.8 SPS. Inference batcher size: 113. Learner queue size: 8. Other stats: (step = 30640640, mean_episode_return = 57.081, mean_episode_step = 954.91, total_loss = -42.998, pg_loss = -56.813, baseline_loss = 20.885, entropy_loss = -7.071, learner_queue_size = 14, _tick = 8543, _time = 1.654e+09, train_seconds = 4630.5)
[2022-05-31 15:27:36,830][root][INFO] - Step 30673920 @ 6650.7 SPS. Inference batcher size: 107. Learner queue size: 5. Other stats: (step = 30673920, mean_episode_return = 127.52, mean_episode_step = 736.32, total_loss = 28.857, pg_loss = -0.61787, baseline_loss = 36.352, entropy_loss = -6.8766, learner_queue_size = 24, _tick = 8554, _time = 1.654e+09, train_seconds = 4635.5)
[2022-05-31 15:27:41,834][root][INFO] - Step 30707200 @ 6650.5 SPS. Inference batcher size: 135. Learner queue size: 24. Other stats: (step = 30707200, mean_episode_return = 129.8, mean_episode_step = 965.89, total_loss = -99.684, pg_loss = -156.08, baseline_loss = 62.519, entropy_loss = -6.1251, learner_queue_size = 11, _tick = 8567, _time = 1.654e+09, train_seconds = 4640.5)
[2022-05-31 15:27:46,840][root][INFO] - Step 30737920 @ 6136.5 SPS. Inference batcher size: 142. Learner queue size: 24. Other stats: (step = 30737920, mean_episode_return = 85.497, mean_episode_step = 811.3, total_loss = -103.06, pg_loss = -141.76, baseline_loss = 44.815, entropy_loss = -6.1085, learner_queue_size = 15, _tick = 8579, _time = 1.654e+09, train_seconds = 4645.5)
[2022-05-31 15:27:51,846][root][INFO] - Step 30771200 @ 6648.0 SPS. Inference batcher size: 112. Learner queue size: 8. Other stats: (step = 30771200, mean_episode_return = 107.6, mean_episode_step = 978.48, total_loss = 8.5657, pg_loss = -26.848, baseline_loss = 42.07, entropy_loss = -6.6557, learner_queue_size = 16, _tick = 8590, _time = 1.654e+09, train_seconds = 4650.5)
[2022-05-31 15:27:56,852][root][INFO] - Step 30804480 @ 6648.0 SPS. Inference batcher size: 158. Learner queue size: 20. Other stats: (step = 30804480, mean_episode_return = 118.53, mean_episode_step = 877.7, total_loss = 66.351, pg_loss = 11.643, baseline_loss = 61.55, entropy_loss = -6.8417, learner_queue_size = 17, _tick = 8601, _time = 1.654e+09, train_seconds = 4655.5)
[2022-05-31 15:28:01,858][root][INFO] - Step 30837760 @ 6647.9 SPS. Inference batcher size: 95. Learner queue size: 19. Other stats: (step = 30837760, mean_episode_return = 67.913, mean_episode_step = 829.75, total_loss = -134.14, pg_loss = -140.63, baseline_loss = 13.461, entropy_loss = -6.9696, learner_queue_size = 22, _tick = 8610, _time = 1.654e+09, train_seconds = 4660.5)
[2022-05-31 15:28:06,864][root][INFO] - Step 30871040 @ 6648.0 SPS. Inference batcher size: 129. Learner queue size: 14. Other stats: (step = 30871040, mean_episode_return = 62.29, mean_episode_step = 808.4, total_loss = 14.663, pg_loss = -18.192, baseline_loss = 38.849, entropy_loss = -5.9942, learner_queue_size = 23, _tick = 8622, _time = 1.654e+09, train_seconds = 4665.5)
[2022-05-31 15:28:11,870][root][INFO] - Step 30904320 @ 6648.0 SPS. Inference batcher size: 153. Learner queue size: 22. Other stats: (step = 30904320, mean_episode_return = 98.694, mean_episode_step = 876.87, total_loss = 115.75, pg_loss = 75.306, baseline_loss = 47.239, entropy_loss = -6.7909, learner_queue_size = 26, _tick = 8633, _time = 1.654e+09, train_seconds = 4670.6)
[2022-05-31 15:28:16,874][root][INFO] - Step 30937600 @ 6651.2 SPS. Inference batcher size: 87. Learner queue size: 8. Other stats: (step = 30937600, mean_episode_return = 62.872, mean_episode_step = 783.27, total_loss = 7.0326, pg_loss = -4.3959, baseline_loss = 18.202, entropy_loss = -6.7731, learner_queue_size = 17, _tick = 8645, _time = 1.654e+09, train_seconds = 4675.6)
[2022-05-31 15:28:21,880][root][INFO] - Step 30970880 @ 6647.9 SPS. Inference batcher size: 88. Learner queue size: 1. Other stats: (step = 30970880, mean_episode_return = None, mean_episode_step = 868.03, total_loss = 97.587, pg_loss = 39.103, baseline_loss = 64.729, entropy_loss = -6.2451, learner_queue_size = 16, _tick = 8655, _time = 1.654e+09, train_seconds = 4680.6)
[2022-05-31 15:28:26,882][root][INFO] - Step 31004160 @ 6653.3 SPS. Inference batcher size: 85. Learner queue size: 0. Other stats: (step = 31004160, mean_episode_return = 142.57, mean_episode_step = 871.88, total_loss = -54.102, pg_loss = -84.25, baseline_loss = 36.756, entropy_loss = -6.6082, learner_queue_size = 26, _tick = 8664, _time = 1.654e+09, train_seconds = 4685.6)
[2022-05-31 15:28:31,886][root][INFO] - Step 31034880 @ 6138.8 SPS. Inference batcher size: 187. Learner queue size: 12. Other stats: (step = 31034880, mean_episode_return = 104.02, mean_episode_step = 626.48, total_loss = 52.709, pg_loss = 22.02, baseline_loss = 36.466, entropy_loss = -5.7768, learner_queue_size = 17, _tick = 8675, _time = 1.654e+09, train_seconds = 4690.6)
[2022-05-31 15:28:36,893][root][INFO] - Step 31068160 @ 6647.4 SPS. Inference batcher size: 97. Learner queue size: 22. Other stats: (step = 31068160, mean_episode_return = 22.48, mean_episode_step = 871.47, total_loss = -92.074, pg_loss = -112.7, baseline_loss = 27.023, entropy_loss = -6.3985, learner_queue_size = 18, _tick = 8687, _time = 1.654e+09, train_seconds = 4695.6)
[2022-05-31 15:28:41,899][root][INFO] - Step 31101440 @ 6647.9 SPS. Inference batcher size: 95. Learner queue size: 15. Other stats: (step = 31101440, mean_episode_return = None, mean_episode_step = 858.97, total_loss = 359.73, pg_loss = 291.95, baseline_loss = 74.178, entropy_loss = -6.3992, learner_queue_size = 27, _tick = 8697, _time = 1.654e+09, train_seconds = 4700.6)
[2022-05-31 15:28:46,906][root][INFO] - Step 31134720 @ 6647.2 SPS. Inference batcher size: 55. Learner queue size: 9. Other stats: (step = 31134720, mean_episode_return = 85.41, mean_episode_step = 867.88, total_loss = -57.745, pg_loss = -78.595, baseline_loss = 27.441, entropy_loss = -6.5901, learner_queue_size = 13, _tick = 8708, _time = 1.654e+09, train_seconds = 4705.6)
[2022-05-31 15:28:51,910][root][INFO] - Step 31168000 @ 6650.1 SPS. Inference batcher size: 165. Learner queue size: 5. Other stats: (step = 31168000, mean_episode_return = 59.55, mean_episode_step = 889.87, total_loss = -180.36, pg_loss = -206.71, baseline_loss = 32.757, entropy_loss = -6.4001, learner_queue_size = 17, _tick = 8720, _time = 1.654e+09, train_seconds = 4710.6)
[2022-05-31 15:28:56,916][root][INFO] - Step 31201280 @ 6647.9 SPS. Inference batcher size: 87. Learner queue size: 4. Other stats: (step = 31201280, mean_episode_return = 91.97, mean_episode_step = 800.92, total_loss = 345.75, pg_loss = 272.72, baseline_loss = 79.444, entropy_loss = -6.4185, learner_queue_size = 20, _tick = 8731, _time = 1.654e+09, train_seconds = 4715.6)
[2022-05-31 15:29:01,922][root][INFO] - Step 31234560 @ 6648.3 SPS. Inference batcher size: 30. Learner queue size: 24. Other stats: (step = 31234560, mean_episode_return = None, mean_episode_step = 736.97, total_loss = 149.56, pg_loss = 94.415, baseline_loss = 61.666, entropy_loss = -6.5228, learner_queue_size = 21, _tick = 8742, _time = 1.654e+09, train_seconds = 4720.6)
[2022-05-31 15:29:06,928][root][INFO] - Step 31265280 @ 6136.5 SPS. Inference batcher size: 106. Learner queue size: 22. Other stats: (step = 31265280, mean_episode_return = 186.9, mean_episode_step = 956.25, total_loss = -62.831, pg_loss = -105.74, baseline_loss = 49.532, entropy_loss = -6.62, learner_queue_size = 32, _tick = 8753, _time = 1.654e+09, train_seconds = 4725.6)
[2022-05-31 15:29:11,930][root][INFO] - Step 31298560 @ 6653.3 SPS. Inference batcher size: 125. Learner queue size: 14. Other stats: (step = 31298560, mean_episode_return = None, mean_episode_step = 779.12, total_loss = 95.55, pg_loss = 76.013, baseline_loss = 24.979, entropy_loss = -5.4424, learner_queue_size = 14, _tick = 8765, _time = 1.654e+09, train_seconds = 4730.6)
[2022-05-31 15:29:16,934][root][INFO] - Step 31331840 @ 6650.6 SPS. Inference batcher size: 85. Learner queue size: 17. Other stats: (step = 31331840, mean_episode_return = None, mean_episode_step = 645.22, total_loss = 170.4, pg_loss = 119.77, baseline_loss = 56.473, entropy_loss = -5.8491, learner_queue_size = 24, _tick = 8777, _time = 1.654e+09, train_seconds = 4735.6)
[2022-05-31 15:29:21,938][root][INFO] - Step 31365120 @ 6650.7 SPS. Inference batcher size: 67. Learner queue size: 6. Other stats: (step = 31365120, mean_episode_return = 106.06, mean_episode_step = 729.91, total_loss = -8.3108, pg_loss = -46.579, baseline_loss = 44.958, entropy_loss = -6.69, learner_queue_size = 9, _tick = 8788, _time = 1.654e+09, train_seconds = 4740.6)
[2022-05-31 15:29:26,942][root][INFO] - Step 31398400 @ 6650.7 SPS. Inference batcher size: 164. Learner queue size: 29. Other stats: (step = 31398400, mean_episode_return = 8.0697, mean_episode_step = 595.07, total_loss = 286.19, pg_loss = 137.86, baseline_loss = 154.43, entropy_loss = -6.0957, learner_queue_size = 15, _tick = 8799, _time = 1.654e+09, train_seconds = 4745.6)
[2022-05-31 15:29:31,949][root][INFO] - Step 31429120 @ 6135.3 SPS. Inference batcher size: 42. Learner queue size: 25. Other stats: (step = 31429120, mean_episode_return = 25.07, mean_episode_step = 708.39, total_loss = 16.635, pg_loss = -14.747, baseline_loss = 38.367, entropy_loss = -6.9848, learner_queue_size = 19, _tick = 8811, _time = 1.654e+09, train_seconds = 4750.6)
[2022-05-31 15:29:36,954][root][INFO] - Step 31464960 @ 7160.9 SPS. Inference batcher size: 97. Learner queue size: 20. Other stats: (step = 31464960, mean_episode_return = 6.5097, mean_episode_step = 675.96, total_loss = -188.88, pg_loss = -200.22, baseline_loss = 17.833, entropy_loss = -6.4992, learner_queue_size = 20, _tick = 8825, _time = 1.654e+09, train_seconds = 4755.6)
[2022-05-31 15:29:41,958][root][INFO] - Step 31495680 @ 6139.0 SPS. Inference batcher size: 122. Learner queue size: 25. Other stats: (step = 31495680, mean_episode_return = 94.46, mean_episode_step = 742.21, total_loss = -27.069, pg_loss = -36.596, baseline_loss = 15.991, entropy_loss = -6.4645, learner_queue_size = 14, _tick = 8833, _time = 1.654e+09, train_seconds = 4760.6)
[2022-05-31 15:29:46,963][root][INFO] - Step 31528960 @ 6649.6 SPS. Inference batcher size: 125. Learner queue size: 12. Other stats: (step = 31528960, mean_episode_return = 155.75, mean_episode_step = 771.95, total_loss = -18.102, pg_loss = -36.41, baseline_loss = 23.659, entropy_loss = -5.3519, learner_queue_size = 20, _tick = 8844, _time = 1.654e+09, train_seconds = 4765.6)
[2022-05-31 15:29:51,966][root][INFO] - Step 31562240 @ 6651.8 SPS. Inference batcher size: 79. Learner queue size: 6. Other stats: (step = 31562240, mean_episode_return = 90.8, mean_episode_step = 665.66, total_loss = -29.719, pg_loss = -51.156, baseline_loss = 28.073, entropy_loss = -6.6353, learner_queue_size = 18, _tick = 8857, _time = 1.654e+09, train_seconds = 4770.7)
[2022-05-31 15:29:56,970][root][INFO] - Step 31595520 @ 6650.8 SPS. Inference batcher size: 135. Learner queue size: 6. Other stats: (step = 31595520, mean_episode_return = 149.09, mean_episode_step = 658.96, total_loss = 43.145, pg_loss = 10.742, baseline_loss = 38.949, entropy_loss = -6.5469, learner_queue_size = 27, _tick = 8869, _time = 1.654e+09, train_seconds = 4775.7)
[2022-05-31 15:30:01,976][root][INFO] - Step 31628800 @ 6647.9 SPS. Inference batcher size: 132. Learner queue size: 8. Other stats: (step = 31628800, mean_episode_return = None, mean_episode_step = 914.69, total_loss = -119.38, pg_loss = -137.16, baseline_loss = 24.306, entropy_loss = -6.5247, learner_queue_size = 12, _tick = 8879, _time = 1.654e+09, train_seconds = 4780.7)
[2022-05-31 15:30:06,982][root][INFO] - Step 31662080 @ 6648.0 SPS. Inference batcher size: 141. Learner queue size: 30. Other stats: (step = 31662080, mean_episode_return = 80.513, mean_episode_step = 712.57, total_loss = 166.68, pg_loss = 142.57, baseline_loss = 31.148, entropy_loss = -7.0334, learner_queue_size = 13, _tick = 8891, _time = 1.654e+09, train_seconds = 4785.7)
[2022-05-31 15:30:11,988][root][INFO] - Step 31695360 @ 6648.0 SPS. Inference batcher size: 67. Learner queue size: 1. Other stats: (step = 31695360, mean_episode_return = 185.39, mean_episode_step = 691.28, total_loss = 54.375, pg_loss = -16.183, baseline_loss = 77.258, entropy_loss = -6.7003, learner_queue_size = 11, _tick = 8904, _time = 1.654e+09, train_seconds = 4790.7)
[2022-05-31 15:30:16,994][root][INFO] - Step 31728640 @ 6648.1 SPS. Inference batcher size: 127. Learner queue size: 28. Other stats: (step = 31728640, mean_episode_return = 10.07, mean_episode_step = 842.62, total_loss = -186.99, pg_loss = -245.14, baseline_loss = 64.874, entropy_loss = -6.7292, learner_queue_size = 15, _tick = 8917, _time = 1.654e+09, train_seconds = 4795.7)
[2022-05-31 15:30:21,998][root][INFO] - Step 31761920 @ 6650.3 SPS. Inference batcher size: 186. Learner queue size: 2. Other stats: (step = 31761920, mean_episode_return = 77.067, mean_episode_step = 805.16, total_loss = 163.96, pg_loss = 114.32, baseline_loss = 56.75, entropy_loss = -7.1071, learner_queue_size = 25, _tick = 8929, _time = 1.654e+09, train_seconds = 4800.7)
[2022-05-31 15:30:27,002][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 15:30:27,082][root][INFO] - Step 31792640 @ 6139.5 SPS. Inference batcher size: 121. Learner queue size: 24. Other stats: (step = 31795200, mean_episode_return = 204.7, mean_episode_step = 787.04, total_loss = 50.438, pg_loss = -38.927, baseline_loss = 96.075, entropy_loss = -6.71, learner_queue_size = 21, _tick = 8941, _time = 1.654e+09, train_seconds = 4805.7)
[2022-05-31 15:30:32,088][root][INFO] - Step 31825920 @ 6543.8 SPS. Inference batcher size: 153. Learner queue size: 12. Other stats: (step = 31825920, mean_episode_return = None, mean_episode_step = 721.06, total_loss = -37.685, pg_loss = -74.237, baseline_loss = 43.195, entropy_loss = -6.6423, learner_queue_size = 21, _tick = 8950, _time = 1.654e+09, train_seconds = 4810.8)
[2022-05-31 15:30:37,090][root][INFO] - Step 31859200 @ 6653.0 SPS. Inference batcher size: 171. Learner queue size: 20. Other stats: (step = 31859200, mean_episode_return = 176.42, mean_episode_step = 786.72, total_loss = -13.14, pg_loss = -57.25, baseline_loss = 51.148, entropy_loss = -7.0384, learner_queue_size = 15, _tick = 8961, _time = 1.654e+09, train_seconds = 4815.8)
[2022-05-31 15:30:42,096][root][INFO] - Step 31892480 @ 6647.9 SPS. Inference batcher size: 115. Learner queue size: 21. Other stats: (step = 31892480, mean_episode_return = 85.392, mean_episode_step = 662.08, total_loss = 162.65, pg_loss = 67.373, baseline_loss = 101.45, entropy_loss = -6.1722, learner_queue_size = 15, _tick = 8973, _time = 1.654e+09, train_seconds = 4820.8)
[2022-05-31 15:30:47,102][root][INFO] - Step 31925760 @ 6648.2 SPS. Inference batcher size: 72. Learner queue size: 14. Other stats: (step = 31925760, mean_episode_return = 61.42, mean_episode_step = 940.95, total_loss = 19.2, pg_loss = -54.538, baseline_loss = 80.44, entropy_loss = -6.7012, learner_queue_size = 19, _tick = 8981, _time = 1.654e+09, train_seconds = 4825.8)
[2022-05-31 15:30:52,106][root][INFO] - Step 31959040 @ 6650.7 SPS. Inference batcher size: 111. Learner queue size: 9. Other stats: (step = 31959040, mean_episode_return = None, mean_episode_step = 666.34, total_loss = 4.554, pg_loss = -42.485, baseline_loss = 53.948, entropy_loss = -6.9096, learner_queue_size = 14, _tick = 8993, _time = 1.654e+09, train_seconds = 4830.8)
[2022-05-31 15:30:57,112][root][INFO] - Step 31992320 @ 6647.9 SPS. Inference batcher size: 45. Learner queue size: 4. Other stats: (step = 31992320, mean_episode_return = 80.15, mean_episode_step = 682.49, total_loss = 190.37, pg_loss = 132.75, baseline_loss = 64.942, entropy_loss = -7.3243, learner_queue_size = 21, _tick = 9005, _time = 1.654e+09, train_seconds = 4835.8)
[2022-05-31 15:31:02,118][root][INFO] - Step 32025600 @ 6648.1 SPS. Inference batcher size: 117. Learner queue size: 30. Other stats: (step = 32025600, mean_episode_return = 165.62, mean_episode_step = 864.28, total_loss = 14.656, pg_loss = -16.696, baseline_loss = 38.546, entropy_loss = -7.1934, learner_queue_size = 18, _tick = 9015, _time = 1.654e+09, train_seconds = 4840.8)
[2022-05-31 15:31:07,122][root][INFO] - Step 32058880 @ 6650.6 SPS. Inference batcher size: 136. Learner queue size: 1. Other stats: (step = 32058880, mean_episode_return = 89.806, mean_episode_step = 658.81, total_loss = 63.787, pg_loss = 25.766, baseline_loss = 45.037, entropy_loss = -7.0156, learner_queue_size = 16, _tick = 9026, _time = 1.654e+09, train_seconds = 4845.8)
[2022-05-31 15:31:12,126][root][INFO] - Step 32092160 @ 6650.7 SPS. Inference batcher size: 127. Learner queue size: 28. Other stats: (step = 32092160, mean_episode_return = None, mean_episode_step = 730.19, total_loss = 5.7548, pg_loss = 0.47154, baseline_loss = 10.584, entropy_loss = -5.3011, learner_queue_size = 19, _tick = 9033, _time = 1.654e+09, train_seconds = 4850.8)
[2022-05-31 15:31:17,130][root][INFO] - Step 32122880 @ 6139.1 SPS. Inference batcher size: 150. Learner queue size: 17. Other stats: (step = 32122880, mean_episode_return = 97.33, mean_episode_step = 944.55, total_loss = -167.99, pg_loss = -218.71, baseline_loss = 57.349, entropy_loss = -6.6259, learner_queue_size = 18, _tick = 9044, _time = 1.654e+09, train_seconds = 4855.8)
[2022-05-31 15:31:22,136][root][INFO] - Step 32156160 @ 6647.8 SPS. Inference batcher size: 122. Learner queue size: 21. Other stats: (step = 32156160, mean_episode_return = None, mean_episode_step = 815.28, total_loss = 138.71, pg_loss = 96.426, baseline_loss = 49.44, entropy_loss = -7.1523, learner_queue_size = 12, _tick = 9054, _time = 1.654e+09, train_seconds = 4860.8)
[2022-05-31 15:31:27,142][root][INFO] - Step 32189440 @ 6647.8 SPS. Inference batcher size: 103. Learner queue size: 22. Other stats: (step = 32189440, mean_episode_return = 158.24, mean_episode_step = 884.4, total_loss = 88.348, pg_loss = 35.628, baseline_loss = 59.225, entropy_loss = -6.5053, learner_queue_size = 17, _tick = 9066, _time = 1.654e+09, train_seconds = 4865.8)
[2022-05-31 15:31:32,146][root][INFO] - Step 32222720 @ 6651.1 SPS. Inference batcher size: 134. Learner queue size: 16. Other stats: (step = 32222720, mean_episode_return = 117.7, mean_episode_step = 753.14, total_loss = -113.86, pg_loss = -151.53, baseline_loss = 44.206, entropy_loss = -6.5344, learner_queue_size = 13, _tick = 9077, _time = 1.654e+09, train_seconds = 4870.8)
[2022-05-31 15:31:37,150][root][INFO] - Step 32256000 @ 6650.8 SPS. Inference batcher size: 127. Learner queue size: 3. Other stats: (step = 32256000, mean_episode_return = 220.44, mean_episode_step = 892.13, total_loss = -4.4667, pg_loss = -57.34, baseline_loss = 59.368, entropy_loss = -6.4953, learner_queue_size = 25, _tick = 9088, _time = 1.654e+09, train_seconds = 4875.8)
[2022-05-31 15:31:42,156][root][INFO] - Step 32289280 @ 6648.0 SPS. Inference batcher size: 25. Learner queue size: 6. Other stats: (step = 32289280, mean_episode_return = 159.09, mean_episode_step = 775.75, total_loss = -120.26, pg_loss = -168.61, baseline_loss = 54.951, entropy_loss = -6.608, learner_queue_size = 30, _tick = 9099, _time = 1.654e+09, train_seconds = 4880.8)
[2022-05-31 15:31:47,162][root][INFO] - Step 32322560 @ 6647.9 SPS. Inference batcher size: 119. Learner queue size: 9. Other stats: (step = 32322560, mean_episode_return = 106.81, mean_episode_step = 796.68, total_loss = -427.56, pg_loss = -512.44, baseline_loss = 91.549, entropy_loss = -6.6713, learner_queue_size = 9, _tick = 9109, _time = 1.654e+09, train_seconds = 4885.8)
[2022-05-31 15:31:52,170][root][INFO] - Step 32355840 @ 6645.3 SPS. Inference batcher size: 121. Learner queue size: 3. Other stats: (step = 32355840, mean_episode_return = 66.738, mean_episode_step = 774.73, total_loss = -428.28, pg_loss = -454.4, baseline_loss = 33.078, entropy_loss = -6.9607, learner_queue_size = 17, _tick = 9121, _time = 1.654e+09, train_seconds = 4890.9)
[2022-05-31 15:31:57,174][root][INFO] - Step 32389120 @ 6650.9 SPS. Inference batcher size: 54. Learner queue size: 2. Other stats: (step = 32389120, mean_episode_return = 51.19, mean_episode_step = 618.39, total_loss = 201.63, pg_loss = 159.1, baseline_loss = 49.74, entropy_loss = -7.2145, learner_queue_size = 12, _tick = 9134, _time = 1.654e+09, train_seconds = 4895.9)
[2022-05-31 15:32:02,178][root][INFO] - Step 32422400 @ 6650.2 SPS. Inference batcher size: 28. Learner queue size: 19. Other stats: (step = 32422400, mean_episode_return = 53.76, mean_episode_step = 623.71, total_loss = 557.78, pg_loss = 472.54, baseline_loss = 91.869, entropy_loss = -6.6285, learner_queue_size = 10, _tick = 9146, _time = 1.654e+09, train_seconds = 4900.9)
[2022-05-31 15:32:07,182][root][INFO] - Step 32455680 @ 6651.1 SPS. Inference batcher size: 79. Learner queue size: 24. Other stats: (step = 32455680, mean_episode_return = 35.04, mean_episode_step = 863.71, total_loss = -126.09, pg_loss = -148.69, baseline_loss = 29.16, entropy_loss = -6.559, learner_queue_size = 20, _tick = 9157, _time = 1.654e+09, train_seconds = 4905.9)
[2022-05-31 15:32:12,186][root][INFO] - Step 32488960 @ 6650.8 SPS. Inference batcher size: 99. Learner queue size: 29. Other stats: (step = 32488960, mean_episode_return = 172.47, mean_episode_step = 858.87, total_loss = 155.85, pg_loss = 86.252, baseline_loss = 75.894, entropy_loss = -6.2947, learner_queue_size = 22, _tick = 9169, _time = 1.654e+09, train_seconds = 4910.9)
[2022-05-31 15:32:17,192][root][INFO] - Step 32519680 @ 6136.6 SPS. Inference batcher size: 29. Learner queue size: 23. Other stats: (step = 32519680, mean_episode_return = 162.7, mean_episode_step = 741.22, total_loss = -96.347, pg_loss = -121.93, baseline_loss = 31.984, entropy_loss = -6.4031, learner_queue_size = 14, _tick = 9178, _time = 1.654e+09, train_seconds = 4915.9)
[2022-05-31 15:32:22,198][root][INFO] - Step 32552960 @ 6647.4 SPS. Inference batcher size: 112. Learner queue size: 21. Other stats: (step = 32552960, mean_episode_return = 103.27, mean_episode_step = 851.76, total_loss = 465.38, pg_loss = 346.5, baseline_loss = 125.45, entropy_loss = -6.5689, learner_queue_size = 18, _tick = 9189, _time = 1.654e+09, train_seconds = 4920.9)
[2022-05-31 15:32:27,204][root][INFO] - Step 32586240 @ 6648.0 SPS. Inference batcher size: 165. Learner queue size: 15. Other stats: (step = 32586240, mean_episode_return = 110.22, mean_episode_step = 908.39, total_loss = -20.145, pg_loss = -80.978, baseline_loss = 67.566, entropy_loss = -6.7335, learner_queue_size = 28, _tick = 9199, _time = 1.654e+09, train_seconds = 4925.9)
[2022-05-31 15:32:32,210][root][INFO] - Step 32619520 @ 6648.6 SPS. Inference batcher size: 85. Learner queue size: 2. Other stats: (step = 32619520, mean_episode_return = 53.364, mean_episode_step = 898.53, total_loss = -236.29, pg_loss = -294.08, baseline_loss = 64.122, entropy_loss = -6.3393, learner_queue_size = 19, _tick = 9210, _time = 1.654e+09, train_seconds = 4930.9)
[2022-05-31 15:32:37,214][root][INFO] - Step 32652800 @ 6650.6 SPS. Inference batcher size: 108. Learner queue size: 3. Other stats: (step = 32652800, mean_episode_return = 124.73, mean_episode_step = 826.5, total_loss = 96.083, pg_loss = 55.39, baseline_loss = 46.931, entropy_loss = -6.2388, learner_queue_size = 16, _tick = 9223, _time = 1.654e+09, train_seconds = 4935.9)
[2022-05-31 15:32:42,218][root][INFO] - Step 32686080 @ 6650.7 SPS. Inference batcher size: 165. Learner queue size: 27. Other stats: (step = 32686080, mean_episode_return = 128.27, mean_episode_step = 777.66, total_loss = -0.96933, pg_loss = -17.482, baseline_loss = 22.886, entropy_loss = -6.3735, learner_queue_size = 13, _tick = 9235, _time = 1.654e+09, train_seconds = 4940.9)
[2022-05-31 15:32:47,222][root][INFO] - Step 32719360 @ 6650.8 SPS. Inference batcher size: 68. Learner queue size: 27. Other stats: (step = 32719360, mean_episode_return = 108.54, mean_episode_step = 843.95, total_loss = 85.815, pg_loss = -13.734, baseline_loss = 105.48, entropy_loss = -5.9294, learner_queue_size = 18, _tick = 9244, _time = 1.654e+09, train_seconds = 4945.9)
[2022-05-31 15:32:52,226][root][INFO] - Step 32752640 @ 6650.7 SPS. Inference batcher size: 114. Learner queue size: 18. Other stats: (step = 32752640, mean_episode_return = 41.469, mean_episode_step = 1003.9, total_loss = -40.884, pg_loss = -57.361, baseline_loss = 23.324, entropy_loss = -6.8465, learner_queue_size = 17, _tick = 9256, _time = 1.654e+09, train_seconds = 4950.9)
[2022-05-31 15:32:57,230][root][INFO] - Step 32783360 @ 6139.1 SPS. Inference batcher size: 129. Learner queue size: 14. Other stats: (step = 32783360, mean_episode_return = 262.7, mean_episode_step = 811.46, total_loss = -19.493, pg_loss = -50.491, baseline_loss = 36.857, entropy_loss = -5.859, learner_queue_size = 17, _tick = 9267, _time = 1.654e+09, train_seconds = 4955.9)
[2022-05-31 15:33:02,236][root][INFO] - Step 32816640 @ 6648.0 SPS. Inference batcher size: 149. Learner queue size: 17. Other stats: (step = 32816640, mean_episode_return = 85.8, mean_episode_step = 692.13, total_loss = 151.64, pg_loss = 102.19, baseline_loss = 55.78, entropy_loss = -6.3259, learner_queue_size = 15, _tick = 9279, _time = 1.654e+09, train_seconds = 4960.9)
[2022-05-31 15:33:07,242][root][INFO] - Step 32849920 @ 6647.9 SPS. Inference batcher size: 190. Learner queue size: 11. Other stats: (step = 32849920, mean_episode_return = 69.694, mean_episode_step = 726.98, total_loss = 238.65, pg_loss = 173.95, baseline_loss = 71.691, entropy_loss = -6.9912, learner_queue_size = 17, _tick = 9289, _time = 1.654e+09, train_seconds = 4965.9)
[2022-05-31 15:33:12,248][root][INFO] - Step 32883200 @ 6647.9 SPS. Inference batcher size: 132. Learner queue size: 11. Other stats: (step = 32883200, mean_episode_return = None, mean_episode_step = 792.91, total_loss = -62.058, pg_loss = -118.85, baseline_loss = 63.699, entropy_loss = -6.9084, learner_queue_size = 31, _tick = 9297, _time = 1.654e+09, train_seconds = 4970.9)
[2022-05-31 15:33:17,254][root][INFO] - Step 32916480 @ 6648.3 SPS. Inference batcher size: 94. Learner queue size: 19. Other stats: (step = 32916480, mean_episode_return = None, mean_episode_step = 774.19, total_loss = 16.637, pg_loss = -6.4492, baseline_loss = 29.813, entropy_loss = -6.7269, learner_queue_size = 24, _tick = 9307, _time = 1.654e+09, train_seconds = 4975.9)
[2022-05-31 15:33:22,258][root][INFO] - Step 32949760 @ 6650.6 SPS. Inference batcher size: 44. Learner queue size: 10. Other stats: (step = 32949760, mean_episode_return = 76.495, mean_episode_step = 946.42, total_loss = 37.665, pg_loss = -40.858, baseline_loss = 85.264, entropy_loss = -6.7411, learner_queue_size = 22, _tick = 9318, _time = 1.654e+09, train_seconds = 4980.9)
[2022-05-31 15:33:27,264][root][INFO] - Step 32983040 @ 6647.9 SPS. Inference batcher size: 94. Learner queue size: 2. Other stats: (step = 32983040, mean_episode_return = 83.01, mean_episode_step = 753.84, total_loss = 42.425, pg_loss = -35.78, baseline_loss = 84.854, entropy_loss = -6.6495, learner_queue_size = 19, _tick = 9330, _time = 1.654e+09, train_seconds = 4985.9)
[2022-05-31 15:33:32,270][root][INFO] - Step 33013760 @ 6136.7 SPS. Inference batcher size: 56. Learner queue size: 21. Other stats: (step = 33013760, mean_episode_return = 133.83, mean_episode_step = 998.27, total_loss = -253.33, pg_loss = -293.22, baseline_loss = 46.534, entropy_loss = -6.6432, learner_queue_size = 26, _tick = 9339, _time = 1.654e+09, train_seconds = 4991.0)
[2022-05-31 15:33:37,271][root][INFO] - Step 33047040 @ 6654.3 SPS. Inference batcher size: 99. Learner queue size: 10. Other stats: (step = 33047040, mean_episode_return = 87.862, mean_episode_step = 809.43, total_loss = 76.111, pg_loss = 26.073, baseline_loss = 56.395, entropy_loss = -6.3575, learner_queue_size = 26, _tick = 9352, _time = 1.654e+09, train_seconds = 4996.0)
[2022-05-31 15:33:42,274][root][INFO] - Step 33080320 @ 6652.4 SPS. Inference batcher size: 158. Learner queue size: 16. Other stats: (step = 33080320, mean_episode_return = 77.47, mean_episode_step = 822.62, total_loss = 535.59, pg_loss = 374.3, baseline_loss = 168.09, entropy_loss = -6.8018, learner_queue_size = 21, _tick = 9364, _time = 1.654e+09, train_seconds = 5001.0)
[2022-05-31 15:33:47,278][root][INFO] - Step 33113600 @ 6650.8 SPS. Inference batcher size: 130. Learner queue size: 7. Other stats: (step = 33113600, mean_episode_return = 116.21, mean_episode_step = 680.35, total_loss = 81.971, pg_loss = 20.672, baseline_loss = 67.769, entropy_loss = -6.4705, learner_queue_size = 26, _tick = 9375, _time = 1.654e+09, train_seconds = 5006.0)
[2022-05-31 15:33:52,284][root][INFO] - Step 33146880 @ 6647.7 SPS. Inference batcher size: 144. Learner queue size: 12. Other stats: (step = 33146880, mean_episode_return = 52.274, mean_episode_step = 653.5, total_loss = 173.52, pg_loss = 29.896, baseline_loss = 149.98, entropy_loss = -6.3624, learner_queue_size = 25, _tick = 9387, _time = 1.654e+09, train_seconds = 5011.0)
[2022-05-31 15:33:57,290][root][INFO] - Step 33180160 @ 6648.4 SPS. Inference batcher size: 138. Learner queue size: 2. Other stats: (step = 33180160, mean_episode_return = 103.37, mean_episode_step = 668.34, total_loss = 35.748, pg_loss = -50.194, baseline_loss = 92.755, entropy_loss = -6.8125, learner_queue_size = 16, _tick = 9399, _time = 1.654e+09, train_seconds = 5016.0)
[2022-05-31 15:34:02,294][root][INFO] - Step 33213440 @ 6650.5 SPS. Inference batcher size: 33. Learner queue size: 29. Other stats: (step = 33213440, mean_episode_return = 118.81, mean_episode_step = 802.74, total_loss = 91.397, pg_loss = 62.641, baseline_loss = 35.27, entropy_loss = -6.5137, learner_queue_size = 14, _tick = 9409, _time = 1.654e+09, train_seconds = 5021.0)
[2022-05-31 15:34:07,298][root][INFO] - Step 33246720 @ 6650.8 SPS. Inference batcher size: 122. Learner queue size: 21. Other stats: (step = 33246720, mean_episode_return = 53.466, mean_episode_step = 800.49, total_loss = -70.855, pg_loss = -92.946, baseline_loss = 28.594, entropy_loss = -6.5032, learner_queue_size = 21, _tick = 9418, _time = 1.654e+09, train_seconds = 5026.0)
[2022-05-31 15:34:12,304][root][INFO] - Step 33277440 @ 6136.6 SPS. Inference batcher size: 106. Learner queue size: 9. Other stats: (step = 33277440, mean_episode_return = None, mean_episode_step = 793.75, total_loss = 162.11, pg_loss = 142.79, baseline_loss = 25.057, entropy_loss = -5.738, learner_queue_size = 19, _tick = 9428, _time = 1.654e+09, train_seconds = 5031.0)
[2022-05-31 15:34:17,310][root][INFO] - Step 33310720 @ 6648.1 SPS. Inference batcher size: 154. Learner queue size: 10. Other stats: (step = 33310720, mean_episode_return = 103.26, mean_episode_step = 817.95, total_loss = 78.151, pg_loss = 22.902, baseline_loss = 61.88, entropy_loss = -6.631, learner_queue_size = 18, _tick = 9438, _time = 1.654e+09, train_seconds = 5036.0)
[2022-05-31 15:34:22,316][root][INFO] - Step 33344000 @ 6648.0 SPS. Inference batcher size: 120. Learner queue size: 11. Other stats: (step = 33344000, mean_episode_return = 62.621, mean_episode_step = 747.92, total_loss = -223.69, pg_loss = -271.31, baseline_loss = 54.11, entropy_loss = -6.4986, learner_queue_size = 18, _tick = 9449, _time = 1.654e+09, train_seconds = 5041.0)
[2022-05-31 15:34:27,318][root][INFO] - Step 33379840 @ 7165.1 SPS. Inference batcher size: 68. Learner queue size: 20. Other stats: (step = 33379840, mean_episode_return = None, mean_episode_step = 777.81, total_loss = -8.5924, pg_loss = -44.436, baseline_loss = 42.525, entropy_loss = -6.6819, learner_queue_size = 20, _tick = 9459, _time = 1.654e+09, train_seconds = 5046.0)
[2022-05-31 15:34:32,324][root][INFO] - Step 33410560 @ 6136.5 SPS. Inference batcher size: 110. Learner queue size: 22. Other stats: (step = 33410560, mean_episode_return = 137.84, mean_episode_step = 847.48, total_loss = -21.858, pg_loss = -46.966, baseline_loss = 31.575, entropy_loss = -6.4668, learner_queue_size = 23, _tick = 9469, _time = 1.654e+09, train_seconds = 5051.0)
[2022-05-31 15:34:37,330][root][INFO] - Step 33443840 @ 6648.0 SPS. Inference batcher size: 86. Learner queue size: 26. Other stats: (step = 33443840, mean_episode_return = None, mean_episode_step = 905.25, total_loss = 282.35, pg_loss = 190.29, baseline_loss = 98.714, entropy_loss = -6.6503, learner_queue_size = 19, _tick = 9480, _time = 1.654e+09, train_seconds = 5056.0)
[2022-05-31 15:34:42,334][root][INFO] - Step 33479680 @ 7162.4 SPS. Inference batcher size: 138. Learner queue size: 27. Other stats: (step = 33479680, mean_episode_return = 102.98, mean_episode_step = 1062.2, total_loss = 218.21, pg_loss = 130.75, baseline_loss = 94.204, entropy_loss = -6.7432, learner_queue_size = 23, _tick = 9492, _time = 1.654e+09, train_seconds = 5061.0)
[2022-05-31 15:34:47,338][root][INFO] - Step 33510400 @ 6139.1 SPS. Inference batcher size: 139. Learner queue size: 25. Other stats: (step = 33510400, mean_episode_return = 95.344, mean_episode_step = 792.61, total_loss = -140.09, pg_loss = -154.87, baseline_loss = 20.898, entropy_loss = -6.1158, learner_queue_size = 25, _tick = 9503, _time = 1.654e+09, train_seconds = 5066.0)
[2022-05-31 15:34:52,343][root][INFO] - Step 33543680 @ 6649.5 SPS. Inference batcher size: 176. Learner queue size: 19. Other stats: (step = 33543680, mean_episode_return = 221.98, mean_episode_step = 934.59, total_loss = -112.26, pg_loss = -119.01, baseline_loss = 13.135, entropy_loss = -6.3785, learner_queue_size = 14, _tick = 9515, _time = 1.654e+09, train_seconds = 5071.0)
[2022-05-31 15:34:57,349][root][INFO] - Step 33576960 @ 6648.0 SPS. Inference batcher size: 165. Learner queue size: 25. Other stats: (step = 33576960, mean_episode_return = None, mean_episode_step = 856.72, total_loss = 115.72, pg_loss = 84.427, baseline_loss = 38.436, entropy_loss = -7.1435, learner_queue_size = 14, _tick = 9524, _time = 1.654e+09, train_seconds = 5076.0)
[2022-05-31 15:35:02,355][root][INFO] - Step 33610240 @ 6648.3 SPS. Inference batcher size: 9. Learner queue size: 27. Other stats: (step = 33610240, mean_episode_return = 123.35, mean_episode_step = 920.18, total_loss = -403.1, pg_loss = -438.53, baseline_loss = 42.373, entropy_loss = -6.9392, learner_queue_size = 20, _tick = 9537, _time = 1.654e+09, train_seconds = 5081.0)
[2022-05-31 15:35:07,358][root][INFO] - Step 33643520 @ 6651.5 SPS. Inference batcher size: 94. Learner queue size: 7. Other stats: (step = 33643520, mean_episode_return = None, mean_episode_step = 1028.4, total_loss = 0.68736, pg_loss = -5.5544, baseline_loss = 13.037, entropy_loss = -6.7955, learner_queue_size = 25, _tick = 9546, _time = 1.654e+09, train_seconds = 5086.0)
[2022-05-31 15:35:12,365][root][INFO] - Step 33676800 @ 6647.5 SPS. Inference batcher size: 3. Learner queue size: 4. Other stats: (step = 33676800, mean_episode_return = 56.205, mean_episode_step = 956.04, total_loss = 265.28, pg_loss = 210.13, baseline_loss = 61.906, entropy_loss = -6.7531, learner_queue_size = 19, _tick = 9559, _time = 1.654e+09, train_seconds = 5091.0)
[2022-05-31 15:35:17,370][root][INFO] - Step 33710080 @ 6648.7 SPS. Inference batcher size: 122. Learner queue size: 16. Other stats: (step = 33710080, mean_episode_return = 152.71, mean_episode_step = 899.81, total_loss = -141.22, pg_loss = -149.18, baseline_loss = 14.55, entropy_loss = -6.592, learner_queue_size = 11, _tick = 9571, _time = 1.654e+09, train_seconds = 5096.1)
[2022-05-31 15:35:22,376][root][INFO] - Step 33740800 @ 6136.7 SPS. Inference batcher size: 78. Learner queue size: 15. Other stats: (step = 33740800, mean_episode_return = 93.3, mean_episode_step = 956.12, total_loss = 174.24, pg_loss = 117.99, baseline_loss = 62.781, entropy_loss = -6.5265, learner_queue_size = 24, _tick = 9579, _time = 1.654e+09, train_seconds = 5101.1)
[2022-05-31 15:35:27,378][root][INFO] - Step 33774080 @ 6653.1 SPS. Inference batcher size: 119. Learner queue size: 12. Other stats: (step = 33774080, mean_episode_return = 81.618, mean_episode_step = 784.05, total_loss = 275.56, pg_loss = 248.74, baseline_loss = 32.209, entropy_loss = -5.3886, learner_queue_size = 23, _tick = 9591, _time = 1.654e+09, train_seconds = 5106.1)
[2022-05-31 15:35:32,382][root][INFO] - Step 33807360 @ 6650.8 SPS. Inference batcher size: 165. Learner queue size: 10. Other stats: (step = 33807360, mean_episode_return = 108.81, mean_episode_step = 686.02, total_loss = 18.025, pg_loss = -91.689, baseline_loss = 115.48, entropy_loss = -5.7636, learner_queue_size = 18, _tick = 9603, _time = 1.654e+09, train_seconds = 5111.1)
[2022-05-31 15:35:37,386][root][INFO] - Step 33840640 @ 6650.6 SPS. Inference batcher size: 156. Learner queue size: 11. Other stats: (step = 33840640, mean_episode_return = 87.856, mean_episode_step = 825.45, total_loss = 292.11, pg_loss = 249.22, baseline_loss = 49.782, entropy_loss = -6.8931, learner_queue_size = 24, _tick = 9616, _time = 1.654e+09, train_seconds = 5116.1)
[2022-05-31 15:35:42,390][root][INFO] - Step 33873920 @ 6650.8 SPS. Inference batcher size: 52. Learner queue size: 2. Other stats: (step = 33873920, mean_episode_return = 58.06, mean_episode_step = 630.64, total_loss = 282.5, pg_loss = 132.21, baseline_loss = 156.8, entropy_loss = -6.5064, learner_queue_size = 12, _tick = 9627, _time = 1.654e+09, train_seconds = 5121.1)
[2022-05-31 15:35:47,394][root][INFO] - Step 33907200 @ 6650.6 SPS. Inference batcher size: 52. Learner queue size: 2. Other stats: (step = 33907200, mean_episode_return = None, mean_episode_step = 541.94, total_loss = 264.32, pg_loss = 188.45, baseline_loss = 82.102, entropy_loss = -6.2374, learner_queue_size = 14, _tick = 9636, _time = 1.654e+09, train_seconds = 5126.1)
[2022-05-31 15:35:52,398][root][INFO] - Step 33940480 @ 6650.8 SPS. Inference batcher size: 56. Learner queue size: 0. Other stats: (step = 33940480, mean_episode_return = None, mean_episode_step = 824.19, total_loss = 184.37, pg_loss = 116.88, baseline_loss = 74.218, entropy_loss = -6.7297, learner_queue_size = 22, _tick = 9644, _time = 1.654e+09, train_seconds = 5131.1)
[2022-05-31 15:35:57,402][root][INFO] - Step 33973760 @ 6650.3 SPS. Inference batcher size: 84. Learner queue size: 16. Other stats: (step = 33973760, mean_episode_return = None, mean_episode_step = 779.25, total_loss = -160.35, pg_loss = -198.66, baseline_loss = 44.584, entropy_loss = -6.2748, learner_queue_size = 14, _tick = 9656, _time = 1.654e+09, train_seconds = 5136.1)
[2022-05-31 15:36:02,406][root][INFO] - Step 34007040 @ 6650.9 SPS. Inference batcher size: 112. Learner queue size: 16. Other stats: (step = 34007040, mean_episode_return = 109.92, mean_episode_step = 733.88, total_loss = -225.49, pg_loss = -262.43, baseline_loss = 43.197, entropy_loss = -6.2664, learner_queue_size = 14, _tick = 9669, _time = 1.654e+09, train_seconds = 5141.1)
[2022-05-31 15:36:07,410][root][INFO] - Step 34037760 @ 6139.0 SPS. Inference batcher size: 112. Learner queue size: 19. Other stats: (step = 34037760, mean_episode_return = 34.76, mean_episode_step = 875.95, total_loss = 155.03, pg_loss = 124.72, baseline_loss = 36.695, entropy_loss = -6.3774, learner_queue_size = 20, _tick = 9680, _time = 1.654e+09, train_seconds = 5146.1)
[2022-05-31 15:36:12,416][root][INFO] - Step 34071040 @ 6648.0 SPS. Inference batcher size: 177. Learner queue size: 6. Other stats: (step = 34071040, mean_episode_return = None, mean_episode_step = 895.47, total_loss = 142.78, pg_loss = 76.178, baseline_loss = 72.942, entropy_loss = -6.3413, learner_queue_size = 12, _tick = 9691, _time = 1.654e+09, train_seconds = 5151.1)
[2022-05-31 15:36:17,422][root][INFO] - Step 34104320 @ 6647.9 SPS. Inference batcher size: 71. Learner queue size: 6. Other stats: (step = 34104320, mean_episode_return = 79.925, mean_episode_step = 722.02, total_loss = -155.2, pg_loss = -179.23, baseline_loss = 30.504, entropy_loss = -6.477, learner_queue_size = 19, _tick = 9703, _time = 1.654e+09, train_seconds = 5156.1)
[2022-05-31 15:36:22,426][root][INFO] - Step 34137600 @ 6651.0 SPS. Inference batcher size: 33. Learner queue size: 2. Other stats: (step = 34137600, mean_episode_return = 155.37, mean_episode_step = 663.56, total_loss = 43.403, pg_loss = 10.401, baseline_loss = 39.206, entropy_loss = -6.2036, learner_queue_size = 19, _tick = 9716, _time = 1.654e+09, train_seconds = 5161.1)
[2022-05-31 15:36:27,430][root][INFO] - Step 34170880 @ 6650.7 SPS. Inference batcher size: 85. Learner queue size: 0. Other stats: (step = 34170880, mean_episode_return = 51.451, mean_episode_step = 725.39, total_loss = -122.36, pg_loss = -147.67, baseline_loss = 31.658, entropy_loss = -6.3396, learner_queue_size = 20, _tick = 9726, _time = 1.654e+09, train_seconds = 5166.1)
[2022-05-31 15:36:32,434][root][INFO] - Step 34201600 @ 6139.2 SPS. Inference batcher size: 136. Learner queue size: 21. Other stats: (step = 34201600, mean_episode_return = 132.63, mean_episode_step = 740.48, total_loss = 76.133, pg_loss = 6.7241, baseline_loss = 75.724, entropy_loss = -6.315, learner_queue_size = 15, _tick = 9738, _time = 1.654e+09, train_seconds = 5171.1)
[2022-05-31 15:36:37,440][root][INFO] - Step 34234880 @ 6647.6 SPS. Inference batcher size: 139. Learner queue size: 23. Other stats: (step = 34234880, mean_episode_return = None, mean_episode_step = 752.84, total_loss = 39.377, pg_loss = 15.729, baseline_loss = 29.937, entropy_loss = -6.2898, learner_queue_size = 9, _tick = 9748, _time = 1.654e+09, train_seconds = 5176.1)
[2022-05-31 15:36:42,446][root][INFO] - Step 34268160 @ 6648.2 SPS. Inference batcher size: 107. Learner queue size: 25. Other stats: (step = 34268160, mean_episode_return = None, mean_episode_step = 795.41, total_loss = 186.14, pg_loss = 99.308, baseline_loss = 93.351, entropy_loss = -6.5164, learner_queue_size = 18, _tick = 9759, _time = 1.654e+09, train_seconds = 5181.1)
[2022-05-31 15:36:47,450][root][INFO] - Step 34301440 @ 6650.7 SPS. Inference batcher size: 141. Learner queue size: 14. Other stats: (step = 34301440, mean_episode_return = 90.071, mean_episode_step = 726.76, total_loss = -151.29, pg_loss = -160.95, baseline_loss = 15.829, entropy_loss = -6.1766, learner_queue_size = 22, _tick = 9770, _time = 1.654e+09, train_seconds = 5186.1)
[2022-05-31 15:36:52,456][root][INFO] - Step 34334720 @ 6648.0 SPS. Inference batcher size: 132. Learner queue size: 13. Other stats: (step = 34334720, mean_episode_return = 82.26, mean_episode_step = 804.58, total_loss = 160.46, pg_loss = 136.72, baseline_loss = 29.951, entropy_loss = -6.2116, learner_queue_size = 19, _tick = 9781, _time = 1.654e+09, train_seconds = 5191.1)
[2022-05-31 15:36:57,458][root][INFO] - Step 34368000 @ 6654.0 SPS. Inference batcher size: 115. Learner queue size: 3. Other stats: (step = 34368000, mean_episode_return = 90.213, mean_episode_step = 777.27, total_loss = -213.53, pg_loss = -260.38, baseline_loss = 53.015, entropy_loss = -6.1677, learner_queue_size = 19, _tick = 9792, _time = 1.654e+09, train_seconds = 5196.1)
[2022-05-31 15:37:02,462][root][INFO] - Step 34401280 @ 6650.1 SPS. Inference batcher size: 150. Learner queue size: 30. Other stats: (step = 34401280, mean_episode_return = 31.8, mean_episode_step = 756.24, total_loss = 345.39, pg_loss = 231.28, baseline_loss = 120.85, entropy_loss = -6.7408, learner_queue_size = 25, _tick = 9803, _time = 1.654e+09, train_seconds = 5201.1)
[2022-05-31 15:37:07,466][root][INFO] - Step 34434560 @ 6650.6 SPS. Inference batcher size: 124. Learner queue size: 24. Other stats: (step = 34434560, mean_episode_return = None, mean_episode_step = 647.28, total_loss = 7.7438, pg_loss = -40.699, baseline_loss = 55.029, entropy_loss = -6.5866, learner_queue_size = 21, _tick = 9813, _time = 1.654e+09, train_seconds = 5206.2)
[2022-05-31 15:37:12,470][root][INFO] - Step 34465280 @ 6139.1 SPS. Inference batcher size: 157. Learner queue size: 14. Other stats: (step = 34465280, mean_episode_return = 144.54, mean_episode_step = 752.11, total_loss = -32.484, pg_loss = -47.268, baseline_loss = 20.803, entropy_loss = -6.0189, learner_queue_size = 20, _tick = 9823, _time = 1.654e+09, train_seconds = 5211.2)
[2022-05-31 15:37:17,476][root][INFO] - Step 34498560 @ 6647.9 SPS. Inference batcher size: 114. Learner queue size: 4. Other stats: (step = 34498560, mean_episode_return = 95.083, mean_episode_step = 677.37, total_loss = -60.517, pg_loss = -140.46, baseline_loss = 86.141, entropy_loss = -6.1945, learner_queue_size = 19, _tick = 9836, _time = 1.654e+09, train_seconds = 5216.2)
[2022-05-31 15:37:22,482][root][INFO] - Step 34531840 @ 6648.1 SPS. Inference batcher size: 112. Learner queue size: 3. Other stats: (step = 34531840, mean_episode_return = 95.239, mean_episode_step = 734.19, total_loss = 107.39, pg_loss = 25.818, baseline_loss = 88.123, entropy_loss = -6.5529, learner_queue_size = 22, _tick = 9846, _time = 1.654e+09, train_seconds = 5221.2)
[2022-05-31 15:37:27,486][root][INFO] - Step 34565120 @ 6650.6 SPS. Inference batcher size: 34. Learner queue size: 18. Other stats: (step = 34565120, mean_episode_return = 125.16, mean_episode_step = 610.28, total_loss = 195.8, pg_loss = 151.97, baseline_loss = 50.566, entropy_loss = -6.7414, learner_queue_size = 15, _tick = 9857, _time = 1.654e+09, train_seconds = 5226.2)
[2022-05-31 15:37:32,493][root][INFO] - Step 34595840 @ 6135.4 SPS. Inference batcher size: 117. Learner queue size: 17. Other stats: (step = 34595840, mean_episode_return = 56.471, mean_episode_step = 951.06, total_loss = 257.78, pg_loss = 220.46, baseline_loss = 44.348, entropy_loss = -7.0296, learner_queue_size = 20, _tick = 9867, _time = 1.654e+09, train_seconds = 5231.2)
[2022-05-31 15:37:37,498][root][INFO] - Step 34629120 @ 6649.5 SPS. Inference batcher size: 160. Learner queue size: 13. Other stats: (step = 34629120, mean_episode_return = 78.718, mean_episode_step = 797.28, total_loss = 179.93, pg_loss = 145.69, baseline_loss = 40.918, entropy_loss = -6.6808, learner_queue_size = 11, _tick = 9877, _time = 1.654e+09, train_seconds = 5236.2)
[2022-05-31 15:37:42,502][root][INFO] - Step 34662400 @ 6650.8 SPS. Inference batcher size: 168. Learner queue size: 17. Other stats: (step = 34662400, mean_episode_return = None, mean_episode_step = 825.78, total_loss = 68.625, pg_loss = 38.44, baseline_loss = 37.137, entropy_loss = -6.9525, learner_queue_size = 18, _tick = 9889, _time = 1.654e+09, train_seconds = 5241.2)
[2022-05-31 15:37:47,508][root][INFO] - Step 34695680 @ 6647.8 SPS. Inference batcher size: 117. Learner queue size: 2. Other stats: (step = 34695680, mean_episode_return = None, mean_episode_step = 850.91, total_loss = 85.845, pg_loss = 50.898, baseline_loss = 41.446, entropy_loss = -6.4998, learner_queue_size = 15, _tick = 9899, _time = 1.654e+09, train_seconds = 5246.2)
[2022-05-31 15:37:52,514][root][INFO] - Step 34726400 @ 6136.9 SPS. Inference batcher size: 182. Learner queue size: 15. Other stats: (step = 34726400, mean_episode_return = 157.78, mean_episode_step = 840.76, total_loss = -45.257, pg_loss = -142.12, baseline_loss = 103.49, entropy_loss = -6.6203, learner_queue_size = 16, _tick = 9909, _time = 1.654e+09, train_seconds = 5251.2)
[2022-05-31 15:37:57,520][root][INFO] - Step 34759680 @ 6648.0 SPS. Inference batcher size: 150. Learner queue size: 20. Other stats: (step = 34759680, mean_episode_return = None, mean_episode_step = 1108.1, total_loss = 116.09, pg_loss = 85.548, baseline_loss = 37.641, entropy_loss = -7.1015, learner_queue_size = 16, _tick = 9920, _time = 1.654e+09, train_seconds = 5256.2)
[2022-05-31 15:38:02,526][root][INFO] - Step 34792960 @ 6648.1 SPS. Inference batcher size: 131. Learner queue size: 14. Other stats: (step = 34792960, mean_episode_return = None, mean_episode_step = 744.78, total_loss = 274.95, pg_loss = 193.18, baseline_loss = 88.853, entropy_loss = -7.0904, learner_queue_size = 22, _tick = 9932, _time = 1.654e+09, train_seconds = 5261.2)
[2022-05-31 15:38:07,530][root][INFO] - Step 34826240 @ 6650.5 SPS. Inference batcher size: 109. Learner queue size: 24. Other stats: (step = 34826240, mean_episode_return = None, mean_episode_step = 731.19, total_loss = -40.686, pg_loss = -58.214, baseline_loss = 24.752, entropy_loss = -7.2237, learner_queue_size = 20, _tick = 9941, _time = 1.654e+09, train_seconds = 5266.2)
[2022-05-31 15:38:12,536][root][INFO] - Step 34859520 @ 6648.0 SPS. Inference batcher size: 127. Learner queue size: 16. Other stats: (step = 34859520, mean_episode_return = 126.6, mean_episode_step = 917.58, total_loss = -20.385, pg_loss = -36.783, baseline_loss = 23.532, entropy_loss = -7.134, learner_queue_size = 14, _tick = 9953, _time = 1.654e+09, train_seconds = 5271.2)
[2022-05-31 15:38:17,542][root][INFO] - Step 34892800 @ 6648.1 SPS. Inference batcher size: 155. Learner queue size: 2. Other stats: (step = 34892800, mean_episode_return = None, mean_episode_step = 855.06, total_loss = 38.897, pg_loss = 2.3612, baseline_loss = 42.717, entropy_loss = -6.1811, learner_queue_size = 16, _tick = 9961, _time = 1.654e+09, train_seconds = 5276.2)
[2022-05-31 15:38:22,546][root][INFO] - Step 34926080 @ 6650.7 SPS. Inference batcher size: 149. Learner queue size: 8. Other stats: (step = 34926080, mean_episode_return = 34.764, mean_episode_step = 1008.1, total_loss = -167.6, pg_loss = -178.62, baseline_loss = 17.419, entropy_loss = -6.4028, learner_queue_size = 24, _tick = 9973, _time = 1.654e+09, train_seconds = 5281.2)
[2022-05-31 15:38:27,550][root][INFO] - Step 34959360 @ 6650.6 SPS. Inference batcher size: 151. Learner queue size: 31. Other stats: (step = 34959360, mean_episode_return = 13.69, mean_episode_step = 877.24, total_loss = -74.827, pg_loss = -129.21, baseline_loss = 61.526, entropy_loss = -7.1394, learner_queue_size = 23, _tick = 9984, _time = 1.654e+09, train_seconds = 5286.2)
[2022-05-31 15:38:32,556][root][INFO] - Step 34990080 @ 6136.5 SPS. Inference batcher size: 162. Learner queue size: 11. Other stats: (step = 34990080, mean_episode_return = 52.119, mean_episode_step = 756.67, total_loss = 219.49, pg_loss = 142.72, baseline_loss = 83.43, entropy_loss = -6.6656, learner_queue_size = 16, _tick = 9994, _time = 1.654e+09, train_seconds = 5291.2)
[2022-05-31 15:38:37,562][root][INFO] - Step 35023360 @ 6648.0 SPS. Inference batcher size: 204. Learner queue size: 4. Other stats: (step = 35023360, mean_episode_return = 111.09, mean_episode_step = 870.39, total_loss = 62.131, pg_loss = 39.197, baseline_loss = 29.952, entropy_loss = -7.0186, learner_queue_size = 25, _tick = 10004, _time = 1.654e+09, train_seconds = 5296.2)
[2022-05-31 15:38:42,570][root][INFO] - Step 35056640 @ 6645.4 SPS. Inference batcher size: 128. Learner queue size: 4. Other stats: (step = 35056640, mean_episode_return = 182.82, mean_episode_step = 822.13, total_loss = 539.91, pg_loss = 437.15, baseline_loss = 108.93, entropy_loss = -6.1713, learner_queue_size = 19, _tick = 10016, _time = 1.654e+09, train_seconds = 5301.3)
[2022-05-31 15:38:47,574][root][INFO] - Step 35089920 @ 6650.9 SPS. Inference batcher size: 124. Learner queue size: 3. Other stats: (step = 35089920, mean_episode_return = 208.36, mean_episode_step = 860.96, total_loss = -15.406, pg_loss = -42.08, baseline_loss = 33.548, entropy_loss = -6.874, learner_queue_size = 23, _tick = 10028, _time = 1.654e+09, train_seconds = 5306.3)
[2022-05-31 15:38:52,578][root][INFO] - Step 35123200 @ 6650.7 SPS. Inference batcher size: 123. Learner queue size: 1. Other stats: (step = 35123200, mean_episode_return = 33.03, mean_episode_step = 913.16, total_loss = 247.73, pg_loss = 192.86, baseline_loss = 61.615, entropy_loss = -6.7476, learner_queue_size = 13, _tick = 10040, _time = 1.654e+09, train_seconds = 5311.3)
[2022-05-31 15:38:57,582][root][INFO] - Step 35156480 @ 6650.6 SPS. Inference batcher size: 141. Learner queue size: 23. Other stats: (step = 35156480, mean_episode_return = 137.09, mean_episode_step = 761.42, total_loss = 386.85, pg_loss = 148.94, baseline_loss = 244.62, entropy_loss = -6.7159, learner_queue_size = 18, _tick = 10051, _time = 1.654e+09, train_seconds = 5316.3)
[2022-05-31 15:39:02,588][root][INFO] - Step 35187200 @ 6136.5 SPS. Inference batcher size: 130. Learner queue size: 14. Other stats: (step = 35187200, mean_episode_return = 73.84, mean_episode_step = 685.84, total_loss = 7.9373, pg_loss = -36.868, baseline_loss = 51.358, entropy_loss = -6.5525, learner_queue_size = 17, _tick = 10062, _time = 1.654e+09, train_seconds = 5321.3)
[2022-05-31 15:39:07,594][root][INFO] - Step 35220480 @ 6648.0 SPS. Inference batcher size: 74. Learner queue size: 19. Other stats: (step = 35220480, mean_episode_return = None, mean_episode_step = 856.78, total_loss = 224.75, pg_loss = 77.998, baseline_loss = 153.54, entropy_loss = -6.7869, learner_queue_size = 30, _tick = 10073, _time = 1.654e+09, train_seconds = 5326.3)
[2022-05-31 15:39:12,600][root][INFO] - Step 35253760 @ 6648.0 SPS. Inference batcher size: 118. Learner queue size: 16. Other stats: (step = 35253760, mean_episode_return = None, mean_episode_step = 677.59, total_loss = 69.904, pg_loss = 21.117, baseline_loss = 55.334, entropy_loss = -6.546, learner_queue_size = 24, _tick = 10082, _time = 1.654e+09, train_seconds = 5331.3)
[2022-05-31 15:39:17,606][root][INFO] - Step 35287040 @ 6648.1 SPS. Inference batcher size: 111. Learner queue size: 17. Other stats: (step = 35287040, mean_episode_return = 131.49, mean_episode_step = 809.84, total_loss = 220.68, pg_loss = 159.3, baseline_loss = 68.056, entropy_loss = -6.6717, learner_queue_size = 25, _tick = 10095, _time = 1.654e+09, train_seconds = 5336.3)
[2022-05-31 15:39:22,612][root][INFO] - Step 35320320 @ 6647.6 SPS. Inference batcher size: 12. Learner queue size: 6. Other stats: (step = 35320320, mean_episode_return = 139.66, mean_episode_step = 831.45, total_loss = -130.39, pg_loss = -151.4, baseline_loss = 26.553, entropy_loss = -5.5467, learner_queue_size = 17, _tick = 10108, _time = 1.654e+09, train_seconds = 5341.3)
[2022-05-31 15:39:27,618][root][INFO] - Step 35353600 @ 6648.5 SPS. Inference batcher size: 124. Learner queue size: 21. Other stats: (step = 35353600, mean_episode_return = 61.343, mean_episode_step = 641.73, total_loss = 183.08, pg_loss = 109.42, baseline_loss = 80.011, entropy_loss = -6.3513, learner_queue_size = 25, _tick = 10120, _time = 1.654e+09, train_seconds = 5346.3)
[2022-05-31 15:39:32,622][root][INFO] - Step 35386880 @ 6650.7 SPS. Inference batcher size: 84. Learner queue size: 12. Other stats: (step = 35386880, mean_episode_return = 106.82, mean_episode_step = 735.36, total_loss = -225.99, pg_loss = -244.7, baseline_loss = 25.575, entropy_loss = -6.8613, learner_queue_size = 19, _tick = 10132, _time = 1.654e+09, train_seconds = 5351.3)
[2022-05-31 15:39:37,626][root][INFO] - Step 35420160 @ 6650.7 SPS. Inference batcher size: 63. Learner queue size: 6. Other stats: (step = 35420160, mean_episode_return = 134.95, mean_episode_step = 694.41, total_loss = 56.718, pg_loss = 29.266, baseline_loss = 33.753, entropy_loss = -6.301, learner_queue_size = 20, _tick = 10144, _time = 1.654e+09, train_seconds = 5356.3)
[2022-05-31 15:39:42,630][root][INFO] - Step 35453440 @ 6650.8 SPS. Inference batcher size: 69. Learner queue size: 2. Other stats: (step = 35453440, mean_episode_return = 156.57, mean_episode_step = 659.7, total_loss = 282.44, pg_loss = 203.95, baseline_loss = 85.001, entropy_loss = -6.5056, learner_queue_size = 20, _tick = 10154, _time = 1.654e+09, train_seconds = 5361.3)
[2022-05-31 15:39:47,634][root][INFO] - Step 35486720 @ 6650.7 SPS. Inference batcher size: 84. Learner queue size: 29. Other stats: (step = 35486720, mean_episode_return = None, mean_episode_step = 995.34, total_loss = -125.78, pg_loss = -130.53, baseline_loss = 11.613, entropy_loss = -6.8593, learner_queue_size = 15, _tick = 10166, _time = 1.654e+09, train_seconds = 5366.3)
[2022-05-31 15:39:52,638][root][INFO] - Step 35517440 @ 6139.1 SPS. Inference batcher size: 61. Learner queue size: 20. Other stats: (step = 35517440, mean_episode_return = None, mean_episode_step = 607.5, total_loss = -63.833, pg_loss = -84.132, baseline_loss = 26.959, entropy_loss = -6.6599, learner_queue_size = 18, _tick = 10175, _time = 1.654e+09, train_seconds = 5371.3)
[2022-05-31 15:39:57,645][root][INFO] - Step 35550720 @ 6646.8 SPS. Inference batcher size: 131. Learner queue size: 19. Other stats: (step = 35550720, mean_episode_return = 81.521, mean_episode_step = 946.06, total_loss = 114.53, pg_loss = 68.546, baseline_loss = 52.713, entropy_loss = -6.7246, learner_queue_size = 21, _tick = 10188, _time = 1.654e+09, train_seconds = 5376.3)
[2022-05-31 15:40:02,647][root][INFO] - Step 35584000 @ 6652.9 SPS. Inference batcher size: 122. Learner queue size: 15. Other stats: (step = 35584000, mean_episode_return = 124.99, mean_episode_step = 713.83, total_loss = 66.98, pg_loss = -59.611, baseline_loss = 133.09, entropy_loss = -6.4978, learner_queue_size = 18, _tick = 10197, _time = 1.654e+09, train_seconds = 5381.3)
[2022-05-31 15:40:07,653][root][INFO] - Step 35617280 @ 6648.0 SPS. Inference batcher size: 124. Learner queue size: 13. Other stats: (step = 35617280, mean_episode_return = 85.636, mean_episode_step = 698.68, total_loss = -24.484, pg_loss = -52.16, baseline_loss = 34.2, entropy_loss = -6.5243, learner_queue_size = 17, _tick = 10207, _time = 1.654e+09, train_seconds = 5386.3)
[2022-05-31 15:40:12,658][root][INFO] - Step 35650560 @ 6649.7 SPS. Inference batcher size: 105. Learner queue size: 3. Other stats: (step = 35650560, mean_episode_return = 10.31, mean_episode_step = 770.89, total_loss = 544.63, pg_loss = 412.63, baseline_loss = 139.26, entropy_loss = -7.2573, learner_queue_size = 30, _tick = 10217, _time = 1.654e+09, train_seconds = 5391.3)
[2022-05-31 15:40:17,662][root][INFO] - Step 35683840 @ 6650.6 SPS. Inference batcher size: 10. Learner queue size: 1. Other stats: (step = 35683840, mean_episode_return = 104.24, mean_episode_step = 957.75, total_loss = 166.8, pg_loss = 67.176, baseline_loss = 106.31, entropy_loss = -6.6847, learner_queue_size = 21, _tick = 10230, _time = 1.654e+09, train_seconds = 5396.3)
[2022-05-31 15:40:22,666][root][INFO] - Step 35717120 @ 6650.8 SPS. Inference batcher size: 133. Learner queue size: 23. Other stats: (step = 35717120, mean_episode_return = 93.081, mean_episode_step = 820.87, total_loss = -16.702, pg_loss = -32.404, baseline_loss = 22.9, entropy_loss = -7.1985, learner_queue_size = 15, _tick = 10241, _time = 1.654e+09, train_seconds = 5401.4)
[2022-05-31 15:40:27,672][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 15:40:27,786][root][INFO] - Step 35747840 @ 6136.6 SPS. Inference batcher size: 10. Learner queue size: 25. Other stats: (step = 35750400, mean_episode_return = 92.307, mean_episode_step = 745.82, total_loss = 381.71, pg_loss = 263.36, baseline_loss = 125.15, entropy_loss = -6.7892, learner_queue_size = 21, _tick = 10252, _time = 1.654e+09, train_seconds = 5406.4)
[2022-05-31 15:40:32,792][root][INFO] - Step 35783680 @ 7000.2 SPS. Inference batcher size: 99. Learner queue size: 2. Other stats: (step = 35783680, mean_episode_return = 179.39, mean_episode_step = 815.73, total_loss = 129.48, pg_loss = 75.043, baseline_loss = 61.163, entropy_loss = -6.7237, learner_queue_size = 23, _tick = 10262, _time = 1.654e+09, train_seconds = 5411.5)
[2022-05-31 15:40:37,794][root][INFO] - Step 35816960 @ 6653.3 SPS. Inference batcher size: 65. Learner queue size: 23. Other stats: (step = 35816960, mean_episode_return = 199.59, mean_episode_step = 721.06, total_loss = -203.37, pg_loss = -238.0, baseline_loss = 41.191, entropy_loss = -6.5629, learner_queue_size = 11, _tick = 10273, _time = 1.654e+09, train_seconds = 5416.5)
[2022-05-31 15:40:42,807][root][INFO] - Step 35847680 @ 6127.5 SPS. Inference batcher size: 149. Learner queue size: 23. Other stats: (step = 35847680, mean_episode_return = 127.96, mean_episode_step = 858.27, total_loss = 102.04, pg_loss = 63.806, baseline_loss = 45.165, entropy_loss = -6.9257, learner_queue_size = 13, _tick = 10282, _time = 1.654e+09, train_seconds = 5421.5)
[2022-05-31 15:40:47,810][root][INFO] - Step 35880960 @ 6652.2 SPS. Inference batcher size: 187. Learner queue size: 7. Other stats: (step = 35880960, mean_episode_return = 88.38, mean_episode_step = 822.63, total_loss = 257.76, pg_loss = 202.96, baseline_loss = 61.461, entropy_loss = -6.6663, learner_queue_size = 22, _tick = 10295, _time = 1.654e+09, train_seconds = 5426.5)
[2022-05-31 15:40:52,817][root][INFO] - Step 35914240 @ 6647.4 SPS. Inference batcher size: 122. Learner queue size: 4. Other stats: (step = 35914240, mean_episode_return = 191.1, mean_episode_step = 746.03, total_loss = 69.651, pg_loss = 11.865, baseline_loss = 63.946, entropy_loss = -6.1601, learner_queue_size = 14, _tick = 10307, _time = 1.654e+09, train_seconds = 5431.5)
[2022-05-31 15:40:57,822][root][INFO] - Step 35947520 @ 6649.1 SPS. Inference batcher size: 115. Learner queue size: 2. Other stats: (step = 35947520, mean_episode_return = 108.13, mean_episode_step = 924.47, total_loss = 74.257, pg_loss = 43.054, baseline_loss = 37.084, entropy_loss = -5.8803, learner_queue_size = 26, _tick = 10318, _time = 1.654e+09, train_seconds = 5436.5)
[2022-05-31 15:41:02,826][root][INFO] - Step 35980800 @ 6650.7 SPS. Inference batcher size: 122. Learner queue size: 31. Other stats: (step = 35980800, mean_episode_return = 358.56, mean_episode_step = 772.87, total_loss = -65.295, pg_loss = -91.13, baseline_loss = 32.535, entropy_loss = -6.7003, learner_queue_size = 30, _tick = 10327, _time = 1.654e+09, train_seconds = 5441.5)
[2022-05-31 15:41:07,830][root][INFO] - Step 36014080 @ 6650.5 SPS. Inference batcher size: 159. Learner queue size: 22. Other stats: (step = 36014080, mean_episode_return = 116.18, mean_episode_step = 744.73, total_loss = 230.42, pg_loss = 193.9, baseline_loss = 43.25, entropy_loss = -6.7365, learner_queue_size = 18, _tick = 10339, _time = 1.654e+09, train_seconds = 5446.5)
[2022-05-31 15:41:12,836][root][INFO] - Step 36044800 @ 6136.7 SPS. Inference batcher size: 94. Learner queue size: 14. Other stats: (step = 36044800, mean_episode_return = 72.735, mean_episode_step = 697.96, total_loss = -76.26, pg_loss = -118.01, baseline_loss = 48.687, entropy_loss = -6.9388, learner_queue_size = 19, _tick = 10351, _time = 1.654e+09, train_seconds = 5451.5)
[2022-05-31 15:41:17,842][root][INFO] - Step 36078080 @ 6648.0 SPS. Inference batcher size: 51. Learner queue size: 14. Other stats: (step = 36078080, mean_episode_return = 171.8, mean_episode_step = 747.94, total_loss = 337.28, pg_loss = 262.46, baseline_loss = 81.724, entropy_loss = -6.9067, learner_queue_size = 24, _tick = 10364, _time = 1.654e+09, train_seconds = 5456.5)
[2022-05-31 15:41:22,846][root][INFO] - Step 36111360 @ 6650.8 SPS. Inference batcher size: 72. Learner queue size: 13. Other stats: (step = 36111360, mean_episode_return = 34.98, mean_episode_step = 653.64, total_loss = 261.14, pg_loss = 220.72, baseline_loss = 46.854, entropy_loss = -6.4393, learner_queue_size = 23, _tick = 10374, _time = 1.654e+09, train_seconds = 5461.5)
[2022-05-31 15:41:27,850][root][INFO] - Step 36144640 @ 6650.6 SPS. Inference batcher size: 156. Learner queue size: 0. Other stats: (step = 36144640, mean_episode_return = 74.905, mean_episode_step = 721.32, total_loss = -146.96, pg_loss = -161.83, baseline_loss = 21.869, entropy_loss = -6.9901, learner_queue_size = 23, _tick = 10386, _time = 1.654e+09, train_seconds = 5466.5)
[2022-05-31 15:41:32,854][root][INFO] - Step 36177920 @ 6650.7 SPS. Inference batcher size: 132. Learner queue size: 1. Other stats: (step = 36177920, mean_episode_return = 23.01, mean_episode_step = 745.74, total_loss = -132.15, pg_loss = -153.83, baseline_loss = 28.489, entropy_loss = -6.8061, learner_queue_size = 18, _tick = 10399, _time = 1.654e+09, train_seconds = 5471.5)
[2022-05-31 15:41:37,859][root][INFO] - Step 36208640 @ 6138.0 SPS. Inference batcher size: 105. Learner queue size: 24. Other stats: (step = 36208640, mean_episode_return = 156.58, mean_episode_step = 768.41, total_loss = 73.68, pg_loss = 39.318, baseline_loss = 40.761, entropy_loss = -6.3986, learner_queue_size = 11, _tick = 10410, _time = 1.654e+09, train_seconds = 5476.5)
[2022-05-31 15:41:42,862][root][INFO] - Step 36241920 @ 6651.9 SPS. Inference batcher size: 172. Learner queue size: 19. Other stats: (step = 36241920, mean_episode_return = 63.81, mean_episode_step = 588.75, total_loss = 118.87, pg_loss = 22.863, baseline_loss = 102.43, entropy_loss = -6.4181, learner_queue_size = 14, _tick = 10422, _time = 1.654e+09, train_seconds = 5481.5)
[2022-05-31 15:41:47,868][root][INFO] - Step 36275200 @ 6648.0 SPS. Inference batcher size: 189. Learner queue size: 23. Other stats: (step = 36275200, mean_episode_return = 42.6, mean_episode_step = 640.79, total_loss = 286.28, pg_loss = 222.78, baseline_loss = 69.856, entropy_loss = -6.3561, learner_queue_size = 18, _tick = 10432, _time = 1.654e+09, train_seconds = 5486.6)
[2022-05-31 15:41:52,874][root][INFO] - Step 36308480 @ 6648.0 SPS. Inference batcher size: 128. Learner queue size: 17. Other stats: (step = 36308480, mean_episode_return = 99.72, mean_episode_step = 852.86, total_loss = -135.65, pg_loss = -144.46, baseline_loss = 15.787, entropy_loss = -6.9789, learner_queue_size = 18, _tick = 10444, _time = 1.654e+09, train_seconds = 5491.6)
[2022-05-31 15:41:57,880][root][INFO] - Step 36341760 @ 6647.9 SPS. Inference batcher size: 80. Learner queue size: 14. Other stats: (step = 36341760, mean_episode_return = 68.415, mean_episode_step = 667.72, total_loss = -18.681, pg_loss = -35.504, baseline_loss = 23.716, entropy_loss = -6.8932, learner_queue_size = 13, _tick = 10455, _time = 1.654e+09, train_seconds = 5496.6)
[2022-05-31 15:42:02,886][root][INFO] - Step 36375040 @ 6647.7 SPS. Inference batcher size: 211. Learner queue size: 17. Other stats: (step = 36375040, mean_episode_return = 109.39, mean_episode_step = 704.49, total_loss = -35.814, pg_loss = -70.391, baseline_loss = 41.257, entropy_loss = -6.6796, learner_queue_size = 21, _tick = 10466, _time = 1.654e+09, train_seconds = 5501.6)
[2022-05-31 15:42:07,892][root][INFO] - Step 36408320 @ 6648.0 SPS. Inference batcher size: 24. Learner queue size: 7. Other stats: (step = 36408320, mean_episode_return = 123.14, mean_episode_step = 812.18, total_loss = -48.617, pg_loss = -54.508, baseline_loss = 12.759, entropy_loss = -6.8675, learner_queue_size = 16, _tick = 10475, _time = 1.654e+09, train_seconds = 5506.6)
[2022-05-31 15:42:12,898][root][INFO] - Step 36441600 @ 6648.0 SPS. Inference batcher size: 67. Learner queue size: 28. Other stats: (step = 36441600, mean_episode_return = None, mean_episode_step = 866.25, total_loss = 162.57, pg_loss = 131.83, baseline_loss = 37.365, entropy_loss = -6.6257, learner_queue_size = 27, _tick = 10484, _time = 1.654e+09, train_seconds = 5511.6)
[2022-05-31 15:42:17,902][root][INFO] - Step 36474880 @ 6650.9 SPS. Inference batcher size: 66. Learner queue size: 28. Other stats: (step = 36474880, mean_episode_return = 84.745, mean_episode_step = 845.52, total_loss = -170.17, pg_loss = -200.59, baseline_loss = 36.828, entropy_loss = -6.4032, learner_queue_size = 16, _tick = 10494, _time = 1.654e+09, train_seconds = 5516.6)
[2022-05-31 15:42:22,909][root][INFO] - Step 36508160 @ 6647.6 SPS. Inference batcher size: 27. Learner queue size: 27. Other stats: (step = 36508160, mean_episode_return = 96.62, mean_episode_step = 730.86, total_loss = 144.26, pg_loss = 61.343, baseline_loss = 89.196, entropy_loss = -6.2751, learner_queue_size = 22, _tick = 10507, _time = 1.654e+09, train_seconds = 5521.6)
[2022-05-31 15:42:27,914][root][INFO] - Step 36541440 @ 6648.7 SPS. Inference batcher size: 86. Learner queue size: 19. Other stats: (step = 36541440, mean_episode_return = None, mean_episode_step = 817.34, total_loss = 36.339, pg_loss = -2.5242, baseline_loss = 45.406, entropy_loss = -6.5427, learner_queue_size = 14, _tick = 10519, _time = 1.654e+09, train_seconds = 5526.6)
[2022-05-31 15:42:32,920][root][INFO] - Step 36572160 @ 6136.4 SPS. Inference batcher size: 131. Learner queue size: 21. Other stats: (step = 36572160, mean_episode_return = 174.62, mean_episode_step = 748.16, total_loss = -37.188, pg_loss = -61.72, baseline_loss = 31.05, entropy_loss = -6.5177, learner_queue_size = 16, _tick = 10530, _time = 1.654e+09, train_seconds = 5531.6)
[2022-05-31 15:42:37,926][root][INFO] - Step 36605440 @ 6648.0 SPS. Inference batcher size: 82. Learner queue size: 14. Other stats: (step = 36605440, mean_episode_return = 98.761, mean_episode_step = 641.35, total_loss = -43.294, pg_loss = -116.42, baseline_loss = 79.475, entropy_loss = -6.3519, learner_queue_size = 18, _tick = 10541, _time = 1.654e+09, train_seconds = 5536.6)
[2022-05-31 15:42:42,930][root][INFO] - Step 36641280 @ 7162.4 SPS. Inference batcher size: 147. Learner queue size: 18. Other stats: (step = 36641280, mean_episode_return = 107.58, mean_episode_step = 792.17, total_loss = -34.551, pg_loss = -67.732, baseline_loss = 39.505, entropy_loss = -6.3231, learner_queue_size = 14, _tick = 10553, _time = 1.654e+09, train_seconds = 5541.6)
[2022-05-31 15:42:47,934][root][INFO] - Step 36672000 @ 6139.1 SPS. Inference batcher size: 149. Learner queue size: 20. Other stats: (step = 36672000, mean_episode_return = 115.42, mean_episode_step = 630.69, total_loss = 211.28, pg_loss = 131.23, baseline_loss = 86.48, entropy_loss = -6.4316, learner_queue_size = 26, _tick = 10564, _time = 1.654e+09, train_seconds = 5546.6)
[2022-05-31 15:42:52,940][root][INFO] - Step 36705280 @ 6648.0 SPS. Inference batcher size: 140. Learner queue size: 14. Other stats: (step = 36705280, mean_episode_return = 131.75, mean_episode_step = 771.71, total_loss = -67.753, pg_loss = -84.183, baseline_loss = 22.781, entropy_loss = -6.3515, learner_queue_size = 23, _tick = 10575, _time = 1.654e+09, train_seconds = 5551.6)
[2022-05-31 15:42:57,946][root][INFO] - Step 36738560 @ 6648.0 SPS. Inference batcher size: 83. Learner queue size: 13. Other stats: (step = 36738560, mean_episode_return = 92.17, mean_episode_step = 891.94, total_loss = 398.89, pg_loss = 297.21, baseline_loss = 108.47, entropy_loss = -6.7839, learner_queue_size = 9, _tick = 10586, _time = 1.654e+09, train_seconds = 5556.6)
[2022-05-31 15:43:02,950][root][INFO] - Step 36771840 @ 6650.8 SPS. Inference batcher size: 84. Learner queue size: 7. Other stats: (step = 36771840, mean_episode_return = None, mean_episode_step = 881.16, total_loss = 26.638, pg_loss = -13.189, baseline_loss = 46.786, entropy_loss = -6.9595, learner_queue_size = 12, _tick = 10595, _time = 1.654e+09, train_seconds = 5561.6)
[2022-05-31 15:43:07,954][root][INFO] - Step 36805120 @ 6650.7 SPS. Inference batcher size: 139. Learner queue size: 5. Other stats: (step = 36805120, mean_episode_return = 179.09, mean_episode_step = 746.43, total_loss = 325.65, pg_loss = 246.24, baseline_loss = 85.914, entropy_loss = -6.5074, learner_queue_size = 27, _tick = 10606, _time = 1.654e+09, train_seconds = 5566.6)
[2022-05-31 15:43:12,958][root][INFO] - Step 36838400 @ 6650.6 SPS. Inference batcher size: 68. Learner queue size: 0. Other stats: (step = 36838400, mean_episode_return = 137.98, mean_episode_step = 707.97, total_loss = 19.08, pg_loss = -1.5775, baseline_loss = 27.015, entropy_loss = -6.3576, learner_queue_size = 23, _tick = 10617, _time = 1.654e+09, train_seconds = 5571.6)
[2022-05-31 15:43:17,964][root][INFO] - Step 36871680 @ 6648.1 SPS. Inference batcher size: 127. Learner queue size: 0. Other stats: (step = 36871680, mean_episode_return = 141.99, mean_episode_step = 712.17, total_loss = -36.331, pg_loss = -66.351, baseline_loss = 36.674, entropy_loss = -6.6535, learner_queue_size = 17, _tick = 10629, _time = 1.654e+09, train_seconds = 5576.6)
[2022-05-31 15:43:22,966][root][INFO] - Step 36904960 @ 6653.3 SPS. Inference batcher size: 125. Learner queue size: 23. Other stats: (step = 36904960, mean_episode_return = 145.17, mean_episode_step = 1096.8, total_loss = 7.1461, pg_loss = -3.7965, baseline_loss = 17.776, entropy_loss = -6.8332, learner_queue_size = 18, _tick = 10638, _time = 1.654e+09, train_seconds = 5581.7)
[2022-05-31 15:43:27,972][root][INFO] - Step 36935680 @ 6136.4 SPS. Inference batcher size: 26. Learner queue size: 25. Other stats: (step = 36935680, mean_episode_return = 320.2, mean_episode_step = 555.88, total_loss = 133.44, pg_loss = 61.143, baseline_loss = 79.088, entropy_loss = -6.7945, learner_queue_size = 14, _tick = 10649, _time = 1.654e+09, train_seconds = 5586.7)
[2022-05-31 15:43:32,979][root][INFO] - Step 36968960 @ 6647.4 SPS. Inference batcher size: 91. Learner queue size: 11. Other stats: (step = 36968960, mean_episode_return = 95.92, mean_episode_step = 939.77, total_loss = 248.49, pg_loss = 105.55, baseline_loss = 149.58, entropy_loss = -6.6381, learner_queue_size = 13, _tick = 10660, _time = 1.654e+09, train_seconds = 5591.7)
[2022-05-31 15:43:37,984][root][INFO] - Step 37002240 @ 6648.5 SPS. Inference batcher size: 118. Learner queue size: 13. Other stats: (step = 37002240, mean_episode_return = 146.67, mean_episode_step = 761.68, total_loss = -32.575, pg_loss = -62.542, baseline_loss = 36.372, entropy_loss = -6.4049, learner_queue_size = 17, _tick = 10670, _time = 1.654e+09, train_seconds = 5596.7)
[2022-05-31 15:43:42,990][root][INFO] - Step 37035520 @ 6648.4 SPS. Inference batcher size: 182. Learner queue size: 7. Other stats: (step = 37035520, mean_episode_return = None, mean_episode_step = 658.47, total_loss = -41.839, pg_loss = -75.106, baseline_loss = 39.593, entropy_loss = -6.326, learner_queue_size = 21, _tick = 10680, _time = 1.654e+09, train_seconds = 5601.7)
[2022-05-31 15:43:47,994][root][INFO] - Step 37068800 @ 6650.7 SPS. Inference batcher size: 119. Learner queue size: 11. Other stats: (step = 37068800, mean_episode_return = 93.17, mean_episode_step = 1153.5, total_loss = 259.29, pg_loss = 172.3, baseline_loss = 93.727, entropy_loss = -6.7455, learner_queue_size = 17, _tick = 10691, _time = 1.654e+09, train_seconds = 5606.7)
[2022-05-31 15:43:52,998][root][INFO] - Step 37102080 @ 6650.6 SPS. Inference batcher size: 170. Learner queue size: 7. Other stats: (step = 37102080, mean_episode_return = 53.299, mean_episode_step = 745.84, total_loss = 160.02, pg_loss = 111.39, baseline_loss = 55.339, entropy_loss = -6.7072, learner_queue_size = 18, _tick = 10701, _time = 1.654e+09, train_seconds = 5611.7)
[2022-05-31 15:43:58,004][root][INFO] - Step 37135360 @ 6647.9 SPS. Inference batcher size: 98. Learner queue size: 1. Other stats: (step = 37135360, mean_episode_return = 92.078, mean_episode_step = 871.65, total_loss = 264.87, pg_loss = 217.24, baseline_loss = 54.731, entropy_loss = -7.1011, learner_queue_size = 21, _tick = 10713, _time = 1.654e+09, train_seconds = 5616.7)
[2022-05-31 15:44:03,011][root][INFO] - Step 37168640 @ 6647.1 SPS. Inference batcher size: 85. Learner queue size: 2. Other stats: (step = 37168640, mean_episode_return = 122.63, mean_episode_step = 871.1, total_loss = 112.9, pg_loss = 80.376, baseline_loss = 39.441, entropy_loss = -6.9179, learner_queue_size = 24, _tick = 10723, _time = 1.654e+09, train_seconds = 5621.7)
[2022-05-31 15:44:08,014][root][INFO] - Step 37201920 @ 6651.7 SPS. Inference batcher size: 100. Learner queue size: 27. Other stats: (step = 37201920, mean_episode_return = 135.76, mean_episode_step = 806.83, total_loss = -76.081, pg_loss = -97.909, baseline_loss = 28.516, entropy_loss = -6.6872, learner_queue_size = 17, _tick = 10733, _time = 1.654e+09, train_seconds = 5626.7)
[2022-05-31 15:44:13,018][root][INFO] - Step 37235200 @ 6650.8 SPS. Inference batcher size: 156. Learner queue size: 25. Other stats: (step = 37235200, mean_episode_return = 102.67, mean_episode_step = 804.89, total_loss = 372.47, pg_loss = 273.05, baseline_loss = 106.07, entropy_loss = -6.6451, learner_queue_size = 22, _tick = 10744, _time = 1.654e+09, train_seconds = 5631.7)
[2022-05-31 15:44:18,022][root][INFO] - Step 37265920 @ 6139.1 SPS. Inference batcher size: 97. Learner queue size: 24. Other stats: (step = 37265920, mean_episode_return = 18.93, mean_episode_step = 813.33, total_loss = 295.38, pg_loss = 205.09, baseline_loss = 97.09, entropy_loss = -6.8021, learner_queue_size = 22, _tick = 10754, _time = 1.654e+09, train_seconds = 5636.7)
[2022-05-31 15:44:23,026][root][INFO] - Step 37299200 @ 6650.6 SPS. Inference batcher size: 34. Learner queue size: 13. Other stats: (step = 37299200, mean_episode_return = 101.09, mean_episode_step = 817.72, total_loss = -3.0527, pg_loss = -39.08, baseline_loss = 42.875, entropy_loss = -6.8479, learner_queue_size = 20, _tick = 10765, _time = 1.654e+09, train_seconds = 5641.7)
[2022-05-31 15:44:28,033][root][INFO] - Step 37332480 @ 6647.4 SPS. Inference batcher size: 131. Learner queue size: 17. Other stats: (step = 37332480, mean_episode_return = 86.238, mean_episode_step = 922.29, total_loss = 169.86, pg_loss = 134.81, baseline_loss = 41.824, entropy_loss = -6.7771, learner_queue_size = 17, _tick = 10776, _time = 1.654e+09, train_seconds = 5646.7)
[2022-05-31 15:44:33,038][root][INFO] - Step 37365760 @ 6648.8 SPS. Inference batcher size: 124. Learner queue size: 17. Other stats: (step = 37365760, mean_episode_return = 65.124, mean_episode_step = 931.66, total_loss = 128.88, pg_loss = 99.218, baseline_loss = 36.338, entropy_loss = -6.672, learner_queue_size = 24, _tick = 10786, _time = 1.654e+09, train_seconds = 5651.7)
[2022-05-31 15:44:38,042][root][INFO] - Step 37399040 @ 6650.6 SPS. Inference batcher size: 104. Learner queue size: 8. Other stats: (step = 37399040, mean_episode_return = 60.995, mean_episode_step = 768.42, total_loss = 50.816, pg_loss = -0.38716, baseline_loss = 57.865, entropy_loss = -6.6616, learner_queue_size = 13, _tick = 10798, _time = 1.654e+09, train_seconds = 5656.7)
[2022-05-31 15:44:43,046][root][INFO] - Step 37432320 @ 6650.7 SPS. Inference batcher size: 159. Learner queue size: 4. Other stats: (step = 37432320, mean_episode_return = 159.62, mean_episode_step = 755.1, total_loss = 695.09, pg_loss = 521.87, baseline_loss = 179.63, entropy_loss = -6.4119, learner_queue_size = 23, _tick = 10811, _time = 1.654e+09, train_seconds = 5661.7)
[2022-05-31 15:44:48,050][root][INFO] - Step 37465600 @ 6650.8 SPS. Inference batcher size: 51. Learner queue size: 0. Other stats: (step = 37465600, mean_episode_return = None, mean_episode_step = 644.56, total_loss = 325.85, pg_loss = 273.79, baseline_loss = 58.909, entropy_loss = -6.8548, learner_queue_size = 22, _tick = 10822, _time = 1.654e+09, train_seconds = 5666.7)
[2022-05-31 15:44:53,054][root][INFO] - Step 37498880 @ 6650.6 SPS. Inference batcher size: 141. Learner queue size: 25. Other stats: (step = 37498880, mean_episode_return = None, mean_episode_step = 1015.1, total_loss = -39.68, pg_loss = -51.198, baseline_loss = 18.503, entropy_loss = -6.9846, learner_queue_size = 20, _tick = 10833, _time = 1.654e+09, train_seconds = 5671.7)
[2022-05-31 15:44:58,058][root][INFO] - Step 37529600 @ 6139.1 SPS. Inference batcher size: 123. Learner queue size: 31. Other stats: (step = 37529600, mean_episode_return = None, mean_episode_step = 773.12, total_loss = 46.1, pg_loss = 21.661, baseline_loss = 30.962, entropy_loss = -6.5237, learner_queue_size = 22, _tick = 10842, _time = 1.654e+09, train_seconds = 5676.7)
[2022-05-31 15:45:03,064][root][INFO] - Step 37562880 @ 6648.0 SPS. Inference batcher size: 125. Learner queue size: 21. Other stats: (step = 37562880, mean_episode_return = None, mean_episode_step = 809.84, total_loss = -50.012, pg_loss = -64.414, baseline_loss = 21.09, entropy_loss = -6.6874, learner_queue_size = 19, _tick = 10854, _time = 1.654e+09, train_seconds = 5681.7)
[2022-05-31 15:45:08,070][root][INFO] - Step 37596160 @ 6648.0 SPS. Inference batcher size: 164. Learner queue size: 16. Other stats: (step = 37596160, mean_episode_return = 12.37, mean_episode_step = 675.11, total_loss = 262.41, pg_loss = 203.5, baseline_loss = 65.279, entropy_loss = -6.3675, learner_queue_size = 14, _tick = 10866, _time = 1.654e+09, train_seconds = 5686.8)
[2022-05-31 15:45:13,074][root][INFO] - Step 37629440 @ 6650.5 SPS. Inference batcher size: 37. Learner queue size: 9. Other stats: (step = 37629440, mean_episode_return = None, mean_episode_step = 783.81, total_loss = 77.59, pg_loss = 54.052, baseline_loss = 30.409, entropy_loss = -6.8704, learner_queue_size = 24, _tick = 10876, _time = 1.654e+09, train_seconds = 5691.8)
[2022-05-31 15:45:18,081][root][INFO] - Step 37662720 @ 6646.3 SPS. Inference batcher size: 200. Learner queue size: 2. Other stats: (step = 37662720, mean_episode_return = 93.417, mean_episode_step = 765.49, total_loss = 379.89, pg_loss = 189.89, baseline_loss = 196.59, entropy_loss = -6.5937, learner_queue_size = 21, _tick = 10888, _time = 1.654e+09, train_seconds = 5696.8)
[2022-05-31 15:45:23,086][root][INFO] - Step 37696000 @ 6650.1 SPS. Inference batcher size: 114. Learner queue size: 2. Other stats: (step = 37696000, mean_episode_return = 246.04, mean_episode_step = 839.4, total_loss = 2.6662, pg_loss = -24.257, baseline_loss = 33.457, entropy_loss = -6.5342, learner_queue_size = 23, _tick = 10900, _time = 1.654e+09, train_seconds = 5701.8)
[2022-05-31 15:45:28,090][root][INFO] - Step 37729280 @ 6650.6 SPS. Inference batcher size: 126. Learner queue size: 23. Other stats: (step = 37729280, mean_episode_return = 62.536, mean_episode_step = 858.68, total_loss = 173.6, pg_loss = 113.98, baseline_loss = 65.771, entropy_loss = -6.1544, learner_queue_size = 16, _tick = 10912, _time = 1.654e+09, train_seconds = 5706.8)
[2022-05-31 15:45:33,094][root][INFO] - Step 37762560 @ 6650.7 SPS. Inference batcher size: 112. Learner queue size: 22. Other stats: (step = 37762560, mean_episode_return = 98.486, mean_episode_step = 933.42, total_loss = 133.71, pg_loss = 95.586, baseline_loss = 44.161, entropy_loss = -6.0341, learner_queue_size = 17, _tick = 10924, _time = 1.654e+09, train_seconds = 5711.8)
[2022-05-31 15:45:38,096][root][INFO] - Step 37793280 @ 6140.9 SPS. Inference batcher size: 140. Learner queue size: 14. Other stats: (step = 37793280, mean_episode_return = 176.38, mean_episode_step = 741.42, total_loss = 19.394, pg_loss = -36.014, baseline_loss = 61.256, entropy_loss = -5.849, learner_queue_size = 18, _tick = 10934, _time = 1.654e+09, train_seconds = 5716.8)
[2022-05-31 15:45:43,103][root][INFO] - Step 37826560 @ 6647.8 SPS. Inference batcher size: 107. Learner queue size: 22. Other stats: (step = 37826560, mean_episode_return = 126.67, mean_episode_step = 589.54, total_loss = -292.64, pg_loss = -312.49, baseline_loss = 26.127, entropy_loss = -6.2819, learner_queue_size = 15, _tick = 10945, _time = 1.654e+09, train_seconds = 5721.8)
[2022-05-31 15:45:48,109][root][INFO] - Step 37859840 @ 6648.0 SPS. Inference batcher size: 153. Learner queue size: 24. Other stats: (step = 37859840, mean_episode_return = 186.01, mean_episode_step = 760.61, total_loss = 219.09, pg_loss = 155.18, baseline_loss = 70.266, entropy_loss = -6.3522, learner_queue_size = 24, _tick = 10957, _time = 1.654e+09, train_seconds = 5726.8)
[2022-05-31 15:45:53,114][root][INFO] - Step 37893120 @ 6648.9 SPS. Inference batcher size: 174. Learner queue size: 15. Other stats: (step = 37893120, mean_episode_return = 100.91, mean_episode_step = 699.88, total_loss = 492.17, pg_loss = 287.7, baseline_loss = 210.91, entropy_loss = -6.4448, learner_queue_size = 23, _tick = 10969, _time = 1.654e+09, train_seconds = 5731.8)
[2022-05-31 15:45:58,118][root][INFO] - Step 37926400 @ 6650.6 SPS. Inference batcher size: 111. Learner queue size: 5. Other stats: (step = 37926400, mean_episode_return = 75.764, mean_episode_step = 770.7, total_loss = -70.645, pg_loss = -100.73, baseline_loss = 36.139, entropy_loss = -6.0564, learner_queue_size = 24, _tick = 10981, _time = 1.654e+09, train_seconds = 5736.8)
[2022-05-31 15:46:03,122][root][INFO] - Step 37959680 @ 6650.8 SPS. Inference batcher size: 174. Learner queue size: 10. Other stats: (step = 37959680, mean_episode_return = 110.19, mean_episode_step = 677.4, total_loss = 145.91, pg_loss = 72.732, baseline_loss = 79.441, entropy_loss = -6.2636, learner_queue_size = 19, _tick = 10993, _time = 1.654e+09, train_seconds = 5741.8)
[2022-05-31 15:46:08,128][root][INFO] - Step 37992960 @ 6647.8 SPS. Inference batcher size: 30. Learner queue size: 8. Other stats: (step = 37992960, mean_episode_return = None, mean_episode_step = 924.0, total_loss = -5.3493, pg_loss = -44.189, baseline_loss = 45.306, entropy_loss = -6.4663, learner_queue_size = 13, _tick = 11001, _time = 1.654e+09, train_seconds = 5746.8)
[2022-05-31 15:46:13,134][root][INFO] - Step 38026240 @ 6648.2 SPS. Inference batcher size: 132. Learner queue size: 15. Other stats: (step = 38026240, mean_episode_return = 81.7, mean_episode_step = 1029.2, total_loss = 134.04, pg_loss = 53.725, baseline_loss = 85.819, entropy_loss = -5.503, learner_queue_size = 25, _tick = 11012, _time = 1.654e+09, train_seconds = 5751.8)
[2022-05-31 15:46:18,138][root][INFO] - Step 38059520 @ 6650.7 SPS. Inference batcher size: 127. Learner queue size: 5. Other stats: (step = 38059520, mean_episode_return = 89.615, mean_episode_step = 735.48, total_loss = -13.775, pg_loss = -61.678, baseline_loss = 54.433, entropy_loss = -6.5303, learner_queue_size = 17, _tick = 11024, _time = 1.654e+09, train_seconds = 5756.8)
[2022-05-31 15:46:23,142][root][INFO] - Step 38092800 @ 6650.8 SPS. Inference batcher size: 82. Learner queue size: 2. Other stats: (step = 38092800, mean_episode_return = 69.503, mean_episode_step = 926.66, total_loss = 109.99, pg_loss = 75.326, baseline_loss = 41.277, entropy_loss = -6.6167, learner_queue_size = 22, _tick = 11037, _time = 1.654e+09, train_seconds = 5761.8)
[2022-05-31 15:46:28,146][root][INFO] - Step 38126080 @ 6650.7 SPS. Inference batcher size: 108. Learner queue size: 24. Other stats: (step = 38126080, mean_episode_return = 149.72, mean_episode_step = 687.0, total_loss = 22.936, pg_loss = -8.6073, baseline_loss = 38.169, entropy_loss = -6.6255, learner_queue_size = 20, _tick = 11046, _time = 1.654e+09, train_seconds = 5766.8)
[2022-05-31 15:46:33,152][root][INFO] - Step 38156800 @ 6136.6 SPS. Inference batcher size: 170. Learner queue size: 21. Other stats: (step = 38156800, mean_episode_return = 132.48, mean_episode_step = 772.34, total_loss = -191.38, pg_loss = -222.24, baseline_loss = 36.957, entropy_loss = -6.097, learner_queue_size = 23, _tick = 11054, _time = 1.654e+09, train_seconds = 5771.8)
[2022-05-31 15:46:38,154][root][INFO] - Step 38190080 @ 6653.3 SPS. Inference batcher size: 114. Learner queue size: 18. Other stats: (step = 38190080, mean_episode_return = None, mean_episode_step = 1148.7, total_loss = 607.72, pg_loss = 445.67, baseline_loss = 168.52, entropy_loss = -6.4727, learner_queue_size = 19, _tick = 11064, _time = 1.654e+09, train_seconds = 5776.8)
[2022-05-31 15:46:43,160][root][INFO] - Step 38223360 @ 6647.4 SPS. Inference batcher size: 116. Learner queue size: 19. Other stats: (step = 38223360, mean_episode_return = 184.18, mean_episode_step = 659.54, total_loss = -95.548, pg_loss = -116.64, baseline_loss = 27.787, entropy_loss = -6.6989, learner_queue_size = 14, _tick = 11074, _time = 1.654e+09, train_seconds = 5781.8)
[2022-05-31 15:46:48,166][root][INFO] - Step 38256640 @ 6648.6 SPS. Inference batcher size: 121. Learner queue size: 15. Other stats: (step = 38256640, mean_episode_return = None, mean_episode_step = 915.62, total_loss = 39.038, pg_loss = 6.1375, baseline_loss = 39.847, entropy_loss = -6.9466, learner_queue_size = 23, _tick = 11084, _time = 1.654e+09, train_seconds = 5786.9)
[2022-05-31 15:46:53,172][root][INFO] - Step 38289920 @ 6647.8 SPS. Inference batcher size: 79. Learner queue size: 6. Other stats: (step = 38289920, mean_episode_return = 69.93, mean_episode_step = 997.52, total_loss = 27.056, pg_loss = -18.668, baseline_loss = 52.074, entropy_loss = -6.3509, learner_queue_size = 20, _tick = 11095, _time = 1.654e+09, train_seconds = 5791.9)
[2022-05-31 15:46:58,178][root][INFO] - Step 38323200 @ 6648.3 SPS. Inference batcher size: 71. Learner queue size: 31. Other stats: (step = 38323200, mean_episode_return = 65.68, mean_episode_step = 947.76, total_loss = 3.146, pg_loss = -18.846, baseline_loss = 27.701, entropy_loss = -5.7087, learner_queue_size = 16, _tick = 11107, _time = 1.654e+09, train_seconds = 5796.9)
[2022-05-31 15:47:03,184][root][INFO] - Step 38356480 @ 6648.3 SPS. Inference batcher size: 132. Learner queue size: 6. Other stats: (step = 38356480, mean_episode_return = 202.78, mean_episode_step = 896.1, total_loss = 48.655, pg_loss = -16.188, baseline_loss = 71.492, entropy_loss = -6.649, learner_queue_size = 16, _tick = 11115, _time = 1.654e+09, train_seconds = 5801.9)
[2022-05-31 15:47:08,186][root][INFO] - Step 38389760 @ 6653.1 SPS. Inference batcher size: 121. Learner queue size: 0. Other stats: (step = 38389760, mean_episode_return = 150.81, mean_episode_step = 780.11, total_loss = -28.819, pg_loss = -49.932, baseline_loss = 27.394, entropy_loss = -6.2807, learner_queue_size = 28, _tick = 11127, _time = 1.654e+09, train_seconds = 5806.9)
[2022-05-31 15:47:13,190][root][INFO] - Step 38423040 @ 6650.7 SPS. Inference batcher size: 169. Learner queue size: 1. Other stats: (step = 38423040, mean_episode_return = 73.811, mean_episode_step = 800.82, total_loss = -141.11, pg_loss = -148.84, baseline_loss = 14.092, entropy_loss = -6.3636, learner_queue_size = 22, _tick = 11136, _time = 1.654e+09, train_seconds = 5811.9)
[2022-05-31 15:47:18,194][root][INFO] - Step 38453760 @ 6139.1 SPS. Inference batcher size: 135. Learner queue size: 15. Other stats: (step = 38453760, mean_episode_return = 48.929, mean_episode_step = 787.69, total_loss = -281.81, pg_loss = -302.78, baseline_loss = 27.521, entropy_loss = -6.5512, learner_queue_size = 15, _tick = 11147, _time = 1.654e+09, train_seconds = 5816.9)
[2022-05-31 15:47:23,200][root][INFO] - Step 38487040 @ 6648.0 SPS. Inference batcher size: 123. Learner queue size: 23. Other stats: (step = 38487040, mean_episode_return = None, mean_episode_step = 1072.5, total_loss = -24.456, pg_loss = -35.913, baseline_loss = 18.465, entropy_loss = -7.0085, learner_queue_size = 9, _tick = 11154, _time = 1.654e+09, train_seconds = 5821.9)
[2022-05-31 15:47:28,206][root][INFO] - Step 38520320 @ 6648.0 SPS. Inference batcher size: 65. Learner queue size: 19. Other stats: (step = 38520320, mean_episode_return = None, mean_episode_step = 919.94, total_loss = 232.92, pg_loss = 190.95, baseline_loss = 48.687, entropy_loss = -6.7141, learner_queue_size = 32, _tick = 11163, _time = 1.654e+09, train_seconds = 5826.9)
[2022-05-31 15:47:33,210][root][INFO] - Step 38553600 @ 6651.2 SPS. Inference batcher size: 140. Learner queue size: 13. Other stats: (step = 38553600, mean_episode_return = 195.92, mean_episode_step = 867.04, total_loss = 92.55, pg_loss = 66.004, baseline_loss = 33.029, entropy_loss = -6.4827, learner_queue_size = 10, _tick = 11175, _time = 1.654e+09, train_seconds = 5831.9)
[2022-05-31 15:47:38,214][root][INFO] - Step 38586880 @ 6650.2 SPS. Inference batcher size: 61. Learner queue size: 17. Other stats: (step = 38586880, mean_episode_return = 282.59, mean_episode_step = 1034.6, total_loss = -7.1234, pg_loss = -31.671, baseline_loss = 31.446, entropy_loss = -6.8978, learner_queue_size = 12, _tick = 11186, _time = 1.654e+09, train_seconds = 5836.9)
[2022-05-31 15:47:43,220][root][INFO] - Step 38620160 @ 6648.1 SPS. Inference batcher size: 112. Learner queue size: 22. Other stats: (step = 38620160, mean_episode_return = 79.42, mean_episode_step = 1361.0, total_loss = 9.7831, pg_loss = -1.3702, baseline_loss = 17.94, entropy_loss = -6.7866, learner_queue_size = 11, _tick = 11195, _time = 1.654e+09, train_seconds = 5841.9)
[2022-05-31 15:47:48,222][root][INFO] - Step 38653440 @ 6653.3 SPS. Inference batcher size: 143. Learner queue size: 20. Other stats: (step = 38653440, mean_episode_return = 31.497, mean_episode_step = 722.43, total_loss = 169.05, pg_loss = 118.8, baseline_loss = 56.085, entropy_loss = -5.8353, learner_queue_size = 18, _tick = 11207, _time = 1.654e+09, train_seconds = 5846.9)
[2022-05-31 15:47:53,226][root][INFO] - Step 38686720 @ 6650.7 SPS. Inference batcher size: 146. Learner queue size: 9. Other stats: (step = 38686720, mean_episode_return = 38.33, mean_episode_step = 920.85, total_loss = -260.68, pg_loss = -302.9, baseline_loss = 49.103, entropy_loss = -6.8818, learner_queue_size = 15, _tick = 11219, _time = 1.654e+09, train_seconds = 5851.9)
[2022-05-31 15:47:58,230][root][INFO] - Step 38720000 @ 6650.6 SPS. Inference batcher size: 125. Learner queue size: 3. Other stats: (step = 38720000, mean_episode_return = 256.7, mean_episode_step = 1029.0, total_loss = 43.058, pg_loss = -7.2346, baseline_loss = 57.51, entropy_loss = -7.2171, learner_queue_size = 16, _tick = 11232, _time = 1.654e+09, train_seconds = 5856.9)
[2022-05-31 15:48:03,234][root][INFO] - Step 38753280 @ 6650.9 SPS. Inference batcher size: 84. Learner queue size: 4. Other stats: (step = 38753280, mean_episode_return = 112.73, mean_episode_step = 789.38, total_loss = 162.72, pg_loss = 96.707, baseline_loss = 72.302, entropy_loss = -6.292, learner_queue_size = 31, _tick = 11245, _time = 1.654e+09, train_seconds = 5861.9)
[2022-05-31 15:48:08,238][root][INFO] - Step 38786560 @ 6650.6 SPS. Inference batcher size: 33. Learner queue size: 6. Other stats: (step = 38786560, mean_episode_return = None, mean_episode_step = 730.75, total_loss = 158.65, pg_loss = 100.82, baseline_loss = 64.395, entropy_loss = -6.5712, learner_queue_size = 24, _tick = 11254, _time = 1.654e+09, train_seconds = 5866.9)
[2022-05-31 15:48:13,242][root][INFO] - Step 38819840 @ 6650.6 SPS. Inference batcher size: 72. Learner queue size: 12. Other stats: (step = 38819840, mean_episode_return = 99.27, mean_episode_step = 700.23, total_loss = -72.126, pg_loss = -106.72, baseline_loss = 40.887, entropy_loss = -6.2884, learner_queue_size = 12, _tick = 11263, _time = 1.654e+09, train_seconds = 5871.9)
[2022-05-31 15:48:18,246][root][INFO] - Step 38850560 @ 6139.1 SPS. Inference batcher size: 96. Learner queue size: 10. Other stats: (step = 38850560, mean_episode_return = 124.69, mean_episode_step = 965.23, total_loss = 28.617, pg_loss = -65.73, baseline_loss = 100.64, entropy_loss = -6.2937, learner_queue_size = 16, _tick = 11272, _time = 1.654e+09, train_seconds = 5876.9)
[2022-05-31 15:48:23,250][root][INFO] - Step 38883840 @ 6650.8 SPS. Inference batcher size: 27. Learner queue size: 10. Other stats: (step = 38883840, mean_episode_return = None, mean_episode_step = 625.88, total_loss = 28.88, pg_loss = 6.0065, baseline_loss = 28.175, entropy_loss = -5.3011, learner_queue_size = 16, _tick = 11284, _time = 1.654e+09, train_seconds = 5881.9)
[2022-05-31 15:48:28,254][root][INFO] - Step 38917120 @ 6650.7 SPS. Inference batcher size: 132. Learner queue size: 11. Other stats: (step = 38917120, mean_episode_return = 85.685, mean_episode_step = 786.47, total_loss = 177.01, pg_loss = 119.52, baseline_loss = 64.043, entropy_loss = -6.5568, learner_queue_size = 21, _tick = 11297, _time = 1.654e+09, train_seconds = 5886.9)
[2022-05-31 15:48:33,258][root][INFO] - Step 38950400 @ 6650.5 SPS. Inference batcher size: 102. Learner queue size: 1. Other stats: (step = 38950400, mean_episode_return = 59.62, mean_episode_step = 695.36, total_loss = 172.38, pg_loss = 100.52, baseline_loss = 78.18, entropy_loss = -6.3227, learner_queue_size = 15, _tick = 11308, _time = 1.654e+09, train_seconds = 5891.9)
[2022-05-31 15:48:38,264][root][INFO] - Step 38983680 @ 6647.9 SPS. Inference batcher size: 41. Learner queue size: 20. Other stats: (step = 38983680, mean_episode_return = 85.147, mean_episode_step = 792.85, total_loss = -81.117, pg_loss = -107.2, baseline_loss = 32.512, entropy_loss = -6.4261, learner_queue_size = 9, _tick = 11319, _time = 1.654e+09, train_seconds = 5896.9)
[2022-05-31 15:48:43,270][root][INFO] - Step 39016960 @ 6648.3 SPS. Inference batcher size: 95. Learner queue size: 27. Other stats: (step = 39016960, mean_episode_return = None, mean_episode_step = 985.28, total_loss = 121.71, pg_loss = 73.601, baseline_loss = 55.068, entropy_loss = -6.957, learner_queue_size = 19, _tick = 11331, _time = 1.654e+09, train_seconds = 5902.0)
[2022-05-31 15:48:48,276][root][INFO] - Step 39047680 @ 6136.4 SPS. Inference batcher size: 90. Learner queue size: 17. Other stats: (step = 39047680, mean_episode_return = 140.13, mean_episode_step = 758.39, total_loss = 25.973, pg_loss = -23.118, baseline_loss = 55.816, entropy_loss = -6.7251, learner_queue_size = 22, _tick = 11342, _time = 1.654e+09, train_seconds = 5907.0)
[2022-05-31 15:48:53,282][root][INFO] - Step 39080960 @ 6648.0 SPS. Inference batcher size: 119. Learner queue size: 13. Other stats: (step = 39080960, mean_episode_return = None, mean_episode_step = 873.75, total_loss = 70.27, pg_loss = 39.757, baseline_loss = 36.003, entropy_loss = -5.4897, learner_queue_size = 16, _tick = 11353, _time = 1.654e+09, train_seconds = 5912.0)
[2022-05-31 15:48:58,288][root][INFO] - Step 39114240 @ 6648.0 SPS. Inference batcher size: 111. Learner queue size: 5. Other stats: (step = 39114240, mean_episode_return = 270.99, mean_episode_step = 768.61, total_loss = 89.156, pg_loss = 27.455, baseline_loss = 68.15, entropy_loss = -6.449, learner_queue_size = 19, _tick = 11364, _time = 1.654e+09, train_seconds = 5917.0)
[2022-05-31 15:49:03,294][root][INFO] - Step 39147520 @ 6648.3 SPS. Inference batcher size: 80. Learner queue size: 30. Other stats: (step = 39147520, mean_episode_return = None, mean_episode_step = 773.25, total_loss = 177.67, pg_loss = 108.09, baseline_loss = 75.928, entropy_loss = -6.3536, learner_queue_size = 19, _tick = 11376, _time = 1.654e+09, train_seconds = 5922.0)
[2022-05-31 15:49:08,298][root][INFO] - Step 39180800 @ 6650.5 SPS. Inference batcher size: 151. Learner queue size: 0. Other stats: (step = 39180800, mean_episode_return = 154.7, mean_episode_step = 814.71, total_loss = 35.567, pg_loss = -26.81, baseline_loss = 68.694, entropy_loss = -6.3171, learner_queue_size = 20, _tick = 11387, _time = 1.654e+09, train_seconds = 5927.0)
[2022-05-31 15:49:13,304][root][INFO] - Step 39211520 @ 6136.5 SPS. Inference batcher size: 179. Learner queue size: 25. Other stats: (step = 39211520, mean_episode_return = 41.506, mean_episode_step = 961.48, total_loss = -22.953, pg_loss = -56.45, baseline_loss = 39.951, entropy_loss = -6.4527, learner_queue_size = 17, _tick = 11394, _time = 1.654e+09, train_seconds = 5932.0)
[2022-05-31 15:49:18,310][root][INFO] - Step 39244800 @ 6648.0 SPS. Inference batcher size: 111. Learner queue size: 15. Other stats: (step = 39244800, mean_episode_return = 133.04, mean_episode_step = 904.09, total_loss = -19.202, pg_loss = -39.344, baseline_loss = 26.541, entropy_loss = -6.3993, learner_queue_size = 18, _tick = 11405, _time = 1.654e+09, train_seconds = 5937.0)
[2022-05-31 15:49:23,314][root][INFO] - Step 39278080 @ 6650.9 SPS. Inference batcher size: 186. Learner queue size: 5. Other stats: (step = 39278080, mean_episode_return = 292.03, mean_episode_step = 790.5, total_loss = 78.989, pg_loss = 18.659, baseline_loss = 66.615, entropy_loss = -6.2838, learner_queue_size = 21, _tick = 11418, _time = 1.654e+09, train_seconds = 5942.0)
[2022-05-31 15:49:28,318][root][INFO] - Step 39311360 @ 6650.8 SPS. Inference batcher size: 211. Learner queue size: 6. Other stats: (step = 39311360, mean_episode_return = 84.261, mean_episode_step = 705.42, total_loss = 126.57, pg_loss = 24.292, baseline_loss = 108.6, entropy_loss = -6.3209, learner_queue_size = 16, _tick = 11430, _time = 1.654e+09, train_seconds = 5947.0)
[2022-05-31 15:49:33,324][root][INFO] - Step 39344640 @ 6647.6 SPS. Inference batcher size: 33. Learner queue size: 5. Other stats: (step = 39344640, mean_episode_return = 140.75, mean_episode_step = 689.74, total_loss = -64.766, pg_loss = -107.35, baseline_loss = 48.757, entropy_loss = -6.1749, learner_queue_size = 24, _tick = 11442, _time = 1.654e+09, train_seconds = 5952.0)
[2022-05-31 15:49:38,330][root][INFO] - Step 39377920 @ 6648.3 SPS. Inference batcher size: 83. Learner queue size: 27. Other stats: (step = 39377920, mean_episode_return = 165.65, mean_episode_step = 1291.2, total_loss = 144.29, pg_loss = 94.644, baseline_loss = 55.736, entropy_loss = -6.0882, learner_queue_size = 11, _tick = 11452, _time = 1.654e+09, train_seconds = 5957.0)
[2022-05-31 15:49:43,334][root][INFO] - Step 39411200 @ 6650.7 SPS. Inference batcher size: 101. Learner queue size: 1. Other stats: (step = 39411200, mean_episode_return = 131.23, mean_episode_step = 772.1, total_loss = -92.355, pg_loss = -135.81, baseline_loss = 49.351, entropy_loss = -5.8994, learner_queue_size = 16, _tick = 11464, _time = 1.654e+09, train_seconds = 5962.0)
[2022-05-31 15:49:48,338][root][INFO] - Step 39444480 @ 6650.7 SPS. Inference batcher size: 118. Learner queue size: 4. Other stats: (step = 39444480, mean_episode_return = 133.5, mean_episode_step = 919.56, total_loss = -298.73, pg_loss = -332.82, baseline_loss = 40.638, entropy_loss = -6.5441, learner_queue_size = 23, _tick = 11473, _time = 1.654e+09, train_seconds = 5967.0)
[2022-05-31 15:49:53,342][root][INFO] - Step 39477760 @ 6650.6 SPS. Inference batcher size: 8. Learner queue size: 25. Other stats: (step = 39477760, mean_episode_return = 68.778, mean_episode_step = 869.22, total_loss = 25.546, pg_loss = 9.9122, baseline_loss = 21.478, entropy_loss = -5.8442, learner_queue_size = 17, _tick = 11485, _time = 1.654e+09, train_seconds = 5972.0)
[2022-05-31 15:49:58,346][root][INFO] - Step 39511040 @ 6650.7 SPS. Inference batcher size: 93. Learner queue size: 28. Other stats: (step = 39511040, mean_episode_return = 99.565, mean_episode_step = 729.92, total_loss = -261.71, pg_loss = -297.02, baseline_loss = 41.751, entropy_loss = -6.4445, learner_queue_size = 12, _tick = 11497, _time = 1.654e+09, train_seconds = 5977.0)
[2022-05-31 15:50:03,352][root][INFO] - Step 39541760 @ 6136.4 SPS. Inference batcher size: 119. Learner queue size: 21. Other stats: (step = 39541760, mean_episode_return = 45.405, mean_episode_step = 1374.6, total_loss = 40.57, pg_loss = -7.5567, baseline_loss = 54.118, entropy_loss = -5.9914, learner_queue_size = 19, _tick = 11505, _time = 1.654e+09, train_seconds = 5982.0)
[2022-05-31 15:50:08,358][root][INFO] - Step 39575040 @ 6648.3 SPS. Inference batcher size: 105. Learner queue size: 18. Other stats: (step = 39575040, mean_episode_return = 205.38, mean_episode_step = 756.42, total_loss = 185.82, pg_loss = 123.76, baseline_loss = 68.439, entropy_loss = -6.379, learner_queue_size = 16, _tick = 11517, _time = 1.654e+09, train_seconds = 5987.0)
[2022-05-31 15:50:13,364][root][INFO] - Step 39608320 @ 6647.9 SPS. Inference batcher size: 176. Learner queue size: 22. Other stats: (step = 39608320, mean_episode_return = None, mean_episode_step = 972.12, total_loss = 281.14, pg_loss = 206.52, baseline_loss = 81.417, entropy_loss = -6.7951, learner_queue_size = 17, _tick = 11527, _time = 1.654e+09, train_seconds = 5992.0)
[2022-05-31 15:50:18,370][root][INFO] - Step 39641600 @ 6648.2 SPS. Inference batcher size: 78. Learner queue size: 19. Other stats: (step = 39641600, mean_episode_return = 54.351, mean_episode_step = 918.5, total_loss = 4.1892, pg_loss = -15.561, baseline_loss = 25.682, entropy_loss = -5.9317, learner_queue_size = 23, _tick = 11537, _time = 1.654e+09, train_seconds = 5997.1)
[2022-05-31 15:50:23,374][root][INFO] - Step 39674880 @ 6650.6 SPS. Inference batcher size: 82. Learner queue size: 17. Other stats: (step = 39674880, mean_episode_return = 151.58, mean_episode_step = 970.78, total_loss = -21.604, pg_loss = -88.93, baseline_loss = 73.046, entropy_loss = -5.721, learner_queue_size = 14, _tick = 11547, _time = 1.654e+09, train_seconds = 6002.1)
[2022-05-31 15:50:28,379][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 15:50:28,493][root][INFO] - Step 39708160 @ 6650.1 SPS. Inference batcher size: 66. Learner queue size: 24. Other stats: (step = 39708160, mean_episode_return = 95.217, mean_episode_step = 887.14, total_loss = -369.84, pg_loss = -410.72, baseline_loss = 47.253, entropy_loss = -6.3676, learner_queue_size = 19, _tick = 11558, _time = 1.654e+09, train_seconds = 6007.1)
[2022-05-31 15:50:33,498][root][INFO] - Step 39741440 @ 6500.5 SPS. Inference batcher size: 137. Learner queue size: 12. Other stats: (step = 39741440, mean_episode_return = 236.82, mean_episode_step = 883.88, total_loss = 78.156, pg_loss = 22.963, baseline_loss = 61.154, entropy_loss = -5.9611, learner_queue_size = 13, _tick = 11571, _time = 1.654e+09, train_seconds = 6012.2)
[2022-05-31 15:50:38,502][root][INFO] - Step 39774720 @ 6650.5 SPS. Inference batcher size: 105. Learner queue size: 9. Other stats: (step = 39774720, mean_episode_return = 75.738, mean_episode_step = 706.91, total_loss = 163.89, pg_loss = 117.72, baseline_loss = 52.17, entropy_loss = -5.9997, learner_queue_size = 25, _tick = 11581, _time = 1.654e+09, train_seconds = 6017.2)
[2022-05-31 15:50:43,506][root][INFO] - Step 39808000 @ 6650.2 SPS. Inference batcher size: 160. Learner queue size: 9. Other stats: (step = 39808000, mean_episode_return = 70.786, mean_episode_step = 1027.3, total_loss = -208.53, pg_loss = -235.63, baseline_loss = 33.475, entropy_loss = -6.3802, learner_queue_size = 12, _tick = 11593, _time = 1.654e+09, train_seconds = 6022.2)
[2022-05-31 15:50:48,510][root][INFO] - Step 39841280 @ 6651.4 SPS. Inference batcher size: 136. Learner queue size: 7. Other stats: (step = 39841280, mean_episode_return = 160.55, mean_episode_step = 931.37, total_loss = -20.924, pg_loss = -82.674, baseline_loss = 67.852, entropy_loss = -6.1015, learner_queue_size = 19, _tick = 11605, _time = 1.654e+09, train_seconds = 6027.2)
[2022-05-31 15:50:53,514][root][INFO] - Step 39874560 @ 6650.7 SPS. Inference batcher size: 61. Learner queue size: 2. Other stats: (step = 39874560, mean_episode_return = 99.48, mean_episode_step = 727.73, total_loss = -299.09, pg_loss = -326.66, baseline_loss = 33.955, entropy_loss = -6.3914, learner_queue_size = 23, _tick = 11616, _time = 1.654e+09, train_seconds = 6032.2)
[2022-05-31 15:50:58,518][root][INFO] - Step 39907840 @ 6650.7 SPS. Inference batcher size: 94. Learner queue size: 27. Other stats: (step = 39907840, mean_episode_return = 45.301, mean_episode_step = 1025.0, total_loss = -42.053, pg_loss = -50.066, baseline_loss = 14.132, entropy_loss = -6.1193, learner_queue_size = 11, _tick = 11626, _time = 1.654e+09, train_seconds = 6037.2)
[2022-05-31 15:51:03,524][root][INFO] - Step 39938560 @ 6136.1 SPS. Inference batcher size: 119. Learner queue size: 26. Other stats: (step = 39938560, mean_episode_return = 37.195, mean_episode_step = 790.57, total_loss = -196.04, pg_loss = -279.2, baseline_loss = 89.321, entropy_loss = -6.1611, learner_queue_size = 15, _tick = 11637, _time = 1.654e+09, train_seconds = 6042.2)
[2022-05-31 15:51:08,530][root][INFO] - Step 39971840 @ 6647.9 SPS. Inference batcher size: 71. Learner queue size: 23. Other stats: (step = 39971840, mean_episode_return = 78.882, mean_episode_step = 937.54, total_loss = 43.942, pg_loss = 17.481, baseline_loss = 32.752, entropy_loss = -6.2904, learner_queue_size = 21, _tick = 11647, _time = 1.654e+09, train_seconds = 6047.2)
[2022-05-31 15:51:13,534][root][INFO] - Step 40007680 @ 7162.9 SPS. Inference batcher size: 103. Learner queue size: 0. Other stats: (step = 40007680, mean_episode_return = 147.62, mean_episode_step = 1378.0, total_loss = 111.85, pg_loss = 52.205, baseline_loss = 65.878, entropy_loss = -6.2282, learner_queue_size = 17, _tick = 11658, _time = 1.654e+09, train_seconds = 6052.2)
[2022-05-31 15:51:18,540][root][INFO] - Step 40040960 @ 6647.6 SPS. Inference batcher size: 16. Learner queue size: 21. Other stats: (step = 40040960, mean_episode_return = 166.32, mean_episode_step = 808.92, total_loss = -23.64, pg_loss = -98.158, baseline_loss = 80.385, entropy_loss = -5.8671, learner_queue_size = 20, _tick = 11666, _time = 1.654e+09, train_seconds = 6057.2)
[2022-05-31 15:51:23,546][root][INFO] - Step 40074240 @ 6648.5 SPS. Inference batcher size: 92. Learner queue size: 10. Other stats: (step = 40074240, mean_episode_return = 174.61, mean_episode_step = 912.04, total_loss = -168.84, pg_loss = -188.34, baseline_loss = 25.687, entropy_loss = -6.1918, learner_queue_size = 8, _tick = 11677, _time = 1.654e+09, train_seconds = 6062.2)
[2022-05-31 15:51:28,550][root][INFO] - Step 40107520 @ 6650.7 SPS. Inference batcher size: 31. Learner queue size: 19. Other stats: (step = 40107520, mean_episode_return = 94.398, mean_episode_step = 957.34, total_loss = 95.795, pg_loss = 11.786, baseline_loss = 90.393, entropy_loss = -6.3833, learner_queue_size = 18, _tick = 11689, _time = 1.654e+09, train_seconds = 6067.2)
[2022-05-31 15:51:33,557][root][INFO] - Step 40138240 @ 6135.4 SPS. Inference batcher size: 147. Learner queue size: 18. Other stats: (step = 40138240, mean_episode_return = 300.99, mean_episode_step = 917.46, total_loss = 238.39, pg_loss = -43.117, baseline_loss = 287.93, entropy_loss = -6.4243, learner_queue_size = 19, _tick = 11701, _time = 1.654e+09, train_seconds = 6072.2)
[2022-05-31 15:51:38,563][root][INFO] - Step 40171520 @ 6648.0 SPS. Inference batcher size: 153. Learner queue size: 10. Other stats: (step = 40171520, mean_episode_return = 85.099, mean_episode_step = 1480.3, total_loss = 85.41, pg_loss = 48.486, baseline_loss = 42.521, entropy_loss = -5.5976, learner_queue_size = 18, _tick = 11713, _time = 1.654e+09, train_seconds = 6077.2)
[2022-05-31 15:51:43,566][root][INFO] - Step 40204800 @ 6651.9 SPS. Inference batcher size: 78. Learner queue size: 14. Other stats: (step = 40204800, mean_episode_return = 97.145, mean_episode_step = 652.99, total_loss = -130.66, pg_loss = -253.32, baseline_loss = 128.61, entropy_loss = -5.9506, learner_queue_size = 24, _tick = 11724, _time = 1.654e+09, train_seconds = 6082.3)
[2022-05-31 15:51:48,570][root][INFO] - Step 40238080 @ 6650.8 SPS. Inference batcher size: 130. Learner queue size: 5. Other stats: (step = 40238080, mean_episode_return = 80.654, mean_episode_step = 829.12, total_loss = 4.6588, pg_loss = -50.599, baseline_loss = 60.776, entropy_loss = -5.5186, learner_queue_size = 18, _tick = 11734, _time = 1.654e+09, train_seconds = 6087.3)
[2022-05-31 15:51:53,576][root][INFO] - Step 40271360 @ 6647.9 SPS. Inference batcher size: 83. Learner queue size: 3. Other stats: (step = 40271360, mean_episode_return = 274.83, mean_episode_step = 982.22, total_loss = -52.377, pg_loss = -99.108, baseline_loss = 52.754, entropy_loss = -6.0226, learner_queue_size = 20, _tick = 11745, _time = 1.654e+09, train_seconds = 6092.3)
[2022-05-31 15:51:58,582][root][INFO] - Step 40304640 @ 6648.0 SPS. Inference batcher size: 123. Learner queue size: 27. Other stats: (step = 40304640, mean_episode_return = 183.01, mean_episode_step = 798.52, total_loss = -2.1111, pg_loss = -124.74, baseline_loss = 128.81, entropy_loss = -6.1768, learner_queue_size = 18, _tick = 11755, _time = 1.654e+09, train_seconds = 6097.3)
[2022-05-31 15:52:03,586][root][INFO] - Step 40337920 @ 6650.7 SPS. Inference batcher size: 109. Learner queue size: 21. Other stats: (step = 40337920, mean_episode_return = 285.65, mean_episode_step = 935.53, total_loss = -85.426, pg_loss = -129.44, baseline_loss = 50.745, entropy_loss = -6.7306, learner_queue_size = 19, _tick = 11764, _time = 1.654e+09, train_seconds = 6102.3)
[2022-05-31 15:52:08,591][root][INFO] - Step 40368640 @ 6137.8 SPS. Inference batcher size: 59. Learner queue size: 15. Other stats: (step = 40368640, mean_episode_return = None, mean_episode_step = 868.41, total_loss = -55.56, pg_loss = -86.299, baseline_loss = 37.058, entropy_loss = -6.3186, learner_queue_size = 25, _tick = 11775, _time = 1.654e+09, train_seconds = 6107.3)
[2022-05-31 15:52:13,597][root][INFO] - Step 40401920 @ 6647.9 SPS. Inference batcher size: 160. Learner queue size: 17. Other stats: (step = 40401920, mean_episode_return = 616.46, mean_episode_step = 865.63, total_loss = -233.82, pg_loss = -333.81, baseline_loss = 106.18, entropy_loss = -6.1968, learner_queue_size = 19, _tick = 11786, _time = 1.654e+09, train_seconds = 6112.3)
[2022-05-31 15:52:18,604][root][INFO] - Step 40435200 @ 6647.2 SPS. Inference batcher size: 24. Learner queue size: 5. Other stats: (step = 40435200, mean_episode_return = 191.38, mean_episode_step = 709.51, total_loss = 34.57, pg_loss = -32.854, baseline_loss = 73.004, entropy_loss = -5.5808, learner_queue_size = 22, _tick = 11796, _time = 1.654e+09, train_seconds = 6117.3)
[2022-05-31 15:52:23,606][root][INFO] - Step 40468480 @ 6652.7 SPS. Inference batcher size: 128. Learner queue size: 3. Other stats: (step = 40468480, mean_episode_return = 19.21, mean_episode_step = 801.25, total_loss = 116.69, pg_loss = 23.132, baseline_loss = 100.17, entropy_loss = -6.6185, learner_queue_size = 22, _tick = 11807, _time = 1.654e+09, train_seconds = 6122.3)
[2022-05-31 15:52:28,611][root][INFO] - Step 40501760 @ 6650.2 SPS. Inference batcher size: 131. Learner queue size: 0. Other stats: (step = 40501760, mean_episode_return = 98.917, mean_episode_step = 896.88, total_loss = -137.78, pg_loss = -166.15, baseline_loss = 34.638, entropy_loss = -6.2701, learner_queue_size = 24, _tick = 11819, _time = 1.654e+09, train_seconds = 6127.3)
[2022-05-31 15:52:33,614][root][INFO] - Step 40535040 @ 6651.7 SPS. Inference batcher size: 114. Learner queue size: 28. Other stats: (step = 40535040, mean_episode_return = None, mean_episode_step = 968.59, total_loss = 8.2849, pg_loss = -35.269, baseline_loss = 50.552, entropy_loss = -6.9974, learner_queue_size = 13, _tick = 11830, _time = 1.654e+09, train_seconds = 6132.3)
[2022-05-31 15:52:38,618][root][INFO] - Step 40568320 @ 6650.6 SPS. Inference batcher size: 140. Learner queue size: 1. Other stats: (step = 40568320, mean_episode_return = 91.477, mean_episode_step = 985.24, total_loss = 138.82, pg_loss = 108.46, baseline_loss = 37.129, entropy_loss = -6.7739, learner_queue_size = 25, _tick = 11840, _time = 1.654e+09, train_seconds = 6137.3)
[2022-05-31 15:52:43,622][root][INFO] - Step 40601600 @ 6650.6 SPS. Inference batcher size: 90. Learner queue size: 25. Other stats: (step = 40601600, mean_episode_return = 162.35, mean_episode_step = 960.03, total_loss = -40.087, pg_loss = -75.682, baseline_loss = 41.824, entropy_loss = -6.229, learner_queue_size = 16, _tick = 11851, _time = 1.654e+09, train_seconds = 6142.3)
[2022-05-31 15:52:48,626][root][INFO] - Step 40634880 @ 6650.9 SPS. Inference batcher size: 114. Learner queue size: 20. Other stats: (step = 40634880, mean_episode_return = 115.19, mean_episode_step = 944.05, total_loss = 71.919, pg_loss = -71.637, baseline_loss = 149.66, entropy_loss = -6.1038, learner_queue_size = 15, _tick = 11860, _time = 1.654e+09, train_seconds = 6147.3)
[2022-05-31 15:52:53,630][root][INFO] - Step 40668160 @ 6650.7 SPS. Inference batcher size: 122. Learner queue size: 30. Other stats: (step = 40668160, mean_episode_return = 125.31, mean_episode_step = 786.46, total_loss = -29.766, pg_loss = -70.247, baseline_loss = 46.386, entropy_loss = -5.906, learner_queue_size = 12, _tick = 11870, _time = 1.654e+09, train_seconds = 6152.3)
[2022-05-31 15:52:58,634][root][INFO] - Step 40698880 @ 6139.0 SPS. Inference batcher size: 123. Learner queue size: 25. Other stats: (step = 40698880, mean_episode_return = 23.84, mean_episode_step = 1450.1, total_loss = -168.33, pg_loss = -224.83, baseline_loss = 62.952, entropy_loss = -6.4504, learner_queue_size = 24, _tick = 11880, _time = 1.654e+09, train_seconds = 6157.3)
[2022-05-31 15:53:03,640][root][INFO] - Step 40732160 @ 6647.9 SPS. Inference batcher size: 123. Learner queue size: 16. Other stats: (step = 40732160, mean_episode_return = 133.6, mean_episode_step = 747.41, total_loss = 59.485, pg_loss = 21.444, baseline_loss = 44.484, entropy_loss = -6.4436, learner_queue_size = 18, _tick = 11893, _time = 1.654e+09, train_seconds = 6162.3)
[2022-05-31 15:53:08,646][root][INFO] - Step 40765440 @ 6648.0 SPS. Inference batcher size: 138. Learner queue size: 18. Other stats: (step = 40765440, mean_episode_return = None, mean_episode_step = 1060.1, total_loss = -70.536, pg_loss = -87.473, baseline_loss = 23.276, entropy_loss = -6.3398, learner_queue_size = 23, _tick = 11902, _time = 1.654e+09, train_seconds = 6167.3)
[2022-05-31 15:53:13,650][root][INFO] - Step 40798720 @ 6650.8 SPS. Inference batcher size: 128. Learner queue size: 15. Other stats: (step = 40798720, mean_episode_return = 161.48, mean_episode_step = 1360.9, total_loss = -216.61, pg_loss = -263.1, baseline_loss = 52.726, entropy_loss = -6.2304, learner_queue_size = 20, _tick = 11914, _time = 1.654e+09, train_seconds = 6172.3)
[2022-05-31 15:53:18,654][root][INFO] - Step 40832000 @ 6650.7 SPS. Inference batcher size: 100. Learner queue size: 21. Other stats: (step = 40832000, mean_episode_return = 104.98, mean_episode_step = 644.24, total_loss = -42.978, pg_loss = -84.879, baseline_loss = 47.522, entropy_loss = -5.6215, learner_queue_size = 17, _tick = 11926, _time = 1.654e+09, train_seconds = 6177.3)
[2022-05-31 15:53:23,658][root][INFO] - Step 40865280 @ 6651.2 SPS. Inference batcher size: 210. Learner queue size: 17. Other stats: (step = 40865280, mean_episode_return = 115.09, mean_episode_step = 893.51, total_loss = 148.12, pg_loss = -16.048, baseline_loss = 170.22, entropy_loss = -6.0526, learner_queue_size = 24, _tick = 11936, _time = 1.654e+09, train_seconds = 6182.3)
[2022-05-31 15:53:28,662][root][INFO] - Step 40898560 @ 6650.2 SPS. Inference batcher size: 142. Learner queue size: 6. Other stats: (step = 40898560, mean_episode_return = 195.47, mean_episode_step = 847.74, total_loss = -108.28, pg_loss = -155.18, baseline_loss = 53.065, entropy_loss = -6.1576, learner_queue_size = 28, _tick = 11947, _time = 1.654e+09, train_seconds = 6187.3)
[2022-05-31 15:53:33,666][root][INFO] - Step 40931840 @ 6650.6 SPS. Inference batcher size: 15. Learner queue size: 2. Other stats: (step = 40931840, mean_episode_return = None, mean_episode_step = 749.44, total_loss = 93.48, pg_loss = 52.712, baseline_loss = 46.825, entropy_loss = -6.0564, learner_queue_size = 25, _tick = 11958, _time = 1.654e+09, train_seconds = 6192.4)
[2022-05-31 15:53:38,674][root][INFO] - Step 40965120 @ 6645.7 SPS. Inference batcher size: 122. Learner queue size: 3. Other stats: (step = 40965120, mean_episode_return = None, mean_episode_step = 726.66, total_loss = -16.407, pg_loss = -157.37, baseline_loss = 146.92, entropy_loss = -5.9594, learner_queue_size = 25, _tick = 11966, _time = 1.654e+09, train_seconds = 6197.4)
[2022-05-31 15:53:43,678][root][INFO] - Step 40998400 @ 6650.6 SPS. Inference batcher size: 114. Learner queue size: 14. Other stats: (step = 40998400, mean_episode_return = 89.08, mean_episode_step = 690.14, total_loss = 130.68, pg_loss = 36.871, baseline_loss = 100.18, entropy_loss = -6.3732, learner_queue_size = 9, _tick = 11977, _time = 1.654e+09, train_seconds = 6202.4)
[2022-05-31 15:53:48,682][root][INFO] - Step 41031680 @ 6650.6 SPS. Inference batcher size: 88. Learner queue size: 24. Other stats: (step = 41031680, mean_episode_return = 188.43, mean_episode_step = 1056.0, total_loss = -12.398, pg_loss = -61.365, baseline_loss = 54.937, entropy_loss = -5.9698, learner_queue_size = 18, _tick = 11986, _time = 1.654e+09, train_seconds = 6207.4)
[2022-05-31 15:53:53,688][root][INFO] - Step 41062400 @ 6136.4 SPS. Inference batcher size: 36. Learner queue size: 25. Other stats: (step = 41062400, mean_episode_return = 178.31, mean_episode_step = 732.37, total_loss = -123.32, pg_loss = -159.69, baseline_loss = 42.335, entropy_loss = -5.9656, learner_queue_size = 20, _tick = 11998, _time = 1.654e+09, train_seconds = 6212.4)
[2022-05-31 15:53:58,695][root][INFO] - Step 41098240 @ 7158.8 SPS. Inference batcher size: 134. Learner queue size: 20. Other stats: (step = 41098240, mean_episode_return = 17.071, mean_episode_step = 797.83, total_loss = 352.49, pg_loss = 259.82, baseline_loss = 98.882, entropy_loss = -6.2124, learner_queue_size = 16, _tick = 12011, _time = 1.654e+09, train_seconds = 6217.4)
[2022-05-31 15:54:03,701][root][INFO] - Step 41131520 @ 6647.2 SPS. Inference batcher size: 156. Learner queue size: 0. Other stats: (step = 41131520, mean_episode_return = 193.14, mean_episode_step = 883.51, total_loss = 5.2583, pg_loss = -18.582, baseline_loss = 30.101, entropy_loss = -6.2611, learner_queue_size = 22, _tick = 12022, _time = 1.654e+09, train_seconds = 6222.4)
[2022-05-31 15:54:08,707][root][INFO] - Step 41162240 @ 6136.5 SPS. Inference batcher size: 118. Learner queue size: 28. Other stats: (step = 41162240, mean_episode_return = 149.58, mean_episode_step = 817.9, total_loss = -159.88, pg_loss = -194.33, baseline_loss = 40.713, entropy_loss = -6.2536, learner_queue_size = 13, _tick = 12032, _time = 1.654e+09, train_seconds = 6227.4)
[2022-05-31 15:54:13,714][root][INFO] - Step 41195520 @ 6647.8 SPS. Inference batcher size: 93. Learner queue size: 19. Other stats: (step = 41195520, mean_episode_return = 100.59, mean_episode_step = 911.55, total_loss = -41.681, pg_loss = -70.098, baseline_loss = 34.529, entropy_loss = -6.1115, learner_queue_size = 15, _tick = 12044, _time = 1.654e+09, train_seconds = 6232.4)
[2022-05-31 15:54:18,720][root][INFO] - Step 41228800 @ 6647.8 SPS. Inference batcher size: 120. Learner queue size: 27. Other stats: (step = 41228800, mean_episode_return = 97.25, mean_episode_step = 917.81, total_loss = 311.77, pg_loss = 262.4, baseline_loss = 56.02, entropy_loss = -6.6494, learner_queue_size = 19, _tick = 12055, _time = 1.654e+09, train_seconds = 6237.4)
[2022-05-31 15:54:23,722][root][INFO] - Step 41262080 @ 6652.7 SPS. Inference batcher size: 62. Learner queue size: 18. Other stats: (step = 41262080, mean_episode_return = 92.279, mean_episode_step = 850.56, total_loss = 60.322, pg_loss = 35.871, baseline_loss = 30.974, entropy_loss = -6.5229, learner_queue_size = 12, _tick = 12066, _time = 1.654e+09, train_seconds = 6242.4)
[2022-05-31 15:54:28,729][root][INFO] - Step 41295360 @ 6647.1 SPS. Inference batcher size: 100. Learner queue size: 10. Other stats: (step = 41295360, mean_episode_return = 67.525, mean_episode_step = 877.71, total_loss = -27.944, pg_loss = -86.502, baseline_loss = 64.998, entropy_loss = -6.4401, learner_queue_size = 18, _tick = 12077, _time = 1.654e+09, train_seconds = 6247.4)
[2022-05-31 15:54:33,734][root][INFO] - Step 41328640 @ 6649.2 SPS. Inference batcher size: 119. Learner queue size: 25. Other stats: (step = 41328640, mean_episode_return = 72.881, mean_episode_step = 897.99, total_loss = -51.253, pg_loss = -77.904, baseline_loss = 32.872, entropy_loss = -6.2217, learner_queue_size = 21, _tick = 12090, _time = 1.654e+09, train_seconds = 6252.4)
[2022-05-31 15:54:38,738][root][INFO] - Step 41361920 @ 6650.6 SPS. Inference batcher size: 124. Learner queue size: 31. Other stats: (step = 41361920, mean_episode_return = 34.78, mean_episode_step = 814.49, total_loss = 224.55, pg_loss = 150.89, baseline_loss = 80.121, entropy_loss = -6.4583, learner_queue_size = 24, _tick = 12103, _time = 1.654e+09, train_seconds = 6257.4)
[2022-05-31 15:54:43,742][root][INFO] - Step 41395200 @ 6650.7 SPS. Inference batcher size: 109. Learner queue size: 25. Other stats: (step = 41395200, mean_episode_return = 59.903, mean_episode_step = 681.74, total_loss = 118.84, pg_loss = -9.1854, baseline_loss = 134.03, entropy_loss = -6.0082, learner_queue_size = 14, _tick = 12113, _time = 1.654e+09, train_seconds = 6262.4)
[2022-05-31 15:54:48,749][root][INFO] - Step 41425920 @ 6135.4 SPS. Inference batcher size: 158. Learner queue size: 12. Other stats: (step = 41425920, mean_episode_return = None, mean_episode_step = 936.88, total_loss = -76.4, pg_loss = -91.619, baseline_loss = 21.504, entropy_loss = -6.2858, learner_queue_size = 18, _tick = 12121, _time = 1.654e+09, train_seconds = 6267.4)
[2022-05-31 15:54:53,755][root][INFO] - Step 41459200 @ 6648.0 SPS. Inference batcher size: 117. Learner queue size: 13. Other stats: (step = 41459200, mean_episode_return = 192.19, mean_episode_step = 719.8, total_loss = 255.3, pg_loss = 144.8, baseline_loss = 116.86, entropy_loss = -6.367, learner_queue_size = 25, _tick = 12132, _time = 1.654e+09, train_seconds = 6272.4)
[2022-05-31 15:54:58,758][root][INFO] - Step 41492480 @ 6652.1 SPS. Inference batcher size: 107. Learner queue size: 14. Other stats: (step = 41492480, mean_episode_return = 145.17, mean_episode_step = 745.95, total_loss = -164.97, pg_loss = -202.67, baseline_loss = 44.243, entropy_loss = -6.5385, learner_queue_size = 16, _tick = 12144, _time = 1.654e+09, train_seconds = 6277.4)
[2022-05-31 15:55:03,762][root][INFO] - Step 41525760 @ 6650.6 SPS. Inference batcher size: 84. Learner queue size: 30. Other stats: (step = 41525760, mean_episode_return = 162.44, mean_episode_step = 902.28, total_loss = 257.47, pg_loss = 197.91, baseline_loss = 66.516, entropy_loss = -6.9546, learner_queue_size = 21, _tick = 12155, _time = 1.654e+09, train_seconds = 6282.4)
[2022-05-31 15:55:08,768][root][INFO] - Step 41559040 @ 6648.3 SPS. Inference batcher size: 81. Learner queue size: 5. Other stats: (step = 41559040, mean_episode_return = 66.537, mean_episode_step = 949.48, total_loss = 886.07, pg_loss = 586.7, baseline_loss = 305.88, entropy_loss = -6.5127, learner_queue_size = 18, _tick = 12164, _time = 1.654e+09, train_seconds = 6287.5)
[2022-05-31 15:55:13,770][root][INFO] - Step 41592320 @ 6653.1 SPS. Inference batcher size: 152. Learner queue size: 30. Other stats: (step = 41592320, mean_episode_return = None, mean_episode_step = 933.38, total_loss = 70.187, pg_loss = 27.188, baseline_loss = 49.466, entropy_loss = -6.468, learner_queue_size = 17, _tick = 12174, _time = 1.654e+09, train_seconds = 6292.5)
[2022-05-31 15:55:18,776][root][INFO] - Step 41625600 @ 6647.9 SPS. Inference batcher size: 159. Learner queue size: 3. Other stats: (step = 41625600, mean_episode_return = 232.79, mean_episode_step = 791.6, total_loss = 544.29, pg_loss = 285.31, baseline_loss = 265.29, entropy_loss = -6.3024, learner_queue_size = 23, _tick = 12183, _time = 1.654e+09, train_seconds = 6297.5)
[2022-05-31 15:55:23,782][root][INFO] - Step 41658880 @ 6648.0 SPS. Inference batcher size: 118. Learner queue size: 2. Other stats: (step = 41658880, mean_episode_return = None, mean_episode_step = 1025.9, total_loss = 105.64, pg_loss = 4.0413, baseline_loss = 107.97, entropy_loss = -6.3625, learner_queue_size = 28, _tick = 12194, _time = 1.654e+09, train_seconds = 6302.5)
[2022-05-31 15:55:28,786][root][INFO] - Step 41692160 @ 6650.8 SPS. Inference batcher size: 107. Learner queue size: 1. Other stats: (step = 41692160, mean_episode_return = 103.31, mean_episode_step = 716.68, total_loss = 118.48, pg_loss = 60.571, baseline_loss = 64.414, entropy_loss = -6.5062, learner_queue_size = 16, _tick = 12205, _time = 1.654e+09, train_seconds = 6307.5)
[2022-05-31 15:55:33,790][root][INFO] - Step 41725440 @ 6650.6 SPS. Inference batcher size: 115. Learner queue size: 3. Other stats: (step = 41725440, mean_episode_return = 102.09, mean_episode_step = 585.95, total_loss = 185.95, pg_loss = 32.152, baseline_loss = 160.06, entropy_loss = -6.2563, learner_queue_size = 15, _tick = 12217, _time = 1.654e+09, train_seconds = 6312.5)
[2022-05-31 15:55:38,794][root][INFO] - Step 41758720 @ 6650.6 SPS. Inference batcher size: 60. Learner queue size: 2. Other stats: (step = 41758720, mean_episode_return = 169.94, mean_episode_step = 969.68, total_loss = 232.89, pg_loss = 150.15, baseline_loss = 89.196, entropy_loss = -6.4528, learner_queue_size = 30, _tick = 12230, _time = 1.654e+09, train_seconds = 6317.5)
[2022-05-31 15:55:43,799][root][INFO] - Step 41792000 @ 6650.2 SPS. Inference batcher size: 31. Learner queue size: 30. Other stats: (step = 41792000, mean_episode_return = 91.855, mean_episode_step = 1513.4, total_loss = 136.59, pg_loss = -136.48, baseline_loss = 279.06, entropy_loss = -5.9905, learner_queue_size = 20, _tick = 12240, _time = 1.654e+09, train_seconds = 6322.5)
[2022-05-31 15:55:48,802][root][INFO] - Step 41825280 @ 6651.3 SPS. Inference batcher size: 32. Learner queue size: 26. Other stats: (step = 41825280, mean_episode_return = 75.144, mean_episode_step = 618.8, total_loss = -11.915, pg_loss = -66.55, baseline_loss = 60.897, entropy_loss = -6.2618, learner_queue_size = 21, _tick = 12251, _time = 1.654e+09, train_seconds = 6327.5)
[2022-05-31 15:55:53,806][root][INFO] - Step 41858560 @ 6650.6 SPS. Inference batcher size: 162. Learner queue size: 21. Other stats: (step = 41858560, mean_episode_return = 100.51, mean_episode_step = 953.97, total_loss = 82.736, pg_loss = 24.283, baseline_loss = 64.741, entropy_loss = -6.2882, learner_queue_size = 14, _tick = 12262, _time = 1.654e+09, train_seconds = 6332.5)
[2022-05-31 15:55:58,812][root][INFO] - Step 41889280 @ 6136.6 SPS. Inference batcher size: 154. Learner queue size: 22. Other stats: (step = 41889280, mean_episode_return = 104.3, mean_episode_step = 647.07, total_loss = -177.44, pg_loss = -195.96, baseline_loss = 24.55, entropy_loss = -6.0305, learner_queue_size = 26, _tick = 12273, _time = 1.654e+09, train_seconds = 6337.5)
[2022-05-31 15:56:03,818][root][INFO] - Step 41922560 @ 6648.0 SPS. Inference batcher size: 157. Learner queue size: 21. Other stats: (step = 41922560, mean_episode_return = None, mean_episode_step = 829.56, total_loss = -8.4558, pg_loss = -53.349, baseline_loss = 50.815, entropy_loss = -5.9221, learner_queue_size = 21, _tick = 12280, _time = 1.654e+09, train_seconds = 6342.5)
[2022-05-31 15:56:08,822][root][INFO] - Step 41955840 @ 6650.7 SPS. Inference batcher size: 86. Learner queue size: 12. Other stats: (step = 41955840, mean_episode_return = 131.44, mean_episode_step = 869.98, total_loss = 42.646, pg_loss = -1.7118, baseline_loss = 50.837, entropy_loss = -6.4792, learner_queue_size = 8, _tick = 12291, _time = 1.654e+09, train_seconds = 6347.5)
[2022-05-31 15:56:13,827][root][INFO] - Step 41989120 @ 6648.8 SPS. Inference batcher size: 5. Learner queue size: 5. Other stats: (step = 41989120, mean_episode_return = 124.71, mean_episode_step = 826.51, total_loss = 565.86, pg_loss = 413.71, baseline_loss = 158.78, entropy_loss = -6.6299, learner_queue_size = 17, _tick = 12302, _time = 1.654e+09, train_seconds = 6352.5)
[2022-05-31 15:56:18,830][root][INFO] - Step 42022400 @ 6652.4 SPS. Inference batcher size: 49. Learner queue size: 0. Other stats: (step = 42022400, mean_episode_return = 110.57, mean_episode_step = 1271.4, total_loss = -53.898, pg_loss = -102.07, baseline_loss = 54.473, entropy_loss = -6.2974, learner_queue_size = 14, _tick = 12311, _time = 1.654e+09, train_seconds = 6357.5)
[2022-05-31 15:56:23,834][root][INFO] - Step 42055680 @ 6650.9 SPS. Inference batcher size: 68. Learner queue size: 4. Other stats: (step = 42055680, mean_episode_return = 197.42, mean_episode_step = 973.1, total_loss = 17.474, pg_loss = -45.982, baseline_loss = 69.661, entropy_loss = -6.2056, learner_queue_size = 27, _tick = 12324, _time = 1.654e+09, train_seconds = 6362.5)
[2022-05-31 15:56:28,840][root][INFO] - Step 42086400 @ 6136.5 SPS. Inference batcher size: 129. Learner queue size: 26. Other stats: (step = 42086400, mean_episode_return = 147.96, mean_episode_step = 813.73, total_loss = 29.408, pg_loss = -7.2281, baseline_loss = 42.697, entropy_loss = -6.0614, learner_queue_size = 18, _tick = 12335, _time = 1.654e+09, train_seconds = 6367.5)
[2022-05-31 15:56:33,846][root][INFO] - Step 42119680 @ 6648.0 SPS. Inference batcher size: 75. Learner queue size: 23. Other stats: (step = 42119680, mean_episode_return = 129.07, mean_episode_step = 1678.4, total_loss = -93.121, pg_loss = -103.2, baseline_loss = 16.578, entropy_loss = -6.4997, learner_queue_size = 11, _tick = 12345, _time = 1.654e+09, train_seconds = 6372.5)
[2022-05-31 15:56:38,850][root][INFO] - Step 42152960 @ 6650.9 SPS. Inference batcher size: 165. Learner queue size: 24. Other stats: (step = 42152960, mean_episode_return = 81.969, mean_episode_step = 910.38, total_loss = 130.59, pg_loss = 71.892, baseline_loss = 65.258, entropy_loss = -6.5585, learner_queue_size = 13, _tick = 12355, _time = 1.654e+09, train_seconds = 6377.5)
[2022-05-31 15:56:43,854][root][INFO] - Step 42186240 @ 6650.6 SPS. Inference batcher size: 121. Learner queue size: 17. Other stats: (step = 42186240, mean_episode_return = 148.66, mean_episode_step = 730.07, total_loss = -135.44, pg_loss = -158.0, baseline_loss = 28.737, entropy_loss = -6.1797, learner_queue_size = 26, _tick = 12365, _time = 1.654e+09, train_seconds = 6382.5)
[2022-05-31 15:56:48,858][root][INFO] - Step 42219520 @ 6650.7 SPS. Inference batcher size: 129. Learner queue size: 9. Other stats: (step = 42219520, mean_episode_return = 82.355, mean_episode_step = 1655.5, total_loss = 118.14, pg_loss = 93.834, baseline_loss = 31.257, entropy_loss = -6.9498, learner_queue_size = 20, _tick = 12375, _time = 1.654e+09, train_seconds = 6387.5)
[2022-05-31 15:56:53,862][root][INFO] - Step 42252800 @ 6650.7 SPS. Inference batcher size: 129. Learner queue size: 6. Other stats: (step = 42252800, mean_episode_return = 100.89, mean_episode_step = 881.58, total_loss = -65.901, pg_loss = -97.798, baseline_loss = 38.18, entropy_loss = -6.2836, learner_queue_size = 27, _tick = 12385, _time = 1.654e+09, train_seconds = 6392.5)
[2022-05-31 15:56:58,868][root][INFO] - Step 42286080 @ 6647.8 SPS. Inference batcher size: 126. Learner queue size: 3. Other stats: (step = 42286080, mean_episode_return = 133.4, mean_episode_step = 803.61, total_loss = -98.5, pg_loss = -142.09, baseline_loss = 49.235, entropy_loss = -5.6419, learner_queue_size = 19, _tick = 12395, _time = 1.654e+09, train_seconds = 6397.6)
[2022-05-31 15:57:03,874][root][INFO] - Step 42319360 @ 6648.4 SPS. Inference batcher size: 137. Learner queue size: 2. Other stats: (step = 42319360, mean_episode_return = 129.2, mean_episode_step = 1887.6, total_loss = -282.21, pg_loss = -353.1, baseline_loss = 76.689, entropy_loss = -5.7995, learner_queue_size = 28, _tick = 12405, _time = 1.654e+09, train_seconds = 6402.6)
[2022-05-31 15:57:08,878][root][INFO] - Step 42352640 @ 6650.5 SPS. Inference batcher size: 66. Learner queue size: 4. Other stats: (step = 42352640, mean_episode_return = 40.881, mean_episode_step = 740.85, total_loss = 275.89, pg_loss = 72.918, baseline_loss = 208.99, entropy_loss = -6.0134, learner_queue_size = 18, _tick = 12416, _time = 1.654e+09, train_seconds = 6407.6)
[2022-05-31 15:57:13,882][root][INFO] - Step 42385920 @ 6650.7 SPS. Inference batcher size: 87. Learner queue size: 9. Other stats: (step = 42385920, mean_episode_return = 178.36, mean_episode_step = 1019.7, total_loss = -122.5, pg_loss = -146.0, baseline_loss = 29.795, entropy_loss = -6.2945, learner_queue_size = 24, _tick = 12427, _time = 1.654e+09, train_seconds = 6412.6)
[2022-05-31 15:57:18,886][root][INFO] - Step 42419200 @ 6650.7 SPS. Inference batcher size: 62. Learner queue size: 0. Other stats: (step = 42419200, mean_episode_return = 351.05, mean_episode_step = 923.33, total_loss = -41.914, pg_loss = -57.766, baseline_loss = 22.397, entropy_loss = -6.5453, learner_queue_size = 21, _tick = 12439, _time = 1.654e+09, train_seconds = 6417.6)
[2022-05-31 15:57:23,890][root][INFO] - Step 42452480 @ 6650.7 SPS. Inference batcher size: 68. Learner queue size: 2. Other stats: (step = 42452480, mean_episode_return = 167.89, mean_episode_step = 774.56, total_loss = 279.52, pg_loss = 223.85, baseline_loss = 61.524, entropy_loss = -5.8617, learner_queue_size = 18, _tick = 12451, _time = 1.654e+09, train_seconds = 6422.6)
[2022-05-31 15:57:28,894][root][INFO] - Step 42483200 @ 6139.1 SPS. Inference batcher size: 109. Learner queue size: 15. Other stats: (step = 42483200, mean_episode_return = 221.69, mean_episode_step = 1682.4, total_loss = -195.8, pg_loss = -320.76, baseline_loss = 131.28, entropy_loss = -6.3245, learner_queue_size = 17, _tick = 12463, _time = 1.654e+09, train_seconds = 6427.6)
[2022-05-31 15:57:33,900][root][INFO] - Step 42516480 @ 6647.6 SPS. Inference batcher size: 137. Learner queue size: 10. Other stats: (step = 42516480, mean_episode_return = 114.24, mean_episode_step = 849.9, total_loss = 40.996, pg_loss = -32.575, baseline_loss = 79.898, entropy_loss = -6.3273, learner_queue_size = 11, _tick = 12476, _time = 1.654e+09, train_seconds = 6432.6)
[2022-05-31 15:57:38,906][root][INFO] - Step 42549760 @ 6648.0 SPS. Inference batcher size: 70. Learner queue size: 18. Other stats: (step = 42549760, mean_episode_return = 394.98, mean_episode_step = 607.75, total_loss = 282.45, pg_loss = 128.06, baseline_loss = 159.95, entropy_loss = -5.5526, learner_queue_size = 20, _tick = 12487, _time = 1.654e+09, train_seconds = 6437.6)
[2022-05-31 15:57:43,910][root][INFO] - Step 42583040 @ 6651.0 SPS. Inference batcher size: 140. Learner queue size: 21. Other stats: (step = 42583040, mean_episode_return = 60.291, mean_episode_step = 1577.4, total_loss = 131.23, pg_loss = 57.623, baseline_loss = 79.695, entropy_loss = -6.0925, learner_queue_size = 23, _tick = 12495, _time = 1.654e+09, train_seconds = 6442.6)
[2022-05-31 15:57:48,914][root][INFO] - Step 42616320 @ 6650.8 SPS. Inference batcher size: 93. Learner queue size: 20. Other stats: (step = 42616320, mean_episode_return = 97.369, mean_episode_step = 668.58, total_loss = -5.8544, pg_loss = -83.5, baseline_loss = 83.607, entropy_loss = -5.9616, learner_queue_size = 19, _tick = 12506, _time = 1.654e+09, train_seconds = 6447.6)
[2022-05-31 15:57:53,918][root][INFO] - Step 42649600 @ 6650.6 SPS. Inference batcher size: 142. Learner queue size: 18. Other stats: (step = 42649600, mean_episode_return = 114.63, mean_episode_step = 682.52, total_loss = 170.88, pg_loss = 110.94, baseline_loss = 66.501, entropy_loss = -6.5591, learner_queue_size = 19, _tick = 12515, _time = 1.654e+09, train_seconds = 6452.6)
[2022-05-31 15:57:58,924][root][INFO] - Step 42682880 @ 6647.9 SPS. Inference batcher size: 47. Learner queue size: 3. Other stats: (step = 42682880, mean_episode_return = 213.39, mean_episode_step = 878.6, total_loss = 64.731, pg_loss = -127.25, baseline_loss = 198.68, entropy_loss = -6.6923, learner_queue_size = 17, _tick = 12527, _time = 1.654e+09, train_seconds = 6457.6)
[2022-05-31 15:58:03,930][root][INFO] - Step 42716160 @ 6648.1 SPS. Inference batcher size: 63. Learner queue size: 2. Other stats: (step = 42716160, mean_episode_return = 167.03, mean_episode_step = 792.01, total_loss = -190.1, pg_loss = -347.26, baseline_loss = 163.19, entropy_loss = -6.032, learner_queue_size = 31, _tick = 12539, _time = 1.654e+09, train_seconds = 6462.6)
[2022-05-31 15:58:08,934][root][INFO] - Step 42749440 @ 6650.7 SPS. Inference batcher size: 107. Learner queue size: 3. Other stats: (step = 42749440, mean_episode_return = 57.924, mean_episode_step = 589.19, total_loss = 166.67, pg_loss = 136.36, baseline_loss = 36.242, entropy_loss = -5.9316, learner_queue_size = 14, _tick = 12551, _time = 1.654e+09, train_seconds = 6467.6)
[2022-05-31 15:58:13,938][root][INFO] - Step 42782720 @ 6650.8 SPS. Inference batcher size: 100. Learner queue size: 23. Other stats: (step = 42782720, mean_episode_return = 138.21, mean_episode_step = 1091.4, total_loss = -129.48, pg_loss = -141.71, baseline_loss = 18.132, entropy_loss = -5.9043, learner_queue_size = 21, _tick = 12563, _time = 1.654e+09, train_seconds = 6472.6)
[2022-05-31 15:58:18,943][root][INFO] - Step 42816000 @ 6649.9 SPS. Inference batcher size: 15. Learner queue size: 28. Other stats: (step = 42816000, mean_episode_return = 144.59, mean_episode_step = 1097.1, total_loss = -264.82, pg_loss = -285.84, baseline_loss = 26.756, entropy_loss = -5.7439, learner_queue_size = 22, _tick = 12574, _time = 1.654e+09, train_seconds = 6477.6)
[2022-05-31 15:58:23,946][root][INFO] - Step 42849280 @ 6651.1 SPS. Inference batcher size: 60. Learner queue size: 12. Other stats: (step = 42849280, mean_episode_return = 96.793, mean_episode_step = 1763.7, total_loss = 152.34, pg_loss = 84.639, baseline_loss = 74.137, entropy_loss = -6.4386, learner_queue_size = 12, _tick = 12585, _time = 1.654e+09, train_seconds = 6482.6)
[2022-05-31 15:58:28,950][root][INFO] - Step 42882560 @ 6651.1 SPS. Inference batcher size: 57. Learner queue size: 5. Other stats: (step = 42882560, mean_episode_return = 206.61, mean_episode_step = 927.96, total_loss = 706.63, pg_loss = 451.77, baseline_loss = 261.7, entropy_loss = -6.8341, learner_queue_size = 5, _tick = 12597, _time = 1.654e+09, train_seconds = 6487.6)
[2022-05-31 15:58:33,954][root][INFO] - Step 42913280 @ 6138.9 SPS. Inference batcher size: 119. Learner queue size: 4. Other stats: (step = 42913280, mean_episode_return = 92.24, mean_episode_step = 672.89, total_loss = 3.8211, pg_loss = -42.449, baseline_loss = 52.766, entropy_loss = -6.4956, learner_queue_size = 22, _tick = 12606, _time = 1.654e+09, train_seconds = 6492.6)
[2022-05-31 15:58:38,958][root][INFO] - Step 42946560 @ 6650.8 SPS. Inference batcher size: 167. Learner queue size: 0. Other stats: (step = 42946560, mean_episode_return = None, mean_episode_step = 876.72, total_loss = -24.111, pg_loss = -90.327, baseline_loss = 73.012, entropy_loss = -6.7959, learner_queue_size = 12, _tick = 12616, _time = 1.654e+09, train_seconds = 6497.6)
[2022-05-31 15:58:43,962][root][INFO] - Step 42979840 @ 6650.2 SPS. Inference batcher size: 47. Learner queue size: 23. Other stats: (step = 42979840, mean_episode_return = 74.478, mean_episode_step = 1044.0, total_loss = -81.991, pg_loss = -141.85, baseline_loss = 66.723, entropy_loss = -6.8595, learner_queue_size = 23, _tick = 12627, _time = 1.654e+09, train_seconds = 6502.6)
[2022-05-31 15:58:48,966][root][INFO] - Step 43010560 @ 6139.5 SPS. Inference batcher size: 2. Learner queue size: 8. Other stats: (step = 43010560, mean_episode_return = 104.33, mean_episode_step = 861.56, total_loss = 130.73, pg_loss = 67.834, baseline_loss = 69.628, entropy_loss = -6.7348, learner_queue_size = 16, _tick = 12639, _time = 1.654e+09, train_seconds = 6507.7)
[2022-05-31 15:58:53,970][root][INFO] - Step 43043840 @ 6650.5 SPS. Inference batcher size: 139. Learner queue size: 9. Other stats: (step = 43043840, mean_episode_return = 82.639, mean_episode_step = 838.91, total_loss = -123.51, pg_loss = -135.38, baseline_loss = 18.611, entropy_loss = -6.7404, learner_queue_size = 21, _tick = 12651, _time = 1.654e+09, train_seconds = 6512.7)
[2022-05-31 15:58:58,974][root][INFO] - Step 43077120 @ 6650.8 SPS. Inference batcher size: 122. Learner queue size: 11. Other stats: (step = 43077120, mean_episode_return = None, mean_episode_step = 830.59, total_loss = 294.48, pg_loss = 191.94, baseline_loss = 109.25, entropy_loss = -6.7056, learner_queue_size = 11, _tick = 12660, _time = 1.654e+09, train_seconds = 6517.7)
[2022-05-31 15:59:03,980][root][INFO] - Step 43110400 @ 6648.4 SPS. Inference batcher size: 151. Learner queue size: 20. Other stats: (step = 43110400, mean_episode_return = 110.22, mean_episode_step = 830.53, total_loss = 148.94, pg_loss = 85.27, baseline_loss = 69.838, entropy_loss = -6.1695, learner_queue_size = 19, _tick = 12670, _time = 1.654e+09, train_seconds = 6522.7)
[2022-05-31 15:59:08,985][root][INFO] - Step 43143680 @ 6648.1 SPS. Inference batcher size: 82. Learner queue size: 15. Other stats: (step = 43143680, mean_episode_return = 120.77, mean_episode_step = 1121.3, total_loss = -190.39, pg_loss = -262.59, baseline_loss = 78.731, entropy_loss = -6.535, learner_queue_size = 17, _tick = 12681, _time = 1.654e+09, train_seconds = 6527.7)
[2022-05-31 15:59:13,990][root][INFO] - Step 43176960 @ 6650.2 SPS. Inference batcher size: 139. Learner queue size: 10. Other stats: (step = 43176960, mean_episode_return = 173.75, mean_episode_step = 925.82, total_loss = -52.209, pg_loss = -85.125, baseline_loss = 39.391, entropy_loss = -6.474, learner_queue_size = 25, _tick = 12694, _time = 1.654e+09, train_seconds = 6532.7)
[2022-05-31 15:59:18,995][root][INFO] - Step 43210240 @ 6648.6 SPS. Inference batcher size: 70. Learner queue size: 29. Other stats: (step = 43210240, mean_episode_return = 118.33, mean_episode_step = 957.69, total_loss = 105.73, pg_loss = 10.407, baseline_loss = 101.67, entropy_loss = -6.3462, learner_queue_size = 26, _tick = 12707, _time = 1.654e+09, train_seconds = 6537.7)
[2022-05-31 15:59:24,001][root][INFO] - Step 43240960 @ 6136.8 SPS. Inference batcher size: 86. Learner queue size: 20. Other stats: (step = 43240960, mean_episode_return = 142.8, mean_episode_step = 780.62, total_loss = -143.27, pg_loss = -170.4, baseline_loss = 33.807, entropy_loss = -6.6746, learner_queue_size = 11, _tick = 12718, _time = 1.654e+09, train_seconds = 6542.7)
[2022-05-31 15:59:29,006][root][INFO] - Step 43274240 @ 6649.9 SPS. Inference batcher size: 46. Learner queue size: 5. Other stats: (step = 43274240, mean_episode_return = None, mean_episode_step = 600.12, total_loss = 205.47, pg_loss = 129.89, baseline_loss = 81.783, entropy_loss = -6.2046, learner_queue_size = 15, _tick = 12728, _time = 1.654e+09, train_seconds = 6547.7)
[2022-05-31 15:59:34,010][root][INFO] - Step 43307520 @ 6650.7 SPS. Inference batcher size: 135. Learner queue size: 5. Other stats: (step = 43307520, mean_episode_return = 89.999, mean_episode_step = 652.46, total_loss = 211.34, pg_loss = 98.881, baseline_loss = 118.21, entropy_loss = -5.7553, learner_queue_size = 18, _tick = 12741, _time = 1.654e+09, train_seconds = 6552.7)
[2022-05-31 15:59:39,014][root][INFO] - Step 43340800 @ 6650.6 SPS. Inference batcher size: 69. Learner queue size: 3. Other stats: (step = 43340800, mean_episode_return = 232.06, mean_episode_step = 750.96, total_loss = 248.05, pg_loss = 32.575, baseline_loss = 221.7, entropy_loss = -6.2244, learner_queue_size = 27, _tick = 12750, _time = 1.654e+09, train_seconds = 6557.7)
[2022-05-31 15:59:44,018][root][INFO] - Step 43374080 @ 6650.4 SPS. Inference batcher size: 59. Learner queue size: 31. Other stats: (step = 43374080, mean_episode_return = 489.95, mean_episode_step = 795.72, total_loss = 162.11, pg_loss = 94.149, baseline_loss = 74.475, entropy_loss = -6.5152, learner_queue_size = 22, _tick = 12761, _time = 1.654e+09, train_seconds = 6562.7)
[2022-05-31 15:59:49,022][root][INFO] - Step 43407360 @ 6651.0 SPS. Inference batcher size: 48. Learner queue size: 18. Other stats: (step = 43407360, mean_episode_return = 139.67, mean_episode_step = 781.66, total_loss = 261.35, pg_loss = 49.009, baseline_loss = 218.46, entropy_loss = -6.1127, learner_queue_size = 16, _tick = 12773, _time = 1.654e+09, train_seconds = 6567.7)
[2022-05-31 15:59:54,026][root][INFO] - Step 43438080 @ 6139.1 SPS. Inference batcher size: 102. Learner queue size: 22. Other stats: (step = 43438080, mean_episode_return = 223.71, mean_episode_step = 740.93, total_loss = 67.08, pg_loss = 8.3476, baseline_loss = 64.943, entropy_loss = -6.2107, learner_queue_size = 16, _tick = 12784, _time = 1.654e+09, train_seconds = 6572.7)
[2022-05-31 15:59:59,032][root][INFO] - Step 43471360 @ 6648.0 SPS. Inference batcher size: 159. Learner queue size: 15. Other stats: (step = 43471360, mean_episode_return = 50.44, mean_episode_step = 710.91, total_loss = -131.24, pg_loss = -144.04, baseline_loss = 19.176, entropy_loss = -6.3721, learner_queue_size = 17, _tick = 12795, _time = 1.654e+09, train_seconds = 6577.7)
[2022-05-31 16:00:04,034][root][INFO] - Step 43504640 @ 6653.3 SPS. Inference batcher size: 79. Learner queue size: 9. Other stats: (step = 43504640, mean_episode_return = 125.88, mean_episode_step = 807.49, total_loss = -217.68, pg_loss = -271.74, baseline_loss = 60.382, entropy_loss = -6.3206, learner_queue_size = 27, _tick = 12803, _time = 1.654e+09, train_seconds = 6582.7)
[2022-05-31 16:00:09,038][root][INFO] - Step 43537920 @ 6650.7 SPS. Inference batcher size: 184. Learner queue size: 4. Other stats: (step = 43537920, mean_episode_return = 105.81, mean_episode_step = 653.61, total_loss = 12.171, pg_loss = -94.892, baseline_loss = 113.45, entropy_loss = -6.3878, learner_queue_size = 31, _tick = 12816, _time = 1.654e+09, train_seconds = 6587.7)
[2022-05-31 16:00:14,044][root][INFO] - Step 43571200 @ 6647.9 SPS. Inference batcher size: 151. Learner queue size: 1. Other stats: (step = 43571200, mean_episode_return = 162.27, mean_episode_step = 581.36, total_loss = -134.76, pg_loss = -177.15, baseline_loss = 49.168, entropy_loss = -6.7795, learner_queue_size = 30, _tick = 12828, _time = 1.654e+09, train_seconds = 6592.7)
[2022-05-31 16:00:19,050][root][INFO] - Step 43604480 @ 6648.2 SPS. Inference batcher size: 111. Learner queue size: 26. Other stats: (step = 43604480, mean_episode_return = None, mean_episode_step = 697.62, total_loss = 22.028, pg_loss = -28.192, baseline_loss = 57.127, entropy_loss = -6.9069, learner_queue_size = 20, _tick = 12839, _time = 1.654e+09, train_seconds = 6597.7)
[2022-05-31 16:00:24,054][root][INFO] - Step 43637760 @ 6650.6 SPS. Inference batcher size: 56. Learner queue size: 0. Other stats: (step = 43637760, mean_episode_return = 62.385, mean_episode_step = 660.49, total_loss = 192.17, pg_loss = 55.074, baseline_loss = 143.78, entropy_loss = -6.6782, learner_queue_size = 18, _tick = 12851, _time = 1.654e+09, train_seconds = 6602.7)
[2022-05-31 16:00:29,058][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 16:00:29,133][root][INFO] - Step 43671040 @ 6650.7 SPS. Inference batcher size: 110. Learner queue size: 30. Other stats: (step = 43671040, mean_episode_return = 280.14, mean_episode_step = 620.47, total_loss = -170.75, pg_loss = -262.95, baseline_loss = 98.709, entropy_loss = -6.5096, learner_queue_size = 15, _tick = 12862, _time = 1.654e+09, train_seconds = 6607.7)
[2022-05-31 16:00:34,138][root][INFO] - Step 43704320 @ 6551.2 SPS. Inference batcher size: 41. Learner queue size: 20. Other stats: (step = 43704320, mean_episode_return = None, mean_episode_step = 879.16, total_loss = 215.25, pg_loss = 165.4, baseline_loss = 56.74, entropy_loss = -6.8827, learner_queue_size = 8, _tick = 12873, _time = 1.654e+09, train_seconds = 6612.8)
[2022-05-31 16:00:39,142][root][INFO] - Step 43737600 @ 6650.7 SPS. Inference batcher size: 106. Learner queue size: 24. Other stats: (step = 43737600, mean_episode_return = 238.63, mean_episode_step = 1138.8, total_loss = -177.12, pg_loss = -192.11, baseline_loss = 21.787, entropy_loss = -6.7941, learner_queue_size = 20, _tick = 12885, _time = 1.654e+09, train_seconds = 6617.8)
[2022-05-31 16:00:44,149][root][INFO] - Step 43768320 @ 6135.9 SPS. Inference batcher size: 114. Learner queue size: 19. Other stats: (step = 43768320, mean_episode_return = 80.059, mean_episode_step = 1179.9, total_loss = 18.871, pg_loss = -156.89, baseline_loss = 182.27, entropy_loss = -6.5134, learner_queue_size = 15, _tick = 12896, _time = 1.654e+09, train_seconds = 6622.8)
[2022-05-31 16:00:49,154][root][INFO] - Step 43801600 @ 6648.7 SPS. Inference batcher size: 115. Learner queue size: 9. Other stats: (step = 43801600, mean_episode_return = 159.61, mean_episode_step = 910.08, total_loss = 981.43, pg_loss = 671.29, baseline_loss = 316.73, entropy_loss = -6.5791, learner_queue_size = 22, _tick = 12907, _time = 1.654e+09, train_seconds = 6627.8)
[2022-05-31 16:00:54,158][root][INFO] - Step 43834880 @ 6650.6 SPS. Inference batcher size: 113. Learner queue size: 9. Other stats: (step = 43834880, mean_episode_return = 178.07, mean_episode_step = 841.97, total_loss = -183.6, pg_loss = -228.27, baseline_loss = 51.432, entropy_loss = -6.764, learner_queue_size = 19, _tick = 12918, _time = 1.654e+09, train_seconds = 6632.8)
[2022-05-31 16:00:59,162][root][INFO] - Step 43868160 @ 6650.7 SPS. Inference batcher size: 108. Learner queue size: 7. Other stats: (step = 43868160, mean_episode_return = 81.788, mean_episode_step = 881.98, total_loss = 1318.0, pg_loss = 708.01, baseline_loss = 616.6, entropy_loss = -6.6498, learner_queue_size = 24, _tick = 12927, _time = 1.654e+09, train_seconds = 6637.8)
[2022-05-31 16:01:04,166][root][INFO] - Step 43901440 @ 6650.8 SPS. Inference batcher size: 20. Learner queue size: 2. Other stats: (step = 43901440, mean_episode_return = 147.74, mean_episode_step = 922.74, total_loss = 795.84, pg_loss = 618.99, baseline_loss = 184.04, entropy_loss = -7.1881, learner_queue_size = 20, _tick = 12938, _time = 1.654e+09, train_seconds = 6642.9)
[2022-05-31 16:01:09,170][root][INFO] - Step 43934720 @ 6650.6 SPS. Inference batcher size: 87. Learner queue size: 21. Other stats: (step = 43934720, mean_episode_return = 89.517, mean_episode_step = 776.81, total_loss = -167.19, pg_loss = -180.78, baseline_loss = 20.509, entropy_loss = -6.9234, learner_queue_size = 14, _tick = 12949, _time = 1.654e+09, train_seconds = 6647.9)
[2022-05-31 16:01:14,176][root][INFO] - Step 43965440 @ 6136.6 SPS. Inference batcher size: 120. Learner queue size: 14. Other stats: (step = 43965440, mean_episode_return = 117.79, mean_episode_step = 911.37, total_loss = 316.73, pg_loss = 222.72, baseline_loss = 100.6, entropy_loss = -6.5813, learner_queue_size = 21, _tick = 12959, _time = 1.654e+09, train_seconds = 6652.9)
[2022-05-31 16:01:19,182][root][INFO] - Step 43998720 @ 6648.1 SPS. Inference batcher size: 126. Learner queue size: 21. Other stats: (step = 43998720, mean_episode_return = 111.58, mean_episode_step = 625.09, total_loss = 310.58, pg_loss = 188.71, baseline_loss = 128.46, entropy_loss = -6.5899, learner_queue_size = 12, _tick = 12971, _time = 1.654e+09, train_seconds = 6657.9)
[2022-05-31 16:01:24,186][root][INFO] - Step 44032000 @ 6650.6 SPS. Inference batcher size: 66. Learner queue size: 11. Other stats: (step = 44032000, mean_episode_return = 98.324, mean_episode_step = 1284.0, total_loss = 162.15, pg_loss = -91.61, baseline_loss = 260.27, entropy_loss = -6.505, learner_queue_size = 30, _tick = 12982, _time = 1.654e+09, train_seconds = 6662.9)
[2022-05-31 16:01:29,192][root][INFO] - Step 44065280 @ 6648.1 SPS. Inference batcher size: 120. Learner queue size: 3. Other stats: (step = 44065280, mean_episode_return = 117.16, mean_episode_step = 836.69, total_loss = -124.96, pg_loss = -191.95, baseline_loss = 73.531, entropy_loss = -6.5448, learner_queue_size = 17, _tick = 12992, _time = 1.654e+09, train_seconds = 6667.9)
[2022-05-31 16:01:34,198][root][INFO] - Step 44098560 @ 6648.0 SPS. Inference batcher size: 79. Learner queue size: 24. Other stats: (step = 44098560, mean_episode_return = 94.27, mean_episode_step = 754.6, total_loss = 69.931, pg_loss = 37.17, baseline_loss = 38.924, entropy_loss = -6.1628, learner_queue_size = 19, _tick = 13004, _time = 1.654e+09, train_seconds = 6672.9)
[2022-05-31 16:01:39,204][root][INFO] - Step 44129280 @ 6136.3 SPS. Inference batcher size: 133. Learner queue size: 26. Other stats: (step = 44129280, mean_episode_return = 153.17, mean_episode_step = 930.07, total_loss = -50.508, pg_loss = -83.024, baseline_loss = 39.326, entropy_loss = -6.8092, learner_queue_size = 22, _tick = 13013, _time = 1.654e+09, train_seconds = 6677.9)
[2022-05-31 16:01:44,210][root][INFO] - Step 44162560 @ 6648.0 SPS. Inference batcher size: 144. Learner queue size: 25. Other stats: (step = 44162560, mean_episode_return = 173.54, mean_episode_step = 889.8, total_loss = 417.66, pg_loss = 353.94, baseline_loss = 70.11, entropy_loss = -6.3868, learner_queue_size = 17, _tick = 13025, _time = 1.654e+09, train_seconds = 6682.9)
[2022-05-31 16:01:49,216][root][INFO] - Step 44195840 @ 6647.9 SPS. Inference batcher size: 157. Learner queue size: 23. Other stats: (step = 44195840, mean_episode_return = 150.92, mean_episode_step = 1049.6, total_loss = 675.43, pg_loss = 562.78, baseline_loss = 117.05, entropy_loss = -4.4017, learner_queue_size = 20, _tick = 13038, _time = 1.654e+09, train_seconds = 6687.9)
[2022-05-31 16:01:54,222][root][INFO] - Step 44229120 @ 6648.1 SPS. Inference batcher size: 115. Learner queue size: 18. Other stats: (step = 44229120, mean_episode_return = None, mean_episode_step = 941.78, total_loss = -92.994, pg_loss = -144.7, baseline_loss = 58.115, entropy_loss = -6.4098, learner_queue_size = 25, _tick = 13049, _time = 1.654e+09, train_seconds = 6692.9)
[2022-05-31 16:01:59,228][root][INFO] - Step 44262400 @ 6648.0 SPS. Inference batcher size: 100. Learner queue size: 17. Other stats: (step = 44262400, mean_episode_return = 126.97, mean_episode_step = 779.1, total_loss = 418.15, pg_loss = 162.39, baseline_loss = 262.51, entropy_loss = -6.7522, learner_queue_size = 22, _tick = 13061, _time = 1.654e+09, train_seconds = 6697.9)
[2022-05-31 16:02:04,234][root][INFO] - Step 44295680 @ 6648.4 SPS. Inference batcher size: 34. Learner queue size: 10. Other stats: (step = 44295680, mean_episode_return = None, mean_episode_step = 1806.6, total_loss = -62.004, pg_loss = -113.73, baseline_loss = 58.068, entropy_loss = -6.3408, learner_queue_size = 22, _tick = 13070, _time = 1.654e+09, train_seconds = 6702.9)
[2022-05-31 16:02:09,241][root][INFO] - Step 44328960 @ 6647.2 SPS. Inference batcher size: 75. Learner queue size: 7. Other stats: (step = 44328960, mean_episode_return = None, mean_episode_step = 837.84, total_loss = 339.17, pg_loss = 171.31, baseline_loss = 174.37, entropy_loss = -6.5198, learner_queue_size = 15, _tick = 13081, _time = 1.654e+09, train_seconds = 6707.9)
[2022-05-31 16:02:14,247][root][INFO] - Step 44362240 @ 6647.4 SPS. Inference batcher size: 95. Learner queue size: 2. Other stats: (step = 44362240, mean_episode_return = 70.33, mean_episode_step = 790.79, total_loss = 743.81, pg_loss = 605.57, baseline_loss = 144.82, entropy_loss = -6.5808, learner_queue_size = 15, _tick = 13092, _time = 1.654e+09, train_seconds = 6712.9)
[2022-05-31 16:02:19,250][root][INFO] - Step 44395520 @ 6652.0 SPS. Inference batcher size: 49. Learner queue size: 0. Other stats: (step = 44395520, mean_episode_return = 118.52, mean_episode_step = 786.57, total_loss = 641.9, pg_loss = 433.42, baseline_loss = 214.77, entropy_loss = -6.2823, learner_queue_size = 21, _tick = 13103, _time = 1.654e+09, train_seconds = 6717.9)
[2022-05-31 16:02:24,254][root][INFO] - Step 44428800 @ 6650.6 SPS. Inference batcher size: 162. Learner queue size: 31. Other stats: (step = 44428800, mean_episode_return = 268.17, mean_episode_step = 824.14, total_loss = 548.03, pg_loss = 368.71, baseline_loss = 186.01, entropy_loss = -6.697, learner_queue_size = 15, _tick = 13114, _time = 1.654e+09, train_seconds = 6722.9)
[2022-05-31 16:02:29,258][root][INFO] - Step 44462080 @ 6650.7 SPS. Inference batcher size: 125. Learner queue size: 26. Other stats: (step = 44462080, mean_episode_return = 150.05, mean_episode_step = 719.49, total_loss = -296.64, pg_loss = -306.57, baseline_loss = 16.407, entropy_loss = -6.4739, learner_queue_size = 20, _tick = 13126, _time = 1.654e+09, train_seconds = 6727.9)
[2022-05-31 16:02:34,262][root][INFO] - Step 44495360 @ 6650.7 SPS. Inference batcher size: 142. Learner queue size: 18. Other stats: (step = 44495360, mean_episode_return = 173.38, mean_episode_step = 927.87, total_loss = 203.35, pg_loss = 94.44, baseline_loss = 115.3, entropy_loss = -6.3871, learner_queue_size = 16, _tick = 13138, _time = 1.654e+09, train_seconds = 6732.9)
[2022-05-31 16:02:39,266][root][INFO] - Step 44526080 @ 6139.1 SPS. Inference batcher size: 141. Learner queue size: 25. Other stats: (step = 44526080, mean_episode_return = None, mean_episode_step = 683.09, total_loss = 209.8, pg_loss = 166.27, baseline_loss = 50.481, entropy_loss = -6.9478, learner_queue_size = 15, _tick = 13145, _time = 1.654e+09, train_seconds = 6738.0)
[2022-05-31 16:02:44,270][root][INFO] - Step 44559360 @ 6650.6 SPS. Inference batcher size: 106. Learner queue size: 10. Other stats: (step = 44559360, mean_episode_return = 210.29, mean_episode_step = 702.58, total_loss = -33.712, pg_loss = -119.71, baseline_loss = 92.361, entropy_loss = -6.3652, learner_queue_size = 22, _tick = 13155, _time = 1.654e+09, train_seconds = 6743.0)
[2022-05-31 16:02:49,274][root][INFO] - Step 44592640 @ 6650.5 SPS. Inference batcher size: 24. Learner queue size: 4. Other stats: (step = 44592640, mean_episode_return = None, mean_episode_step = 1009.3, total_loss = 112.51, pg_loss = 1.0394, baseline_loss = 117.94, entropy_loss = -6.4637, learner_queue_size = 21, _tick = 13163, _time = 1.654e+09, train_seconds = 6748.0)
[2022-05-31 16:02:54,278][root][INFO] - Step 44625920 @ 6650.9 SPS. Inference batcher size: 85. Learner queue size: 2. Other stats: (step = 44625920, mean_episode_return = 73.51, mean_episode_step = 1329.6, total_loss = 135.27, pg_loss = 42.626, baseline_loss = 99.358, entropy_loss = -6.7133, learner_queue_size = 19, _tick = 13173, _time = 1.654e+09, train_seconds = 6753.0)
[2022-05-31 16:02:59,282][root][INFO] - Step 44659200 @ 6650.7 SPS. Inference batcher size: 65. Learner queue size: 24. Other stats: (step = 44659200, mean_episode_return = 81.975, mean_episode_step = 970.45, total_loss = 66.439, pg_loss = -28.94, baseline_loss = 102.01, entropy_loss = -6.6269, learner_queue_size = 17, _tick = 13185, _time = 1.654e+09, train_seconds = 6758.0)
[2022-05-31 16:03:04,286][root][INFO] - Step 44689920 @ 6139.1 SPS. Inference batcher size: 199. Learner queue size: 18. Other stats: (step = 44689920, mean_episode_return = 205.46, mean_episode_step = 864.83, total_loss = 81.578, pg_loss = 37.188, baseline_loss = 50.762, entropy_loss = -6.3722, learner_queue_size = 24, _tick = 13197, _time = 1.654e+09, train_seconds = 6763.0)
[2022-05-31 16:03:09,292][root][INFO] - Step 44723200 @ 6648.1 SPS. Inference batcher size: 43. Learner queue size: 16. Other stats: (step = 44723200, mean_episode_return = 66.744, mean_episode_step = 1865.9, total_loss = -22.747, pg_loss = -69.047, baseline_loss = 52.403, entropy_loss = -6.1034, learner_queue_size = 19, _tick = 13209, _time = 1.654e+09, train_seconds = 6768.0)
[2022-05-31 16:03:14,298][root][INFO] - Step 44756480 @ 6648.1 SPS. Inference batcher size: 116. Learner queue size: 20. Other stats: (step = 44756480, mean_episode_return = 69.075, mean_episode_step = 883.98, total_loss = 71.925, pg_loss = 16.018, baseline_loss = 62.128, entropy_loss = -6.2214, learner_queue_size = 17, _tick = 13222, _time = 1.654e+09, train_seconds = 6773.0)
[2022-05-31 16:03:19,304][root][INFO] - Step 44789760 @ 6647.9 SPS. Inference batcher size: 136. Learner queue size: 21. Other stats: (step = 44789760, mean_episode_return = 65.944, mean_episode_step = 895.69, total_loss = 412.88, pg_loss = 143.99, baseline_loss = 274.73, entropy_loss = -5.8399, learner_queue_size = 21, _tick = 13233, _time = 1.654e+09, train_seconds = 6778.0)
[2022-05-31 16:03:24,310][root][INFO] - Step 44823040 @ 6648.1 SPS. Inference batcher size: 110. Learner queue size: 3. Other stats: (step = 44823040, mean_episode_return = 16.27, mean_episode_step = 981.25, total_loss = 97.284, pg_loss = 65.738, baseline_loss = 38.114, entropy_loss = -6.5676, learner_queue_size = 13, _tick = 13243, _time = 1.654e+09, train_seconds = 6783.0)
[2022-05-31 16:03:29,314][root][INFO] - Step 44856320 @ 6650.6 SPS. Inference batcher size: 93. Learner queue size: 3. Other stats: (step = 44856320, mean_episode_return = 75.195, mean_episode_step = 762.51, total_loss = 72.004, pg_loss = 3.382, baseline_loss = 75.287, entropy_loss = -6.665, learner_queue_size = 21, _tick = 13255, _time = 1.654e+09, train_seconds = 6788.0)
[2022-05-31 16:03:34,320][root][INFO] - Step 44889600 @ 6647.9 SPS. Inference batcher size: 70. Learner queue size: 4. Other stats: (step = 44889600, mean_episode_return = 74.45, mean_episode_step = 1244.9, total_loss = 349.72, pg_loss = 253.04, baseline_loss = 102.77, entropy_loss = -6.0923, learner_queue_size = 19, _tick = 13267, _time = 1.654e+09, train_seconds = 6793.0)
[2022-05-31 16:03:39,326][root][INFO] - Step 44922880 @ 6648.0 SPS. Inference batcher size: 95. Learner queue size: 1. Other stats: (step = 44922880, mean_episode_return = 123.28, mean_episode_step = 812.89, total_loss = 281.95, pg_loss = 159.77, baseline_loss = 128.56, entropy_loss = -6.375, learner_queue_size = 15, _tick = 13279, _time = 1.654e+09, train_seconds = 6798.0)
[2022-05-31 16:03:44,330][root][INFO] - Step 44956160 @ 6650.8 SPS. Inference batcher size: 21. Learner queue size: 2. Other stats: (step = 44956160, mean_episode_return = 223.92, mean_episode_step = 865.99, total_loss = 122.63, pg_loss = 65.262, baseline_loss = 63.802, entropy_loss = -6.4312, learner_queue_size = 19, _tick = 13289, _time = 1.654e+09, train_seconds = 6803.0)
[2022-05-31 16:03:49,334][root][INFO] - Step 44986880 @ 6139.1 SPS. Inference batcher size: 118. Learner queue size: 14. Other stats: (step = 44986880, mean_episode_return = 201.01, mean_episode_step = 1726.9, total_loss = 55.047, pg_loss = -43.319, baseline_loss = 104.57, entropy_loss = -6.2039, learner_queue_size = 17, _tick = 13300, _time = 1.654e+09, train_seconds = 6808.0)
[2022-05-31 16:03:54,340][root][INFO] - Step 45020160 @ 6647.9 SPS. Inference batcher size: 94. Learner queue size: 16. Other stats: (step = 45020160, mean_episode_return = 107.61, mean_episode_step = 870.67, total_loss = 51.07, pg_loss = 32.287, baseline_loss = 24.327, entropy_loss = -5.5437, learner_queue_size = 11, _tick = 13312, _time = 1.654e+09, train_seconds = 6813.0)
[2022-05-31 16:03:59,346][root][INFO] - Step 45053440 @ 6648.0 SPS. Inference batcher size: 131. Learner queue size: 23. Other stats: (step = 45053440, mean_episode_return = None, mean_episode_step = 1395.3, total_loss = -115.31, pg_loss = -155.5, baseline_loss = 46.581, entropy_loss = -6.3926, learner_queue_size = 25, _tick = 13322, _time = 1.654e+09, train_seconds = 6818.0)
[2022-05-31 16:04:04,349][root][INFO] - Step 45086720 @ 6652.1 SPS. Inference batcher size: 96. Learner queue size: 15. Other stats: (step = 45086720, mean_episode_return = 105.81, mean_episode_step = 1910.3, total_loss = 176.03, pg_loss = 118.46, baseline_loss = 63.869, entropy_loss = -6.2993, learner_queue_size = 16, _tick = 13329, _time = 1.654e+09, train_seconds = 6823.0)
[2022-05-31 16:04:09,354][root][INFO] - Step 45120000 @ 6649.3 SPS. Inference batcher size: 45. Learner queue size: 14. Other stats: (step = 45120000, mean_episode_return = None, mean_episode_step = 698.94, total_loss = 269.4, pg_loss = 145.44, baseline_loss = 130.57, entropy_loss = -6.6009, learner_queue_size = 17, _tick = 13340, _time = 1.654e+09, train_seconds = 6828.0)
[2022-05-31 16:04:14,360][root][INFO] - Step 45153280 @ 6648.1 SPS. Inference batcher size: 24. Learner queue size: 2. Other stats: (step = 45153280, mean_episode_return = 64.152, mean_episode_step = 1172.6, total_loss = 19.959, pg_loss = -230.21, baseline_loss = 256.35, entropy_loss = -6.1862, learner_queue_size = 17, _tick = 13352, _time = 1.654e+09, train_seconds = 6833.0)
[2022-05-31 16:04:19,366][root][INFO] - Step 45186560 @ 6648.0 SPS. Inference batcher size: 91. Learner queue size: 15. Other stats: (step = 45186560, mean_episode_return = 204.04, mean_episode_step = 625.87, total_loss = -32.279, pg_loss = -92.666, baseline_loss = 66.763, entropy_loss = -6.3766, learner_queue_size = 27, _tick = 13364, _time = 1.654e+09, train_seconds = 6838.1)
[2022-05-31 16:04:24,372][root][INFO] - Step 45219840 @ 6647.9 SPS. Inference batcher size: 129. Learner queue size: 6. Other stats: (step = 45219840, mean_episode_return = 53.495, mean_episode_step = 936.68, total_loss = 279.34, pg_loss = 71.521, baseline_loss = 214.0, entropy_loss = -6.1786, learner_queue_size = 24, _tick = 13375, _time = 1.654e+09, train_seconds = 6843.1)
[2022-05-31 16:04:29,378][root][INFO] - Step 45253120 @ 6647.9 SPS. Inference batcher size: 123. Learner queue size: 29. Other stats: (step = 45253120, mean_episode_return = 85.949, mean_episode_step = 575.68, total_loss = -235.34, pg_loss = -253.55, baseline_loss = 24.9, entropy_loss = -6.6942, learner_queue_size = 18, _tick = 13388, _time = 1.654e+09, train_seconds = 6848.1)
[2022-05-31 16:04:34,382][root][INFO] - Step 45283840 @ 6139.4 SPS. Inference batcher size: 26. Learner queue size: 16. Other stats: (step = 45283840, mean_episode_return = 341.51, mean_episode_step = 836.04, total_loss = 34.862, pg_loss = -3.472, baseline_loss = 45.267, entropy_loss = -6.9331, learner_queue_size = 15, _tick = 13398, _time = 1.654e+09, train_seconds = 6853.1)
[2022-05-31 16:04:39,384][root][INFO] - Step 45317120 @ 6652.8 SPS. Inference batcher size: 148. Learner queue size: 14. Other stats: (step = 45317120, mean_episode_return = 158.47, mean_episode_step = 1273.3, total_loss = -217.52, pg_loss = -256.25, baseline_loss = 45.22, entropy_loss = -6.4899, learner_queue_size = 18, _tick = 13410, _time = 1.654e+09, train_seconds = 6858.1)
[2022-05-31 16:04:44,391][root][INFO] - Step 45350400 @ 6647.3 SPS. Inference batcher size: 3. Learner queue size: 12. Other stats: (step = 45350400, mean_episode_return = 90.027, mean_episode_step = 823.6, total_loss = 542.4, pg_loss = 411.17, baseline_loss = 137.42, entropy_loss = -6.1916, learner_queue_size = 22, _tick = 13421, _time = 1.654e+09, train_seconds = 6863.1)
[2022-05-31 16:04:49,397][root][INFO] - Step 45383680 @ 6647.5 SPS. Inference batcher size: 134. Learner queue size: 6. Other stats: (step = 45383680, mean_episode_return = 149.13, mean_episode_step = 609.51, total_loss = 821.45, pg_loss = 640.66, baseline_loss = 186.98, entropy_loss = -6.1822, learner_queue_size = 30, _tick = 13433, _time = 1.654e+09, train_seconds = 6868.1)
[2022-05-31 16:04:54,403][root][INFO] - Step 45416960 @ 6648.0 SPS. Inference batcher size: 112. Learner queue size: 1. Other stats: (step = 45416960, mean_episode_return = 126.68, mean_episode_step = 841.19, total_loss = 16.117, pg_loss = -7.2482, baseline_loss = 29.953, entropy_loss = -6.5876, learner_queue_size = 27, _tick = 13444, _time = 1.654e+09, train_seconds = 6873.1)
[2022-05-31 16:04:59,409][root][INFO] - Step 45450240 @ 6648.1 SPS. Inference batcher size: 86. Learner queue size: 20. Other stats: (step = 45450240, mean_episode_return = 226.94, mean_episode_step = 994.03, total_loss = -301.6, pg_loss = -378.28, baseline_loss = 82.972, entropy_loss = -6.2986, learner_queue_size = 11, _tick = 13454, _time = 1.654e+09, train_seconds = 6878.1)
[2022-05-31 16:05:04,416][root][INFO] - Step 45480960 @ 6136.1 SPS. Inference batcher size: 130. Learner queue size: 28. Other stats: (step = 45480960, mean_episode_return = 133.59, mean_episode_step = 840.53, total_loss = -170.36, pg_loss = -248.94, baseline_loss = 84.842, entropy_loss = -6.2623, learner_queue_size = 16, _tick = 13465, _time = 1.654e+09, train_seconds = 6883.1)
[2022-05-31 16:05:09,422][root][INFO] - Step 45514240 @ 6647.9 SPS. Inference batcher size: 136. Learner queue size: 19. Other stats: (step = 45514240, mean_episode_return = 119.87, mean_episode_step = 694.01, total_loss = 34.869, pg_loss = -39.422, baseline_loss = 80.741, entropy_loss = -6.4503, learner_queue_size = 20, _tick = 13476, _time = 1.654e+09, train_seconds = 6888.1)
[2022-05-31 16:05:14,428][root][INFO] - Step 45547520 @ 6647.9 SPS. Inference batcher size: 103. Learner queue size: 19. Other stats: (step = 45547520, mean_episode_return = 32.38, mean_episode_step = 596.82, total_loss = 385.11, pg_loss = 290.64, baseline_loss = 101.02, entropy_loss = -6.5509, learner_queue_size = 20, _tick = 13488, _time = 1.654e+09, train_seconds = 6893.1)
[2022-05-31 16:05:19,430][root][INFO] - Step 45580800 @ 6653.2 SPS. Inference batcher size: 136. Learner queue size: 5. Other stats: (step = 45580800, mean_episode_return = 91.448, mean_episode_step = 1355.5, total_loss = 459.49, pg_loss = 323.6, baseline_loss = 141.81, entropy_loss = -5.9231, learner_queue_size = 17, _tick = 13499, _time = 1.654e+09, train_seconds = 6898.1)
[2022-05-31 16:05:24,434][root][INFO] - Step 45614080 @ 6650.6 SPS. Inference batcher size: 25. Learner queue size: 7. Other stats: (step = 45614080, mean_episode_return = 41.321, mean_episode_step = 1989.3, total_loss = 51.939, pg_loss = 14.76, baseline_loss = 43.435, entropy_loss = -6.2562, learner_queue_size = 14, _tick = 13510, _time = 1.654e+09, train_seconds = 6903.1)
[2022-05-31 16:05:29,438][root][INFO] - Step 45647360 @ 6650.7 SPS. Inference batcher size: 199. Learner queue size: 15. Other stats: (step = 45647360, mean_episode_return = 93.097, mean_episode_step = 648.66, total_loss = 204.83, pg_loss = 90.608, baseline_loss = 120.21, entropy_loss = -5.9819, learner_queue_size = 23, _tick = 13520, _time = 1.654e+09, train_seconds = 6908.1)
[2022-05-31 16:05:34,442][root][INFO] - Step 45680640 @ 6650.7 SPS. Inference batcher size: 109. Learner queue size: 5. Other stats: (step = 45680640, mean_episode_return = None, mean_episode_step = 1013.3, total_loss = 105.76, pg_loss = 66.414, baseline_loss = 45.368, entropy_loss = -6.0226, learner_queue_size = 17, _tick = 13530, _time = 1.654e+09, train_seconds = 6913.1)
[2022-05-31 16:05:39,446][root][INFO] - Step 45713920 @ 6650.7 SPS. Inference batcher size: 137. Learner queue size: 14. Other stats: (step = 45713920, mean_episode_return = 106.91, mean_episode_step = 1298.0, total_loss = -226.7, pg_loss = -245.23, baseline_loss = 24.93, entropy_loss = -6.4072, learner_queue_size = 27, _tick = 13538, _time = 1.654e+09, train_seconds = 6918.1)
[2022-05-31 16:05:44,450][root][INFO] - Step 45747200 @ 6650.7 SPS. Inference batcher size: 39. Learner queue size: 4. Other stats: (step = 45747200, mean_episode_return = 90.501, mean_episode_step = 822.14, total_loss = -243.64, pg_loss = -312.12, baseline_loss = 74.699, entropy_loss = -6.2151, learner_queue_size = 28, _tick = 13551, _time = 1.654e+09, train_seconds = 6923.1)
[2022-05-31 16:05:49,454][root][INFO] - Step 45780480 @ 6650.6 SPS. Inference batcher size: 111. Learner queue size: 4. Other stats: (step = 45780480, mean_episode_return = 358.74, mean_episode_step = 965.13, total_loss = 63.135, pg_loss = -78.627, baseline_loss = 148.04, entropy_loss = -6.2813, learner_queue_size = 16, _tick = 13563, _time = 1.654e+09, train_seconds = 6928.1)
[2022-05-31 16:05:54,458][root][INFO] - Step 45813760 @ 6650.5 SPS. Inference batcher size: 70. Learner queue size: 29. Other stats: (step = 45813760, mean_episode_return = None, mean_episode_step = 781.88, total_loss = -117.51, pg_loss = -145.43, baseline_loss = 34.257, entropy_loss = -6.3411, learner_queue_size = 20, _tick = 13573, _time = 1.654e+09, train_seconds = 6933.1)
[2022-05-31 16:05:59,462][root][INFO] - Step 45847040 @ 6650.9 SPS. Inference batcher size: 120. Learner queue size: 25. Other stats: (step = 45847040, mean_episode_return = 83.92, mean_episode_step = 890.16, total_loss = 432.61, pg_loss = 224.83, baseline_loss = 214.36, entropy_loss = -6.5919, learner_queue_size = 20, _tick = 13582, _time = 1.654e+09, train_seconds = 6938.1)
[2022-05-31 16:06:04,463][root][INFO] - Step 45880320 @ 6654.3 SPS. Inference batcher size: 128. Learner queue size: 20. Other stats: (step = 45880320, mean_episode_return = 59.071, mean_episode_step = 1110.7, total_loss = 122.66, pg_loss = 58.586, baseline_loss = 70.559, entropy_loss = -6.4812, learner_queue_size = 20, _tick = 13594, _time = 1.654e+09, train_seconds = 6943.1)
[2022-05-31 16:06:09,469][root][INFO] - Step 45911040 @ 6136.5 SPS. Inference batcher size: 128. Learner queue size: 19. Other stats: (step = 45911040, mean_episode_return = 257.73, mean_episode_step = 654.43, total_loss = -102.79, pg_loss = -170.98, baseline_loss = 74.913, entropy_loss = -6.7223, learner_queue_size = 20, _tick = 13603, _time = 1.654e+09, train_seconds = 6948.2)
[2022-05-31 16:06:14,475][root][INFO] - Step 45944320 @ 6647.9 SPS. Inference batcher size: 66. Learner queue size: 19. Other stats: (step = 45944320, mean_episode_return = 227.39, mean_episode_step = 907.65, total_loss = 47.353, pg_loss = -92.518, baseline_loss = 145.41, entropy_loss = -5.539, learner_queue_size = 15, _tick = 13616, _time = 1.654e+09, train_seconds = 6953.2)
[2022-05-31 16:06:19,479][root][INFO] - Step 45977600 @ 6651.9 SPS. Inference batcher size: 140. Learner queue size: 15. Other stats: (step = 45977600, mean_episode_return = 307.77, mean_episode_step = 809.98, total_loss = -136.2, pg_loss = -235.93, baseline_loss = 106.18, entropy_loss = -6.4534, learner_queue_size = 30, _tick = 13626, _time = 1.654e+09, train_seconds = 6958.2)
[2022-05-31 16:06:24,483][root][INFO] - Step 46010880 @ 6650.8 SPS. Inference batcher size: 110. Learner queue size: 12. Other stats: (step = 46010880, mean_episode_return = 101.38, mean_episode_step = 890.25, total_loss = -39.519, pg_loss = -65.203, baseline_loss = 32.074, entropy_loss = -6.3899, learner_queue_size = 18, _tick = 13638, _time = 1.654e+09, train_seconds = 6963.2)
[2022-05-31 16:06:29,486][root][INFO] - Step 46044160 @ 6651.2 SPS. Inference batcher size: 190. Learner queue size: 9. Other stats: (step = 46044160, mean_episode_return = 295.62, mean_episode_step = 759.88, total_loss = -52.676, pg_loss = -140.1, baseline_loss = 93.967, entropy_loss = -6.5384, learner_queue_size = 24, _tick = 13650, _time = 1.654e+09, train_seconds = 6968.2)
[2022-05-31 16:06:34,492][root][INFO] - Step 46077440 @ 6647.8 SPS. Inference batcher size: 149. Learner queue size: 5. Other stats: (step = 46077440, mean_episode_return = 135.78, mean_episode_step = 982.37, total_loss = -58.034, pg_loss = -99.803, baseline_loss = 48.37, entropy_loss = -6.6009, learner_queue_size = 21, _tick = 13658, _time = 1.654e+09, train_seconds = 6973.2)
[2022-05-31 16:06:39,498][root][INFO] - Step 46110720 @ 6648.2 SPS. Inference batcher size: 155. Learner queue size: 4. Other stats: (step = 46110720, mean_episode_return = 143.9, mean_episode_step = 842.28, total_loss = 48.355, pg_loss = -20.297, baseline_loss = 75.435, entropy_loss = -6.7835, learner_queue_size = 22, _tick = 13668, _time = 1.654e+09, train_seconds = 6978.2)
[2022-05-31 16:06:44,502][root][INFO] - Step 46144000 @ 6650.7 SPS. Inference batcher size: 37. Learner queue size: 6. Other stats: (step = 46144000, mean_episode_return = 80.014, mean_episode_step = 1241.3, total_loss = -273.51, pg_loss = -306.17, baseline_loss = 39.643, entropy_loss = -6.9837, learner_queue_size = 15, _tick = 13677, _time = 1.654e+09, train_seconds = 6983.2)
[2022-05-31 16:06:49,507][root][INFO] - Step 46177280 @ 6650.0 SPS. Inference batcher size: 56. Learner queue size: 4. Other stats: (step = 46177280, mean_episode_return = 223.61, mean_episode_step = 761.67, total_loss = -28.287, pg_loss = -58.197, baseline_loss = 36.415, entropy_loss = -6.5053, learner_queue_size = 28, _tick = 13689, _time = 1.654e+09, train_seconds = 6988.2)
[2022-05-31 16:06:54,510][root][INFO] - Step 46210560 @ 6651.4 SPS. Inference batcher size: 117. Learner queue size: 1. Other stats: (step = 46210560, mean_episode_return = 135.96, mean_episode_step = 1275.1, total_loss = -181.92, pg_loss = -336.45, baseline_loss = 161.21, entropy_loss = -6.6816, learner_queue_size = 8, _tick = 13701, _time = 1.654e+09, train_seconds = 6993.2)
[2022-05-31 16:06:59,514][root][INFO] - Step 46243840 @ 6650.7 SPS. Inference batcher size: 87. Learner queue size: 3. Other stats: (step = 46243840, mean_episode_return = 68.737, mean_episode_step = 2151.1, total_loss = 229.0, pg_loss = 189.74, baseline_loss = 45.491, entropy_loss = -6.2271, learner_queue_size = 30, _tick = 13711, _time = 1.654e+09, train_seconds = 6998.2)
[2022-05-31 16:07:04,518][root][INFO] - Step 46277120 @ 6650.7 SPS. Inference batcher size: 37. Learner queue size: 24. Other stats: (step = 46277120, mean_episode_return = 137.17, mean_episode_step = 884.17, total_loss = -144.69, pg_loss = -198.7, baseline_loss = 60.269, entropy_loss = -6.2592, learner_queue_size = 10, _tick = 13723, _time = 1.654e+09, train_seconds = 7003.2)
[2022-05-31 16:07:09,522][root][INFO] - Step 46310400 @ 6650.6 SPS. Inference batcher size: 61. Learner queue size: 26. Other stats: (step = 46310400, mean_episode_return = 179.39, mean_episode_step = 1388.0, total_loss = 174.34, pg_loss = 110.28, baseline_loss = 70.495, entropy_loss = -6.4388, learner_queue_size = 20, _tick = 13735, _time = 1.654e+09, train_seconds = 7008.2)
[2022-05-31 16:07:14,526][root][INFO] - Step 46343680 @ 6650.8 SPS. Inference batcher size: 40. Learner queue size: 31. Other stats: (step = 46343680, mean_episode_return = 102.57, mean_episode_step = 2275.8, total_loss = -144.91, pg_loss = -172.61, baseline_loss = 34.138, entropy_loss = -6.4442, learner_queue_size = 20, _tick = 13745, _time = 1.654e+09, train_seconds = 7013.2)
[2022-05-31 16:07:19,530][root][INFO] - Step 46376960 @ 6650.6 SPS. Inference batcher size: 63. Learner queue size: 23. Other stats: (step = 46376960, mean_episode_return = 41.016, mean_episode_step = 866.34, total_loss = -41.949, pg_loss = -88.936, baseline_loss = 53.77, entropy_loss = -6.7826, learner_queue_size = 15, _tick = 13757, _time = 1.654e+09, train_seconds = 7018.2)
[2022-05-31 16:07:24,534][root][INFO] - Step 46410240 @ 6650.7 SPS. Inference batcher size: 53. Learner queue size: 29. Other stats: (step = 46410240, mean_episode_return = 59.37, mean_episode_step = 1384.2, total_loss = 188.61, pg_loss = 132.33, baseline_loss = 62.459, entropy_loss = -6.1776, learner_queue_size = 27, _tick = 13768, _time = 1.654e+09, train_seconds = 7023.2)
[2022-05-31 16:07:29,540][root][INFO] - Step 46440960 @ 6136.5 SPS. Inference batcher size: 156. Learner queue size: 16. Other stats: (step = 46440960, mean_episode_return = 201.86, mean_episode_step = 829.82, total_loss = -23.559, pg_loss = -63.888, baseline_loss = 46.486, entropy_loss = -6.1571, learner_queue_size = 12, _tick = 13778, _time = 1.654e+09, train_seconds = 7028.2)
[2022-05-31 16:07:34,546][root][INFO] - Step 46474240 @ 6647.6 SPS. Inference batcher size: 95. Learner queue size: 18. Other stats: (step = 46474240, mean_episode_return = 157.01, mean_episode_step = 1166.4, total_loss = 7.6598, pg_loss = -39.931, baseline_loss = 54.141, entropy_loss = -6.5505, learner_queue_size = 15, _tick = 13789, _time = 1.654e+09, train_seconds = 7033.2)
[2022-05-31 16:07:39,555][root][INFO] - Step 46507520 @ 6644.3 SPS. Inference batcher size: 96. Learner queue size: 11. Other stats: (step = 46507520, mean_episode_return = 136.96, mean_episode_step = 698.08, total_loss = -2.7659, pg_loss = -70.809, baseline_loss = 74.48, entropy_loss = -6.4375, learner_queue_size = 19, _tick = 13801, _time = 1.654e+09, train_seconds = 7038.2)
[2022-05-31 16:07:44,558][root][INFO] - Step 46540800 @ 6652.2 SPS. Inference batcher size: 106. Learner queue size: 10. Other stats: (step = 46540800, mean_episode_return = 86.94, mean_episode_step = 744.05, total_loss = 320.23, pg_loss = 116.09, baseline_loss = 210.33, entropy_loss = -6.188, learner_queue_size = 23, _tick = 13813, _time = 1.654e+09, train_seconds = 7043.2)
[2022-05-31 16:07:49,562][root][INFO] - Step 46574080 @ 6650.7 SPS. Inference batcher size: 153. Learner queue size: 10. Other stats: (step = 46574080, mean_episode_return = 319.3, mean_episode_step = 1049.9, total_loss = -9.0901, pg_loss = -75.38, baseline_loss = 72.796, entropy_loss = -6.5057, learner_queue_size = 19, _tick = 13824, _time = 1.654e+09, train_seconds = 7048.2)
[2022-05-31 16:07:54,568][root][INFO] - Step 46607360 @ 6647.4 SPS. Inference batcher size: 114. Learner queue size: 3. Other stats: (step = 46607360, mean_episode_return = 30.08, mean_episode_step = 2241.6, total_loss = 382.39, pg_loss = 280.92, baseline_loss = 107.79, entropy_loss = -6.3196, learner_queue_size = 12, _tick = 13837, _time = 1.654e+09, train_seconds = 7053.3)
[2022-05-31 16:07:59,574][root][INFO] - Step 46640640 @ 6648.6 SPS. Inference batcher size: 83. Learner queue size: 11. Other stats: (step = 46640640, mean_episode_return = None, mean_episode_step = 657.94, total_loss = 18.621, pg_loss = -11.785, baseline_loss = 37.003, entropy_loss = -6.5974, learner_queue_size = 26, _tick = 13848, _time = 1.654e+09, train_seconds = 7058.3)
[2022-05-31 16:08:04,578][root][INFO] - Step 46673920 @ 6650.6 SPS. Inference batcher size: 43. Learner queue size: 8. Other stats: (step = 46673920, mean_episode_return = None, mean_episode_step = 1023.4, total_loss = 97.696, pg_loss = 84.186, baseline_loss = 19.545, entropy_loss = -6.0353, learner_queue_size = 28, _tick = 13859, _time = 1.654e+09, train_seconds = 7063.3)
[2022-05-31 16:08:09,582][root][INFO] - Step 46707200 @ 6650.8 SPS. Inference batcher size: 130. Learner queue size: 5. Other stats: (step = 46707200, mean_episode_return = 158.95, mean_episode_step = 878.57, total_loss = 4.6522, pg_loss = -36.189, baseline_loss = 47.058, entropy_loss = -6.2169, learner_queue_size = 14, _tick = 13870, _time = 1.654e+09, train_seconds = 7068.3)
[2022-05-31 16:08:14,588][root][INFO] - Step 46740480 @ 6648.4 SPS. Inference batcher size: 116. Learner queue size: 5. Other stats: (step = 46740480, mean_episode_return = 155.19, mean_episode_step = 802.97, total_loss = 114.41, pg_loss = -27.456, baseline_loss = 148.14, entropy_loss = -6.265, learner_queue_size = 10, _tick = 13881, _time = 1.654e+09, train_seconds = 7073.3)
[2022-05-31 16:08:19,594][root][INFO] - Step 46771200 @ 6136.4 SPS. Inference batcher size: 19. Learner queue size: 19. Other stats: (step = 46771200, mean_episode_return = 257.2, mean_episode_step = 2100.9, total_loss = -28.175, pg_loss = -95.817, baseline_loss = 74.194, entropy_loss = -6.5512, learner_queue_size = 10, _tick = 13893, _time = 1.654e+09, train_seconds = 7078.3)
[2022-05-31 16:08:24,598][root][INFO] - Step 46807040 @ 7161.8 SPS. Inference batcher size: 13. Learner queue size: 21. Other stats: (step = 46807040, mean_episode_return = None, mean_episode_step = 904.56, total_loss = 121.3, pg_loss = 102.4, baseline_loss = 25.51, entropy_loss = -6.6173, learner_queue_size = 17, _tick = 13905, _time = 1.654e+09, train_seconds = 7083.3)
[2022-05-31 16:08:29,602][root][INFO] - Step 46837760 @ 6139.0 SPS. Inference batcher size: 3. Learner queue size: 23. Other stats: (step = 46837760, mean_episode_return = 151.49, mean_episode_step = 657.49, total_loss = 7.0853, pg_loss = -21.382, baseline_loss = 34.907, entropy_loss = -6.44, learner_queue_size = 22, _tick = 13916, _time = 1.654e+09, train_seconds = 7088.3)
[2022-05-31 16:08:34,611][root][INFO] - Step 46871040 @ 6644.5 SPS. Inference batcher size: 55. Learner queue size: 3. Other stats: (step = 46871040, mean_episode_return = 107.38, mean_episode_step = 841.58, total_loss = 29.345, pg_loss = 6.2116, baseline_loss = 29.482, entropy_loss = -6.3485, learner_queue_size = 20, _tick = 13926, _time = 1.654e+09, train_seconds = 7093.3)
[2022-05-31 16:08:39,614][root][INFO] - Step 46904320 @ 6652.0 SPS. Inference batcher size: 127. Learner queue size: 19. Other stats: (step = 46904320, mean_episode_return = 101.05, mean_episode_step = 1010.5, total_loss = 8.9518, pg_loss = -51.635, baseline_loss = 66.659, entropy_loss = -6.0716, learner_queue_size = 15, _tick = 13936, _time = 1.654e+09, train_seconds = 7098.3)
[2022-05-31 16:08:44,619][root][INFO] - Step 46937600 @ 6649.8 SPS. Inference batcher size: 17. Learner queue size: 15. Other stats: (step = 46937600, mean_episode_return = 141.28, mean_episode_step = 950.21, total_loss = -253.08, pg_loss = -293.72, baseline_loss = 47.415, entropy_loss = -6.7816, learner_queue_size = 21, _tick = 13944, _time = 1.654e+09, train_seconds = 7103.3)
[2022-05-31 16:08:49,622][root][INFO] - Step 46970880 @ 6651.5 SPS. Inference batcher size: 173. Learner queue size: 10. Other stats: (step = 46970880, mean_episode_return = 56.8, mean_episode_step = 860.47, total_loss = 312.59, pg_loss = 205.97, baseline_loss = 113.5, entropy_loss = -6.8798, learner_queue_size = 18, _tick = 13954, _time = 1.654e+09, train_seconds = 7108.3)
[2022-05-31 16:08:54,626][root][INFO] - Step 47004160 @ 6650.7 SPS. Inference batcher size: 130. Learner queue size: 9. Other stats: (step = 47004160, mean_episode_return = 129.9, mean_episode_step = 1177.6, total_loss = -29.846, pg_loss = -73.747, baseline_loss = 50.398, entropy_loss = -6.4966, learner_queue_size = 19, _tick = 13964, _time = 1.654e+09, train_seconds = 7113.3)
[2022-05-31 16:08:59,630][root][INFO] - Step 47037440 @ 6650.7 SPS. Inference batcher size: 123. Learner queue size: 23. Other stats: (step = 47037440, mean_episode_return = 61.062, mean_episode_step = 1116.7, total_loss = -169.69, pg_loss = -207.9, baseline_loss = 45.021, entropy_loss = -6.8167, learner_queue_size = 13, _tick = 13973, _time = 1.654e+09, train_seconds = 7118.3)
[2022-05-31 16:09:04,636][root][INFO] - Step 47070720 @ 6647.9 SPS. Inference batcher size: 149. Learner queue size: 6. Other stats: (step = 47070720, mean_episode_return = 177.76, mean_episode_step = 1045.4, total_loss = 38.862, pg_loss = 1.7293, baseline_loss = 43.793, entropy_loss = -6.6598, learner_queue_size = 17, _tick = 13983, _time = 1.654e+09, train_seconds = 7123.3)
[2022-05-31 16:09:09,642][root][INFO] - Step 47104000 @ 6648.2 SPS. Inference batcher size: 190. Learner queue size: 27. Other stats: (step = 47104000, mean_episode_return = 98.458, mean_episode_step = 988.52, total_loss = 54.03, pg_loss = -13.16, baseline_loss = 73.759, entropy_loss = -6.569, learner_queue_size = 23, _tick = 13996, _time = 1.654e+09, train_seconds = 7128.3)
[2022-05-31 16:09:14,646][root][INFO] - Step 47137280 @ 6650.7 SPS. Inference batcher size: 81. Learner queue size: 19. Other stats: (step = 47137280, mean_episode_return = 233.86, mean_episode_step = 1357.0, total_loss = 294.66, pg_loss = 189.1, baseline_loss = 112.19, entropy_loss = -6.6202, learner_queue_size = 16, _tick = 14006, _time = 1.654e+09, train_seconds = 7133.3)
[2022-05-31 16:09:19,650][root][INFO] - Step 47170560 @ 6650.6 SPS. Inference batcher size: 43. Learner queue size: 14. Other stats: (step = 47170560, mean_episode_return = 151.82, mean_episode_step = 1173.1, total_loss = 272.5, pg_loss = 131.54, baseline_loss = 147.51, entropy_loss = -6.5569, learner_queue_size = 14, _tick = 14016, _time = 1.654e+09, train_seconds = 7138.3)
[2022-05-31 16:09:24,654][root][INFO] - Step 47201280 @ 6139.1 SPS. Inference batcher size: 127. Learner queue size: 18. Other stats: (step = 47201280, mean_episode_return = 133.86, mean_episode_step = 843.13, total_loss = -85.332, pg_loss = -149.53, baseline_loss = 70.34, entropy_loss = -6.1419, learner_queue_size = 17, _tick = 14026, _time = 1.654e+09, train_seconds = 7143.3)
[2022-05-31 16:09:29,660][root][INFO] - Step 47234560 @ 6648.0 SPS. Inference batcher size: 151. Learner queue size: 16. Other stats: (step = 47234560, mean_episode_return = 113.71, mean_episode_step = 1075.5, total_loss = -30.643, pg_loss = -57.967, baseline_loss = 33.869, entropy_loss = -6.5447, learner_queue_size = 23, _tick = 14039, _time = 1.654e+09, train_seconds = 7148.3)
[2022-05-31 16:09:34,666][root][INFO] - Step 47267840 @ 6647.6 SPS. Inference batcher size: 93. Learner queue size: 31. Other stats: (step = 47267840, mean_episode_return = 115.45, mean_episode_step = 761.18, total_loss = 325.73, pg_loss = 173.79, baseline_loss = 157.75, entropy_loss = -5.8147, learner_queue_size = 16, _tick = 14051, _time = 1.654e+09, train_seconds = 7153.4)
[2022-05-31 16:09:39,670][root][INFO] - Step 47301120 @ 6651.2 SPS. Inference batcher size: 74. Learner queue size: 30. Other stats: (step = 47301120, mean_episode_return = 75.06, mean_episode_step = 1139.3, total_loss = 284.87, pg_loss = 150.36, baseline_loss = 140.64, entropy_loss = -6.1287, learner_queue_size = 14, _tick = 14062, _time = 1.654e+09, train_seconds = 7158.4)
[2022-05-31 16:09:44,674][root][INFO] - Step 47334400 @ 6650.6 SPS. Inference batcher size: 118. Learner queue size: 29. Other stats: (step = 47334400, mean_episode_return = 26.51, mean_episode_step = 542.29, total_loss = 89.957, pg_loss = 42.736, baseline_loss = 53.365, entropy_loss = -6.1446, learner_queue_size = 17, _tick = 14073, _time = 1.654e+09, train_seconds = 7163.4)
[2022-05-31 16:09:49,678][root][INFO] - Step 47365120 @ 6139.1 SPS. Inference batcher size: 145. Learner queue size: 19. Other stats: (step = 47365120, mean_episode_return = 60.099, mean_episode_step = 603.17, total_loss = 364.39, pg_loss = 229.17, baseline_loss = 141.88, entropy_loss = -6.6622, learner_queue_size = 23, _tick = 14082, _time = 1.654e+09, train_seconds = 7168.4)
[2022-05-31 16:09:54,682][root][INFO] - Step 47398400 @ 6650.7 SPS. Inference batcher size: 163. Learner queue size: 13. Other stats: (step = 47398400, mean_episode_return = 214.55, mean_episode_step = 2189.5, total_loss = -44.23, pg_loss = -87.467, baseline_loss = 49.185, entropy_loss = -5.9484, learner_queue_size = 22, _tick = 14093, _time = 1.654e+09, train_seconds = 7173.4)
[2022-05-31 16:09:59,686][root][INFO] - Step 47431680 @ 6650.8 SPS. Inference batcher size: 93. Learner queue size: 10. Other stats: (step = 47431680, mean_episode_return = 99.05, mean_episode_step = 882.87, total_loss = 91.335, pg_loss = -80.437, baseline_loss = 177.99, entropy_loss = -6.2222, learner_queue_size = 17, _tick = 14104, _time = 1.654e+09, train_seconds = 7178.4)
[2022-05-31 16:10:04,690][root][INFO] - Step 47464960 @ 6650.6 SPS. Inference batcher size: 139. Learner queue size: 3. Other stats: (step = 47464960, mean_episode_return = 68.12, mean_episode_step = 1076.2, total_loss = 102.99, pg_loss = 24.082, baseline_loss = 85.359, entropy_loss = -6.4479, learner_queue_size = 20, _tick = 14115, _time = 1.654e+09, train_seconds = 7183.4)
[2022-05-31 16:10:09,694][root][INFO] - Step 47498240 @ 6650.5 SPS. Inference batcher size: 24. Learner queue size: 31. Other stats: (step = 47498240, mean_episode_return = 110.58, mean_episode_step = 1065.9, total_loss = 338.37, pg_loss = 191.59, baseline_loss = 153.12, entropy_loss = -6.3432, learner_queue_size = 10, _tick = 14124, _time = 1.654e+09, train_seconds = 7188.4)
[2022-05-31 16:10:14,701][root][INFO] - Step 47528960 @ 6136.1 SPS. Inference batcher size: 131. Learner queue size: 16. Other stats: (step = 47528960, mean_episode_return = 94.437, mean_episode_step = 864.92, total_loss = 107.84, pg_loss = 73.045, baseline_loss = 40.998, entropy_loss = -6.1995, learner_queue_size = 16, _tick = 14134, _time = 1.654e+09, train_seconds = 7193.4)
[2022-05-31 16:10:19,707][root][INFO] - Step 47562240 @ 6648.0 SPS. Inference batcher size: 108. Learner queue size: 20. Other stats: (step = 47562240, mean_episode_return = 53.051, mean_episode_step = 2127.3, total_loss = -25.983, pg_loss = -106.27, baseline_loss = 86.433, entropy_loss = -6.1421, learner_queue_size = 17, _tick = 14144, _time = 1.654e+09, train_seconds = 7198.4)
[2022-05-31 16:10:24,710][root][INFO] - Step 47595520 @ 6651.5 SPS. Inference batcher size: 119. Learner queue size: 21. Other stats: (step = 47595520, mean_episode_return = 307.62, mean_episode_step = 768.96, total_loss = -102.76, pg_loss = -230.18, baseline_loss = 133.94, entropy_loss = -6.5196, learner_queue_size = 24, _tick = 14155, _time = 1.654e+09, train_seconds = 7203.4)
[2022-05-31 16:10:29,714][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 16:10:29,825][root][INFO] - Step 47628800 @ 6650.5 SPS. Inference batcher size: 73. Learner queue size: 19. Other stats: (step = 47628800, mean_episode_return = 85.451, mean_episode_step = 788.16, total_loss = 185.52, pg_loss = 95.264, baseline_loss = 96.876, entropy_loss = -6.6156, learner_queue_size = 8, _tick = 14167, _time = 1.654e+09, train_seconds = 7208.4)
[2022-05-31 16:10:34,831][root][INFO] - Step 47662080 @ 6503.5 SPS. Inference batcher size: 125. Learner queue size: 12. Other stats: (step = 47662080, mean_episode_return = 152.44, mean_episode_step = 658.05, total_loss = 279.81, pg_loss = 119.2, baseline_loss = 166.74, entropy_loss = -6.1338, learner_queue_size = 20, _tick = 14177, _time = 1.654e+09, train_seconds = 7213.5)
[2022-05-31 16:10:39,838][root][INFO] - Step 47695360 @ 6647.8 SPS. Inference batcher size: 29. Learner queue size: 22. Other stats: (step = 47695360, mean_episode_return = 137.7, mean_episode_step = 835.08, total_loss = -179.48, pg_loss = -210.15, baseline_loss = 37.547, entropy_loss = -6.8781, learner_queue_size = 11, _tick = 14186, _time = 1.654e+09, train_seconds = 7218.5)
[2022-05-31 16:10:44,842][root][INFO] - Step 47728640 @ 6649.9 SPS. Inference batcher size: 89. Learner queue size: 4. Other stats: (step = 47728640, mean_episode_return = 149.18, mean_episode_step = 1270.8, total_loss = -70.007, pg_loss = -103.42, baseline_loss = 39.844, entropy_loss = -6.4317, learner_queue_size = 20, _tick = 14198, _time = 1.654e+09, train_seconds = 7223.5)
[2022-05-31 16:10:49,846][root][INFO] - Step 47761920 @ 6650.7 SPS. Inference batcher size: 128. Learner queue size: 12. Other stats: (step = 47761920, mean_episode_return = 112.64, mean_episode_step = 1128.4, total_loss = 160.51, pg_loss = 139.02, baseline_loss = 26.837, entropy_loss = -5.3529, learner_queue_size = 21, _tick = 14209, _time = 1.654e+09, train_seconds = 7228.5)
[2022-05-31 16:10:54,850][root][INFO] - Step 47795200 @ 6650.7 SPS. Inference batcher size: 102. Learner queue size: 2. Other stats: (step = 47795200, mean_episode_return = None, mean_episode_step = 936.5, total_loss = 105.84, pg_loss = 49.671, baseline_loss = 63.034, entropy_loss = -6.8643, learner_queue_size = 26, _tick = 14219, _time = 1.654e+09, train_seconds = 7233.5)
[2022-05-31 16:10:59,856][root][INFO] - Step 47828480 @ 6648.0 SPS. Inference batcher size: 118. Learner queue size: 2. Other stats: (step = 47828480, mean_episode_return = None, mean_episode_step = 1171.4, total_loss = 104.74, pg_loss = 46.146, baseline_loss = 64.772, entropy_loss = -6.1792, learner_queue_size = 13, _tick = 14230, _time = 1.654e+09, train_seconds = 7238.5)
[2022-05-31 16:11:04,862][root][INFO] - Step 47861760 @ 6648.1 SPS. Inference batcher size: 70. Learner queue size: 27. Other stats: (step = 47861760, mean_episode_return = 118.82, mean_episode_step = 1148.9, total_loss = -35.73, pg_loss = -75.034, baseline_loss = 45.347, entropy_loss = -6.0434, learner_queue_size = 16, _tick = 14242, _time = 1.654e+09, train_seconds = 7243.5)
[2022-05-31 16:11:09,868][root][INFO] - Step 47892480 @ 6136.6 SPS. Inference batcher size: 119. Learner queue size: 18. Other stats: (step = 47892480, mean_episode_return = 98.999, mean_episode_step = 1420.8, total_loss = -62.56, pg_loss = -72.258, baseline_loss = 16.721, entropy_loss = -7.0237, learner_queue_size = 11, _tick = 14253, _time = 1.654e+09, train_seconds = 7248.6)
[2022-05-31 16:11:14,874][root][INFO] - Step 47925760 @ 6648.1 SPS. Inference batcher size: 204. Learner queue size: 16. Other stats: (step = 47925760, mean_episode_return = 146.11, mean_episode_step = 2320.6, total_loss = 294.91, pg_loss = 212.84, baseline_loss = 87.977, entropy_loss = -5.9042, learner_queue_size = 15, _tick = 14264, _time = 1.654e+09, train_seconds = 7253.6)
[2022-05-31 16:11:19,878][root][INFO] - Step 47959040 @ 6650.6 SPS. Inference batcher size: 124. Learner queue size: 13. Other stats: (step = 47959040, mean_episode_return = 273.44, mean_episode_step = 901.0, total_loss = -159.71, pg_loss = -215.82, baseline_loss = 62.199, entropy_loss = -6.0951, learner_queue_size = 21, _tick = 14275, _time = 1.654e+09, train_seconds = 7258.6)
[2022-05-31 16:11:24,882][root][INFO] - Step 47992320 @ 6650.7 SPS. Inference batcher size: 93. Learner queue size: 8. Other stats: (step = 47992320, mean_episode_return = 305.03, mean_episode_step = 788.66, total_loss = 15.896, pg_loss = -30.799, baseline_loss = 53.807, entropy_loss = -7.1131, learner_queue_size = 19, _tick = 14284, _time = 1.654e+09, train_seconds = 7263.6)
[2022-05-31 16:11:29,888][root][INFO] - Step 48025600 @ 6647.9 SPS. Inference batcher size: 83. Learner queue size: 2. Other stats: (step = 48025600, mean_episode_return = 174.38, mean_episode_step = 752.75, total_loss = 270.57, pg_loss = 199.74, baseline_loss = 77.398, entropy_loss = -6.5689, learner_queue_size = 12, _tick = 14297, _time = 1.654e+09, train_seconds = 7268.6)
[2022-05-31 16:11:34,894][root][INFO] - Step 48058880 @ 6648.1 SPS. Inference batcher size: 76. Learner queue size: 5. Other stats: (step = 48058880, mean_episode_return = None, mean_episode_step = 738.59, total_loss = 67.692, pg_loss = 9.3931, baseline_loss = 64.828, entropy_loss = -6.5296, learner_queue_size = 17, _tick = 14306, _time = 1.654e+09, train_seconds = 7273.6)
[2022-05-31 16:11:39,898][root][INFO] - Step 48089600 @ 6139.0 SPS. Inference batcher size: 145. Learner queue size: 23. Other stats: (step = 48089600, mean_episode_return = 98.746, mean_episode_step = 1100.6, total_loss = 388.46, pg_loss = 296.78, baseline_loss = 98.294, entropy_loss = -6.6166, learner_queue_size = 25, _tick = 14317, _time = 1.654e+09, train_seconds = 7278.6)
[2022-05-31 16:11:44,902][root][INFO] - Step 48125440 @ 7162.3 SPS. Inference batcher size: 112. Learner queue size: 26. Other stats: (step = 48125440, mean_episode_return = 277.92, mean_episode_step = 970.4, total_loss = 52.434, pg_loss = 21.151, baseline_loss = 37.864, entropy_loss = -6.5811, learner_queue_size = 24, _tick = 14329, _time = 1.654e+09, train_seconds = 7283.6)
[2022-05-31 16:11:49,908][root][INFO] - Step 48156160 @ 6136.5 SPS. Inference batcher size: 68. Learner queue size: 21. Other stats: (step = 48156160, mean_episode_return = 108.59, mean_episode_step = 880.02, total_loss = 423.29, pg_loss = 263.06, baseline_loss = 166.16, entropy_loss = -5.9437, learner_queue_size = 23, _tick = 14337, _time = 1.654e+09, train_seconds = 7288.6)
[2022-05-31 16:11:54,914][root][INFO] - Step 48192000 @ 7159.5 SPS. Inference batcher size: 148. Learner queue size: 16. Other stats: (step = 48192000, mean_episode_return = 156.66, mean_episode_step = 913.55, total_loss = 31.405, pg_loss = -34.938, baseline_loss = 72.476, entropy_loss = -6.1324, learner_queue_size = 16, _tick = 14348, _time = 1.654e+09, train_seconds = 7293.6)
[2022-05-31 16:11:59,917][root][INFO] - Step 48222720 @ 6140.6 SPS. Inference batcher size: 122. Learner queue size: 23. Other stats: (step = 48222720, mean_episode_return = 83.995, mean_episode_step = 890.64, total_loss = 32.82, pg_loss = -9.0103, baseline_loss = 48.77, entropy_loss = -6.9391, learner_queue_size = 27, _tick = 14357, _time = 1.654e+09, train_seconds = 7298.6)
[2022-05-31 16:12:04,922][root][INFO] - Step 48256000 @ 6649.1 SPS. Inference batcher size: 11. Learner queue size: 14. Other stats: (step = 48256000, mean_episode_return = 115.35, mean_episode_step = 924.96, total_loss = -54.903, pg_loss = -70.617, baseline_loss = 22.39, entropy_loss = -6.6748, learner_queue_size = 15, _tick = 14368, _time = 1.654e+09, train_seconds = 7303.6)
[2022-05-31 16:12:09,926][root][INFO] - Step 48289280 @ 6650.6 SPS. Inference batcher size: 72. Learner queue size: 15. Other stats: (step = 48289280, mean_episode_return = 86.784, mean_episode_step = 1100.5, total_loss = 189.84, pg_loss = 159.93, baseline_loss = 36.119, entropy_loss = -6.2019, learner_queue_size = 29, _tick = 14378, _time = 1.654e+09, train_seconds = 7308.6)
[2022-05-31 16:12:14,932][root][INFO] - Step 48322560 @ 6647.6 SPS. Inference batcher size: 139. Learner queue size: 2. Other stats: (step = 48322560, mean_episode_return = 272.74, mean_episode_step = 857.96, total_loss = 46.664, pg_loss = -106.9, baseline_loss = 160.33, entropy_loss = -6.7693, learner_queue_size = 20, _tick = 14390, _time = 1.654e+09, train_seconds = 7313.6)
[2022-05-31 16:12:19,938][root][INFO] - Step 48355840 @ 6648.5 SPS. Inference batcher size: 87. Learner queue size: 13. Other stats: (step = 48355840, mean_episode_return = 111.02, mean_episode_step = 1227.5, total_loss = 92.686, pg_loss = 17.455, baseline_loss = 81.412, entropy_loss = -6.1812, learner_queue_size = 19, _tick = 14401, _time = 1.654e+09, train_seconds = 7318.6)
[2022-05-31 16:12:24,943][root][INFO] - Step 48389120 @ 6649.3 SPS. Inference batcher size: 24. Learner queue size: 3. Other stats: (step = 48389120, mean_episode_return = 64.941, mean_episode_step = 674.04, total_loss = 266.48, pg_loss = 132.64, baseline_loss = 139.85, entropy_loss = -6.0023, learner_queue_size = 26, _tick = 14412, _time = 1.654e+09, train_seconds = 7323.6)
[2022-05-31 16:12:29,950][root][INFO] - Step 48422400 @ 6646.6 SPS. Inference batcher size: 166. Learner queue size: 31. Other stats: (step = 48422400, mean_episode_return = 209.12, mean_episode_step = 927.61, total_loss = 33.626, pg_loss = -23.03, baseline_loss = 63.114, entropy_loss = -6.4581, learner_queue_size = 25, _tick = 14423, _time = 1.654e+09, train_seconds = 7328.6)
[2022-05-31 16:12:34,954][root][INFO] - Step 48455680 @ 6650.6 SPS. Inference batcher size: 121. Learner queue size: 1. Other stats: (step = 48455680, mean_episode_return = 148.11, mean_episode_step = 2517.5, total_loss = -48.534, pg_loss = -120.66, baseline_loss = 78.636, entropy_loss = -6.5091, learner_queue_size = 25, _tick = 14433, _time = 1.654e+09, train_seconds = 7333.6)
[2022-05-31 16:12:39,960][root][INFO] - Step 48486400 @ 6136.5 SPS. Inference batcher size: 128. Learner queue size: 17. Other stats: (step = 48486400, mean_episode_return = 193.47, mean_episode_step = 705.53, total_loss = 13.014, pg_loss = -31.215, baseline_loss = 50.931, entropy_loss = -6.7014, learner_queue_size = 16, _tick = 14444, _time = 1.654e+09, train_seconds = 7338.6)
[2022-05-31 16:12:44,966][root][INFO] - Step 48522240 @ 7159.7 SPS. Inference batcher size: 89. Learner queue size: 12. Other stats: (step = 48522240, mean_episode_return = 71.281, mean_episode_step = 1203.8, total_loss = 106.64, pg_loss = 24.245, baseline_loss = 88.849, entropy_loss = -6.4497, learner_queue_size = 10, _tick = 14456, _time = 1.654e+09, train_seconds = 7343.7)
[2022-05-31 16:12:49,970][root][INFO] - Step 48555520 @ 6650.6 SPS. Inference batcher size: 118. Learner queue size: 21. Other stats: (step = 48555520, mean_episode_return = 170.57, mean_episode_step = 1203.3, total_loss = 593.3, pg_loss = 429.22, baseline_loss = 170.54, entropy_loss = -6.4566, learner_queue_size = 20, _tick = 14468, _time = 1.654e+09, train_seconds = 7348.7)
[2022-05-31 16:12:54,974][root][INFO] - Step 48586240 @ 6139.3 SPS. Inference batcher size: 145. Learner queue size: 15. Other stats: (step = 48586240, mean_episode_return = 170.76, mean_episode_step = 968.21, total_loss = 181.44, pg_loss = 106.85, baseline_loss = 81.329, entropy_loss = -6.7436, learner_queue_size = 17, _tick = 14479, _time = 1.654e+09, train_seconds = 7353.7)
[2022-05-31 16:12:59,979][root][INFO] - Step 48622080 @ 7161.5 SPS. Inference batcher size: 61. Learner queue size: 18. Other stats: (step = 48622080, mean_episode_return = 112.89, mean_episode_step = 910.01, total_loss = -39.859, pg_loss = -122.41, baseline_loss = 89.189, entropy_loss = -6.6422, learner_queue_size = 18, _tick = 14491, _time = 1.654e+09, train_seconds = 7358.7)
[2022-05-31 16:13:04,985][root][INFO] - Step 48655360 @ 6647.6 SPS. Inference batcher size: 66. Learner queue size: 13. Other stats: (step = 48655360, mean_episode_return = 36.146, mean_episode_step = 1148.8, total_loss = -147.69, pg_loss = -163.49, baseline_loss = 22.838, entropy_loss = -7.0369, learner_queue_size = 13, _tick = 14502, _time = 1.654e+09, train_seconds = 7363.7)
[2022-05-31 16:13:09,991][root][INFO] - Step 48686080 @ 6136.3 SPS. Inference batcher size: 111. Learner queue size: 15. Other stats: (step = 48686080, mean_episode_return = 137.75, mean_episode_step = 682.55, total_loss = 184.63, pg_loss = 89.099, baseline_loss = 102.35, entropy_loss = -6.8195, learner_queue_size = 7, _tick = 14510, _time = 1.654e+09, train_seconds = 7368.7)
[2022-05-31 16:13:14,994][root][INFO] - Step 48719360 @ 6652.1 SPS. Inference batcher size: 131. Learner queue size: 17. Other stats: (step = 48719360, mean_episode_return = 377.13, mean_episode_step = 2662.4, total_loss = 56.638, pg_loss = -49.815, baseline_loss = 113.54, entropy_loss = -7.087, learner_queue_size = 13, _tick = 14522, _time = 1.654e+09, train_seconds = 7373.7)
[2022-05-31 16:13:19,998][root][INFO] - Step 48752640 @ 6650.7 SPS. Inference batcher size: 221. Learner queue size: 3. Other stats: (step = 48752640, mean_episode_return = 204.77, mean_episode_step = 952.53, total_loss = 181.8, pg_loss = 97.391, baseline_loss = 91.719, entropy_loss = -7.3073, learner_queue_size = 18, _tick = 14531, _time = 1.654e+09, train_seconds = 7378.7)
[2022-05-31 16:13:25,004][root][INFO] - Step 48785920 @ 6647.4 SPS. Inference batcher size: 25. Learner queue size: 28. Other stats: (step = 48785920, mean_episode_return = 182.34, mean_episode_step = 1269.5, total_loss = -50.955, pg_loss = -65.018, baseline_loss = 20.648, entropy_loss = -6.5856, learner_queue_size = 17, _tick = 14543, _time = 1.654e+09, train_seconds = 7383.7)
[2022-05-31 16:13:30,010][root][INFO] - Step 48816640 @ 6137.2 SPS. Inference batcher size: 135. Learner queue size: 26. Other stats: (step = 48816640, mean_episode_return = None, mean_episode_step = 823.38, total_loss = 44.436, pg_loss = -9.1858, baseline_loss = 60.219, entropy_loss = -6.5975, learner_queue_size = 14, _tick = 14551, _time = 1.654e+09, train_seconds = 7388.7)
[2022-05-31 16:13:35,014][root][INFO] - Step 48849920 @ 6650.6 SPS. Inference batcher size: 178. Learner queue size: 17. Other stats: (step = 48849920, mean_episode_return = None, mean_episode_step = 955.72, total_loss = -83.852, pg_loss = -142.07, baseline_loss = 65.097, entropy_loss = -6.8821, learner_queue_size = 21, _tick = 14563, _time = 1.654e+09, train_seconds = 7393.7)
[2022-05-31 16:13:40,020][root][INFO] - Step 48883200 @ 6647.9 SPS. Inference batcher size: 112. Learner queue size: 23. Other stats: (step = 48883200, mean_episode_return = 135.61, mean_episode_step = 1081.0, total_loss = -72.89, pg_loss = -109.25, baseline_loss = 42.873, entropy_loss = -6.5172, learner_queue_size = 14, _tick = 14575, _time = 1.654e+09, train_seconds = 7398.7)
[2022-05-31 16:13:45,026][root][INFO] - Step 48916480 @ 6648.2 SPS. Inference batcher size: 102. Learner queue size: 9. Other stats: (step = 48916480, mean_episode_return = 135.83, mean_episode_step = 800.77, total_loss = 119.5, pg_loss = -8.6794, baseline_loss = 134.54, entropy_loss = -6.3623, learner_queue_size = 24, _tick = 14587, _time = 1.654e+09, train_seconds = 7403.7)
[2022-05-31 16:13:50,030][root][INFO] - Step 48949760 @ 6650.7 SPS. Inference batcher size: 136. Learner queue size: 11. Other stats: (step = 48949760, mean_episode_return = 99.93, mean_episode_step = 837.99, total_loss = 197.57, pg_loss = 110.63, baseline_loss = 93.577, entropy_loss = -6.6363, learner_queue_size = 24, _tick = 14597, _time = 1.654e+09, train_seconds = 7408.7)
[2022-05-31 16:13:55,034][root][INFO] - Step 48983040 @ 6650.1 SPS. Inference batcher size: 132. Learner queue size: 3. Other stats: (step = 48983040, mean_episode_return = 267.22, mean_episode_step = 2424.5, total_loss = -61.2, pg_loss = -95.875, baseline_loss = 41.358, entropy_loss = -6.6829, learner_queue_size = 14, _tick = 14608, _time = 1.654e+09, train_seconds = 7413.7)
[2022-05-31 16:14:00,038][root][INFO] - Step 49016320 @ 6651.2 SPS. Inference batcher size: 0. Learner queue size: 23. Other stats: (step = 49016320, mean_episode_return = 102.61, mean_episode_step = 797.16, total_loss = -39.969, pg_loss = -116.03, baseline_loss = 82.369, entropy_loss = -6.3121, learner_queue_size = 15, _tick = 14618, _time = 1.654e+09, train_seconds = 7418.7)
[2022-05-31 16:14:05,042][root][INFO] - Step 49049600 @ 6650.7 SPS. Inference batcher size: 149. Learner queue size: 0. Other stats: (step = 49049600, mean_episode_return = 102.9, mean_episode_step = 889.05, total_loss = 618.89, pg_loss = 397.15, baseline_loss = 227.75, entropy_loss = -6.0113, learner_queue_size = 14, _tick = 14629, _time = 1.654e+09, train_seconds = 7423.7)
[2022-05-31 16:14:10,048][root][INFO] - Step 49080320 @ 6136.4 SPS. Inference batcher size: 180. Learner queue size: 17. Other stats: (step = 49080320, mean_episode_return = 133.8, mean_episode_step = 981.45, total_loss = -34.693, pg_loss = -116.71, baseline_loss = 87.922, entropy_loss = -5.9058, learner_queue_size = 24, _tick = 14640, _time = 1.654e+09, train_seconds = 7428.7)
[2022-05-31 16:14:15,054][root][INFO] - Step 49116160 @ 7159.5 SPS. Inference batcher size: 57. Learner queue size: 16. Other stats: (step = 49116160, mean_episode_return = None, mean_episode_step = 819.19, total_loss = 14.253, pg_loss = -47.112, baseline_loss = 67.543, entropy_loss = -6.1783, learner_queue_size = 12, _tick = 14650, _time = 1.654e+09, train_seconds = 7433.7)
[2022-05-31 16:14:20,060][root][INFO] - Step 49146880 @ 6136.7 SPS. Inference batcher size: 127. Learner queue size: 19. Other stats: (step = 49146880, mean_episode_return = 183.49, mean_episode_step = 1257.8, total_loss = 279.43, pg_loss = 209.36, baseline_loss = 76.31, entropy_loss = -6.2404, learner_queue_size = 22, _tick = 14660, _time = 1.654e+09, train_seconds = 7438.7)
[2022-05-31 16:14:25,066][root][INFO] - Step 49180160 @ 6648.0 SPS. Inference batcher size: 168. Learner queue size: 11. Other stats: (step = 49180160, mean_episode_return = 15.75, mean_episode_step = 1133.7, total_loss = -56.554, pg_loss = -89.795, baseline_loss = 40.214, entropy_loss = -6.9739, learner_queue_size = 20, _tick = 14672, _time = 1.654e+09, train_seconds = 7443.8)
[2022-05-31 16:14:30,070][root][INFO] - Step 49213440 @ 6650.3 SPS. Inference batcher size: 46. Learner queue size: 7. Other stats: (step = 49213440, mean_episode_return = 144.02, mean_episode_step = 2672.2, total_loss = 201.23, pg_loss = 113.54, baseline_loss = 94.022, entropy_loss = -6.3371, learner_queue_size = 16, _tick = 14684, _time = 1.654e+09, train_seconds = 7448.8)
[2022-05-31 16:14:35,077][root][INFO] - Step 49246720 @ 6647.5 SPS. Inference batcher size: 135. Learner queue size: 3. Other stats: (step = 49246720, mean_episode_return = 106.49, mean_episode_step = 893.22, total_loss = -164.58, pg_loss = -208.37, baseline_loss = 50.414, entropy_loss = -6.6296, learner_queue_size = 21, _tick = 14697, _time = 1.654e+09, train_seconds = 7453.8)
[2022-05-31 16:14:40,082][root][INFO] - Step 49280000 @ 6649.0 SPS. Inference batcher size: 166. Learner queue size: 21. Other stats: (step = 49280000, mean_episode_return = 126.97, mean_episode_step = 906.5, total_loss = -26.347, pg_loss = -60.931, baseline_loss = 40.93, entropy_loss = -6.3459, learner_queue_size = 15, _tick = 14710, _time = 1.654e+09, train_seconds = 7458.8)
[2022-05-31 16:14:45,088][root][INFO] - Step 49310720 @ 6136.6 SPS. Inference batcher size: 121. Learner queue size: 16. Other stats: (step = 49310720, mean_episode_return = 273.52, mean_episode_step = 829.98, total_loss = 276.72, pg_loss = 170.56, baseline_loss = 111.96, entropy_loss = -5.8033, learner_queue_size = 21, _tick = 14721, _time = 1.654e+09, train_seconds = 7463.8)
[2022-05-31 16:14:50,094][root][INFO] - Step 49344000 @ 6648.0 SPS. Inference batcher size: 81. Learner queue size: 8. Other stats: (step = 49344000, mean_episode_return = 128.16, mean_episode_step = 710.57, total_loss = 256.8, pg_loss = 39.63, baseline_loss = 223.43, entropy_loss = -6.2609, learner_queue_size = 27, _tick = 14733, _time = 1.654e+09, train_seconds = 7468.8)
[2022-05-31 16:14:55,098][root][INFO] - Step 49377280 @ 6650.6 SPS. Inference batcher size: 53. Learner queue size: 11. Other stats: (step = 49377280, mean_episode_return = 108.72, mean_episode_step = 714.98, total_loss = 217.8, pg_loss = 99.311, baseline_loss = 124.53, entropy_loss = -6.0434, learner_queue_size = 19, _tick = 14745, _time = 1.654e+09, train_seconds = 7473.8)
[2022-05-31 16:15:00,102][root][INFO] - Step 49410560 @ 6650.8 SPS. Inference batcher size: 81. Learner queue size: 6. Other stats: (step = 49410560, mean_episode_return = 104.04, mean_episode_step = 751.93, total_loss = 61.516, pg_loss = 9.5007, baseline_loss = 58.046, entropy_loss = -6.0313, learner_queue_size = 18, _tick = 14755, _time = 1.654e+09, train_seconds = 7478.8)
[2022-05-31 16:15:05,108][root][INFO] - Step 49443840 @ 6648.1 SPS. Inference batcher size: 123. Learner queue size: 2. Other stats: (step = 49443840, mean_episode_return = 58.151, mean_episode_step = 779.77, total_loss = 29.109, pg_loss = 2.5743, baseline_loss = 33.089, entropy_loss = -6.5548, learner_queue_size = 15, _tick = 14767, _time = 1.654e+09, train_seconds = 7483.8)
[2022-05-31 16:15:10,114][root][INFO] - Step 49474560 @ 6137.1 SPS. Inference batcher size: 69. Learner queue size: 17. Other stats: (step = 49474560, mean_episode_return = 142.24, mean_episode_step = 898.84, total_loss = 125.35, pg_loss = 8.1461, baseline_loss = 123.82, entropy_loss = -6.6154, learner_queue_size = 17, _tick = 14778, _time = 1.654e+09, train_seconds = 7488.8)
[2022-05-31 16:15:15,118][root][INFO] - Step 49507840 @ 6650.1 SPS. Inference batcher size: 160. Learner queue size: 24. Other stats: (step = 49507840, mean_episode_return = 218.39, mean_episode_step = 1309.9, total_loss = 93.351, pg_loss = 44.607, baseline_loss = 55.11, entropy_loss = -6.3663, learner_queue_size = 25, _tick = 14789, _time = 1.654e+09, train_seconds = 7493.8)
[2022-05-31 16:15:20,122][root][INFO] - Step 49541120 @ 6650.7 SPS. Inference batcher size: 67. Learner queue size: 14. Other stats: (step = 49541120, mean_episode_return = 79.94, mean_episode_step = 619.99, total_loss = 311.65, pg_loss = 221.1, baseline_loss = 96.386, entropy_loss = -5.8359, learner_queue_size = 16, _tick = 14801, _time = 1.654e+09, train_seconds = 7498.8)
[2022-05-31 16:15:25,126][root][INFO] - Step 49574400 @ 6650.7 SPS. Inference batcher size: 94. Learner queue size: 2. Other stats: (step = 49574400, mean_episode_return = 138.04, mean_episode_step = 1024.9, total_loss = 124.73, pg_loss = 86.676, baseline_loss = 44.57, entropy_loss = -6.5205, learner_queue_size = 11, _tick = 14813, _time = 1.654e+09, train_seconds = 7503.8)
[2022-05-31 16:15:30,130][root][INFO] - Step 49607680 @ 6650.7 SPS. Inference batcher size: 121. Learner queue size: 3. Other stats: (step = 49607680, mean_episode_return = 108.4, mean_episode_step = 835.62, total_loss = 66.401, pg_loss = -40.987, baseline_loss = 113.27, entropy_loss = -5.8797, learner_queue_size = 19, _tick = 14824, _time = 1.654e+09, train_seconds = 7508.8)
[2022-05-31 16:15:35,136][root][INFO] - Step 49640960 @ 6647.6 SPS. Inference batcher size: 89. Learner queue size: 5. Other stats: (step = 49640960, mean_episode_return = 55.66, mean_episode_step = 2536.2, total_loss = -75.497, pg_loss = -77.757, baseline_loss = 8.9863, entropy_loss = -6.7263, learner_queue_size = 28, _tick = 14836, _time = 1.654e+09, train_seconds = 7513.8)
[2022-05-31 16:15:40,143][root][INFO] - Step 49674240 @ 6647.9 SPS. Inference batcher size: 72. Learner queue size: 22. Other stats: (step = 49674240, mean_episode_return = 113.19, mean_episode_step = 890.85, total_loss = 154.43, pg_loss = 45.007, baseline_loss = 116.04, entropy_loss = -6.6207, learner_queue_size = 22, _tick = 14847, _time = 1.654e+09, train_seconds = 7518.8)
[2022-05-31 16:15:45,146][root][INFO] - Step 49704960 @ 6139.5 SPS. Inference batcher size: 172. Learner queue size: 14. Other stats: (step = 49704960, mean_episode_return = 139.93, mean_episode_step = 711.36, total_loss = 187.57, pg_loss = 89.805, baseline_loss = 103.93, entropy_loss = -6.1647, learner_queue_size = 23, _tick = 14858, _time = 1.654e+09, train_seconds = 7523.8)
[2022-05-31 16:15:50,151][root][INFO] - Step 49738240 @ 6649.9 SPS. Inference batcher size: 150. Learner queue size: 16. Other stats: (step = 49738240, mean_episode_return = None, mean_episode_step = 914.31, total_loss = 331.29, pg_loss = 161.0, baseline_loss = 176.44, entropy_loss = -6.1506, learner_queue_size = 9, _tick = 14869, _time = 1.654e+09, train_seconds = 7528.8)
[2022-05-31 16:15:55,154][root][INFO] - Step 49771520 @ 6651.6 SPS. Inference batcher size: 85. Learner queue size: 10. Other stats: (step = 49771520, mean_episode_return = 107.76, mean_episode_step = 1151.3, total_loss = -274.09, pg_loss = -317.14, baseline_loss = 49.196, entropy_loss = -6.1541, learner_queue_size = 18, _tick = 14880, _time = 1.654e+09, train_seconds = 7533.8)
[2022-05-31 16:16:00,161][root][INFO] - Step 49804800 @ 6646.0 SPS. Inference batcher size: 70. Learner queue size: 3. Other stats: (step = 49804800, mean_episode_return = 270.85, mean_episode_step = 628.96, total_loss = 171.07, pg_loss = 91.316, baseline_loss = 85.799, entropy_loss = -6.0441, learner_queue_size = 22, _tick = 14890, _time = 1.654e+09, train_seconds = 7538.8)
[2022-05-31 16:16:05,164][root][INFO] - Step 49838080 @ 6653.0 SPS. Inference batcher size: 111. Learner queue size: 3. Other stats: (step = 49838080, mean_episode_return = None, mean_episode_step = 711.19, total_loss = 372.16, pg_loss = 243.56, baseline_loss = 134.69, entropy_loss = -6.0873, learner_queue_size = 22, _tick = 14901, _time = 1.654e+09, train_seconds = 7543.8)
[2022-05-31 16:16:10,166][root][INFO] - Step 49871360 @ 6652.9 SPS. Inference batcher size: 97. Learner queue size: 29. Other stats: (step = 49871360, mean_episode_return = 248.93, mean_episode_step = 916.2, total_loss = -62.674, pg_loss = -148.41, baseline_loss = 91.957, entropy_loss = -6.2257, learner_queue_size = 15, _tick = 14912, _time = 1.654e+09, train_seconds = 7548.9)
[2022-05-31 16:16:15,173][root][INFO] - Step 49902080 @ 6136.0 SPS. Inference batcher size: 95. Learner queue size: 22. Other stats: (step = 49902080, mean_episode_return = 168.1, mean_episode_step = 899.28, total_loss = 361.23, pg_loss = 276.48, baseline_loss = 91.069, entropy_loss = -6.3231, learner_queue_size = 18, _tick = 14924, _time = 1.654e+09, train_seconds = 7553.9)
[2022-05-31 16:16:20,179][root][INFO] - Step 49935360 @ 6648.0 SPS. Inference batcher size: 106. Learner queue size: 18. Other stats: (step = 49935360, mean_episode_return = 40.74, mean_episode_step = 995.67, total_loss = 233.95, pg_loss = 164.81, baseline_loss = 75.322, entropy_loss = -6.1745, learner_queue_size = 21, _tick = 14936, _time = 1.654e+09, train_seconds = 7558.9)
[2022-05-31 16:16:25,183][root][INFO] - Step 49971200 @ 7162.3 SPS. Inference batcher size: 83. Learner queue size: 19. Other stats: (step = 49971200, mean_episode_return = 107.2, mean_episode_step = 794.27, total_loss = 112.73, pg_loss = 59.369, baseline_loss = 57.914, entropy_loss = -4.5542, learner_queue_size = 18, _tick = 14948, _time = 1.654e+09, train_seconds = 7563.9)
[2022-05-31 16:16:30,189][root][INFO] - Step 50001920 @ 6136.0 SPS. Inference batcher size: 124. Learner queue size: 20. Other stats: (step = 50001920, mean_episode_return = 109.84, mean_episode_step = 1067.1, total_loss = 102.63, pg_loss = 99.902, baseline_loss = 9.6759, entropy_loss = -6.947, learner_queue_size = 32, _tick = 14956, _time = 1.654e+09, train_seconds = 7568.9)
[2022-05-31 16:16:35,194][root][INFO] - Step 50035200 @ 6649.6 SPS. Inference batcher size: 151. Learner queue size: 16. Other stats: (step = 50035200, mean_episode_return = 124.7, mean_episode_step = 865.95, total_loss = -71.109, pg_loss = -82.47, baseline_loss = 17.602, entropy_loss = -6.2419, learner_queue_size = 12, _tick = 14969, _time = 1.654e+09, train_seconds = 7573.9)
[2022-05-31 16:16:40,198][root][INFO] - Step 50068480 @ 6650.6 SPS. Inference batcher size: 217. Learner queue size: 5. Other stats: (step = 50068480, mean_episode_return = 104.92, mean_episode_step = 2569.6, total_loss = -114.76, pg_loss = -137.43, baseline_loss = 28.994, entropy_loss = -6.3266, learner_queue_size = 16, _tick = 14975, _time = 1.654e+09, train_seconds = 7578.9)
[2022-05-31 16:16:45,202][root][INFO] - Step 50101760 @ 6650.6 SPS. Inference batcher size: 94. Learner queue size: 27. Other stats: (step = 50101760, mean_episode_return = None, mean_episode_step = 922.38, total_loss = 230.97, pg_loss = 187.15, baseline_loss = 50.363, entropy_loss = -6.5468, learner_queue_size = 15, _tick = 14987, _time = 1.654e+09, train_seconds = 7583.9)
[2022-05-31 16:16:50,206][root][INFO] - Step 50135040 @ 6650.7 SPS. Inference batcher size: 122. Learner queue size: 21. Other stats: (step = 50135040, mean_episode_return = 185.44, mean_episode_step = 1074.0, total_loss = -80.428, pg_loss = -103.42, baseline_loss = 29.401, entropy_loss = -6.4116, learner_queue_size = 20, _tick = 15000, _time = 1.654e+09, train_seconds = 7588.9)
[2022-05-31 16:16:55,210][root][INFO] - Step 50168320 @ 6650.7 SPS. Inference batcher size: 169. Learner queue size: 3. Other stats: (step = 50168320, mean_episode_return = None, mean_episode_step = 743.72, total_loss = 262.17, pg_loss = 183.66, baseline_loss = 84.658, entropy_loss = -6.1479, learner_queue_size = 19, _tick = 15011, _time = 1.654e+09, train_seconds = 7593.9)
[2022-05-31 16:17:00,214][root][INFO] - Step 50201600 @ 6650.6 SPS. Inference batcher size: 49. Learner queue size: 29. Other stats: (step = 50201600, mean_episode_return = None, mean_episode_step = 1159.0, total_loss = 34.572, pg_loss = 8.0329, baseline_loss = 32.986, entropy_loss = -6.4473, learner_queue_size = 16, _tick = 15021, _time = 1.654e+09, train_seconds = 7598.9)
[2022-05-31 16:17:05,220][root][INFO] - Step 50234880 @ 6647.5 SPS. Inference batcher size: 47. Learner queue size: 18. Other stats: (step = 50234880, mean_episode_return = 177.42, mean_episode_step = 773.01, total_loss = -99.567, pg_loss = -238.33, baseline_loss = 145.12, entropy_loss = -6.3501, learner_queue_size = 15, _tick = 15033, _time = 1.654e+09, train_seconds = 7603.9)
[2022-05-31 16:17:10,227][root][INFO] - Step 50265600 @ 6136.5 SPS. Inference batcher size: 27. Learner queue size: 21. Other stats: (step = 50265600, mean_episode_return = 172.37, mean_episode_step = 725.48, total_loss = 132.91, pg_loss = 99.104, baseline_loss = 39.951, entropy_loss = -6.1446, learner_queue_size = 23, _tick = 15044, _time = 1.654e+09, train_seconds = 7608.9)
[2022-05-31 16:17:15,228][root][INFO] - Step 50298880 @ 6653.6 SPS. Inference batcher size: 111. Learner queue size: 16. Other stats: (step = 50298880, mean_episode_return = 100.63, mean_episode_step = 682.14, total_loss = 279.56, pg_loss = 160.76, baseline_loss = 125.03, entropy_loss = -6.2243, learner_queue_size = 23, _tick = 15056, _time = 1.654e+09, train_seconds = 7613.9)
[2022-05-31 16:17:20,234][root][INFO] - Step 50332160 @ 6648.0 SPS. Inference batcher size: 94. Learner queue size: 19. Other stats: (step = 50332160, mean_episode_return = 182.92, mean_episode_step = 884.02, total_loss = 617.97, pg_loss = 253.5, baseline_loss = 370.45, entropy_loss = -5.9842, learner_queue_size = 18, _tick = 15067, _time = 1.654e+09, train_seconds = 7618.9)
[2022-05-31 16:17:25,238][root][INFO] - Step 50365440 @ 6651.2 SPS. Inference batcher size: 109. Learner queue size: 27. Other stats: (step = 50365440, mean_episode_return = 423.8, mean_episode_step = 1115.2, total_loss = -162.61, pg_loss = -252.3, baseline_loss = 95.941, entropy_loss = -6.2524, learner_queue_size = 14, _tick = 15078, _time = 1.654e+09, train_seconds = 7623.9)
[2022-05-31 16:17:30,244][root][INFO] - Step 50398720 @ 6647.9 SPS. Inference batcher size: 40. Learner queue size: 15. Other stats: (step = 50398720, mean_episode_return = 224.53, mean_episode_step = 733.25, total_loss = 475.35, pg_loss = 281.8, baseline_loss = 199.41, entropy_loss = -5.8616, learner_queue_size = 25, _tick = 15089, _time = 1.654e+09, train_seconds = 7628.9)
[2022-05-31 16:17:35,250][root][INFO] - Step 50432000 @ 6648.0 SPS. Inference batcher size: 184. Learner queue size: 23. Other stats: (step = 50432000, mean_episode_return = 139.96, mean_episode_step = 2604.0, total_loss = 54.197, pg_loss = -0.8204, baseline_loss = 61.604, entropy_loss = -6.5876, learner_queue_size = 13, _tick = 15100, _time = 1.654e+09, train_seconds = 7633.9)
[2022-05-31 16:17:40,254][root][INFO] - Step 50465280 @ 6650.8 SPS. Inference batcher size: 130. Learner queue size: 3. Other stats: (step = 50465280, mean_episode_return = 114.17, mean_episode_step = 1221.0, total_loss = 179.61, pg_loss = 119.93, baseline_loss = 66.146, entropy_loss = -6.4666, learner_queue_size = 17, _tick = 15113, _time = 1.654e+09, train_seconds = 7638.9)
[2022-05-31 16:17:45,260][root][INFO] - Step 50498560 @ 6648.4 SPS. Inference batcher size: 78. Learner queue size: 5. Other stats: (step = 50498560, mean_episode_return = 225.51, mean_episode_step = 545.42, total_loss = 219.23, pg_loss = 151.03, baseline_loss = 74.494, entropy_loss = -6.2933, learner_queue_size = 14, _tick = 15125, _time = 1.654e+09, train_seconds = 7643.9)
[2022-05-31 16:17:50,265][root][INFO] - Step 50531840 @ 6648.5 SPS. Inference batcher size: 136. Learner queue size: 3. Other stats: (step = 50531840, mean_episode_return = 147.35, mean_episode_step = 2566.5, total_loss = 62.968, pg_loss = 22.91, baseline_loss = 46.357, entropy_loss = -6.2981, learner_queue_size = 25, _tick = 15137, _time = 1.654e+09, train_seconds = 7649.0)
[2022-05-31 16:17:55,270][root][INFO] - Step 50565120 @ 6649.8 SPS. Inference batcher size: 49. Learner queue size: 19. Other stats: (step = 50565120, mean_episode_return = 168.86, mean_episode_step = 1002.4, total_loss = 389.1, pg_loss = 239.53, baseline_loss = 155.84, entropy_loss = -6.2766, learner_queue_size = 19, _tick = 15147, _time = 1.654e+09, train_seconds = 7654.0)
[2022-05-31 16:18:00,274][root][INFO] - Step 50598400 @ 6650.9 SPS. Inference batcher size: 103. Learner queue size: 27. Other stats: (step = 50598400, mean_episode_return = None, mean_episode_step = 629.75, total_loss = 650.11, pg_loss = 366.88, baseline_loss = 289.63, entropy_loss = -6.3894, learner_queue_size = 13, _tick = 15159, _time = 1.654e+09, train_seconds = 7659.0)
[2022-05-31 16:18:05,279][root][INFO] - Step 50629120 @ 6137.1 SPS. Inference batcher size: 125. Learner queue size: 14. Other stats: (step = 50629120, mean_episode_return = 333.25, mean_episode_step = 738.64, total_loss = -141.68, pg_loss = -190.04, baseline_loss = 54.529, entropy_loss = -6.1702, learner_queue_size = 19, _tick = 15170, _time = 1.654e+09, train_seconds = 7664.0)
[2022-05-31 16:18:10,282][root][INFO] - Step 50662400 @ 6652.8 SPS. Inference batcher size: 47. Learner queue size: 17. Other stats: (step = 50662400, mean_episode_return = 148.39, mean_episode_step = 862.83, total_loss = 236.65, pg_loss = 148.85, baseline_loss = 94.522, entropy_loss = -6.7134, learner_queue_size = 22, _tick = 15182, _time = 1.654e+09, train_seconds = 7669.0)
[2022-05-31 16:18:15,286][root][INFO] - Step 50695680 @ 6650.7 SPS. Inference batcher size: 102. Learner queue size: 14. Other stats: (step = 50695680, mean_episode_return = None, mean_episode_step = 883.03, total_loss = 57.646, pg_loss = 24.026, baseline_loss = 40.167, entropy_loss = -6.5461, learner_queue_size = 26, _tick = 15193, _time = 1.654e+09, train_seconds = 7674.0)
[2022-05-31 16:18:20,290][root][INFO] - Step 50728960 @ 6650.7 SPS. Inference batcher size: 50. Learner queue size: 16. Other stats: (step = 50728960, mean_episode_return = 272.04, mean_episode_step = 880.12, total_loss = 327.52, pg_loss = 191.87, baseline_loss = 141.52, entropy_loss = -5.8705, learner_queue_size = 12, _tick = 15206, _time = 1.654e+09, train_seconds = 7679.0)
[2022-05-31 16:18:25,296][root][INFO] - Step 50762240 @ 6648.2 SPS. Inference batcher size: 145. Learner queue size: 8. Other stats: (step = 50762240, mean_episode_return = 154.77, mean_episode_step = 659.89, total_loss = -25.565, pg_loss = -70.042, baseline_loss = 50.503, entropy_loss = -6.026, learner_queue_size = 11, _tick = 15219, _time = 1.654e+09, train_seconds = 7684.0)
[2022-05-31 16:18:30,298][root][INFO] - Step 50795520 @ 6653.1 SPS. Inference batcher size: 96. Learner queue size: 4. Other stats: (step = 50795520, mean_episode_return = 249.36, mean_episode_step = 2637.5, total_loss = 37.641, pg_loss = -20.688, baseline_loss = 64.611, entropy_loss = -6.2825, learner_queue_size = 25, _tick = 15231, _time = 1.654e+09, train_seconds = 7689.0)
[2022-05-31 16:18:35,302][root][INFO] - Step 50828800 @ 6650.6 SPS. Inference batcher size: 102. Learner queue size: 26. Other stats: (step = 50828800, mean_episode_return = 54.161, mean_episode_step = 730.0, total_loss = 270.23, pg_loss = 197.06, baseline_loss = 79.202, entropy_loss = -6.0336, learner_queue_size = 20, _tick = 15242, _time = 1.654e+09, train_seconds = 7694.0)
[2022-05-31 16:18:40,306][root][INFO] - Step 50862080 @ 6650.8 SPS. Inference batcher size: 101. Learner queue size: 22. Other stats: (step = 50862080, mean_episode_return = 48.73, mean_episode_step = 791.32, total_loss = -35.196, pg_loss = -60.834, baseline_loss = 31.957, entropy_loss = -6.319, learner_queue_size = 18, _tick = 15252, _time = 1.654e+09, train_seconds = 7699.0)
[2022-05-31 16:18:45,310][root][INFO] - Step 50892800 @ 6139.1 SPS. Inference batcher size: 117. Learner queue size: 19. Other stats: (step = 50892800, mean_episode_return = 154.33, mean_episode_step = 1004.2, total_loss = -115.85, pg_loss = -159.29, baseline_loss = 49.511, entropy_loss = -6.0775, learner_queue_size = 17, _tick = 15263, _time = 1.654e+09, train_seconds = 7704.0)
[2022-05-31 16:18:50,314][root][INFO] - Step 50926080 @ 6650.5 SPS. Inference batcher size: 147. Learner queue size: 20. Other stats: (step = 50926080, mean_episode_return = 149.12, mean_episode_step = 914.69, total_loss = 53.206, pg_loss = 5.2932, baseline_loss = 54.64, entropy_loss = -6.7275, learner_queue_size = 16, _tick = 15275, _time = 1.654e+09, train_seconds = 7709.0)
[2022-05-31 16:18:55,318][root][INFO] - Step 50959360 @ 6650.7 SPS. Inference batcher size: 108. Learner queue size: 15. Other stats: (step = 50959360, mean_episode_return = 166.36, mean_episode_step = 2777.3, total_loss = 42.9, pg_loss = 10.84, baseline_loss = 38.569, entropy_loss = -6.5095, learner_queue_size = 12, _tick = 15288, _time = 1.654e+09, train_seconds = 7714.0)
[2022-05-31 16:19:00,322][root][INFO] - Step 50992640 @ 6650.8 SPS. Inference batcher size: 56. Learner queue size: 10. Other stats: (step = 50992640, mean_episode_return = 252.77, mean_episode_step = 1226.3, total_loss = -51.747, pg_loss = -86.408, baseline_loss = 41.262, entropy_loss = -6.6014, learner_queue_size = 14, _tick = 15297, _time = 1.654e+09, train_seconds = 7719.0)
[2022-05-31 16:19:05,328][root][INFO] - Step 51025920 @ 6647.9 SPS. Inference batcher size: 12. Learner queue size: 8. Other stats: (step = 51025920, mean_episode_return = 91.948, mean_episode_step = 802.76, total_loss = 37.163, pg_loss = 4.1555, baseline_loss = 39.573, entropy_loss = -6.5655, learner_queue_size = 26, _tick = 15306, _time = 1.654e+09, train_seconds = 7724.0)
[2022-05-31 16:19:10,334][root][INFO] - Step 51059200 @ 6648.1 SPS. Inference batcher size: 71. Learner queue size: 10. Other stats: (step = 51059200, mean_episode_return = 29.366, mean_episode_step = 1206.7, total_loss = 406.38, pg_loss = 286.13, baseline_loss = 126.68, entropy_loss = -6.4246, learner_queue_size = 16, _tick = 15319, _time = 1.654e+09, train_seconds = 7729.0)
[2022-05-31 16:19:15,340][root][INFO] - Step 51092480 @ 6647.3 SPS. Inference batcher size: 140. Learner queue size: 4. Other stats: (step = 51092480, mean_episode_return = 105.03, mean_episode_step = 927.17, total_loss = 61.645, pg_loss = -2.557, baseline_loss = 70.619, entropy_loss = -6.4166, learner_queue_size = 21, _tick = 15327, _time = 1.654e+09, train_seconds = 7734.0)
[2022-05-31 16:19:20,346][root][INFO] - Step 51125760 @ 6648.6 SPS. Inference batcher size: 85. Learner queue size: 1. Other stats: (step = 51125760, mean_episode_return = 85.729, mean_episode_step = 946.0, total_loss = 57.572, pg_loss = 17.321, baseline_loss = 46.59, entropy_loss = -6.3384, learner_queue_size = 19, _tick = 15339, _time = 1.654e+09, train_seconds = 7739.0)
[2022-05-31 16:19:25,350][root][INFO] - Step 51159040 @ 6650.8 SPS. Inference batcher size: 101. Learner queue size: 3. Other stats: (step = 51159040, mean_episode_return = 69.144, mean_episode_step = 905.6, total_loss = 370.55, pg_loss = 120.99, baseline_loss = 255.64, entropy_loss = -6.0746, learner_queue_size = 19, _tick = 15352, _time = 1.654e+09, train_seconds = 7744.0)
[2022-05-31 16:19:30,354][root][INFO] - Step 51192320 @ 6650.5 SPS. Inference batcher size: 149. Learner queue size: 29. Other stats: (step = 51192320, mean_episode_return = 103.06, mean_episode_step = 817.41, total_loss = 204.43, pg_loss = 122.88, baseline_loss = 88.142, entropy_loss = -6.5908, learner_queue_size = 29, _tick = 15365, _time = 1.654e+09, train_seconds = 7749.0)
[2022-05-31 16:19:35,358][root][INFO] - Step 51223040 @ 6138.7 SPS. Inference batcher size: 30. Learner queue size: 16. Other stats: (step = 51223040, mean_episode_return = 158.88, mean_episode_step = 1175.7, total_loss = 41.417, pg_loss = 11.047, baseline_loss = 36.941, entropy_loss = -6.5715, learner_queue_size = 19, _tick = 15375, _time = 1.654e+09, train_seconds = 7754.0)
[2022-05-31 16:19:40,365][root][INFO] - Step 51256320 @ 6647.6 SPS. Inference batcher size: 97. Learner queue size: 22. Other stats: (step = 51256320, mean_episode_return = 81.416, mean_episode_step = 898.21, total_loss = 294.15, pg_loss = 219.19, baseline_loss = 81.273, entropy_loss = -6.3123, learner_queue_size = 19, _tick = 15387, _time = 1.654e+09, train_seconds = 7759.0)
[2022-05-31 16:19:45,370][root][INFO] - Step 51289600 @ 6649.0 SPS. Inference batcher size: 22. Learner queue size: 16. Other stats: (step = 51289600, mean_episode_return = 76.591, mean_episode_step = 748.41, total_loss = 153.32, pg_loss = -39.758, baseline_loss = 199.45, entropy_loss = -6.3744, learner_queue_size = 21, _tick = 15400, _time = 1.654e+09, train_seconds = 7764.1)
[2022-05-31 16:19:50,375][root][INFO] - Step 51322880 @ 6649.4 SPS. Inference batcher size: 61. Learner queue size: 5. Other stats: (step = 51322880, mean_episode_return = None, mean_episode_step = 885.53, total_loss = 152.67, pg_loss = 82.173, baseline_loss = 76.514, entropy_loss = -6.0164, learner_queue_size = 25, _tick = 15411, _time = 1.654e+09, train_seconds = 7769.1)
[2022-05-31 16:19:55,381][root][INFO] - Step 51356160 @ 6647.9 SPS. Inference batcher size: 61. Learner queue size: 30. Other stats: (step = 51356160, mean_episode_return = 87.935, mean_episode_step = 815.3, total_loss = 115.58, pg_loss = 54.571, baseline_loss = 67.126, entropy_loss = -6.1181, learner_queue_size = 17, _tick = 15423, _time = 1.654e+09, train_seconds = 7774.1)
[2022-05-31 16:20:00,386][root][INFO] - Step 51389440 @ 6649.4 SPS. Inference batcher size: 65. Learner queue size: 30. Other stats: (step = 51389440, mean_episode_return = 170.51, mean_episode_step = 702.03, total_loss = 106.05, pg_loss = -25.133, baseline_loss = 136.98, entropy_loss = -5.7957, learner_queue_size = 21, _tick = 15434, _time = 1.654e+09, train_seconds = 7779.1)
[2022-05-31 16:20:05,390][root][INFO] - Step 51420160 @ 6139.1 SPS. Inference batcher size: 121. Learner queue size: 21. Other stats: (step = 51420160, mean_episode_return = 89.963, mean_episode_step = 461.21, total_loss = 277.86, pg_loss = 177.0, baseline_loss = 106.55, entropy_loss = -5.6855, learner_queue_size = 19, _tick = 15445, _time = 1.654e+09, train_seconds = 7784.1)
[2022-05-31 16:20:10,396][root][INFO] - Step 51453440 @ 6648.0 SPS. Inference batcher size: 121. Learner queue size: 12. Other stats: (step = 51453440, mean_episode_return = 48.481, mean_episode_step = 557.89, total_loss = 128.31, pg_loss = 81.688, baseline_loss = 52.724, entropy_loss = -6.1002, learner_queue_size = 28, _tick = 15457, _time = 1.654e+09, train_seconds = 7789.1)
[2022-05-31 16:20:15,402][root][INFO] - Step 51486720 @ 6647.9 SPS. Inference batcher size: 86. Learner queue size: 7. Other stats: (step = 51486720, mean_episode_return = 172.27, mean_episode_step = 990.99, total_loss = -86.957, pg_loss = -146.53, baseline_loss = 65.975, entropy_loss = -6.4036, learner_queue_size = 24, _tick = 15470, _time = 1.654e+09, train_seconds = 7794.1)
[2022-05-31 16:20:20,408][root][INFO] - Step 51520000 @ 6648.0 SPS. Inference batcher size: 48. Learner queue size: 2. Other stats: (step = 51520000, mean_episode_return = 194.78, mean_episode_step = 816.99, total_loss = 355.78, pg_loss = 245.81, baseline_loss = 116.25, entropy_loss = -6.2767, learner_queue_size = 18, _tick = 15482, _time = 1.654e+09, train_seconds = 7799.1)
[2022-05-31 16:20:25,414][root][INFO] - Step 51553280 @ 6648.1 SPS. Inference batcher size: 105. Learner queue size: 21. Other stats: (step = 51553280, mean_episode_return = 77.38, mean_episode_step = 641.88, total_loss = 477.0, pg_loss = 327.85, baseline_loss = 155.48, entropy_loss = -6.335, learner_queue_size = 19, _tick = 15491, _time = 1.654e+09, train_seconds = 7804.1)
[2022-05-31 16:20:30,420][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 16:20:30,521][root][INFO] - Step 51586560 @ 6647.9 SPS. Inference batcher size: 131. Learner queue size: 20. Other stats: (step = 51586560, mean_episode_return = 160.94, mean_episode_step = 831.0, total_loss = 117.55, pg_loss = -12.499, baseline_loss = 136.3, entropy_loss = -6.2548, learner_queue_size = 16, _tick = 15502, _time = 1.654e+09, train_seconds = 7809.1)
[2022-05-31 16:20:35,526][root][INFO] - Step 51617280 @ 6016.5 SPS. Inference batcher size: 116. Learner queue size: 26. Other stats: (step = 51617280, mean_episode_return = 61.15, mean_episode_step = 636.99, total_loss = 13.915, pg_loss = -79.628, baseline_loss = 99.665, entropy_loss = -6.1218, learner_queue_size = 23, _tick = 15513, _time = 1.654e+09, train_seconds = 7814.2)
[2022-05-31 16:20:40,530][root][INFO] - Step 51650560 @ 6650.7 SPS. Inference batcher size: 62. Learner queue size: 14. Other stats: (step = 51650560, mean_episode_return = 95.415, mean_episode_step = 2878.7, total_loss = -40.191, pg_loss = -55.542, baseline_loss = 22.144, entropy_loss = -6.793, learner_queue_size = 9, _tick = 15525, _time = 1.654e+09, train_seconds = 7819.2)
[2022-05-31 16:20:45,534][root][INFO] - Step 51683840 @ 6650.8 SPS. Inference batcher size: 131. Learner queue size: 10. Other stats: (step = 51683840, mean_episode_return = None, mean_episode_step = 859.44, total_loss = 70.937, pg_loss = 45.353, baseline_loss = 31.949, entropy_loss = -6.3652, learner_queue_size = 11, _tick = 15536, _time = 1.654e+09, train_seconds = 7824.2)
[2022-05-31 16:20:50,538][root][INFO] - Step 51717120 @ 6650.5 SPS. Inference batcher size: 164. Learner queue size: 6. Other stats: (step = 51717120, mean_episode_return = 136.01, mean_episode_step = 629.75, total_loss = 435.11, pg_loss = 299.4, baseline_loss = 141.44, entropy_loss = -5.7299, learner_queue_size = 27, _tick = 15548, _time = 1.654e+09, train_seconds = 7829.2)
[2022-05-31 16:20:55,544][root][INFO] - Step 51750400 @ 6647.9 SPS. Inference batcher size: 126. Learner queue size: 2. Other stats: (step = 51750400, mean_episode_return = None, mean_episode_step = 887.31, total_loss = 23.308, pg_loss = -24.191, baseline_loss = 52.694, entropy_loss = -5.1953, learner_queue_size = 16, _tick = 15560, _time = 1.654e+09, train_seconds = 7834.2)
[2022-05-31 16:21:00,546][root][INFO] - Step 51783680 @ 6653.4 SPS. Inference batcher size: 188. Learner queue size: 7. Other stats: (step = 51783680, mean_episode_return = 162.54, mean_episode_step = 635.73, total_loss = 287.9, pg_loss = 118.87, baseline_loss = 175.08, entropy_loss = -6.0515, learner_queue_size = 24, _tick = 15573, _time = 1.654e+09, train_seconds = 7839.2)
[2022-05-31 16:21:05,554][root][INFO] - Step 51814400 @ 6134.4 SPS. Inference batcher size: 226. Learner queue size: 18. Other stats: (step = 51814400, mean_episode_return = 140.46, mean_episode_step = 2663.8, total_loss = 84.41, pg_loss = 30.315, baseline_loss = 60.24, entropy_loss = -6.1443, learner_queue_size = 17, _tick = 15585, _time = 1.654e+09, train_seconds = 7844.2)
[2022-05-31 16:21:10,558][root][INFO] - Step 51847680 @ 6650.5 SPS. Inference batcher size: 103. Learner queue size: 19. Other stats: (step = 51847680, mean_episode_return = 258.39, mean_episode_step = 927.97, total_loss = 21.075, pg_loss = -97.229, baseline_loss = 124.08, entropy_loss = -5.7727, learner_queue_size = 24, _tick = 15596, _time = 1.654e+09, train_seconds = 7849.2)
[2022-05-31 16:21:15,562][root][INFO] - Step 51880960 @ 6650.8 SPS. Inference batcher size: 89. Learner queue size: 6. Other stats: (step = 51880960, mean_episode_return = 113.15, mean_episode_step = 766.36, total_loss = 242.59, pg_loss = -28.217, baseline_loss = 276.75, entropy_loss = -5.9396, learner_queue_size = 24, _tick = 15608, _time = 1.654e+09, train_seconds = 7854.2)
[2022-05-31 16:21:20,566][root][INFO] - Step 51914240 @ 6650.1 SPS. Inference batcher size: 138. Learner queue size: 17. Other stats: (step = 51914240, mean_episode_return = 149.73, mean_episode_step = 2918.7, total_loss = 104.45, pg_loss = 45.287, baseline_loss = 65.607, entropy_loss = -6.4432, learner_queue_size = 26, _tick = 15618, _time = 1.654e+09, train_seconds = 7859.3)
[2022-05-31 16:21:25,570][root][INFO] - Step 51947520 @ 6651.3 SPS. Inference batcher size: 67. Learner queue size: 19. Other stats: (step = 51947520, mean_episode_return = 125.45, mean_episode_step = 960.58, total_loss = -177.71, pg_loss = -205.15, baseline_loss = 33.166, entropy_loss = -5.7244, learner_queue_size = 17, _tick = 15630, _time = 1.654e+09, train_seconds = 7864.3)
[2022-05-31 16:21:30,574][root][INFO] - Step 51980800 @ 6650.7 SPS. Inference batcher size: 93. Learner queue size: 6. Other stats: (step = 51980800, mean_episode_return = None, mean_episode_step = 779.25, total_loss = -73.79, pg_loss = -78.53, baseline_loss = 11.477, entropy_loss = -6.7369, learner_queue_size = 12, _tick = 15641, _time = 1.654e+09, train_seconds = 7869.3)
[2022-05-31 16:21:35,578][root][INFO] - Step 52014080 @ 6650.6 SPS. Inference batcher size: 112. Learner queue size: 10. Other stats: (step = 52014080, mean_episode_return = 87.968, mean_episode_step = 2856.7, total_loss = 76.266, pg_loss = 52.623, baseline_loss = 30.235, entropy_loss = -6.593, learner_queue_size = 11, _tick = 15654, _time = 1.654e+09, train_seconds = 7874.3)
[2022-05-31 16:21:40,582][root][INFO] - Step 52047360 @ 6650.7 SPS. Inference batcher size: 136. Learner queue size: 11. Other stats: (step = 52047360, mean_episode_return = 100.86, mean_episode_step = 609.83, total_loss = 132.15, pg_loss = 87.041, baseline_loss = 51.381, entropy_loss = -6.2719, learner_queue_size = 25, _tick = 15667, _time = 1.654e+09, train_seconds = 7879.3)
[2022-05-31 16:21:45,588][root][INFO] - Step 52080640 @ 6647.9 SPS. Inference batcher size: 67. Learner queue size: 3. Other stats: (step = 52080640, mean_episode_return = 101.61, mean_episode_step = 778.57, total_loss = 162.42, pg_loss = 89.835, baseline_loss = 79.035, entropy_loss = -6.446, learner_queue_size = 24, _tick = 15679, _time = 1.654e+09, train_seconds = 7884.3)
[2022-05-31 16:21:50,594][root][INFO] - Step 52113920 @ 6648.0 SPS. Inference batcher size: 9. Learner queue size: 1. Other stats: (step = 52113920, mean_episode_return = 133.67, mean_episode_step = 740.49, total_loss = 151.34, pg_loss = 65.95, baseline_loss = 91.767, entropy_loss = -6.3766, learner_queue_size = 19, _tick = 15690, _time = 1.654e+09, train_seconds = 7889.3)
[2022-05-31 16:21:55,598][root][INFO] - Step 52147200 @ 6650.7 SPS. Inference batcher size: 133. Learner queue size: 2. Other stats: (step = 52147200, mean_episode_return = 67.545, mean_episode_step = 669.29, total_loss = 44.65, pg_loss = 0.46041, baseline_loss = 50.372, entropy_loss = -6.1828, learner_queue_size = 21, _tick = 15703, _time = 1.654e+09, train_seconds = 7894.3)
[2022-05-31 16:22:00,602][root][INFO] - Step 52180480 @ 6650.8 SPS. Inference batcher size: 109. Learner queue size: 0. Other stats: (step = 52180480, mean_episode_return = 157.01, mean_episode_step = 654.38, total_loss = 37.597, pg_loss = 6.1299, baseline_loss = 37.79, entropy_loss = -6.3225, learner_queue_size = 18, _tick = 15715, _time = 1.654e+09, train_seconds = 7899.3)
[2022-05-31 16:22:05,606][root][INFO] - Step 52213760 @ 6650.6 SPS. Inference batcher size: 70. Learner queue size: 23. Other stats: (step = 52213760, mean_episode_return = 222.03, mean_episode_step = 1042.5, total_loss = 184.73, pg_loss = 135.92, baseline_loss = 55.493, entropy_loss = -6.6885, learner_queue_size = 17, _tick = 15727, _time = 1.654e+09, train_seconds = 7904.3)
[2022-05-31 16:22:10,612][root][INFO] - Step 52244480 @ 6136.5 SPS. Inference batcher size: 115. Learner queue size: 14. Other stats: (step = 52244480, mean_episode_return = 53.025, mean_episode_step = 708.39, total_loss = 211.74, pg_loss = 146.19, baseline_loss = 71.793, entropy_loss = -6.242, learner_queue_size = 16, _tick = 15738, _time = 1.654e+09, train_seconds = 7909.3)
[2022-05-31 16:22:15,618][root][INFO] - Step 52277760 @ 6647.8 SPS. Inference batcher size: 139. Learner queue size: 19. Other stats: (step = 52277760, mean_episode_return = 499.56, mean_episode_step = 811.66, total_loss = -262.71, pg_loss = -359.79, baseline_loss = 103.02, entropy_loss = -5.939, learner_queue_size = 23, _tick = 15750, _time = 1.654e+09, train_seconds = 7914.3)
[2022-05-31 16:22:20,622][root][INFO] - Step 52311040 @ 6651.0 SPS. Inference batcher size: 108. Learner queue size: 19. Other stats: (step = 52311040, mean_episode_return = 146.98, mean_episode_step = 898.04, total_loss = 28.509, pg_loss = -64.253, baseline_loss = 99.125, entropy_loss = -6.3627, learner_queue_size = 15, _tick = 15761, _time = 1.654e+09, train_seconds = 7919.3)
[2022-05-31 16:22:25,626][root][INFO] - Step 52344320 @ 6650.7 SPS. Inference batcher size: 122. Learner queue size: 10. Other stats: (step = 52344320, mean_episode_return = 188.72, mean_episode_step = 565.72, total_loss = -127.14, pg_loss = -243.79, baseline_loss = 123.03, entropy_loss = -6.3795, learner_queue_size = 14, _tick = 15773, _time = 1.654e+09, train_seconds = 7924.3)
[2022-05-31 16:22:30,631][root][INFO] - Step 52377600 @ 6649.4 SPS. Inference batcher size: 4. Learner queue size: 1. Other stats: (step = 52377600, mean_episode_return = 125.02, mean_episode_step = 1204.6, total_loss = 57.509, pg_loss = -40.319, baseline_loss = 103.94, entropy_loss = -6.1118, learner_queue_size = 12, _tick = 15786, _time = 1.654e+09, train_seconds = 7929.3)
[2022-05-31 16:22:35,637][root][INFO] - Step 52410880 @ 6647.8 SPS. Inference batcher size: 107. Learner queue size: 1. Other stats: (step = 52410880, mean_episode_return = None, mean_episode_step = 750.12, total_loss = -58.662, pg_loss = -124.58, baseline_loss = 72.552, entropy_loss = -6.6302, learner_queue_size = 19, _tick = 15797, _time = 1.654e+09, train_seconds = 7934.3)
[2022-05-31 16:22:40,643][root][INFO] - Step 52444160 @ 6648.3 SPS. Inference batcher size: 59. Learner queue size: 3. Other stats: (step = 52444160, mean_episode_return = 61.291, mean_episode_step = 2919.3, total_loss = 661.79, pg_loss = 473.63, baseline_loss = 194.88, entropy_loss = -6.7129, learner_queue_size = 19, _tick = 15809, _time = 1.654e+09, train_seconds = 7939.3)
[2022-05-31 16:22:45,646][root][INFO] - Step 52477440 @ 6651.8 SPS. Inference batcher size: 149. Learner queue size: 31. Other stats: (step = 52477440, mean_episode_return = 194.17, mean_episode_step = 902.39, total_loss = 104.0, pg_loss = 65.106, baseline_loss = 44.934, entropy_loss = -6.0401, learner_queue_size = 15, _tick = 15822, _time = 1.654e+09, train_seconds = 7944.3)
[2022-05-31 16:22:50,650][root][INFO] - Step 52508160 @ 6139.1 SPS. Inference batcher size: 157. Learner queue size: 21. Other stats: (step = 52508160, mean_episode_return = 69.326, mean_episode_step = 751.91, total_loss = 160.5, pg_loss = 20.45, baseline_loss = 146.35, entropy_loss = -6.3007, learner_queue_size = 24, _tick = 15832, _time = 1.654e+09, train_seconds = 7949.3)
[2022-05-31 16:22:55,654][root][INFO] - Step 52541440 @ 6650.8 SPS. Inference batcher size: 63. Learner queue size: 12. Other stats: (step = 52541440, mean_episode_return = None, mean_episode_step = 613.97, total_loss = -82.382, pg_loss = -130.22, baseline_loss = 53.801, entropy_loss = -5.9612, learner_queue_size = 22, _tick = 15843, _time = 1.654e+09, train_seconds = 7954.3)
[2022-05-31 16:23:00,658][root][INFO] - Step 52574720 @ 6650.6 SPS. Inference batcher size: 134. Learner queue size: 20. Other stats: (step = 52574720, mean_episode_return = 73.505, mean_episode_step = 960.23, total_loss = 1.6951, pg_loss = -31.399, baseline_loss = 39.653, entropy_loss = -6.5589, learner_queue_size = 25, _tick = 15853, _time = 1.654e+09, train_seconds = 7959.3)
[2022-05-31 16:23:05,664][root][INFO] - Step 52608000 @ 6647.8 SPS. Inference batcher size: 101. Learner queue size: 12. Other stats: (step = 52608000, mean_episode_return = 103.37, mean_episode_step = 836.96, total_loss = -189.85, pg_loss = -220.89, baseline_loss = 37.647, entropy_loss = -6.6053, learner_queue_size = 14, _tick = 15866, _time = 1.654e+09, train_seconds = 7964.3)
[2022-05-31 16:23:10,670][root][INFO] - Step 52641280 @ 6648.3 SPS. Inference batcher size: 73. Learner queue size: 7. Other stats: (step = 52641280, mean_episode_return = 175.59, mean_episode_step = 717.11, total_loss = 44.331, pg_loss = -149.15, baseline_loss = 200.19, entropy_loss = -6.7102, learner_queue_size = 18, _tick = 15877, _time = 1.654e+09, train_seconds = 7969.4)
[2022-05-31 16:23:15,674][root][INFO] - Step 52674560 @ 6650.6 SPS. Inference batcher size: 109. Learner queue size: 27. Other stats: (step = 52674560, mean_episode_return = 128.95, mean_episode_step = 902.46, total_loss = -101.41, pg_loss = -140.27, baseline_loss = 45.302, entropy_loss = -6.4451, learner_queue_size = 13, _tick = 15887, _time = 1.654e+09, train_seconds = 7974.4)
[2022-05-31 16:23:20,678][root][INFO] - Step 52705280 @ 6139.0 SPS. Inference batcher size: 96. Learner queue size: 26. Other stats: (step = 52705280, mean_episode_return = 65.39, mean_episode_step = 1136.8, total_loss = -121.08, pg_loss = -192.33, baseline_loss = 77.514, entropy_loss = -6.2643, learner_queue_size = 14, _tick = 15898, _time = 1.654e+09, train_seconds = 7979.4)
[2022-05-31 16:23:25,684][root][INFO] - Step 52738560 @ 6648.0 SPS. Inference batcher size: 103. Learner queue size: 16. Other stats: (step = 52738560, mean_episode_return = 49.44, mean_episode_step = 743.96, total_loss = 133.91, pg_loss = -13.551, baseline_loss = 153.56, entropy_loss = -6.0927, learner_queue_size = 30, _tick = 15908, _time = 1.654e+09, train_seconds = 7984.4)
[2022-05-31 16:23:30,690][root][INFO] - Step 52771840 @ 6648.1 SPS. Inference batcher size: 122. Learner queue size: 12. Other stats: (step = 52771840, mean_episode_return = 86.553, mean_episode_step = 887.97, total_loss = 54.679, pg_loss = 11.924, baseline_loss = 48.945, entropy_loss = -6.1902, learner_queue_size = 27, _tick = 15920, _time = 1.654e+09, train_seconds = 7989.4)
[2022-05-31 16:23:35,694][root][INFO] - Step 52805120 @ 6650.5 SPS. Inference batcher size: 188. Learner queue size: 11. Other stats: (step = 52805120, mean_episode_return = 108.94, mean_episode_step = 718.98, total_loss = 16.532, pg_loss = -5.5792, baseline_loss = 28.096, entropy_loss = -5.9848, learner_queue_size = 22, _tick = 15933, _time = 1.654e+09, train_seconds = 7994.4)
[2022-05-31 16:23:40,698][root][INFO] - Step 52838400 @ 6650.9 SPS. Inference batcher size: 80. Learner queue size: 28. Other stats: (step = 52838400, mean_episode_return = None, mean_episode_step = 794.25, total_loss = 258.34, pg_loss = 127.37, baseline_loss = 137.36, entropy_loss = -6.3861, learner_queue_size = 10, _tick = 15944, _time = 1.654e+09, train_seconds = 7999.4)
[2022-05-31 16:23:45,702][root][INFO] - Step 52871680 @ 6650.7 SPS. Inference batcher size: 148. Learner queue size: 22. Other stats: (step = 52871680, mean_episode_return = 191.13, mean_episode_step = 917.38, total_loss = -186.68, pg_loss = -225.99, baseline_loss = 45.579, entropy_loss = -6.2742, learner_queue_size = 13, _tick = 15957, _time = 1.654e+09, train_seconds = 8004.4)
[2022-05-31 16:23:50,708][root][INFO] - Step 52902400 @ 6136.5 SPS. Inference batcher size: 94. Learner queue size: 13. Other stats: (step = 52902400, mean_episode_return = 122.94, mean_episode_step = 1051.3, total_loss = -15.47, pg_loss = -56.046, baseline_loss = 46.723, entropy_loss = -6.1462, learner_queue_size = 15, _tick = 15968, _time = 1.654e+09, train_seconds = 8009.4)
[2022-05-31 16:23:55,714][root][INFO] - Step 52935680 @ 6647.9 SPS. Inference batcher size: 47. Learner queue size: 13. Other stats: (step = 52935680, mean_episode_return = None, mean_episode_step = 837.53, total_loss = 60.138, pg_loss = -14.242, baseline_loss = 80.774, entropy_loss = -6.3942, learner_queue_size = 19, _tick = 15977, _time = 1.654e+09, train_seconds = 8014.4)
[2022-05-31 16:24:00,718][root][INFO] - Step 52968960 @ 6651.0 SPS. Inference batcher size: 144. Learner queue size: 11. Other stats: (step = 52968960, mean_episode_return = None, mean_episode_step = 716.88, total_loss = 442.13, pg_loss = 273.93, baseline_loss = 174.65, entropy_loss = -6.4519, learner_queue_size = 19, _tick = 15989, _time = 1.654e+09, train_seconds = 8019.4)
[2022-05-31 16:24:05,724][root][INFO] - Step 53002240 @ 6647.6 SPS. Inference batcher size: 78. Learner queue size: 6. Other stats: (step = 53002240, mean_episode_return = 175.58, mean_episode_step = 857.14, total_loss = 154.48, pg_loss = 95.929, baseline_loss = 65.043, entropy_loss = -6.4877, learner_queue_size = 15, _tick = 16002, _time = 1.654e+09, train_seconds = 8024.4)
[2022-05-31 16:24:10,730][root][INFO] - Step 53035520 @ 6648.4 SPS. Inference batcher size: 122. Learner queue size: 22. Other stats: (step = 53035520, mean_episode_return = 33.1, mean_episode_step = 717.44, total_loss = 122.4, pg_loss = 39.607, baseline_loss = 88.984, entropy_loss = -6.1875, learner_queue_size = 12, _tick = 16013, _time = 1.654e+09, train_seconds = 8029.4)
[2022-05-31 16:24:15,734][root][INFO] - Step 53068800 @ 6650.7 SPS. Inference batcher size: 161. Learner queue size: 11. Other stats: (step = 53068800, mean_episode_return = 192.94, mean_episode_step = 906.44, total_loss = -91.767, pg_loss = -209.93, baseline_loss = 124.12, entropy_loss = -5.9614, learner_queue_size = 23, _tick = 16025, _time = 1.654e+09, train_seconds = 8034.4)
[2022-05-31 16:24:20,738][root][INFO] - Step 53102080 @ 6650.8 SPS. Inference batcher size: 131. Learner queue size: 0. Other stats: (step = 53102080, mean_episode_return = 136.48, mean_episode_step = 1031.7, total_loss = 137.99, pg_loss = 43.976, baseline_loss = 100.18, entropy_loss = -6.1675, learner_queue_size = 19, _tick = 16038, _time = 1.654e+09, train_seconds = 8039.4)
[2022-05-31 16:24:25,742][root][INFO] - Step 53135360 @ 6650.6 SPS. Inference batcher size: 110. Learner queue size: 7. Other stats: (step = 53135360, mean_episode_return = 180.02, mean_episode_step = 702.31, total_loss = 109.83, pg_loss = 17.088, baseline_loss = 98.384, entropy_loss = -5.6373, learner_queue_size = 29, _tick = 16050, _time = 1.654e+09, train_seconds = 8044.4)
[2022-05-31 16:24:30,747][root][INFO] - Step 53168640 @ 6649.8 SPS. Inference batcher size: 17. Learner queue size: 31. Other stats: (step = 53168640, mean_episode_return = 157.48, mean_episode_step = 935.44, total_loss = 12.641, pg_loss = -72.027, baseline_loss = 90.699, entropy_loss = -6.0307, learner_queue_size = 23, _tick = 16063, _time = 1.654e+09, train_seconds = 8049.4)
[2022-05-31 16:24:35,750][root][INFO] - Step 53199360 @ 6139.9 SPS. Inference batcher size: 36. Learner queue size: 19. Other stats: (step = 53199360, mean_episode_return = 134.67, mean_episode_step = 771.84, total_loss = 117.42, pg_loss = 70.537, baseline_loss = 53.24, entropy_loss = -6.3618, learner_queue_size = 14, _tick = 16075, _time = 1.654e+09, train_seconds = 8054.4)
[2022-05-31 16:24:40,754][root][INFO] - Step 53235200 @ 7161.7 SPS. Inference batcher size: 5. Learner queue size: 19. Other stats: (step = 53235200, mean_episode_return = 132.6, mean_episode_step = 2751.7, total_loss = 106.32, pg_loss = 59.399, baseline_loss = 53.306, entropy_loss = -6.3876, learner_queue_size = 16, _tick = 16088, _time = 1.654e+09, train_seconds = 8059.4)
[2022-05-31 16:24:45,758][root][INFO] - Step 53265920 @ 6139.6 SPS. Inference batcher size: 73. Learner queue size: 18. Other stats: (step = 53265920, mean_episode_return = 110.74, mean_episode_step = 1022.5, total_loss = -24.53, pg_loss = -50.028, baseline_loss = 32.176, entropy_loss = -6.678, learner_queue_size = 17, _tick = 16098, _time = 1.654e+09, train_seconds = 8064.4)
[2022-05-31 16:24:50,764][root][INFO] - Step 53299200 @ 6648.1 SPS. Inference batcher size: 157. Learner queue size: 10. Other stats: (step = 53299200, mean_episode_return = None, mean_episode_step = 713.41, total_loss = 425.81, pg_loss = 283.18, baseline_loss = 148.88, entropy_loss = -6.2578, learner_queue_size = 30, _tick = 16109, _time = 1.654e+09, train_seconds = 8069.4)
[2022-05-31 16:24:55,766][root][INFO] - Step 53332480 @ 6653.2 SPS. Inference batcher size: 185. Learner queue size: 4. Other stats: (step = 53332480, mean_episode_return = None, mean_episode_step = 1043.6, total_loss = -77.823, pg_loss = -155.19, baseline_loss = 83.699, entropy_loss = -6.3288, learner_queue_size = 24, _tick = 16118, _time = 1.654e+09, train_seconds = 8074.5)
[2022-05-31 16:25:00,770][root][INFO] - Step 53365760 @ 6650.7 SPS. Inference batcher size: 143. Learner queue size: 0. Other stats: (step = 53365760, mean_episode_return = 39.08, mean_episode_step = 822.84, total_loss = -109.48, pg_loss = -152.17, baseline_loss = 49.128, entropy_loss = -6.442, learner_queue_size = 23, _tick = 16130, _time = 1.654e+09, train_seconds = 8079.5)
[2022-05-31 16:25:05,774][root][INFO] - Step 53399040 @ 6650.7 SPS. Inference batcher size: 135. Learner queue size: 29. Other stats: (step = 53399040, mean_episode_return = 244.34, mean_episode_step = 2884.5, total_loss = -182.94, pg_loss = -203.05, baseline_loss = 26.746, entropy_loss = -6.6355, learner_queue_size = 27, _tick = 16141, _time = 1.654e+09, train_seconds = 8084.5)
[2022-05-31 16:25:10,778][root][INFO] - Step 53432320 @ 6650.6 SPS. Inference batcher size: 70. Learner queue size: 10. Other stats: (step = 53432320, mean_episode_return = 171.15, mean_episode_step = 634.65, total_loss = -22.781, pg_loss = -89.058, baseline_loss = 72.395, entropy_loss = -6.1173, learner_queue_size = 10, _tick = 16153, _time = 1.654e+09, train_seconds = 8089.5)
[2022-05-31 16:25:15,784][root][INFO] - Step 53465600 @ 6647.5 SPS. Inference batcher size: 123. Learner queue size: 23. Other stats: (step = 53465600, mean_episode_return = 116.51, mean_episode_step = 759.09, total_loss = -211.5, pg_loss = -260.78, baseline_loss = 55.123, entropy_loss = -5.8475, learner_queue_size = 23, _tick = 16162, _time = 1.654e+09, train_seconds = 8094.5)
[2022-05-31 16:25:20,791][root][INFO] - Step 53496320 @ 6136.3 SPS. Inference batcher size: 179. Learner queue size: 21. Other stats: (step = 53496320, mean_episode_return = 139.5, mean_episode_step = 1658.9, total_loss = -40.204, pg_loss = -115.89, baseline_loss = 81.936, entropy_loss = -6.246, learner_queue_size = 18, _tick = 16174, _time = 1.654e+09, train_seconds = 8099.5)
[2022-05-31 16:25:25,797][root][INFO] - Step 53529600 @ 6647.9 SPS. Inference batcher size: 27. Learner queue size: 16. Other stats: (step = 53529600, mean_episode_return = 138.3, mean_episode_step = 771.23, total_loss = 218.98, pg_loss = 79.636, baseline_loss = 145.31, entropy_loss = -5.9663, learner_queue_size = 15, _tick = 16186, _time = 1.654e+09, train_seconds = 8104.5)
[2022-05-31 16:25:30,802][root][INFO] - Step 53562880 @ 6648.9 SPS. Inference batcher size: 159. Learner queue size: 18. Other stats: (step = 53562880, mean_episode_return = 34.951, mean_episode_step = 790.58, total_loss = 135.74, pg_loss = 55.339, baseline_loss = 86.151, entropy_loss = -5.7523, learner_queue_size = 28, _tick = 16194, _time = 1.654e+09, train_seconds = 8109.5)
[2022-05-31 16:25:35,806][root][INFO] - Step 53596160 @ 6650.9 SPS. Inference batcher size: 54. Learner queue size: 6. Other stats: (step = 53596160, mean_episode_return = 114.16, mean_episode_step = 1121.9, total_loss = 296.65, pg_loss = 176.47, baseline_loss = 126.46, entropy_loss = -6.2775, learner_queue_size = 16, _tick = 16207, _time = 1.654e+09, train_seconds = 8114.5)
[2022-05-31 16:25:40,811][root][INFO] - Step 53629440 @ 6649.7 SPS. Inference batcher size: 53. Learner queue size: 5. Other stats: (step = 53629440, mean_episode_return = 312.74, mean_episode_step = 710.47, total_loss = 150.05, pg_loss = 35.805, baseline_loss = 120.64, entropy_loss = -6.396, learner_queue_size = 22, _tick = 16220, _time = 1.654e+09, train_seconds = 8119.5)
[2022-05-31 16:25:45,814][root][INFO] - Step 53662720 @ 6651.7 SPS. Inference batcher size: 129. Learner queue size: 3. Other stats: (step = 53662720, mean_episode_return = 98.53, mean_episode_step = 3030.1, total_loss = 71.973, pg_loss = 29.175, baseline_loss = 49.439, entropy_loss = -6.6401, learner_queue_size = 25, _tick = 16233, _time = 1.654e+09, train_seconds = 8124.5)
[2022-05-31 16:25:50,820][root][INFO] - Step 53696000 @ 6647.9 SPS. Inference batcher size: 124. Learner queue size: 2. Other stats: (step = 53696000, mean_episode_return = 166.36, mean_episode_step = 761.18, total_loss = 78.768, pg_loss = -14.728, baseline_loss = 99.313, entropy_loss = -5.8164, learner_queue_size = 18, _tick = 16244, _time = 1.654e+09, train_seconds = 8129.5)
[2022-05-31 16:25:55,823][root][INFO] - Step 53729280 @ 6652.6 SPS. Inference batcher size: 99. Learner queue size: 23. Other stats: (step = 53729280, mean_episode_return = 137.27, mean_episode_step = 594.16, total_loss = -45.14, pg_loss = -144.07, baseline_loss = 105.1, entropy_loss = -6.1691, learner_queue_size = 12, _tick = 16255, _time = 1.654e+09, train_seconds = 8134.5)
[2022-05-31 16:26:00,826][root][INFO] - Step 53760000 @ 6139.6 SPS. Inference batcher size: 83. Learner queue size: 11. Other stats: (step = 53760000, mean_episode_return = 104.87, mean_episode_step = 1086.8, total_loss = -78.265, pg_loss = -91.554, baseline_loss = 19.724, entropy_loss = -6.4352, learner_queue_size = 15, _tick = 16267, _time = 1.654e+09, train_seconds = 8139.5)
[2022-05-31 16:26:05,830][root][INFO] - Step 53793280 @ 6650.9 SPS. Inference batcher size: 91. Learner queue size: 23. Other stats: (step = 53793280, mean_episode_return = 129.9, mean_episode_step = 677.16, total_loss = 125.18, pg_loss = 39.34, baseline_loss = 92.494, entropy_loss = -6.6581, learner_queue_size = 17, _tick = 16280, _time = 1.654e+09, train_seconds = 8144.5)
[2022-05-31 16:26:10,834][root][INFO] - Step 53826560 @ 6650.6 SPS. Inference batcher size: 156. Learner queue size: 5. Other stats: (step = 53826560, mean_episode_return = 392.27, mean_episode_step = 3042.9, total_loss = 180.71, pg_loss = 45.404, baseline_loss = 141.84, entropy_loss = -6.5341, learner_queue_size = 22, _tick = 16291, _time = 1.654e+09, train_seconds = 8149.5)
[2022-05-31 16:26:15,839][root][INFO] - Step 53859840 @ 6649.3 SPS. Inference batcher size: 156. Learner queue size: 6. Other stats: (step = 53859840, mean_episode_return = None, mean_episode_step = 1208.6, total_loss = -52.014, pg_loss = -75.428, baseline_loss = 29.832, entropy_loss = -6.4172, learner_queue_size = 18, _tick = 16303, _time = 1.654e+09, train_seconds = 8154.5)
[2022-05-31 16:26:20,842][root][INFO] - Step 53893120 @ 6652.1 SPS. Inference batcher size: 109. Learner queue size: 7. Other stats: (step = 53893120, mean_episode_return = 63.329, mean_episode_step = 808.61, total_loss = -10.015, pg_loss = -63.026, baseline_loss = 59.557, entropy_loss = -6.5461, learner_queue_size = 24, _tick = 16314, _time = 1.654e+09, train_seconds = 8159.5)
[2022-05-31 16:26:25,846][root][INFO] - Step 53926400 @ 6650.7 SPS. Inference batcher size: 128. Learner queue size: 2. Other stats: (step = 53926400, mean_episode_return = 59.031, mean_episode_step = 2955.2, total_loss = 40.46, pg_loss = 0.5174, baseline_loss = 45.918, entropy_loss = -5.975, learner_queue_size = 18, _tick = 16325, _time = 1.654e+09, train_seconds = 8164.5)
[2022-05-31 16:26:30,852][root][INFO] - Step 53959680 @ 6647.9 SPS. Inference batcher size: 93. Learner queue size: 3. Other stats: (step = 53959680, mean_episode_return = 89.41, mean_episode_step = 881.17, total_loss = 223.55, pg_loss = 130.74, baseline_loss = 98.821, entropy_loss = -6.0126, learner_queue_size = 30, _tick = 16336, _time = 1.654e+09, train_seconds = 8169.5)
[2022-05-31 16:26:35,856][root][INFO] - Step 53990400 @ 6138.7 SPS. Inference batcher size: 64. Learner queue size: 28. Other stats: (step = 53990400, mean_episode_return = 79.007, mean_episode_step = 868.98, total_loss = -30.621, pg_loss = -99.541, baseline_loss = 75.293, entropy_loss = -6.3725, learner_queue_size = 20, _tick = 16348, _time = 1.654e+09, train_seconds = 8174.5)
[2022-05-31 16:26:40,862][root][INFO] - Step 54026240 @ 7159.9 SPS. Inference batcher size: 178. Learner queue size: 22. Other stats: (step = 54026240, mean_episode_return = 151.57, mean_episode_step = 736.25, total_loss = 86.125, pg_loss = 19.278, baseline_loss = 73.187, entropy_loss = -6.3399, learner_queue_size = 14, _tick = 16361, _time = 1.654e+09, train_seconds = 8179.5)
[2022-05-31 16:26:45,868][root][INFO] - Step 54056960 @ 6136.6 SPS. Inference batcher size: 160. Learner queue size: 18. Other stats: (step = 54056960, mean_episode_return = 49.07, mean_episode_step = 668.33, total_loss = 230.39, pg_loss = 151.37, baseline_loss = 85.58, entropy_loss = -6.5595, learner_queue_size = 27, _tick = 16372, _time = 1.654e+09, train_seconds = 8184.6)
[2022-05-31 16:26:50,872][root][INFO] - Step 54090240 @ 6650.7 SPS. Inference batcher size: 72. Learner queue size: 13. Other stats: (step = 54090240, mean_episode_return = 202.64, mean_episode_step = 687.35, total_loss = 88.34, pg_loss = -14.313, baseline_loss = 108.65, entropy_loss = -5.9999, learner_queue_size = 20, _tick = 16383, _time = 1.654e+09, train_seconds = 8189.6)
[2022-05-31 16:26:55,877][root][INFO] - Step 54123520 @ 6649.4 SPS. Inference batcher size: 87. Learner queue size: 13. Other stats: (step = 54123520, mean_episode_return = 113.7, mean_episode_step = 1416.3, total_loss = 147.84, pg_loss = 68.285, baseline_loss = 85.662, entropy_loss = -6.1115, learner_queue_size = 30, _tick = 16396, _time = 1.654e+09, train_seconds = 8194.6)
[2022-05-31 16:27:00,882][root][INFO] - Step 54156800 @ 6649.1 SPS. Inference batcher size: 144. Learner queue size: 14. Other stats: (step = 54156800, mean_episode_return = 233.87, mean_episode_step = 578.95, total_loss = 458.16, pg_loss = 271.49, baseline_loss = 192.87, entropy_loss = -6.2067, learner_queue_size = 15, _tick = 16409, _time = 1.654e+09, train_seconds = 8199.6)
[2022-05-31 16:27:05,886][root][INFO] - Step 54190080 @ 6650.8 SPS. Inference batcher size: 31. Learner queue size: 9. Other stats: (step = 54190080, mean_episode_return = 227.51, mean_episode_step = 2909.3, total_loss = -22.684, pg_loss = -127.77, baseline_loss = 111.25, entropy_loss = -6.1628, learner_queue_size = 21, _tick = 16421, _time = 1.654e+09, train_seconds = 8204.6)
[2022-05-31 16:27:10,890][root][INFO] - Step 54223360 @ 6650.8 SPS. Inference batcher size: 63. Learner queue size: 3. Other stats: (step = 54223360, mean_episode_return = 187.75, mean_episode_step = 849.87, total_loss = 19.937, pg_loss = -104.01, baseline_loss = 129.93, entropy_loss = -5.9797, learner_queue_size = 16, _tick = 16434, _time = 1.654e+09, train_seconds = 8209.6)
[2022-05-31 16:27:15,894][root][INFO] - Step 54256640 @ 6650.6 SPS. Inference batcher size: 67. Learner queue size: 23. Other stats: (step = 54256640, mean_episode_return = 111.31, mean_episode_step = 786.27, total_loss = 175.4, pg_loss = 83.19, baseline_loss = 98.664, entropy_loss = -6.455, learner_queue_size = 10, _tick = 16445, _time = 1.654e+09, train_seconds = 8214.6)
[2022-05-31 16:27:20,898][root][INFO] - Step 54289920 @ 6650.4 SPS. Inference batcher size: 83. Learner queue size: 2. Other stats: (step = 54289920, mean_episode_return = 104.53, mean_episode_step = 664.93, total_loss = 398.05, pg_loss = 187.02, baseline_loss = 217.23, entropy_loss = -6.2066, learner_queue_size = 22, _tick = 16457, _time = 1.654e+09, train_seconds = 8219.6)
[2022-05-31 16:27:25,902][root][INFO] - Step 54323200 @ 6651.2 SPS. Inference batcher size: 54. Learner queue size: 31. Other stats: (step = 54323200, mean_episode_return = 189.7, mean_episode_step = 861.29, total_loss = 22.524, pg_loss = -28.133, baseline_loss = 56.745, entropy_loss = -6.0885, learner_queue_size = 31, _tick = 16467, _time = 1.654e+09, train_seconds = 8224.6)
[2022-05-31 16:27:30,906][root][INFO] - Step 54356480 @ 6650.7 SPS. Inference batcher size: 45. Learner queue size: 22. Other stats: (step = 54356480, mean_episode_return = 128.8, mean_episode_step = 3104.3, total_loss = -121.04, pg_loss = -221.52, baseline_loss = 106.4, entropy_loss = -5.9171, learner_queue_size = 14, _tick = 16479, _time = 1.654e+09, train_seconds = 8229.6)
[2022-05-31 16:27:35,910][root][INFO] - Step 54389760 @ 6650.7 SPS. Inference batcher size: 131. Learner queue size: 29. Other stats: (step = 54389760, mean_episode_return = 194.06, mean_episode_step = 867.6, total_loss = -156.01, pg_loss = -218.85, baseline_loss = 69.335, entropy_loss = -6.4958, learner_queue_size = 23, _tick = 16489, _time = 1.654e+09, train_seconds = 8234.6)
[2022-05-31 16:27:40,914][root][INFO] - Step 54420480 @ 6139.1 SPS. Inference batcher size: 96. Learner queue size: 18. Other stats: (step = 54420480, mean_episode_return = 85.738, mean_episode_step = 856.56, total_loss = -234.8, pg_loss = -268.9, baseline_loss = 40.368, entropy_loss = -6.2704, learner_queue_size = 24, _tick = 16497, _time = 1.654e+09, train_seconds = 8239.6)
[2022-05-31 16:27:45,918][root][INFO] - Step 54453760 @ 6650.6 SPS. Inference batcher size: 139. Learner queue size: 16. Other stats: (step = 54453760, mean_episode_return = 312.25, mean_episode_step = 705.03, total_loss = 356.44, pg_loss = 244.97, baseline_loss = 118.2, entropy_loss = -6.7254, learner_queue_size = 15, _tick = 16508, _time = 1.654e+09, train_seconds = 8244.6)
[2022-05-31 16:27:50,922][root][INFO] - Step 54487040 @ 6650.8 SPS. Inference batcher size: 107. Learner queue size: 12. Other stats: (step = 54487040, mean_episode_return = 53.936, mean_episode_step = 934.77, total_loss = -125.49, pg_loss = -135.73, baseline_loss = 17.249, entropy_loss = -7.0168, learner_queue_size = 19, _tick = 16518, _time = 1.654e+09, train_seconds = 8249.6)
[2022-05-31 16:27:55,926][root][INFO] - Step 54520320 @ 6650.6 SPS. Inference batcher size: 103. Learner queue size: 7. Other stats: (step = 54520320, mean_episode_return = 237.73, mean_episode_step = 881.02, total_loss = 581.06, pg_loss = 398.84, baseline_loss = 188.97, entropy_loss = -6.7463, learner_queue_size = 16, _tick = 16527, _time = 1.654e+09, train_seconds = 8254.6)
[2022-05-31 16:28:00,932][root][INFO] - Step 54553600 @ 6648.3 SPS. Inference batcher size: 105. Learner queue size: 3. Other stats: (step = 54553600, mean_episode_return = 128.61, mean_episode_step = 731.69, total_loss = 82.499, pg_loss = 53.685, baseline_loss = 35.231, entropy_loss = -6.4165, learner_queue_size = 29, _tick = 16539, _time = 1.654e+09, train_seconds = 8259.6)
[2022-05-31 16:28:05,934][root][INFO] - Step 54586880 @ 6653.1 SPS. Inference batcher size: 96. Learner queue size: 28. Other stats: (step = 54586880, mean_episode_return = None, mean_episode_step = 859.16, total_loss = 54.424, pg_loss = 20.914, baseline_loss = 39.884, entropy_loss = -6.3742, learner_queue_size = 23, _tick = 16549, _time = 1.654e+09, train_seconds = 8264.6)
[2022-05-31 16:28:10,938][root][INFO] - Step 54617600 @ 6139.0 SPS. Inference batcher size: 100. Learner queue size: 17. Other stats: (step = 54617600, mean_episode_return = 131.95, mean_episode_step = 709.83, total_loss = 143.75, pg_loss = 77.262, baseline_loss = 72.659, entropy_loss = -6.1757, learner_queue_size = 19, _tick = 16559, _time = 1.654e+09, train_seconds = 8269.6)
[2022-05-31 16:28:15,944][root][INFO] - Step 54650880 @ 6648.0 SPS. Inference batcher size: 134. Learner queue size: 12. Other stats: (step = 54650880, mean_episode_return = 125.42, mean_episode_step = 870.06, total_loss = 105.19, pg_loss = 77.08, baseline_loss = 34.437, entropy_loss = -6.3288, learner_queue_size = 23, _tick = 16572, _time = 1.654e+09, train_seconds = 8274.6)
[2022-05-31 16:28:20,950][root][INFO] - Step 54684160 @ 6647.9 SPS. Inference batcher size: 25. Learner queue size: 19. Other stats: (step = 54684160, mean_episode_return = 92.716, mean_episode_step = 959.4, total_loss = 44.392, pg_loss = -7.4245, baseline_loss = 57.922, entropy_loss = -6.105, learner_queue_size = 16, _tick = 16581, _time = 1.654e+09, train_seconds = 8279.6)
[2022-05-31 16:28:25,954][root][INFO] - Step 54717440 @ 6650.9 SPS. Inference batcher size: 124. Learner queue size: 13. Other stats: (step = 54717440, mean_episode_return = 211.73, mean_episode_step = 715.55, total_loss = -120.99, pg_loss = -213.94, baseline_loss = 99.275, entropy_loss = -6.3215, learner_queue_size = 24, _tick = 16594, _time = 1.654e+09, train_seconds = 8284.6)
[2022-05-31 16:28:30,960][root][INFO] - Step 54750720 @ 6647.6 SPS. Inference batcher size: 65. Learner queue size: 1. Other stats: (step = 54750720, mean_episode_return = 169.32, mean_episode_step = 781.6, total_loss = 208.83, pg_loss = 178.43, baseline_loss = 36.429, entropy_loss = -6.0313, learner_queue_size = 23, _tick = 16605, _time = 1.654e+09, train_seconds = 8289.6)
[2022-05-31 16:28:35,966][root][INFO] - Step 54784000 @ 6648.4 SPS. Inference batcher size: 174. Learner queue size: 30. Other stats: (step = 54784000, mean_episode_return = 116.97, mean_episode_step = 821.3, total_loss = -128.0, pg_loss = -230.05, baseline_loss = 108.03, entropy_loss = -5.978, learner_queue_size = 19, _tick = 16616, _time = 1.654e+09, train_seconds = 8294.7)
[2022-05-31 16:28:40,971][root][INFO] - Step 54817280 @ 6650.0 SPS. Inference batcher size: 97. Learner queue size: 19. Other stats: (step = 54817280, mean_episode_return = None, mean_episode_step = 650.91, total_loss = 646.92, pg_loss = 459.57, baseline_loss = 193.27, entropy_loss = -5.933, learner_queue_size = 19, _tick = 16627, _time = 1.654e+09, train_seconds = 8299.7)
[2022-05-31 16:28:45,974][root][INFO] - Step 54848000 @ 6139.4 SPS. Inference batcher size: 10. Learner queue size: 16. Other stats: (step = 54848000, mean_episode_return = 131.41, mean_episode_step = 808.88, total_loss = 13.021, pg_loss = -67.756, baseline_loss = 86.586, entropy_loss = -5.8087, learner_queue_size = 12, _tick = 16637, _time = 1.654e+09, train_seconds = 8304.7)
[2022-05-31 16:28:50,978][root][INFO] - Step 54883840 @ 7162.8 SPS. Inference batcher size: 129. Learner queue size: 23. Other stats: (step = 54883840, mean_episode_return = 125.96, mean_episode_step = 3207.9, total_loss = 63.224, pg_loss = 18.776, baseline_loss = 50.963, entropy_loss = -6.515, learner_queue_size = 22, _tick = 16648, _time = 1.654e+09, train_seconds = 8309.7)
[2022-05-31 16:28:55,984][root][INFO] - Step 54914560 @ 6136.7 SPS. Inference batcher size: 116. Learner queue size: 18. Other stats: (step = 54914560, mean_episode_return = 233.9, mean_episode_step = 715.77, total_loss = 547.94, pg_loss = 264.18, baseline_loss = 289.89, entropy_loss = -6.1244, learner_queue_size = 18, _tick = 16658, _time = 1.654e+09, train_seconds = 8314.7)
[2022-05-31 16:29:00,986][root][INFO] - Step 54947840 @ 6653.4 SPS. Inference batcher size: 16. Learner queue size: 9. Other stats: (step = 54947840, mean_episode_return = 167.74, mean_episode_step = 767.48, total_loss = 137.21, pg_loss = -17.265, baseline_loss = 160.34, entropy_loss = -5.8672, learner_queue_size = 20, _tick = 16671, _time = 1.654e+09, train_seconds = 8319.7)
[2022-05-31 16:29:05,990][root][INFO] - Step 54981120 @ 6650.6 SPS. Inference batcher size: 38. Learner queue size: 10. Other stats: (step = 54981120, mean_episode_return = 102.39, mean_episode_step = 891.03, total_loss = -231.48, pg_loss = -280.72, baseline_loss = 55.413, entropy_loss = -6.1757, learner_queue_size = 19, _tick = 16682, _time = 1.654e+09, train_seconds = 8324.7)
[2022-05-31 16:29:10,994][root][INFO] - Step 55014400 @ 6650.7 SPS. Inference batcher size: 109. Learner queue size: 13. Other stats: (step = 55014400, mean_episode_return = 187.51, mean_episode_step = 603.75, total_loss = 12.972, pg_loss = -55.392, baseline_loss = 74.605, entropy_loss = -6.2417, learner_queue_size = 9, _tick = 16694, _time = 1.654e+09, train_seconds = 8329.7)
[2022-05-31 16:29:16,000][root][INFO] - Step 55045120 @ 6136.3 SPS. Inference batcher size: 127. Learner queue size: 22. Other stats: (step = 55045120, mean_episode_return = 189.25, mean_episode_step = 2949.4, total_loss = -100.21, pg_loss = -174.38, baseline_loss = 79.95, entropy_loss = -5.7773, learner_queue_size = 17, _tick = 16705, _time = 1.654e+09, train_seconds = 8334.7)
[2022-05-31 16:29:21,006][root][INFO] - Step 55078400 @ 6648.4 SPS. Inference batcher size: 145. Learner queue size: 18. Other stats: (step = 55078400, mean_episode_return = 183.1, mean_episode_step = 749.64, total_loss = -41.685, pg_loss = -130.5, baseline_loss = 94.987, entropy_loss = -6.1743, learner_queue_size = 32, _tick = 16715, _time = 1.654e+09, train_seconds = 8339.7)
[2022-05-31 16:29:26,012][root][INFO] - Step 55111680 @ 6648.0 SPS. Inference batcher size: 99. Learner queue size: 4. Other stats: (step = 55111680, mean_episode_return = 147.71, mean_episode_step = 725.7, total_loss = -104.67, pg_loss = -177.84, baseline_loss = 78.978, entropy_loss = -5.8154, learner_queue_size = 21, _tick = 16725, _time = 1.654e+09, train_seconds = 8344.7)
[2022-05-31 16:29:31,018][root][INFO] - Step 55144960 @ 6648.2 SPS. Inference batcher size: 120. Learner queue size: 2. Other stats: (step = 55144960, mean_episode_return = 118.81, mean_episode_step = 908.06, total_loss = 297.4, pg_loss = 174.1, baseline_loss = 129.37, entropy_loss = -6.0674, learner_queue_size = 15, _tick = 16737, _time = 1.654e+09, train_seconds = 8349.7)
[2022-05-31 16:29:36,022][root][INFO] - Step 55178240 @ 6650.7 SPS. Inference batcher size: 115. Learner queue size: 18. Other stats: (step = 55178240, mean_episode_return = 169.07, mean_episode_step = 653.66, total_loss = 342.62, pg_loss = 193.7, baseline_loss = 154.87, entropy_loss = -5.9445, learner_queue_size = 8, _tick = 16748, _time = 1.654e+09, train_seconds = 8354.7)
[2022-05-31 16:29:41,026][root][INFO] - Step 55211520 @ 6650.6 SPS. Inference batcher size: 104. Learner queue size: 28. Other stats: (step = 55211520, mean_episode_return = 253.47, mean_episode_step = 680.55, total_loss = 74.606, pg_loss = -89.423, baseline_loss = 169.94, entropy_loss = -5.9103, learner_queue_size = 22, _tick = 16759, _time = 1.654e+09, train_seconds = 8359.7)
[2022-05-31 16:29:46,030][root][INFO] - Step 55244800 @ 6650.7 SPS. Inference batcher size: 116. Learner queue size: 26. Other stats: (step = 55244800, mean_episode_return = 102.25, mean_episode_step = 1030.1, total_loss = -8.3584, pg_loss = -42.402, baseline_loss = 40.045, entropy_loss = -6.0009, learner_queue_size = 26, _tick = 16772, _time = 1.654e+09, train_seconds = 8364.7)
[2022-05-31 16:29:51,034][root][INFO] - Step 55275520 @ 6139.0 SPS. Inference batcher size: 128. Learner queue size: 9. Other stats: (step = 55275520, mean_episode_return = 185.46, mean_episode_step = 817.93, total_loss = 278.21, pg_loss = 70.159, baseline_loss = 214.51, entropy_loss = -6.4559, learner_queue_size = 12, _tick = 16784, _time = 1.654e+09, train_seconds = 8369.7)
[2022-05-31 16:29:56,038][root][INFO] - Step 55308800 @ 6650.8 SPS. Inference batcher size: 103. Learner queue size: 9. Other stats: (step = 55308800, mean_episode_return = 75.291, mean_episode_step = 754.0, total_loss = 119.59, pg_loss = 71.693, baseline_loss = 54.258, entropy_loss = -6.3613, learner_queue_size = 26, _tick = 16794, _time = 1.654e+09, train_seconds = 8374.7)
[2022-05-31 16:30:01,042][root][INFO] - Step 55342080 @ 6650.6 SPS. Inference batcher size: 65. Learner queue size: 15. Other stats: (step = 55342080, mean_episode_return = None, mean_episode_step = 727.06, total_loss = -31.283, pg_loss = -68.375, baseline_loss = 42.895, entropy_loss = -5.8028, learner_queue_size = 8, _tick = 16801, _time = 1.654e+09, train_seconds = 8379.7)
[2022-05-31 16:30:06,046][root][INFO] - Step 55375360 @ 6650.6 SPS. Inference batcher size: 144. Learner queue size: 15. Other stats: (step = 55375360, mean_episode_return = None, mean_episode_step = 1000.6, total_loss = 294.94, pg_loss = 218.22, baseline_loss = 83.072, entropy_loss = -6.3519, learner_queue_size = 9, _tick = 16810, _time = 1.654e+09, train_seconds = 8384.7)
[2022-05-31 16:30:11,052][root][INFO] - Step 55406080 @ 6136.6 SPS. Inference batcher size: 132. Learner queue size: 24. Other stats: (step = 55406080, mean_episode_return = 112.59, mean_episode_step = 1057.5, total_loss = 107.31, pg_loss = 82.401, baseline_loss = 31.099, entropy_loss = -6.1883, learner_queue_size = 20, _tick = 16818, _time = 1.654e+09, train_seconds = 8389.7)
[2022-05-31 16:30:16,058][root][INFO] - Step 55439360 @ 6648.0 SPS. Inference batcher size: 67. Learner queue size: 3. Other stats: (step = 55439360, mean_episode_return = 122.63, mean_episode_step = 882.29, total_loss = 12.752, pg_loss = -49.32, baseline_loss = 68.404, entropy_loss = -6.3319, learner_queue_size = 10, _tick = 16830, _time = 1.654e+09, train_seconds = 8394.7)
[2022-05-31 16:30:21,062][root][INFO] - Step 55472640 @ 6650.8 SPS. Inference batcher size: 14. Learner queue size: 9. Other stats: (step = 55472640, mean_episode_return = 171.88, mean_episode_step = 838.3, total_loss = -22.109, pg_loss = -66.673, baseline_loss = 51.206, entropy_loss = -6.6424, learner_queue_size = 32, _tick = 16840, _time = 1.654e+09, train_seconds = 8399.7)
[2022-05-31 16:30:26,066][root][INFO] - Step 55505920 @ 6650.5 SPS. Inference batcher size: 116. Learner queue size: 22. Other stats: (step = 55505920, mean_episode_return = 83.36, mean_episode_step = 1037.1, total_loss = 0.80495, pg_loss = -17.061, baseline_loss = 24.565, entropy_loss = -6.699, learner_queue_size = 22, _tick = 16853, _time = 1.654e+09, train_seconds = 8404.8)
[2022-05-31 16:30:31,070][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 16:30:31,170][root][INFO] - Step 55539200 @ 6650.8 SPS. Inference batcher size: 217. Learner queue size: 25. Other stats: (step = 55539200, mean_episode_return = 1.8447, mean_episode_step = 957.58, total_loss = 53.979, pg_loss = 5.8353, baseline_loss = 54.815, entropy_loss = -6.6717, learner_queue_size = 11, _tick = 16865, _time = 1.654e+09, train_seconds = 8409.8)
[2022-05-31 16:30:36,174][root][INFO] - Step 55569920 @ 6018.7 SPS. Inference batcher size: 109. Learner queue size: 21. Other stats: (step = 55569920, mean_episode_return = 117.27, mean_episode_step = 922.63, total_loss = 23.483, pg_loss = -2.9778, baseline_loss = 33.19, entropy_loss = -6.7299, learner_queue_size = 23, _tick = 16876, _time = 1.654e+09, train_seconds = 8414.9)
[2022-05-31 16:30:41,180][root][INFO] - Step 55603200 @ 6647.9 SPS. Inference batcher size: 116. Learner queue size: 18. Other stats: (step = 55603200, mean_episode_return = 76.718, mean_episode_step = 882.37, total_loss = 442.45, pg_loss = 354.91, baseline_loss = 93.911, entropy_loss = -6.3691, learner_queue_size = 8, _tick = 16884, _time = 1.654e+09, train_seconds = 8419.9)
[2022-05-31 16:30:46,186][root][INFO] - Step 55639040 @ 7159.7 SPS. Inference batcher size: 146. Learner queue size: 19. Other stats: (step = 55639040, mean_episode_return = None, mean_episode_step = 709.34, total_loss = -69.549, pg_loss = -96.853, baseline_loss = 33.719, entropy_loss = -6.4143, learner_queue_size = 17, _tick = 16896, _time = 1.654e+09, train_seconds = 8424.9)
[2022-05-31 16:30:51,190][root][INFO] - Step 55669760 @ 6139.0 SPS. Inference batcher size: 116. Learner queue size: 2. Other stats: (step = 55669760, mean_episode_return = 54.911, mean_episode_step = 860.53, total_loss = 145.35, pg_loss = 114.79, baseline_loss = 37.018, entropy_loss = -6.453, learner_queue_size = 11, _tick = 16907, _time = 1.654e+09, train_seconds = 8429.9)
[2022-05-31 16:30:56,194][root][INFO] - Step 55703040 @ 6650.6 SPS. Inference batcher size: 96. Learner queue size: 0. Other stats: (step = 55703040, mean_episode_return = 96.04, mean_episode_step = 790.54, total_loss = 140.19, pg_loss = 85.672, baseline_loss = 61.209, entropy_loss = -6.6923, learner_queue_size = 13, _tick = 16920, _time = 1.654e+09, train_seconds = 8434.9)
[2022-05-31 16:31:01,200][root][INFO] - Step 55733760 @ 6136.3 SPS. Inference batcher size: 171. Learner queue size: 11. Other stats: (step = 55733760, mean_episode_return = 60.911, mean_episode_step = 980.18, total_loss = -209.43, pg_loss = -308.03, baseline_loss = 104.49, entropy_loss = -5.8789, learner_queue_size = 29, _tick = 16930, _time = 1.654e+09, train_seconds = 8439.9)
[2022-05-31 16:31:06,206][root][INFO] - Step 55767040 @ 6648.1 SPS. Inference batcher size: 106. Learner queue size: 13. Other stats: (step = 55767040, mean_episode_return = 213.62, mean_episode_step = 823.02, total_loss = 106.21, pg_loss = 57.185, baseline_loss = 55.13, entropy_loss = -6.1028, learner_queue_size = 12, _tick = 16941, _time = 1.654e+09, train_seconds = 8444.9)
[2022-05-31 16:31:11,210][root][INFO] - Step 55800320 @ 6651.0 SPS. Inference batcher size: 146. Learner queue size: 5. Other stats: (step = 55800320, mean_episode_return = 221.37, mean_episode_step = 687.25, total_loss = 30.407, pg_loss = -23.112, baseline_loss = 59.255, entropy_loss = -5.735, learner_queue_size = 28, _tick = 16954, _time = 1.654e+09, train_seconds = 8449.9)
[2022-05-31 16:31:16,214][root][INFO] - Step 55833600 @ 6650.9 SPS. Inference batcher size: 147. Learner queue size: 1. Other stats: (step = 55833600, mean_episode_return = 89.266, mean_episode_step = 572.68, total_loss = 100.15, pg_loss = -40.157, baseline_loss = 146.13, entropy_loss = -5.8182, learner_queue_size = 17, _tick = 16966, _time = 1.654e+09, train_seconds = 8454.9)
[2022-05-31 16:31:21,219][root][INFO] - Step 55866880 @ 6649.8 SPS. Inference batcher size: 138. Learner queue size: 27. Other stats: (step = 55866880, mean_episode_return = 69.499, mean_episode_step = 780.83, total_loss = 54.686, pg_loss = 3.4353, baseline_loss = 57.137, entropy_loss = -5.8871, learner_queue_size = 20, _tick = 16979, _time = 1.654e+09, train_seconds = 8459.9)
[2022-05-31 16:31:26,222][root][INFO] - Step 55897600 @ 6139.8 SPS. Inference batcher size: 151. Learner queue size: 22. Other stats: (step = 55897600, mean_episode_return = 106.8, mean_episode_step = 822.9, total_loss = -40.635, pg_loss = -100.54, baseline_loss = 65.858, entropy_loss = -5.9488, learner_queue_size = 23, _tick = 16989, _time = 1.654e+09, train_seconds = 8464.9)
[2022-05-31 16:31:31,228][root][INFO] - Step 55930880 @ 6648.0 SPS. Inference batcher size: 143. Learner queue size: 14. Other stats: (step = 55930880, mean_episode_return = 100.46, mean_episode_step = 550.27, total_loss = -163.18, pg_loss = -222.03, baseline_loss = 65.166, entropy_loss = -6.3158, learner_queue_size = 17, _tick = 17001, _time = 1.654e+09, train_seconds = 8469.9)
[2022-05-31 16:31:36,234][root][INFO] - Step 55964160 @ 6648.0 SPS. Inference batcher size: 159. Learner queue size: 12. Other stats: (step = 55964160, mean_episode_return = None, mean_episode_step = 749.06, total_loss = 154.42, pg_loss = 70.784, baseline_loss = 90.101, entropy_loss = -6.4647, learner_queue_size = 25, _tick = 17013, _time = 1.654e+09, train_seconds = 8474.9)
[2022-05-31 16:31:41,238][root][INFO] - Step 55997440 @ 6650.7 SPS. Inference batcher size: 94. Learner queue size: 11. Other stats: (step = 55997440, mean_episode_return = 13.25, mean_episode_step = 976.0, total_loss = 359.83, pg_loss = 206.54, baseline_loss = 159.9, entropy_loss = -6.6036, learner_queue_size = 17, _tick = 17025, _time = 1.654e+09, train_seconds = 8479.9)
[2022-05-31 16:31:46,242][root][INFO] - Step 56030720 @ 6650.8 SPS. Inference batcher size: 107. Learner queue size: 6. Other stats: (step = 56030720, mean_episode_return = 140.69, mean_episode_step = 763.17, total_loss = 151.58, pg_loss = 76.712, baseline_loss = 80.808, entropy_loss = -5.9432, learner_queue_size = 10, _tick = 17036, _time = 1.654e+09, train_seconds = 8484.9)
[2022-05-31 16:31:51,246][root][INFO] - Step 56064000 @ 6650.6 SPS. Inference batcher size: 88. Learner queue size: 7. Other stats: (step = 56064000, mean_episode_return = 149.53, mean_episode_step = 703.69, total_loss = -44.311, pg_loss = -165.8, baseline_loss = 127.83, entropy_loss = -6.3457, learner_queue_size = 23, _tick = 17047, _time = 1.654e+09, train_seconds = 8489.9)
[2022-05-31 16:31:56,250][root][INFO] - Step 56097280 @ 6650.7 SPS. Inference batcher size: 77. Learner queue size: 20. Other stats: (step = 56097280, mean_episode_return = 61.821, mean_episode_step = 650.54, total_loss = 244.11, pg_loss = 121.96, baseline_loss = 128.42, entropy_loss = -6.2657, learner_queue_size = 13, _tick = 17058, _time = 1.654e+09, train_seconds = 8494.9)
[2022-05-31 16:32:01,254][root][INFO] - Step 56130560 @ 6650.7 SPS. Inference batcher size: 72. Learner queue size: 0. Other stats: (step = 56130560, mean_episode_return = 367.71, mean_episode_step = 766.72, total_loss = 144.28, pg_loss = 5.8797, baseline_loss = 144.61, entropy_loss = -6.2057, learner_queue_size = 21, _tick = 17069, _time = 1.654e+09, train_seconds = 8499.9)
[2022-05-31 16:32:06,258][root][INFO] - Step 56161280 @ 6139.0 SPS. Inference batcher size: 120. Learner queue size: 25. Other stats: (step = 56161280, mean_episode_return = None, mean_episode_step = 3099.5, total_loss = 44.165, pg_loss = -16.349, baseline_loss = 66.781, entropy_loss = -6.2675, learner_queue_size = 23, _tick = 17080, _time = 1.654e+09, train_seconds = 8504.9)
[2022-05-31 16:32:11,262][root][INFO] - Step 56197120 @ 7162.2 SPS. Inference batcher size: 123. Learner queue size: 17. Other stats: (step = 56197120, mean_episode_return = None, mean_episode_step = 793.66, total_loss = 70.105, pg_loss = 11.209, baseline_loss = 65.256, entropy_loss = -6.3605, learner_queue_size = 13, _tick = 17091, _time = 1.654e+09, train_seconds = 8509.9)
[2022-05-31 16:32:16,266][root][INFO] - Step 56227840 @ 6139.2 SPS. Inference batcher size: 120. Learner queue size: 20. Other stats: (step = 56227840, mean_episode_return = 41.221, mean_episode_step = 1067.8, total_loss = 50.966, pg_loss = -17.646, baseline_loss = 74.768, entropy_loss = -6.156, learner_queue_size = 20, _tick = 17103, _time = 1.654e+09, train_seconds = 8515.0)
[2022-05-31 16:32:21,272][root][INFO] - Step 56261120 @ 6647.8 SPS. Inference batcher size: 77. Learner queue size: 6. Other stats: (step = 56261120, mean_episode_return = 168.37, mean_episode_step = 790.92, total_loss = 347.31, pg_loss = 179.37, baseline_loss = 173.76, entropy_loss = -5.824, learner_queue_size = 21, _tick = 17113, _time = 1.654e+09, train_seconds = 8520.0)
[2022-05-31 16:32:26,278][root][INFO] - Step 56294400 @ 6648.3 SPS. Inference batcher size: 106. Learner queue size: 12. Other stats: (step = 56294400, mean_episode_return = 55.96, mean_episode_step = 814.88, total_loss = 240.56, pg_loss = 126.85, baseline_loss = 119.79, entropy_loss = -6.0719, learner_queue_size = 17, _tick = 17124, _time = 1.654e+09, train_seconds = 8525.0)
[2022-05-31 16:32:31,282][root][INFO] - Step 56327680 @ 6650.6 SPS. Inference batcher size: 129. Learner queue size: 6. Other stats: (step = 56327680, mean_episode_return = 139.44, mean_episode_step = 943.73, total_loss = 111.44, pg_loss = -19.552, baseline_loss = 137.0, entropy_loss = -6.0109, learner_queue_size = 12, _tick = 17137, _time = 1.654e+09, train_seconds = 8530.0)
[2022-05-31 16:32:36,286][root][INFO] - Step 56360960 @ 6650.3 SPS. Inference batcher size: 130. Learner queue size: 23. Other stats: (step = 56360960, mean_episode_return = 134.39, mean_episode_step = 683.7, total_loss = 2.4673, pg_loss = -108.36, baseline_loss = 117.65, entropy_loss = -6.8255, learner_queue_size = 13, _tick = 17149, _time = 1.654e+09, train_seconds = 8535.0)
[2022-05-31 16:32:41,293][root][INFO] - Step 56391680 @ 6136.2 SPS. Inference batcher size: 115. Learner queue size: 19. Other stats: (step = 56391680, mean_episode_return = 488.67, mean_episode_step = 763.57, total_loss = 95.27, pg_loss = 15.344, baseline_loss = 86.473, entropy_loss = -6.5472, learner_queue_size = 23, _tick = 17160, _time = 1.654e+09, train_seconds = 8540.0)
[2022-05-31 16:32:46,299][root][INFO] - Step 56424960 @ 6648.1 SPS. Inference batcher size: 166. Learner queue size: 14. Other stats: (step = 56424960, mean_episode_return = 135.34, mean_episode_step = 743.4, total_loss = 271.4, pg_loss = 160.03, baseline_loss = 118.03, entropy_loss = -6.6675, learner_queue_size = 15, _tick = 17171, _time = 1.654e+09, train_seconds = 8545.0)
[2022-05-31 16:32:51,305][root][INFO] - Step 56458240 @ 6648.1 SPS. Inference batcher size: 161. Learner queue size: 18. Other stats: (step = 56458240, mean_episode_return = 56.256, mean_episode_step = 724.09, total_loss = -113.27, pg_loss = -204.7, baseline_loss = 97.663, entropy_loss = -6.2308, learner_queue_size = 27, _tick = 17182, _time = 1.654e+09, train_seconds = 8550.0)
[2022-05-31 16:32:56,311][root][INFO] - Step 56491520 @ 6648.1 SPS. Inference batcher size: 123. Learner queue size: 19. Other stats: (step = 56491520, mean_episode_return = 242.06, mean_episode_step = 694.38, total_loss = -147.71, pg_loss = -252.68, baseline_loss = 110.93, entropy_loss = -5.9609, learner_queue_size = 21, _tick = 17193, _time = 1.654e+09, train_seconds = 8555.0)
[2022-05-31 16:33:01,314][root][INFO] - Step 56524800 @ 6651.4 SPS. Inference batcher size: 78. Learner queue size: 6. Other stats: (step = 56524800, mean_episode_return = 66.46, mean_episode_step = 639.03, total_loss = 543.45, pg_loss = 365.95, baseline_loss = 183.57, entropy_loss = -6.0714, learner_queue_size = 19, _tick = 17206, _time = 1.654e+09, train_seconds = 8560.0)
[2022-05-31 16:33:06,320][root][INFO] - Step 56558080 @ 6647.4 SPS. Inference batcher size: 149. Learner queue size: 5. Other stats: (step = 56558080, mean_episode_return = 187.09, mean_episode_step = 754.01, total_loss = -45.2, pg_loss = -79.349, baseline_loss = 40.392, entropy_loss = -6.2435, learner_queue_size = 11, _tick = 17215, _time = 1.654e+09, train_seconds = 8565.0)
[2022-05-31 16:33:11,326][root][INFO] - Step 56591360 @ 6648.7 SPS. Inference batcher size: 126. Learner queue size: 2. Other stats: (step = 56591360, mean_episode_return = None, mean_episode_step = 3406.2, total_loss = 13.344, pg_loss = -34.18, baseline_loss = 53.53, entropy_loss = -6.0063, learner_queue_size = 24, _tick = 17226, _time = 1.654e+09, train_seconds = 8570.0)
[2022-05-31 16:33:16,330][root][INFO] - Step 56624640 @ 6650.7 SPS. Inference batcher size: 125. Learner queue size: 24. Other stats: (step = 56624640, mean_episode_return = 163.9, mean_episode_step = 606.07, total_loss = 461.09, pg_loss = 337.43, baseline_loss = 129.69, entropy_loss = -6.0371, learner_queue_size = 21, _tick = 17238, _time = 1.654e+09, train_seconds = 8575.0)
[2022-05-31 16:33:21,334][root][INFO] - Step 56655360 @ 6138.8 SPS. Inference batcher size: 25. Learner queue size: 24. Other stats: (step = 56655360, mean_episode_return = None, mean_episode_step = 863.22, total_loss = 47.003, pg_loss = 7.7451, baseline_loss = 45.382, entropy_loss = -6.1244, learner_queue_size = 25, _tick = 17249, _time = 1.654e+09, train_seconds = 8580.0)
[2022-05-31 16:33:26,338][root][INFO] - Step 56688640 @ 6651.0 SPS. Inference batcher size: 121. Learner queue size: 9. Other stats: (step = 56688640, mean_episode_return = 155.42, mean_episode_step = 672.39, total_loss = 80.617, pg_loss = 11.825, baseline_loss = 74.704, entropy_loss = -5.9127, learner_queue_size = 12, _tick = 17262, _time = 1.654e+09, train_seconds = 8585.0)
[2022-05-31 16:33:31,342][root][INFO] - Step 56721920 @ 6650.8 SPS. Inference batcher size: 29. Learner queue size: 5. Other stats: (step = 56721920, mean_episode_return = 76.599, mean_episode_step = 870.32, total_loss = -32.45, pg_loss = -67.777, baseline_loss = 40.83, entropy_loss = -5.5036, learner_queue_size = 12, _tick = 17274, _time = 1.654e+09, train_seconds = 8590.0)
[2022-05-31 16:33:36,349][root][INFO] - Step 56755200 @ 6647.0 SPS. Inference batcher size: 60. Learner queue size: 31. Other stats: (step = 56755200, mean_episode_return = 217.25, mean_episode_step = 1001.6, total_loss = 444.29, pg_loss = 267.26, baseline_loss = 183.3, entropy_loss = -6.2665, learner_queue_size = 23, _tick = 17286, _time = 1.654e+09, train_seconds = 8595.0)
[2022-05-31 16:33:41,354][root][INFO] - Step 56788480 @ 6648.9 SPS. Inference batcher size: 78. Learner queue size: 16. Other stats: (step = 56788480, mean_episode_return = 83.957, mean_episode_step = 724.69, total_loss = -2.602, pg_loss = -110.19, baseline_loss = 113.59, entropy_loss = -6.0018, learner_queue_size = 16, _tick = 17296, _time = 1.654e+09, train_seconds = 8600.0)
[2022-05-31 16:33:46,361][root][INFO] - Step 56819200 @ 6136.0 SPS. Inference batcher size: 88. Learner queue size: 13. Other stats: (step = 56819200, mean_episode_return = 59.855, mean_episode_step = 692.48, total_loss = 86.001, pg_loss = 20.015, baseline_loss = 72.191, entropy_loss = -6.204, learner_queue_size = 29, _tick = 17306, _time = 1.654e+09, train_seconds = 8605.0)
[2022-05-31 16:33:51,366][root][INFO] - Step 56852480 @ 6648.8 SPS. Inference batcher size: 125. Learner queue size: 14. Other stats: (step = 56852480, mean_episode_return = 110.52, mean_episode_step = 3293.7, total_loss = -20.067, pg_loss = -125.44, baseline_loss = 111.7, entropy_loss = -6.3212, learner_queue_size = 15, _tick = 17319, _time = 1.654e+09, train_seconds = 8610.1)
[2022-05-31 16:33:56,370][root][INFO] - Step 56885760 @ 6650.6 SPS. Inference batcher size: 132. Learner queue size: 19. Other stats: (step = 56885760, mean_episode_return = 272.81, mean_episode_step = 855.17, total_loss = 153.26, pg_loss = -16.821, baseline_loss = 176.02, entropy_loss = -5.9467, learner_queue_size = 19, _tick = 17331, _time = 1.654e+09, train_seconds = 8615.1)
[2022-05-31 16:34:01,374][root][INFO] - Step 56919040 @ 6650.7 SPS. Inference batcher size: 160. Learner queue size: 4. Other stats: (step = 56919040, mean_episode_return = None, mean_episode_step = 969.34, total_loss = -210.21, pg_loss = -237.19, baseline_loss = 33.625, entropy_loss = -6.6469, learner_queue_size = 18, _tick = 17342, _time = 1.654e+09, train_seconds = 8620.1)
[2022-05-31 16:34:06,378][root][INFO] - Step 56952320 @ 6650.7 SPS. Inference batcher size: 64. Learner queue size: 25. Other stats: (step = 56952320, mean_episode_return = 361.07, mean_episode_step = 681.61, total_loss = -175.42, pg_loss = -468.75, baseline_loss = 299.76, entropy_loss = -6.4315, learner_queue_size = 19, _tick = 17353, _time = 1.654e+09, train_seconds = 8625.1)
[2022-05-31 16:34:11,384][root][INFO] - Step 56983040 @ 6136.3 SPS. Inference batcher size: 158. Learner queue size: 25. Other stats: (step = 56983040, mean_episode_return = 128.38, mean_episode_step = 617.88, total_loss = 84.966, pg_loss = -11.053, baseline_loss = 102.75, entropy_loss = -6.7346, learner_queue_size = 32, _tick = 17364, _time = 1.654e+09, train_seconds = 8630.1)
[2022-05-31 16:34:16,390][root][INFO] - Step 57016320 @ 6648.4 SPS. Inference batcher size: 125. Learner queue size: 12. Other stats: (step = 57016320, mean_episode_return = 219.83, mean_episode_step = 754.19, total_loss = 492.01, pg_loss = 269.62, baseline_loss = 229.41, entropy_loss = -7.0165, learner_queue_size = 8, _tick = 17375, _time = 1.654e+09, train_seconds = 8635.1)
[2022-05-31 16:34:21,394][root][INFO] - Step 57049600 @ 6650.7 SPS. Inference batcher size: 130. Learner queue size: 7. Other stats: (step = 57049600, mean_episode_return = 161.92, mean_episode_step = 639.27, total_loss = 222.53, pg_loss = 98.577, baseline_loss = 130.28, entropy_loss = -6.3241, learner_queue_size = 20, _tick = 17385, _time = 1.654e+09, train_seconds = 8640.1)
[2022-05-31 16:34:26,398][root][INFO] - Step 57082880 @ 6650.7 SPS. Inference batcher size: 81. Learner queue size: 3. Other stats: (step = 57082880, mean_episode_return = 184.53, mean_episode_step = 755.13, total_loss = 4.1443, pg_loss = -72.978, baseline_loss = 83.626, entropy_loss = -6.5038, learner_queue_size = 15, _tick = 17397, _time = 1.654e+09, train_seconds = 8645.1)
[2022-05-31 16:34:31,404][root][INFO] - Step 57116160 @ 6648.2 SPS. Inference batcher size: 41. Learner queue size: 2. Other stats: (step = 57116160, mean_episode_return = 196.64, mean_episode_step = 3478.9, total_loss = -114.88, pg_loss = -162.76, baseline_loss = 54.702, entropy_loss = -6.827, learner_queue_size = 18, _tick = 17410, _time = 1.654e+09, train_seconds = 8650.1)
[2022-05-31 16:34:36,414][root][INFO] - Step 57149440 @ 6642.5 SPS. Inference batcher size: 191. Learner queue size: 4. Other stats: (step = 57149440, mean_episode_return = 566.8, mean_episode_step = 685.38, total_loss = -51.084, pg_loss = -159.5, baseline_loss = 114.62, entropy_loss = -6.2107, learner_queue_size = 32, _tick = 17422, _time = 1.654e+09, train_seconds = 8655.1)
[2022-05-31 16:34:41,418][root][INFO] - Step 57182720 @ 6650.8 SPS. Inference batcher size: 163. Learner queue size: 3. Other stats: (step = 57182720, mean_episode_return = 139.2, mean_episode_step = 1114.3, total_loss = 65.902, pg_loss = -25.703, baseline_loss = 97.894, entropy_loss = -6.2888, learner_queue_size = 9, _tick = 17433, _time = 1.654e+09, train_seconds = 8660.1)
[2022-05-31 16:34:46,422][root][INFO] - Step 57216000 @ 6650.6 SPS. Inference batcher size: 83. Learner queue size: 1. Other stats: (step = 57216000, mean_episode_return = 147.33, mean_episode_step = 3464.1, total_loss = 147.29, pg_loss = 29.046, baseline_loss = 124.67, entropy_loss = -6.4245, learner_queue_size = 12, _tick = 17443, _time = 1.654e+09, train_seconds = 8665.1)
[2022-05-31 16:34:51,426][root][INFO] - Step 57249280 @ 6650.7 SPS. Inference batcher size: 104. Learner queue size: 25. Other stats: (step = 57249280, mean_episode_return = 219.39, mean_episode_step = 958.79, total_loss = -503.24, pg_loss = -739.19, baseline_loss = 242.49, entropy_loss = -6.5325, learner_queue_size = 7, _tick = 17453, _time = 1.654e+09, train_seconds = 8670.1)
[2022-05-31 16:34:56,430][root][INFO] - Step 57282560 @ 6650.7 SPS. Inference batcher size: 55. Learner queue size: 14. Other stats: (step = 57282560, mean_episode_return = 123.31, mean_episode_step = 919.95, total_loss = -77.599, pg_loss = -144.5, baseline_loss = 73.462, entropy_loss = -6.5646, learner_queue_size = 14, _tick = 17465, _time = 1.654e+09, train_seconds = 8675.1)
[2022-05-31 16:35:01,436][root][INFO] - Step 57313280 @ 6136.1 SPS. Inference batcher size: 78. Learner queue size: 21. Other stats: (step = 57313280, mean_episode_return = 26.99, mean_episode_step = 616.61, total_loss = 373.78, pg_loss = 252.8, baseline_loss = 126.74, entropy_loss = -5.7579, learner_queue_size = 31, _tick = 17477, _time = 1.654e+09, train_seconds = 8680.1)
[2022-05-31 16:35:06,442][root][INFO] - Step 57346560 @ 6648.0 SPS. Inference batcher size: 128. Learner queue size: 6. Other stats: (step = 57346560, mean_episode_return = 200.48, mean_episode_step = 526.28, total_loss = 406.97, pg_loss = 201.37, baseline_loss = 211.63, entropy_loss = -6.0309, learner_queue_size = 21, _tick = 17489, _time = 1.654e+09, train_seconds = 8685.1)
[2022-05-31 16:35:11,446][root][INFO] - Step 57379840 @ 6651.3 SPS. Inference batcher size: 21. Learner queue size: 1. Other stats: (step = 57379840, mean_episode_return = 48.241, mean_episode_step = 617.35, total_loss = -8.3745, pg_loss = -54.889, baseline_loss = 53.048, entropy_loss = -6.533, learner_queue_size = 16, _tick = 17498, _time = 1.654e+09, train_seconds = 8690.1)
[2022-05-31 16:35:16,450][root][INFO] - Step 57410560 @ 6139.1 SPS. Inference batcher size: 185. Learner queue size: 20. Other stats: (step = 57410560, mean_episode_return = 44.04, mean_episode_step = 872.5, total_loss = 504.55, pg_loss = 408.09, baseline_loss = 102.86, entropy_loss = -6.4006, learner_queue_size = 26, _tick = 17507, _time = 1.654e+09, train_seconds = 8695.1)
[2022-05-31 16:35:21,454][root][INFO] - Step 57446400 @ 7162.3 SPS. Inference batcher size: 94. Learner queue size: 25. Other stats: (step = 57446400, mean_episode_return = 250.44, mean_episode_step = 771.98, total_loss = 118.62, pg_loss = 69.662, baseline_loss = 55.525, entropy_loss = -6.562, learner_queue_size = 19, _tick = 17519, _time = 1.654e+09, train_seconds = 8700.1)
[2022-05-31 16:35:26,458][root][INFO] - Step 57479680 @ 6650.8 SPS. Inference batcher size: 93. Learner queue size: 20. Other stats: (step = 57479680, mean_episode_return = 85.719, mean_episode_step = 653.65, total_loss = 263.67, pg_loss = 159.57, baseline_loss = 110.19, entropy_loss = -6.0934, learner_queue_size = 20, _tick = 17528, _time = 1.654e+09, train_seconds = 8705.1)
[2022-05-31 16:35:31,462][root][INFO] - Step 57510400 @ 6139.0 SPS. Inference batcher size: 145. Learner queue size: 22. Other stats: (step = 57510400, mean_episode_return = 140.18, mean_episode_step = 792.0, total_loss = 314.54, pg_loss = 91.553, baseline_loss = 229.7, entropy_loss = -6.7172, learner_queue_size = 21, _tick = 17538, _time = 1.654e+09, train_seconds = 8710.1)
[2022-05-31 16:35:36,466][root][INFO] - Step 57543680 @ 6650.7 SPS. Inference batcher size: 70. Learner queue size: 13. Other stats: (step = 57543680, mean_episode_return = 127.95, mean_episode_step = 1192.6, total_loss = 225.07, pg_loss = 163.12, baseline_loss = 68.752, entropy_loss = -6.8015, learner_queue_size = 14, _tick = 17550, _time = 1.654e+09, train_seconds = 8715.2)
[2022-05-31 16:35:41,470][root][INFO] - Step 57576960 @ 6650.8 SPS. Inference batcher size: 109. Learner queue size: 6. Other stats: (step = 57576960, mean_episode_return = 125.49, mean_episode_step = 584.7, total_loss = -11.011, pg_loss = -79.09, baseline_loss = 74.897, entropy_loss = -6.8186, learner_queue_size = 24, _tick = 17563, _time = 1.654e+09, train_seconds = 8720.2)
[2022-05-31 16:35:46,474][root][INFO] - Step 57610240 @ 6650.7 SPS. Inference batcher size: 154. Learner queue size: 30. Other stats: (step = 57610240, mean_episode_return = 149.97, mean_episode_step = 686.92, total_loss = 39.991, pg_loss = -26.494, baseline_loss = 73.392, entropy_loss = -6.9074, learner_queue_size = 13, _tick = 17574, _time = 1.654e+09, train_seconds = 8725.2)
[2022-05-31 16:35:51,478][root][INFO] - Step 57643520 @ 6650.6 SPS. Inference batcher size: 147. Learner queue size: 1. Other stats: (step = 57643520, mean_episode_return = 27.72, mean_episode_step = 762.91, total_loss = 9.3943, pg_loss = -34.771, baseline_loss = 50.399, entropy_loss = -6.2336, learner_queue_size = 23, _tick = 17585, _time = 1.654e+09, train_seconds = 8730.2)
[2022-05-31 16:35:56,484][root][INFO] - Step 57674240 @ 6136.8 SPS. Inference batcher size: 99. Learner queue size: 21. Other stats: (step = 57674240, mean_episode_return = 136.37, mean_episode_step = 645.6, total_loss = -381.34, pg_loss = -435.62, baseline_loss = 60.529, entropy_loss = -6.245, learner_queue_size = 16, _tick = 17595, _time = 1.654e+09, train_seconds = 8735.2)
[2022-05-31 16:36:01,486][root][INFO] - Step 57710080 @ 7164.8 SPS. Inference batcher size: 71. Learner queue size: 19. Other stats: (step = 57710080, mean_episode_return = 63.605, mean_episode_step = 649.2, total_loss = 341.66, pg_loss = 236.56, baseline_loss = 111.11, entropy_loss = -6.0143, learner_queue_size = 19, _tick = 17608, _time = 1.654e+09, train_seconds = 8740.2)
[2022-05-31 16:36:06,490][root][INFO] - Step 57743360 @ 6650.9 SPS. Inference batcher size: 139. Learner queue size: 26. Other stats: (step = 57743360, mean_episode_return = 25.85, mean_episode_step = 3352.4, total_loss = 159.54, pg_loss = 39.649, baseline_loss = 126.2, entropy_loss = -6.3047, learner_queue_size = 21, _tick = 17620, _time = 1.654e+09, train_seconds = 8745.2)
[2022-05-31 16:36:11,496][root][INFO] - Step 57774080 @ 6136.2 SPS. Inference batcher size: 121. Learner queue size: 11. Other stats: (step = 57774080, mean_episode_return = 144.84, mean_episode_step = 576.26, total_loss = 107.9, pg_loss = -50.752, baseline_loss = 164.62, entropy_loss = -5.9729, learner_queue_size = 13, _tick = 17632, _time = 1.654e+09, train_seconds = 8750.2)
[2022-05-31 16:36:16,502][root][INFO] - Step 57807360 @ 6648.4 SPS. Inference batcher size: 96. Learner queue size: 18. Other stats: (step = 57807360, mean_episode_return = None, mean_episode_step = 1166.3, total_loss = 262.6, pg_loss = 175.49, baseline_loss = 93.592, entropy_loss = -6.4832, learner_queue_size = 15, _tick = 17644, _time = 1.654e+09, train_seconds = 8755.2)
[2022-05-31 16:36:21,506][root][INFO] - Step 57840640 @ 6650.6 SPS. Inference batcher size: 109. Learner queue size: 0. Other stats: (step = 57840640, mean_episode_return = 70.943, mean_episode_step = 799.23, total_loss = 9.5269, pg_loss = -15.236, baseline_loss = 31.38, entropy_loss = -6.6172, learner_queue_size = 28, _tick = 17656, _time = 1.654e+09, train_seconds = 8760.2)
[2022-05-31 16:36:26,510][root][INFO] - Step 57873920 @ 6650.9 SPS. Inference batcher size: 127. Learner queue size: 2. Other stats: (step = 57873920, mean_episode_return = 43.93, mean_episode_step = 646.6, total_loss = -110.31, pg_loss = -152.81, baseline_loss = 48.752, entropy_loss = -6.2535, learner_queue_size = 17, _tick = 17668, _time = 1.654e+09, train_seconds = 8765.2)
[2022-05-31 16:36:31,514][root][INFO] - Step 57907200 @ 6650.6 SPS. Inference batcher size: 85. Learner queue size: 30. Other stats: (step = 57907200, mean_episode_return = 152.31, mean_episode_step = 633.66, total_loss = 277.05, pg_loss = 158.76, baseline_loss = 124.55, entropy_loss = -6.257, learner_queue_size = 26, _tick = 17680, _time = 1.654e+09, train_seconds = 8770.2)
[2022-05-31 16:36:36,518][root][INFO] - Step 57937920 @ 6139.2 SPS. Inference batcher size: 158. Learner queue size: 14. Other stats: (step = 57937920, mean_episode_return = 35.741, mean_episode_step = 764.9, total_loss = 81.905, pg_loss = -10.278, baseline_loss = 98.76, entropy_loss = -6.5768, learner_queue_size = 11, _tick = 17690, _time = 1.654e+09, train_seconds = 8775.2)
[2022-05-31 16:36:41,521][root][INFO] - Step 57971200 @ 6651.9 SPS. Inference batcher size: 123. Learner queue size: 15. Other stats: (step = 57971200, mean_episode_return = 93.729, mean_episode_step = 1167.4, total_loss = -36.37, pg_loss = -92.123, baseline_loss = 62.272, entropy_loss = -6.5195, learner_queue_size = 13, _tick = 17701, _time = 1.654e+09, train_seconds = 8780.2)
[2022-05-31 16:36:46,526][root][INFO] - Step 58004480 @ 6649.5 SPS. Inference batcher size: 116. Learner queue size: 9. Other stats: (step = 58004480, mean_episode_return = 125.93, mean_episode_step = 877.72, total_loss = 0.93214, pg_loss = -36.099, baseline_loss = 43.551, entropy_loss = -6.5199, learner_queue_size = 18, _tick = 17713, _time = 1.654e+09, train_seconds = 8785.2)
[2022-05-31 16:36:51,534][root][INFO] - Step 58037760 @ 6644.9 SPS. Inference batcher size: 227. Learner queue size: 2. Other stats: (step = 58037760, mean_episode_return = 213.88, mean_episode_step = 782.01, total_loss = 608.51, pg_loss = 81.601, baseline_loss = 533.45, entropy_loss = -6.5432, learner_queue_size = 21, _tick = 17726, _time = 1.654e+09, train_seconds = 8790.2)
[2022-05-31 16:36:56,540][root][INFO] - Step 58071040 @ 6648.4 SPS. Inference batcher size: 114. Learner queue size: 5. Other stats: (step = 58071040, mean_episode_return = 157.06, mean_episode_step = 619.05, total_loss = 255.96, pg_loss = 156.81, baseline_loss = 105.45, entropy_loss = -6.295, learner_queue_size = 23, _tick = 17736, _time = 1.654e+09, train_seconds = 8795.2)
[2022-05-31 16:37:01,542][root][INFO] - Step 58104320 @ 6653.4 SPS. Inference batcher size: 174. Learner queue size: 27. Other stats: (step = 58104320, mean_episode_return = 98.13, mean_episode_step = 888.45, total_loss = -28.295, pg_loss = -60.887, baseline_loss = 38.93, entropy_loss = -6.3386, learner_queue_size = 15, _tick = 17749, _time = 1.654e+09, train_seconds = 8800.2)
[2022-05-31 16:37:06,546][root][INFO] - Step 58137600 @ 6650.7 SPS. Inference batcher size: 90. Learner queue size: 28. Other stats: (step = 58137600, mean_episode_return = None, mean_episode_step = 707.66, total_loss = 265.33, pg_loss = 194.99, baseline_loss = 76.621, entropy_loss = -6.2808, learner_queue_size = 10, _tick = 17760, _time = 1.654e+09, train_seconds = 8805.2)
[2022-05-31 16:37:11,550][root][INFO] - Step 58168320 @ 6138.5 SPS. Inference batcher size: 99. Learner queue size: 11. Other stats: (step = 58168320, mean_episode_return = 274.54, mean_episode_step = 3616.0, total_loss = 73.113, pg_loss = -27.947, baseline_loss = 107.48, entropy_loss = -6.4199, learner_queue_size = 14, _tick = 17771, _time = 1.654e+09, train_seconds = 8810.2)
[2022-05-31 16:37:16,556][root][INFO] - Step 58201600 @ 6648.3 SPS. Inference batcher size: 102. Learner queue size: 10. Other stats: (step = 58201600, mean_episode_return = 315.05, mean_episode_step = 952.04, total_loss = 57.548, pg_loss = -158.26, baseline_loss = 222.0, entropy_loss = -6.1822, learner_queue_size = 16, _tick = 17782, _time = 1.654e+09, train_seconds = 8815.2)
[2022-05-31 16:37:21,559][root][INFO] - Step 58234880 @ 6652.9 SPS. Inference batcher size: 189. Learner queue size: 29. Other stats: (step = 58234880, mean_episode_return = 227.17, mean_episode_step = 924.68, total_loss = 136.38, pg_loss = -42.453, baseline_loss = 185.06, entropy_loss = -6.2234, learner_queue_size = 23, _tick = 17793, _time = 1.654e+09, train_seconds = 8820.2)
[2022-05-31 16:37:26,565][root][INFO] - Step 58268160 @ 6647.9 SPS. Inference batcher size: 116. Learner queue size: 13. Other stats: (step = 58268160, mean_episode_return = None, mean_episode_step = 3606.4, total_loss = 6.7057, pg_loss = -82.767, baseline_loss = 95.443, entropy_loss = -5.9703, learner_queue_size = 20, _tick = 17804, _time = 1.654e+09, train_seconds = 8825.2)
[2022-05-31 16:37:31,570][root][INFO] - Step 58301440 @ 6648.9 SPS. Inference batcher size: 41. Learner queue size: 14. Other stats: (step = 58301440, mean_episode_return = 91.09, mean_episode_step = 553.27, total_loss = 154.16, pg_loss = 30.172, baseline_loss = 130.03, entropy_loss = -6.0354, learner_queue_size = 19, _tick = 17817, _time = 1.654e+09, train_seconds = 8830.3)
[2022-05-31 16:37:36,574][root][INFO] - Step 58334720 @ 6650.5 SPS. Inference batcher size: 106. Learner queue size: 17. Other stats: (step = 58334720, mean_episode_return = 247.5, mean_episode_step = 757.2, total_loss = -35.764, pg_loss = -148.79, baseline_loss = 119.65, entropy_loss = -6.6269, learner_queue_size = 24, _tick = 17829, _time = 1.654e+09, train_seconds = 8835.3)
[2022-05-31 16:37:41,578][root][INFO] - Step 58368000 @ 6650.9 SPS. Inference batcher size: 0. Learner queue size: 9. Other stats: (step = 58368000, mean_episode_return = None, mean_episode_step = 3747.7, total_loss = 255.44, pg_loss = 224.84, baseline_loss = 37.373, entropy_loss = -6.7696, learner_queue_size = 20, _tick = 17840, _time = 1.654e+09, train_seconds = 8840.3)
[2022-05-31 16:37:46,582][root][INFO] - Step 58401280 @ 6650.5 SPS. Inference batcher size: 119. Learner queue size: 3. Other stats: (step = 58401280, mean_episode_return = None, mean_episode_step = 664.41, total_loss = 160.49, pg_loss = 111.06, baseline_loss = 55.667, entropy_loss = -6.2403, learner_queue_size = 23, _tick = 17851, _time = 1.654e+09, train_seconds = 8845.3)
[2022-05-31 16:37:51,586][root][INFO] - Step 58434560 @ 6650.8 SPS. Inference batcher size: 33. Learner queue size: 28. Other stats: (step = 58434560, mean_episode_return = 104.24, mean_episode_step = 764.21, total_loss = 287.96, pg_loss = 214.72, baseline_loss = 79.829, entropy_loss = -6.5833, learner_queue_size = 18, _tick = 17861, _time = 1.654e+09, train_seconds = 8850.3)
[2022-05-31 16:37:56,590][root][INFO] - Step 58467840 @ 6650.5 SPS. Inference batcher size: 74. Learner queue size: 29. Other stats: (step = 58467840, mean_episode_return = 71.21, mean_episode_step = 726.75, total_loss = 344.97, pg_loss = 200.31, baseline_loss = 151.22, entropy_loss = -6.5623, learner_queue_size = 21, _tick = 17871, _time = 1.654e+09, train_seconds = 8855.3)
[2022-05-31 16:38:01,594][root][INFO] - Step 58498560 @ 6139.1 SPS. Inference batcher size: 127. Learner queue size: 21. Other stats: (step = 58498560, mean_episode_return = 111.48, mean_episode_step = 1209.3, total_loss = 52.934, pg_loss = -9.6682, baseline_loss = 69.149, entropy_loss = -6.5473, learner_queue_size = 21, _tick = 17882, _time = 1.654e+09, train_seconds = 8860.3)
[2022-05-31 16:38:06,598][root][INFO] - Step 58534400 @ 7162.4 SPS. Inference batcher size: 123. Learner queue size: 18. Other stats: (step = 58534400, mean_episode_return = 70.254, mean_episode_step = 792.39, total_loss = -82.409, pg_loss = -117.56, baseline_loss = 41.555, entropy_loss = -6.4051, learner_queue_size = 18, _tick = 17894, _time = 1.654e+09, train_seconds = 8865.3)
[2022-05-31 16:38:11,602][root][INFO] - Step 58567680 @ 6650.7 SPS. Inference batcher size: 102. Learner queue size: 0. Other stats: (step = 58567680, mean_episode_return = 93.749, mean_episode_step = 822.07, total_loss = 44.502, pg_loss = -1.2376, baseline_loss = 52.365, entropy_loss = -6.6249, learner_queue_size = 22, _tick = 17907, _time = 1.654e+09, train_seconds = 8870.3)
[2022-05-31 16:38:16,606][root][INFO] - Step 58598400 @ 6139.0 SPS. Inference batcher size: 121. Learner queue size: 27. Other stats: (step = 58598400, mean_episode_return = None, mean_episode_step = 1274.5, total_loss = 204.2, pg_loss = 125.84, baseline_loss = 84.922, entropy_loss = -6.5554, learner_queue_size = 11, _tick = 17916, _time = 1.654e+09, train_seconds = 8875.3)
[2022-05-31 16:38:21,610][root][INFO] - Step 58631680 @ 6650.7 SPS. Inference batcher size: 87. Learner queue size: 10. Other stats: (step = 58631680, mean_episode_return = 63.523, mean_episode_step = 661.73, total_loss = 641.39, pg_loss = 332.35, baseline_loss = 315.12, entropy_loss = -6.09, learner_queue_size = 18, _tick = 17928, _time = 1.654e+09, train_seconds = 8880.3)
[2022-05-31 16:38:26,614][root][INFO] - Step 58664960 @ 6650.8 SPS. Inference batcher size: 99. Learner queue size: 6. Other stats: (step = 58664960, mean_episode_return = 149.0, mean_episode_step = 941.96, total_loss = -126.61, pg_loss = -196.95, baseline_loss = 76.537, entropy_loss = -6.2, learner_queue_size = 17, _tick = 17941, _time = 1.654e+09, train_seconds = 8885.3)
[2022-05-31 16:38:31,620][root][INFO] - Step 58698240 @ 6648.0 SPS. Inference batcher size: 122. Learner queue size: 2. Other stats: (step = 58698240, mean_episode_return = 118.98, mean_episode_step = 1194.5, total_loss = -163.92, pg_loss = -209.99, baseline_loss = 52.404, entropy_loss = -6.3348, learner_queue_size = 18, _tick = 17950, _time = 1.654e+09, train_seconds = 8890.3)
[2022-05-31 16:38:36,626][root][INFO] - Step 58731520 @ 6647.9 SPS. Inference batcher size: 60. Learner queue size: 3. Other stats: (step = 58731520, mean_episode_return = 131.47, mean_episode_step = 677.96, total_loss = 435.01, pg_loss = 284.26, baseline_loss = 157.65, entropy_loss = -6.9084, learner_queue_size = 19, _tick = 17963, _time = 1.654e+09, train_seconds = 8895.3)
[2022-05-31 16:38:41,630][root][INFO] - Step 58764800 @ 6650.9 SPS. Inference batcher size: 132. Learner queue size: 3. Other stats: (step = 58764800, mean_episode_return = 61.29, mean_episode_step = 796.72, total_loss = 264.07, pg_loss = 171.49, baseline_loss = 99.135, entropy_loss = -6.5512, learner_queue_size = 19, _tick = 17974, _time = 1.654e+09, train_seconds = 8900.3)
[2022-05-31 16:38:46,636][root][INFO] - Step 58795520 @ 6136.5 SPS. Inference batcher size: 147. Learner queue size: 14. Other stats: (step = 58795520, mean_episode_return = 105.67, mean_episode_step = 569.5, total_loss = 408.81, pg_loss = 234.69, baseline_loss = 179.9, entropy_loss = -5.7776, learner_queue_size = 18, _tick = 17985, _time = 1.654e+09, train_seconds = 8905.3)
[2022-05-31 16:38:51,642][root][INFO] - Step 58828800 @ 6647.8 SPS. Inference batcher size: 127. Learner queue size: 11. Other stats: (step = 58828800, mean_episode_return = 134.2, mean_episode_step = 890.37, total_loss = 74.29, pg_loss = 24.054, baseline_loss = 56.339, entropy_loss = -6.1028, learner_queue_size = 28, _tick = 17995, _time = 1.654e+09, train_seconds = 8910.3)
[2022-05-31 16:38:56,648][root][INFO] - Step 58862080 @ 6648.0 SPS. Inference batcher size: 103. Learner queue size: 7. Other stats: (step = 58862080, mean_episode_return = 127.2, mean_episode_step = 1250.1, total_loss = 84.317, pg_loss = -13.984, baseline_loss = 104.16, entropy_loss = -5.8615, learner_queue_size = 16, _tick = 18005, _time = 1.654e+09, train_seconds = 8915.3)
[2022-05-31 16:39:01,654][root][INFO] - Step 58895360 @ 6648.4 SPS. Inference batcher size: 114. Learner queue size: 18. Other stats: (step = 58895360, mean_episode_return = 135.45, mean_episode_step = 661.48, total_loss = 171.71, pg_loss = 117.07, baseline_loss = 61.245, entropy_loss = -6.6036, learner_queue_size = 22, _tick = 18016, _time = 1.654e+09, train_seconds = 8920.3)
[2022-05-31 16:39:06,658][root][INFO] - Step 58928640 @ 6650.6 SPS. Inference batcher size: 69. Learner queue size: 23. Other stats: (step = 58928640, mean_episode_return = 97.093, mean_episode_step = 773.95, total_loss = 249.27, pg_loss = 25.21, baseline_loss = 230.49, entropy_loss = -6.4269, learner_queue_size = 17, _tick = 18029, _time = 1.654e+09, train_seconds = 8925.3)
[2022-05-31 16:39:11,663][root][INFO] - Step 58961920 @ 6649.9 SPS. Inference batcher size: 71. Learner queue size: 28. Other stats: (step = 58961920, mean_episode_return = 69.661, mean_episode_step = 753.41, total_loss = 45.057, pg_loss = 14.635, baseline_loss = 36.711, entropy_loss = -6.2895, learner_queue_size = 19, _tick = 18040, _time = 1.654e+09, train_seconds = 8930.3)
[2022-05-31 16:39:16,666][root][INFO] - Step 58995200 @ 6651.3 SPS. Inference batcher size: 27. Learner queue size: 22. Other stats: (step = 58995200, mean_episode_return = 57.071, mean_episode_step = 678.96, total_loss = -18.121, pg_loss = -38.586, baseline_loss = 26.829, entropy_loss = -6.3638, learner_queue_size = 14, _tick = 18052, _time = 1.654e+09, train_seconds = 8935.4)
[2022-05-31 16:39:21,670][root][INFO] - Step 59028480 @ 6651.0 SPS. Inference batcher size: 92. Learner queue size: 29. Other stats: (step = 59028480, mean_episode_return = 259.01, mean_episode_step = 703.43, total_loss = 81.54, pg_loss = 33.877, baseline_loss = 54.254, entropy_loss = -6.591, learner_queue_size = 17, _tick = 18065, _time = 1.654e+09, train_seconds = 8940.4)
[2022-05-31 16:39:26,674][root][INFO] - Step 59059200 @ 6139.0 SPS. Inference batcher size: 107. Learner queue size: 28. Other stats: (step = 59059200, mean_episode_return = None, mean_episode_step = 3663.5, total_loss = 141.63, pg_loss = 73.471, baseline_loss = 74.469, entropy_loss = -6.3104, learner_queue_size = 28, _tick = 18074, _time = 1.654e+09, train_seconds = 8945.4)
[2022-05-31 16:39:31,680][root][INFO] - Step 59092480 @ 6647.9 SPS. Inference batcher size: 100. Learner queue size: 29. Other stats: (step = 59092480, mean_episode_return = None, mean_episode_step = 750.62, total_loss = 145.19, pg_loss = 109.53, baseline_loss = 42.039, entropy_loss = -6.3764, learner_queue_size = 21, _tick = 18085, _time = 1.654e+09, train_seconds = 8950.4)
[2022-05-31 16:39:36,686][root][INFO] - Step 59128320 @ 7159.5 SPS. Inference batcher size: 106. Learner queue size: 24. Other stats: (step = 59128320, mean_episode_return = 210.27, mean_episode_step = 615.06, total_loss = -38.918, pg_loss = -95.471, baseline_loss = 62.702, entropy_loss = -6.1485, learner_queue_size = 13, _tick = 18098, _time = 1.654e+09, train_seconds = 8955.4)
[2022-05-31 16:39:41,692][root][INFO] - Step 59159040 @ 6136.4 SPS. Inference batcher size: 115. Learner queue size: 15. Other stats: (step = 59159040, mean_episode_return = 195.12, mean_episode_step = 695.37, total_loss = 129.37, pg_loss = 34.575, baseline_loss = 100.99, entropy_loss = -6.1941, learner_queue_size = 17, _tick = 18110, _time = 1.654e+09, train_seconds = 8960.4)
[2022-05-31 16:39:46,698][root][INFO] - Step 59192320 @ 6648.4 SPS. Inference batcher size: 8. Learner queue size: 4. Other stats: (step = 59192320, mean_episode_return = 111.54, mean_episode_step = 657.83, total_loss = 17.298, pg_loss = -37.94, baseline_loss = 61.534, entropy_loss = -6.2963, learner_queue_size = 32, _tick = 18123, _time = 1.654e+09, train_seconds = 8965.4)
[2022-05-31 16:39:51,702][root][INFO] - Step 59225600 @ 6650.7 SPS. Inference batcher size: 134. Learner queue size: 10. Other stats: (step = 59225600, mean_episode_return = 277.25, mean_episode_step = 720.78, total_loss = 39.647, pg_loss = -75.029, baseline_loss = 120.77, entropy_loss = -6.0919, learner_queue_size = 23, _tick = 18134, _time = 1.654e+09, train_seconds = 8970.4)
[2022-05-31 16:39:56,707][root][INFO] - Step 59258880 @ 6649.5 SPS. Inference batcher size: 14. Learner queue size: 5. Other stats: (step = 59258880, mean_episode_return = 166.24, mean_episode_step = 867.75, total_loss = 216.96, pg_loss = 131.01, baseline_loss = 92.631, entropy_loss = -6.685, learner_queue_size = 28, _tick = 18147, _time = 1.654e+09, train_seconds = 8975.4)
[2022-05-31 16:40:01,710][root][INFO] - Step 59292160 @ 6651.9 SPS. Inference batcher size: 83. Learner queue size: 0. Other stats: (step = 59292160, mean_episode_return = 151.31, mean_episode_step = 620.73, total_loss = 140.35, pg_loss = 79.616, baseline_loss = 66.619, entropy_loss = -5.8877, learner_queue_size = 13, _tick = 18160, _time = 1.654e+09, train_seconds = 8980.4)
[2022-05-31 16:40:06,714][root][INFO] - Step 59325440 @ 6650.7 SPS. Inference batcher size: 119. Learner queue size: 26. Other stats: (step = 59325440, mean_episode_return = 141.73, mean_episode_step = 656.9, total_loss = 25.881, pg_loss = -105.42, baseline_loss = 136.95, entropy_loss = -5.6432, learner_queue_size = 19, _tick = 18170, _time = 1.654e+09, train_seconds = 8985.4)
[2022-05-31 16:40:11,718][root][INFO] - Step 59358720 @ 6650.7 SPS. Inference batcher size: 124. Learner queue size: 0. Other stats: (step = 59358720, mean_episode_return = 87.255, mean_episode_step = 853.74, total_loss = 180.47, pg_loss = 8.8913, baseline_loss = 177.46, entropy_loss = -5.8787, learner_queue_size = 12, _tick = 18181, _time = 1.654e+09, train_seconds = 8990.4)
[2022-05-31 16:40:16,722][root][INFO] - Step 59392000 @ 6650.7 SPS. Inference batcher size: 206. Learner queue size: 1. Other stats: (step = 59392000, mean_episode_return = 94.29, mean_episode_step = 1200.5, total_loss = 802.14, pg_loss = 498.69, baseline_loss = 309.14, entropy_loss = -5.6904, learner_queue_size = 28, _tick = 18193, _time = 1.654e+09, train_seconds = 8995.4)
[2022-05-31 16:40:21,726][root][INFO] - Step 59425280 @ 6650.6 SPS. Inference batcher size: 127. Learner queue size: 24. Other stats: (step = 59425280, mean_episode_return = None, mean_episode_step = 793.91, total_loss = -117.51, pg_loss = -129.89, baseline_loss = 18.248, entropy_loss = -5.8662, learner_queue_size = 12, _tick = 18205, _time = 1.654e+09, train_seconds = 9000.4)
[2022-05-31 16:40:26,730][root][INFO] - Step 59458560 @ 6650.5 SPS. Inference batcher size: 10. Learner queue size: 21. Other stats: (step = 59458560, mean_episode_return = None, mean_episode_step = 764.41, total_loss = 182.24, pg_loss = 85.69, baseline_loss = 102.86, entropy_loss = -6.311, learner_queue_size = 17, _tick = 18216, _time = 1.654e+09, train_seconds = 9005.4)
[2022-05-31 16:40:31,734][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 16:40:31,846][root][INFO] - Step 59489280 @ 6139.2 SPS. Inference batcher size: 51. Learner queue size: 23. Other stats: (step = 59491840, mean_episode_return = None, mean_episode_step = 4269.7, total_loss = 478.45, pg_loss = 242.29, baseline_loss = 242.09, entropy_loss = -5.9256, learner_queue_size = 18, _tick = 18225, _time = 1.654e+09, train_seconds = 9010.4)
[2022-05-31 16:40:36,850][root][INFO] - Step 59522560 @ 6505.2 SPS. Inference batcher size: 32. Learner queue size: 17. Other stats: (step = 59522560, mean_episode_return = None, mean_episode_step = 862.78, total_loss = 239.66, pg_loss = 41.234, baseline_loss = 204.08, entropy_loss = -5.6547, learner_queue_size = 15, _tick = 18234, _time = 1.654e+09, train_seconds = 9015.5)
[2022-05-31 16:40:41,855][root][INFO] - Step 59555840 @ 6648.6 SPS. Inference batcher size: 178. Learner queue size: 14. Other stats: (step = 59555840, mean_episode_return = None, mean_episode_step = 567.84, total_loss = -52.202, pg_loss = -131.47, baseline_loss = 85.07, entropy_loss = -5.7998, learner_queue_size = 20, _tick = 18244, _time = 1.654e+09, train_seconds = 9020.5)
[2022-05-31 16:40:46,858][root][INFO] - Step 59589120 @ 6652.6 SPS. Inference batcher size: 128. Learner queue size: 15. Other stats: (step = 59589120, mean_episode_return = 184.1, mean_episode_step = 845.64, total_loss = 52.369, pg_loss = -119.25, baseline_loss = 177.65, entropy_loss = -6.0258, learner_queue_size = 6, _tick = 18256, _time = 1.654e+09, train_seconds = 9025.5)
[2022-05-31 16:40:51,862][root][INFO] - Step 59622400 @ 6650.7 SPS. Inference batcher size: 130. Learner queue size: 3. Other stats: (step = 59622400, mean_episode_return = 102.15, mean_episode_step = 1016.4, total_loss = -11.568, pg_loss = -21.869, baseline_loss = 17.057, entropy_loss = -6.7554, learner_queue_size = 21, _tick = 18264, _time = 1.654e+09, train_seconds = 9030.5)
[2022-05-31 16:40:56,868][root][INFO] - Step 59655680 @ 6647.9 SPS. Inference batcher size: 105. Learner queue size: 5. Other stats: (step = 59655680, mean_episode_return = 266.31, mean_episode_step = 4256.0, total_loss = -46.379, pg_loss = -55.389, baseline_loss = 15.234, entropy_loss = -6.2239, learner_queue_size = 21, _tick = 18276, _time = 1.654e+09, train_seconds = 9035.6)
[2022-05-31 16:41:01,874][root][INFO] - Step 59688960 @ 6647.8 SPS. Inference batcher size: 6. Learner queue size: 30. Other stats: (step = 59688960, mean_episode_return = 106.32, mean_episode_step = 933.85, total_loss = -59.08, pg_loss = -62.703, baseline_loss = 10.314, entropy_loss = -6.6912, learner_queue_size = 21, _tick = 18287, _time = 1.654e+09, train_seconds = 9040.6)
[2022-05-31 16:41:06,878][root][INFO] - Step 59722240 @ 6651.1 SPS. Inference batcher size: 69. Learner queue size: 17. Other stats: (step = 59722240, mean_episode_return = 258.78, mean_episode_step = 710.15, total_loss = 153.48, pg_loss = 115.79, baseline_loss = 44.116, entropy_loss = -6.4313, learner_queue_size = 14, _tick = 18300, _time = 1.654e+09, train_seconds = 9045.6)
[2022-05-31 16:41:11,884][root][INFO] - Step 59752960 @ 6136.7 SPS. Inference batcher size: 166. Learner queue size: 23. Other stats: (step = 59752960, mean_episode_return = None, mean_episode_step = 715.06, total_loss = 146.19, pg_loss = 93.912, baseline_loss = 58.51, entropy_loss = -6.2337, learner_queue_size = 20, _tick = 18310, _time = 1.654e+09, train_seconds = 9050.6)
[2022-05-31 16:41:16,886][root][INFO] - Step 59786240 @ 6653.3 SPS. Inference batcher size: 145. Learner queue size: 17. Other stats: (step = 59786240, mean_episode_return = 288.02, mean_episode_step = 967.87, total_loss = -136.3, pg_loss = -151.24, baseline_loss = 21.258, entropy_loss = -6.3233, learner_queue_size = 30, _tick = 18322, _time = 1.654e+09, train_seconds = 9055.6)
[2022-05-31 16:41:21,890][root][INFO] - Step 59819520 @ 6650.8 SPS. Inference batcher size: 77. Learner queue size: 14. Other stats: (step = 59819520, mean_episode_return = None, mean_episode_step = 4217.9, total_loss = -131.02, pg_loss = -150.17, baseline_loss = 25.804, entropy_loss = -6.6499, learner_queue_size = 17, _tick = 18333, _time = 1.654e+09, train_seconds = 9060.6)
[2022-05-31 16:41:26,894][root][INFO] - Step 59852800 @ 6650.7 SPS. Inference batcher size: 143. Learner queue size: 19. Other stats: (step = 59852800, mean_episode_return = 441.49, mean_episode_step = 531.03, total_loss = 18.083, pg_loss = -1.9792, baseline_loss = 26.518, entropy_loss = -6.4552, learner_queue_size = 22, _tick = 18344, _time = 1.654e+09, train_seconds = 9065.6)
[2022-05-31 16:41:31,900][root][INFO] - Step 59886080 @ 6648.1 SPS. Inference batcher size: 93. Learner queue size: 12. Other stats: (step = 59886080, mean_episode_return = 123.77, mean_episode_step = 784.38, total_loss = 44.434, pg_loss = 2.7122, baseline_loss = 48.186, entropy_loss = -6.4645, learner_queue_size = 21, _tick = 18356, _time = 1.654e+09, train_seconds = 9070.6)
[2022-05-31 16:41:36,902][root][INFO] - Step 59919360 @ 6653.2 SPS. Inference batcher size: 143. Learner queue size: 14. Other stats: (step = 59919360, mean_episode_return = 81.426, mean_episode_step = 3824.8, total_loss = 35.414, pg_loss = 9.7027, baseline_loss = 32.246, entropy_loss = -6.5345, learner_queue_size = 27, _tick = 18366, _time = 1.654e+09, train_seconds = 9075.6)
[2022-05-31 16:41:41,906][root][INFO] - Step 59952640 @ 6650.6 SPS. Inference batcher size: 86. Learner queue size: 2. Other stats: (step = 59952640, mean_episode_return = 132.72, mean_episode_step = 1152.3, total_loss = 227.38, pg_loss = 87.281, baseline_loss = 146.52, entropy_loss = -6.4182, learner_queue_size = 21, _tick = 18379, _time = 1.654e+09, train_seconds = 9080.6)
[2022-05-31 16:41:46,908][root][INFO] - Step 59985920 @ 6652.9 SPS. Inference batcher size: 131. Learner queue size: 7. Other stats: (step = 59985920, mean_episode_return = None, mean_episode_step = 750.03, total_loss = 93.465, pg_loss = 14.815, baseline_loss = 84.352, entropy_loss = -5.7024, learner_queue_size = 20, _tick = 18388, _time = 1.654e+09, train_seconds = 9085.6)
[2022-05-31 16:41:51,914][root][INFO] - Step 60019200 @ 6648.2 SPS. Inference batcher size: 105. Learner queue size: 4. Other stats: (step = 60019200, mean_episode_return = 190.49, mean_episode_step = 878.12, total_loss = -107.04, pg_loss = -232.65, baseline_loss = 131.75, entropy_loss = -6.1312, learner_queue_size = 16, _tick = 18400, _time = 1.654e+09, train_seconds = 9090.6)
[2022-05-31 16:41:56,918][root][INFO] - Step 60052480 @ 6651.0 SPS. Inference batcher size: 36. Learner queue size: 28. Other stats: (step = 60052480, mean_episode_return = 220.32, mean_episode_step = 1075.4, total_loss = 262.12, pg_loss = 124.43, baseline_loss = 143.77, entropy_loss = -6.082, learner_queue_size = 17, _tick = 18413, _time = 1.654e+09, train_seconds = 9095.6)
[2022-05-31 16:42:01,924][root][INFO] - Step 60083200 @ 6136.9 SPS. Inference batcher size: 76. Learner queue size: 22. Other stats: (step = 60083200, mean_episode_return = 187.4, mean_episode_step = 4572.8, total_loss = -125.73, pg_loss = -130.87, baseline_loss = 11.778, entropy_loss = -6.6415, learner_queue_size = 22, _tick = 18423, _time = 1.654e+09, train_seconds = 9100.6)
[2022-05-31 16:42:06,926][root][INFO] - Step 60119040 @ 7164.8 SPS. Inference batcher size: 17. Learner queue size: 20. Other stats: (step = 60119040, mean_episode_return = 238.64, mean_episode_step = 711.01, total_loss = 126.2, pg_loss = 88.255, baseline_loss = 44.016, entropy_loss = -6.0721, learner_queue_size = 15, _tick = 18435, _time = 1.654e+09, train_seconds = 9105.6)
[2022-05-31 16:42:11,930][root][INFO] - Step 60152320 @ 6650.7 SPS. Inference batcher size: 90. Learner queue size: 26. Other stats: (step = 60152320, mean_episode_return = 190.68, mean_episode_step = 816.14, total_loss = -436.93, pg_loss = -513.46, baseline_loss = 82.75, entropy_loss = -6.2219, learner_queue_size = 24, _tick = 18445, _time = 1.654e+09, train_seconds = 9110.6)
[2022-05-31 16:42:16,934][root][INFO] - Step 60185600 @ 6650.7 SPS. Inference batcher size: 126. Learner queue size: 19. Other stats: (step = 60185600, mean_episode_return = 46.431, mean_episode_step = 1460.0, total_loss = 172.09, pg_loss = 141.27, baseline_loss = 37.192, entropy_loss = -6.3751, learner_queue_size = 18, _tick = 18454, _time = 1.654e+09, train_seconds = 9115.6)
[2022-05-31 16:42:21,940][root][INFO] - Step 60216320 @ 6137.1 SPS. Inference batcher size: 130. Learner queue size: 14. Other stats: (step = 60216320, mean_episode_return = 96.943, mean_episode_step = 1038.7, total_loss = -36.135, pg_loss = -105.52, baseline_loss = 75.467, entropy_loss = -6.0788, learner_queue_size = 15, _tick = 18465, _time = 1.654e+09, train_seconds = 9120.6)
[2022-05-31 16:42:26,945][root][INFO] - Step 60249600 @ 6648.1 SPS. Inference batcher size: 65. Learner queue size: 13. Other stats: (step = 60249600, mean_episode_return = None, mean_episode_step = 587.31, total_loss = 251.44, pg_loss = 188.45, baseline_loss = 69.571, entropy_loss = -6.5737, learner_queue_size = 29, _tick = 18473, _time = 1.654e+09, train_seconds = 9125.6)
[2022-05-31 16:42:31,951][root][INFO] - Step 60282880 @ 6648.1 SPS. Inference batcher size: 136. Learner queue size: 19. Other stats: (step = 60282880, mean_episode_return = 148.84, mean_episode_step = 1157.7, total_loss = 159.04, pg_loss = 125.44, baseline_loss = 40.395, entropy_loss = -6.7976, learner_queue_size = 23, _tick = 18484, _time = 1.654e+09, train_seconds = 9130.6)
[2022-05-31 16:42:36,954][root][INFO] - Step 60316160 @ 6652.5 SPS. Inference batcher size: 67. Learner queue size: 9. Other stats: (step = 60316160, mean_episode_return = None, mean_episode_step = 1063.5, total_loss = 297.59, pg_loss = 222.59, baseline_loss = 81.091, entropy_loss = -6.0993, learner_queue_size = 17, _tick = 18494, _time = 1.654e+09, train_seconds = 9135.6)
[2022-05-31 16:42:41,958][root][INFO] - Step 60349440 @ 6650.8 SPS. Inference batcher size: 110. Learner queue size: 3. Other stats: (step = 60349440, mean_episode_return = 296.88, mean_episode_step = 928.32, total_loss = 391.72, pg_loss = 268.82, baseline_loss = 129.41, entropy_loss = -6.5091, learner_queue_size = 15, _tick = 18506, _time = 1.654e+09, train_seconds = 9140.6)
[2022-05-31 16:42:46,962][root][INFO] - Step 60382720 @ 6650.6 SPS. Inference batcher size: 117. Learner queue size: 27. Other stats: (step = 60382720, mean_episode_return = 118.89, mean_episode_step = 825.21, total_loss = 147.67, pg_loss = 108.37, baseline_loss = 46.133, entropy_loss = -6.8332, learner_queue_size = 14, _tick = 18518, _time = 1.654e+09, train_seconds = 9145.6)
[2022-05-31 16:42:51,966][root][INFO] - Step 60413440 @ 6139.0 SPS. Inference batcher size: 16. Learner queue size: 22. Other stats: (step = 60413440, mean_episode_return = 225.07, mean_episode_step = 807.9, total_loss = -253.35, pg_loss = -335.92, baseline_loss = 89.008, entropy_loss = -6.4383, learner_queue_size = 22, _tick = 18529, _time = 1.654e+09, train_seconds = 9150.7)
[2022-05-31 16:42:56,970][root][INFO] - Step 60446720 @ 6650.7 SPS. Inference batcher size: 81. Learner queue size: 17. Other stats: (step = 60446720, mean_episode_return = 14.905, mean_episode_step = 830.66, total_loss = 31.97, pg_loss = -2.7628, baseline_loss = 40.784, entropy_loss = -6.0508, learner_queue_size = 22, _tick = 18541, _time = 1.654e+09, train_seconds = 9155.7)
[2022-05-31 16:43:01,974][root][INFO] - Step 60480000 @ 6650.8 SPS. Inference batcher size: 171. Learner queue size: 15. Other stats: (step = 60480000, mean_episode_return = 102.29, mean_episode_step = 717.53, total_loss = 130.87, pg_loss = 93.659, baseline_loss = 42.989, entropy_loss = -5.78, learner_queue_size = 9, _tick = 18553, _time = 1.654e+09, train_seconds = 9160.7)
[2022-05-31 16:43:06,976][root][INFO] - Step 60513280 @ 6653.3 SPS. Inference batcher size: 128. Learner queue size: 2. Other stats: (step = 60513280, mean_episode_return = 206.0, mean_episode_step = 902.48, total_loss = 414.91, pg_loss = 308.8, baseline_loss = 111.85, entropy_loss = -5.742, learner_queue_size = 17, _tick = 18564, _time = 1.654e+09, train_seconds = 9165.7)
[2022-05-31 16:43:11,982][root][INFO] - Step 60546560 @ 6648.1 SPS. Inference batcher size: 81. Learner queue size: 29. Other stats: (step = 60546560, mean_episode_return = 89.69, mean_episode_step = 627.34, total_loss = -98.898, pg_loss = -154.71, baseline_loss = 61.603, entropy_loss = -5.7907, learner_queue_size = 16, _tick = 18574, _time = 1.654e+09, train_seconds = 9170.7)
[2022-05-31 16:43:16,989][root][INFO] - Step 60579840 @ 6646.9 SPS. Inference batcher size: 16. Learner queue size: 30. Other stats: (step = 60579840, mean_episode_return = 72.705, mean_episode_step = 808.16, total_loss = 442.6, pg_loss = 306.36, baseline_loss = 142.17, entropy_loss = -5.934, learner_queue_size = 25, _tick = 18584, _time = 1.654e+09, train_seconds = 9175.7)
[2022-05-31 16:43:21,991][root][INFO] - Step 60610560 @ 6141.6 SPS. Inference batcher size: 119. Learner queue size: 11. Other stats: (step = 60610560, mean_episode_return = 215.2, mean_episode_step = 4708.6, total_loss = -50.683, pg_loss = -307.97, baseline_loss = 263.26, entropy_loss = -5.9758, learner_queue_size = 18, _tick = 18595, _time = 1.654e+09, train_seconds = 9180.7)
[2022-05-31 16:43:26,994][root][INFO] - Step 60643840 @ 6651.7 SPS. Inference batcher size: 74. Learner queue size: 9. Other stats: (step = 60643840, mean_episode_return = 154.99, mean_episode_step = 684.03, total_loss = -190.36, pg_loss = -207.78, baseline_loss = 24.013, entropy_loss = -6.5996, learner_queue_size = 13, _tick = 18607, _time = 1.654e+09, train_seconds = 9185.7)
[2022-05-31 16:43:32,000][root][INFO] - Step 60674560 @ 6137.0 SPS. Inference batcher size: 137. Learner queue size: 19. Other stats: (step = 60674560, mean_episode_return = 7.7996, mean_episode_step = 633.47, total_loss = 402.92, pg_loss = 233.27, baseline_loss = 175.86, entropy_loss = -6.2146, learner_queue_size = 16, _tick = 18617, _time = 1.654e+09, train_seconds = 9190.7)
[2022-05-31 16:43:37,006][root][INFO] - Step 60707840 @ 6648.1 SPS. Inference batcher size: 128. Learner queue size: 17. Other stats: (step = 60707840, mean_episode_return = 41.78, mean_episode_step = 861.15, total_loss = -153.55, pg_loss = -157.76, baseline_loss = 10.635, entropy_loss = -6.4248, learner_queue_size = 24, _tick = 18628, _time = 1.654e+09, train_seconds = 9195.7)
[2022-05-31 16:43:42,010][root][INFO] - Step 60741120 @ 6650.0 SPS. Inference batcher size: 90. Learner queue size: 16. Other stats: (step = 60741120, mean_episode_return = 280.99, mean_episode_step = 832.77, total_loss = -73.246, pg_loss = -76.052, baseline_loss = 9.3073, entropy_loss = -6.5011, learner_queue_size = 17, _tick = 18636, _time = 1.654e+09, train_seconds = 9200.7)
[2022-05-31 16:43:47,014][root][INFO] - Step 60774400 @ 6650.7 SPS. Inference batcher size: 99. Learner queue size: 3. Other stats: (step = 60774400, mean_episode_return = 191.74, mean_episode_step = 1633.2, total_loss = 406.8, pg_loss = 287.56, baseline_loss = 125.92, entropy_loss = -6.6777, learner_queue_size = 18, _tick = 18645, _time = 1.654e+09, train_seconds = 9205.7)
[2022-05-31 16:43:52,020][root][INFO] - Step 60805120 @ 6136.5 SPS. Inference batcher size: 118. Learner queue size: 11. Other stats: (step = 60805120, mean_episode_return = 86.02, mean_episode_step = 835.78, total_loss = 257.59, pg_loss = 178.54, baseline_loss = 85.09, entropy_loss = -6.037, learner_queue_size = 17, _tick = 18656, _time = 1.654e+09, train_seconds = 9210.7)
[2022-05-31 16:43:57,026][root][INFO] - Step 60838400 @ 6648.0 SPS. Inference batcher size: 139. Learner queue size: 21. Other stats: (step = 60838400, mean_episode_return = 147.81, mean_episode_step = 867.8, total_loss = 184.09, pg_loss = 107.65, baseline_loss = 82.536, entropy_loss = -6.0886, learner_queue_size = 19, _tick = 18669, _time = 1.654e+09, train_seconds = 9215.7)
[2022-05-31 16:44:02,030][root][INFO] - Step 60871680 @ 6650.7 SPS. Inference batcher size: 120. Learner queue size: 23. Other stats: (step = 60871680, mean_episode_return = 142.51, mean_episode_step = 3865.7, total_loss = -58.95, pg_loss = -71.57, baseline_loss = 19.148, entropy_loss = -6.5277, learner_queue_size = 16, _tick = 18681, _time = 1.654e+09, train_seconds = 9220.7)
[2022-05-31 16:44:07,037][root][INFO] - Step 60904960 @ 6647.4 SPS. Inference batcher size: 140. Learner queue size: 16. Other stats: (step = 60904960, mean_episode_return = 179.57, mean_episode_step = 905.71, total_loss = 65.116, pg_loss = 15.633, baseline_loss = 55.589, entropy_loss = -6.1047, learner_queue_size = 23, _tick = 18689, _time = 1.654e+09, train_seconds = 9225.7)
[2022-05-31 16:44:12,042][root][INFO] - Step 60938240 @ 6648.8 SPS. Inference batcher size: 117. Learner queue size: 10. Other stats: (step = 60938240, mean_episode_return = 183.11, mean_episode_step = 991.2, total_loss = 86.019, pg_loss = 31.867, baseline_loss = 60.403, entropy_loss = -6.2516, learner_queue_size = 13, _tick = 18702, _time = 1.654e+09, train_seconds = 9230.7)
[2022-05-31 16:44:17,046][root][INFO] - Step 60971520 @ 6650.6 SPS. Inference batcher size: 148. Learner queue size: 10. Other stats: (step = 60971520, mean_episode_return = 64.54, mean_episode_step = 698.54, total_loss = -153.59, pg_loss = -194.25, baseline_loss = 47.032, entropy_loss = -6.3689, learner_queue_size = 13, _tick = 18714, _time = 1.654e+09, train_seconds = 9235.7)
[2022-05-31 16:44:22,050][root][INFO] - Step 61004800 @ 6650.8 SPS. Inference batcher size: 138. Learner queue size: 3. Other stats: (step = 61004800, mean_episode_return = 165.48, mean_episode_step = 774.62, total_loss = 156.31, pg_loss = 74.231, baseline_loss = 88.461, entropy_loss = -6.3866, learner_queue_size = 24, _tick = 18726, _time = 1.654e+09, train_seconds = 9240.7)
[2022-05-31 16:44:27,054][root][INFO] - Step 61038080 @ 6650.7 SPS. Inference batcher size: 41. Learner queue size: 5. Other stats: (step = 61038080, mean_episode_return = 60.965, mean_episode_step = 832.05, total_loss = 267.55, pg_loss = 160.44, baseline_loss = 113.42, entropy_loss = -6.3144, learner_queue_size = 18, _tick = 18737, _time = 1.654e+09, train_seconds = 9245.7)
[2022-05-31 16:44:32,058][root][INFO] - Step 61071360 @ 6650.7 SPS. Inference batcher size: 111. Learner queue size: 2. Other stats: (step = 61071360, mean_episode_return = 42.862, mean_episode_step = 710.48, total_loss = 145.07, pg_loss = 67.487, baseline_loss = 83.7, entropy_loss = -6.1121, learner_queue_size = 21, _tick = 18749, _time = 1.654e+09, train_seconds = 9250.7)
[2022-05-31 16:44:37,062][root][INFO] - Step 61104640 @ 6650.7 SPS. Inference batcher size: 98. Learner queue size: 3. Other stats: (step = 61104640, mean_episode_return = None, mean_episode_step = 987.88, total_loss = -132.5, pg_loss = -153.0, baseline_loss = 27.219, entropy_loss = -6.7185, learner_queue_size = 11, _tick = 18756, _time = 1.654e+09, train_seconds = 9255.7)
[2022-05-31 16:44:42,066][root][INFO] - Step 61137920 @ 6650.6 SPS. Inference batcher size: 172. Learner queue size: 4. Other stats: (step = 61137920, mean_episode_return = 1.9497, mean_episode_step = 958.94, total_loss = 74.704, pg_loss = -9.9026, baseline_loss = 91.183, entropy_loss = -6.5759, learner_queue_size = 23, _tick = 18766, _time = 1.654e+09, train_seconds = 9260.8)
[2022-05-31 16:44:47,070][root][INFO] - Step 61171200 @ 6650.7 SPS. Inference batcher size: 97. Learner queue size: 17. Other stats: (step = 61171200, mean_episode_return = 227.86, mean_episode_step = 928.46, total_loss = -82.526, pg_loss = -137.99, baseline_loss = 61.924, entropy_loss = -6.458, learner_queue_size = 13, _tick = 18777, _time = 1.654e+09, train_seconds = 9265.8)
[2022-05-31 16:44:52,074][root][INFO] - Step 61204480 @ 6650.6 SPS. Inference batcher size: 99. Learner queue size: 28. Other stats: (step = 61204480, mean_episode_return = 33.936, mean_episode_step = 1085.7, total_loss = -79.625, pg_loss = -99.257, baseline_loss = 26.084, entropy_loss = -6.4519, learner_queue_size = 21, _tick = 18789, _time = 1.654e+09, train_seconds = 9270.8)
[2022-05-31 16:44:57,078][root][INFO] - Step 61237760 @ 6650.7 SPS. Inference batcher size: 148. Learner queue size: 23. Other stats: (step = 61237760, mean_episode_return = 276.45, mean_episode_step = 734.15, total_loss = -89.908, pg_loss = -140.73, baseline_loss = 57.207, entropy_loss = -6.3812, learner_queue_size = 23, _tick = 18801, _time = 1.654e+09, train_seconds = 9275.8)
[2022-05-31 16:45:02,084][root][INFO] - Step 61268480 @ 6136.1 SPS. Inference batcher size: 85. Learner queue size: 15. Other stats: (step = 61268480, mean_episode_return = 177.41, mean_episode_step = 663.76, total_loss = 408.03, pg_loss = 191.78, baseline_loss = 222.0, entropy_loss = -5.7517, learner_queue_size = 17, _tick = 18811, _time = 1.654e+09, train_seconds = 9280.8)
[2022-05-31 16:45:07,090][root][INFO] - Step 61301760 @ 6648.0 SPS. Inference batcher size: 70. Learner queue size: 12. Other stats: (step = 61301760, mean_episode_return = 115.56, mean_episode_step = 881.96, total_loss = 134.35, pg_loss = 100.05, baseline_loss = 40.594, entropy_loss = -6.2931, learner_queue_size = 13, _tick = 18822, _time = 1.654e+09, train_seconds = 9285.8)
[2022-05-31 16:45:12,097][root][INFO] - Step 61335040 @ 6647.8 SPS. Inference batcher size: 96. Learner queue size: 15. Other stats: (step = 61335040, mean_episode_return = 139.11, mean_episode_step = 4119.0, total_loss = -50.802, pg_loss = -96.532, baseline_loss = 52.229, entropy_loss = -6.499, learner_queue_size = 24, _tick = 18834, _time = 1.654e+09, train_seconds = 9290.8)
[2022-05-31 16:45:17,103][root][INFO] - Step 61368320 @ 6648.0 SPS. Inference batcher size: 109. Learner queue size: 16. Other stats: (step = 61368320, mean_episode_return = 571.79, mean_episode_step = 802.33, total_loss = 432.77, pg_loss = 317.53, baseline_loss = 121.12, entropy_loss = -5.8891, learner_queue_size = 20, _tick = 18847, _time = 1.654e+09, train_seconds = 9295.8)
[2022-05-31 16:45:22,109][root][INFO] - Step 61401600 @ 6648.0 SPS. Inference batcher size: 100. Learner queue size: 13. Other stats: (step = 61401600, mean_episode_return = 244.1, mean_episode_step = 937.33, total_loss = 143.62, pg_loss = 21.74, baseline_loss = 128.17, entropy_loss = -6.2849, learner_queue_size = 20, _tick = 18859, _time = 1.654e+09, train_seconds = 9300.8)
[2022-05-31 16:45:27,114][root][INFO] - Step 61434880 @ 6648.8 SPS. Inference batcher size: 146. Learner queue size: 10. Other stats: (step = 61434880, mean_episode_return = 87.12, mean_episode_step = 901.84, total_loss = 84.361, pg_loss = 0.5015, baseline_loss = 90.245, entropy_loss = -6.3853, learner_queue_size = 17, _tick = 18871, _time = 1.654e+09, train_seconds = 9305.8)
[2022-05-31 16:45:32,118][root][INFO] - Step 61468160 @ 6650.7 SPS. Inference batcher size: 106. Learner queue size: 5. Other stats: (step = 61468160, mean_episode_return = 42.541, mean_episode_step = 583.25, total_loss = 198.45, pg_loss = 62.882, baseline_loss = 141.68, entropy_loss = -6.1089, learner_queue_size = 19, _tick = 18883, _time = 1.654e+09, train_seconds = 9310.8)
[2022-05-31 16:45:37,124][root][INFO] - Step 61501440 @ 6647.9 SPS. Inference batcher size: 121. Learner queue size: 1. Other stats: (step = 61501440, mean_episode_return = 168.1, mean_episode_step = 793.05, total_loss = 55.064, pg_loss = 41.169, baseline_loss = 20.971, entropy_loss = -7.0755, learner_queue_size = 24, _tick = 18896, _time = 1.654e+09, train_seconds = 9315.8)
[2022-05-31 16:45:42,127][root][INFO] - Step 61534720 @ 6652.8 SPS. Inference batcher size: 135. Learner queue size: 27. Other stats: (step = 61534720, mean_episode_return = 112.43, mean_episode_step = 916.16, total_loss = 153.96, pg_loss = 139.16, baseline_loss = 21.591, entropy_loss = -6.7931, learner_queue_size = 22, _tick = 18908, _time = 1.654e+09, train_seconds = 9320.8)
[2022-05-31 16:45:47,130][root][INFO] - Step 61565440 @ 6139.7 SPS. Inference batcher size: 51. Learner queue size: 22. Other stats: (step = 61565440, mean_episode_return = None, mean_episode_step = 674.72, total_loss = 19.91, pg_loss = -41.019, baseline_loss = 67.119, entropy_loss = -6.1898, learner_queue_size = 10, _tick = 18917, _time = 1.654e+09, train_seconds = 9325.8)
[2022-05-31 16:45:52,134][root][INFO] - Step 61601280 @ 7162.3 SPS. Inference batcher size: 95. Learner queue size: 26. Other stats: (step = 61601280, mean_episode_return = 227.89, mean_episode_step = 3898.1, total_loss = -23.316, pg_loss = -41.251, baseline_loss = 24.69, entropy_loss = -6.7541, learner_queue_size = 14, _tick = 18928, _time = 1.654e+09, train_seconds = 9330.8)
[2022-05-31 16:45:57,140][root][INFO] - Step 61632000 @ 6136.6 SPS. Inference batcher size: 135. Learner queue size: 21. Other stats: (step = 61632000, mean_episode_return = 44.522, mean_episode_step = 887.38, total_loss = 320.41, pg_loss = 204.01, baseline_loss = 122.89, entropy_loss = -6.4935, learner_queue_size = 13, _tick = 18938, _time = 1.654e+09, train_seconds = 9335.8)
[2022-05-31 16:46:02,146][root][INFO] - Step 61665280 @ 6648.0 SPS. Inference batcher size: 92. Learner queue size: 14. Other stats: (step = 61665280, mean_episode_return = 43.376, mean_episode_step = 824.04, total_loss = 135.37, pg_loss = 77.499, baseline_loss = 63.989, entropy_loss = -6.1216, learner_queue_size = 18, _tick = 18950, _time = 1.654e+09, train_seconds = 9340.8)
[2022-05-31 16:46:07,152][root][INFO] - Step 61698560 @ 6648.0 SPS. Inference batcher size: 145. Learner queue size: 10. Other stats: (step = 61698560, mean_episode_return = None, mean_episode_step = 879.12, total_loss = -117.75, pg_loss = -143.4, baseline_loss = 32.136, entropy_loss = -6.4915, learner_queue_size = 22, _tick = 18962, _time = 1.654e+09, train_seconds = 9345.8)
[2022-05-31 16:46:12,154][root][INFO] - Step 61731840 @ 6653.2 SPS. Inference batcher size: 187. Learner queue size: 10. Other stats: (step = 61731840, mean_episode_return = 177.48, mean_episode_step = 686.52, total_loss = 642.86, pg_loss = 315.8, baseline_loss = 333.05, entropy_loss = -5.989, learner_queue_size = 17, _tick = 18975, _time = 1.654e+09, train_seconds = 9350.8)
[2022-05-31 16:46:17,158][root][INFO] - Step 61765120 @ 6650.8 SPS. Inference batcher size: 100. Learner queue size: 1. Other stats: (step = 61765120, mean_episode_return = 148.18, mean_episode_step = 3845.9, total_loss = 12.041, pg_loss = -32.653, baseline_loss = 50.926, entropy_loss = -6.232, learner_queue_size = 22, _tick = 18988, _time = 1.654e+09, train_seconds = 9355.8)
[2022-05-31 16:46:22,162][root][INFO] - Step 61795840 @ 6139.1 SPS. Inference batcher size: 125. Learner queue size: 19. Other stats: (step = 61795840, mean_episode_return = 202.63, mean_episode_step = 687.8, total_loss = -81.73, pg_loss = -137.86, baseline_loss = 62.124, entropy_loss = -5.9974, learner_queue_size = 21, _tick = 18997, _time = 1.654e+09, train_seconds = 9360.8)
[2022-05-31 16:46:27,168][root][INFO] - Step 61829120 @ 6648.1 SPS. Inference batcher size: 142. Learner queue size: 15. Other stats: (step = 61829120, mean_episode_return = 289.92, mean_episode_step = 4107.1, total_loss = -45.673, pg_loss = -117.89, baseline_loss = 78.434, entropy_loss = -6.2151, learner_queue_size = 17, _tick = 19009, _time = 1.654e+09, train_seconds = 9365.9)
[2022-05-31 16:46:32,170][root][INFO] - Step 61862400 @ 6653.2 SPS. Inference batcher size: 131. Learner queue size: 15. Other stats: (step = 61862400, mean_episode_return = 115.04, mean_episode_step = 760.85, total_loss = -57.874, pg_loss = -94.077, baseline_loss = 42.554, entropy_loss = -6.3513, learner_queue_size = 20, _tick = 19021, _time = 1.654e+09, train_seconds = 9370.9)
[2022-05-31 16:46:37,174][root][INFO] - Step 61895680 @ 6650.8 SPS. Inference batcher size: 28. Learner queue size: 12. Other stats: (step = 61895680, mean_episode_return = 212.49, mean_episode_step = 793.92, total_loss = -20.456, pg_loss = -59.246, baseline_loss = 45.22, entropy_loss = -6.4297, learner_queue_size = 21, _tick = 19034, _time = 1.654e+09, train_seconds = 9375.9)
[2022-05-31 16:46:42,178][root][INFO] - Step 61928960 @ 6650.7 SPS. Inference batcher size: 67. Learner queue size: 4. Other stats: (step = 61928960, mean_episode_return = None, mean_episode_step = 644.75, total_loss = 97.676, pg_loss = 43.129, baseline_loss = 60.559, entropy_loss = -6.0131, learner_queue_size = 18, _tick = 19045, _time = 1.654e+09, train_seconds = 9380.9)
[2022-05-31 16:46:47,182][root][INFO] - Step 61962240 @ 6650.6 SPS. Inference batcher size: 28. Learner queue size: 22. Other stats: (step = 61962240, mean_episode_return = 133.79, mean_episode_step = 846.34, total_loss = -100.43, pg_loss = -136.23, baseline_loss = 42.01, entropy_loss = -6.2124, learner_queue_size = 22, _tick = 19056, _time = 1.654e+09, train_seconds = 9385.9)
[2022-05-31 16:46:52,186][root][INFO] - Step 61992960 @ 6139.1 SPS. Inference batcher size: 194. Learner queue size: 16. Other stats: (step = 61992960, mean_episode_return = None, mean_episode_step = 802.56, total_loss = 41.968, pg_loss = 7.1439, baseline_loss = 41.546, entropy_loss = -6.7227, learner_queue_size = 18, _tick = 19067, _time = 1.654e+09, train_seconds = 9390.9)
[2022-05-31 16:46:57,192][root][INFO] - Step 62026240 @ 6648.0 SPS. Inference batcher size: 95. Learner queue size: 16. Other stats: (step = 62026240, mean_episode_return = 162.49, mean_episode_step = 1040.1, total_loss = 97.079, pg_loss = 50.572, baseline_loss = 52.866, entropy_loss = -6.3597, learner_queue_size = 14, _tick = 19077, _time = 1.654e+09, train_seconds = 9395.9)
[2022-05-31 16:47:02,198][root][INFO] - Step 62059520 @ 6648.0 SPS. Inference batcher size: 164. Learner queue size: 13. Other stats: (step = 62059520, mean_episode_return = 76.958, mean_episode_step = 728.49, total_loss = 62.593, pg_loss = 13.427, baseline_loss = 55.44, entropy_loss = -6.2742, learner_queue_size = 18, _tick = 19088, _time = 1.654e+09, train_seconds = 9400.9)
[2022-05-31 16:47:07,202][root][INFO] - Step 62092800 @ 6650.7 SPS. Inference batcher size: 131. Learner queue size: 8. Other stats: (step = 62092800, mean_episode_return = 88.855, mean_episode_step = 775.11, total_loss = 81.899, pg_loss = -32.562, baseline_loss = 120.6, entropy_loss = -6.1387, learner_queue_size = 17, _tick = 19100, _time = 1.654e+09, train_seconds = 9405.9)
[2022-05-31 16:47:12,206][root][INFO] - Step 62126080 @ 6650.8 SPS. Inference batcher size: 90. Learner queue size: 2. Other stats: (step = 62126080, mean_episode_return = 31.38, mean_episode_step = 4381.2, total_loss = 97.733, pg_loss = 20.979, baseline_loss = 83.528, entropy_loss = -6.7736, learner_queue_size = 22, _tick = 19111, _time = 1.654e+09, train_seconds = 9410.9)
[2022-05-31 16:47:17,211][root][INFO] - Step 62159360 @ 6650.0 SPS. Inference batcher size: 29. Learner queue size: 29. Other stats: (step = 62159360, mean_episode_return = 119.89, mean_episode_step = 818.51, total_loss = 316.1, pg_loss = 209.71, baseline_loss = 112.81, entropy_loss = -6.427, learner_queue_size = 22, _tick = 19123, _time = 1.654e+09, train_seconds = 9415.9)
[2022-05-31 16:47:22,214][root][INFO] - Step 62192640 @ 6651.3 SPS. Inference batcher size: 155. Learner queue size: 1. Other stats: (step = 62192640, mean_episode_return = 102.08, mean_episode_step = 774.79, total_loss = -53.561, pg_loss = -98.122, baseline_loss = 50.925, entropy_loss = -6.3637, learner_queue_size = 17, _tick = 19135, _time = 1.654e+09, train_seconds = 9420.9)
[2022-05-31 16:47:27,218][root][INFO] - Step 62225920 @ 6650.7 SPS. Inference batcher size: 129. Learner queue size: 22. Other stats: (step = 62225920, mean_episode_return = 133.37, mean_episode_step = 854.56, total_loss = 15.702, pg_loss = -43.275, baseline_loss = 65.43, entropy_loss = -6.4524, learner_queue_size = 15, _tick = 19146, _time = 1.654e+09, train_seconds = 9425.9)
[2022-05-31 16:47:32,222][root][INFO] - Step 62259200 @ 6650.8 SPS. Inference batcher size: 145. Learner queue size: 31. Other stats: (step = 62259200, mean_episode_return = 130.86, mean_episode_step = 924.64, total_loss = 112.47, pg_loss = 57.917, baseline_loss = 61.432, entropy_loss = -6.8836, learner_queue_size = 23, _tick = 19156, _time = 1.654e+09, train_seconds = 9430.9)
[2022-05-31 16:47:37,228][root][INFO] - Step 62289920 @ 6136.6 SPS. Inference batcher size: 152. Learner queue size: 29. Other stats: (step = 62289920, mean_episode_return = 88.489, mean_episode_step = 4354.7, total_loss = 221.85, pg_loss = 183.59, baseline_loss = 45.177, entropy_loss = -6.914, learner_queue_size = 25, _tick = 19168, _time = 1.654e+09, train_seconds = 9435.9)
[2022-05-31 16:47:42,234][root][INFO] - Step 62323200 @ 6647.9 SPS. Inference batcher size: 132. Learner queue size: 26. Other stats: (step = 62323200, mean_episode_return = 137.51, mean_episode_step = 1057.6, total_loss = 119.45, pg_loss = 97.556, baseline_loss = 28.441, entropy_loss = -6.5432, learner_queue_size = 17, _tick = 19180, _time = 1.654e+09, train_seconds = 9440.9)
[2022-05-31 16:47:47,239][root][INFO] - Step 62356480 @ 6649.4 SPS. Inference batcher size: 51. Learner queue size: 11. Other stats: (step = 62356480, mean_episode_return = 79.049, mean_episode_step = 903.89, total_loss = -46.877, pg_loss = -96.118, baseline_loss = 55.64, entropy_loss = -6.3988, learner_queue_size = 23, _tick = 19192, _time = 1.654e+09, train_seconds = 9445.9)
[2022-05-31 16:47:52,245][root][INFO] - Step 62389760 @ 6647.7 SPS. Inference batcher size: 187. Learner queue size: 14. Other stats: (step = 62389760, mean_episode_return = 180.36, mean_episode_step = 4003.0, total_loss = 239.6, pg_loss = 131.44, baseline_loss = 114.42, entropy_loss = -6.2591, learner_queue_size = 20, _tick = 19204, _time = 1.654e+09, train_seconds = 9450.9)
[2022-05-31 16:47:57,251][root][INFO] - Step 62423040 @ 6648.0 SPS. Inference batcher size: 104. Learner queue size: 14. Other stats: (step = 62423040, mean_episode_return = 190.63, mean_episode_step = 943.99, total_loss = -60.033, pg_loss = -134.26, baseline_loss = 80.148, entropy_loss = -5.92, learner_queue_size = 19, _tick = 19217, _time = 1.654e+09, train_seconds = 9455.9)
[2022-05-31 16:48:02,254][root][INFO] - Step 62456320 @ 6652.5 SPS. Inference batcher size: 150. Learner queue size: 17. Other stats: (step = 62456320, mean_episode_return = 156.69, mean_episode_step = 846.2, total_loss = 42.225, pg_loss = -55.622, baseline_loss = 103.87, entropy_loss = -6.0268, learner_queue_size = 22, _tick = 19229, _time = 1.654e+09, train_seconds = 9460.9)
[2022-05-31 16:48:07,260][root][INFO] - Step 62489600 @ 6648.0 SPS. Inference batcher size: 133. Learner queue size: 12. Other stats: (step = 62489600, mean_episode_return = 155.34, mean_episode_step = 958.99, total_loss = 180.75, pg_loss = 84.249, baseline_loss = 102.98, entropy_loss = -6.4764, learner_queue_size = 26, _tick = 19241, _time = 1.654e+09, train_seconds = 9465.9)
[2022-05-31 16:48:12,266][root][INFO] - Step 62522880 @ 6648.1 SPS. Inference batcher size: 38. Learner queue size: 10. Other stats: (step = 62522880, mean_episode_return = 53.599, mean_episode_step = 552.51, total_loss = -23.663, pg_loss = -57.957, baseline_loss = 40.891, entropy_loss = -6.5966, learner_queue_size = 21, _tick = 19253, _time = 1.654e+09, train_seconds = 9471.0)
[2022-05-31 16:48:17,270][root][INFO] - Step 62556160 @ 6650.4 SPS. Inference batcher size: 72. Learner queue size: 11. Other stats: (step = 62556160, mean_episode_return = 39.64, mean_episode_step = 925.14, total_loss = 8.7795, pg_loss = -29.877, baseline_loss = 45.589, entropy_loss = -6.9318, learner_queue_size = 20, _tick = 19264, _time = 1.654e+09, train_seconds = 9476.0)
[2022-05-31 16:48:22,275][root][INFO] - Step 62589440 @ 6649.1 SPS. Inference batcher size: 152. Learner queue size: 3. Other stats: (step = 62589440, mean_episode_return = None, mean_episode_step = 606.44, total_loss = 133.78, pg_loss = 72.756, baseline_loss = 67.571, entropy_loss = -6.5503, learner_queue_size = 21, _tick = 19275, _time = 1.654e+09, train_seconds = 9481.0)
[2022-05-31 16:48:27,278][root][INFO] - Step 62622720 @ 6652.6 SPS. Inference batcher size: 114. Learner queue size: 5. Other stats: (step = 62622720, mean_episode_return = 173.23, mean_episode_step = 646.36, total_loss = 25.884, pg_loss = -18.473, baseline_loss = 50.84, entropy_loss = -6.4832, learner_queue_size = 26, _tick = 19286, _time = 1.654e+09, train_seconds = 9486.0)
[2022-05-31 16:48:32,284][root][INFO] - Step 62656000 @ 6648.3 SPS. Inference batcher size: 56. Learner queue size: 5. Other stats: (step = 62656000, mean_episode_return = 191.47, mean_episode_step = 4240.8, total_loss = 86.964, pg_loss = 12.897, baseline_loss = 80.53, entropy_loss = -6.4631, learner_queue_size = 14, _tick = 19298, _time = 1.654e+09, train_seconds = 9491.0)
[2022-05-31 16:48:37,289][root][INFO] - Step 62689280 @ 6648.6 SPS. Inference batcher size: 39. Learner queue size: 15. Other stats: (step = 62689280, mean_episode_return = 43.33, mean_episode_step = 852.61, total_loss = 376.9, pg_loss = 220.93, baseline_loss = 162.44, entropy_loss = -6.4729, learner_queue_size = 15, _tick = 19310, _time = 1.654e+09, train_seconds = 9496.0)
[2022-05-31 16:48:42,295][root][INFO] - Step 62720000 @ 6137.0 SPS. Inference batcher size: 180. Learner queue size: 8. Other stats: (step = 62720000, mean_episode_return = 312.3, mean_episode_step = 761.86, total_loss = 526.17, pg_loss = 352.46, baseline_loss = 179.71, entropy_loss = -6.0044, learner_queue_size = 22, _tick = 19321, _time = 1.654e+09, train_seconds = 9501.0)
[2022-05-31 16:48:47,301][root][INFO] - Step 62753280 @ 6648.4 SPS. Inference batcher size: 73. Learner queue size: 12. Other stats: (step = 62753280, mean_episode_return = 99.81, mean_episode_step = 872.44, total_loss = -342.81, pg_loss = -380.74, baseline_loss = 43.984, entropy_loss = -6.0583, learner_queue_size = 19, _tick = 19331, _time = 1.654e+09, train_seconds = 9506.0)
[2022-05-31 16:48:52,302][root][INFO] - Step 62786560 @ 6653.9 SPS. Inference batcher size: 114. Learner queue size: 13. Other stats: (step = 62786560, mean_episode_return = 382.42, mean_episode_step = 734.38, total_loss = -27.021, pg_loss = -146.17, baseline_loss = 125.7, entropy_loss = -6.5502, learner_queue_size = 21, _tick = 19340, _time = 1.654e+09, train_seconds = 9511.0)
[2022-05-31 16:48:57,306][root][INFO] - Step 62819840 @ 6651.1 SPS. Inference batcher size: 183. Learner queue size: 12. Other stats: (step = 62819840, mean_episode_return = 70.45, mean_episode_step = 4638.9, total_loss = -82.908, pg_loss = -125.36, baseline_loss = 49.148, entropy_loss = -6.6944, learner_queue_size = 28, _tick = 19350, _time = 1.654e+09, train_seconds = 9516.0)
[2022-05-31 16:49:02,310][root][INFO] - Step 62853120 @ 6650.8 SPS. Inference batcher size: 93. Learner queue size: 9. Other stats: (step = 62853120, mean_episode_return = 181.77, mean_episode_step = 858.45, total_loss = 151.42, pg_loss = -22.4, baseline_loss = 180.03, entropy_loss = -6.208, learner_queue_size = 19, _tick = 19360, _time = 1.654e+09, train_seconds = 9521.0)
[2022-05-31 16:49:07,315][root][INFO] - Step 62886400 @ 6648.6 SPS. Inference batcher size: 109. Learner queue size: 2. Other stats: (step = 62886400, mean_episode_return = None, mean_episode_step = 918.06, total_loss = 140.69, pg_loss = 74.442, baseline_loss = 72.964, entropy_loss = -6.7159, learner_queue_size = 18, _tick = 19368, _time = 1.654e+09, train_seconds = 9526.0)
[2022-05-31 16:49:12,318][root][INFO] - Step 62919680 @ 6652.7 SPS. Inference batcher size: 115. Learner queue size: 17. Other stats: (step = 62919680, mean_episode_return = None, mean_episode_step = 1384.2, total_loss = -0.088526, pg_loss = -9.3064, baseline_loss = 15.301, entropy_loss = -6.0832, learner_queue_size = 28, _tick = 19379, _time = 1.654e+09, train_seconds = 9531.0)
[2022-05-31 16:49:17,323][root][INFO] - Step 62952960 @ 6648.5 SPS. Inference batcher size: 97. Learner queue size: 6. Other stats: (step = 62952960, mean_episode_return = None, mean_episode_step = 764.66, total_loss = -37.674, pg_loss = -83.209, baseline_loss = 51.481, entropy_loss = -5.9452, learner_queue_size = 15, _tick = 19390, _time = 1.654e+09, train_seconds = 9536.0)
[2022-05-31 16:49:22,329][root][INFO] - Step 62986240 @ 6648.6 SPS. Inference batcher size: 72. Learner queue size: 3. Other stats: (step = 62986240, mean_episode_return = 69.38, mean_episode_step = 1021.9, total_loss = 189.68, pg_loss = 115.29, baseline_loss = 80.386, entropy_loss = -5.9994, learner_queue_size = 17, _tick = 19399, _time = 1.654e+09, train_seconds = 9541.0)
[2022-05-31 16:49:27,334][root][INFO] - Step 63019520 @ 6649.5 SPS. Inference batcher size: 119. Learner queue size: 27. Other stats: (step = 63019520, mean_episode_return = 153.17, mean_episode_step = 1307.6, total_loss = 108.75, pg_loss = 19.591, baseline_loss = 95.096, entropy_loss = -5.9359, learner_queue_size = 20, _tick = 19411, _time = 1.654e+09, train_seconds = 9546.0)
[2022-05-31 16:49:32,339][root][INFO] - Step 63052800 @ 6650.1 SPS. Inference batcher size: 20. Learner queue size: 29. Other stats: (step = 63052800, mean_episode_return = 202.94, mean_episode_step = 724.48, total_loss = 47.107, pg_loss = -31.928, baseline_loss = 85.193, entropy_loss = -6.1579, learner_queue_size = 24, _tick = 19422, _time = 1.654e+09, train_seconds = 9551.0)
[2022-05-31 16:49:37,342][root][INFO] - Step 63083520 @ 6139.6 SPS. Inference batcher size: 136. Learner queue size: 27. Other stats: (step = 63083520, mean_episode_return = 75.487, mean_episode_step = 4204.8, total_loss = 180.51, pg_loss = 74.04, baseline_loss = 112.6, entropy_loss = -6.1238, learner_queue_size = 13, _tick = 19432, _time = 1.654e+09, train_seconds = 9556.0)
[2022-05-31 16:49:42,348][root][INFO] - Step 63116800 @ 6648.1 SPS. Inference batcher size: 130. Learner queue size: 18. Other stats: (step = 63116800, mean_episode_return = None, mean_episode_step = 1121.9, total_loss = 301.82, pg_loss = 193.0, baseline_loss = 115.03, entropy_loss = -6.2049, learner_queue_size = 24, _tick = 19442, _time = 1.654e+09, train_seconds = 9561.0)
[2022-05-31 16:49:47,354][root][INFO] - Step 63150080 @ 6648.4 SPS. Inference batcher size: 125. Learner queue size: 7. Other stats: (step = 63150080, mean_episode_return = 167.43, mean_episode_step = 773.03, total_loss = 112.61, pg_loss = 49.451, baseline_loss = 69.298, entropy_loss = -6.1396, learner_queue_size = 30, _tick = 19452, _time = 1.654e+09, train_seconds = 9566.0)
[2022-05-31 16:49:52,360][root][INFO] - Step 63183360 @ 6647.7 SPS. Inference batcher size: 126. Learner queue size: 3. Other stats: (step = 63183360, mean_episode_return = 199.42, mean_episode_step = 898.83, total_loss = -226.95, pg_loss = -283.9, baseline_loss = 62.728, entropy_loss = -5.7828, learner_queue_size = 21, _tick = 19464, _time = 1.654e+09, train_seconds = 9571.0)
[2022-05-31 16:49:57,366][root][INFO] - Step 63216640 @ 6648.3 SPS. Inference batcher size: 160. Learner queue size: 7. Other stats: (step = 63216640, mean_episode_return = 222.55, mean_episode_step = 726.23, total_loss = -2.1979, pg_loss = -73.029, baseline_loss = 76.822, entropy_loss = -5.991, learner_queue_size = 12, _tick = 19475, _time = 1.654e+09, train_seconds = 9576.1)
[2022-05-31 16:50:02,370][root][INFO] - Step 63249920 @ 6650.4 SPS. Inference batcher size: 137. Learner queue size: 8. Other stats: (step = 63249920, mean_episode_return = 114.53, mean_episode_step = 738.82, total_loss = -140.65, pg_loss = -172.29, baseline_loss = 37.815, entropy_loss = -6.1779, learner_queue_size = 16, _tick = 19487, _time = 1.654e+09, train_seconds = 9581.1)
[2022-05-31 16:50:07,374][root][INFO] - Step 63283200 @ 6650.7 SPS. Inference batcher size: 36. Learner queue size: 30. Other stats: (step = 63283200, mean_episode_return = 141.01, mean_episode_step = 875.78, total_loss = -141.0, pg_loss = -204.9, baseline_loss = 69.869, entropy_loss = -5.9721, learner_queue_size = 13, _tick = 19498, _time = 1.654e+09, train_seconds = 9586.1)
[2022-05-31 16:50:12,378][root][INFO] - Step 63316480 @ 6650.6 SPS. Inference batcher size: 39. Learner queue size: 5. Other stats: (step = 63316480, mean_episode_return = 134.52, mean_episode_step = 622.91, total_loss = -10.715, pg_loss = -70.124, baseline_loss = 65.442, entropy_loss = -6.033, learner_queue_size = 15, _tick = 19511, _time = 1.654e+09, train_seconds = 9591.1)
[2022-05-31 16:50:17,382][root][INFO] - Step 63349760 @ 6650.7 SPS. Inference batcher size: 134. Learner queue size: 13. Other stats: (step = 63349760, mean_episode_return = 152.31, mean_episode_step = 797.24, total_loss = -175.47, pg_loss = -189.26, baseline_loss = 20.174, entropy_loss = -6.3838, learner_queue_size = 13, _tick = 19523, _time = 1.654e+09, train_seconds = 9596.1)
[2022-05-31 16:50:22,388][root][INFO] - Step 63383040 @ 6647.7 SPS. Inference batcher size: 108. Learner queue size: 21. Other stats: (step = 63383040, mean_episode_return = 291.02, mean_episode_step = 733.63, total_loss = 104.1, pg_loss = 48.82, baseline_loss = 61.575, entropy_loss = -6.2955, learner_queue_size = 21, _tick = 19535, _time = 1.654e+09, train_seconds = 9601.1)
[2022-05-31 16:50:27,394][root][INFO] - Step 63413760 @ 6136.7 SPS. Inference batcher size: 163. Learner queue size: 20. Other stats: (step = 63413760, mean_episode_return = 128.6, mean_episode_step = 726.48, total_loss = 264.33, pg_loss = 174.74, baseline_loss = 95.567, entropy_loss = -5.9816, learner_queue_size = 28, _tick = 19546, _time = 1.654e+09, train_seconds = 9606.1)
[2022-05-31 16:50:32,400][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 16:50:32,511][root][INFO] - Step 63447040 @ 6648.1 SPS. Inference batcher size: 18. Learner queue size: 16. Other stats: (step = 63447040, mean_episode_return = None, mean_episode_step = 757.03, total_loss = 412.05, pg_loss = 264.05, baseline_loss = 154.26, entropy_loss = -6.2591, learner_queue_size = 20, _tick = 19558, _time = 1.654e+09, train_seconds = 9611.1)
[2022-05-31 16:50:37,514][root][INFO] - Step 63482880 @ 7008.4 SPS. Inference batcher size: 134. Learner queue size: 22. Other stats: (step = 63482880, mean_episode_return = 137.87, mean_episode_step = 1529.8, total_loss = -106.65, pg_loss = -123.39, baseline_loss = 23.154, entropy_loss = -6.4142, learner_queue_size = 8, _tick = 19572, _time = 1.654e+09, train_seconds = 9616.2)
[2022-05-31 16:50:42,519][root][INFO] - Step 63513600 @ 6137.9 SPS. Inference batcher size: 136. Learner queue size: 22. Other stats: (step = 63513600, mean_episode_return = 203.05, mean_episode_step = 855.8, total_loss = -42.069, pg_loss = -76.024, baseline_loss = 40.355, entropy_loss = -6.4002, learner_queue_size = 13, _tick = 19580, _time = 1.654e+09, train_seconds = 9621.2)
[2022-05-31 16:50:47,525][root][INFO] - Step 63546880 @ 6648.0 SPS. Inference batcher size: 128. Learner queue size: 15. Other stats: (step = 63546880, mean_episode_return = 227.09, mean_episode_step = 1101.6, total_loss = 4.1107, pg_loss = -98.135, baseline_loss = 108.36, entropy_loss = -6.1126, learner_queue_size = 22, _tick = 19592, _time = 1.654e+09, train_seconds = 9626.2)
[2022-05-31 16:50:52,531][root][INFO] - Step 63580160 @ 6648.1 SPS. Inference batcher size: 137. Learner queue size: 22. Other stats: (step = 63580160, mean_episode_return = 60.6, mean_episode_step = 637.35, total_loss = 55.42, pg_loss = -12.023, baseline_loss = 73.701, entropy_loss = -6.2585, learner_queue_size = 32, _tick = 19605, _time = 1.654e+09, train_seconds = 9631.2)
[2022-05-31 16:50:57,534][root][INFO] - Step 63613440 @ 6651.9 SPS. Inference batcher size: 75. Learner queue size: 12. Other stats: (step = 63613440, mean_episode_return = 46.895, mean_episode_step = 4292.2, total_loss = 32.976, pg_loss = 16.013, baseline_loss = 23.754, entropy_loss = -6.7912, learner_queue_size = 21, _tick = 19617, _time = 1.654e+09, train_seconds = 9636.2)
[2022-05-31 16:51:02,538][root][INFO] - Step 63646720 @ 6650.7 SPS. Inference batcher size: 171. Learner queue size: 4. Other stats: (step = 63646720, mean_episode_return = 8.4197, mean_episode_step = 1270.8, total_loss = -74.719, pg_loss = -118.8, baseline_loss = 50.618, entropy_loss = -6.5366, learner_queue_size = 16, _tick = 19627, _time = 1.654e+09, train_seconds = 9641.2)
[2022-05-31 16:51:07,542][root][INFO] - Step 63677440 @ 6139.0 SPS. Inference batcher size: 39. Learner queue size: 17. Other stats: (step = 63677440, mean_episode_return = 66.61, mean_episode_step = 983.31, total_loss = 308.04, pg_loss = 200.51, baseline_loss = 113.86, entropy_loss = -6.3335, learner_queue_size = 23, _tick = 19638, _time = 1.654e+09, train_seconds = 9646.2)
[2022-05-31 16:51:12,546][root][INFO] - Step 63710720 @ 6651.1 SPS. Inference batcher size: 103. Learner queue size: 12. Other stats: (step = 63710720, mean_episode_return = 316.97, mean_episode_step = 969.96, total_loss = -187.86, pg_loss = -237.57, baseline_loss = 55.998, entropy_loss = -6.2906, learner_queue_size = 18, _tick = 19649, _time = 1.654e+09, train_seconds = 9651.2)
[2022-05-31 16:51:17,552][root][INFO] - Step 63744000 @ 6647.9 SPS. Inference batcher size: 128. Learner queue size: 22. Other stats: (step = 63744000, mean_episode_return = 184.98, mean_episode_step = 1037.1, total_loss = 164.6, pg_loss = 112.63, baseline_loss = 58.167, entropy_loss = -6.1904, learner_queue_size = 26, _tick = 19657, _time = 1.654e+09, train_seconds = 9656.2)
[2022-05-31 16:51:22,558][root][INFO] - Step 63777280 @ 6648.0 SPS. Inference batcher size: 145. Learner queue size: 13. Other stats: (step = 63777280, mean_episode_return = 180.24, mean_episode_step = 768.43, total_loss = 86.827, pg_loss = 7.7838, baseline_loss = 85.033, entropy_loss = -5.9892, learner_queue_size = 26, _tick = 19669, _time = 1.654e+09, train_seconds = 9661.2)
[2022-05-31 16:51:27,562][root][INFO] - Step 63810560 @ 6650.5 SPS. Inference batcher size: 128. Learner queue size: 14. Other stats: (step = 63810560, mean_episode_return = 379.19, mean_episode_step = 1078.2, total_loss = -57.706, pg_loss = -117.24, baseline_loss = 65.787, entropy_loss = -6.2508, learner_queue_size = 25, _tick = 19680, _time = 1.654e+09, train_seconds = 9666.2)
[2022-05-31 16:51:32,566][root][INFO] - Step 63843840 @ 6650.1 SPS. Inference batcher size: 10. Learner queue size: 13. Other stats: (step = 63843840, mean_episode_return = 116.25, mean_episode_step = 711.56, total_loss = 38.011, pg_loss = -16.304, baseline_loss = 60.944, entropy_loss = -6.6285, learner_queue_size = 19, _tick = 19692, _time = 1.654e+09, train_seconds = 9671.3)
[2022-05-31 16:51:37,570][root][INFO] - Step 63877120 @ 6651.3 SPS. Inference batcher size: 111. Learner queue size: 10. Other stats: (step = 63877120, mean_episode_return = 15.83, mean_episode_step = 907.78, total_loss = 64.596, pg_loss = -17.322, baseline_loss = 88.412, entropy_loss = -6.493, learner_queue_size = 16, _tick = 19704, _time = 1.654e+09, train_seconds = 9676.3)
[2022-05-31 16:51:42,576][root][INFO] - Step 63910400 @ 6647.9 SPS. Inference batcher size: 154. Learner queue size: 12. Other stats: (step = 63910400, mean_episode_return = 258.12, mean_episode_step = 1323.9, total_loss = 11.304, pg_loss = -52.807, baseline_loss = 70.574, entropy_loss = -6.4633, learner_queue_size = 14, _tick = 19715, _time = 1.654e+09, train_seconds = 9681.3)
[2022-05-31 16:51:47,582][root][INFO] - Step 63943680 @ 6647.9 SPS. Inference batcher size: 46. Learner queue size: 6. Other stats: (step = 63943680, mean_episode_return = 50.295, mean_episode_step = 667.53, total_loss = 102.0, pg_loss = 5.6102, baseline_loss = 102.84, entropy_loss = -6.4519, learner_queue_size = 25, _tick = 19726, _time = 1.654e+09, train_seconds = 9686.3)
[2022-05-31 16:51:52,586][root][INFO] - Step 63976960 @ 6650.9 SPS. Inference batcher size: 94. Learner queue size: 0. Other stats: (step = 63976960, mean_episode_return = 93.196, mean_episode_step = 732.42, total_loss = 97.529, pg_loss = -71.007, baseline_loss = 174.55, entropy_loss = -6.0182, learner_queue_size = 13, _tick = 19736, _time = 1.654e+09, train_seconds = 9691.3)
[2022-05-31 16:51:57,590][root][INFO] - Step 64010240 @ 6650.6 SPS. Inference batcher size: 112. Learner queue size: 2. Other stats: (step = 64010240, mean_episode_return = -32.39, mean_episode_step = 909.2, total_loss = 192.59, pg_loss = 104.49, baseline_loss = 94.592, entropy_loss = -6.4979, learner_queue_size = 22, _tick = 19748, _time = 1.654e+09, train_seconds = 9696.3)
[2022-05-31 16:52:02,596][root][INFO] - Step 64040960 @ 6137.0 SPS. Inference batcher size: 98. Learner queue size: 16. Other stats: (step = 64040960, mean_episode_return = 189.88, mean_episode_step = 4352.8, total_loss = -109.99, pg_loss = -123.37, baseline_loss = 19.96, entropy_loss = -6.5891, learner_queue_size = 14, _tick = 19759, _time = 1.654e+09, train_seconds = 9701.3)
[2022-05-31 16:52:07,598][root][INFO] - Step 64076800 @ 7164.8 SPS. Inference batcher size: 56. Learner queue size: 15. Other stats: (step = 64076800, mean_episode_return = 145.31, mean_episode_step = 801.96, total_loss = 11.4, pg_loss = -33.427, baseline_loss = 51.329, entropy_loss = -6.502, learner_queue_size = 15, _tick = 19769, _time = 1.654e+09, train_seconds = 9706.3)
[2022-05-31 16:52:12,605][root][INFO] - Step 64107520 @ 6135.4 SPS. Inference batcher size: 109. Learner queue size: 16. Other stats: (step = 64107520, mean_episode_return = 185.12, mean_episode_step = 800.46, total_loss = 237.2, pg_loss = 91.291, baseline_loss = 152.41, entropy_loss = -6.4949, learner_queue_size = 24, _tick = 19780, _time = 1.654e+09, train_seconds = 9711.3)
[2022-05-31 16:52:17,610][root][INFO] - Step 64140800 @ 6649.3 SPS. Inference batcher size: 101. Learner queue size: 17. Other stats: (step = 64140800, mean_episode_return = 136.4, mean_episode_step = 962.83, total_loss = 87.526, pg_loss = 48.776, baseline_loss = 45.769, entropy_loss = -7.02, learner_queue_size = 14, _tick = 19791, _time = 1.654e+09, train_seconds = 9716.3)
[2022-05-31 16:52:22,614][root][INFO] - Step 64174080 @ 6650.7 SPS. Inference batcher size: 46. Learner queue size: 15. Other stats: (step = 64174080, mean_episode_return = 138.34, mean_episode_step = 1075.8, total_loss = 198.17, pg_loss = 98.451, baseline_loss = 106.05, entropy_loss = -6.3345, learner_queue_size = 18, _tick = 19804, _time = 1.654e+09, train_seconds = 9721.3)
[2022-05-31 16:52:27,618][root][INFO] - Step 64207360 @ 6650.6 SPS. Inference batcher size: 124. Learner queue size: 5. Other stats: (step = 64207360, mean_episode_return = 166.5, mean_episode_step = 707.73, total_loss = 198.0, pg_loss = 113.36, baseline_loss = 90.488, entropy_loss = -5.8501, learner_queue_size = 25, _tick = 19817, _time = 1.654e+09, train_seconds = 9726.3)
[2022-05-31 16:52:32,622][root][INFO] - Step 64240640 @ 6650.7 SPS. Inference batcher size: 122. Learner queue size: 31. Other stats: (step = 64240640, mean_episode_return = 139.57, mean_episode_step = 440.15, total_loss = 424.72, pg_loss = 231.3, baseline_loss = 199.45, entropy_loss = -6.0264, learner_queue_size = 21, _tick = 19828, _time = 1.654e+09, train_seconds = 9731.3)
[2022-05-31 16:52:37,628][root][INFO] - Step 64271360 @ 6136.6 SPS. Inference batcher size: 187. Learner queue size: 25. Other stats: (step = 64271360, mean_episode_return = 129.74, mean_episode_step = 851.49, total_loss = 46.338, pg_loss = -12.207, baseline_loss = 64.742, entropy_loss = -6.1977, learner_queue_size = 20, _tick = 19838, _time = 1.654e+09, train_seconds = 9736.3)
[2022-05-31 16:52:42,634][root][INFO] - Step 64307200 @ 7159.6 SPS. Inference batcher size: 101. Learner queue size: 18. Other stats: (step = 64307200, mean_episode_return = 120.29, mean_episode_step = 4164.8, total_loss = -12.977, pg_loss = -39.128, baseline_loss = 33.029, entropy_loss = -6.8785, learner_queue_size = 13, _tick = 19852, _time = 1.654e+09, train_seconds = 9741.3)
[2022-05-31 16:52:47,638][root][INFO] - Step 64340480 @ 6650.6 SPS. Inference batcher size: 80. Learner queue size: 30. Other stats: (step = 64340480, mean_episode_return = 243.73, mean_episode_step = 866.46, total_loss = 58.348, pg_loss = 17.707, baseline_loss = 47.376, entropy_loss = -6.7348, learner_queue_size = 25, _tick = 19865, _time = 1.654e+09, train_seconds = 9746.3)
[2022-05-31 16:52:52,642][root][INFO] - Step 64371200 @ 6139.0 SPS. Inference batcher size: 134. Learner queue size: 22. Other stats: (step = 64371200, mean_episode_return = 254.03, mean_episode_step = 709.3, total_loss = 229.73, pg_loss = 138.35, baseline_loss = 97.652, entropy_loss = -6.2723, learner_queue_size = 21, _tick = 19874, _time = 1.654e+09, train_seconds = 9751.3)
[2022-05-31 16:52:57,646][root][INFO] - Step 64407040 @ 7162.3 SPS. Inference batcher size: 64. Learner queue size: 25. Other stats: (step = 64407040, mean_episode_return = 58.501, mean_episode_step = 880.9, total_loss = -3.5785, pg_loss = -30.036, baseline_loss = 33.179, entropy_loss = -6.7212, learner_queue_size = 14, _tick = 19888, _time = 1.654e+09, train_seconds = 9756.3)
[2022-05-31 16:53:02,652][root][INFO] - Step 64437760 @ 6136.6 SPS. Inference batcher size: 183. Learner queue size: 23. Other stats: (step = 64437760, mean_episode_return = 264.93, mean_episode_step = 847.79, total_loss = 289.29, pg_loss = 156.8, baseline_loss = 138.79, entropy_loss = -6.2998, learner_queue_size = 16, _tick = 19899, _time = 1.654e+09, train_seconds = 9761.3)
[2022-05-31 16:53:07,658][root][INFO] - Step 64471040 @ 6648.0 SPS. Inference batcher size: 180. Learner queue size: 14. Other stats: (step = 64471040, mean_episode_return = 189.6, mean_episode_step = 4359.7, total_loss = -154.77, pg_loss = -342.48, baseline_loss = 194.17, entropy_loss = -6.4624, learner_queue_size = 24, _tick = 19911, _time = 1.654e+09, train_seconds = 9766.3)
[2022-05-31 16:53:12,662][root][INFO] - Step 64504320 @ 6650.8 SPS. Inference batcher size: 58. Learner queue size: 19. Other stats: (step = 64504320, mean_episode_return = None, mean_episode_step = 996.31, total_loss = 608.98, pg_loss = 459.13, baseline_loss = 156.46, entropy_loss = -6.6148, learner_queue_size = 32, _tick = 19921, _time = 1.654e+09, train_seconds = 9771.3)
[2022-05-31 16:53:17,667][root][INFO] - Step 64537600 @ 6649.6 SPS. Inference batcher size: 60. Learner queue size: 11. Other stats: (step = 64537600, mean_episode_return = 48.762, mean_episode_step = 1069.9, total_loss = 164.54, pg_loss = 94.481, baseline_loss = 76.613, entropy_loss = -6.5586, learner_queue_size = 22, _tick = 19932, _time = 1.654e+09, train_seconds = 9776.4)
[2022-05-31 16:53:22,672][root][INFO] - Step 64570880 @ 6648.4 SPS. Inference batcher size: 114. Learner queue size: 17. Other stats: (step = 64570880, mean_episode_return = 189.57, mean_episode_step = 4266.8, total_loss = -109.65, pg_loss = -148.8, baseline_loss = 45.477, entropy_loss = -6.3267, learner_queue_size = 19, _tick = 19944, _time = 1.654e+09, train_seconds = 9781.4)
[2022-05-31 16:53:27,678][root][INFO] - Step 64604160 @ 6648.4 SPS. Inference batcher size: 92. Learner queue size: 22. Other stats: (step = 64604160, mean_episode_return = 304.89, mean_episode_step = 927.88, total_loss = -94.768, pg_loss = -136.04, baseline_loss = 47.873, entropy_loss = -6.6005, learner_queue_size = 31, _tick = 19956, _time = 1.654e+09, train_seconds = 9786.4)
[2022-05-31 16:53:32,682][root][INFO] - Step 64637440 @ 6650.9 SPS. Inference batcher size: 91. Learner queue size: 2. Other stats: (step = 64637440, mean_episode_return = 125.56, mean_episode_step = 858.8, total_loss = 736.37, pg_loss = 518.61, baseline_loss = 224.3, entropy_loss = -6.5476, learner_queue_size = 27, _tick = 19969, _time = 1.654e+09, train_seconds = 9791.4)
[2022-05-31 16:53:37,689][root][INFO] - Step 64670720 @ 6647.0 SPS. Inference batcher size: 193. Learner queue size: 4. Other stats: (step = 64670720, mean_episode_return = 169.96, mean_episode_step = 650.4, total_loss = 249.39, pg_loss = 161.05, baseline_loss = 94.583, entropy_loss = -6.2427, learner_queue_size = 18, _tick = 19980, _time = 1.654e+09, train_seconds = 9796.4)
[2022-05-31 16:53:42,694][root][INFO] - Step 64704000 @ 6649.2 SPS. Inference batcher size: 106. Learner queue size: 28. Other stats: (step = 64704000, mean_episode_return = 50.02, mean_episode_step = 1338.7, total_loss = 368.5, pg_loss = 300.5, baseline_loss = 74.424, entropy_loss = -6.4227, learner_queue_size = 20, _tick = 19991, _time = 1.654e+09, train_seconds = 9801.4)
[2022-05-31 16:53:47,698][root][INFO] - Step 64737280 @ 6650.7 SPS. Inference batcher size: 120. Learner queue size: 2. Other stats: (step = 64737280, mean_episode_return = 174.35, mean_episode_step = 971.57, total_loss = 141.42, pg_loss = 110.76, baseline_loss = 36.873, entropy_loss = -6.2135, learner_queue_size = 14, _tick = 20001, _time = 1.654e+09, train_seconds = 9806.4)
[2022-05-31 16:53:52,702][root][INFO] - Step 64770560 @ 6650.7 SPS. Inference batcher size: 70. Learner queue size: 27. Other stats: (step = 64770560, mean_episode_return = 123.04, mean_episode_step = 784.78, total_loss = -204.73, pg_loss = -326.1, baseline_loss = 127.57, entropy_loss = -6.2047, learner_queue_size = 14, _tick = 20012, _time = 1.654e+09, train_seconds = 9811.4)
[2022-05-31 16:53:57,706][root][INFO] - Step 64803840 @ 6650.5 SPS. Inference batcher size: 51. Learner queue size: 23. Other stats: (step = 64803840, mean_episode_return = 46.094, mean_episode_step = 868.21, total_loss = -53.518, pg_loss = -112.47, baseline_loss = 65.025, entropy_loss = -6.0687, learner_queue_size = 23, _tick = 20025, _time = 1.654e+09, train_seconds = 9816.4)
[2022-05-31 16:54:02,710][root][INFO] - Step 64837120 @ 6650.8 SPS. Inference batcher size: 180. Learner queue size: 28. Other stats: (step = 64837120, mean_episode_return = 115.09, mean_episode_step = 615.9, total_loss = 634.44, pg_loss = 420.75, baseline_loss = 219.49, entropy_loss = -5.7953, learner_queue_size = 17, _tick = 20037, _time = 1.654e+09, train_seconds = 9821.4)
[2022-05-31 16:54:07,716][root][INFO] - Step 64867840 @ 6136.2 SPS. Inference batcher size: 131. Learner queue size: 17. Other stats: (step = 64867840, mean_episode_return = 176.9, mean_episode_step = 576.64, total_loss = -131.91, pg_loss = -237.99, baseline_loss = 111.75, entropy_loss = -5.6689, learner_queue_size = 16, _tick = 20048, _time = 1.654e+09, train_seconds = 9826.4)
[2022-05-31 16:54:12,722][root][INFO] - Step 64901120 @ 6648.1 SPS. Inference batcher size: 107. Learner queue size: 22. Other stats: (step = 64901120, mean_episode_return = 176.75, mean_episode_step = 446.18, total_loss = 141.27, pg_loss = 82.489, baseline_loss = 64.456, entropy_loss = -5.6734, learner_queue_size = 12, _tick = 20061, _time = 1.654e+09, train_seconds = 9831.4)
[2022-05-31 16:54:17,728][root][INFO] - Step 64934400 @ 6647.9 SPS. Inference batcher size: 151. Learner queue size: 9. Other stats: (step = 64934400, mean_episode_return = 229.05, mean_episode_step = 688.57, total_loss = 38.878, pg_loss = -1.2196, baseline_loss = 46.155, entropy_loss = -6.0576, learner_queue_size = 24, _tick = 20071, _time = 1.654e+09, train_seconds = 9836.4)
[2022-05-31 16:54:22,734][root][INFO] - Step 64967680 @ 6648.4 SPS. Inference batcher size: 100. Learner queue size: 5. Other stats: (step = 64967680, mean_episode_return = 185.87, mean_episode_step = 1061.6, total_loss = 14.838, pg_loss = -9.0157, baseline_loss = 30.167, entropy_loss = -6.3126, learner_queue_size = 19, _tick = 20080, _time = 1.654e+09, train_seconds = 9841.4)
[2022-05-31 16:54:27,738][root][INFO] - Step 65000960 @ 6650.7 SPS. Inference batcher size: 72. Learner queue size: 5. Other stats: (step = 65000960, mean_episode_return = 45.211, mean_episode_step = 4418.2, total_loss = 231.81, pg_loss = 162.67, baseline_loss = 75.72, entropy_loss = -6.5727, learner_queue_size = 12, _tick = 20090, _time = 1.654e+09, train_seconds = 9846.4)
[2022-05-31 16:54:32,744][root][INFO] - Step 65034240 @ 6647.8 SPS. Inference batcher size: 95. Learner queue size: 1. Other stats: (step = 65034240, mean_episode_return = 54.726, mean_episode_step = 939.62, total_loss = 71.597, pg_loss = 45.34, baseline_loss = 32.699, entropy_loss = -6.4421, learner_queue_size = 18, _tick = 20103, _time = 1.654e+09, train_seconds = 9851.4)
[2022-05-31 16:54:37,750][root][INFO] - Step 65067520 @ 6647.6 SPS. Inference batcher size: 133. Learner queue size: 2. Other stats: (step = 65067520, mean_episode_return = 171.86, mean_episode_step = 842.34, total_loss = 200.11, pg_loss = 159.98, baseline_loss = 46.786, entropy_loss = -6.6515, learner_queue_size = 22, _tick = 20115, _time = 1.654e+09, train_seconds = 9856.4)
[2022-05-31 16:54:42,754][root][INFO] - Step 65100800 @ 6651.3 SPS. Inference batcher size: 172. Learner queue size: 3. Other stats: (step = 65100800, mean_episode_return = 93.125, mean_episode_step = 726.87, total_loss = 63.264, pg_loss = -27.343, baseline_loss = 96.843, entropy_loss = -6.2355, learner_queue_size = 26, _tick = 20126, _time = 1.654e+09, train_seconds = 9861.4)
[2022-05-31 16:54:47,758][root][INFO] - Step 65134080 @ 6650.8 SPS. Inference batcher size: 46. Learner queue size: 19. Other stats: (step = 65134080, mean_episode_return = 123.33, mean_episode_step = 924.74, total_loss = -2.4447, pg_loss = -25.749, baseline_loss = 29.775, entropy_loss = -6.4714, learner_queue_size = 11, _tick = 20137, _time = 1.654e+09, train_seconds = 9866.4)
[2022-05-31 16:54:52,762][root][INFO] - Step 65164800 @ 6139.0 SPS. Inference batcher size: 69. Learner queue size: 16. Other stats: (step = 65164800, mean_episode_return = 100.72, mean_episode_step = 893.13, total_loss = 184.6, pg_loss = 130.66, baseline_loss = 60.261, entropy_loss = -6.3182, learner_queue_size = 24, _tick = 20147, _time = 1.654e+09, train_seconds = 9871.4)
[2022-05-31 16:54:57,766][root][INFO] - Step 65198080 @ 6650.8 SPS. Inference batcher size: 137. Learner queue size: 23. Other stats: (step = 65198080, mean_episode_return = 105.45, mean_episode_step = 736.33, total_loss = -70.365, pg_loss = -86.411, baseline_loss = 22.559, entropy_loss = -6.5134, learner_queue_size = 18, _tick = 20160, _time = 1.654e+09, train_seconds = 9876.5)
[2022-05-31 16:55:02,769][root][INFO] - Step 65231360 @ 6651.8 SPS. Inference batcher size: 92. Learner queue size: 18. Other stats: (step = 65231360, mean_episode_return = 184.8, mean_episode_step = 1135.2, total_loss = 163.86, pg_loss = 92.81, baseline_loss = 77.313, entropy_loss = -6.2646, learner_queue_size = 12, _tick = 20170, _time = 1.654e+09, train_seconds = 9881.5)
[2022-05-31 16:55:07,775][root][INFO] - Step 65264640 @ 6648.0 SPS. Inference batcher size: 82. Learner queue size: 20. Other stats: (step = 65264640, mean_episode_return = None, mean_episode_step = 777.84, total_loss = 404.58, pg_loss = 331.01, baseline_loss = 79.712, entropy_loss = -6.1458, learner_queue_size = 21, _tick = 20178, _time = 1.654e+09, train_seconds = 9886.5)
[2022-05-31 16:55:12,778][root][INFO] - Step 65297920 @ 6652.1 SPS. Inference batcher size: 109. Learner queue size: 9. Other stats: (step = 65297920, mean_episode_return = 397.68, mean_episode_step = 839.85, total_loss = -126.09, pg_loss = -166.71, baseline_loss = 46.801, entropy_loss = -6.1741, learner_queue_size = 20, _tick = 20187, _time = 1.654e+09, train_seconds = 9891.5)
[2022-05-31 16:55:17,782][root][INFO] - Step 65331200 @ 6650.6 SPS. Inference batcher size: 2. Learner queue size: 2. Other stats: (step = 65331200, mean_episode_return = 305.61, mean_episode_step = 714.33, total_loss = 253.51, pg_loss = 119.62, baseline_loss = 140.01, entropy_loss = -6.123, learner_queue_size = 21, _tick = 20199, _time = 1.654e+09, train_seconds = 9896.5)
[2022-05-31 16:55:22,789][root][INFO] - Step 65364480 @ 6647.5 SPS. Inference batcher size: 112. Learner queue size: 5. Other stats: (step = 65364480, mean_episode_return = 217.13, mean_episode_step = 4349.5, total_loss = 611.28, pg_loss = 463.62, baseline_loss = 154.01, entropy_loss = -6.3482, learner_queue_size = 27, _tick = 20211, _time = 1.654e+09, train_seconds = 9901.5)
[2022-05-31 16:55:27,791][root][INFO] - Step 65395200 @ 6141.0 SPS. Inference batcher size: 60. Learner queue size: 24. Other stats: (step = 65395200, mean_episode_return = 744.29, mean_episode_step = 878.04, total_loss = 66.667, pg_loss = 23.927, baseline_loss = 48.932, entropy_loss = -6.191, learner_queue_size = 15, _tick = 20222, _time = 1.654e+09, train_seconds = 9906.5)
[2022-05-31 16:55:32,797][root][INFO] - Step 65431040 @ 7159.3 SPS. Inference batcher size: 79. Learner queue size: 29. Other stats: (step = 65431040, mean_episode_return = None, mean_episode_step = 859.97, total_loss = -30.28, pg_loss = -52.326, baseline_loss = 28.64, entropy_loss = -6.5943, learner_queue_size = 18, _tick = 20234, _time = 1.654e+09, train_seconds = 9911.5)
[2022-05-31 16:55:37,804][root][INFO] - Step 65464320 @ 6646.8 SPS. Inference batcher size: 35. Learner queue size: 23. Other stats: (step = 65464320, mean_episode_return = 147.1, mean_episode_step = 793.12, total_loss = 66.951, pg_loss = 41.841, baseline_loss = 31.81, entropy_loss = -6.6993, learner_queue_size = 23, _tick = 20243, _time = 1.654e+09, train_seconds = 9916.5)
[2022-05-31 16:55:42,810][root][INFO] - Step 65495040 @ 6136.5 SPS. Inference batcher size: 67. Learner queue size: 12. Other stats: (step = 65495040, mean_episode_return = None, mean_episode_step = 1276.0, total_loss = -28.977, pg_loss = -36.557, baseline_loss = 14.634, entropy_loss = -7.0534, learner_queue_size = 19, _tick = 20252, _time = 1.654e+09, train_seconds = 9921.5)
[2022-05-31 16:55:47,816][root][INFO] - Step 65528320 @ 6648.0 SPS. Inference batcher size: 116. Learner queue size: 21. Other stats: (step = 65528320, mean_episode_return = None, mean_episode_step = 4425.6, total_loss = 232.09, pg_loss = 173.08, baseline_loss = 65.754, entropy_loss = -6.7425, learner_queue_size = 22, _tick = 20262, _time = 1.654e+09, train_seconds = 9926.5)
[2022-05-31 16:55:52,822][root][INFO] - Step 65561600 @ 6647.9 SPS. Inference batcher size: 105. Learner queue size: 13. Other stats: (step = 65561600, mean_episode_return = 54.611, mean_episode_step = 849.4, total_loss = 143.21, pg_loss = 82.681, baseline_loss = 66.708, entropy_loss = -6.1742, learner_queue_size = 21, _tick = 20275, _time = 1.654e+09, train_seconds = 9931.5)
[2022-05-31 16:55:57,828][root][INFO] - Step 65594880 @ 6647.9 SPS. Inference batcher size: 164. Learner queue size: 16. Other stats: (step = 65594880, mean_episode_return = 64.482, mean_episode_step = 1251.2, total_loss = 138.7, pg_loss = 77.324, baseline_loss = 68.036, entropy_loss = -6.6603, learner_queue_size = 22, _tick = 20286, _time = 1.654e+09, train_seconds = 9936.5)
[2022-05-31 16:56:02,834][root][INFO] - Step 65628160 @ 6648.6 SPS. Inference batcher size: 132. Learner queue size: 16. Other stats: (step = 65628160, mean_episode_return = 45.549, mean_episode_step = 4357.5, total_loss = 293.81, pg_loss = 213.56, baseline_loss = 86.792, entropy_loss = -6.5354, learner_queue_size = 16, _tick = 20298, _time = 1.654e+09, train_seconds = 9941.5)
[2022-05-31 16:56:07,838][root][INFO] - Step 65661440 @ 6650.7 SPS. Inference batcher size: 151. Learner queue size: 4. Other stats: (step = 65661440, mean_episode_return = 61.241, mean_episode_step = 979.82, total_loss = 56.308, pg_loss = 17.863, baseline_loss = 44.681, entropy_loss = -6.2359, learner_queue_size = 13, _tick = 20309, _time = 1.654e+09, train_seconds = 9946.5)
[2022-05-31 16:56:12,842][root][INFO] - Step 65694720 @ 6650.5 SPS. Inference batcher size: 171. Learner queue size: 17. Other stats: (step = 65694720, mean_episode_return = 153.38, mean_episode_step = 821.32, total_loss = 734.59, pg_loss = 432.66, baseline_loss = 308.01, entropy_loss = -6.0849, learner_queue_size = 18, _tick = 20321, _time = 1.654e+09, train_seconds = 9951.5)
[2022-05-31 16:56:17,846][root][INFO] - Step 65728000 @ 6650.9 SPS. Inference batcher size: 95. Learner queue size: 16. Other stats: (step = 65728000, mean_episode_return = 196.98, mean_episode_step = 779.88, total_loss = 1.8808, pg_loss = -147.08, baseline_loss = 155.14, entropy_loss = -6.1759, learner_queue_size = 24, _tick = 20333, _time = 1.654e+09, train_seconds = 9956.5)
[2022-05-31 16:56:22,850][root][INFO] - Step 65761280 @ 6650.8 SPS. Inference batcher size: 51. Learner queue size: 14. Other stats: (step = 65761280, mean_episode_return = 132.93, mean_episode_step = 740.09, total_loss = 341.18, pg_loss = 225.16, baseline_loss = 122.32, entropy_loss = -6.304, learner_queue_size = 23, _tick = 20345, _time = 1.654e+09, train_seconds = 9961.5)
[2022-05-31 16:56:27,854][root][INFO] - Step 65794560 @ 6650.6 SPS. Inference batcher size: 133. Learner queue size: 3. Other stats: (step = 65794560, mean_episode_return = 165.77, mean_episode_step = 642.33, total_loss = 314.95, pg_loss = 224.44, baseline_loss = 96.43, entropy_loss = -5.9154, learner_queue_size = 21, _tick = 20358, _time = 1.654e+09, train_seconds = 9966.5)
[2022-05-31 16:56:32,858][root][INFO] - Step 65827840 @ 6650.5 SPS. Inference batcher size: 91. Learner queue size: 0. Other stats: (step = 65827840, mean_episode_return = None, mean_episode_step = 601.72, total_loss = 798.65, pg_loss = 359.56, baseline_loss = 445.04, entropy_loss = -5.9507, learner_queue_size = 18, _tick = 20369, _time = 1.654e+09, train_seconds = 9971.5)
[2022-05-31 16:56:37,862][root][INFO] - Step 65861120 @ 6650.9 SPS. Inference batcher size: 116. Learner queue size: 25. Other stats: (step = 65861120, mean_episode_return = 221.03, mean_episode_step = 671.89, total_loss = -141.35, pg_loss = -175.8, baseline_loss = 40.975, entropy_loss = -6.5277, learner_queue_size = 21, _tick = 20380, _time = 1.654e+09, train_seconds = 9976.5)
[2022-05-31 16:56:42,868][root][INFO] - Step 65891840 @ 6136.6 SPS. Inference batcher size: 125. Learner queue size: 23. Other stats: (step = 65891840, mean_episode_return = None, mean_episode_step = 4567.9, total_loss = 99.302, pg_loss = 43.45, baseline_loss = 62.62, entropy_loss = -6.768, learner_queue_size = 20, _tick = 20390, _time = 1.654e+09, train_seconds = 9981.6)
[2022-05-31 16:56:47,874][root][INFO] - Step 65925120 @ 6648.0 SPS. Inference batcher size: 105. Learner queue size: 12. Other stats: (step = 65925120, mean_episode_return = None, mean_episode_step = 651.81, total_loss = 62.629, pg_loss = -1.7187, baseline_loss = 70.592, entropy_loss = -6.2437, learner_queue_size = 16, _tick = 20399, _time = 1.654e+09, train_seconds = 9986.6)
[2022-05-31 16:56:52,879][root][INFO] - Step 65958400 @ 6649.9 SPS. Inference batcher size: 73. Learner queue size: 9. Other stats: (step = 65958400, mean_episode_return = None, mean_episode_step = 903.12, total_loss = 177.05, pg_loss = 38.469, baseline_loss = 144.72, entropy_loss = -6.1431, learner_queue_size = 15, _tick = 20408, _time = 1.654e+09, train_seconds = 9991.6)
[2022-05-31 16:56:57,882][root][INFO] - Step 65991680 @ 6651.6 SPS. Inference batcher size: 130. Learner queue size: 7. Other stats: (step = 65991680, mean_episode_return = 267.08, mean_episode_step = 761.54, total_loss = -101.27, pg_loss = -287.05, baseline_loss = 192.26, entropy_loss = -6.4775, learner_queue_size = 20, _tick = 20420, _time = 1.654e+09, train_seconds = 9996.6)
[2022-05-31 16:57:02,888][root][INFO] - Step 66024960 @ 6648.2 SPS. Inference batcher size: 124. Learner queue size: 2. Other stats: (step = 66024960, mean_episode_return = 63.959, mean_episode_step = 899.85, total_loss = 1010.9, pg_loss = 369.94, baseline_loss = 647.81, entropy_loss = -6.9, learner_queue_size = 21, _tick = 20432, _time = 1.654e+09, train_seconds = 1.0002e+04)
[2022-05-31 16:57:07,891][root][INFO] - Step 66055680 @ 6140.6 SPS. Inference batcher size: 182. Learner queue size: 24. Other stats: (step = 66055680, mean_episode_return = 605.73, mean_episode_step = 4521.8, total_loss = 371.43, pg_loss = 263.98, baseline_loss = 114.22, entropy_loss = -6.7715, learner_queue_size = 25, _tick = 20443, _time = 1.654e+09, train_seconds = 1.0007e+04)
[2022-05-31 16:57:12,894][root][INFO] - Step 66091520 @ 7163.1 SPS. Inference batcher size: 54. Learner queue size: 23. Other stats: (step = 66091520, mean_episode_return = 290.05, mean_episode_step = 819.19, total_loss = 104.41, pg_loss = 78.189, baseline_loss = 33.392, entropy_loss = -7.175, learner_queue_size = 22, _tick = 20456, _time = 1.654e+09, train_seconds = 1.0012e+04)
[2022-05-31 16:57:17,898][root][INFO] - Step 66124800 @ 6650.7 SPS. Inference batcher size: 57. Learner queue size: 19. Other stats: (step = 66124800, mean_episode_return = None, mean_episode_step = 737.47, total_loss = 62.895, pg_loss = 33.846, baseline_loss = 36.138, entropy_loss = -7.0889, learner_queue_size = 15, _tick = 20466, _time = 1.654e+09, train_seconds = 1.0017e+04)
[2022-05-31 16:57:22,904][root][INFO] - Step 66155520 @ 6136.0 SPS. Inference batcher size: 165. Learner queue size: 16. Other stats: (step = 66155520, mean_episode_return = None, mean_episode_step = 4592.2, total_loss = 141.12, pg_loss = 91.397, baseline_loss = 56.444, entropy_loss = -6.7176, learner_queue_size = 19, _tick = 20477, _time = 1.654e+09, train_seconds = 1.0022e+04)
[2022-05-31 16:57:27,910][root][INFO] - Step 66191360 @ 7160.1 SPS. Inference batcher size: 144. Learner queue size: 25. Other stats: (step = 66191360, mean_episode_return = None, mean_episode_step = 735.81, total_loss = 205.96, pg_loss = 107.05, baseline_loss = 105.32, entropy_loss = -6.404, learner_queue_size = 16, _tick = 20487, _time = 1.654e+09, train_seconds = 1.0027e+04)
[2022-05-31 16:57:32,916][root][INFO] - Step 66222080 @ 6136.6 SPS. Inference batcher size: 81. Learner queue size: 20. Other stats: (step = 66222080, mean_episode_return = 415.19, mean_episode_step = 1265.8, total_loss = 258.58, pg_loss = 167.08, baseline_loss = 97.687, entropy_loss = -6.1786, learner_queue_size = 18, _tick = 20496, _time = 1.654e+09, train_seconds = 1.0032e+04)
[2022-05-31 16:57:37,922][root][INFO] - Step 66255360 @ 6648.1 SPS. Inference batcher size: 157. Learner queue size: 14. Other stats: (step = 66255360, mean_episode_return = 120.29, mean_episode_step = 774.57, total_loss = 312.57, pg_loss = 186.8, baseline_loss = 132.41, entropy_loss = -6.6346, learner_queue_size = 18, _tick = 20508, _time = 1.654e+09, train_seconds = 1.0037e+04)
[2022-05-31 16:57:42,926][root][INFO] - Step 66288640 @ 6650.8 SPS. Inference batcher size: 85. Learner queue size: 7. Other stats: (step = 66288640, mean_episode_return = 76.715, mean_episode_step = 652.95, total_loss = 305.52, pg_loss = 171.47, baseline_loss = 140.36, entropy_loss = -6.3107, learner_queue_size = 25, _tick = 20518, _time = 1.654e+09, train_seconds = 1.0042e+04)
[2022-05-31 16:57:47,932][root][INFO] - Step 66321920 @ 6647.9 SPS. Inference batcher size: 115. Learner queue size: 7. Other stats: (step = 66321920, mean_episode_return = 104.4, mean_episode_step = 783.83, total_loss = 116.69, pg_loss = 49.79, baseline_loss = 73.482, entropy_loss = -6.579, learner_queue_size = 12, _tick = 20531, _time = 1.654e+09, train_seconds = 1.0047e+04)
[2022-05-31 16:57:52,938][root][INFO] - Step 66355200 @ 6648.2 SPS. Inference batcher size: 99. Learner queue size: 0. Other stats: (step = 66355200, mean_episode_return = 155.32, mean_episode_step = 735.93, total_loss = -101.44, pg_loss = -161.67, baseline_loss = 66.81, entropy_loss = -6.5818, learner_queue_size = 14, _tick = 20544, _time = 1.654e+09, train_seconds = 1.0052e+04)
[2022-05-31 16:57:57,942][root][INFO] - Step 66385920 @ 6139.0 SPS. Inference batcher size: 26. Learner queue size: 21. Other stats: (step = 66385920, mean_episode_return = None, mean_episode_step = 1367.0, total_loss = 168.59, pg_loss = 104.6, baseline_loss = 70.203, entropy_loss = -6.2141, learner_queue_size = 26, _tick = 20554, _time = 1.654e+09, train_seconds = 1.0057e+04)
[2022-05-31 16:58:02,946][root][INFO] - Step 66419200 @ 6650.6 SPS. Inference batcher size: 160. Learner queue size: 19. Other stats: (step = 66419200, mean_episode_return = 143.21, mean_episode_step = 659.71, total_loss = 436.09, pg_loss = 228.58, baseline_loss = 213.47, entropy_loss = -5.959, learner_queue_size = 19, _tick = 20565, _time = 1.654e+09, train_seconds = 1.0062e+04)
[2022-05-31 16:58:07,952][root][INFO] - Step 66455040 @ 7159.2 SPS. Inference batcher size: 165. Learner queue size: 23. Other stats: (step = 66455040, mean_episode_return = -3.4704, mean_episode_step = 633.55, total_loss = -156.76, pg_loss = -229.96, baseline_loss = 79.909, entropy_loss = -6.7107, learner_queue_size = 21, _tick = 20579, _time = 1.654e+09, train_seconds = 1.0067e+04)
[2022-05-31 16:58:12,958][root][INFO] - Step 66488320 @ 6648.2 SPS. Inference batcher size: 88. Learner queue size: 24. Other stats: (step = 66488320, mean_episode_return = 200.35, mean_episode_step = 801.16, total_loss = 69.601, pg_loss = -40.09, baseline_loss = 116.52, entropy_loss = -6.8312, learner_queue_size = 21, _tick = 20590, _time = 1.654e+09, train_seconds = 1.0072e+04)
[2022-05-31 16:58:17,964][root][INFO] - Step 66519040 @ 6136.4 SPS. Inference batcher size: 148. Learner queue size: 20. Other stats: (step = 66519040, mean_episode_return = 127.24, mean_episode_step = 706.76, total_loss = 87.383, pg_loss = 30.384, baseline_loss = 63.651, entropy_loss = -6.6519, learner_queue_size = 16, _tick = 20602, _time = 1.654e+09, train_seconds = 1.0077e+04)
[2022-05-31 16:58:22,970][root][INFO] - Step 66552320 @ 6647.9 SPS. Inference batcher size: 128. Learner queue size: 20. Other stats: (step = 66552320, mean_episode_return = 139.94, mean_episode_step = 831.1, total_loss = 83.731, pg_loss = -28.438, baseline_loss = 117.87, entropy_loss = -5.6983, learner_queue_size = 22, _tick = 20614, _time = 1.654e+09, train_seconds = 1.0082e+04)
[2022-05-31 16:58:27,974][root][INFO] - Step 66585600 @ 6651.2 SPS. Inference batcher size: 121. Learner queue size: 15. Other stats: (step = 66585600, mean_episode_return = None, mean_episode_step = 924.53, total_loss = 447.05, pg_loss = 212.64, baseline_loss = 240.64, entropy_loss = -6.2386, learner_queue_size = 13, _tick = 20625, _time = 1.654e+09, train_seconds = 1.0087e+04)
[2022-05-31 16:58:32,978][root][INFO] - Step 66618880 @ 6650.4 SPS. Inference batcher size: 152. Learner queue size: 7. Other stats: (step = 66618880, mean_episode_return = 108.65, mean_episode_step = 896.89, total_loss = 187.58, pg_loss = 133.38, baseline_loss = 60.714, entropy_loss = -6.5208, learner_queue_size = 14, _tick = 20637, _time = 1.654e+09, train_seconds = 1.0092e+04)
[2022-05-31 16:58:37,984][root][INFO] - Step 66652160 @ 6647.9 SPS. Inference batcher size: 117. Learner queue size: 7. Other stats: (step = 66652160, mean_episode_return = 324.55, mean_episode_step = 1268.8, total_loss = 85.943, pg_loss = -20.287, baseline_loss = 112.48, entropy_loss = -6.2479, learner_queue_size = 13, _tick = 20649, _time = 1.654e+09, train_seconds = 1.0097e+04)
[2022-05-31 16:58:42,990][root][INFO] - Step 66685440 @ 6648.4 SPS. Inference batcher size: 114. Learner queue size: 2. Other stats: (step = 66685440, mean_episode_return = 120.05, mean_episode_step = 4568.1, total_loss = 16.832, pg_loss = -55.245, baseline_loss = 78.105, entropy_loss = -6.0284, learner_queue_size = 16, _tick = 20661, _time = 1.654e+09, train_seconds = 1.0102e+04)
[2022-05-31 16:58:47,996][root][INFO] - Step 66718720 @ 6648.0 SPS. Inference batcher size: 36. Learner queue size: 18. Other stats: (step = 66718720, mean_episode_return = 229.59, mean_episode_step = 609.99, total_loss = -69.258, pg_loss = -109.02, baseline_loss = 46.024, entropy_loss = -6.2571, learner_queue_size = 18, _tick = 20673, _time = 1.654e+09, train_seconds = 1.0107e+04)
[2022-05-31 16:58:53,002][root][INFO] - Step 66752000 @ 6648.1 SPS. Inference batcher size: 32. Learner queue size: 27. Other stats: (step = 66752000, mean_episode_return = 51.253, mean_episode_step = 688.72, total_loss = 73.046, pg_loss = 3.1272, baseline_loss = 76.537, entropy_loss = -6.6181, learner_queue_size = 14, _tick = 20684, _time = 1.654e+09, train_seconds = 1.0112e+04)
[2022-05-31 16:58:58,006][root][INFO] - Step 66785280 @ 6650.7 SPS. Inference batcher size: 106. Learner queue size: 27. Other stats: (step = 66785280, mean_episode_return = None, mean_episode_step = 622.41, total_loss = 662.1, pg_loss = 447.67, baseline_loss = 220.7, entropy_loss = -6.2662, learner_queue_size = 19, _tick = 20695, _time = 1.654e+09, train_seconds = 1.0117e+04)
[2022-05-31 16:59:03,010][root][INFO] - Step 66818560 @ 6650.5 SPS. Inference batcher size: 173. Learner queue size: 24. Other stats: (step = 66818560, mean_episode_return = 111.06, mean_episode_step = 825.04, total_loss = 467.24, pg_loss = 335.9, baseline_loss = 137.76, entropy_loss = -6.4307, learner_queue_size = 17, _tick = 20707, _time = 1.654e+09, train_seconds = 1.0122e+04)
[2022-05-31 16:59:08,016][root][INFO] - Step 66849280 @ 6136.5 SPS. Inference batcher size: 163. Learner queue size: 14. Other stats: (step = 66849280, mean_episode_return = 170.92, mean_episode_step = 4537.4, total_loss = 141.21, pg_loss = 79.591, baseline_loss = 67.863, entropy_loss = -6.2456, learner_queue_size = 13, _tick = 20718, _time = 1.654e+09, train_seconds = 1.0127e+04)
[2022-05-31 16:59:13,022][root][INFO] - Step 66882560 @ 6648.3 SPS. Inference batcher size: 44. Learner queue size: 29. Other stats: (step = 66882560, mean_episode_return = 216.25, mean_episode_step = 694.63, total_loss = 57.473, pg_loss = -6.3583, baseline_loss = 69.932, entropy_loss = -6.1004, learner_queue_size = 14, _tick = 20729, _time = 1.654e+09, train_seconds = 1.0132e+04)
[2022-05-31 16:59:18,026][root][INFO] - Step 66915840 @ 6650.6 SPS. Inference batcher size: 77. Learner queue size: 18. Other stats: (step = 66915840, mean_episode_return = 44.94, mean_episode_step = 731.4, total_loss = 25.028, pg_loss = -45.401, baseline_loss = 76.496, entropy_loss = -6.0675, learner_queue_size = 18, _tick = 20742, _time = 1.654e+09, train_seconds = 1.0137e+04)
[2022-05-31 16:59:23,030][root][INFO] - Step 66949120 @ 6650.8 SPS. Inference batcher size: 128. Learner queue size: 24. Other stats: (step = 66949120, mean_episode_return = 100.39, mean_episode_step = 679.5, total_loss = -121.31, pg_loss = -218.32, baseline_loss = 103.56, entropy_loss = -6.5443, learner_queue_size = 14, _tick = 20754, _time = 1.654e+09, train_seconds = 1.0142e+04)
[2022-05-31 16:59:28,034][root][INFO] - Step 66979840 @ 6139.1 SPS. Inference batcher size: 134. Learner queue size: 13. Other stats: (step = 66979840, mean_episode_return = 65.174, mean_episode_step = 1054.1, total_loss = -103.07, pg_loss = -135.59, baseline_loss = 39.485, entropy_loss = -6.9638, learner_queue_size = 19, _tick = 20764, _time = 1.654e+09, train_seconds = 1.0147e+04)
[2022-05-31 16:59:33,040][root][INFO] - Step 67013120 @ 6647.7 SPS. Inference batcher size: 76. Learner queue size: 12. Other stats: (step = 67013120, mean_episode_return = 202.13, mean_episode_step = 845.53, total_loss = 262.54, pg_loss = 193.72, baseline_loss = 75.338, entropy_loss = -6.5213, learner_queue_size = 19, _tick = 20777, _time = 1.654e+09, train_seconds = 1.0152e+04)
[2022-05-31 16:59:38,046][root][INFO] - Step 67046400 @ 6647.9 SPS. Inference batcher size: 88. Learner queue size: 16. Other stats: (step = 67046400, mean_episode_return = 614.59, mean_episode_step = 729.44, total_loss = 217.0, pg_loss = 124.26, baseline_loss = 99.39, entropy_loss = -6.6418, learner_queue_size = 20, _tick = 20788, _time = 1.654e+09, train_seconds = 1.0157e+04)
[2022-05-31 16:59:43,053][root][INFO] - Step 67079680 @ 6647.5 SPS. Inference batcher size: 88. Learner queue size: 2. Other stats: (step = 67079680, mean_episode_return = 169.76, mean_episode_step = 846.78, total_loss = 448.97, pg_loss = 230.26, baseline_loss = 224.64, entropy_loss = -5.9288, learner_queue_size = 14, _tick = 20798, _time = 1.654e+09, train_seconds = 1.0162e+04)
[2022-05-31 16:59:48,058][root][INFO] - Step 67112960 @ 6648.4 SPS. Inference batcher size: 86. Learner queue size: 3. Other stats: (step = 67112960, mean_episode_return = 81.629, mean_episode_step = 4659.8, total_loss = 30.089, pg_loss = -13.962, baseline_loss = 50.361, entropy_loss = -6.3097, learner_queue_size = 20, _tick = 20809, _time = 1.654e+09, train_seconds = 1.0167e+04)
[2022-05-31 16:59:53,062][root][INFO] - Step 67146240 @ 6651.2 SPS. Inference batcher size: 117. Learner queue size: 1. Other stats: (step = 67146240, mean_episode_return = 33.831, mean_episode_step = 631.56, total_loss = 76.031, pg_loss = 24.034, baseline_loss = 58.585, entropy_loss = -6.5869, learner_queue_size = 25, _tick = 20822, _time = 1.654e+09, train_seconds = 1.0172e+04)
[2022-05-31 16:59:58,066][root][INFO] - Step 67176960 @ 6139.2 SPS. Inference batcher size: 98. Learner queue size: 23. Other stats: (step = 67176960, mean_episode_return = 181.25, mean_episode_step = 1339.1, total_loss = 81.153, pg_loss = 10.222, baseline_loss = 77.261, entropy_loss = -6.33, learner_queue_size = 25, _tick = 20831, _time = 1.654e+09, train_seconds = 1.0177e+04)
[2022-05-31 17:00:03,070][root][INFO] - Step 67212800 @ 7162.2 SPS. Inference batcher size: 45. Learner queue size: 23. Other stats: (step = 67212800, mean_episode_return = 104.01, mean_episode_step = 4726.4, total_loss = -17.701, pg_loss = -8.0947, baseline_loss = 44.751, entropy_loss = -6.4137, learner_queue_size = 13, _tick = 20841, _time = 1.654e+09, train_seconds = 1.0182e+04)
[2022-05-31 17:00:08,072][root][INFO] - Step 67246080 @ 6653.5 SPS. Inference batcher size: 91. Learner queue size: 20. Other stats: (step = 67246080, mean_episode_return = 118.91, mean_episode_step = 1061.8, total_loss = 93.54, pg_loss = 11.681, baseline_loss = 87.942, entropy_loss = -6.0834, learner_queue_size = 20, _tick = 20855, _time = 1.654e+09, train_seconds = 1.0187e+04)
[2022-05-31 17:00:13,077][root][INFO] - Step 67276800 @ 6137.8 SPS. Inference batcher size: 115. Learner queue size: 15. Other stats: (step = 67276800, mean_episode_return = 133.7, mean_episode_step = 1365.9, total_loss = 86.351, pg_loss = -13.005, baseline_loss = 105.73, entropy_loss = -6.3726, learner_queue_size = 17, _tick = 20867, _time = 1.654e+09, train_seconds = 1.0192e+04)
[2022-05-31 17:00:18,083][root][INFO] - Step 67310080 @ 6648.0 SPS. Inference batcher size: 143. Learner queue size: 15. Other stats: (step = 67310080, mean_episode_return = 151.83, mean_episode_step = 865.94, total_loss = 78.389, pg_loss = 25.121, baseline_loss = 60.145, entropy_loss = -6.8773, learner_queue_size = 20, _tick = 20876, _time = 1.654e+09, train_seconds = 1.0197e+04)
[2022-05-31 17:00:23,089][root][INFO] - Step 67343360 @ 6648.0 SPS. Inference batcher size: 194. Learner queue size: 17. Other stats: (step = 67343360, mean_episode_return = 174.77, mean_episode_step = 914.1, total_loss = 81.049, pg_loss = 60.523, baseline_loss = 27.827, entropy_loss = -7.3008, learner_queue_size = 26, _tick = 20888, _time = 1.654e+09, train_seconds = 1.0202e+04)
[2022-05-31 17:00:28,095][root][INFO] - Step 67376640 @ 6647.9 SPS. Inference batcher size: 41. Learner queue size: 13. Other stats: (step = 67376640, mean_episode_return = 83.764, mean_episode_step = 4786.6, total_loss = -17.894, pg_loss = -41.506, baseline_loss = 30.708, entropy_loss = -7.0963, learner_queue_size = 24, _tick = 20898, _time = 1.654e+09, train_seconds = 1.0207e+04)
[2022-05-31 17:00:33,101][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 17:00:33,223][root][INFO] - Step 67409920 @ 6648.0 SPS. Inference batcher size: 26. Learner queue size: 23. Other stats: (step = 67412480, mean_episode_return = 320.93, mean_episode_step = 954.61, total_loss = 50.529, pg_loss = 4.4735, baseline_loss = 52.774, entropy_loss = -6.7188, learner_queue_size = 23, _tick = 20911, _time = 1.654e+09, train_seconds = 1.0212e+04)
[2022-05-31 17:00:38,226][root][INFO] - Step 67443200 @ 6493.7 SPS. Inference batcher size: 143. Learner queue size: 18. Other stats: (step = 67443200, mean_episode_return = 59.561, mean_episode_step = 772.62, total_loss = 6.8419, pg_loss = -43.166, baseline_loss = 56.424, entropy_loss = -6.4159, learner_queue_size = 18, _tick = 20921, _time = 1.654e+09, train_seconds = 1.0217e+04)
[2022-05-31 17:00:43,230][root][INFO] - Step 67476480 @ 6650.8 SPS. Inference batcher size: 122. Learner queue size: 24. Other stats: (step = 67476480, mean_episode_return = 186.03, mean_episode_step = 4817.8, total_loss = 76.308, pg_loss = 37.27, baseline_loss = 45.592, entropy_loss = -6.5535, learner_queue_size = 14, _tick = 20932, _time = 1.654e+09, train_seconds = 1.0222e+04)
[2022-05-31 17:00:48,236][root][INFO] - Step 67509760 @ 6648.0 SPS. Inference batcher size: 76. Learner queue size: 11. Other stats: (step = 67509760, mean_episode_return = 136.61, mean_episode_step = 891.27, total_loss = -44.206, pg_loss = -81.176, baseline_loss = 43.027, entropy_loss = -6.0572, learner_queue_size = 19, _tick = 20945, _time = 1.654e+09, train_seconds = 1.0227e+04)
[2022-05-31 17:00:53,238][root][INFO] - Step 67543040 @ 6653.2 SPS. Inference batcher size: 134. Learner queue size: 12. Other stats: (step = 67543040, mean_episode_return = 185.36, mean_episode_step = 672.33, total_loss = 69.221, pg_loss = -98.609, baseline_loss = 173.87, entropy_loss = -6.04, learner_queue_size = 16, _tick = 20955, _time = 1.654e+09, train_seconds = 1.0232e+04)
[2022-05-31 17:00:58,242][root][INFO] - Step 67576320 @ 6650.6 SPS. Inference batcher size: 74. Learner queue size: 8. Other stats: (step = 67576320, mean_episode_return = 15.975, mean_episode_step = 793.76, total_loss = 152.49, pg_loss = 38.704, baseline_loss = 120.45, entropy_loss = -6.6614, learner_queue_size = 15, _tick = 20967, _time = 1.654e+09, train_seconds = 1.0237e+04)
[2022-05-31 17:01:03,246][root][INFO] - Step 67609600 @ 6650.9 SPS. Inference batcher size: 115. Learner queue size: 9. Other stats: (step = 67609600, mean_episode_return = None, mean_episode_step = 807.69, total_loss = -87.174, pg_loss = -228.03, baseline_loss = 146.84, entropy_loss = -5.9893, learner_queue_size = 10, _tick = 20977, _time = 1.654e+09, train_seconds = 1.0242e+04)
[2022-05-31 17:01:08,250][root][INFO] - Step 67642880 @ 6650.7 SPS. Inference batcher size: 67. Learner queue size: 30. Other stats: (step = 67642880, mean_episode_return = None, mean_episode_step = 1414.7, total_loss = -19.294, pg_loss = -60.876, baseline_loss = 47.874, entropy_loss = -6.2917, learner_queue_size = 28, _tick = 20987, _time = 1.654e+09, train_seconds = 1.0247e+04)
[2022-05-31 17:01:13,254][root][INFO] - Step 67676160 @ 6650.7 SPS. Inference batcher size: 102. Learner queue size: 12. Other stats: (step = 67676160, mean_episode_return = 149.99, mean_episode_step = 663.35, total_loss = -74.373, pg_loss = -120.06, baseline_loss = 52.316, entropy_loss = -6.633, learner_queue_size = 11, _tick = 21000, _time = 1.654e+09, train_seconds = 1.0252e+04)
[2022-05-31 17:01:18,260][root][INFO] - Step 67706880 @ 6136.5 SPS. Inference batcher size: 124. Learner queue size: 21. Other stats: (step = 67706880, mean_episode_return = 156.55, mean_episode_step = 673.43, total_loss = 11.338, pg_loss = -10.465, baseline_loss = 28.53, entropy_loss = -6.7265, learner_queue_size = 16, _tick = 21011, _time = 1.654e+09, train_seconds = 1.0257e+04)
[2022-05-31 17:01:23,266][root][INFO] - Step 67740160 @ 6648.2 SPS. Inference batcher size: 115. Learner queue size: 13. Other stats: (step = 67740160, mean_episode_return = 56.204, mean_episode_step = 804.13, total_loss = 472.61, pg_loss = 361.9, baseline_loss = 117.01, entropy_loss = -6.299, learner_queue_size = 16, _tick = 21023, _time = 1.654e+09, train_seconds = 1.0262e+04)
[2022-05-31 17:01:28,272][root][INFO] - Step 67773440 @ 6647.7 SPS. Inference batcher size: 104. Learner queue size: 14. Other stats: (step = 67773440, mean_episode_return = 135.37, mean_episode_step = 812.64, total_loss = -93.979, pg_loss = -177.54, baseline_loss = 89.459, entropy_loss = -5.898, learner_queue_size = 26, _tick = 21035, _time = 1.654e+09, train_seconds = 1.0267e+04)
[2022-05-31 17:01:33,278][root][INFO] - Step 67806720 @ 6648.3 SPS. Inference batcher size: 113. Learner queue size: 3. Other stats: (step = 67806720, mean_episode_return = None, mean_episode_step = 930.0, total_loss = -107.16, pg_loss = -150.27, baseline_loss = 49.613, entropy_loss = -6.4985, learner_queue_size = 18, _tick = 21045, _time = 1.654e+09, train_seconds = 1.0272e+04)
[2022-05-31 17:01:38,282][root][INFO] - Step 67840000 @ 6650.8 SPS. Inference batcher size: 132. Learner queue size: 29. Other stats: (step = 67840000, mean_episode_return = 291.29, mean_episode_step = 745.47, total_loss = 274.87, pg_loss = 97.258, baseline_loss = 183.99, entropy_loss = -6.3775, learner_queue_size = 16, _tick = 21058, _time = 1.654e+09, train_seconds = 1.0277e+04)
[2022-05-31 17:01:43,286][root][INFO] - Step 67873280 @ 6650.5 SPS. Inference batcher size: 67. Learner queue size: 16. Other stats: (step = 67873280, mean_episode_return = 116.02, mean_episode_step = 793.47, total_loss = 447.23, pg_loss = 231.35, baseline_loss = 222.41, entropy_loss = -6.5298, learner_queue_size = 16, _tick = 21070, _time = 1.654e+09, train_seconds = 1.0282e+04)
[2022-05-31 17:01:48,290][root][INFO] - Step 67904000 @ 6139.3 SPS. Inference batcher size: 124. Learner queue size: 18. Other stats: (step = 67904000, mean_episode_return = 187.0, mean_episode_step = 655.2, total_loss = 285.3, pg_loss = 173.09, baseline_loss = 118.49, entropy_loss = -6.2905, learner_queue_size = 22, _tick = 21081, _time = 1.654e+09, train_seconds = 1.0287e+04)
[2022-05-31 17:01:53,296][root][INFO] - Step 67937280 @ 6648.0 SPS. Inference batcher size: 145. Learner queue size: 11. Other stats: (step = 67937280, mean_episode_return = 67.88, mean_episode_step = 837.09, total_loss = -223.12, pg_loss = -238.04, baseline_loss = 21.831, entropy_loss = -6.9059, learner_queue_size = 20, _tick = 21092, _time = 1.654e+09, train_seconds = 1.0292e+04)
[2022-05-31 17:01:58,302][root][INFO] - Step 67970560 @ 6648.0 SPS. Inference batcher size: 120. Learner queue size: 8. Other stats: (step = 67970560, mean_episode_return = None, mean_episode_step = 867.97, total_loss = 396.13, pg_loss = 276.0, baseline_loss = 126.78, entropy_loss = -6.6424, learner_queue_size = 16, _tick = 21102, _time = 1.654e+09, train_seconds = 1.0297e+04)
[2022-05-31 17:02:03,306][root][INFO] - Step 68003840 @ 6650.7 SPS. Inference batcher size: 94. Learner queue size: 7. Other stats: (step = 68003840, mean_episode_return = 154.14, mean_episode_step = 4634.0, total_loss = -114.79, pg_loss = -141.11, baseline_loss = 32.748, entropy_loss = -6.4267, learner_queue_size = 12, _tick = 21114, _time = 1.654e+09, train_seconds = 1.0302e+04)
[2022-05-31 17:02:08,310][root][INFO] - Step 68037120 @ 6650.8 SPS. Inference batcher size: 135. Learner queue size: 1. Other stats: (step = 68037120, mean_episode_return = 147.75, mean_episode_step = 763.68, total_loss = -168.45, pg_loss = -196.22, baseline_loss = 34.251, entropy_loss = -6.4792, learner_queue_size = 30, _tick = 21126, _time = 1.654e+09, train_seconds = 1.0307e+04)
[2022-05-31 17:02:13,314][root][INFO] - Step 68067840 @ 6139.0 SPS. Inference batcher size: 175. Learner queue size: 19. Other stats: (step = 68067840, mean_episode_return = 195.71, mean_episode_step = 1522.5, total_loss = 194.49, pg_loss = 151.91, baseline_loss = 48.935, entropy_loss = -6.3513, learner_queue_size = 25, _tick = 21137, _time = 1.654e+09, train_seconds = 1.0312e+04)
[2022-05-31 17:02:18,320][root][INFO] - Step 68101120 @ 6647.8 SPS. Inference batcher size: 50. Learner queue size: 8. Other stats: (step = 68101120, mean_episode_return = 128.38, mean_episode_step = 634.07, total_loss = 138.78, pg_loss = 30.303, baseline_loss = 114.65, entropy_loss = -6.1659, learner_queue_size = 22, _tick = 21150, _time = 1.654e+09, train_seconds = 1.0317e+04)
[2022-05-31 17:02:23,326][root][INFO] - Step 68134400 @ 6648.0 SPS. Inference batcher size: 158. Learner queue size: 3. Other stats: (step = 68134400, mean_episode_return = None, mean_episode_step = 719.97, total_loss = 32.751, pg_loss = -76.867, baseline_loss = 115.75, entropy_loss = -6.1283, learner_queue_size = 26, _tick = 21162, _time = 1.654e+09, train_seconds = 1.0322e+04)
[2022-05-31 17:02:28,330][root][INFO] - Step 68167680 @ 6650.8 SPS. Inference batcher size: 115. Learner queue size: 27. Other stats: (step = 68167680, mean_episode_return = 139.74, mean_episode_step = 4681.5, total_loss = -183.01, pg_loss = -227.58, baseline_loss = 50.648, entropy_loss = -6.0745, learner_queue_size = 13, _tick = 21174, _time = 1.654e+09, train_seconds = 1.0327e+04)
[2022-05-31 17:02:33,334][root][INFO] - Step 68200960 @ 6650.8 SPS. Inference batcher size: 158. Learner queue size: 30. Other stats: (step = 68200960, mean_episode_return = 140.72, mean_episode_step = 613.87, total_loss = 56.928, pg_loss = 15.722, baseline_loss = 47.469, entropy_loss = -6.2626, learner_queue_size = 20, _tick = 21186, _time = 1.654e+09, train_seconds = 1.0332e+04)
[2022-05-31 17:02:38,338][root][INFO] - Step 68231680 @ 6138.8 SPS. Inference batcher size: 62. Learner queue size: 15. Other stats: (step = 68231680, mean_episode_return = 443.29, mean_episode_step = 1304.5, total_loss = 54.443, pg_loss = 7.2035, baseline_loss = 53.652, entropy_loss = -6.4119, learner_queue_size = 24, _tick = 21196, _time = 1.654e+09, train_seconds = 1.0337e+04)
[2022-05-31 17:02:43,342][root][INFO] - Step 68267520 @ 7162.6 SPS. Inference batcher size: 127. Learner queue size: 21. Other stats: (step = 68267520, mean_episode_return = 193.72, mean_episode_step = 4851.6, total_loss = 214.89, pg_loss = 109.81, baseline_loss = 111.42, entropy_loss = -6.3407, learner_queue_size = 19, _tick = 21210, _time = 1.654e+09, train_seconds = 1.0342e+04)
[2022-05-31 17:02:48,348][root][INFO] - Step 68298240 @ 6136.3 SPS. Inference batcher size: 111. Learner queue size: 17. Other stats: (step = 68298240, mean_episode_return = 128.43, mean_episode_step = 657.47, total_loss = -60.099, pg_loss = -86.037, baseline_loss = 32.613, entropy_loss = -6.6753, learner_queue_size = 25, _tick = 21219, _time = 1.654e+09, train_seconds = 1.0347e+04)
[2022-05-31 17:02:53,356][root][INFO] - Step 68331520 @ 6645.8 SPS. Inference batcher size: 162. Learner queue size: 14. Other stats: (step = 68331520, mean_episode_return = 138.64, mean_episode_step = 1626.8, total_loss = -118.64, pg_loss = -125.71, baseline_loss = 13.695, entropy_loss = -6.6265, learner_queue_size = 14, _tick = 21227, _time = 1.654e+09, train_seconds = 1.0352e+04)
[2022-05-31 17:02:58,362][root][INFO] - Step 68364800 @ 6647.9 SPS. Inference batcher size: 114. Learner queue size: 10. Other stats: (step = 68364800, mean_episode_return = 123.22, mean_episode_step = 761.97, total_loss = 126.69, pg_loss = 102.24, baseline_loss = 30.908, entropy_loss = -6.4599, learner_queue_size = 22, _tick = 21240, _time = 1.654e+09, train_seconds = 1.0357e+04)
[2022-05-31 17:03:03,368][root][INFO] - Step 68398080 @ 6648.0 SPS. Inference batcher size: 120. Learner queue size: 13. Other stats: (step = 68398080, mean_episode_return = 222.39, mean_episode_step = 922.26, total_loss = 283.23, pg_loss = 106.37, baseline_loss = 183.31, entropy_loss = -6.4508, learner_queue_size = 24, _tick = 21253, _time = 1.654e+09, train_seconds = 1.0362e+04)
[2022-05-31 17:03:08,370][root][INFO] - Step 68431360 @ 6653.4 SPS. Inference batcher size: 110. Learner queue size: 6. Other stats: (step = 68431360, mean_episode_return = 149.49, mean_episode_step = 700.81, total_loss = 194.28, pg_loss = 124.22, baseline_loss = 76.58, entropy_loss = -6.518, learner_queue_size = 23, _tick = 21264, _time = 1.654e+09, train_seconds = 1.0367e+04)
[2022-05-31 17:03:13,374][root][INFO] - Step 68464640 @ 6650.6 SPS. Inference batcher size: 92. Learner queue size: 3. Other stats: (step = 68464640, mean_episode_return = 89.25, mean_episode_step = 748.06, total_loss = 145.16, pg_loss = 87.985, baseline_loss = 64.006, entropy_loss = -6.8267, learner_queue_size = 21, _tick = 21277, _time = 1.654e+09, train_seconds = 1.0372e+04)
[2022-05-31 17:03:18,384][root][INFO] - Step 68497920 @ 6643.1 SPS. Inference batcher size: 42. Learner queue size: 14. Other stats: (step = 68497920, mean_episode_return = 258.92, mean_episode_step = 727.03, total_loss = 488.06, pg_loss = 303.78, baseline_loss = 190.42, entropy_loss = -6.1354, learner_queue_size = 14, _tick = 21289, _time = 1.654e+09, train_seconds = 1.0377e+04)
[2022-05-31 17:03:23,390][root][INFO] - Step 68528640 @ 6136.2 SPS. Inference batcher size: 121. Learner queue size: 32. Other stats: (step = 68528640, mean_episode_return = 143.99, mean_episode_step = 950.9, total_loss = 39.224, pg_loss = 1.8499, baseline_loss = 43.794, entropy_loss = -6.4199, learner_queue_size = 17, _tick = 21299, _time = 1.654e+09, train_seconds = 1.0382e+04)
[2022-05-31 17:03:28,396][root][INFO] - Step 68561920 @ 6648.0 SPS. Inference batcher size: 129. Learner queue size: 22. Other stats: (step = 68561920, mean_episode_return = 222.22, mean_episode_step = 1048.2, total_loss = -32.715, pg_loss = -73.188, baseline_loss = 46.42, entropy_loss = -5.947, learner_queue_size = 16, _tick = 21310, _time = 1.654e+09, train_seconds = 1.0387e+04)
[2022-05-31 17:03:33,402][root][INFO] - Step 68597760 @ 7159.6 SPS. Inference batcher size: 90. Learner queue size: 12. Other stats: (step = 68597760, mean_episode_return = 139.26, mean_episode_step = 561.05, total_loss = -28.412, pg_loss = -73.48, baseline_loss = 51.198, entropy_loss = -6.1292, learner_queue_size = 12, _tick = 21322, _time = 1.654e+09, train_seconds = 1.0392e+04)
[2022-05-31 17:03:38,408][root][INFO] - Step 68628480 @ 6136.6 SPS. Inference batcher size: 117. Learner queue size: 9. Other stats: (step = 68628480, mean_episode_return = 25.74, mean_episode_step = 637.67, total_loss = 322.5, pg_loss = 211.77, baseline_loss = 117.01, entropy_loss = -6.2707, learner_queue_size = 26, _tick = 21332, _time = 1.654e+09, train_seconds = 1.0397e+04)
[2022-05-31 17:03:43,414][root][INFO] - Step 68661760 @ 6648.0 SPS. Inference batcher size: 152. Learner queue size: 7. Other stats: (step = 68661760, mean_episode_return = 182.91, mean_episode_step = 763.68, total_loss = 118.23, pg_loss = 36.893, baseline_loss = 87.302, entropy_loss = -5.9697, learner_queue_size = 17, _tick = 21344, _time = 1.654e+09, train_seconds = 1.0402e+04)
[2022-05-31 17:03:48,418][root][INFO] - Step 68695040 @ 6650.6 SPS. Inference batcher size: 114. Learner queue size: 12. Other stats: (step = 68695040, mean_episode_return = 59.959, mean_episode_step = 4859.4, total_loss = 158.95, pg_loss = 70.456, baseline_loss = 94.665, entropy_loss = -6.1659, learner_queue_size = 27, _tick = 21356, _time = 1.654e+09, train_seconds = 1.0407e+04)
[2022-05-31 17:03:53,423][root][INFO] - Step 68728320 @ 6650.1 SPS. Inference batcher size: 51. Learner queue size: 29. Other stats: (step = 68728320, mean_episode_return = None, mean_episode_step = 721.06, total_loss = 139.48, pg_loss = 27.791, baseline_loss = 117.78, entropy_loss = -6.0926, learner_queue_size = 26, _tick = 21367, _time = 1.654e+09, train_seconds = 1.0412e+04)
[2022-05-31 17:03:58,426][root][INFO] - Step 68761600 @ 6651.2 SPS. Inference batcher size: 106. Learner queue size: 29. Other stats: (step = 68761600, mean_episode_return = 178.43, mean_episode_step = 770.73, total_loss = -52.041, pg_loss = -82.694, baseline_loss = 37.118, entropy_loss = -6.4651, learner_queue_size = 16, _tick = 21378, _time = 1.654e+09, train_seconds = 1.0417e+04)
[2022-05-31 17:04:03,432][root][INFO] - Step 68794880 @ 6647.9 SPS. Inference batcher size: 32. Learner queue size: 18. Other stats: (step = 68794880, mean_episode_return = None, mean_episode_step = 736.94, total_loss = -22.052, pg_loss = -51.996, baseline_loss = 36.531, entropy_loss = -6.5872, learner_queue_size = 18, _tick = 21387, _time = 1.654e+09, train_seconds = 1.0422e+04)
[2022-05-31 17:04:08,438][root][INFO] - Step 68825600 @ 6136.7 SPS. Inference batcher size: 74. Learner queue size: 12. Other stats: (step = 68825600, mean_episode_return = 73.053, mean_episode_step = 791.13, total_loss = 31.049, pg_loss = 12.822, baseline_loss = 24.831, entropy_loss = -6.6038, learner_queue_size = 19, _tick = 21397, _time = 1.654e+09, train_seconds = 1.0427e+04)
[2022-05-31 17:04:13,445][root][INFO] - Step 68858880 @ 6646.8 SPS. Inference batcher size: 78. Learner queue size: 7. Other stats: (step = 68858880, mean_episode_return = None, mean_episode_step = 4968.8, total_loss = -9.9938, pg_loss = -42.517, baseline_loss = 38.669, entropy_loss = -6.1466, learner_queue_size = 16, _tick = 21408, _time = 1.654e+09, train_seconds = 1.0432e+04)
[2022-05-31 17:04:18,450][root][INFO] - Step 68892160 @ 6649.2 SPS. Inference batcher size: 90. Learner queue size: 31. Other stats: (step = 68892160, mean_episode_return = 151.87, mean_episode_step = 953.39, total_loss = 196.07, pg_loss = 160.65, baseline_loss = 41.951, entropy_loss = -6.5257, learner_queue_size = 23, _tick = 21418, _time = 1.654e+09, train_seconds = 1.0437e+04)
[2022-05-31 17:04:23,454][root][INFO] - Step 68925440 @ 6650.7 SPS. Inference batcher size: 85. Learner queue size: 22. Other stats: (step = 68925440, mean_episode_return = 43.107, mean_episode_step = 1057.4, total_loss = 179.74, pg_loss = 131.42, baseline_loss = 54.613, entropy_loss = -6.2933, learner_queue_size = 14, _tick = 21430, _time = 1.654e+09, train_seconds = 1.0442e+04)
[2022-05-31 17:04:28,458][root][INFO] - Step 68956160 @ 6139.2 SPS. Inference batcher size: 169. Learner queue size: 14. Other stats: (step = 68956160, mean_episode_return = None, mean_episode_step = 682.25, total_loss = 537.07, pg_loss = 423.97, baseline_loss = 119.07, entropy_loss = -5.9683, learner_queue_size = 18, _tick = 21441, _time = 1.654e+09, train_seconds = 1.0447e+04)
[2022-05-31 17:04:33,464][root][INFO] - Step 68989440 @ 6648.0 SPS. Inference batcher size: 70. Learner queue size: 2. Other stats: (step = 68989440, mean_episode_return = 230.87, mean_episode_step = 748.8, total_loss = 118.74, pg_loss = 70.196, baseline_loss = 54.407, entropy_loss = -5.8662, learner_queue_size = 19, _tick = 21453, _time = 1.654e+09, train_seconds = 1.0452e+04)
[2022-05-31 17:04:38,466][root][INFO] - Step 69022720 @ 6653.3 SPS. Inference batcher size: 126. Learner queue size: 15. Other stats: (step = 69022720, mean_episode_return = None, mean_episode_step = 879.72, total_loss = -48.999, pg_loss = -106.03, baseline_loss = 63.507, entropy_loss = -6.4774, learner_queue_size = 26, _tick = 21462, _time = 1.654e+09, train_seconds = 1.0457e+04)
[2022-05-31 17:04:43,470][root][INFO] - Step 69056000 @ 6650.7 SPS. Inference batcher size: 90. Learner queue size: 29. Other stats: (step = 69056000, mean_episode_return = 161.64, mean_episode_step = 649.76, total_loss = 442.87, pg_loss = 302.62, baseline_loss = 146.6, entropy_loss = -6.351, learner_queue_size = 17, _tick = 21474, _time = 1.654e+09, train_seconds = 1.0462e+04)
[2022-05-31 17:04:48,475][root][INFO] - Step 69089280 @ 6648.8 SPS. Inference batcher size: 38. Learner queue size: 25. Other stats: (step = 69089280, mean_episode_return = 95.49, mean_episode_step = 789.2, total_loss = 15.52, pg_loss = -41.96, baseline_loss = 63.79, entropy_loss = -6.3097, learner_queue_size = 11, _tick = 21484, _time = 1.654e+09, train_seconds = 1.0467e+04)
[2022-05-31 17:04:53,482][root][INFO] - Step 69122560 @ 6647.6 SPS. Inference batcher size: 62. Learner queue size: 13. Other stats: (step = 69122560, mean_episode_return = 168.18, mean_episode_step = 727.32, total_loss = -39.257, pg_loss = -68.993, baseline_loss = 36.561, entropy_loss = -6.8251, learner_queue_size = 13, _tick = 21497, _time = 1.654e+09, train_seconds = 1.0472e+04)
[2022-05-31 17:04:58,486][root][INFO] - Step 69153280 @ 6138.7 SPS. Inference batcher size: 106. Learner queue size: 14. Other stats: (step = 69153280, mean_episode_return = 135.3, mean_episode_step = 779.85, total_loss = -86.609, pg_loss = -131.2, baseline_loss = 51.196, entropy_loss = -6.6058, learner_queue_size = 8, _tick = 21508, _time = 1.654e+09, train_seconds = 1.0477e+04)
[2022-05-31 17:05:03,492][root][INFO] - Step 69189120 @ 7159.5 SPS. Inference batcher size: 81. Learner queue size: 0. Other stats: (step = 69189120, mean_episode_return = 54.831, mean_episode_step = 874.79, total_loss = 98.333, pg_loss = 47.587, baseline_loss = 57.061, entropy_loss = -6.3152, learner_queue_size = 27, _tick = 21521, _time = 1.654e+09, train_seconds = 1.0482e+04)
[2022-05-31 17:05:08,498][root][INFO] - Step 69219840 @ 6136.5 SPS. Inference batcher size: 150. Learner queue size: 18. Other stats: (step = 69219840, mean_episode_return = 219.93, mean_episode_step = 792.41, total_loss = 266.93, pg_loss = 102.12, baseline_loss = 171.12, entropy_loss = -6.3145, learner_queue_size = 21, _tick = 21530, _time = 1.654e+09, train_seconds = 1.0487e+04)
[2022-05-31 17:05:13,502][root][INFO] - Step 69253120 @ 6650.7 SPS. Inference batcher size: 62. Learner queue size: 2. Other stats: (step = 69253120, mean_episode_return = 134.95, mean_episode_step = 709.11, total_loss = -112.34, pg_loss = -143.26, baseline_loss = 36.938, entropy_loss = -6.0136, learner_queue_size = 18, _tick = 21543, _time = 1.654e+09, train_seconds = 1.0492e+04)
[2022-05-31 17:05:18,506][root][INFO] - Step 69286400 @ 6650.7 SPS. Inference batcher size: 101. Learner queue size: 8. Other stats: (step = 69286400, mean_episode_return = 226.02, mean_episode_step = 1579.3, total_loss = -93.764, pg_loss = -111.94, baseline_loss = 24.884, entropy_loss = -6.7025, learner_queue_size = 23, _tick = 21555, _time = 1.654e+09, train_seconds = 1.0497e+04)
[2022-05-31 17:05:23,510][root][INFO] - Step 69319680 @ 6650.7 SPS. Inference batcher size: 111. Learner queue size: 3. Other stats: (step = 69319680, mean_episode_return = 106.26, mean_episode_step = 657.3, total_loss = 41.985, pg_loss = -41.385, baseline_loss = 89.36, entropy_loss = -5.9898, learner_queue_size = 21, _tick = 21568, _time = 1.654e+09, train_seconds = 1.0502e+04)
[2022-05-31 17:05:28,518][root][INFO] - Step 69352960 @ 6645.4 SPS. Inference batcher size: 96. Learner queue size: 4. Other stats: (step = 69352960, mean_episode_return = 233.59, mean_episode_step = 1021.2, total_loss = 44.453, pg_loss = -31.848, baseline_loss = 82.507, entropy_loss = -6.2061, learner_queue_size = 32, _tick = 21580, _time = 1.654e+09, train_seconds = 1.0507e+04)
[2022-05-31 17:05:33,522][root][INFO] - Step 69386240 @ 6650.7 SPS. Inference batcher size: 115. Learner queue size: 27. Other stats: (step = 69386240, mean_episode_return = 24.38, mean_episode_step = 1692.1, total_loss = 61.631, pg_loss = 9.9249, baseline_loss = 58.066, entropy_loss = -6.3602, learner_queue_size = 14, _tick = 21588, _time = 1.654e+09, train_seconds = 1.0512e+04)
[2022-05-31 17:05:38,526][root][INFO] - Step 69419520 @ 6650.3 SPS. Inference batcher size: 7. Learner queue size: 20. Other stats: (step = 69419520, mean_episode_return = 310.73, mean_episode_step = 931.75, total_loss = -70.739, pg_loss = -103.57, baseline_loss = 38.637, entropy_loss = -5.8033, learner_queue_size = 14, _tick = 21598, _time = 1.654e+09, train_seconds = 1.0517e+04)
[2022-05-31 17:05:43,530][root][INFO] - Step 69452800 @ 6651.0 SPS. Inference batcher size: 63. Learner queue size: 0. Other stats: (step = 69452800, mean_episode_return = 17.73, mean_episode_step = 799.78, total_loss = 115.36, pg_loss = 72.4, baseline_loss = 49.156, entropy_loss = -6.1969, learner_queue_size = 18, _tick = 21610, _time = 1.654e+09, train_seconds = 1.0522e+04)
[2022-05-31 17:05:48,536][root][INFO] - Step 69483520 @ 6136.7 SPS. Inference batcher size: 98. Learner queue size: 15. Other stats: (step = 69483520, mean_episode_return = 227.77, mean_episode_step = 655.28, total_loss = 706.95, pg_loss = 476.55, baseline_loss = 236.46, entropy_loss = -6.0612, learner_queue_size = 30, _tick = 21622, _time = 1.654e+09, train_seconds = 1.0527e+04)
[2022-05-31 17:05:53,538][root][INFO] - Step 69516800 @ 6653.3 SPS. Inference batcher size: 86. Learner queue size: 13. Other stats: (step = 69516800, mean_episode_return = 288.27, mean_episode_step = 648.27, total_loss = 68.758, pg_loss = 18.326, baseline_loss = 56.088, entropy_loss = -5.6562, learner_queue_size = 23, _tick = 21635, _time = 1.654e+09, train_seconds = 1.0532e+04)
[2022-05-31 17:05:58,542][root][INFO] - Step 69550080 @ 6650.8 SPS. Inference batcher size: 27. Learner queue size: 3. Other stats: (step = 69550080, mean_episode_return = 165.54, mean_episode_step = 845.19, total_loss = 66.964, pg_loss = -51.026, baseline_loss = 123.75, entropy_loss = -5.765, learner_queue_size = 21, _tick = 21647, _time = 1.654e+09, train_seconds = 1.0537e+04)
[2022-05-31 17:06:03,548][root][INFO] - Step 69583360 @ 6647.6 SPS. Inference batcher size: 107. Learner queue size: 23. Other stats: (step = 69583360, mean_episode_return = 433.8, mean_episode_step = 840.46, total_loss = 151.11, pg_loss = -3.7307, baseline_loss = 160.74, entropy_loss = -5.8952, learner_queue_size = 17, _tick = 21660, _time = 1.654e+09, train_seconds = 1.0542e+04)
[2022-05-31 17:06:08,555][root][INFO] - Step 69616640 @ 6647.1 SPS. Inference batcher size: 17. Learner queue size: 16. Other stats: (step = 69616640, mean_episode_return = 98.853, mean_episode_step = 873.77, total_loss = 548.24, pg_loss = 373.83, baseline_loss = 180.45, entropy_loss = -6.0463, learner_queue_size = 16, _tick = 21672, _time = 1.654e+09, train_seconds = 1.0547e+04)
[2022-05-31 17:06:13,561][root][INFO] - Step 69647360 @ 6136.1 SPS. Inference batcher size: 65. Learner queue size: 14. Other stats: (step = 69647360, mean_episode_return = 99.745, mean_episode_step = 703.59, total_loss = 144.25, pg_loss = 63.98, baseline_loss = 86.29, entropy_loss = -6.0214, learner_queue_size = 29, _tick = 21682, _time = 1.654e+09, train_seconds = 1.0552e+04)
[2022-05-31 17:06:18,567][root][INFO] - Step 69680640 @ 6648.0 SPS. Inference batcher size: 193. Learner queue size: 15. Other stats: (step = 69680640, mean_episode_return = 146.34, mean_episode_step = 590.33, total_loss = -147.94, pg_loss = -184.63, baseline_loss = 42.832, entropy_loss = -6.142, learner_queue_size = 24, _tick = 21693, _time = 1.654e+09, train_seconds = 1.0557e+04)
[2022-05-31 17:06:23,573][root][INFO] - Step 69713920 @ 6648.0 SPS. Inference batcher size: 107. Learner queue size: 14. Other stats: (step = 69713920, mean_episode_return = None, mean_episode_step = 617.88, total_loss = 69.634, pg_loss = 29.087, baseline_loss = 47.204, entropy_loss = -6.6567, learner_queue_size = 13, _tick = 21703, _time = 1.654e+09, train_seconds = 1.0562e+04)
[2022-05-31 17:06:28,578][root][INFO] - Step 69747200 @ 6649.9 SPS. Inference batcher size: 90. Learner queue size: 10. Other stats: (step = 69747200, mean_episode_return = 137.67, mean_episode_step = 717.06, total_loss = -163.64, pg_loss = -202.92, baseline_loss = 45.691, entropy_loss = -6.4151, learner_queue_size = 11, _tick = 21713, _time = 1.654e+09, train_seconds = 1.0567e+04)
[2022-05-31 17:06:33,583][root][INFO] - Step 69780480 @ 6648.8 SPS. Inference batcher size: 60. Learner queue size: 17. Other stats: (step = 69780480, mean_episode_return = 92.627, mean_episode_step = 755.72, total_loss = -47.245, pg_loss = -70.176, baseline_loss = 29.622, entropy_loss = -6.6909, learner_queue_size = 21, _tick = 21723, _time = 1.654e+09, train_seconds = 1.0572e+04)
[2022-05-31 17:06:38,590][root][INFO] - Step 69813760 @ 6647.9 SPS. Inference batcher size: 73. Learner queue size: 7. Other stats: (step = 69813760, mean_episode_return = 202.17, mean_episode_step = 1075.1, total_loss = 245.91, pg_loss = 220.71, baseline_loss = 31.711, entropy_loss = -6.5153, learner_queue_size = 12, _tick = 21734, _time = 1.654e+09, train_seconds = 1.0577e+04)
[2022-05-31 17:06:43,594][root][INFO] - Step 69847040 @ 6650.1 SPS. Inference batcher size: 150. Learner queue size: 9. Other stats: (step = 69847040, mean_episode_return = 75.795, mean_episode_step = 827.03, total_loss = -40.437, pg_loss = -46.119, baseline_loss = 12.005, entropy_loss = -6.3232, learner_queue_size = 15, _tick = 21746, _time = 1.654e+09, train_seconds = 1.0582e+04)
[2022-05-31 17:06:48,598][root][INFO] - Step 69880320 @ 6650.6 SPS. Inference batcher size: 120. Learner queue size: 8. Other stats: (step = 69880320, mean_episode_return = 139.79, mean_episode_step = 961.17, total_loss = 116.31, pg_loss = 36.893, baseline_loss = 85.426, entropy_loss = -6.0114, learner_queue_size = 20, _tick = 21759, _time = 1.654e+09, train_seconds = 1.0587e+04)
[2022-05-31 17:06:53,604][root][INFO] - Step 69911040 @ 6136.6 SPS. Inference batcher size: 159. Learner queue size: 29. Other stats: (step = 69911040, mean_episode_return = 81.525, mean_episode_step = 743.57, total_loss = -114.04, pg_loss = -144.99, baseline_loss = 37.445, entropy_loss = -6.4947, learner_queue_size = 18, _tick = 21770, _time = 1.654e+09, train_seconds = 1.0592e+04)
[2022-05-31 17:06:58,610][root][INFO] - Step 69946880 @ 7159.5 SPS. Inference batcher size: 120. Learner queue size: 24. Other stats: (step = 69946880, mean_episode_return = 184.35, mean_episode_step = 727.39, total_loss = -127.76, pg_loss = -148.17, baseline_loss = 26.901, entropy_loss = -6.4852, learner_queue_size = 21, _tick = 21782, _time = 1.654e+09, train_seconds = 1.0597e+04)
[2022-05-31 17:07:03,616][root][INFO] - Step 69977600 @ 6136.6 SPS. Inference batcher size: 125. Learner queue size: 16. Other stats: (step = 69977600, mean_episode_return = 183.69, mean_episode_step = 745.1, total_loss = 101.65, pg_loss = -18.633, baseline_loss = 126.48, entropy_loss = -6.2064, learner_queue_size = 21, _tick = 21793, _time = 1.654e+09, train_seconds = 1.0602e+04)
[2022-05-31 17:07:08,622][root][INFO] - Step 70010880 @ 6648.2 SPS. Inference batcher size: 83. Learner queue size: 7. Other stats: (step = 70010880, mean_episode_return = 72.729, mean_episode_step = 730.58, total_loss = 283.47, pg_loss = 206.77, baseline_loss = 83.101, entropy_loss = -6.407, learner_queue_size = 18, _tick = 21806, _time = 1.654e+09, train_seconds = 1.0607e+04)
[2022-05-31 17:07:13,629][root][INFO] - Step 70044160 @ 6647.0 SPS. Inference batcher size: 129. Learner queue size: 5. Other stats: (step = 70044160, mean_episode_return = 477.6, mean_episode_step = 959.45, total_loss = -20.271, pg_loss = -54.864, baseline_loss = 40.978, entropy_loss = -6.3855, learner_queue_size = 17, _tick = 21818, _time = 1.654e+09, train_seconds = 1.0612e+04)
[2022-05-31 17:07:18,634][root][INFO] - Step 70077440 @ 6649.0 SPS. Inference batcher size: 114. Learner queue size: 3. Other stats: (step = 70077440, mean_episode_return = 316.47, mean_episode_step = 1725.5, total_loss = 173.51, pg_loss = 112.4, baseline_loss = 67.677, entropy_loss = -6.5708, learner_queue_size = 25, _tick = 21831, _time = 1.654e+09, train_seconds = 1.0617e+04)
[2022-05-31 17:07:23,640][root][INFO] - Step 70110720 @ 6648.3 SPS. Inference batcher size: 72. Learner queue size: 2. Other stats: (step = 70110720, mean_episode_return = 114.21, mean_episode_step = 551.32, total_loss = -81.098, pg_loss = -261.68, baseline_loss = 186.64, entropy_loss = -6.0582, learner_queue_size = 14, _tick = 21842, _time = 1.654e+09, train_seconds = 1.0622e+04)
[2022-05-31 17:07:28,642][root][INFO] - Step 70144000 @ 6653.0 SPS. Inference batcher size: 81. Learner queue size: 31. Other stats: (step = 70144000, mean_episode_return = 291.79, mean_episode_step = 822.19, total_loss = -120.75, pg_loss = -305.35, baseline_loss = 190.78, entropy_loss = -6.1821, learner_queue_size = 21, _tick = 21854, _time = 1.654e+09, train_seconds = 1.0627e+04)
[2022-05-31 17:07:33,646][root][INFO] - Step 70177280 @ 6650.7 SPS. Inference batcher size: 99. Learner queue size: 3. Other stats: (step = 70177280, mean_episode_return = 145.86, mean_episode_step = 6321.9, total_loss = -42.148, pg_loss = -109.04, baseline_loss = 73.529, entropy_loss = -6.6393, learner_queue_size = 17, _tick = 21865, _time = 1.654e+09, train_seconds = 1.0632e+04)
[2022-05-31 17:07:38,650][root][INFO] - Step 70210560 @ 6650.6 SPS. Inference batcher size: 205. Learner queue size: 3. Other stats: (step = 70210560, mean_episode_return = 104.95, mean_episode_step = 646.8, total_loss = 125.6, pg_loss = 32.683, baseline_loss = 99.066, entropy_loss = -6.1457, learner_queue_size = 26, _tick = 21877, _time = 1.654e+09, train_seconds = 1.0637e+04)
[2022-05-31 17:07:43,654][root][INFO] - Step 70243840 @ 6650.8 SPS. Inference batcher size: 155. Learner queue size: 27. Other stats: (step = 70243840, mean_episode_return = 167.42, mean_episode_step = 886.34, total_loss = 341.51, pg_loss = 226.85, baseline_loss = 121.11, entropy_loss = -6.4451, learner_queue_size = 16, _tick = 21890, _time = 1.654e+09, train_seconds = 1.0642e+04)
[2022-05-31 17:07:48,658][root][INFO] - Step 70274560 @ 6139.0 SPS. Inference batcher size: 153. Learner queue size: 18. Other stats: (step = 70274560, mean_episode_return = 190.07, mean_episode_step = 634.3, total_loss = -155.95, pg_loss = -209.49, baseline_loss = 59.64, entropy_loss = -6.1033, learner_queue_size = 17, _tick = 21902, _time = 1.654e+09, train_seconds = 1.0647e+04)
[2022-05-31 17:07:53,662][root][INFO] - Step 70307840 @ 6650.8 SPS. Inference batcher size: 92. Learner queue size: 11. Other stats: (step = 70307840, mean_episode_return = None, mean_episode_step = 743.44, total_loss = -27.5, pg_loss = -66.442, baseline_loss = 45.766, entropy_loss = -6.8243, learner_queue_size = 24, _tick = 21913, _time = 1.654e+09, train_seconds = 1.0652e+04)
[2022-05-31 17:07:58,670][root][INFO] - Step 70341120 @ 6646.0 SPS. Inference batcher size: 10. Learner queue size: 2. Other stats: (step = 70341120, mean_episode_return = 180.1, mean_episode_step = 1651.6, total_loss = 260.89, pg_loss = 172.16, baseline_loss = 94.902, entropy_loss = -6.1769, learner_queue_size = 18, _tick = 21924, _time = 1.654e+09, train_seconds = 1.0657e+04)
[2022-05-31 17:08:03,674][root][INFO] - Step 70374400 @ 6650.0 SPS. Inference batcher size: 117. Learner queue size: 18. Other stats: (step = 70374400, mean_episode_return = 71.519, mean_episode_step = 560.97, total_loss = -123.84, pg_loss = -140.11, baseline_loss = 22.482, entropy_loss = -6.2098, learner_queue_size = 26, _tick = 21934, _time = 1.654e+09, train_seconds = 1.0662e+04)
[2022-05-31 17:08:08,680][root][INFO] - Step 70407680 @ 6648.4 SPS. Inference batcher size: 104. Learner queue size: 3. Other stats: (step = 70407680, mean_episode_return = 85.046, mean_episode_step = 1214.0, total_loss = -16.537, pg_loss = -50.064, baseline_loss = 39.944, entropy_loss = -6.4173, learner_queue_size = 17, _tick = 21947, _time = 1.654e+09, train_seconds = 1.0667e+04)
[2022-05-31 17:08:13,682][root][INFO] - Step 70440960 @ 6653.0 SPS. Inference batcher size: 56. Learner queue size: 8. Other stats: (step = 70440960, mean_episode_return = 72.276, mean_episode_step = 747.11, total_loss = 123.97, pg_loss = 55.763, baseline_loss = 74.073, entropy_loss = -5.8624, learner_queue_size = 25, _tick = 21958, _time = 1.654e+09, train_seconds = 1.0672e+04)
[2022-05-31 17:08:18,689][root][INFO] - Step 70474240 @ 6647.3 SPS. Inference batcher size: 48. Learner queue size: 8. Other stats: (step = 70474240, mean_episode_return = 236.01, mean_episode_step = 778.07, total_loss = -50.302, pg_loss = -82.536, baseline_loss = 38.18, entropy_loss = -5.9457, learner_queue_size = 32, _tick = 21966, _time = 1.654e+09, train_seconds = 1.0677e+04)
[2022-05-31 17:08:23,694][root][INFO] - Step 70507520 @ 6648.8 SPS. Inference batcher size: 143. Learner queue size: 26. Other stats: (step = 70507520, mean_episode_return = 113.72, mean_episode_step = 636.68, total_loss = 215.4, pg_loss = 23.715, baseline_loss = 197.61, entropy_loss = -5.9281, learner_queue_size = 19, _tick = 21978, _time = 1.654e+09, train_seconds = 1.0682e+04)
[2022-05-31 17:08:28,700][root][INFO] - Step 70538240 @ 6136.6 SPS. Inference batcher size: 175. Learner queue size: 21. Other stats: (step = 70538240, mean_episode_return = 163.17, mean_episode_step = 668.49, total_loss = -113.04, pg_loss = -173.06, baseline_loss = 65.873, entropy_loss = -5.8494, learner_queue_size = 30, _tick = 21990, _time = 1.654e+09, train_seconds = 1.0687e+04)
[2022-05-31 17:08:33,702][root][INFO] - Step 70571520 @ 6653.3 SPS. Inference batcher size: 151. Learner queue size: 12. Other stats: (step = 70571520, mean_episode_return = 143.1, mean_episode_step = 550.22, total_loss = 0.33647, pg_loss = -82.899, baseline_loss = 89.399, entropy_loss = -6.1639, learner_queue_size = 17, _tick = 22002, _time = 1.654e+09, train_seconds = 1.0692e+04)
[2022-05-31 17:08:38,708][root][INFO] - Step 70604800 @ 6648.0 SPS. Inference batcher size: 137. Learner queue size: 12. Other stats: (step = 70604800, mean_episode_return = 86.976, mean_episode_step = 6001.4, total_loss = 356.04, pg_loss = 122.36, baseline_loss = 239.77, entropy_loss = -6.0923, learner_queue_size = 23, _tick = 22015, _time = 1.654e+09, train_seconds = 1.0697e+04)
[2022-05-31 17:08:43,714][root][INFO] - Step 70638080 @ 6648.0 SPS. Inference batcher size: 25. Learner queue size: 18. Other stats: (step = 70638080, mean_episode_return = 135.53, mean_episode_step = 759.15, total_loss = 93.521, pg_loss = 28.693, baseline_loss = 70.952, entropy_loss = -6.1238, learner_queue_size = 25, _tick = 22027, _time = 1.654e+09, train_seconds = 1.0702e+04)
[2022-05-31 17:08:48,718][root][INFO] - Step 70671360 @ 6650.7 SPS. Inference batcher size: 168. Learner queue size: 3. Other stats: (step = 70671360, mean_episode_return = 155.44, mean_episode_step = 483.57, total_loss = 90.039, pg_loss = -19.896, baseline_loss = 116.05, entropy_loss = -6.1174, learner_queue_size = 19, _tick = 22039, _time = 1.654e+09, train_seconds = 1.0707e+04)
[2022-05-31 17:08:53,722][root][INFO] - Step 70704640 @ 6650.7 SPS. Inference batcher size: 171. Learner queue size: 10. Other stats: (step = 70704640, mean_episode_return = 72.341, mean_episode_step = 1719.7, total_loss = -239.63, pg_loss = -337.75, baseline_loss = 104.68, entropy_loss = -6.5625, learner_queue_size = 18, _tick = 22050, _time = 1.654e+09, train_seconds = 1.0712e+04)
[2022-05-31 17:08:58,726][root][INFO] - Step 70737920 @ 6650.7 SPS. Inference batcher size: 90. Learner queue size: 26. Other stats: (step = 70737920, mean_episode_return = None, mean_episode_step = 698.03, total_loss = 120.18, pg_loss = 33.854, baseline_loss = 92.719, entropy_loss = -6.3971, learner_queue_size = 20, _tick = 22061, _time = 1.654e+09, train_seconds = 1.0717e+04)
[2022-05-31 17:09:03,730][root][INFO] - Step 70771200 @ 6650.6 SPS. Inference batcher size: 93. Learner queue size: 25. Other stats: (step = 70771200, mean_episode_return = 213.5, mean_episode_step = 671.33, total_loss = 6.4499, pg_loss = -45.358, baseline_loss = 58.17, entropy_loss = -6.3616, learner_queue_size = 11, _tick = 22072, _time = 1.654e+09, train_seconds = 1.0722e+04)
[2022-05-31 17:09:08,734][root][INFO] - Step 70804480 @ 6650.8 SPS. Inference batcher size: 153. Learner queue size: 1. Other stats: (step = 70804480, mean_episode_return = 273.12, mean_episode_step = 1853.9, total_loss = 8.8363, pg_loss = -18.22, baseline_loss = 33.216, entropy_loss = -6.1602, learner_queue_size = 24, _tick = 22085, _time = 1.654e+09, train_seconds = 1.0727e+04)
[2022-05-31 17:09:13,738][root][INFO] - Step 70837760 @ 6650.6 SPS. Inference batcher size: 81. Learner queue size: 22. Other stats: (step = 70837760, mean_episode_return = 53.124, mean_episode_step = 618.5, total_loss = 109.35, pg_loss = -3.0983, baseline_loss = 118.87, entropy_loss = -6.4243, learner_queue_size = 19, _tick = 22095, _time = 1.654e+09, train_seconds = 1.0732e+04)
[2022-05-31 17:09:18,742][root][INFO] - Step 70871040 @ 6650.7 SPS. Inference batcher size: 76. Learner queue size: 23. Other stats: (step = 70871040, mean_episode_return = 115.96, mean_episode_step = 5349.0, total_loss = 89.663, pg_loss = 63.045, baseline_loss = 33.12, entropy_loss = -6.5025, learner_queue_size = 19, _tick = 22108, _time = 1.654e+09, train_seconds = 1.0737e+04)
[2022-05-31 17:09:23,746][root][INFO] - Step 70901760 @ 6139.0 SPS. Inference batcher size: 94. Learner queue size: 16. Other stats: (step = 70901760, mean_episode_return = 189.25, mean_episode_step = 776.14, total_loss = -100.83, pg_loss = -140.12, baseline_loss = 45.422, entropy_loss = -6.1333, learner_queue_size = 11, _tick = 22119, _time = 1.654e+09, train_seconds = 1.0742e+04)
[2022-05-31 17:09:28,750][root][INFO] - Step 70935040 @ 6650.7 SPS. Inference batcher size: 126. Learner queue size: 19. Other stats: (step = 70935040, mean_episode_return = 299.23, mean_episode_step = 750.02, total_loss = 19.958, pg_loss = -167.68, baseline_loss = 193.78, entropy_loss = -6.144, learner_queue_size = 17, _tick = 22131, _time = 1.654e+09, train_seconds = 1.0747e+04)
[2022-05-31 17:09:33,754][root][INFO] - Step 70968320 @ 6650.8 SPS. Inference batcher size: 56. Learner queue size: 13. Other stats: (step = 70968320, mean_episode_return = 221.38, mean_episode_step = 1861.4, total_loss = -116.26, pg_loss = -238.94, baseline_loss = 129.25, entropy_loss = -6.5615, learner_queue_size = 27, _tick = 22140, _time = 1.654e+09, train_seconds = 1.0752e+04)
[2022-05-31 17:09:38,758][root][INFO] - Step 71001600 @ 6650.5 SPS. Inference batcher size: 127. Learner queue size: 31. Other stats: (step = 71001600, mean_episode_return = 366.81, mean_episode_step = 681.91, total_loss = 317.21, pg_loss = 177.84, baseline_loss = 145.51, entropy_loss = -6.1484, learner_queue_size = 15, _tick = 22152, _time = 1.654e+09, train_seconds = 1.0757e+04)
[2022-05-31 17:09:43,762][root][INFO] - Step 71034880 @ 6650.8 SPS. Inference batcher size: 113. Learner queue size: 2. Other stats: (step = 71034880, mean_episode_return = 329.57, mean_episode_step = 777.38, total_loss = 70.778, pg_loss = 4.9524, baseline_loss = 72.186, entropy_loss = -6.3603, learner_queue_size = 21, _tick = 22164, _time = 1.654e+09, train_seconds = 1.0762e+04)
[2022-05-31 17:09:48,766][root][INFO] - Step 71065600 @ 6139.2 SPS. Inference batcher size: 99. Learner queue size: 17. Other stats: (step = 71065600, mean_episode_return = 93.784, mean_episode_step = 941.49, total_loss = 123.45, pg_loss = 45.754, baseline_loss = 84.362, entropy_loss = -6.6707, learner_queue_size = 13, _tick = 22174, _time = 1.654e+09, train_seconds = 1.0768e+04)
[2022-05-31 17:09:53,772][root][INFO] - Step 71098880 @ 6647.9 SPS. Inference batcher size: 99. Learner queue size: 21. Other stats: (step = 71098880, mean_episode_return = 210.88, mean_episode_step = 488.26, total_loss = 150.47, pg_loss = 88.702, baseline_loss = 68.216, entropy_loss = -6.4513, learner_queue_size = 19, _tick = 22186, _time = 1.654e+09, train_seconds = 1.0772e+04)
[2022-05-31 17:09:58,778][root][INFO] - Step 71132160 @ 6648.0 SPS. Inference batcher size: 96. Learner queue size: 18. Other stats: (step = 71132160, mean_episode_return = 313.35, mean_episode_step = 610.4, total_loss = -34.464, pg_loss = -80.054, baseline_loss = 51.967, entropy_loss = -6.3774, learner_queue_size = 28, _tick = 22198, _time = 1.654e+09, train_seconds = 1.0778e+04)
[2022-05-31 17:10:03,782][root][INFO] - Step 71165440 @ 6650.9 SPS. Inference batcher size: 89. Learner queue size: 4. Other stats: (step = 71165440, mean_episode_return = 208.35, mean_episode_step = 857.64, total_loss = -53.494, pg_loss = -85.287, baseline_loss = 38.442, entropy_loss = -6.6488, learner_queue_size = 13, _tick = 22210, _time = 1.654e+09, train_seconds = 1.0782e+04)
[2022-05-31 17:10:08,786][root][INFO] - Step 71198720 @ 6650.7 SPS. Inference batcher size: 188. Learner queue size: 21. Other stats: (step = 71198720, mean_episode_return = 91.725, mean_episode_step = 770.84, total_loss = -57.007, pg_loss = -107.84, baseline_loss = 57.257, entropy_loss = -6.4236, learner_queue_size = 19, _tick = 22222, _time = 1.654e+09, train_seconds = 1.0788e+04)
[2022-05-31 17:10:13,792][root][INFO] - Step 71229440 @ 6136.0 SPS. Inference batcher size: 101. Learner queue size: 15. Other stats: (step = 71229440, mean_episode_return = 82.64, mean_episode_step = 788.88, total_loss = -109.37, pg_loss = -130.91, baseline_loss = 28.391, entropy_loss = -6.8542, learner_queue_size = 19, _tick = 22233, _time = 1.654e+09, train_seconds = 1.0792e+04)
[2022-05-31 17:10:18,798][root][INFO] - Step 71262720 @ 6648.5 SPS. Inference batcher size: 129. Learner queue size: 18. Other stats: (step = 71262720, mean_episode_return = None, mean_episode_step = 1034.1, total_loss = 226.78, pg_loss = 173.47, baseline_loss = 60.069, entropy_loss = -6.7607, learner_queue_size = 17, _tick = 22243, _time = 1.654e+09, train_seconds = 1.0798e+04)
[2022-05-31 17:10:23,802][root][INFO] - Step 71296000 @ 6650.7 SPS. Inference batcher size: 117. Learner queue size: 17. Other stats: (step = 71296000, mean_episode_return = 108.68, mean_episode_step = 5308.6, total_loss = 289.3, pg_loss = 224.85, baseline_loss = 71.257, entropy_loss = -6.8074, learner_queue_size = 32, _tick = 22254, _time = 1.654e+09, train_seconds = 1.0802e+04)
[2022-05-31 17:10:28,806][root][INFO] - Step 71329280 @ 6650.7 SPS. Inference batcher size: 75. Learner queue size: 10. Other stats: (step = 71329280, mean_episode_return = 111.17, mean_episode_step = 690.36, total_loss = -48.297, pg_loss = -72.744, baseline_loss = 31.006, entropy_loss = -6.5589, learner_queue_size = 23, _tick = 22264, _time = 1.654e+09, train_seconds = 1.0808e+04)
[2022-05-31 17:10:33,812][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 17:10:33,892][root][INFO] - Step 71362560 @ 6648.0 SPS. Inference batcher size: 1. Learner queue size: 2. Other stats: (step = 71362560, mean_episode_return = 78.751, mean_episode_step = 993.3, total_loss = 45.237, pg_loss = 18.161, baseline_loss = 33.192, entropy_loss = -6.1153, learner_queue_size = 10, _tick = 22275, _time = 1.654e+09, train_seconds = 1.0812e+04)
[2022-05-31 17:10:38,894][root][INFO] - Step 71395840 @ 6548.8 SPS. Inference batcher size: 138. Learner queue size: 1. Other stats: (step = 71395840, mean_episode_return = 52.169, mean_episode_step = 2323.9, total_loss = 86.23, pg_loss = 42.85, baseline_loss = 50.216, entropy_loss = -6.8357, learner_queue_size = 28, _tick = 22285, _time = 1.654e+09, train_seconds = 1.0818e+04)
[2022-05-31 17:10:43,898][root][INFO] - Step 71429120 @ 6650.6 SPS. Inference batcher size: 79. Learner queue size: 28. Other stats: (step = 71429120, mean_episode_return = 108.84, mean_episode_step = 784.68, total_loss = 391.02, pg_loss = 312.37, baseline_loss = 84.78, entropy_loss = -6.1224, learner_queue_size = 21, _tick = 22298, _time = 1.654e+09, train_seconds = 1.0823e+04)
[2022-05-31 17:10:48,902][root][INFO] - Step 71462400 @ 6650.9 SPS. Inference batcher size: 1. Learner queue size: 30. Other stats: (step = 71462400, mean_episode_return = None, mean_episode_step = 844.66, total_loss = 25.602, pg_loss = -80.955, baseline_loss = 111.88, entropy_loss = -5.3267, learner_queue_size = 22, _tick = 22308, _time = 1.654e+09, train_seconds = 1.0828e+04)
[2022-05-31 17:10:53,906][root][INFO] - Step 71495680 @ 6650.5 SPS. Inference batcher size: 137. Learner queue size: 21. Other stats: (step = 71495680, mean_episode_return = 77.058, mean_episode_step = 1228.8, total_loss = -256.95, pg_loss = -277.0, baseline_loss = 26.295, entropy_loss = -6.2417, learner_queue_size = 20, _tick = 22318, _time = 1.654e+09, train_seconds = 1.0833e+04)
[2022-05-31 17:10:58,910][root][INFO] - Step 71526400 @ 6139.2 SPS. Inference batcher size: 125. Learner queue size: 11. Other stats: (step = 71526400, mean_episode_return = 177.53, mean_episode_step = 777.05, total_loss = -122.9, pg_loss = -133.4, baseline_loss = 16.837, entropy_loss = -6.3364, learner_queue_size = 21, _tick = 22328, _time = 1.654e+09, train_seconds = 1.0838e+04)
[2022-05-31 17:11:03,914][root][INFO] - Step 71559680 @ 6650.7 SPS. Inference batcher size: 126. Learner queue size: 23. Other stats: (step = 71559680, mean_episode_return = None, mean_episode_step = 2055.0, total_loss = -74.143, pg_loss = -88.794, baseline_loss = 21.122, entropy_loss = -6.4708, learner_queue_size = 6, _tick = 22339, _time = 1.654e+09, train_seconds = 1.0843e+04)
[2022-05-31 17:11:08,920][root][INFO] - Step 71592960 @ 6648.0 SPS. Inference batcher size: 122. Learner queue size: 13. Other stats: (step = 71592960, mean_episode_return = 65.6, mean_episode_step = 953.97, total_loss = 311.93, pg_loss = 211.09, baseline_loss = 107.38, entropy_loss = -6.5395, learner_queue_size = 23, _tick = 22351, _time = 1.654e+09, train_seconds = 1.0848e+04)
[2022-05-31 17:11:13,926][root][INFO] - Step 71626240 @ 6648.0 SPS. Inference batcher size: 62. Learner queue size: 15. Other stats: (step = 71626240, mean_episode_return = 84.289, mean_episode_step = 794.15, total_loss = 147.37, pg_loss = 107.05, baseline_loss = 47.014, entropy_loss = -6.7002, learner_queue_size = 25, _tick = 22360, _time = 1.654e+09, train_seconds = 1.0853e+04)
[2022-05-31 17:11:18,932][root][INFO] - Step 71659520 @ 6648.0 SPS. Inference batcher size: 70. Learner queue size: 16. Other stats: (step = 71659520, mean_episode_return = None, mean_episode_step = 2188.0, total_loss = 14.708, pg_loss = -21.786, baseline_loss = 43.008, entropy_loss = -6.5141, learner_queue_size = 19, _tick = 22370, _time = 1.654e+09, train_seconds = 1.0858e+04)
[2022-05-31 17:11:23,938][root][INFO] - Step 71692800 @ 6648.1 SPS. Inference batcher size: 122. Learner queue size: 20. Other stats: (step = 71692800, mean_episode_return = 116.92, mean_episode_step = 757.4, total_loss = 141.0, pg_loss = -25.453, baseline_loss = 172.97, entropy_loss = -6.5183, learner_queue_size = 17, _tick = 22381, _time = 1.654e+09, train_seconds = 1.0863e+04)
[2022-05-31 17:11:28,942][root][INFO] - Step 71726080 @ 6650.8 SPS. Inference batcher size: 118. Learner queue size: 7. Other stats: (step = 71726080, mean_episode_return = None, mean_episode_step = 5409.1, total_loss = 211.03, pg_loss = 84.808, baseline_loss = 133.17, entropy_loss = -6.9475, learner_queue_size = 22, _tick = 22391, _time = 1.654e+09, train_seconds = 1.0868e+04)
[2022-05-31 17:11:33,948][root][INFO] - Step 71759360 @ 6647.9 SPS. Inference batcher size: 148. Learner queue size: 5. Other stats: (step = 71759360, mean_episode_return = 153.45, mean_episode_step = 1071.6, total_loss = 273.68, pg_loss = 113.96, baseline_loss = 166.18, entropy_loss = -6.4558, learner_queue_size = 15, _tick = 22404, _time = 1.654e+09, train_seconds = 1.0873e+04)
[2022-05-31 17:11:38,954][root][INFO] - Step 71792640 @ 6648.0 SPS. Inference batcher size: 109. Learner queue size: 4. Other stats: (step = 71792640, mean_episode_return = None, mean_episode_step = 878.66, total_loss = 119.59, pg_loss = 73.021, baseline_loss = 52.662, entropy_loss = -6.093, learner_queue_size = 20, _tick = 22415, _time = 1.654e+09, train_seconds = 1.0878e+04)
[2022-05-31 17:11:43,958][root][INFO] - Step 71825920 @ 6650.6 SPS. Inference batcher size: 47. Learner queue size: 3. Other stats: (step = 71825920, mean_episode_return = 347.18, mean_episode_step = 915.18, total_loss = -33.001, pg_loss = -84.242, baseline_loss = 57.688, entropy_loss = -6.4469, learner_queue_size = 12, _tick = 22426, _time = 1.654e+09, train_seconds = 1.0883e+04)
[2022-05-31 17:11:48,964][root][INFO] - Step 71859200 @ 6647.6 SPS. Inference batcher size: 70. Learner queue size: 7. Other stats: (step = 71859200, mean_episode_return = 328.65, mean_episode_step = 900.29, total_loss = 138.06, pg_loss = 88.297, baseline_loss = 56.076, entropy_loss = -6.3162, learner_queue_size = 21, _tick = 22438, _time = 1.654e+09, train_seconds = 1.0888e+04)
[2022-05-31 17:11:53,970][root][INFO] - Step 71892480 @ 6648.6 SPS. Inference batcher size: 17. Learner queue size: 21. Other stats: (step = 71892480, mean_episode_return = 209.52, mean_episode_step = 726.09, total_loss = 427.95, pg_loss = 249.38, baseline_loss = 184.58, entropy_loss = -6.0028, learner_queue_size = 19, _tick = 22450, _time = 1.654e+09, train_seconds = 1.0893e+04)
[2022-05-31 17:11:58,974][root][INFO] - Step 71923200 @ 6139.0 SPS. Inference batcher size: 154. Learner queue size: 27. Other stats: (step = 71923200, mean_episode_return = None, mean_episode_step = 1056.4, total_loss = 104.62, pg_loss = 58.409, baseline_loss = 52.753, entropy_loss = -6.537, learner_queue_size = 21, _tick = 22460, _time = 1.654e+09, train_seconds = 1.0898e+04)
[2022-05-31 17:12:03,980][root][INFO] - Step 71956480 @ 6648.0 SPS. Inference batcher size: 132. Learner queue size: 21. Other stats: (step = 71956480, mean_episode_return = 143.51, mean_episode_step = 523.02, total_loss = 199.43, pg_loss = 111.12, baseline_loss = 94.517, entropy_loss = -6.1986, learner_queue_size = 26, _tick = 22472, _time = 1.654e+09, train_seconds = 1.0903e+04)
[2022-05-31 17:12:08,986][root][INFO] - Step 71989760 @ 6648.1 SPS. Inference batcher size: 122. Learner queue size: 13. Other stats: (step = 71989760, mean_episode_return = 82.244, mean_episode_step = 5515.6, total_loss = 158.69, pg_loss = 78.623, baseline_loss = 86.374, entropy_loss = -6.3061, learner_queue_size = 22, _tick = 22484, _time = 1.654e+09, train_seconds = 1.0908e+04)
[2022-05-31 17:12:13,990][root][INFO] - Step 72023040 @ 6650.8 SPS. Inference batcher size: 114. Learner queue size: 7. Other stats: (step = 72023040, mean_episode_return = 148.46, mean_episode_step = 1898.7, total_loss = 201.69, pg_loss = 81.766, baseline_loss = 126.05, entropy_loss = -6.1185, learner_queue_size = 23, _tick = 22495, _time = 1.654e+09, train_seconds = 1.0913e+04)
[2022-05-31 17:12:18,994][root][INFO] - Step 72056320 @ 6650.7 SPS. Inference batcher size: 117. Learner queue size: 25. Other stats: (step = 72056320, mean_episode_return = 127.29, mean_episode_step = 727.53, total_loss = -294.49, pg_loss = -334.41, baseline_loss = 46.592, entropy_loss = -6.6788, learner_queue_size = 13, _tick = 22508, _time = 1.654e+09, train_seconds = 1.0918e+04)
[2022-05-31 17:12:23,998][root][INFO] - Step 72089600 @ 6650.6 SPS. Inference batcher size: 121. Learner queue size: 18. Other stats: (step = 72089600, mean_episode_return = 229.28, mean_episode_step = 689.73, total_loss = 242.68, pg_loss = 121.15, baseline_loss = 127.86, entropy_loss = -6.3297, learner_queue_size = 18, _tick = 22519, _time = 1.654e+09, train_seconds = 1.0923e+04)
[2022-05-31 17:12:29,002][root][INFO] - Step 72120320 @ 6139.1 SPS. Inference batcher size: 180. Learner queue size: 15. Other stats: (step = 72120320, mean_episode_return = 95.33, mean_episode_step = 773.28, total_loss = -95.565, pg_loss = -120.69, baseline_loss = 31.719, entropy_loss = -6.5957, learner_queue_size = 14, _tick = 22530, _time = 1.654e+09, train_seconds = 1.0928e+04)
[2022-05-31 17:12:34,006][root][INFO] - Step 72153600 @ 6650.7 SPS. Inference batcher size: 129. Learner queue size: 7. Other stats: (step = 72153600, mean_episode_return = None, mean_episode_step = 1091.7, total_loss = 343.92, pg_loss = 239.07, baseline_loss = 111.2, entropy_loss = -6.3496, learner_queue_size = 20, _tick = 22540, _time = 1.654e+09, train_seconds = 1.0933e+04)
[2022-05-31 17:12:39,012][root][INFO] - Step 72186880 @ 6648.0 SPS. Inference batcher size: 38. Learner queue size: 9. Other stats: (step = 72186880, mean_episode_return = None, mean_episode_step = 2340.9, total_loss = -40.673, pg_loss = -85.261, baseline_loss = 50.685, entropy_loss = -6.0966, learner_queue_size = 23, _tick = 22550, _time = 1.654e+09, train_seconds = 1.0938e+04)
[2022-05-31 17:12:44,019][root][INFO] - Step 72220160 @ 6647.6 SPS. Inference batcher size: 80. Learner queue size: 7. Other stats: (step = 72220160, mean_episode_return = 210.98, mean_episode_step = 618.28, total_loss = -81.097, pg_loss = -135.61, baseline_loss = 60.631, entropy_loss = -6.1193, learner_queue_size = 18, _tick = 22563, _time = 1.654e+09, train_seconds = 1.0943e+04)
[2022-05-31 17:12:49,025][root][INFO] - Step 72253440 @ 6647.3 SPS. Inference batcher size: 115. Learner queue size: 15. Other stats: (step = 72253440, mean_episode_return = 155.42, mean_episode_step = 5853.5, total_loss = 19.523, pg_loss = -61.091, baseline_loss = 86.736, entropy_loss = -6.1218, learner_queue_size = 26, _tick = 22575, _time = 1.654e+09, train_seconds = 1.0948e+04)
[2022-05-31 17:12:54,031][root][INFO] - Step 72286720 @ 6648.0 SPS. Inference batcher size: 145. Learner queue size: 4. Other stats: (step = 72286720, mean_episode_return = 170.99, mean_episode_step = 708.0, total_loss = 126.36, pg_loss = -25.155, baseline_loss = 157.48, entropy_loss = -5.9653, learner_queue_size = 24, _tick = 22585, _time = 1.654e+09, train_seconds = 1.0953e+04)
[2022-05-31 17:12:59,034][root][INFO] - Step 72320000 @ 6651.9 SPS. Inference batcher size: 154. Learner queue size: 25. Other stats: (step = 72320000, mean_episode_return = 80.45, mean_episode_step = 642.91, total_loss = -293.38, pg_loss = -326.02, baseline_loss = 39.147, entropy_loss = -6.501, learner_queue_size = 15, _tick = 22598, _time = 1.654e+09, train_seconds = 1.0958e+04)
[2022-05-31 17:13:04,038][root][INFO] - Step 72353280 @ 6650.8 SPS. Inference batcher size: 36. Learner queue size: 28. Other stats: (step = 72353280, mean_episode_return = 104.48, mean_episode_step = 1038.3, total_loss = -9.7599, pg_loss = -47.149, baseline_loss = 43.5, entropy_loss = -6.111, learner_queue_size = 28, _tick = 22609, _time = 1.654e+09, train_seconds = 1.0963e+04)
[2022-05-31 17:13:09,045][root][INFO] - Step 72384000 @ 6135.5 SPS. Inference batcher size: 89. Learner queue size: 16. Other stats: (step = 72384000, mean_episode_return = 193.43, mean_episode_step = 646.99, total_loss = 289.04, pg_loss = 204.13, baseline_loss = 91.147, entropy_loss = -6.2391, learner_queue_size = 26, _tick = 22618, _time = 1.654e+09, train_seconds = 1.0968e+04)
[2022-05-31 17:13:14,051][root][INFO] - Step 72417280 @ 6648.0 SPS. Inference batcher size: 112. Learner queue size: 13. Other stats: (step = 72417280, mean_episode_return = 150.96, mean_episode_step = 5637.1, total_loss = -19.977, pg_loss = -64.384, baseline_loss = 50.76, entropy_loss = -6.3526, learner_queue_size = 15, _tick = 22631, _time = 1.654e+09, train_seconds = 1.0973e+04)
[2022-05-31 17:13:19,055][root][INFO] - Step 72450560 @ 6650.7 SPS. Inference batcher size: 129. Learner queue size: 5. Other stats: (step = 72450560, mean_episode_return = 117.68, mean_episode_step = 864.99, total_loss = -84.121, pg_loss = -126.96, baseline_loss = 49.11, entropy_loss = -6.2727, learner_queue_size = 15, _tick = 22644, _time = 1.654e+09, train_seconds = 1.0978e+04)
[2022-05-31 17:13:24,058][root][INFO] - Step 72483840 @ 6651.9 SPS. Inference batcher size: 142. Learner queue size: 29. Other stats: (step = 72483840, mean_episode_return = 25.77, mean_episode_step = 832.23, total_loss = -32.676, pg_loss = -50.737, baseline_loss = 24.713, entropy_loss = -6.6519, learner_queue_size = 17, _tick = 22656, _time = 1.654e+09, train_seconds = 1.0983e+04)
[2022-05-31 17:13:29,062][root][INFO] - Step 72517120 @ 6650.7 SPS. Inference batcher size: 109. Learner queue size: 7. Other stats: (step = 72517120, mean_episode_return = 58.52, mean_episode_step = 5898.4, total_loss = 171.01, pg_loss = 102.04, baseline_loss = 75.137, entropy_loss = -6.1673, learner_queue_size = 22, _tick = 22667, _time = 1.654e+09, train_seconds = 1.0988e+04)
[2022-05-31 17:13:34,066][root][INFO] - Step 72547840 @ 6139.1 SPS. Inference batcher size: 141. Learner queue size: 18. Other stats: (step = 72547840, mean_episode_return = 112.55, mean_episode_step = 884.34, total_loss = -127.04, pg_loss = -145.28, baseline_loss = 24.737, entropy_loss = -6.5003, learner_queue_size = 13, _tick = 22678, _time = 1.654e+09, train_seconds = 1.0993e+04)
[2022-05-31 17:13:39,072][root][INFO] - Step 72581120 @ 6648.0 SPS. Inference batcher size: 120. Learner queue size: 14. Other stats: (step = 72581120, mean_episode_return = 245.14, mean_episode_step = 913.89, total_loss = 182.15, pg_loss = 111.4, baseline_loss = 77.536, entropy_loss = -6.7806, learner_queue_size = 21, _tick = 22691, _time = 1.654e+09, train_seconds = 1.0998e+04)
[2022-05-31 17:13:44,078][root][INFO] - Step 72614400 @ 6648.0 SPS. Inference batcher size: 108. Learner queue size: 18. Other stats: (step = 72614400, mean_episode_return = 98.896, mean_episode_step = 1627.2, total_loss = 188.75, pg_loss = 111.94, baseline_loss = 83.227, entropy_loss = -6.4201, learner_queue_size = 14, _tick = 22704, _time = 1.654e+09, train_seconds = 1.1003e+04)
[2022-05-31 17:13:49,084][root][INFO] - Step 72647680 @ 6647.9 SPS. Inference batcher size: 129. Learner queue size: 2. Other stats: (step = 72647680, mean_episode_return = 163.44, mean_episode_step = 616.64, total_loss = -186.31, pg_loss = -253.76, baseline_loss = 73.646, entropy_loss = -6.1905, learner_queue_size = 15, _tick = 22716, _time = 1.654e+09, train_seconds = 1.1008e+04)
[2022-05-31 17:13:54,086][root][INFO] - Step 72680960 @ 6653.5 SPS. Inference batcher size: 83. Learner queue size: 14. Other stats: (step = 72680960, mean_episode_return = 192.21, mean_episode_step = 773.52, total_loss = 61.308, pg_loss = -2.596, baseline_loss = 70.208, entropy_loss = -6.3039, learner_queue_size = 15, _tick = 22728, _time = 1.654e+09, train_seconds = 1.1013e+04)
[2022-05-31 17:13:59,092][root][INFO] - Step 72714240 @ 6647.8 SPS. Inference batcher size: 118. Learner queue size: 2. Other stats: (step = 72714240, mean_episode_return = 30.391, mean_episode_step = 605.42, total_loss = 257.92, pg_loss = 137.16, baseline_loss = 126.99, entropy_loss = -6.2238, learner_queue_size = 14, _tick = 22738, _time = 1.654e+09, train_seconds = 1.1018e+04)
[2022-05-31 17:14:04,098][root][INFO] - Step 72747520 @ 6648.2 SPS. Inference batcher size: 123. Learner queue size: 27. Other stats: (step = 72747520, mean_episode_return = 153.99, mean_episode_step = 797.73, total_loss = 352.64, pg_loss = 271.7, baseline_loss = 87.128, entropy_loss = -6.1911, learner_queue_size = 19, _tick = 22751, _time = 1.654e+09, train_seconds = 1.1023e+04)
[2022-05-31 17:14:09,102][root][INFO] - Step 72780800 @ 6650.7 SPS. Inference batcher size: 130. Learner queue size: 25. Other stats: (step = 72780800, mean_episode_return = None, mean_episode_step = 1139.8, total_loss = -42.774, pg_loss = -90.217, baseline_loss = 53.574, entropy_loss = -6.1312, learner_queue_size = 17, _tick = 22761, _time = 1.654e+09, train_seconds = 1.1028e+04)
[2022-05-31 17:14:14,109][root][INFO] - Step 72811520 @ 6135.3 SPS. Inference batcher size: 141. Learner queue size: 14. Other stats: (step = 72811520, mean_episode_return = 35.63, mean_episode_step = 2071.9, total_loss = -103.82, pg_loss = -141.95, baseline_loss = 44.614, entropy_loss = -6.486, learner_queue_size = 13, _tick = 22772, _time = 1.654e+09, train_seconds = 1.1033e+04)
[2022-05-31 17:14:19,114][root][INFO] - Step 72844800 @ 6649.5 SPS. Inference batcher size: 135. Learner queue size: 31. Other stats: (step = 72844800, mean_episode_return = None, mean_episode_step = 655.44, total_loss = 43.977, pg_loss = 14.355, baseline_loss = 35.797, entropy_loss = -6.1758, learner_queue_size = 20, _tick = 22782, _time = 1.654e+09, train_seconds = 1.1038e+04)
[2022-05-31 17:14:24,118][root][INFO] - Step 72878080 @ 6650.6 SPS. Inference batcher size: 108. Learner queue size: 23. Other stats: (step = 72878080, mean_episode_return = 204.56, mean_episode_step = 1420.7, total_loss = -214.81, pg_loss = -307.98, baseline_loss = 98.896, entropy_loss = -5.7247, learner_queue_size = 23, _tick = 22793, _time = 1.654e+09, train_seconds = 1.1043e+04)
[2022-05-31 17:14:29,124][root][INFO] - Step 72911360 @ 6647.9 SPS. Inference batcher size: 151. Learner queue size: 12. Other stats: (step = 72911360, mean_episode_return = 175.54, mean_episode_step = 649.86, total_loss = 72.603, pg_loss = -6.0568, baseline_loss = 84.493, entropy_loss = -5.8335, learner_queue_size = 20, _tick = 22805, _time = 1.654e+09, train_seconds = 1.1048e+04)
[2022-05-31 17:14:34,130][root][INFO] - Step 72944640 @ 6648.2 SPS. Inference batcher size: 130. Learner queue size: 16. Other stats: (step = 72944640, mean_episode_return = 226.97, mean_episode_step = 480.81, total_loss = -311.68, pg_loss = -414.77, baseline_loss = 109.37, entropy_loss = -6.2806, learner_queue_size = 29, _tick = 22818, _time = 1.654e+09, train_seconds = 1.1053e+04)
[2022-05-31 17:14:39,136][root][INFO] - Step 72977920 @ 6647.9 SPS. Inference batcher size: 40. Learner queue size: 5. Other stats: (step = 72977920, mean_episode_return = 160.03, mean_episode_step = 820.9, total_loss = 4.9164, pg_loss = -74.89, baseline_loss = 86.015, entropy_loss = -6.2092, learner_queue_size = 15, _tick = 22831, _time = 1.654e+09, train_seconds = 1.1058e+04)
[2022-05-31 17:14:44,143][root][INFO] - Step 73011200 @ 6646.6 SPS. Inference batcher size: 114. Learner queue size: 14. Other stats: (step = 73011200, mean_episode_return = 156.83, mean_episode_step = 734.82, total_loss = -116.72, pg_loss = -130.82, baseline_loss = 20.489, entropy_loss = -6.3872, learner_queue_size = 25, _tick = 22843, _time = 1.654e+09, train_seconds = 1.1063e+04)
[2022-05-31 17:14:49,149][root][INFO] - Step 73044480 @ 6648.0 SPS. Inference batcher size: 68. Learner queue size: 2. Other stats: (step = 73044480, mean_episode_return = 58.542, mean_episode_step = 5648.6, total_loss = 75.79, pg_loss = 61.701, baseline_loss = 20.882, entropy_loss = -6.7932, learner_queue_size = 21, _tick = 22854, _time = 1.654e+09, train_seconds = 1.1068e+04)
[2022-05-31 17:14:54,154][root][INFO] - Step 73077760 @ 6649.2 SPS. Inference batcher size: 94. Learner queue size: 21. Other stats: (step = 73077760, mean_episode_return = 130.37, mean_episode_step = 744.75, total_loss = 162.04, pg_loss = 101.64, baseline_loss = 66.543, entropy_loss = -6.137, learner_queue_size = 7, _tick = 22867, _time = 1.654e+09, train_seconds = 1.1073e+04)
[2022-05-31 17:14:59,158][root][INFO] - Step 73111040 @ 6651.0 SPS. Inference batcher size: 170. Learner queue size: 27. Other stats: (step = 73111040, mean_episode_return = 221.27, mean_episode_step = 775.59, total_loss = -36.322, pg_loss = -92.439, baseline_loss = 62.448, entropy_loss = -6.3306, learner_queue_size = 18, _tick = 22877, _time = 1.654e+09, train_seconds = 1.1078e+04)
[2022-05-31 17:15:04,164][root][INFO] - Step 73141760 @ 6136.4 SPS. Inference batcher size: 119. Learner queue size: 20. Other stats: (step = 73141760, mean_episode_return = 113.46, mean_episode_step = 1618.4, total_loss = -52.067, pg_loss = -79.805, baseline_loss = 33.752, entropy_loss = -6.0143, learner_queue_size = 16, _tick = 22889, _time = 1.654e+09, train_seconds = 1.1083e+04)
[2022-05-31 17:15:09,170][root][INFO] - Step 73175040 @ 6648.2 SPS. Inference batcher size: 100. Learner queue size: 22. Other stats: (step = 73175040, mean_episode_return = 75.475, mean_episode_step = 2156.6, total_loss = 119.86, pg_loss = 70.725, baseline_loss = 55.402, entropy_loss = -6.2642, learner_queue_size = 15, _tick = 22901, _time = 1.654e+09, train_seconds = 1.1088e+04)
[2022-05-31 17:15:14,174][root][INFO] - Step 73208320 @ 6650.8 SPS. Inference batcher size: 140. Learner queue size: 16. Other stats: (step = 73208320, mean_episode_return = None, mean_episode_step = 689.38, total_loss = -206.99, pg_loss = -238.37, baseline_loss = 37.739, entropy_loss = -6.3625, learner_queue_size = 28, _tick = 22912, _time = 1.654e+09, train_seconds = 1.1093e+04)
[2022-05-31 17:15:19,178][root][INFO] - Step 73241600 @ 6650.7 SPS. Inference batcher size: 140. Learner queue size: 0. Other stats: (step = 73241600, mean_episode_return = 213.72, mean_episode_step = 1176.6, total_loss = -37.899, pg_loss = -100.67, baseline_loss = 68.697, entropy_loss = -5.9294, learner_queue_size = 12, _tick = 22923, _time = 1.654e+09, train_seconds = 1.1098e+04)
[2022-05-31 17:15:24,182][root][INFO] - Step 73274880 @ 6650.4 SPS. Inference batcher size: 87. Learner queue size: 4. Other stats: (step = 73274880, mean_episode_return = 139.67, mean_episode_step = 995.22, total_loss = 234.49, pg_loss = 171.26, baseline_loss = 69.512, entropy_loss = -6.2816, learner_queue_size = 22, _tick = 22935, _time = 1.654e+09, train_seconds = 1.1103e+04)
[2022-05-31 17:15:29,186][root][INFO] - Step 73305600 @ 6139.3 SPS. Inference batcher size: 102. Learner queue size: 25. Other stats: (step = 73305600, mean_episode_return = 196.64, mean_episode_step = 5752.5, total_loss = -261.93, pg_loss = -327.56, baseline_loss = 71.509, entropy_loss = -5.885, learner_queue_size = 17, _tick = 22946, _time = 1.654e+09, train_seconds = 1.1108e+04)
[2022-05-31 17:15:34,190][root][INFO] - Step 73341440 @ 7162.3 SPS. Inference batcher size: 63. Learner queue size: 25. Other stats: (step = 73341440, mean_episode_return = 69.534, mean_episode_step = 818.67, total_loss = -36.681, pg_loss = -52.298, baseline_loss = 21.927, entropy_loss = -6.3101, learner_queue_size = 22, _tick = 22959, _time = 1.654e+09, train_seconds = 1.1113e+04)
[2022-05-31 17:15:39,196][root][INFO] - Step 73372160 @ 6136.6 SPS. Inference batcher size: 151. Learner queue size: 21. Other stats: (step = 73372160, mean_episode_return = 157.84, mean_episode_step = 702.67, total_loss = 217.52, pg_loss = 104.96, baseline_loss = 119.03, entropy_loss = -6.4665, learner_queue_size = 26, _tick = 22971, _time = 1.654e+09, train_seconds = 1.1118e+04)
[2022-05-31 17:15:44,202][root][INFO] - Step 73405440 @ 6648.0 SPS. Inference batcher size: 113. Learner queue size: 16. Other stats: (step = 73405440, mean_episode_return = 143.32, mean_episode_step = 5906.4, total_loss = -81.797, pg_loss = -106.45, baseline_loss = 31.057, entropy_loss = -6.4014, learner_queue_size = 6, _tick = 22984, _time = 1.654e+09, train_seconds = 1.1123e+04)
[2022-05-31 17:15:49,206][root][INFO] - Step 73441280 @ 7162.0 SPS. Inference batcher size: 139. Learner queue size: 11. Other stats: (step = 73441280, mean_episode_return = 161.84, mean_episode_step = 1986.0, total_loss = -85.451, pg_loss = -110.89, baseline_loss = 31.79, entropy_loss = -6.35, learner_queue_size = 11, _tick = 22995, _time = 1.654e+09, train_seconds = 1.1128e+04)
[2022-05-31 17:15:54,209][root][INFO] - Step 73472000 @ 6140.2 SPS. Inference batcher size: 117. Learner queue size: 14. Other stats: (step = 73472000, mean_episode_return = 62.821, mean_episode_step = 717.3, total_loss = 98.221, pg_loss = 36.253, baseline_loss = 68.237, entropy_loss = -6.2692, learner_queue_size = 18, _tick = 23006, _time = 1.654e+09, train_seconds = 1.1133e+04)
[2022-05-31 17:15:59,215][root][INFO] - Step 73505280 @ 6648.0 SPS. Inference batcher size: 179. Learner queue size: 10. Other stats: (step = 73505280, mean_episode_return = 162.95, mean_episode_step = 581.8, total_loss = 80.625, pg_loss = -75.31, baseline_loss = 162.01, entropy_loss = -6.072, learner_queue_size = 21, _tick = 23017, _time = 1.654e+09, train_seconds = 1.1138e+04)
[2022-05-31 17:16:04,218][root][INFO] - Step 73538560 @ 6652.4 SPS. Inference batcher size: 140. Learner queue size: 7. Other stats: (step = 73538560, mean_episode_return = 318.53, mean_episode_step = 775.11, total_loss = 65.044, pg_loss = -144.09, baseline_loss = 215.4, entropy_loss = -6.2678, learner_queue_size = 21, _tick = 23028, _time = 1.654e+09, train_seconds = 1.1143e+04)
[2022-05-31 17:16:09,222][root][INFO] - Step 73571840 @ 6650.8 SPS. Inference batcher size: 133. Learner queue size: 2. Other stats: (step = 73571840, mean_episode_return = 129.12, mean_episode_step = 846.95, total_loss = 488.81, pg_loss = 360.54, baseline_loss = 134.53, entropy_loss = -6.2567, learner_queue_size = 16, _tick = 23039, _time = 1.654e+09, train_seconds = 1.1148e+04)
[2022-05-31 17:16:14,226][root][INFO] - Step 73605120 @ 6650.7 SPS. Inference batcher size: 181. Learner queue size: 29. Other stats: (step = 73605120, mean_episode_return = 136.34, mean_episode_step = 593.05, total_loss = 39.462, pg_loss = -15.233, baseline_loss = 60.531, entropy_loss = -5.837, learner_queue_size = 20, _tick = 23050, _time = 1.654e+09, train_seconds = 1.1153e+04)
[2022-05-31 17:16:19,231][root][INFO] - Step 73635840 @ 6138.5 SPS. Inference batcher size: 55. Learner queue size: 21. Other stats: (step = 73635840, mean_episode_return = 50.88, mean_episode_step = 525.94, total_loss = -122.35, pg_loss = -157.49, baseline_loss = 40.893, entropy_loss = -5.7457, learner_queue_size = 12, _tick = 23062, _time = 1.654e+09, train_seconds = 1.1158e+04)
[2022-05-31 17:16:24,237][root][INFO] - Step 73669120 @ 6647.2 SPS. Inference batcher size: 146. Learner queue size: 11. Other stats: (step = 73669120, mean_episode_return = 52.584, mean_episode_step = 6418.9, total_loss = 264.24, pg_loss = 172.12, baseline_loss = 98.725, entropy_loss = -6.6048, learner_queue_size = 16, _tick = 23074, _time = 1.654e+09, train_seconds = 1.1163e+04)
[2022-05-31 17:16:29,242][root][INFO] - Step 73702400 @ 6649.5 SPS. Inference batcher size: 76. Learner queue size: 11. Other stats: (step = 73702400, mean_episode_return = 46.789, mean_episode_step = 805.48, total_loss = 103.85, pg_loss = 41.406, baseline_loss = 68.85, entropy_loss = -6.4039, learner_queue_size = 17, _tick = 23086, _time = 1.654e+09, train_seconds = 1.1168e+04)
[2022-05-31 17:16:34,246][root][INFO] - Step 73735680 @ 6650.6 SPS. Inference batcher size: 136. Learner queue size: 0. Other stats: (step = 73735680, mean_episode_return = 48.258, mean_episode_step = 643.67, total_loss = 670.96, pg_loss = 348.81, baseline_loss = 328.41, entropy_loss = -6.2643, learner_queue_size = 18, _tick = 23097, _time = 1.654e+09, train_seconds = 1.1173e+04)
[2022-05-31 17:16:39,250][root][INFO] - Step 73768960 @ 6650.7 SPS. Inference batcher size: 138. Learner queue size: 8. Other stats: (step = 73768960, mean_episode_return = 84.44, mean_episode_step = 1266.0, total_loss = 238.29, pg_loss = 141.44, baseline_loss = 103.51, entropy_loss = -6.66, learner_queue_size = 26, _tick = 23109, _time = 1.654e+09, train_seconds = 1.1178e+04)
[2022-05-31 17:16:44,256][root][INFO] - Step 73802240 @ 6647.5 SPS. Inference batcher size: 84. Learner queue size: 2. Other stats: (step = 73802240, mean_episode_return = 161.33, mean_episode_step = 2243.8, total_loss = 253.2, pg_loss = 201.54, baseline_loss = 58.467, entropy_loss = -6.8139, learner_queue_size = 25, _tick = 23121, _time = 1.654e+09, train_seconds = 1.1183e+04)
[2022-05-31 17:16:49,262][root][INFO] - Step 73835520 @ 6649.1 SPS. Inference batcher size: 88. Learner queue size: 2. Other stats: (step = 73835520, mean_episode_return = 60.201, mean_episode_step = 1072.7, total_loss = -27.206, pg_loss = -83.02, baseline_loss = 62.257, entropy_loss = -6.4434, learner_queue_size = 10, _tick = 23131, _time = 1.654e+09, train_seconds = 1.1188e+04)
[2022-05-31 17:16:54,268][root][INFO] - Step 73866240 @ 6136.6 SPS. Inference batcher size: 107. Learner queue size: 25. Other stats: (step = 73866240, mean_episode_return = 102.63, mean_episode_step = 687.68, total_loss = 64.83, pg_loss = -25.145, baseline_loss = 96.46, entropy_loss = -6.4846, learner_queue_size = 8, _tick = 23143, _time = 1.654e+09, train_seconds = 1.1193e+04)
[2022-05-31 17:16:59,274][root][INFO] - Step 73899520 @ 6648.0 SPS. Inference batcher size: 130. Learner queue size: 16. Other stats: (step = 73899520, mean_episode_return = 102.13, mean_episode_step = 793.89, total_loss = -200.29, pg_loss = -256.54, baseline_loss = 62.559, entropy_loss = -6.3068, learner_queue_size = 14, _tick = 23154, _time = 1.654e+09, train_seconds = 1.1198e+04)
[2022-05-31 17:17:04,278][root][INFO] - Step 73932800 @ 6650.3 SPS. Inference batcher size: 163. Learner queue size: 10. Other stats: (step = 73932800, mean_episode_return = 48.84, mean_episode_step = 1396.0, total_loss = -42.98, pg_loss = -99.216, baseline_loss = 62.742, entropy_loss = -6.5054, learner_queue_size = 19, _tick = 23166, _time = 1.654e+09, train_seconds = 1.1203e+04)
[2022-05-31 17:17:09,282][root][INFO] - Step 73966080 @ 6650.7 SPS. Inference batcher size: 79. Learner queue size: 2. Other stats: (step = 73966080, mean_episode_return = 129.65, mean_episode_step = 2426.8, total_loss = 167.25, pg_loss = 107.97, baseline_loss = 65.5, entropy_loss = -6.2217, learner_queue_size = 24, _tick = 23176, _time = 1.654e+09, train_seconds = 1.1208e+04)
[2022-05-31 17:17:14,288][root][INFO] - Step 73999360 @ 6648.0 SPS. Inference batcher size: 124. Learner queue size: 4. Other stats: (step = 73999360, mean_episode_return = 130.38, mean_episode_step = 800.68, total_loss = 214.51, pg_loss = 102.73, baseline_loss = 118.26, entropy_loss = -6.4788, learner_queue_size = 19, _tick = 23187, _time = 1.654e+09, train_seconds = 1.1213e+04)
[2022-05-31 17:17:19,290][root][INFO] - Step 74032640 @ 6653.3 SPS. Inference batcher size: 187. Learner queue size: 2. Other stats: (step = 74032640, mean_episode_return = None, mean_episode_step = 1739.9, total_loss = 265.76, pg_loss = 126.11, baseline_loss = 146.39, entropy_loss = -6.7323, learner_queue_size = 15, _tick = 23197, _time = 1.654e+09, train_seconds = 1.1218e+04)
[2022-05-31 17:17:24,294][root][INFO] - Step 74065920 @ 6650.8 SPS. Inference batcher size: 126. Learner queue size: 22. Other stats: (step = 74065920, mean_episode_return = None, mean_episode_step = 944.62, total_loss = 86.164, pg_loss = -7.7549, baseline_loss = 99.904, entropy_loss = -5.9856, learner_queue_size = 16, _tick = 23207, _time = 1.654e+09, train_seconds = 1.1223e+04)
[2022-05-31 17:17:29,300][root][INFO] - Step 74096640 @ 6136.6 SPS. Inference batcher size: 155. Learner queue size: 23. Other stats: (step = 74096640, mean_episode_return = 205.22, mean_episode_step = 770.57, total_loss = -168.16, pg_loss = -203.63, baseline_loss = 41.554, entropy_loss = -6.0832, learner_queue_size = 16, _tick = 23216, _time = 1.654e+09, train_seconds = 1.1228e+04)
[2022-05-31 17:17:34,306][root][INFO] - Step 74129920 @ 6648.1 SPS. Inference batcher size: 103. Learner queue size: 10. Other stats: (step = 74129920, mean_episode_return = 89.195, mean_episode_step = 1003.8, total_loss = -282.84, pg_loss = -303.68, baseline_loss = 27.453, entropy_loss = -6.6197, learner_queue_size = 24, _tick = 23229, _time = 1.654e+09, train_seconds = 1.1233e+04)
[2022-05-31 17:17:39,312][root][INFO] - Step 74163200 @ 6648.1 SPS. Inference batcher size: 148. Learner queue size: 17. Other stats: (step = 74163200, mean_episode_return = 122.82, mean_episode_step = 692.54, total_loss = 123.38, pg_loss = 21.177, baseline_loss = 108.45, entropy_loss = -6.2556, learner_queue_size = 23, _tick = 23240, _time = 1.654e+09, train_seconds = 1.1238e+04)
[2022-05-31 17:17:44,314][root][INFO] - Step 74196480 @ 6653.3 SPS. Inference batcher size: 153. Learner queue size: 12. Other stats: (step = 74196480, mean_episode_return = 177.49, mean_episode_step = 722.34, total_loss = 355.91, pg_loss = 101.27, baseline_loss = 260.51, entropy_loss = -5.8731, learner_queue_size = 22, _tick = 23253, _time = 1.654e+09, train_seconds = 1.1243e+04)
[2022-05-31 17:17:49,319][root][INFO] - Step 74229760 @ 6650.0 SPS. Inference batcher size: 11. Learner queue size: 7. Other stats: (step = 74229760, mean_episode_return = 192.75, mean_episode_step = 2687.7, total_loss = 40.847, pg_loss = 4.0252, baseline_loss = 42.822, entropy_loss = -6.0001, learner_queue_size = 15, _tick = 23264, _time = 1.654e+09, train_seconds = 1.1248e+04)
[2022-05-31 17:17:54,325][root][INFO] - Step 74263040 @ 6647.4 SPS. Inference batcher size: 38. Learner queue size: 2. Other stats: (step = 74263040, mean_episode_return = 82.5, mean_episode_step = 846.12, total_loss = 30.635, pg_loss = -50.99, baseline_loss = 87.998, entropy_loss = -6.3732, learner_queue_size = 23, _tick = 23273, _time = 1.654e+09, train_seconds = 1.1253e+04)
[2022-05-31 17:17:59,330][root][INFO] - Step 74296320 @ 6649.3 SPS. Inference batcher size: 71. Learner queue size: 31. Other stats: (step = 74296320, mean_episode_return = 218.23, mean_episode_step = 689.8, total_loss = 86.824, pg_loss = 41.641, baseline_loss = 51.226, entropy_loss = -6.0428, learner_queue_size = 9, _tick = 23283, _time = 1.654e+09, train_seconds = 1.1258e+04)
[2022-05-31 17:18:04,336][root][INFO] - Step 74327040 @ 6136.1 SPS. Inference batcher size: 114. Learner queue size: 17. Other stats: (step = 74327040, mean_episode_return = 270.27, mean_episode_step = 761.52, total_loss = 137.3, pg_loss = 66.567, baseline_loss = 77.08, entropy_loss = -6.3423, learner_queue_size = 22, _tick = 23295, _time = 1.654e+09, train_seconds = 1.1263e+04)
[2022-05-31 17:18:09,342][root][INFO] - Step 74360320 @ 6648.4 SPS. Inference batcher size: 59. Learner queue size: 19. Other stats: (step = 74360320, mean_episode_return = 160.63, mean_episode_step = 701.49, total_loss = 184.52, pg_loss = 104.03, baseline_loss = 87.214, entropy_loss = -6.7182, learner_queue_size = 12, _tick = 23308, _time = 1.654e+09, train_seconds = 1.1268e+04)
[2022-05-31 17:18:14,346][root][INFO] - Step 74393600 @ 6650.5 SPS. Inference batcher size: 46. Learner queue size: 10. Other stats: (step = 74393600, mean_episode_return = 143.4, mean_episode_step = 3281.0, total_loss = 158.59, pg_loss = 74.852, baseline_loss = 89.944, entropy_loss = -6.2054, learner_queue_size = 20, _tick = 23319, _time = 1.654e+09, train_seconds = 1.1273e+04)
[2022-05-31 17:18:19,350][root][INFO] - Step 74426880 @ 6650.9 SPS. Inference batcher size: 31. Learner queue size: 8. Other stats: (step = 74426880, mean_episode_return = 283.16, mean_episode_step = 1129.1, total_loss = -65.304, pg_loss = -77.09, baseline_loss = 18.58, entropy_loss = -6.7938, learner_queue_size = 20, _tick = 23329, _time = 1.654e+09, train_seconds = 1.1278e+04)
[2022-05-31 17:18:24,357][root][INFO] - Step 74460160 @ 6646.7 SPS. Inference batcher size: 71. Learner queue size: 2. Other stats: (step = 74460160, mean_episode_return = 100.25, mean_episode_step = 766.99, total_loss = 83.916, pg_loss = 63.333, baseline_loss = 26.906, entropy_loss = -6.3231, learner_queue_size = 18, _tick = 23342, _time = 1.654e+09, train_seconds = 1.1283e+04)
[2022-05-31 17:18:29,362][root][INFO] - Step 74493440 @ 6649.4 SPS. Inference batcher size: 77. Learner queue size: 26. Other stats: (step = 74493440, mean_episode_return = 104.33, mean_episode_step = 978.68, total_loss = 4.7184, pg_loss = -68.523, baseline_loss = 79.06, entropy_loss = -5.8193, learner_queue_size = 11, _tick = 23355, _time = 1.654e+09, train_seconds = 1.1288e+04)
[2022-05-31 17:18:34,368][root][INFO] - Step 74524160 @ 6136.6 SPS. Inference batcher size: 162. Learner queue size: 11. Other stats: (step = 74524160, mean_episode_return = 185.79, mean_episode_step = 709.12, total_loss = -20.424, pg_loss = -272.33, baseline_loss = 257.71, entropy_loss = -5.8019, learner_queue_size = 18, _tick = 23367, _time = 1.654e+09, train_seconds = 1.1293e+04)
[2022-05-31 17:18:39,374][root][INFO] - Step 74557440 @ 6648.1 SPS. Inference batcher size: 62. Learner queue size: 17. Other stats: (step = 74557440, mean_episode_return = 208.31, mean_episode_step = 3211.1, total_loss = -17.869, pg_loss = -56.361, baseline_loss = 44.968, entropy_loss = -6.4753, learner_queue_size = 28, _tick = 23380, _time = 1.654e+09, train_seconds = 1.1298e+04)
[2022-05-31 17:18:44,378][root][INFO] - Step 74590720 @ 6650.6 SPS. Inference batcher size: 159. Learner queue size: 16. Other stats: (step = 74590720, mean_episode_return = 77.905, mean_episode_step = 663.97, total_loss = -218.95, pg_loss = -263.04, baseline_loss = 50.514, entropy_loss = -6.4222, learner_queue_size = 21, _tick = 23393, _time = 1.654e+09, train_seconds = 1.1303e+04)
[2022-05-31 17:18:49,384][root][INFO] - Step 74624000 @ 6647.9 SPS. Inference batcher size: 73. Learner queue size: 11. Other stats: (step = 74624000, mean_episode_return = 11.04, mean_episode_step = 680.04, total_loss = -14.006, pg_loss = -82.671, baseline_loss = 75.034, entropy_loss = -6.3689, learner_queue_size = 26, _tick = 23405, _time = 1.654e+09, train_seconds = 1.1308e+04)
[2022-05-31 17:18:54,390][root][INFO] - Step 74657280 @ 6648.2 SPS. Inference batcher size: 37. Learner queue size: 10. Other stats: (step = 74657280, mean_episode_return = 168.89, mean_episode_step = 2382.3, total_loss = 131.46, pg_loss = -19.614, baseline_loss = 157.67, entropy_loss = -6.5966, learner_queue_size = 21, _tick = 23418, _time = 1.654e+09, train_seconds = 1.1313e+04)
[2022-05-31 17:18:59,396][root][INFO] - Step 74690560 @ 6648.0 SPS. Inference batcher size: 89. Learner queue size: 1. Other stats: (step = 74690560, mean_episode_return = 195.62, mean_episode_step = 857.52, total_loss = -22.205, pg_loss = -62.3, baseline_loss = 46.11, entropy_loss = -6.0157, learner_queue_size = 22, _tick = 23431, _time = 1.654e+09, train_seconds = 1.1318e+04)
[2022-05-31 17:19:04,398][root][INFO] - Step 74723840 @ 6653.3 SPS. Inference batcher size: 122. Learner queue size: 25. Other stats: (step = 74723840, mean_episode_return = 61.32, mean_episode_step = 759.11, total_loss = -21.921, pg_loss = -76.426, baseline_loss = 61.004, entropy_loss = -6.5003, learner_queue_size = 12, _tick = 23442, _time = 1.654e+09, train_seconds = 1.1323e+04)
[2022-05-31 17:19:09,402][root][INFO] - Step 74757120 @ 6650.7 SPS. Inference batcher size: 109. Learner queue size: 18. Other stats: (step = 74757120, mean_episode_return = 118.55, mean_episode_step = 906.77, total_loss = 35.808, pg_loss = -2.0268, baseline_loss = 44.463, entropy_loss = -6.6279, learner_queue_size = 17, _tick = 23453, _time = 1.654e+09, train_seconds = 1.1328e+04)
[2022-05-31 17:19:14,406][root][INFO] - Step 74787840 @ 6139.1 SPS. Inference batcher size: 73. Learner queue size: 15. Other stats: (step = 74787840, mean_episode_return = 112.24, mean_episode_step = 5432.0, total_loss = 390.79, pg_loss = 277.64, baseline_loss = 119.29, entropy_loss = -6.1518, learner_queue_size = 22, _tick = 23464, _time = 1.654e+09, train_seconds = 1.1333e+04)
[2022-05-31 17:19:19,410][root][INFO] - Step 74821120 @ 6650.8 SPS. Inference batcher size: 133. Learner queue size: 6. Other stats: (step = 74821120, mean_episode_return = 149.66, mean_episode_step = 1581.0, total_loss = -164.83, pg_loss = -190.36, baseline_loss = 31.913, entropy_loss = -6.3881, learner_queue_size = 14, _tick = 23475, _time = 1.654e+09, train_seconds = 1.1338e+04)
[2022-05-31 17:19:24,414][root][INFO] - Step 74854400 @ 6650.6 SPS. Inference batcher size: 50. Learner queue size: 2. Other stats: (step = 74854400, mean_episode_return = 64.72, mean_episode_step = 766.17, total_loss = -39.607, pg_loss = -94.96, baseline_loss = 62.16, entropy_loss = -6.8066, learner_queue_size = 21, _tick = 23486, _time = 1.654e+09, train_seconds = 1.1343e+04)
[2022-05-31 17:19:29,418][root][INFO] - Step 74887680 @ 6650.7 SPS. Inference batcher size: 113. Learner queue size: 2. Other stats: (step = 74887680, mean_episode_return = 308.77, mean_episode_step = 556.33, total_loss = 267.39, pg_loss = 151.84, baseline_loss = 121.69, entropy_loss = -6.1414, learner_queue_size = 16, _tick = 23498, _time = 1.654e+09, train_seconds = 1.1348e+04)
[2022-05-31 17:19:34,424][root][INFO] - Step 74920960 @ 6647.8 SPS. Inference batcher size: 173. Learner queue size: 0. Other stats: (step = 74920960, mean_episode_return = 221.58, mean_episode_step = 3461.2, total_loss = 327.52, pg_loss = 184.56, baseline_loss = 149.35, entropy_loss = -6.3911, learner_queue_size = 24, _tick = 23509, _time = 1.654e+09, train_seconds = 1.1353e+04)
[2022-05-31 17:19:39,430][root][INFO] - Step 74954240 @ 6648.3 SPS. Inference batcher size: 118. Learner queue size: 22. Other stats: (step = 74954240, mean_episode_return = 122.32, mean_episode_step = 681.68, total_loss = -103.48, pg_loss = -230.64, baseline_loss = 133.03, entropy_loss = -5.8664, learner_queue_size = 22, _tick = 23518, _time = 1.654e+09, train_seconds = 1.1358e+04)
[2022-05-31 17:19:44,434][root][INFO] - Step 74987520 @ 6650.7 SPS. Inference batcher size: 123. Learner queue size: 23. Other stats: (step = 74987520, mean_episode_return = 302.98, mean_episode_step = 642.44, total_loss = 186.05, pg_loss = 96.413, baseline_loss = 95.903, entropy_loss = -6.2694, learner_queue_size = 20, _tick = 23531, _time = 1.654e+09, train_seconds = 1.1363e+04)
[2022-05-31 17:19:49,438][root][INFO] - Step 75018240 @ 6139.0 SPS. Inference batcher size: 11. Learner queue size: 17. Other stats: (step = 75018240, mean_episode_return = None, mean_episode_step = 576.47, total_loss = 233.88, pg_loss = 135.3, baseline_loss = 105.2, entropy_loss = -6.611, learner_queue_size = 25, _tick = 23541, _time = 1.654e+09, train_seconds = 1.1368e+04)
[2022-05-31 17:19:54,442][root][INFO] - Step 75051520 @ 6650.7 SPS. Inference batcher size: 172. Learner queue size: 12. Other stats: (step = 75051520, mean_episode_return = 133.89, mean_episode_step = 5470.9, total_loss = 75.865, pg_loss = 1.235, baseline_loss = 80.791, entropy_loss = -6.1609, learner_queue_size = 10, _tick = 23552, _time = 1.654e+09, train_seconds = 1.1373e+04)
[2022-05-31 17:19:59,446][root][INFO] - Step 75084800 @ 6650.7 SPS. Inference batcher size: 18. Learner queue size: 3. Other stats: (step = 75084800, mean_episode_return = 127.06, mean_episode_step = 1944.2, total_loss = -120.0, pg_loss = -192.69, baseline_loss = 78.732, entropy_loss = -6.0472, learner_queue_size = 18, _tick = 23564, _time = 1.654e+09, train_seconds = 1.1378e+04)
[2022-05-31 17:20:04,451][root][INFO] - Step 75118080 @ 6649.2 SPS. Inference batcher size: 170. Learner queue size: 4. Other stats: (step = 75118080, mean_episode_return = 97.189, mean_episode_step = 564.06, total_loss = 231.85, pg_loss = 165.57, baseline_loss = 72.86, entropy_loss = -6.5808, learner_queue_size = 24, _tick = 23576, _time = 1.654e+09, train_seconds = 1.1383e+04)
[2022-05-31 17:20:09,454][root][INFO] - Step 75151360 @ 6652.2 SPS. Inference batcher size: 129. Learner queue size: 30. Other stats: (step = 75151360, mean_episode_return = 107.02, mean_episode_step = 631.51, total_loss = 90.353, pg_loss = 57.884, baseline_loss = 38.924, entropy_loss = -6.4545, learner_queue_size = 19, _tick = 23586, _time = 1.654e+09, train_seconds = 1.1388e+04)
[2022-05-31 17:20:14,458][root][INFO] - Step 75184640 @ 6650.6 SPS. Inference batcher size: 188. Learner queue size: 23. Other stats: (step = 75184640, mean_episode_return = None, mean_episode_step = 1844.4, total_loss = 174.3, pg_loss = 127.43, baseline_loss = 53.466, entropy_loss = -6.5963, learner_queue_size = 17, _tick = 23598, _time = 1.654e+09, train_seconds = 1.1393e+04)
[2022-05-31 17:20:19,462][root][INFO] - Step 75215360 @ 6139.1 SPS. Inference batcher size: 154. Learner queue size: 17. Other stats: (step = 75215360, mean_episode_return = 165.63, mean_episode_step = 699.99, total_loss = -17.156, pg_loss = -30.58, baseline_loss = 20.034, entropy_loss = -6.6103, learner_queue_size = 14, _tick = 23608, _time = 1.654e+09, train_seconds = 1.1398e+04)
[2022-05-31 17:20:24,468][root][INFO] - Step 75248640 @ 6648.0 SPS. Inference batcher size: 101. Learner queue size: 21. Other stats: (step = 75248640, mean_episode_return = 209.01, mean_episode_step = 2795.9, total_loss = 81.984, pg_loss = 45.482, baseline_loss = 42.816, entropy_loss = -6.3138, learner_queue_size = 24, _tick = 23621, _time = 1.654e+09, train_seconds = 1.1403e+04)
[2022-05-31 17:20:29,474][root][INFO] - Step 75281920 @ 6648.0 SPS. Inference batcher size: 147. Learner queue size: 24. Other stats: (step = 75281920, mean_episode_return = 113.02, mean_episode_step = 782.31, total_loss = 64.109, pg_loss = 27.358, baseline_loss = 42.841, entropy_loss = -6.0908, learner_queue_size = 19, _tick = 23634, _time = 1.654e+09, train_seconds = 1.1408e+04)
[2022-05-31 17:20:34,478][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 17:20:34,648][root][INFO] - Step 75315200 @ 6650.7 SPS. Inference batcher size: 48. Learner queue size: 23. Other stats: (step = 75315200, mean_episode_return = 167.56, mean_episode_step = 716.32, total_loss = -138.55, pg_loss = -156.7, baseline_loss = 24.39, entropy_loss = -6.2377, learner_queue_size = 18, _tick = 23647, _time = 1.654e+09, train_seconds = 1.1413e+04)
[2022-05-31 17:20:39,650][root][INFO] - Step 75348480 @ 6434.6 SPS. Inference batcher size: 144. Learner queue size: 23. Other stats: (step = 75348480, mean_episode_return = None, mean_episode_step = 943.88, total_loss = -79.917, pg_loss = -106.37, baseline_loss = 32.556, entropy_loss = -6.1068, learner_queue_size = 20, _tick = 23658, _time = 1.654e+09, train_seconds = 1.1418e+04)
[2022-05-31 17:20:44,654][root][INFO] - Step 75381760 @ 6650.8 SPS. Inference batcher size: 78. Learner queue size: 18. Other stats: (step = 75381760, mean_episode_return = None, mean_episode_step = 893.28, total_loss = -55.373, pg_loss = -99.087, baseline_loss = 49.855, entropy_loss = -6.141, learner_queue_size = 19, _tick = 23668, _time = 1.654e+09, train_seconds = 1.1423e+04)
[2022-05-31 17:20:49,660][root][INFO] - Step 75415040 @ 6648.0 SPS. Inference batcher size: 54. Learner queue size: 5. Other stats: (step = 75415040, mean_episode_return = 267.92, mean_episode_step = 5571.3, total_loss = -75.766, pg_loss = -90.848, baseline_loss = 21.402, entropy_loss = -6.3205, learner_queue_size = 21, _tick = 23679, _time = 1.654e+09, train_seconds = 1.1428e+04)
[2022-05-31 17:20:54,662][root][INFO] - Step 75448320 @ 6653.3 SPS. Inference batcher size: 183. Learner queue size: 29. Other stats: (step = 75448320, mean_episode_return = 146.8, mean_episode_step = 1826.2, total_loss = 213.19, pg_loss = 146.54, baseline_loss = 72.884, entropy_loss = -6.2339, learner_queue_size = 26, _tick = 23692, _time = 1.654e+09, train_seconds = 1.1433e+04)
[2022-05-31 17:20:59,666][root][INFO] - Step 75481600 @ 6650.7 SPS. Inference batcher size: 86. Learner queue size: 1. Other stats: (step = 75481600, mean_episode_return = 174.13, mean_episode_step = 644.15, total_loss = 231.5, pg_loss = 95.468, baseline_loss = 141.84, entropy_loss = -5.8152, learner_queue_size = 25, _tick = 23703, _time = 1.654e+09, train_seconds = 1.1438e+04)
[2022-05-31 17:21:04,670][root][INFO] - Step 75514880 @ 6650.6 SPS. Inference batcher size: 96. Learner queue size: 24. Other stats: (step = 75514880, mean_episode_return = 154.72, mean_episode_step = 7402.0, total_loss = 209.59, pg_loss = 151.46, baseline_loss = 64.693, entropy_loss = -6.5644, learner_queue_size = 22, _tick = 23715, _time = 1.654e+09, train_seconds = 1.1443e+04)
[2022-05-31 17:21:09,676][root][INFO] - Step 75545600 @ 6136.6 SPS. Inference batcher size: 128. Learner queue size: 15. Other stats: (step = 75545600, mean_episode_return = 88.239, mean_episode_step = 602.88, total_loss = -174.78, pg_loss = -253.13, baseline_loss = 84.38, entropy_loss = -6.0323, learner_queue_size = 20, _tick = 23727, _time = 1.654e+09, train_seconds = 1.1448e+04)
[2022-05-31 17:21:14,682][root][INFO] - Step 75578880 @ 6648.0 SPS. Inference batcher size: 123. Learner queue size: 20. Other stats: (step = 75578880, mean_episode_return = 194.04, mean_episode_step = 680.2, total_loss = 87.302, pg_loss = 14.215, baseline_loss = 79.453, entropy_loss = -6.3662, learner_queue_size = 22, _tick = 23739, _time = 1.654e+09, train_seconds = 1.1453e+04)
[2022-05-31 17:21:19,686][root][INFO] - Step 75612160 @ 6650.8 SPS. Inference batcher size: 103. Learner queue size: 20. Other stats: (step = 75612160, mean_episode_return = 70.409, mean_episode_step = 1133.0, total_loss = 245.61, pg_loss = 126.0, baseline_loss = 125.8, entropy_loss = -6.186, learner_queue_size = 20, _tick = 23751, _time = 1.654e+09, train_seconds = 1.1458e+04)
[2022-05-31 17:21:24,691][root][INFO] - Step 75645440 @ 6650.0 SPS. Inference batcher size: 95. Learner queue size: 9. Other stats: (step = 75645440, mean_episode_return = 227.58, mean_episode_step = 754.13, total_loss = 41.389, pg_loss = -6.832, baseline_loss = 54.857, entropy_loss = -6.6357, learner_queue_size = 22, _tick = 23763, _time = 1.654e+09, train_seconds = 1.1463e+04)
[2022-05-31 17:21:29,692][root][INFO] - Step 75678720 @ 6654.1 SPS. Inference batcher size: 32. Learner queue size: 5. Other stats: (step = 75678720, mean_episode_return = 131.13, mean_episode_step = 5593.4, total_loss = 482.77, pg_loss = 264.35, baseline_loss = 225.09, entropy_loss = -6.6792, learner_queue_size = 14, _tick = 23775, _time = 1.654e+09, train_seconds = 1.1468e+04)
[2022-05-31 17:21:34,694][root][INFO] - Step 75712000 @ 6653.3 SPS. Inference batcher size: 97. Learner queue size: 0. Other stats: (step = 75712000, mean_episode_return = 124.35, mean_episode_step = 1421.8, total_loss = 318.99, pg_loss = 112.56, baseline_loss = 212.45, entropy_loss = -6.0141, learner_queue_size = 30, _tick = 23788, _time = 1.654e+09, train_seconds = 1.1473e+04)
[2022-05-31 17:21:39,698][root][INFO] - Step 75745280 @ 6650.5 SPS. Inference batcher size: 132. Learner queue size: 18. Other stats: (step = 75745280, mean_episode_return = 110.43, mean_episode_step = 639.81, total_loss = 247.26, pg_loss = 68.494, baseline_loss = 184.74, entropy_loss = -5.9751, learner_queue_size = 10, _tick = 23800, _time = 1.654e+09, train_seconds = 1.1478e+04)
[2022-05-31 17:21:44,704][root][INFO] - Step 75776000 @ 6136.5 SPS. Inference batcher size: 143. Learner queue size: 18. Other stats: (step = 75776000, mean_episode_return = 148.18, mean_episode_step = 2684.5, total_loss = 174.93, pg_loss = 105.76, baseline_loss = 75.483, entropy_loss = -6.3132, learner_queue_size = 23, _tick = 23811, _time = 1.654e+09, train_seconds = 1.1483e+04)
[2022-05-31 17:21:49,710][root][INFO] - Step 75809280 @ 6648.0 SPS. Inference batcher size: 102. Learner queue size: 14. Other stats: (step = 75809280, mean_episode_return = 268.18, mean_episode_step = 724.86, total_loss = 177.31, pg_loss = 117.74, baseline_loss = 65.878, entropy_loss = -6.309, learner_queue_size = 21, _tick = 23824, _time = 1.654e+09, train_seconds = 1.1488e+04)
[2022-05-31 17:21:54,714][root][INFO] - Step 75842560 @ 6650.9 SPS. Inference batcher size: 97. Learner queue size: 16. Other stats: (step = 75842560, mean_episode_return = 115.44, mean_episode_step = 707.84, total_loss = -176.78, pg_loss = -184.16, baseline_loss = 13.192, entropy_loss = -5.8159, learner_queue_size = 20, _tick = 23836, _time = 1.654e+09, train_seconds = 1.1493e+04)
[2022-05-31 17:21:59,720][root][INFO] - Step 75875840 @ 6647.9 SPS. Inference batcher size: 120. Learner queue size: 15. Other stats: (step = 75875840, mean_episode_return = 77.0, mean_episode_step = 660.64, total_loss = 33.318, pg_loss = -6.9601, baseline_loss = 46.83, entropy_loss = -6.5519, learner_queue_size = 25, _tick = 23847, _time = 1.654e+09, train_seconds = 1.1498e+04)
[2022-05-31 17:22:04,726][root][INFO] - Step 75909120 @ 6648.0 SPS. Inference batcher size: 142. Learner queue size: 4. Other stats: (step = 75909120, mean_episode_return = 148.67, mean_episode_step = 642.96, total_loss = 1093.0, pg_loss = 729.36, baseline_loss = 370.18, entropy_loss = -6.5878, learner_queue_size = 17, _tick = 23859, _time = 1.654e+09, train_seconds = 1.1503e+04)
[2022-05-31 17:22:09,732][root][INFO] - Step 75942400 @ 6647.8 SPS. Inference batcher size: 133. Learner queue size: 6. Other stats: (step = 75942400, mean_episode_return = None, mean_episode_step = 5814.4, total_loss = 131.75, pg_loss = 74.851, baseline_loss = 63.261, entropy_loss = -6.3605, learner_queue_size = 24, _tick = 23871, _time = 1.654e+09, train_seconds = 1.1508e+04)
[2022-05-31 17:22:14,738][root][INFO] - Step 75975680 @ 6648.4 SPS. Inference batcher size: 125. Learner queue size: 21. Other stats: (step = 75975680, mean_episode_return = 124.96, mean_episode_step = 706.16, total_loss = 186.02, pg_loss = 103.3, baseline_loss = 89.099, entropy_loss = -6.3773, learner_queue_size = 17, _tick = 23883, _time = 1.654e+09, train_seconds = 1.1513e+04)
[2022-05-31 17:22:19,742][root][INFO] - Step 76008960 @ 6650.6 SPS. Inference batcher size: 152. Learner queue size: 20. Other stats: (step = 76008960, mean_episode_return = 172.63, mean_episode_step = 806.02, total_loss = 42.526, pg_loss = 4.2281, baseline_loss = 44.79, entropy_loss = -6.4919, learner_queue_size = 17, _tick = 23895, _time = 1.654e+09, train_seconds = 1.1518e+04)
[2022-05-31 17:22:24,746][root][INFO] - Step 76039680 @ 6138.5 SPS. Inference batcher size: 196. Learner queue size: 21. Other stats: (step = 76039680, mean_episode_return = 269.89, mean_episode_step = 2359.2, total_loss = 232.47, pg_loss = -57.188, baseline_loss = 295.48, entropy_loss = -5.8181, learner_queue_size = 23, _tick = 23907, _time = 1.654e+09, train_seconds = 1.1523e+04)
[2022-05-31 17:22:29,753][root][INFO] - Step 76072960 @ 6647.7 SPS. Inference batcher size: 34. Learner queue size: 6. Other stats: (step = 76072960, mean_episode_return = 117.06, mean_episode_step = 667.96, total_loss = 626.65, pg_loss = 433.93, baseline_loss = 199.03, entropy_loss = -6.319, learner_queue_size = 5, _tick = 23919, _time = 1.654e+09, train_seconds = 1.1528e+04)
[2022-05-31 17:22:34,758][root][INFO] - Step 76106240 @ 6649.0 SPS. Inference batcher size: 39. Learner queue size: 6. Other stats: (step = 76106240, mean_episode_return = None, mean_episode_step = 726.06, total_loss = 332.65, pg_loss = 230.73, baseline_loss = 108.15, entropy_loss = -6.2305, learner_queue_size = 16, _tick = 23929, _time = 1.654e+09, train_seconds = 1.1533e+04)
[2022-05-31 17:22:39,766][root][INFO] - Step 76139520 @ 6645.3 SPS. Inference batcher size: 65. Learner queue size: 27. Other stats: (step = 76139520, mean_episode_return = 113.75, mean_episode_step = 1223.3, total_loss = -90.632, pg_loss = -102.69, baseline_loss = 18.631, entropy_loss = -6.5748, learner_queue_size = 16, _tick = 23941, _time = 1.654e+09, train_seconds = 1.1538e+04)
[2022-05-31 17:22:44,770][root][INFO] - Step 76172800 @ 6650.8 SPS. Inference batcher size: 109. Learner queue size: 18. Other stats: (step = 76172800, mean_episode_return = 138.34, mean_episode_step = 882.03, total_loss = 6.189, pg_loss = -51.402, baseline_loss = 64.379, entropy_loss = -6.7881, learner_queue_size = 14, _tick = 23953, _time = 1.654e+09, train_seconds = 1.1544e+04)
[2022-05-31 17:22:49,774][root][INFO] - Step 76206080 @ 6650.2 SPS. Inference batcher size: 4. Learner queue size: 5. Other stats: (step = 76206080, mean_episode_return = 393.56, mean_episode_step = 5920.3, total_loss = 267.79, pg_loss = 171.87, baseline_loss = 102.91, entropy_loss = -6.9941, learner_queue_size = 15, _tick = 23964, _time = 1.654e+09, train_seconds = 1.1548e+04)
[2022-05-31 17:22:54,781][root][INFO] - Step 76236800 @ 6136.2 SPS. Inference batcher size: 130. Learner queue size: 23. Other stats: (step = 76236800, mean_episode_return = 161.18, mean_episode_step = 817.4, total_loss = 159.54, pg_loss = 89.27, baseline_loss = 76.364, entropy_loss = -6.0942, learner_queue_size = 15, _tick = 23976, _time = 1.654e+09, train_seconds = 1.1554e+04)
[2022-05-31 17:22:59,787][root][INFO] - Step 76272640 @ 7159.3 SPS. Inference batcher size: 66. Learner queue size: 3. Other stats: (step = 76272640, mean_episode_return = 169.9, mean_episode_step = 624.33, total_loss = 146.17, pg_loss = 40.658, baseline_loss = 111.42, entropy_loss = -5.907, learner_queue_size = 15, _tick = 23989, _time = 1.654e+09, train_seconds = 1.1558e+04)
[2022-05-31 17:23:04,793][root][INFO] - Step 76303360 @ 6136.6 SPS. Inference batcher size: 64. Learner queue size: 24. Other stats: (step = 76303360, mean_episode_return = 140.23, mean_episode_step = 2599.6, total_loss = -168.98, pg_loss = -203.46, baseline_loss = 40.459, entropy_loss = -5.9762, learner_queue_size = 18, _tick = 24000, _time = 1.654e+09, train_seconds = 1.1564e+04)
[2022-05-31 17:23:09,799][root][INFO] - Step 76336640 @ 6648.0 SPS. Inference batcher size: 122. Learner queue size: 11. Other stats: (step = 76336640, mean_episode_return = 146.42, mean_episode_step = 781.44, total_loss = -12.429, pg_loss = -39.487, baseline_loss = 33.802, entropy_loss = -6.7435, learner_queue_size = 14, _tick = 24011, _time = 1.654e+09, train_seconds = 1.1568e+04)
[2022-05-31 17:23:14,805][root][INFO] - Step 76369920 @ 6648.0 SPS. Inference batcher size: 121. Learner queue size: 7. Other stats: (step = 76369920, mean_episode_return = 97.95, mean_episode_step = 724.34, total_loss = 137.79, pg_loss = 114.08, baseline_loss = 30.781, entropy_loss = -7.071, learner_queue_size = 19, _tick = 24021, _time = 1.654e+09, train_seconds = 1.1574e+04)
[2022-05-31 17:23:19,810][root][INFO] - Step 76403200 @ 6649.1 SPS. Inference batcher size: 93. Learner queue size: 31. Other stats: (step = 76403200, mean_episode_return = 246.36, mean_episode_step = 1202.9, total_loss = 46.575, pg_loss = -21.651, baseline_loss = 74.208, entropy_loss = -5.982, learner_queue_size = 17, _tick = 24033, _time = 1.654e+09, train_seconds = 1.1578e+04)
[2022-05-31 17:23:24,814][root][INFO] - Step 76436480 @ 6650.7 SPS. Inference batcher size: 66. Learner queue size: 31. Other stats: (step = 76436480, mean_episode_return = 314.03, mean_episode_step = 757.32, total_loss = 193.01, pg_loss = 53.534, baseline_loss = 145.22, entropy_loss = -5.7444, learner_queue_size = 20, _tick = 24043, _time = 1.654e+09, train_seconds = 1.1584e+04)
[2022-05-31 17:23:29,818][root][INFO] - Step 76467200 @ 6139.1 SPS. Inference batcher size: 69. Learner queue size: 9. Other stats: (step = 76467200, mean_episode_return = 107.81, mean_episode_step = 5781.8, total_loss = 131.0, pg_loss = 16.659, baseline_loss = 120.47, entropy_loss = -6.1265, learner_queue_size = 21, _tick = 24054, _time = 1.654e+09, train_seconds = 1.1588e+04)
[2022-05-31 17:23:34,822][root][INFO] - Step 76503040 @ 7162.2 SPS. Inference batcher size: 10. Learner queue size: 7. Other stats: (step = 76503040, mean_episode_return = 290.35, mean_episode_step = 959.65, total_loss = 104.86, pg_loss = 6.4324, baseline_loss = 104.82, entropy_loss = -6.3939, learner_queue_size = 7, _tick = 24068, _time = 1.654e+09, train_seconds = 1.1594e+04)
[2022-05-31 17:23:39,828][root][INFO] - Step 76533760 @ 6136.2 SPS. Inference batcher size: 103. Learner queue size: 14. Other stats: (step = 76533760, mean_episode_return = 187.75, mean_episode_step = 672.44, total_loss = 274.1, pg_loss = 114.18, baseline_loss = 165.92, entropy_loss = -6.0066, learner_queue_size = 18, _tick = 24079, _time = 1.654e+09, train_seconds = 1.1598e+04)
[2022-05-31 17:23:44,834][root][INFO] - Step 76567040 @ 6648.5 SPS. Inference batcher size: 103. Learner queue size: 9. Other stats: (step = 76567040, mean_episode_return = 174.29, mean_episode_step = 2953.2, total_loss = 86.067, pg_loss = -38.215, baseline_loss = 130.65, entropy_loss = -6.3704, learner_queue_size = 20, _tick = 24091, _time = 1.654e+09, train_seconds = 1.1604e+04)
[2022-05-31 17:23:49,838][root][INFO] - Step 76600320 @ 6650.7 SPS. Inference batcher size: 118. Learner queue size: 1. Other stats: (step = 76600320, mean_episode_return = 117.54, mean_episode_step = 643.0, total_loss = -104.23, pg_loss = -194.52, baseline_loss = 96.696, entropy_loss = -6.4081, learner_queue_size = 18, _tick = 24102, _time = 1.654e+09, train_seconds = 1.1608e+04)
[2022-05-31 17:23:54,844][root][INFO] - Step 76631040 @ 6136.6 SPS. Inference batcher size: 73. Learner queue size: 23. Other stats: (step = 76631040, mean_episode_return = 142.86, mean_episode_step = 1126.9, total_loss = 73.813, pg_loss = 7.4619, baseline_loss = 73.27, entropy_loss = -6.9192, learner_queue_size = 19, _tick = 24114, _time = 1.654e+09, train_seconds = 1.1614e+04)
[2022-05-31 17:23:59,850][root][INFO] - Step 76664320 @ 6648.0 SPS. Inference batcher size: 77. Learner queue size: 22. Other stats: (step = 76664320, mean_episode_return = 58.738, mean_episode_step = 705.97, total_loss = -57.261, pg_loss = -157.34, baseline_loss = 106.25, entropy_loss = -6.177, learner_queue_size = 12, _tick = 24126, _time = 1.654e+09, train_seconds = 1.1618e+04)
[2022-05-31 17:24:04,854][root][INFO] - Step 76697600 @ 6650.8 SPS. Inference batcher size: 92. Learner queue size: 8. Other stats: (step = 76697600, mean_episode_return = 16.37, mean_episode_step = 716.45, total_loss = 191.49, pg_loss = 75.767, baseline_loss = 121.97, entropy_loss = -6.2547, learner_queue_size = 18, _tick = 24139, _time = 1.654e+09, train_seconds = 1.1624e+04)
[2022-05-31 17:24:09,858][root][INFO] - Step 76730880 @ 6650.8 SPS. Inference batcher size: 139. Learner queue size: 11. Other stats: (step = 76730880, mean_episode_return = 263.24, mean_episode_step = 8057.9, total_loss = -71.467, pg_loss = -117.47, baseline_loss = 52.773, entropy_loss = -6.7693, learner_queue_size = 14, _tick = 24151, _time = 1.654e+09, train_seconds = 1.1628e+04)
[2022-05-31 17:24:14,862][root][INFO] - Step 76764160 @ 6650.6 SPS. Inference batcher size: 114. Learner queue size: 6. Other stats: (step = 76764160, mean_episode_return = 261.81, mean_episode_step = 695.33, total_loss = -235.33, pg_loss = -273.06, baseline_loss = 44.746, entropy_loss = -7.0097, learner_queue_size = 18, _tick = 24164, _time = 1.654e+09, train_seconds = 1.1634e+04)
[2022-05-31 17:24:19,866][root][INFO] - Step 76797440 @ 6650.8 SPS. Inference batcher size: 99. Learner queue size: 1. Other stats: (step = 76797440, mean_episode_return = 32.835, mean_episode_step = 730.28, total_loss = -16.183, pg_loss = -62.145, baseline_loss = 52.752, entropy_loss = -6.7898, learner_queue_size = 16, _tick = 24177, _time = 1.654e+09, train_seconds = 1.1639e+04)
[2022-05-31 17:24:24,870][root][INFO] - Step 76830720 @ 6650.6 SPS. Inference batcher size: 125. Learner queue size: 15. Other stats: (step = 76830720, mean_episode_return = 319.81, mean_episode_step = 2681.3, total_loss = -171.25, pg_loss = -220.84, baseline_loss = 55.866, entropy_loss = -6.2804, learner_queue_size = 11, _tick = 24189, _time = 1.654e+09, train_seconds = 1.1644e+04)
[2022-05-31 17:24:29,876][root][INFO] - Step 76861440 @ 6136.5 SPS. Inference batcher size: 138. Learner queue size: 13. Other stats: (step = 76861440, mean_episode_return = 92.061, mean_episode_step = 820.22, total_loss = -136.73, pg_loss = -152.6, baseline_loss = 22.534, entropy_loss = -6.6695, learner_queue_size = 15, _tick = 24199, _time = 1.654e+09, train_seconds = 1.1649e+04)
[2022-05-31 17:24:34,882][root][INFO] - Step 76894720 @ 6648.0 SPS. Inference batcher size: 147. Learner queue size: 17. Other stats: (step = 76894720, mean_episode_return = 228.43, mean_episode_step = 5851.9, total_loss = -174.09, pg_loss = -226.9, baseline_loss = 59.421, entropy_loss = -6.613, learner_queue_size = 21, _tick = 24212, _time = 1.654e+09, train_seconds = 1.1654e+04)
[2022-05-31 17:24:39,886][root][INFO] - Step 76928000 @ 6650.8 SPS. Inference batcher size: 128. Learner queue size: 9. Other stats: (step = 76928000, mean_episode_return = 26.301, mean_episode_step = 719.7, total_loss = -174.27, pg_loss = -194.85, baseline_loss = 27.296, entropy_loss = -6.7156, learner_queue_size = 23, _tick = 24222, _time = 1.654e+09, train_seconds = 1.1659e+04)
[2022-05-31 17:24:44,892][root][INFO] - Step 76961280 @ 6647.9 SPS. Inference batcher size: 191. Learner queue size: 2. Other stats: (step = 76961280, mean_episode_return = 55.963, mean_episode_step = 809.31, total_loss = 436.57, pg_loss = 257.41, baseline_loss = 185.35, entropy_loss = -6.1922, learner_queue_size = 25, _tick = 24235, _time = 1.654e+09, train_seconds = 1.1664e+04)
[2022-05-31 17:24:49,898][root][INFO] - Step 76994560 @ 6648.0 SPS. Inference batcher size: 135. Learner queue size: 5. Other stats: (step = 76994560, mean_episode_return = 11.02, mean_episode_step = 6546.1, total_loss = 22.889, pg_loss = -46.623, baseline_loss = 75.905, entropy_loss = -6.3928, learner_queue_size = 15, _tick = 24245, _time = 1.654e+09, train_seconds = 1.1669e+04)
[2022-05-31 17:24:54,902][root][INFO] - Step 77027840 @ 6650.8 SPS. Inference batcher size: 132. Learner queue size: 31. Other stats: (step = 77027840, mean_episode_return = 118.3, mean_episode_step = 835.73, total_loss = -123.81, pg_loss = -175.69, baseline_loss = 58.361, entropy_loss = -6.4779, learner_queue_size = 19, _tick = 24258, _time = 1.654e+09, train_seconds = 1.1674e+04)
[2022-05-31 17:24:59,906][root][INFO] - Step 77061120 @ 6650.7 SPS. Inference batcher size: 193. Learner queue size: 20. Other stats: (step = 77061120, mean_episode_return = 208.49, mean_episode_step = 754.76, total_loss = -3.4972, pg_loss = -77.143, baseline_loss = 79.727, entropy_loss = -6.0811, learner_queue_size = 19, _tick = 24270, _time = 1.654e+09, train_seconds = 1.1679e+04)
[2022-05-31 17:25:04,912][root][INFO] - Step 77091840 @ 6136.1 SPS. Inference batcher size: 118. Learner queue size: 14. Other stats: (step = 77091840, mean_episode_return = 143.61, mean_episode_step = 2510.6, total_loss = 414.95, pg_loss = 187.23, baseline_loss = 233.53, entropy_loss = -5.8062, learner_queue_size = 8, _tick = 24280, _time = 1.654e+09, train_seconds = 1.1684e+04)
[2022-05-31 17:25:09,918][root][INFO] - Step 77125120 @ 6648.0 SPS. Inference batcher size: 154. Learner queue size: 14. Other stats: (step = 77125120, mean_episode_return = 8.0797, mean_episode_step = 770.6, total_loss = 396.37, pg_loss = 264.41, baseline_loss = 138.22, entropy_loss = -6.2618, learner_queue_size = 23, _tick = 24293, _time = 1.654e+09, train_seconds = 1.1689e+04)
[2022-05-31 17:25:14,922][root][INFO] - Step 77158400 @ 6651.4 SPS. Inference batcher size: 96. Learner queue size: 11. Other stats: (step = 77158400, mean_episode_return = 62.09, mean_episode_step = 6018.1, total_loss = 280.83, pg_loss = 181.52, baseline_loss = 105.57, entropy_loss = -6.2657, learner_queue_size = 17, _tick = 24304, _time = 1.654e+09, train_seconds = 1.1694e+04)
[2022-05-31 17:25:19,926][root][INFO] - Step 77191680 @ 6650.6 SPS. Inference batcher size: 3. Learner queue size: 4. Other stats: (step = 77191680, mean_episode_return = 50.8, mean_episode_step = 746.37, total_loss = 48.603, pg_loss = -14.639, baseline_loss = 69.684, entropy_loss = -6.4422, learner_queue_size = 20, _tick = 24314, _time = 1.654e+09, train_seconds = 1.1699e+04)
[2022-05-31 17:25:24,933][root][INFO] - Step 77224960 @ 6647.4 SPS. Inference batcher size: 127. Learner queue size: 4. Other stats: (step = 77224960, mean_episode_return = None, mean_episode_step = 777.25, total_loss = 205.57, pg_loss = 146.43, baseline_loss = 65.838, entropy_loss = -6.7052, learner_queue_size = 11, _tick = 24325, _time = 1.654e+09, train_seconds = 1.1704e+04)
[2022-05-31 17:25:29,938][root][INFO] - Step 77258240 @ 6648.8 SPS. Inference batcher size: 113. Learner queue size: 3. Other stats: (step = 77258240, mean_episode_return = None, mean_episode_step = 6358.9, total_loss = 764.13, pg_loss = 377.02, baseline_loss = 393.57, entropy_loss = -6.4623, learner_queue_size = 20, _tick = 24336, _time = 1.654e+09, train_seconds = 1.1709e+04)
[2022-05-31 17:25:34,944][root][INFO] - Step 77291520 @ 6648.5 SPS. Inference batcher size: 125. Learner queue size: 4. Other stats: (step = 77291520, mean_episode_return = 83.507, mean_episode_step = 650.48, total_loss = 124.99, pg_loss = 64.361, baseline_loss = 66.866, entropy_loss = -6.2403, learner_queue_size = 21, _tick = 24348, _time = 1.654e+09, train_seconds = 1.1714e+04)
[2022-05-31 17:25:39,946][root][INFO] - Step 77324800 @ 6652.9 SPS. Inference batcher size: 131. Learner queue size: 16. Other stats: (step = 77324800, mean_episode_return = 89.91, mean_episode_step = 626.79, total_loss = 55.059, pg_loss = -38.719, baseline_loss = 99.949, entropy_loss = -6.1705, learner_queue_size = 11, _tick = 24358, _time = 1.654e+09, train_seconds = 1.1719e+04)
[2022-05-31 17:25:44,950][root][INFO] - Step 77358080 @ 6650.7 SPS. Inference batcher size: 86. Learner queue size: 17. Other stats: (step = 77358080, mean_episode_return = 135.52, mean_episode_step = 990.39, total_loss = 20.72, pg_loss = -47.46, baseline_loss = 74.15, entropy_loss = -5.9692, learner_queue_size = 16, _tick = 24370, _time = 1.654e+09, train_seconds = 1.1724e+04)
[2022-05-31 17:25:49,956][root][INFO] - Step 77388800 @ 6136.4 SPS. Inference batcher size: 176. Learner queue size: 14. Other stats: (step = 77388800, mean_episode_return = 49.23, mean_episode_step = 680.15, total_loss = 60.952, pg_loss = -10.725, baseline_loss = 77.755, entropy_loss = -6.0785, learner_queue_size = 26, _tick = 24381, _time = 1.654e+09, train_seconds = 1.1729e+04)
[2022-05-31 17:25:54,962][root][INFO] - Step 77422080 @ 6648.0 SPS. Inference batcher size: 108. Learner queue size: 15. Other stats: (step = 77422080, mean_episode_return = 138.98, mean_episode_step = 6231.5, total_loss = 204.99, pg_loss = 159.68, baseline_loss = 51.875, entropy_loss = -6.5677, learner_queue_size = 23, _tick = 24393, _time = 1.654e+09, train_seconds = 1.1734e+04)
[2022-05-31 17:25:59,968][root][INFO] - Step 77455360 @ 6648.0 SPS. Inference batcher size: 160. Learner queue size: 15. Other stats: (step = 77455360, mean_episode_return = 151.78, mean_episode_step = 963.18, total_loss = 150.48, pg_loss = 109.69, baseline_loss = 47.581, entropy_loss = -6.7938, learner_queue_size = 18, _tick = 24403, _time = 1.654e+09, train_seconds = 1.1739e+04)
[2022-05-31 17:26:04,974][root][INFO] - Step 77488640 @ 6648.2 SPS. Inference batcher size: 159. Learner queue size: 10. Other stats: (step = 77488640, mean_episode_return = 68.398, mean_episode_step = 729.64, total_loss = 201.45, pg_loss = 152.41, baseline_loss = 55.524, entropy_loss = -6.492, learner_queue_size = 15, _tick = 24414, _time = 1.654e+09, train_seconds = 1.1744e+04)
[2022-05-31 17:26:09,978][root][INFO] - Step 77521920 @ 6650.7 SPS. Inference batcher size: 131. Learner queue size: 1. Other stats: (step = 77521920, mean_episode_return = 135.9, mean_episode_step = 6255.1, total_loss = 64.892, pg_loss = 8.9108, baseline_loss = 62.349, entropy_loss = -6.3676, learner_queue_size = 19, _tick = 24425, _time = 1.654e+09, train_seconds = 1.1749e+04)
[2022-05-31 17:26:14,984][root][INFO] - Step 77555200 @ 6648.3 SPS. Inference batcher size: 138. Learner queue size: 3. Other stats: (step = 77555200, mean_episode_return = 123.95, mean_episode_step = 860.28, total_loss = 82.11, pg_loss = -70.774, baseline_loss = 158.36, entropy_loss = -5.4786, learner_queue_size = 25, _tick = 24437, _time = 1.654e+09, train_seconds = 1.1754e+04)
[2022-05-31 17:26:19,990][root][INFO] - Step 77585920 @ 6136.9 SPS. Inference batcher size: 92. Learner queue size: 15. Other stats: (step = 77585920, mean_episode_return = 119.58, mean_episode_step = 628.12, total_loss = 208.79, pg_loss = 146.6, baseline_loss = 68.293, entropy_loss = -6.1003, learner_queue_size = 17, _tick = 24449, _time = 1.654e+09, train_seconds = 1.1759e+04)
[2022-05-31 17:26:24,996][root][INFO] - Step 77619200 @ 6647.9 SPS. Inference batcher size: 51. Learner queue size: 18. Other stats: (step = 77619200, mean_episode_return = 231.39, mean_episode_step = 1209.8, total_loss = 212.84, pg_loss = 116.22, baseline_loss = 102.8, entropy_loss = -6.1741, learner_queue_size = 21, _tick = 24460, _time = 1.654e+09, train_seconds = 1.1764e+04)
[2022-05-31 17:26:29,998][root][INFO] - Step 77652480 @ 6653.0 SPS. Inference batcher size: 109. Learner queue size: 11. Other stats: (step = 77652480, mean_episode_return = 182.62, mean_episode_step = 749.79, total_loss = -38.212, pg_loss = -58.348, baseline_loss = 26.047, entropy_loss = -5.9107, learner_queue_size = 18, _tick = 24472, _time = 1.654e+09, train_seconds = 1.1769e+04)
[2022-05-31 17:26:35,005][root][INFO] - Step 77685760 @ 6646.8 SPS. Inference batcher size: 36. Learner queue size: 2. Other stats: (step = 77685760, mean_episode_return = None, mean_episode_step = 804.25, total_loss = -37.197, pg_loss = -48.519, baseline_loss = 17.511, entropy_loss = -6.1895, learner_queue_size = 13, _tick = 24482, _time = 1.654e+09, train_seconds = 1.1774e+04)
[2022-05-31 17:26:40,012][root][INFO] - Step 77719040 @ 6646.4 SPS. Inference batcher size: 23. Learner queue size: 9. Other stats: (step = 77719040, mean_episode_return = 56.995, mean_episode_step = 904.46, total_loss = 80.215, pg_loss = -25.757, baseline_loss = 111.95, entropy_loss = -5.9829, learner_queue_size = 24, _tick = 24495, _time = 1.654e+09, train_seconds = 1.1779e+04)
[2022-05-31 17:26:45,018][root][INFO] - Step 77752320 @ 6648.1 SPS. Inference batcher size: 83. Learner queue size: 19. Other stats: (step = 77752320, mean_episode_return = 176.69, mean_episode_step = 588.78, total_loss = -109.14, pg_loss = -213.55, baseline_loss = 110.79, entropy_loss = -6.3776, learner_queue_size = 18, _tick = 24506, _time = 1.654e+09, train_seconds = 1.1784e+04)
[2022-05-31 17:26:50,024][root][INFO] - Step 77783040 @ 6136.5 SPS. Inference batcher size: 109. Learner queue size: 17. Other stats: (step = 77783040, mean_episode_return = 196.86, mean_episode_step = 6329.1, total_loss = 22.796, pg_loss = -43.567, baseline_loss = 72.745, entropy_loss = -6.3816, learner_queue_size = 22, _tick = 24516, _time = 1.654e+09, train_seconds = 1.1789e+04)
[2022-05-31 17:26:55,030][root][INFO] - Step 77816320 @ 6648.0 SPS. Inference batcher size: 126. Learner queue size: 12. Other stats: (step = 77816320, mean_episode_return = 128.44, mean_episode_step = 735.16, total_loss = 104.09, pg_loss = 67.45, baseline_loss = 43.385, entropy_loss = -6.7494, learner_queue_size = 21, _tick = 24528, _time = 1.654e+09, train_seconds = 1.1794e+04)
[2022-05-31 17:27:00,034][root][INFO] - Step 77849600 @ 6650.9 SPS. Inference batcher size: 105. Learner queue size: 5. Other stats: (step = 77849600, mean_episode_return = 322.41, mean_episode_step = 767.04, total_loss = 87.929, pg_loss = 44.848, baseline_loss = 49.331, entropy_loss = -6.2494, learner_queue_size = 18, _tick = 24539, _time = 1.654e+09, train_seconds = 1.1799e+04)
[2022-05-31 17:27:05,038][root][INFO] - Step 77882880 @ 6650.8 SPS. Inference batcher size: 0. Learner queue size: 31. Other stats: (step = 77882880, mean_episode_return = 464.54, mean_episode_step = 662.04, total_loss = 497.63, pg_loss = 317.58, baseline_loss = 185.84, entropy_loss = -5.7885, learner_queue_size = 19, _tick = 24550, _time = 1.654e+09, train_seconds = 1.1804e+04)
[2022-05-31 17:27:10,042][root][INFO] - Step 77913600 @ 6138.9 SPS. Inference batcher size: 47. Learner queue size: 10. Other stats: (step = 77913600, mean_episode_return = 100.79, mean_episode_step = 515.99, total_loss = 169.19, pg_loss = 82.786, baseline_loss = 92.775, entropy_loss = -6.3711, learner_queue_size = 22, _tick = 24560, _time = 1.654e+09, train_seconds = 1.1809e+04)
[2022-05-31 17:27:15,048][root][INFO] - Step 77946880 @ 6648.0 SPS. Inference batcher size: 94. Learner queue size: 14. Other stats: (step = 77946880, mean_episode_return = 483.75, mean_episode_step = 5879.6, total_loss = -57.977, pg_loss = -152.77, baseline_loss = 101.13, entropy_loss = -6.342, learner_queue_size = 16, _tick = 24570, _time = 1.654e+09, train_seconds = 1.1814e+04)
[2022-05-31 17:27:20,054][root][INFO] - Step 77980160 @ 6648.1 SPS. Inference batcher size: 82. Learner queue size: 16. Other stats: (step = 77980160, mean_episode_return = 172.76, mean_episode_step = 556.35, total_loss = 745.2, pg_loss = 355.87, baseline_loss = 395.58, entropy_loss = -6.2475, learner_queue_size = 29, _tick = 24581, _time = 1.654e+09, train_seconds = 1.1819e+04)
[2022-05-31 17:27:25,058][root][INFO] - Step 78013440 @ 6650.7 SPS. Inference batcher size: 90. Learner queue size: 13. Other stats: (step = 78013440, mean_episode_return = 167.86, mean_episode_step = 757.11, total_loss = -178.43, pg_loss = -210.0, baseline_loss = 38.391, entropy_loss = -6.819, learner_queue_size = 21, _tick = 24592, _time = 1.654e+09, train_seconds = 1.1824e+04)
[2022-05-31 17:27:30,062][root][INFO] - Step 78046720 @ 6650.3 SPS. Inference batcher size: 136. Learner queue size: 17. Other stats: (step = 78046720, mean_episode_return = 186.39, mean_episode_step = 6007.6, total_loss = -10.099, pg_loss = -47.553, baseline_loss = 44.159, entropy_loss = -6.7043, learner_queue_size = 19, _tick = 24605, _time = 1.654e+09, train_seconds = 1.1829e+04)
[2022-05-31 17:27:35,066][root][INFO] - Step 78080000 @ 6651.1 SPS. Inference batcher size: 180. Learner queue size: 13. Other stats: (step = 78080000, mean_episode_return = 99.085, mean_episode_step = 716.24, total_loss = -18.054, pg_loss = -73.441, baseline_loss = 61.882, entropy_loss = -6.495, learner_queue_size = 23, _tick = 24616, _time = 1.654e+09, train_seconds = 1.1834e+04)
[2022-05-31 17:27:40,070][root][INFO] - Step 78113280 @ 6650.5 SPS. Inference batcher size: 35. Learner queue size: 12. Other stats: (step = 78113280, mean_episode_return = 140.66, mean_episode_step = 824.05, total_loss = 642.57, pg_loss = 489.18, baseline_loss = 159.73, entropy_loss = -6.3426, learner_queue_size = 18, _tick = 24627, _time = 1.654e+09, train_seconds = 1.1839e+04)
[2022-05-31 17:27:45,074][root][INFO] - Step 78146560 @ 6650.7 SPS. Inference batcher size: 108. Learner queue size: 27. Other stats: (step = 78146560, mean_episode_return = 80.464, mean_episode_step = 987.71, total_loss = -136.21, pg_loss = -166.47, baseline_loss = 36.445, entropy_loss = -6.1918, learner_queue_size = 12, _tick = 24638, _time = 1.654e+09, train_seconds = 1.1844e+04)
[2022-05-31 17:27:50,078][root][INFO] - Step 78177280 @ 6139.2 SPS. Inference batcher size: 154. Learner queue size: 18. Other stats: (step = 78177280, mean_episode_return = 136.28, mean_episode_step = 668.85, total_loss = 420.86, pg_loss = 290.9, baseline_loss = 136.73, entropy_loss = -6.7651, learner_queue_size = 16, _tick = 24649, _time = 1.654e+09, train_seconds = 1.1849e+04)
[2022-05-31 17:27:55,079][root][INFO] - Step 78210560 @ 6654.2 SPS. Inference batcher size: 101. Learner queue size: 19. Other stats: (step = 78210560, mean_episode_return = 104.6, mean_episode_step = 6005.4, total_loss = 24.503, pg_loss = -40.948, baseline_loss = 71.108, entropy_loss = -5.6579, learner_queue_size = 16, _tick = 24661, _time = 1.654e+09, train_seconds = 1.1854e+04)
[2022-05-31 17:28:00,085][root][INFO] - Step 78243840 @ 6647.9 SPS. Inference batcher size: 105. Learner queue size: 16. Other stats: (step = 78243840, mean_episode_return = 354.26, mean_episode_step = 625.07, total_loss = 114.15, pg_loss = -18.009, baseline_loss = 137.67, entropy_loss = -5.5205, learner_queue_size = 29, _tick = 24673, _time = 1.654e+09, train_seconds = 1.1859e+04)
[2022-05-31 17:28:05,091][root][INFO] - Step 78277120 @ 6647.9 SPS. Inference batcher size: 116. Learner queue size: 6. Other stats: (step = 78277120, mean_episode_return = 356.47, mean_episode_step = 587.22, total_loss = 36.349, pg_loss = -71.986, baseline_loss = 113.83, entropy_loss = -5.4927, learner_queue_size = 16, _tick = 24685, _time = 1.654e+09, train_seconds = 1.1864e+04)
[2022-05-31 17:28:10,094][root][INFO] - Step 78310400 @ 6652.7 SPS. Inference batcher size: 130. Learner queue size: 2. Other stats: (step = 78310400, mean_episode_return = 214.08, mean_episode_step = 836.28, total_loss = -88.311, pg_loss = -186.74, baseline_loss = 104.28, entropy_loss = -5.8525, learner_queue_size = 23, _tick = 24696, _time = 1.654e+09, train_seconds = 1.1869e+04)
[2022-05-31 17:28:15,095][root][INFO] - Step 78343680 @ 6654.2 SPS. Inference batcher size: 68. Learner queue size: 23. Other stats: (step = 78343680, mean_episode_return = 468.26, mean_episode_step = 533.68, total_loss = 174.37, pg_loss = 57.484, baseline_loss = 122.58, entropy_loss = -5.6903, learner_queue_size = 17, _tick = 24708, _time = 1.654e+09, train_seconds = 1.1874e+04)
[2022-05-31 17:28:20,098][root][INFO] - Step 78376960 @ 6652.3 SPS. Inference batcher size: 140. Learner queue size: 22. Other stats: (step = 78376960, mean_episode_return = 68.249, mean_episode_step = 899.29, total_loss = 326.35, pg_loss = 226.69, baseline_loss = 106.01, entropy_loss = -6.3467, learner_queue_size = 11, _tick = 24719, _time = 1.654e+09, train_seconds = 1.1879e+04)
[2022-05-31 17:28:25,102][root][INFO] - Step 78407680 @ 6139.1 SPS. Inference batcher size: 37. Learner queue size: 19. Other stats: (step = 78407680, mean_episode_return = 158.44, mean_episode_step = 871.82, total_loss = 685.33, pg_loss = 281.6, baseline_loss = 409.65, entropy_loss = -5.9168, learner_queue_size = 23, _tick = 24729, _time = 1.654e+09, train_seconds = 1.1884e+04)
[2022-05-31 17:28:30,108][root][INFO] - Step 78440960 @ 6647.4 SPS. Inference batcher size: 134. Learner queue size: 3. Other stats: (step = 78440960, mean_episode_return = 270.44, mean_episode_step = 604.36, total_loss = 253.29, pg_loss = 79.443, baseline_loss = 179.97, entropy_loss = -6.1229, learner_queue_size = 17, _tick = 24741, _time = 1.654e+09, train_seconds = 1.1889e+04)
[2022-05-31 17:28:35,114][root][INFO] - Step 78474240 @ 6647.9 SPS. Inference batcher size: 130. Learner queue size: 6. Other stats: (step = 78474240, mean_episode_return = 301.15, mean_episode_step = 5952.6, total_loss = 121.81, pg_loss = -48.039, baseline_loss = 175.85, entropy_loss = -5.9961, learner_queue_size = 22, _tick = 24753, _time = 1.654e+09, train_seconds = 1.1894e+04)
[2022-05-31 17:28:40,118][root][INFO] - Step 78507520 @ 6651.4 SPS. Inference batcher size: 62. Learner queue size: 1. Other stats: (step = 78507520, mean_episode_return = 108.73, mean_episode_step = 610.8, total_loss = 288.14, pg_loss = 199.95, baseline_loss = 94.248, entropy_loss = -6.0561, learner_queue_size = 25, _tick = 24765, _time = 1.654e+09, train_seconds = 1.1899e+04)
[2022-05-31 17:28:45,124][root][INFO] - Step 78540800 @ 6647.7 SPS. Inference batcher size: 106. Learner queue size: 3. Other stats: (step = 78540800, mean_episode_return = 201.62, mean_episode_step = 582.45, total_loss = 951.75, pg_loss = 680.3, baseline_loss = 277.36, entropy_loss = -5.9085, learner_queue_size = 17, _tick = 24777, _time = 1.654e+09, train_seconds = 1.1904e+04)
[2022-05-31 17:28:50,130][root][INFO] - Step 78574080 @ 6648.3 SPS. Inference batcher size: 129. Learner queue size: 1. Other stats: (step = 78574080, mean_episode_return = 251.21, mean_episode_step = 588.61, total_loss = 396.0, pg_loss = 221.87, baseline_loss = 180.05, entropy_loss = -5.9218, learner_queue_size = 18, _tick = 24788, _time = 1.654e+09, train_seconds = 1.1909e+04)
[2022-05-31 17:28:55,134][root][INFO] - Step 78607360 @ 6650.8 SPS. Inference batcher size: 97. Learner queue size: 18. Other stats: (step = 78607360, mean_episode_return = 190.81, mean_episode_step = 603.9, total_loss = -62.425, pg_loss = -128.7, baseline_loss = 72.198, entropy_loss = -5.9211, learner_queue_size = 17, _tick = 24800, _time = 1.654e+09, train_seconds = 1.1914e+04)
[2022-05-31 17:29:00,142][root][INFO] - Step 78640640 @ 6645.9 SPS. Inference batcher size: 108. Learner queue size: 1. Other stats: (step = 78640640, mean_episode_return = 128.53, mean_episode_step = 808.19, total_loss = 254.14, pg_loss = 140.92, baseline_loss = 119.29, entropy_loss = -6.0653, learner_queue_size = 23, _tick = 24813, _time = 1.654e+09, train_seconds = 1.1919e+04)
[2022-05-31 17:29:05,146][root][INFO] - Step 78673920 @ 6650.2 SPS. Inference batcher size: 98. Learner queue size: 27. Other stats: (step = 78673920, mean_episode_return = 241.67, mean_episode_step = 825.84, total_loss = 123.73, pg_loss = -78.822, baseline_loss = 207.93, entropy_loss = -5.3731, learner_queue_size = 10, _tick = 24824, _time = 1.654e+09, train_seconds = 1.1924e+04)
[2022-05-31 17:29:10,150][root][INFO] - Step 78707200 @ 6650.6 SPS. Inference batcher size: 30. Learner queue size: 24. Other stats: (step = 78707200, mean_episode_return = 31.58, mean_episode_step = 688.93, total_loss = 416.7, pg_loss = 187.44, baseline_loss = 235.39, entropy_loss = -6.1423, learner_queue_size = 14, _tick = 24837, _time = 1.654e+09, train_seconds = 1.1929e+04)
[2022-05-31 17:29:15,155][root][INFO] - Step 78740480 @ 6649.9 SPS. Inference batcher size: 58. Learner queue size: 27. Other stats: (step = 78740480, mean_episode_return = 237.62, mean_episode_step = 922.41, total_loss = 368.45, pg_loss = 254.04, baseline_loss = 120.25, entropy_loss = -5.842, learner_queue_size = 27, _tick = 24849, _time = 1.654e+09, train_seconds = 1.1934e+04)
[2022-05-31 17:29:20,158][root][INFO] - Step 78773760 @ 6651.1 SPS. Inference batcher size: 9. Learner queue size: 17. Other stats: (step = 78773760, mean_episode_return = 199.85, mean_episode_step = 759.73, total_loss = 678.97, pg_loss = 357.8, baseline_loss = 327.31, entropy_loss = -6.1377, learner_queue_size = 17, _tick = 24861, _time = 1.654e+09, train_seconds = 1.1939e+04)
[2022-05-31 17:29:25,162][root][INFO] - Step 78807040 @ 6651.0 SPS. Inference batcher size: 157. Learner queue size: 29. Other stats: (step = 78807040, mean_episode_return = 76.315, mean_episode_step = 794.59, total_loss = 50.532, pg_loss = -10.562, baseline_loss = 67.52, entropy_loss = -6.4257, learner_queue_size = 24, _tick = 24873, _time = 1.654e+09, train_seconds = 1.1944e+04)
[2022-05-31 17:29:30,166][root][INFO] - Step 78837760 @ 6139.2 SPS. Inference batcher size: 49. Learner queue size: 21. Other stats: (step = 78837760, mean_episode_return = 216.45, mean_episode_step = 725.33, total_loss = -69.025, pg_loss = -110.56, baseline_loss = 48.001, entropy_loss = -6.4607, learner_queue_size = 18, _tick = 24885, _time = 1.654e+09, train_seconds = 1.1949e+04)
[2022-05-31 17:29:35,172][root][INFO] - Step 78871040 @ 6648.3 SPS. Inference batcher size: 93. Learner queue size: 15. Other stats: (step = 78871040, mean_episode_return = 83.449, mean_episode_step = 818.15, total_loss = 18.669, pg_loss = -44.844, baseline_loss = 70.206, entropy_loss = -6.6924, learner_queue_size = 10, _tick = 24898, _time = 1.654e+09, train_seconds = 1.1954e+04)
[2022-05-31 17:29:40,175][root][INFO] - Step 78904320 @ 6652.3 SPS. Inference batcher size: 135. Learner queue size: 21. Other stats: (step = 78904320, mean_episode_return = None, mean_episode_step = 1071.9, total_loss = -25.652, pg_loss = -37.361, baseline_loss = 18.477, entropy_loss = -6.7683, learner_queue_size = 25, _tick = 24909, _time = 1.654e+09, train_seconds = 1.1959e+04)
[2022-05-31 17:29:45,178][root][INFO] - Step 78937600 @ 6651.1 SPS. Inference batcher size: 2. Learner queue size: 11. Other stats: (step = 78937600, mean_episode_return = 162.26, mean_episode_step = 889.51, total_loss = 175.66, pg_loss = 127.06, baseline_loss = 55.075, entropy_loss = -6.4728, learner_queue_size = 15, _tick = 24920, _time = 1.654e+09, train_seconds = 1.1964e+04)
[2022-05-31 17:29:50,189][root][INFO] - Step 78970880 @ 6642.2 SPS. Inference batcher size: 136. Learner queue size: 12. Other stats: (step = 78970880, mean_episode_return = 264.57, mean_episode_step = 827.55, total_loss = 149.54, pg_loss = -21.139, baseline_loss = 177.02, entropy_loss = -6.3395, learner_queue_size = 22, _tick = 24929, _time = 1.654e+09, train_seconds = 1.1969e+04)
[2022-05-31 17:29:55,194][root][INFO] - Step 79004160 @ 6648.8 SPS. Inference batcher size: 169. Learner queue size: 16. Other stats: (step = 79004160, mean_episode_return = None, mean_episode_step = 1223.7, total_loss = 179.89, pg_loss = 107.26, baseline_loss = 79.007, entropy_loss = -6.3757, learner_queue_size = 20, _tick = 24940, _time = 1.654e+09, train_seconds = 1.1974e+04)
[2022-05-31 17:30:00,198][root][INFO] - Step 79037440 @ 6650.7 SPS. Inference batcher size: 95. Learner queue size: 1. Other stats: (step = 79037440, mean_episode_return = 181.64, mean_episode_step = 760.86, total_loss = -84.605, pg_loss = -96.764, baseline_loss = 18.539, entropy_loss = -6.3807, learner_queue_size = 15, _tick = 24951, _time = 1.654e+09, train_seconds = 1.1979e+04)
[2022-05-31 17:30:05,204][root][INFO] - Step 79070720 @ 6648.3 SPS. Inference batcher size: 79. Learner queue size: 5. Other stats: (step = 79070720, mean_episode_return = 190.05, mean_episode_step = 615.03, total_loss = 389.95, pg_loss = 279.14, baseline_loss = 116.69, entropy_loss = -5.8756, learner_queue_size = 21, _tick = 24962, _time = 1.654e+09, train_seconds = 1.1984e+04)
[2022-05-31 17:30:10,206][root][INFO] - Step 79104000 @ 6653.2 SPS. Inference batcher size: 56. Learner queue size: 27. Other stats: (step = 79104000, mean_episode_return = None, mean_episode_step = 6213.4, total_loss = 333.53, pg_loss = 200.66, baseline_loss = 138.71, entropy_loss = -5.834, learner_queue_size = 20, _tick = 24974, _time = 1.654e+09, train_seconds = 1.1989e+04)
[2022-05-31 17:30:15,210][root][INFO] - Step 79137280 @ 6650.7 SPS. Inference batcher size: 40. Learner queue size: 30. Other stats: (step = 79137280, mean_episode_return = 117.24, mean_episode_step = 511.49, total_loss = 161.67, pg_loss = -19.85, baseline_loss = 187.06, entropy_loss = -5.5377, learner_queue_size = 17, _tick = 24986, _time = 1.654e+09, train_seconds = 1.1994e+04)
[2022-05-31 17:30:20,217][root][INFO] - Step 79168000 @ 6135.4 SPS. Inference batcher size: 152. Learner queue size: 26. Other stats: (step = 79168000, mean_episode_return = 141.72, mean_episode_step = 567.64, total_loss = 128.6, pg_loss = 47.406, baseline_loss = 87.061, entropy_loss = -5.87, learner_queue_size = 22, _tick = 24997, _time = 1.654e+09, train_seconds = 1.1999e+04)
[2022-05-31 17:30:25,223][root][INFO] - Step 79201280 @ 6648.1 SPS. Inference batcher size: 148. Learner queue size: 8. Other stats: (step = 79201280, mean_episode_return = 65.457, mean_episode_step = 679.38, total_loss = 215.47, pg_loss = -188.88, baseline_loss = 410.12, entropy_loss = -5.7686, learner_queue_size = 26, _tick = 25009, _time = 1.654e+09, train_seconds = 1.2004e+04)
[2022-05-31 17:30:30,226][root][INFO] - Step 79234560 @ 6651.8 SPS. Inference batcher size: 80. Learner queue size: 16. Other stats: (step = 79234560, mean_episode_return = 123.19, mean_episode_step = 675.88, total_loss = -84.239, pg_loss = -123.86, baseline_loss = 46.314, entropy_loss = -6.6923, learner_queue_size = 19, _tick = 25022, _time = 1.654e+09, train_seconds = 1.2009e+04)
[2022-05-31 17:30:35,232][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 17:30:35,325][root][INFO] - Step 79267840 @ 6648.1 SPS. Inference batcher size: 13. Learner queue size: 9. Other stats: (step = 79267840, mean_episode_return = 150.36, mean_episode_step = 631.99, total_loss = -197.23, pg_loss = -252.11, baseline_loss = 61.181, entropy_loss = -6.304, learner_queue_size = 17, _tick = 25034, _time = 1.654e+09, train_seconds = 1.2014e+04)
[2022-05-31 17:30:40,330][root][INFO] - Step 79301120 @ 6528.1 SPS. Inference batcher size: 45. Learner queue size: 3. Other stats: (step = 79301120, mean_episode_return = 78.73, mean_episode_step = 717.89, total_loss = -79.186, pg_loss = -91.518, baseline_loss = 18.322, entropy_loss = -5.9899, learner_queue_size = 17, _tick = 25047, _time = 1.654e+09, train_seconds = 1.2019e+04)
[2022-05-31 17:30:45,334][root][INFO] - Step 79334400 @ 6650.6 SPS. Inference batcher size: 100. Learner queue size: 24. Other stats: (step = 79334400, mean_episode_return = 222.66, mean_episode_step = 583.36, total_loss = 131.75, pg_loss = 57.469, baseline_loss = 79.963, entropy_loss = -5.6806, learner_queue_size = 12, _tick = 25059, _time = 1.654e+09, train_seconds = 1.2024e+04)
[2022-05-31 17:30:50,340][root][INFO] - Step 79367680 @ 6648.1 SPS. Inference batcher size: 124. Learner queue size: 15. Other stats: (step = 79367680, mean_episode_return = 89.095, mean_episode_step = 698.8, total_loss = 17.82, pg_loss = -45.365, baseline_loss = 68.861, entropy_loss = -5.6765, learner_queue_size = 15, _tick = 25070, _time = 1.654e+09, train_seconds = 1.2029e+04)
[2022-05-31 17:30:55,346][root][INFO] - Step 79398400 @ 6137.1 SPS. Inference batcher size: 93. Learner queue size: 15. Other stats: (step = 79398400, mean_episode_return = 69.811, mean_episode_step = 757.35, total_loss = -413.64, pg_loss = -437.87, baseline_loss = 30.448, entropy_loss = -6.2212, learner_queue_size = 24, _tick = 25080, _time = 1.654e+09, train_seconds = 1.2034e+04)
[2022-05-31 17:31:00,350][root][INFO] - Step 79431680 @ 6649.6 SPS. Inference batcher size: 6. Learner queue size: 15. Other stats: (step = 79431680, mean_episode_return = 175.0, mean_episode_step = 982.16, total_loss = 122.19, pg_loss = 28.813, baseline_loss = 99.714, entropy_loss = -6.3397, learner_queue_size = 18, _tick = 25091, _time = 1.654e+09, train_seconds = 1.2039e+04)
[2022-05-31 17:31:05,354][root][INFO] - Step 79464960 @ 6651.3 SPS. Inference batcher size: 15. Learner queue size: 6. Other stats: (step = 79464960, mean_episode_return = 148.64, mean_episode_step = 543.28, total_loss = 60.345, pg_loss = -5.1983, baseline_loss = 71.662, entropy_loss = -6.1182, learner_queue_size = 18, _tick = 25104, _time = 1.654e+09, train_seconds = 1.2044e+04)
[2022-05-31 17:31:10,358][root][INFO] - Step 79498240 @ 6650.7 SPS. Inference batcher size: 66. Learner queue size: 30. Other stats: (step = 79498240, mean_episode_return = 199.05, mean_episode_step = 800.59, total_loss = 165.14, pg_loss = 97.35, baseline_loss = 74.155, entropy_loss = -6.3698, learner_queue_size = 19, _tick = 25115, _time = 1.654e+09, train_seconds = 1.2049e+04)
[2022-05-31 17:31:15,362][root][INFO] - Step 79531520 @ 6650.7 SPS. Inference batcher size: 151. Learner queue size: 18. Other stats: (step = 79531520, mean_episode_return = 173.04, mean_episode_step = 1187.6, total_loss = 184.68, pg_loss = 136.23, baseline_loss = 54.82, entropy_loss = -6.3752, learner_queue_size = 8, _tick = 25127, _time = 1.654e+09, train_seconds = 1.2054e+04)
[2022-05-31 17:31:20,366][root][INFO] - Step 79562240 @ 6139.0 SPS. Inference batcher size: 96. Learner queue size: 30. Other stats: (step = 79562240, mean_episode_return = None, mean_episode_step = 665.84, total_loss = 3.5569, pg_loss = -48.771, baseline_loss = 58.837, entropy_loss = -6.5092, learner_queue_size = 19, _tick = 25138, _time = 1.654e+09, train_seconds = 1.2059e+04)
[2022-05-31 17:31:25,370][root][INFO] - Step 79595520 @ 6650.8 SPS. Inference batcher size: 130. Learner queue size: 12. Other stats: (step = 79595520, mean_episode_return = 181.49, mean_episode_step = 671.23, total_loss = -145.64, pg_loss = -182.14, baseline_loss = 42.998, entropy_loss = -6.5, learner_queue_size = 28, _tick = 25151, _time = 1.654e+09, train_seconds = 1.2064e+04)
[2022-05-31 17:31:30,376][root][INFO] - Step 79628800 @ 6647.5 SPS. Inference batcher size: 64. Learner queue size: 3. Other stats: (step = 79628800, mean_episode_return = 299.03, mean_episode_step = 5950.4, total_loss = 160.85, pg_loss = 79.417, baseline_loss = 87.171, entropy_loss = -5.7421, learner_queue_size = 16, _tick = 25163, _time = 1.654e+09, train_seconds = 1.2069e+04)
[2022-05-31 17:31:35,382][root][INFO] - Step 79662080 @ 6648.0 SPS. Inference batcher size: 101. Learner queue size: 31. Other stats: (step = 79662080, mean_episode_return = 66.72, mean_episode_step = 687.27, total_loss = 99.292, pg_loss = 65.958, baseline_loss = 39.036, entropy_loss = -5.7026, learner_queue_size = 22, _tick = 25176, _time = 1.654e+09, train_seconds = 1.2074e+04)
[2022-05-31 17:31:40,386][root][INFO] - Step 79695360 @ 6651.2 SPS. Inference batcher size: 67. Learner queue size: 18. Other stats: (step = 79695360, mean_episode_return = 60.802, mean_episode_step = 869.8, total_loss = -82.681, pg_loss = -110.24, baseline_loss = 33.197, entropy_loss = -5.6327, learner_queue_size = 15, _tick = 25189, _time = 1.654e+09, train_seconds = 1.2079e+04)
[2022-05-31 17:31:45,392][root][INFO] - Step 79726080 @ 6136.3 SPS. Inference batcher size: 6. Learner queue size: 18. Other stats: (step = 79726080, mean_episode_return = 235.26, mean_episode_step = 535.83, total_loss = -225.77, pg_loss = -278.76, baseline_loss = 58.756, entropy_loss = -5.7609, learner_queue_size = 23, _tick = 25200, _time = 1.654e+09, train_seconds = 1.2084e+04)
[2022-05-31 17:31:50,398][root][INFO] - Step 79759360 @ 6648.0 SPS. Inference batcher size: 129. Learner queue size: 18. Other stats: (step = 79759360, mean_episode_return = 109.47, mean_episode_step = 632.11, total_loss = 616.16, pg_loss = 311.02, baseline_loss = 310.87, entropy_loss = -5.7374, learner_queue_size = 26, _tick = 25213, _time = 1.654e+09, train_seconds = 1.2089e+04)
[2022-05-31 17:31:55,404][root][INFO] - Step 79792640 @ 6648.0 SPS. Inference batcher size: 98. Learner queue size: 12. Other stats: (step = 79792640, mean_episode_return = None, mean_episode_step = 6064.1, total_loss = 83.095, pg_loss = -6.0013, baseline_loss = 95.286, entropy_loss = -6.1895, learner_queue_size = 22, _tick = 25224, _time = 1.654e+09, train_seconds = 1.2094e+04)
[2022-05-31 17:32:00,410][root][INFO] - Step 79825920 @ 6648.3 SPS. Inference batcher size: 84. Learner queue size: 12. Other stats: (step = 79825920, mean_episode_return = 166.39, mean_episode_step = 721.82, total_loss = 7.5667, pg_loss = -77.557, baseline_loss = 91.127, entropy_loss = -6.0032, learner_queue_size = 27, _tick = 25234, _time = 1.654e+09, train_seconds = 1.2099e+04)
[2022-05-31 17:32:05,414][root][INFO] - Step 79859200 @ 6650.8 SPS. Inference batcher size: 83. Learner queue size: 26. Other stats: (step = 79859200, mean_episode_return = 325.94, mean_episode_step = 803.62, total_loss = 28.539, pg_loss = -20.803, baseline_loss = 55.604, entropy_loss = -6.2623, learner_queue_size = 18, _tick = 25246, _time = 1.654e+09, train_seconds = 1.2104e+04)
[2022-05-31 17:32:10,418][root][INFO] - Step 79892480 @ 6650.7 SPS. Inference batcher size: 127. Learner queue size: 29. Other stats: (step = 79892480, mean_episode_return = None, mean_episode_step = 6150.5, total_loss = 293.97, pg_loss = 240.67, baseline_loss = 59.623, entropy_loss = -6.3258, learner_queue_size = 24, _tick = 25256, _time = 1.654e+09, train_seconds = 1.2109e+04)
[2022-05-31 17:32:15,424][root][INFO] - Step 79923200 @ 6136.6 SPS. Inference batcher size: 105. Learner queue size: 21. Other stats: (step = 79923200, mean_episode_return = 107.82, mean_episode_step = 697.32, total_loss = 94.378, pg_loss = 5.3566, baseline_loss = 94.643, entropy_loss = -5.6212, learner_queue_size = 14, _tick = 25268, _time = 1.654e+09, train_seconds = 1.2114e+04)
[2022-05-31 17:32:20,430][root][INFO] - Step 79956480 @ 6648.0 SPS. Inference batcher size: 135. Learner queue size: 14. Other stats: (step = 79956480, mean_episode_return = 143.04, mean_episode_step = 1256.9, total_loss = -76.152, pg_loss = -139.99, baseline_loss = 69.913, entropy_loss = -6.0722, learner_queue_size = 10, _tick = 25281, _time = 1.654e+09, train_seconds = 1.2119e+04)
[2022-05-31 17:32:25,434][root][INFO] - Step 79989760 @ 6650.7 SPS. Inference batcher size: 94. Learner queue size: 15. Other stats: (step = 79989760, mean_episode_return = 73.587, mean_episode_step = 760.42, total_loss = 115.52, pg_loss = 23.16, baseline_loss = 97.925, entropy_loss = -5.5661, learner_queue_size = 15, _tick = 25293, _time = 1.654e+09, train_seconds = 1.2124e+04)
[2022-05-31 17:32:30,438][root][INFO] - Step 80023040 @ 6650.7 SPS. Inference batcher size: 153. Learner queue size: 8. Other stats: (step = 80023040, mean_episode_return = 163.37, mean_episode_step = 819.96, total_loss = 235.52, pg_loss = 137.02, baseline_loss = 104.73, entropy_loss = -6.2221, learner_queue_size = 23, _tick = 25303, _time = 1.654e+09, train_seconds = 1.2129e+04)
[2022-05-31 17:32:35,442][root][INFO] - Step 80056320 @ 6650.6 SPS. Inference batcher size: 106. Learner queue size: 6. Other stats: (step = 80056320, mean_episode_return = 343.08, mean_episode_step = 637.33, total_loss = 138.54, pg_loss = 67.567, baseline_loss = 77.567, entropy_loss = -6.5895, learner_queue_size = 24, _tick = 25314, _time = 1.654e+09, train_seconds = 1.2134e+04)
[2022-05-31 17:32:40,448][root][INFO] - Step 80089600 @ 6648.3 SPS. Inference batcher size: 94. Learner queue size: 6. Other stats: (step = 80089600, mean_episode_return = 78.645, mean_episode_step = 787.15, total_loss = -116.01, pg_loss = -135.34, baseline_loss = 25.71, entropy_loss = -6.3825, learner_queue_size = 26, _tick = 25325, _time = 1.654e+09, train_seconds = 1.2139e+04)
[2022-05-31 17:32:45,450][root][INFO] - Step 80122880 @ 6653.2 SPS. Inference batcher size: 117. Learner queue size: 1. Other stats: (step = 80122880, mean_episode_return = 315.91, mean_episode_step = 796.16, total_loss = 200.01, pg_loss = -10.53, baseline_loss = 216.89, entropy_loss = -6.3498, learner_queue_size = 16, _tick = 25336, _time = 1.654e+09, train_seconds = 1.2144e+04)
[2022-05-31 17:32:50,454][root][INFO] - Step 80156160 @ 6650.6 SPS. Inference batcher size: 68. Learner queue size: 26. Other stats: (step = 80156160, mean_episode_return = 534.72, mean_episode_step = 6250.0, total_loss = 228.55, pg_loss = 119.91, baseline_loss = 114.9, entropy_loss = -6.2519, learner_queue_size = 19, _tick = 25349, _time = 1.654e+09, train_seconds = 1.2149e+04)
[2022-05-31 17:32:55,459][root][INFO] - Step 80186880 @ 6137.7 SPS. Inference batcher size: 133. Learner queue size: 17. Other stats: (step = 80186880, mean_episode_return = 182.16, mean_episode_step = 824.56, total_loss = -109.64, pg_loss = -173.23, baseline_loss = 69.779, entropy_loss = -6.1924, learner_queue_size = 22, _tick = 25360, _time = 1.654e+09, train_seconds = 1.2154e+04)
[2022-05-31 17:33:00,465][root][INFO] - Step 80220160 @ 6648.0 SPS. Inference batcher size: 137. Learner queue size: 14. Other stats: (step = 80220160, mean_episode_return = 14.67, mean_episode_step = 1288.4, total_loss = -26.525, pg_loss = -82.586, baseline_loss = 62.149, entropy_loss = -6.0874, learner_queue_size = 18, _tick = 25372, _time = 1.654e+09, train_seconds = 1.2159e+04)
[2022-05-31 17:33:05,470][root][INFO] - Step 80253440 @ 6649.5 SPS. Inference batcher size: 139. Learner queue size: 14. Other stats: (step = 80253440, mean_episode_return = 341.68, mean_episode_step = 893.95, total_loss = 110.26, pg_loss = 66.331, baseline_loss = 50.237, entropy_loss = -6.3118, learner_queue_size = 21, _tick = 25384, _time = 1.654e+09, train_seconds = 1.2164e+04)
[2022-05-31 17:33:10,476][root][INFO] - Step 80286720 @ 6647.9 SPS. Inference batcher size: 136. Learner queue size: 1. Other stats: (step = 80286720, mean_episode_return = 99.535, mean_episode_step = 687.4, total_loss = 514.95, pg_loss = 336.54, baseline_loss = 184.69, entropy_loss = -6.2845, learner_queue_size = 16, _tick = 25394, _time = 1.654e+09, train_seconds = 1.2169e+04)
[2022-05-31 17:33:15,482][root][INFO] - Step 80320000 @ 6648.2 SPS. Inference batcher size: 91. Learner queue size: 6. Other stats: (step = 80320000, mean_episode_return = 127.11, mean_episode_step = 6362.0, total_loss = 5.8333, pg_loss = -30.611, baseline_loss = 43.057, entropy_loss = -6.613, learner_queue_size = 17, _tick = 25404, _time = 1.654e+09, train_seconds = 1.2174e+04)
[2022-05-31 17:33:20,488][root][INFO] - Step 80353280 @ 6647.4 SPS. Inference batcher size: 133. Learner queue size: 4. Other stats: (step = 80353280, mean_episode_return = 199.79, mean_episode_step = 760.73, total_loss = 196.49, pg_loss = 112.64, baseline_loss = 90.609, entropy_loss = -6.7579, learner_queue_size = 26, _tick = 25416, _time = 1.654e+09, train_seconds = 1.2179e+04)
[2022-05-31 17:33:25,494][root][INFO] - Step 80386560 @ 6648.6 SPS. Inference batcher size: 76. Learner queue size: 29. Other stats: (step = 80386560, mean_episode_return = 114.45, mean_episode_step = 620.19, total_loss = 135.92, pg_loss = 4.1253, baseline_loss = 137.95, entropy_loss = -6.1646, learner_queue_size = 22, _tick = 25426, _time = 1.654e+09, train_seconds = 1.2184e+04)
[2022-05-31 17:33:30,500][root][INFO] - Step 80419840 @ 6648.0 SPS. Inference batcher size: 98. Learner queue size: 29. Other stats: (step = 80419840, mean_episode_return = 243.74, mean_episode_step = 6612.0, total_loss = 275.59, pg_loss = 129.83, baseline_loss = 152.76, entropy_loss = -7.0019, learner_queue_size = 21, _tick = 25438, _time = 1.654e+09, train_seconds = 1.2189e+04)
[2022-05-31 17:33:35,506][root][INFO] - Step 80450560 @ 6136.7 SPS. Inference batcher size: 182. Learner queue size: 19. Other stats: (step = 80450560, mean_episode_return = 386.69, mean_episode_step = 727.14, total_loss = -192.9, pg_loss = -328.79, baseline_loss = 142.19, entropy_loss = -6.2967, learner_queue_size = 12, _tick = 25450, _time = 1.654e+09, train_seconds = 1.2194e+04)
[2022-05-31 17:33:40,510][root][INFO] - Step 80483840 @ 6650.7 SPS. Inference batcher size: 73. Learner queue size: 15. Other stats: (step = 80483840, mean_episode_return = 191.93, mean_episode_step = 911.56, total_loss = -77.127, pg_loss = -112.57, baseline_loss = 42.64, entropy_loss = -7.2, learner_queue_size = 14, _tick = 25462, _time = 1.654e+09, train_seconds = 1.2199e+04)
[2022-05-31 17:33:45,514][root][INFO] - Step 80517120 @ 6650.6 SPS. Inference batcher size: 103. Learner queue size: 12. Other stats: (step = 80517120, mean_episode_return = 79.375, mean_episode_step = 752.93, total_loss = 265.79, pg_loss = 142.02, baseline_loss = 130.66, entropy_loss = -6.8894, learner_queue_size = 21, _tick = 25472, _time = 1.654e+09, train_seconds = 1.2204e+04)
[2022-05-31 17:33:50,518][root][INFO] - Step 80550400 @ 6650.5 SPS. Inference batcher size: 20. Learner queue size: 7. Other stats: (step = 80550400, mean_episode_return = 117.08, mean_episode_step = 889.84, total_loss = 135.44, pg_loss = 70.537, baseline_loss = 71.864, entropy_loss = -6.9662, learner_queue_size = 7, _tick = 25482, _time = 1.654e+09, train_seconds = 1.2209e+04)
[2022-05-31 17:33:55,522][root][INFO] - Step 80583680 @ 6650.9 SPS. Inference batcher size: 170. Learner queue size: 5. Other stats: (step = 80583680, mean_episode_return = 194.4, mean_episode_step = 688.88, total_loss = 156.26, pg_loss = 10.192, baseline_loss = 152.04, entropy_loss = -5.9721, learner_queue_size = 24, _tick = 25494, _time = 1.654e+09, train_seconds = 1.2214e+04)
[2022-05-31 17:34:00,526][root][INFO] - Step 80616960 @ 6650.7 SPS. Inference batcher size: 136. Learner queue size: 31. Other stats: (step = 80616960, mean_episode_return = 124.41, mean_episode_step = 825.99, total_loss = 550.68, pg_loss = 361.56, baseline_loss = 195.8, entropy_loss = -6.6799, learner_queue_size = 31, _tick = 25506, _time = 1.654e+09, train_seconds = 1.2219e+04)
[2022-05-31 17:34:05,530][root][INFO] - Step 80650240 @ 6650.5 SPS. Inference batcher size: 64. Learner queue size: 24. Other stats: (step = 80650240, mean_episode_return = 301.83, mean_episode_step = 822.01, total_loss = 34.44, pg_loss = -118.56, baseline_loss = 159.52, entropy_loss = -6.5215, learner_queue_size = 24, _tick = 25519, _time = 1.654e+09, train_seconds = 1.2224e+04)
[2022-05-31 17:34:10,538][root][INFO] - Step 80683520 @ 6646.2 SPS. Inference batcher size: 80. Learner queue size: 22. Other stats: (step = 80683520, mean_episode_return = 113.21, mean_episode_step = 6638.9, total_loss = -274.96, pg_loss = -296.74, baseline_loss = 28.887, entropy_loss = -7.112, learner_queue_size = 20, _tick = 25532, _time = 1.654e+09, train_seconds = 1.2229e+04)
[2022-05-31 17:34:15,544][root][INFO] - Step 80714240 @ 6136.1 SPS. Inference batcher size: 143. Learner queue size: 16. Other stats: (step = 80714240, mean_episode_return = 302.17, mean_episode_step = 713.94, total_loss = 17.319, pg_loss = -75.628, baseline_loss = 100.0, entropy_loss = -7.0537, learner_queue_size = 19, _tick = 25544, _time = 1.654e+09, train_seconds = 1.2234e+04)
[2022-05-31 17:34:20,550][root][INFO] - Step 80747520 @ 6648.0 SPS. Inference batcher size: 130. Learner queue size: 22. Other stats: (step = 80747520, mean_episode_return = 106.66, mean_episode_step = 776.54, total_loss = -36.17, pg_loss = -55.766, baseline_loss = 26.661, entropy_loss = -7.0641, learner_queue_size = 11, _tick = 25556, _time = 1.654e+09, train_seconds = 1.2239e+04)
[2022-05-31 17:34:25,554][root][INFO] - Step 80780800 @ 6650.6 SPS. Inference batcher size: 144. Learner queue size: 6. Other stats: (step = 80780800, mean_episode_return = 96.589, mean_episode_step = 785.32, total_loss = -22.524, pg_loss = -90.542, baseline_loss = 74.89, entropy_loss = -6.873, learner_queue_size = 24, _tick = 25567, _time = 1.654e+09, train_seconds = 1.2244e+04)
[2022-05-31 17:34:30,558][root][INFO] - Step 80814080 @ 6650.7 SPS. Inference batcher size: 74. Learner queue size: 5. Other stats: (step = 80814080, mean_episode_return = 239.38, mean_episode_step = 849.7, total_loss = 228.09, pg_loss = 188.0, baseline_loss = 46.934, entropy_loss = -6.8474, learner_queue_size = 13, _tick = 25580, _time = 1.654e+09, train_seconds = 1.2249e+04)
[2022-05-31 17:34:35,562][root][INFO] - Step 80847360 @ 6650.7 SPS. Inference batcher size: 107. Learner queue size: 25. Other stats: (step = 80847360, mean_episode_return = 151.33, mean_episode_step = 867.91, total_loss = -48.635, pg_loss = -163.46, baseline_loss = 121.28, entropy_loss = -6.4478, learner_queue_size = 11, _tick = 25589, _time = 1.654e+09, train_seconds = 1.2254e+04)
[2022-05-31 17:34:40,568][root][INFO] - Step 80878080 @ 6136.5 SPS. Inference batcher size: 49. Learner queue size: 17. Other stats: (step = 80878080, mean_episode_return = 81.514, mean_episode_step = 1108.1, total_loss = 30.203, pg_loss = -4.3736, baseline_loss = 41.131, entropy_loss = -6.555, learner_queue_size = 18, _tick = 25600, _time = 1.654e+09, train_seconds = 1.2259e+04)
[2022-05-31 17:34:45,574][root][INFO] - Step 80911360 @ 6647.9 SPS. Inference batcher size: 102. Learner queue size: 13. Other stats: (step = 80911360, mean_episode_return = 180.22, mean_episode_step = 1456.2, total_loss = -214.09, pg_loss = -227.2, baseline_loss = 19.957, entropy_loss = -6.843, learner_queue_size = 23, _tick = 25611, _time = 1.654e+09, train_seconds = 1.2264e+04)
[2022-05-31 17:34:50,580][root][INFO] - Step 80944640 @ 6647.9 SPS. Inference batcher size: 135. Learner queue size: 24. Other stats: (step = 80944640, mean_episode_return = 156.39, mean_episode_step = 6399.7, total_loss = 320.4, pg_loss = 150.85, baseline_loss = 176.13, entropy_loss = -6.583, learner_queue_size = 18, _tick = 25624, _time = 1.654e+09, train_seconds = 1.2269e+04)
[2022-05-31 17:34:55,586][root][INFO] - Step 80977920 @ 6648.3 SPS. Inference batcher size: 138. Learner queue size: 20. Other stats: (step = 80977920, mean_episode_return = 179.61, mean_episode_step = 842.25, total_loss = -3.2918, pg_loss = -106.78, baseline_loss = 109.93, entropy_loss = -6.4433, learner_queue_size = 19, _tick = 25637, _time = 1.654e+09, train_seconds = 1.2274e+04)
[2022-05-31 17:35:00,592][root][INFO] - Step 81011200 @ 6647.9 SPS. Inference batcher size: 118. Learner queue size: 19. Other stats: (step = 81011200, mean_episode_return = None, mean_episode_step = 594.47, total_loss = 470.45, pg_loss = 289.25, baseline_loss = 187.45, entropy_loss = -6.2479, learner_queue_size = 26, _tick = 25649, _time = 1.654e+09, train_seconds = 1.2279e+04)
[2022-05-31 17:35:05,598][root][INFO] - Step 81044480 @ 6647.9 SPS. Inference batcher size: 136. Learner queue size: 3. Other stats: (step = 81044480, mean_episode_return = 193.04, mean_episode_step = 624.2, total_loss = -149.75, pg_loss = -227.96, baseline_loss = 84.259, entropy_loss = -6.0459, learner_queue_size = 14, _tick = 25661, _time = 1.654e+09, train_seconds = 1.2284e+04)
[2022-05-31 17:35:10,602][root][INFO] - Step 81077760 @ 6650.8 SPS. Inference batcher size: 109. Learner queue size: 2. Other stats: (step = 81077760, mean_episode_return = 130.04, mean_episode_step = 584.51, total_loss = 148.1, pg_loss = 19.731, baseline_loss = 134.42, entropy_loss = -6.0571, learner_queue_size = 16, _tick = 25673, _time = 1.654e+09, train_seconds = 1.2289e+04)
[2022-05-31 17:35:15,606][root][INFO] - Step 81111040 @ 6650.8 SPS. Inference batcher size: 93. Learner queue size: 24. Other stats: (step = 81111040, mean_episode_return = 143.05, mean_episode_step = 654.17, total_loss = 426.98, pg_loss = 193.27, baseline_loss = 239.94, entropy_loss = -6.2276, learner_queue_size = 20, _tick = 25685, _time = 1.654e+09, train_seconds = 1.2294e+04)
[2022-05-31 17:35:20,610][root][INFO] - Step 81144320 @ 6650.8 SPS. Inference batcher size: 68. Learner queue size: 25. Other stats: (step = 81144320, mean_episode_return = 155.48, mean_episode_step = 610.3, total_loss = 217.93, pg_loss = 52.44, baseline_loss = 171.47, entropy_loss = -5.9746, learner_queue_size = 15, _tick = 25698, _time = 1.654e+09, train_seconds = 1.2299e+04)
[2022-05-31 17:35:25,616][root][INFO] - Step 81175040 @ 6136.1 SPS. Inference batcher size: 89. Learner queue size: 32. Other stats: (step = 81175040, mean_episode_return = 112.92, mean_episode_step = 572.09, total_loss = -276.17, pg_loss = -328.52, baseline_loss = 58.557, entropy_loss = -6.2077, learner_queue_size = 25, _tick = 25709, _time = 1.654e+09, train_seconds = 1.2304e+04)
[2022-05-31 17:35:30,622][root][INFO] - Step 81208320 @ 6648.0 SPS. Inference batcher size: 87. Learner queue size: 13. Other stats: (step = 81208320, mean_episode_return = 108.11, mean_episode_step = 488.35, total_loss = -65.337, pg_loss = -222.16, baseline_loss = 163.02, entropy_loss = -6.1923, learner_queue_size = 19, _tick = 25721, _time = 1.654e+09, train_seconds = 1.2309e+04)
[2022-05-31 17:35:35,626][root][INFO] - Step 81241600 @ 6651.2 SPS. Inference batcher size: 148. Learner queue size: 17. Other stats: (step = 81241600, mean_episode_return = 47.771, mean_episode_step = 665.46, total_loss = -67.368, pg_loss = -161.13, baseline_loss = 100.28, entropy_loss = -6.5175, learner_queue_size = 19, _tick = 25733, _time = 1.654e+09, train_seconds = 1.2314e+04)
[2022-05-31 17:35:40,630][root][INFO] - Step 81274880 @ 6650.2 SPS. Inference batcher size: 57. Learner queue size: 7. Other stats: (step = 81274880, mean_episode_return = 107.49, mean_episode_step = 594.7, total_loss = 185.42, pg_loss = 81.697, baseline_loss = 110.15, entropy_loss = -6.4274, learner_queue_size = 25, _tick = 25745, _time = 1.654e+09, train_seconds = 1.2319e+04)
[2022-05-31 17:35:45,634][root][INFO] - Step 81308160 @ 6651.2 SPS. Inference batcher size: 49. Learner queue size: 31. Other stats: (step = 81308160, mean_episode_return = 118.77, mean_episode_step = 510.75, total_loss = -44.151, pg_loss = -236.59, baseline_loss = 198.45, entropy_loss = -6.0134, learner_queue_size = 21, _tick = 25758, _time = 1.654e+09, train_seconds = 1.2324e+04)
[2022-05-31 17:35:50,638][root][INFO] - Step 81341440 @ 6650.7 SPS. Inference batcher size: 79. Learner queue size: 2. Other stats: (step = 81341440, mean_episode_return = 195.46, mean_episode_step = 846.58, total_loss = -50.131, pg_loss = -135.3, baseline_loss = 91.113, entropy_loss = -5.9388, learner_queue_size = 26, _tick = 25770, _time = 1.654e+09, train_seconds = 1.2329e+04)
[2022-05-31 17:35:55,642][root][INFO] - Step 81374720 @ 6650.2 SPS. Inference batcher size: 35. Learner queue size: 31. Other stats: (step = 81374720, mean_episode_return = 78.947, mean_episode_step = 769.7, total_loss = 3.574, pg_loss = -41.13, baseline_loss = 50.94, entropy_loss = -6.2363, learner_queue_size = 25, _tick = 25783, _time = 1.654e+09, train_seconds = 1.2334e+04)
[2022-05-31 17:36:00,646][root][INFO] - Step 81408000 @ 6651.2 SPS. Inference batcher size: 154. Learner queue size: 24. Other stats: (step = 81408000, mean_episode_return = 153.44, mean_episode_step = 616.22, total_loss = 40.902, pg_loss = -44.082, baseline_loss = 91.193, entropy_loss = -6.2087, learner_queue_size = 21, _tick = 25795, _time = 1.654e+09, train_seconds = 1.2339e+04)
[2022-05-31 17:36:05,652][root][INFO] - Step 81438720 @ 6136.6 SPS. Inference batcher size: 68. Learner queue size: 13. Other stats: (step = 81438720, mean_episode_return = 155.07, mean_episode_step = 1270.2, total_loss = -10.953, pg_loss = -77.13, baseline_loss = 72.152, entropy_loss = -5.9751, learner_queue_size = 17, _tick = 25807, _time = 1.654e+09, train_seconds = 1.2344e+04)
[2022-05-31 17:36:10,658][root][INFO] - Step 81472000 @ 6648.1 SPS. Inference batcher size: 181. Learner queue size: 9. Other stats: (step = 81472000, mean_episode_return = 119.61, mean_episode_step = 682.85, total_loss = 319.93, pg_loss = 264.91, baseline_loss = 61.33, entropy_loss = -6.3078, learner_queue_size = 28, _tick = 25820, _time = 1.654e+09, train_seconds = 1.2349e+04)
[2022-05-31 17:36:15,662][root][INFO] - Step 81505280 @ 6650.6 SPS. Inference batcher size: 95. Learner queue size: 11. Other stats: (step = 81505280, mean_episode_return = 365.33, mean_episode_step = 851.15, total_loss = 196.0, pg_loss = 139.1, baseline_loss = 62.746, entropy_loss = -5.8483, learner_queue_size = 26, _tick = 25830, _time = 1.654e+09, train_seconds = 1.2354e+04)
[2022-05-31 17:36:20,666][root][INFO] - Step 81538560 @ 6650.8 SPS. Inference batcher size: 126. Learner queue size: 31. Other stats: (step = 81538560, mean_episode_return = 220.78, mean_episode_step = 1184.4, total_loss = 85.87, pg_loss = 10.217, baseline_loss = 81.234, entropy_loss = -5.582, learner_queue_size = 20, _tick = 25841, _time = 1.654e+09, train_seconds = 1.2359e+04)
[2022-05-31 17:36:25,670][root][INFO] - Step 81571840 @ 6650.5 SPS. Inference batcher size: 163. Learner queue size: 3. Other stats: (step = 81571840, mean_episode_return = 102.5, mean_episode_step = 720.48, total_loss = 713.01, pg_loss = 549.3, baseline_loss = 170.21, entropy_loss = -6.5082, learner_queue_size = 15, _tick = 25853, _time = 1.654e+09, train_seconds = 1.2364e+04)
[2022-05-31 17:36:30,676][root][INFO] - Step 81605120 @ 6647.8 SPS. Inference batcher size: 60. Learner queue size: 3. Other stats: (step = 81605120, mean_episode_return = None, mean_episode_step = 858.94, total_loss = 683.77, pg_loss = 539.17, baseline_loss = 151.41, entropy_loss = -6.8191, learner_queue_size = 15, _tick = 25864, _time = 1.654e+09, train_seconds = 1.2369e+04)
[2022-05-31 17:36:35,682][root][INFO] - Step 81638400 @ 6648.4 SPS. Inference batcher size: 122. Learner queue size: 27. Other stats: (step = 81638400, mean_episode_return = 269.64, mean_episode_step = 763.07, total_loss = -62.605, pg_loss = -100.66, baseline_loss = 44.708, entropy_loss = -6.6574, learner_queue_size = 16, _tick = 25877, _time = 1.654e+09, train_seconds = 1.2374e+04)
[2022-05-31 17:36:40,686][root][INFO] - Step 81671680 @ 6650.6 SPS. Inference batcher size: 85. Learner queue size: 28. Other stats: (step = 81671680, mean_episode_return = 173.9, mean_episode_step = 655.71, total_loss = 211.2, pg_loss = 93.771, baseline_loss = 124.06, entropy_loss = -6.6313, learner_queue_size = 14, _tick = 25887, _time = 1.654e+09, train_seconds = 1.2379e+04)
[2022-05-31 17:36:45,692][root][INFO] - Step 81702400 @ 6136.7 SPS. Inference batcher size: 153. Learner queue size: 25. Other stats: (step = 81702400, mean_episode_return = 241.47, mean_episode_step = 1462.0, total_loss = 286.31, pg_loss = 193.43, baseline_loss = 99.268, entropy_loss = -6.383, learner_queue_size = 21, _tick = 25899, _time = 1.654e+09, train_seconds = 1.2384e+04)
[2022-05-31 17:36:50,698][root][INFO] - Step 81735680 @ 6648.0 SPS. Inference batcher size: 103. Learner queue size: 18. Other stats: (step = 81735680, mean_episode_return = 326.19, mean_episode_step = 550.94, total_loss = 290.12, pg_loss = 228.09, baseline_loss = 68.072, entropy_loss = -6.0484, learner_queue_size = 19, _tick = 25912, _time = 1.654e+09, train_seconds = 1.2389e+04)
[2022-05-31 17:36:55,704][root][INFO] - Step 81768960 @ 6648.0 SPS. Inference batcher size: 63. Learner queue size: 9. Other stats: (step = 81768960, mean_episode_return = 59.035, mean_episode_step = 1239.2, total_loss = 337.01, pg_loss = 211.58, baseline_loss = 131.73, entropy_loss = -6.2967, learner_queue_size = 18, _tick = 25923, _time = 1.654e+09, train_seconds = 1.2394e+04)
[2022-05-31 17:37:00,710][root][INFO] - Step 81799680 @ 6136.6 SPS. Inference batcher size: 163. Learner queue size: 24. Other stats: (step = 81799680, mean_episode_return = None, mean_episode_step = 908.09, total_loss = -24.403, pg_loss = -66.993, baseline_loss = 48.983, entropy_loss = -6.3931, learner_queue_size = 21, _tick = 25934, _time = 1.654e+09, train_seconds = 1.2399e+04)
[2022-05-31 17:37:05,716][root][INFO] - Step 81832960 @ 6647.8 SPS. Inference batcher size: 132. Learner queue size: 16. Other stats: (step = 81832960, mean_episode_return = 230.7, mean_episode_step = 646.45, total_loss = 100.96, pg_loss = -50.951, baseline_loss = 157.62, entropy_loss = -5.7095, learner_queue_size = 19, _tick = 25946, _time = 1.654e+09, train_seconds = 1.2404e+04)
[2022-05-31 17:37:10,722][root][INFO] - Step 81866240 @ 6648.0 SPS. Inference batcher size: 137. Learner queue size: 14. Other stats: (step = 81866240, mean_episode_return = 167.19, mean_episode_step = 659.13, total_loss = 106.75, pg_loss = 34.292, baseline_loss = 78.975, entropy_loss = -6.5138, learner_queue_size = 17, _tick = 25959, _time = 1.654e+09, train_seconds = 1.2409e+04)
[2022-05-31 17:37:15,726][root][INFO] - Step 81899520 @ 6651.0 SPS. Inference batcher size: 130. Learner queue size: 10. Other stats: (step = 81899520, mean_episode_return = 107.55, mean_episode_step = 773.85, total_loss = 114.93, pg_loss = 1.6924, baseline_loss = 119.6, entropy_loss = -6.3685, learner_queue_size = 17, _tick = 25970, _time = 1.654e+09, train_seconds = 1.2414e+04)
[2022-05-31 17:37:20,730][root][INFO] - Step 81932800 @ 6650.6 SPS. Inference batcher size: 83. Learner queue size: 5. Other stats: (step = 81932800, mean_episode_return = 129.56, mean_episode_step = 580.87, total_loss = 126.16, pg_loss = 8.0034, baseline_loss = 124.82, entropy_loss = -6.6654, learner_queue_size = 23, _tick = 25982, _time = 1.654e+09, train_seconds = 1.2419e+04)
[2022-05-31 17:37:25,734][root][INFO] - Step 81966080 @ 6650.7 SPS. Inference batcher size: 123. Learner queue size: 12. Other stats: (step = 81966080, mean_episode_return = None, mean_episode_step = 665.72, total_loss = 73.412, pg_loss = -6.8154, baseline_loss = 86.764, entropy_loss = -6.5371, learner_queue_size = 8, _tick = 25992, _time = 1.654e+09, train_seconds = 1.2424e+04)
[2022-05-31 17:37:30,740][root][INFO] - Step 81996800 @ 6136.3 SPS. Inference batcher size: 139. Learner queue size: 14. Other stats: (step = 81996800, mean_episode_return = 105.64, mean_episode_step = 538.55, total_loss = 375.65, pg_loss = 260.23, baseline_loss = 121.89, entropy_loss = -6.4703, learner_queue_size = 15, _tick = 26003, _time = 1.654e+09, train_seconds = 1.2429e+04)
[2022-05-31 17:37:35,746][root][INFO] - Step 82030080 @ 6648.3 SPS. Inference batcher size: 43. Learner queue size: 11. Other stats: (step = 82030080, mean_episode_return = 158.18, mean_episode_step = 667.56, total_loss = -32.105, pg_loss = -98.728, baseline_loss = 72.713, entropy_loss = -6.0902, learner_queue_size = 16, _tick = 26015, _time = 1.654e+09, train_seconds = 1.2434e+04)
[2022-05-31 17:37:40,752][root][INFO] - Step 82063360 @ 6648.0 SPS. Inference batcher size: 112. Learner queue size: 3. Other stats: (step = 82063360, mean_episode_return = 140.09, mean_episode_step = 1509.8, total_loss = 37.911, pg_loss = -77.385, baseline_loss = 121.31, entropy_loss = -6.0135, learner_queue_size = 19, _tick = 26028, _time = 1.654e+09, train_seconds = 1.2439e+04)
[2022-05-31 17:37:45,754][root][INFO] - Step 82096640 @ 6653.5 SPS. Inference batcher size: 112. Learner queue size: 4. Other stats: (step = 82096640, mean_episode_return = 87.38, mean_episode_step = 516.65, total_loss = 35.883, pg_loss = 8.0557, baseline_loss = 34.61, entropy_loss = -6.7824, learner_queue_size = 22, _tick = 26041, _time = 1.654e+09, train_seconds = 1.2444e+04)
[2022-05-31 17:37:50,758][root][INFO] - Step 82129920 @ 6650.7 SPS. Inference batcher size: 109. Learner queue size: 30. Other stats: (step = 82129920, mean_episode_return = 129.81, mean_episode_step = 743.62, total_loss = 143.25, pg_loss = 113.74, baseline_loss = 36.487, entropy_loss = -6.9758, learner_queue_size = 22, _tick = 26053, _time = 1.654e+09, train_seconds = 1.2449e+04)
[2022-05-31 17:37:55,762][root][INFO] - Step 82160640 @ 6139.0 SPS. Inference batcher size: 117. Learner queue size: 25. Other stats: (step = 82160640, mean_episode_return = 78.794, mean_episode_step = 624.9, total_loss = -113.33, pg_loss = -140.98, baseline_loss = 34.231, entropy_loss = -6.5767, learner_queue_size = 21, _tick = 26065, _time = 1.654e+09, train_seconds = 1.2454e+04)
[2022-05-31 17:38:00,766][root][INFO] - Step 82193920 @ 6650.6 SPS. Inference batcher size: 61. Learner queue size: 14. Other stats: (step = 82193920, mean_episode_return = 100.54, mean_episode_step = 975.5, total_loss = 3.4532, pg_loss = -71.624, baseline_loss = 81.672, entropy_loss = -6.5952, learner_queue_size = 21, _tick = 26076, _time = 1.654e+09, train_seconds = 1.246e+04)
[2022-05-31 17:38:05,770][root][INFO] - Step 82227200 @ 6650.7 SPS. Inference batcher size: 132. Learner queue size: 10. Other stats: (step = 82227200, mean_episode_return = 57.72, mean_episode_step = 780.88, total_loss = 391.33, pg_loss = 197.74, baseline_loss = 199.72, entropy_loss = -6.1223, learner_queue_size = 19, _tick = 26089, _time = 1.654e+09, train_seconds = 1.2464e+04)
[2022-05-31 17:38:10,774][root][INFO] - Step 82260480 @ 6650.7 SPS. Inference batcher size: 75. Learner queue size: 4. Other stats: (step = 82260480, mean_episode_return = 197.98, mean_episode_step = 850.5, total_loss = -208.46, pg_loss = -255.15, baseline_loss = 53.628, entropy_loss = -6.945, learner_queue_size = 14, _tick = 26100, _time = 1.654e+09, train_seconds = 1.247e+04)
[2022-05-31 17:38:15,778][root][INFO] - Step 82293760 @ 6650.8 SPS. Inference batcher size: 91. Learner queue size: 3. Other stats: (step = 82293760, mean_episode_return = 239.08, mean_episode_step = 637.93, total_loss = -9.8291, pg_loss = -31.49, baseline_loss = 29.011, entropy_loss = -7.35, learner_queue_size = 13, _tick = 26113, _time = 1.654e+09, train_seconds = 1.2474e+04)
[2022-05-31 17:38:20,782][root][INFO] - Step 82327040 @ 6650.6 SPS. Inference batcher size: 131. Learner queue size: 18. Other stats: (step = 82327040, mean_episode_return = 366.65, mean_episode_step = 787.24, total_loss = 117.9, pg_loss = 18.074, baseline_loss = 106.36, entropy_loss = -6.5302, learner_queue_size = 16, _tick = 26125, _time = 1.654e+09, train_seconds = 1.248e+04)
[2022-05-31 17:38:25,784][root][INFO] - Step 82357760 @ 6141.4 SPS. Inference batcher size: 104. Learner queue size: 22. Other stats: (step = 82357760, mean_episode_return = None, mean_episode_step = 720.31, total_loss = 301.73, pg_loss = 190.43, baseline_loss = 117.8, entropy_loss = -6.507, learner_queue_size = 27, _tick = 26135, _time = 1.654e+09, train_seconds = 1.2484e+04)
[2022-05-31 17:38:30,790][root][INFO] - Step 82391040 @ 6648.1 SPS. Inference batcher size: 108. Learner queue size: 9. Other stats: (step = 82391040, mean_episode_return = 246.79, mean_episode_step = 746.02, total_loss = 132.18, pg_loss = -25.542, baseline_loss = 163.88, entropy_loss = -6.1632, learner_queue_size = 15, _tick = 26147, _time = 1.654e+09, train_seconds = 1.249e+04)
[2022-05-31 17:38:35,796][root][INFO] - Step 82424320 @ 6648.4 SPS. Inference batcher size: 118. Learner queue size: 3. Other stats: (step = 82424320, mean_episode_return = 99.773, mean_episode_step = 649.77, total_loss = 183.38, pg_loss = 33.659, baseline_loss = 156.26, entropy_loss = -6.5366, learner_queue_size = 19, _tick = 26159, _time = 1.654e+09, train_seconds = 1.2494e+04)
[2022-05-31 17:38:40,801][root][INFO] - Step 82457600 @ 6649.3 SPS. Inference batcher size: 135. Learner queue size: 3. Other stats: (step = 82457600, mean_episode_return = 195.83, mean_episode_step = 698.35, total_loss = 136.97, pg_loss = 31.235, baseline_loss = 111.87, entropy_loss = -6.1368, learner_queue_size = 23, _tick = 26171, _time = 1.654e+09, train_seconds = 1.25e+04)
[2022-05-31 17:38:45,806][root][INFO] - Step 82490880 @ 6649.0 SPS. Inference batcher size: 184. Learner queue size: 1. Other stats: (step = 82490880, mean_episode_return = 123.1, mean_episode_step = 812.96, total_loss = -23.884, pg_loss = -71.721, baseline_loss = 54.478, entropy_loss = -6.6414, learner_queue_size = 23, _tick = 26181, _time = 1.654e+09, train_seconds = 1.2504e+04)
[2022-05-31 17:38:50,810][root][INFO] - Step 82521600 @ 6139.0 SPS. Inference batcher size: 124. Learner queue size: 32. Other stats: (step = 82521600, mean_episode_return = 168.42, mean_episode_step = 1254.0, total_loss = -105.72, pg_loss = -118.95, baseline_loss = 20.049, entropy_loss = -6.8234, learner_queue_size = 15, _tick = 26193, _time = 1.654e+09, train_seconds = 1.251e+04)
[2022-05-31 17:38:55,814][root][INFO] - Step 82557440 @ 7162.3 SPS. Inference batcher size: 90. Learner queue size: 9. Other stats: (step = 82557440, mean_episode_return = 305.35, mean_episode_step = 814.7, total_loss = -21.444, pg_loss = -47.736, baseline_loss = 32.856, entropy_loss = -6.5641, learner_queue_size = 8, _tick = 26207, _time = 1.654e+09, train_seconds = 1.2514e+04)
[2022-05-31 17:39:00,820][root][INFO] - Step 82588160 @ 6136.6 SPS. Inference batcher size: 137. Learner queue size: 20. Other stats: (step = 82588160, mean_episode_return = 55.001, mean_episode_step = 557.96, total_loss = -2.2545, pg_loss = -22.431, baseline_loss = 27.353, entropy_loss = -7.1763, learner_queue_size = 16, _tick = 26218, _time = 1.654e+09, train_seconds = 1.252e+04)
[2022-05-31 17:39:05,825][root][INFO] - Step 82621440 @ 6649.6 SPS. Inference batcher size: 129. Learner queue size: 9. Other stats: (step = 82621440, mean_episode_return = None, mean_episode_step = 751.5, total_loss = 118.83, pg_loss = 66.52, baseline_loss = 58.916, entropy_loss = -6.6027, learner_queue_size = 16, _tick = 26229, _time = 1.654e+09, train_seconds = 1.2524e+04)
[2022-05-31 17:39:10,830][root][INFO] - Step 82654720 @ 6649.2 SPS. Inference batcher size: 151. Learner queue size: 6. Other stats: (step = 82654720, mean_episode_return = 127.34, mean_episode_step = 832.18, total_loss = -106.78, pg_loss = -137.58, baseline_loss = 36.905, entropy_loss = -6.098, learner_queue_size = 19, _tick = 26239, _time = 1.654e+09, train_seconds = 1.253e+04)
[2022-05-31 17:39:15,834][root][INFO] - Step 82688000 @ 6650.7 SPS. Inference batcher size: 82. Learner queue size: 28. Other stats: (step = 82688000, mean_episode_return = None, mean_episode_step = 803.09, total_loss = 87.373, pg_loss = 61.535, baseline_loss = 32.459, entropy_loss = -6.6203, learner_queue_size = 23, _tick = 26250, _time = 1.654e+09, train_seconds = 1.2534e+04)
[2022-05-31 17:39:20,838][root][INFO] - Step 82721280 @ 6650.7 SPS. Inference batcher size: 79. Learner queue size: 17. Other stats: (step = 82721280, mean_episode_return = 145.33, mean_episode_step = 686.12, total_loss = 227.1, pg_loss = 89.842, baseline_loss = 143.54, entropy_loss = -6.2777, learner_queue_size = 17, _tick = 26262, _time = 1.654e+09, train_seconds = 1.254e+04)
[2022-05-31 17:39:25,842][root][INFO] - Step 82754560 @ 6650.3 SPS. Inference batcher size: 39. Learner queue size: 15. Other stats: (step = 82754560, mean_episode_return = 206.5, mean_episode_step = 771.4, total_loss = 146.37, pg_loss = 90.409, baseline_loss = 61.967, entropy_loss = -6.0068, learner_queue_size = 13, _tick = 26273, _time = 1.654e+09, train_seconds = 1.2544e+04)
[2022-05-31 17:39:30,849][root][INFO] - Step 82785280 @ 6135.6 SPS. Inference batcher size: 116. Learner queue size: 8. Other stats: (step = 82785280, mean_episode_return = 139.71, mean_episode_step = 1151.7, total_loss = 414.17, pg_loss = 214.48, baseline_loss = 205.9, entropy_loss = -6.2146, learner_queue_size = 17, _tick = 26285, _time = 1.654e+09, train_seconds = 1.255e+04)
[2022-05-31 17:39:35,855][root][INFO] - Step 82818560 @ 6648.0 SPS. Inference batcher size: 74. Learner queue size: 23. Other stats: (step = 82818560, mean_episode_return = 209.02, mean_episode_step = 748.49, total_loss = 30.009, pg_loss = -36.523, baseline_loss = 72.699, entropy_loss = -6.1678, learner_queue_size = 26, _tick = 26298, _time = 1.654e+09, train_seconds = 1.2554e+04)
[2022-05-31 17:39:40,861][root][INFO] - Step 82851840 @ 6647.9 SPS. Inference batcher size: 124. Learner queue size: 23. Other stats: (step = 82851840, mean_episode_return = None, mean_episode_step = 741.94, total_loss = 409.44, pg_loss = 239.49, baseline_loss = 176.17, entropy_loss = -6.2249, learner_queue_size = 18, _tick = 26308, _time = 1.654e+09, train_seconds = 1.256e+04)
[2022-05-31 17:39:45,867][root][INFO] - Step 82885120 @ 6648.0 SPS. Inference batcher size: 111. Learner queue size: 3. Other stats: (step = 82885120, mean_episode_return = 275.86, mean_episode_step = 545.65, total_loss = 42.863, pg_loss = -114.88, baseline_loss = 163.52, entropy_loss = -5.7816, learner_queue_size = 13, _tick = 26320, _time = 1.654e+09, train_seconds = 1.2565e+04)
[2022-05-31 17:39:50,870][root][INFO] - Step 82918400 @ 6652.4 SPS. Inference batcher size: 129. Learner queue size: 8. Other stats: (step = 82918400, mean_episode_return = 176.6, mean_episode_step = 755.83, total_loss = -276.4, pg_loss = -329.08, baseline_loss = 59.141, entropy_loss = -6.4571, learner_queue_size = 18, _tick = 26332, _time = 1.654e+09, train_seconds = 1.257e+04)
[2022-05-31 17:39:55,876][root][INFO] - Step 82951680 @ 6647.8 SPS. Inference batcher size: 116. Learner queue size: 22. Other stats: (step = 82951680, mean_episode_return = 170.54, mean_episode_step = 637.8, total_loss = 185.07, pg_loss = 107.22, baseline_loss = 84.408, entropy_loss = -6.5528, learner_queue_size = 16, _tick = 26344, _time = 1.654e+09, train_seconds = 1.2575e+04)
[2022-05-31 17:40:00,882][root][INFO] - Step 82982400 @ 6136.8 SPS. Inference batcher size: 113. Learner queue size: 19. Other stats: (step = 82982400, mean_episode_return = 197.94, mean_episode_step = 570.52, total_loss = 125.4, pg_loss = 11.669, baseline_loss = 119.51, entropy_loss = -5.7751, learner_queue_size = 26, _tick = 26356, _time = 1.654e+09, train_seconds = 1.258e+04)
[2022-05-31 17:40:05,888][root][INFO] - Step 83015680 @ 6648.0 SPS. Inference batcher size: 74. Learner queue size: 18. Other stats: (step = 83015680, mean_episode_return = 263.13, mean_episode_step = 705.02, total_loss = 58.257, pg_loss = -56.9, baseline_loss = 121.42, entropy_loss = -6.2601, learner_queue_size = 22, _tick = 26368, _time = 1.654e+09, train_seconds = 1.2585e+04)
[2022-05-31 17:40:10,894][root][INFO] - Step 83048960 @ 6648.2 SPS. Inference batcher size: 153. Learner queue size: 7. Other stats: (step = 83048960, mean_episode_return = 155.82, mean_episode_step = 590.07, total_loss = 84.783, pg_loss = 29.463, baseline_loss = 61.882, entropy_loss = -6.5616, learner_queue_size = 11, _tick = 26378, _time = 1.654e+09, train_seconds = 1.259e+04)
[2022-05-31 17:40:15,900][root][INFO] - Step 83082240 @ 6647.9 SPS. Inference batcher size: 132. Learner queue size: 14. Other stats: (step = 83082240, mean_episode_return = 175.35, mean_episode_step = 632.19, total_loss = 323.34, pg_loss = 168.45, baseline_loss = 160.69, entropy_loss = -5.799, learner_queue_size = 26, _tick = 26390, _time = 1.654e+09, train_seconds = 1.2595e+04)
[2022-05-31 17:40:20,902][root][INFO] - Step 83115520 @ 6653.4 SPS. Inference batcher size: 125. Learner queue size: 16. Other stats: (step = 83115520, mean_episode_return = 197.56, mean_episode_step = 631.12, total_loss = -166.55, pg_loss = -231.23, baseline_loss = 70.74, entropy_loss = -6.0551, learner_queue_size = 22, _tick = 26402, _time = 1.654e+09, train_seconds = 1.26e+04)
[2022-05-31 17:40:25,906][root][INFO] - Step 83148800 @ 6650.6 SPS. Inference batcher size: 119. Learner queue size: 8. Other stats: (step = 83148800, mean_episode_return = 214.2, mean_episode_step = 617.87, total_loss = 500.22, pg_loss = 281.76, baseline_loss = 224.56, entropy_loss = -6.1017, learner_queue_size = 10, _tick = 26413, _time = 1.654e+09, train_seconds = 1.2605e+04)
[2022-05-31 17:40:30,910][root][INFO] - Step 83182080 @ 6650.7 SPS. Inference batcher size: 85. Learner queue size: 1. Other stats: (step = 83182080, mean_episode_return = 289.51, mean_episode_step = 846.49, total_loss = 34.319, pg_loss = -96.098, baseline_loss = 136.29, entropy_loss = -5.8703, learner_queue_size = 23, _tick = 26425, _time = 1.654e+09, train_seconds = 1.261e+04)
[2022-05-31 17:40:35,916][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 17:40:35,989][root][INFO] - Step 83212800 @ 6136.8 SPS. Inference batcher size: 23. Learner queue size: 15. Other stats: (step = 83215360, mean_episode_return = 261.4, mean_episode_step = 639.43, total_loss = -207.17, pg_loss = -241.0, baseline_loss = 40.119, entropy_loss = -6.2909, learner_queue_size = 15, _tick = 26438, _time = 1.654e+09, train_seconds = 1.2615e+04)
[2022-05-31 17:40:40,991][root][INFO] - Step 83246080 @ 6557.6 SPS. Inference batcher size: 154. Learner queue size: 15. Other stats: (step = 83246080, mean_episode_return = 257.2, mean_episode_step = 871.58, total_loss = 108.67, pg_loss = 20.162, baseline_loss = 94.987, entropy_loss = -6.481, learner_queue_size = 16, _tick = 26449, _time = 1.654e+09, train_seconds = 1.262e+04)
[2022-05-31 17:40:45,997][root][INFO] - Step 83279360 @ 6648.0 SPS. Inference batcher size: 76. Learner queue size: 18. Other stats: (step = 83279360, mean_episode_return = 196.86, mean_episode_step = 611.89, total_loss = -80.763, pg_loss = -148.73, baseline_loss = 74.27, entropy_loss = -6.3028, learner_queue_size = 20, _tick = 26460, _time = 1.654e+09, train_seconds = 1.2625e+04)
[2022-05-31 17:40:51,002][root][INFO] - Step 83312640 @ 6649.2 SPS. Inference batcher size: 106. Learner queue size: 18. Other stats: (step = 83312640, mean_episode_return = 70.56, mean_episode_step = 1137.9, total_loss = 250.66, pg_loss = 191.63, baseline_loss = 65.505, entropy_loss = -6.4822, learner_queue_size = 20, _tick = 26473, _time = 1.654e+09, train_seconds = 1.263e+04)
[2022-05-31 17:40:56,006][root][INFO] - Step 83345920 @ 6650.8 SPS. Inference batcher size: 138. Learner queue size: 3. Other stats: (step = 83345920, mean_episode_return = None, mean_episode_step = 760.66, total_loss = -64.023, pg_loss = -83.459, baseline_loss = 25.929, entropy_loss = -6.4938, learner_queue_size = 32, _tick = 26485, _time = 1.654e+09, train_seconds = 1.2635e+04)
[2022-05-31 17:41:01,010][root][INFO] - Step 83379200 @ 6650.7 SPS. Inference batcher size: 114. Learner queue size: 20. Other stats: (step = 83379200, mean_episode_return = 43.68, mean_episode_step = 854.45, total_loss = -156.76, pg_loss = -182.11, baseline_loss = 31.841, entropy_loss = -6.4891, learner_queue_size = 10, _tick = 26495, _time = 1.654e+09, train_seconds = 1.264e+04)
[2022-05-31 17:41:06,014][root][INFO] - Step 83412480 @ 6650.7 SPS. Inference batcher size: 44. Learner queue size: 22. Other stats: (step = 83412480, mean_episode_return = None, mean_episode_step = 671.91, total_loss = 115.81, pg_loss = 71.898, baseline_loss = 50.035, entropy_loss = -6.1225, learner_queue_size = 17, _tick = 26505, _time = 1.654e+09, train_seconds = 1.2645e+04)
[2022-05-31 17:41:11,021][root][INFO] - Step 83443200 @ 6135.4 SPS. Inference batcher size: 182. Learner queue size: 6. Other stats: (step = 83443200, mean_episode_return = 161.63, mean_episode_step = 678.03, total_loss = 163.99, pg_loss = -5.7641, baseline_loss = 175.71, entropy_loss = -5.963, learner_queue_size = 22, _tick = 26516, _time = 1.654e+09, train_seconds = 1.265e+04)
[2022-05-31 17:41:16,026][root][INFO] - Step 83476480 @ 6649.4 SPS. Inference batcher size: 98. Learner queue size: 27. Other stats: (step = 83476480, mean_episode_return = 96.368, mean_episode_step = 1235.9, total_loss = -43.429, pg_loss = -90.661, baseline_loss = 53.684, entropy_loss = -6.4517, learner_queue_size = 19, _tick = 26529, _time = 1.654e+09, train_seconds = 1.2655e+04)
[2022-05-31 17:41:21,030][root][INFO] - Step 83509760 @ 6650.6 SPS. Inference batcher size: 51. Learner queue size: 31. Other stats: (step = 83509760, mean_episode_return = 154.01, mean_episode_step = 804.71, total_loss = 259.4, pg_loss = 183.25, baseline_loss = 82.861, entropy_loss = -6.7107, learner_queue_size = 27, _tick = 26540, _time = 1.654e+09, train_seconds = 1.266e+04)
[2022-05-31 17:41:26,038][root][INFO] - Step 83543040 @ 6645.3 SPS. Inference batcher size: 88. Learner queue size: 27. Other stats: (step = 83543040, mean_episode_return = 188.07, mean_episode_step = 690.71, total_loss = 3.44, pg_loss = -25.982, baseline_loss = 35.427, entropy_loss = -6.0048, learner_queue_size = 22, _tick = 26550, _time = 1.654e+09, train_seconds = 1.2665e+04)
[2022-05-31 17:41:31,042][root][INFO] - Step 83576320 @ 6650.8 SPS. Inference batcher size: 46. Learner queue size: 26. Other stats: (step = 83576320, mean_episode_return = 129.24, mean_episode_step = 1046.4, total_loss = 382.05, pg_loss = 261.07, baseline_loss = 126.89, entropy_loss = -5.9186, learner_queue_size = 17, _tick = 26562, _time = 1.654e+09, train_seconds = 1.267e+04)
[2022-05-31 17:41:36,048][root][INFO] - Step 83607040 @ 6136.1 SPS. Inference batcher size: 140. Learner queue size: 20. Other stats: (step = 83607040, mean_episode_return = 164.27, mean_episode_step = 823.09, total_loss = 287.95, pg_loss = 165.6, baseline_loss = 128.59, entropy_loss = -6.2438, learner_queue_size = 16, _tick = 26573, _time = 1.654e+09, train_seconds = 1.2675e+04)
[2022-05-31 17:41:41,054][root][INFO] - Step 83640320 @ 6648.1 SPS. Inference batcher size: 106. Learner queue size: 17. Other stats: (step = 83640320, mean_episode_return = 105.25, mean_episode_step = 920.4, total_loss = -119.82, pg_loss = -144.99, baseline_loss = 31.524, entropy_loss = -6.3627, learner_queue_size = 20, _tick = 26584, _time = 1.654e+09, train_seconds = 1.268e+04)
[2022-05-31 17:41:46,058][root][INFO] - Step 83673600 @ 6651.2 SPS. Inference batcher size: 115. Learner queue size: 25. Other stats: (step = 83673600, mean_episode_return = 228.47, mean_episode_step = 734.11, total_loss = -60.6, pg_loss = -119.03, baseline_loss = 64.94, entropy_loss = -6.5102, learner_queue_size = 25, _tick = 26595, _time = 1.654e+09, train_seconds = 1.2685e+04)
[2022-05-31 17:41:51,062][root][INFO] - Step 83706880 @ 6650.6 SPS. Inference batcher size: 136. Learner queue size: 4. Other stats: (step = 83706880, mean_episode_return = 135.0, mean_episode_step = 811.27, total_loss = 180.13, pg_loss = 117.21, baseline_loss = 69.659, entropy_loss = -6.737, learner_queue_size = 11, _tick = 26608, _time = 1.654e+09, train_seconds = 1.269e+04)
[2022-05-31 17:41:56,066][root][INFO] - Step 83740160 @ 6650.8 SPS. Inference batcher size: 62. Learner queue size: 2. Other stats: (step = 83740160, mean_episode_return = 286.24, mean_episode_step = 736.34, total_loss = 190.75, pg_loss = 95.307, baseline_loss = 101.3, entropy_loss = -5.8534, learner_queue_size = 21, _tick = 26621, _time = 1.654e+09, train_seconds = 1.2695e+04)
[2022-05-31 17:42:01,070][root][INFO] - Step 83773440 @ 6650.7 SPS. Inference batcher size: 97. Learner queue size: 6. Other stats: (step = 83773440, mean_episode_return = 324.53, mean_episode_step = 755.75, total_loss = 21.546, pg_loss = -34.481, baseline_loss = 62.087, entropy_loss = -6.0607, learner_queue_size = 19, _tick = 26634, _time = 1.654e+09, train_seconds = 1.27e+04)
[2022-05-31 17:42:06,074][root][INFO] - Step 83806720 @ 6650.6 SPS. Inference batcher size: 109. Learner queue size: 23. Other stats: (step = 83806720, mean_episode_return = 170.05, mean_episode_step = 482.53, total_loss = -8.5977, pg_loss = -140.98, baseline_loss = 138.35, entropy_loss = -5.9674, learner_queue_size = 20, _tick = 26646, _time = 1.654e+09, train_seconds = 1.2705e+04)
[2022-05-31 17:42:11,080][root][INFO] - Step 83837440 @ 6136.6 SPS. Inference batcher size: 59. Learner queue size: 16. Other stats: (step = 83837440, mean_episode_return = 347.01, mean_episode_step = 780.15, total_loss = 461.9, pg_loss = 329.68, baseline_loss = 138.55, entropy_loss = -6.3311, learner_queue_size = 21, _tick = 26658, _time = 1.654e+09, train_seconds = 1.271e+04)
[2022-05-31 17:42:16,086][root][INFO] - Step 83870720 @ 6648.1 SPS. Inference batcher size: 101. Learner queue size: 5. Other stats: (step = 83870720, mean_episode_return = 65.61, mean_episode_step = 669.97, total_loss = -198.1, pg_loss = -215.9, baseline_loss = 24.417, entropy_loss = -6.6216, learner_queue_size = 15, _tick = 26668, _time = 1.654e+09, train_seconds = 1.2715e+04)
[2022-05-31 17:42:21,090][root][INFO] - Step 83904000 @ 6650.7 SPS. Inference batcher size: 161. Learner queue size: 28. Other stats: (step = 83904000, mean_episode_return = 103.0, mean_episode_step = 1272.3, total_loss = 46.025, pg_loss = 4.9965, baseline_loss = 47.474, entropy_loss = -6.4455, learner_queue_size = 17, _tick = 26678, _time = 1.654e+09, train_seconds = 1.272e+04)
[2022-05-31 17:42:26,096][root][INFO] - Step 83934720 @ 6136.7 SPS. Inference batcher size: 76. Learner queue size: 24. Other stats: (step = 83934720, mean_episode_return = 211.8, mean_episode_step = 639.4, total_loss = 20.247, pg_loss = -36.893, baseline_loss = 63.809, entropy_loss = -6.6684, learner_queue_size = 27, _tick = 26690, _time = 1.654e+09, train_seconds = 1.2725e+04)
[2022-05-31 17:42:31,099][root][INFO] - Step 83968000 @ 6652.5 SPS. Inference batcher size: 65. Learner queue size: 13. Other stats: (step = 83968000, mean_episode_return = 67.125, mean_episode_step = 784.33, total_loss = 130.02, pg_loss = 64.511, baseline_loss = 71.512, entropy_loss = -6.0078, learner_queue_size = 14, _tick = 26701, _time = 1.654e+09, train_seconds = 1.273e+04)
[2022-05-31 17:42:36,105][root][INFO] - Step 84001280 @ 6647.5 SPS. Inference batcher size: 123. Learner queue size: 2. Other stats: (step = 84001280, mean_episode_return = 180.86, mean_episode_step = 697.33, total_loss = -27.609, pg_loss = -125.83, baseline_loss = 104.36, entropy_loss = -6.1418, learner_queue_size = 21, _tick = 26714, _time = 1.654e+09, train_seconds = 1.2735e+04)
[2022-05-31 17:42:41,110][root][INFO] - Step 84034560 @ 6649.5 SPS. Inference batcher size: 92. Learner queue size: 29. Other stats: (step = 84034560, mean_episode_return = 147.9, mean_episode_step = 703.79, total_loss = 514.2, pg_loss = 315.24, baseline_loss = 205.44, entropy_loss = -6.472, learner_queue_size = 23, _tick = 26726, _time = 1.654e+09, train_seconds = 1.274e+04)
[2022-05-31 17:42:46,116][root][INFO] - Step 84067840 @ 6648.3 SPS. Inference batcher size: 72. Learner queue size: 17. Other stats: (step = 84067840, mean_episode_return = 98.265, mean_episode_step = 621.33, total_loss = -153.85, pg_loss = -177.69, baseline_loss = 30.122, entropy_loss = -6.2808, learner_queue_size = 17, _tick = 26739, _time = 1.654e+09, train_seconds = 1.2745e+04)
[2022-05-31 17:42:51,122][root][INFO] - Step 84098560 @ 6136.7 SPS. Inference batcher size: 127. Learner queue size: 14. Other stats: (step = 84098560, mean_episode_return = 392.5, mean_episode_step = 703.61, total_loss = 91.251, pg_loss = -199.79, baseline_loss = 297.5, entropy_loss = -6.4656, learner_queue_size = 24, _tick = 26749, _time = 1.654e+09, train_seconds = 1.275e+04)
[2022-05-31 17:42:56,126][root][INFO] - Step 84131840 @ 6650.3 SPS. Inference batcher size: 130. Learner queue size: 8. Other stats: (step = 84131840, mean_episode_return = 526.66, mean_episode_step = 800.12, total_loss = -8.846, pg_loss = -68.72, baseline_loss = 66.257, entropy_loss = -6.383, learner_queue_size = 18, _tick = 26761, _time = 1.654e+09, train_seconds = 1.2755e+04)
[2022-05-31 17:43:01,130][root][INFO] - Step 84165120 @ 6650.6 SPS. Inference batcher size: 90. Learner queue size: 6. Other stats: (step = 84165120, mean_episode_return = 97.519, mean_episode_step = 656.07, total_loss = 42.776, pg_loss = 9.4842, baseline_loss = 39.357, entropy_loss = -6.0648, learner_queue_size = 31, _tick = 26772, _time = 1.654e+09, train_seconds = 1.276e+04)
[2022-05-31 17:43:06,134][root][INFO] - Step 84198400 @ 6650.7 SPS. Inference batcher size: 94. Learner queue size: 31. Other stats: (step = 84198400, mean_episode_return = 185.68, mean_episode_step = 747.8, total_loss = -173.49, pg_loss = -209.47, baseline_loss = 42.221, entropy_loss = -6.2428, learner_queue_size = 9, _tick = 26784, _time = 1.654e+09, train_seconds = 1.2765e+04)
[2022-05-31 17:43:11,140][root][INFO] - Step 84231680 @ 6648.0 SPS. Inference batcher size: 97. Learner queue size: 26. Other stats: (step = 84231680, mean_episode_return = None, mean_episode_step = 623.44, total_loss = 182.04, pg_loss = 110.02, baseline_loss = 78.414, entropy_loss = -6.3916, learner_queue_size = 20, _tick = 26794, _time = 1.654e+09, train_seconds = 1.277e+04)
[2022-05-31 17:43:16,147][root][INFO] - Step 84262400 @ 6136.0 SPS. Inference batcher size: 149. Learner queue size: 20. Other stats: (step = 84262400, mean_episode_return = 244.15, mean_episode_step = 649.59, total_loss = 256.34, pg_loss = 149.07, baseline_loss = 113.39, entropy_loss = -6.1149, learner_queue_size = 21, _tick = 26805, _time = 1.654e+09, train_seconds = 1.2775e+04)
[2022-05-31 17:43:21,153][root][INFO] - Step 84295680 @ 6647.9 SPS. Inference batcher size: 96. Learner queue size: 18. Other stats: (step = 84295680, mean_episode_return = 287.0, mean_episode_step = 642.54, total_loss = 92.533, pg_loss = -89.919, baseline_loss = 188.12, entropy_loss = -5.6717, learner_queue_size = 12, _tick = 26818, _time = 1.654e+09, train_seconds = 1.278e+04)
[2022-05-31 17:43:26,159][root][INFO] - Step 84328960 @ 6648.0 SPS. Inference batcher size: 178. Learner queue size: 21. Other stats: (step = 84328960, mean_episode_return = 362.79, mean_episode_step = 1182.5, total_loss = 58.766, pg_loss = -58.263, baseline_loss = 123.01, entropy_loss = -5.9764, learner_queue_size = 12, _tick = 26830, _time = 1.654e+09, train_seconds = 1.2785e+04)
[2022-05-31 17:43:31,162][root][INFO] - Step 84362240 @ 6651.7 SPS. Inference batcher size: 93. Learner queue size: 29. Other stats: (step = 84362240, mean_episode_return = 180.25, mean_episode_step = 584.81, total_loss = -58.545, pg_loss = -107.27, baseline_loss = 54.186, entropy_loss = -5.4648, learner_queue_size = 15, _tick = 26843, _time = 1.654e+09, train_seconds = 1.279e+04)
[2022-05-31 17:43:36,166][root][INFO] - Step 84395520 @ 6650.7 SPS. Inference batcher size: 158. Learner queue size: 3. Other stats: (step = 84395520, mean_episode_return = 210.0, mean_episode_step = 510.35, total_loss = 181.25, pg_loss = 68.002, baseline_loss = 119.53, entropy_loss = -6.2842, learner_queue_size = 19, _tick = 26854, _time = 1.654e+09, train_seconds = 1.2795e+04)
[2022-05-31 17:43:41,170][root][INFO] - Step 84426240 @ 6138.9 SPS. Inference batcher size: 106. Learner queue size: 25. Other stats: (step = 84426240, mean_episode_return = 120.15, mean_episode_step = 699.77, total_loss = 14.856, pg_loss = -112.34, baseline_loss = 133.42, entropy_loss = -6.2242, learner_queue_size = 14, _tick = 26866, _time = 1.654e+09, train_seconds = 1.28e+04)
[2022-05-31 17:43:46,177][root][INFO] - Step 84459520 @ 6647.3 SPS. Inference batcher size: 110. Learner queue size: 16. Other stats: (step = 84459520, mean_episode_return = 115.09, mean_episode_step = 715.91, total_loss = 259.71, pg_loss = 134.56, baseline_loss = 131.31, entropy_loss = -6.161, learner_queue_size = 21, _tick = 26878, _time = 1.654e+09, train_seconds = 1.2805e+04)
[2022-05-31 17:43:51,183][root][INFO] - Step 84492800 @ 6647.9 SPS. Inference batcher size: 134. Learner queue size: 18. Other stats: (step = 84492800, mean_episode_return = 41.57, mean_episode_step = 1348.5, total_loss = 30.517, pg_loss = -55.414, baseline_loss = 92.384, entropy_loss = -6.4538, learner_queue_size = 24, _tick = 26888, _time = 1.654e+09, train_seconds = 1.281e+04)
[2022-05-31 17:43:56,189][root][INFO] - Step 84526080 @ 6647.8 SPS. Inference batcher size: 95. Learner queue size: 8. Other stats: (step = 84526080, mean_episode_return = 173.94, mean_episode_step = 748.05, total_loss = 238.11, pg_loss = 91.181, baseline_loss = 153.48, entropy_loss = -6.5472, learner_queue_size = 14, _tick = 26898, _time = 1.654e+09, train_seconds = 1.2815e+04)
[2022-05-31 17:44:01,194][root][INFO] - Step 84559360 @ 6649.3 SPS. Inference batcher size: 90. Learner queue size: 6. Other stats: (step = 84559360, mean_episode_return = 161.88, mean_episode_step = 594.47, total_loss = -194.42, pg_loss = -220.08, baseline_loss = 32.414, entropy_loss = -6.7591, learner_queue_size = 15, _tick = 26910, _time = 1.654e+09, train_seconds = 1.282e+04)
[2022-05-31 17:44:06,198][root][INFO] - Step 84592640 @ 6650.6 SPS. Inference batcher size: 113. Learner queue size: 31. Other stats: (step = 84592640, mean_episode_return = None, mean_episode_step = 1327.1, total_loss = 169.98, pg_loss = 124.87, baseline_loss = 52.399, entropy_loss = -7.2942, learner_queue_size = 29, _tick = 26922, _time = 1.654e+09, train_seconds = 1.2825e+04)
[2022-05-31 17:44:11,202][root][INFO] - Step 84625920 @ 6650.7 SPS. Inference batcher size: 152. Learner queue size: 26. Other stats: (step = 84625920, mean_episode_return = 63.424, mean_episode_step = 768.33, total_loss = -28.625, pg_loss = -48.019, baseline_loss = 26.151, entropy_loss = -6.7564, learner_queue_size = 14, _tick = 26933, _time = 1.654e+09, train_seconds = 1.283e+04)
[2022-05-31 17:44:16,206][root][INFO] - Step 84659200 @ 6650.7 SPS. Inference batcher size: 85. Learner queue size: 25. Other stats: (step = 84659200, mean_episode_return = 194.28, mean_episode_step = 712.88, total_loss = -101.72, pg_loss = -148.58, baseline_loss = 53.237, entropy_loss = -6.3823, learner_queue_size = 18, _tick = 26943, _time = 1.654e+09, train_seconds = 1.2835e+04)
[2022-05-31 17:44:21,210][root][INFO] - Step 84689920 @ 6139.0 SPS. Inference batcher size: 98. Learner queue size: 14. Other stats: (step = 84689920, mean_episode_return = 296.75, mean_episode_step = 479.76, total_loss = -156.62, pg_loss = -255.1, baseline_loss = 104.66, entropy_loss = -6.1792, learner_queue_size = 27, _tick = 26955, _time = 1.654e+09, train_seconds = 1.284e+04)
[2022-05-31 17:44:26,211][root][INFO] - Step 84723200 @ 6654.2 SPS. Inference batcher size: 164. Learner queue size: 15. Other stats: (step = 84723200, mean_episode_return = 117.68, mean_episode_step = 701.62, total_loss = -281.18, pg_loss = -309.72, baseline_loss = 35.071, entropy_loss = -6.5395, learner_queue_size = 16, _tick = 26966, _time = 1.654e+09, train_seconds = 1.2845e+04)
[2022-05-31 17:44:31,217][root][INFO] - Step 84756480 @ 6648.0 SPS. Inference batcher size: 168. Learner queue size: 8. Other stats: (step = 84756480, mean_episode_return = 279.64, mean_episode_step = 524.36, total_loss = 144.16, pg_loss = 30.089, baseline_loss = 119.92, entropy_loss = -5.8563, learner_queue_size = 20, _tick = 26978, _time = 1.654e+09, train_seconds = 1.285e+04)
[2022-05-31 17:44:36,222][root][INFO] - Step 84789760 @ 6649.7 SPS. Inference batcher size: 131. Learner queue size: 3. Other stats: (step = 84789760, mean_episode_return = 218.41, mean_episode_step = 481.37, total_loss = -12.682, pg_loss = -141.1, baseline_loss = 134.49, entropy_loss = -6.0806, learner_queue_size = 9, _tick = 26991, _time = 1.654e+09, train_seconds = 1.2855e+04)
[2022-05-31 17:44:41,231][root][INFO] - Step 84823040 @ 6643.9 SPS. Inference batcher size: 132. Learner queue size: 28. Other stats: (step = 84823040, mean_episode_return = 170.29, mean_episode_step = 634.07, total_loss = -64.15, pg_loss = -132.91, baseline_loss = 75.465, entropy_loss = -6.7081, learner_queue_size = 16, _tick = 27003, _time = 1.654e+09, train_seconds = 1.286e+04)
[2022-05-31 17:44:46,238][root][INFO] - Step 84853760 @ 6136.0 SPS. Inference batcher size: 149. Learner queue size: 16. Other stats: (step = 84853760, mean_episode_return = 66.93, mean_episode_step = 1336.5, total_loss = 38.959, pg_loss = 7.8253, baseline_loss = 37.877, entropy_loss = -6.7429, learner_queue_size = 19, _tick = 27014, _time = 1.654e+09, train_seconds = 1.2865e+04)
[2022-05-31 17:44:51,244][root][INFO] - Step 84887040 @ 6647.8 SPS. Inference batcher size: 79. Learner queue size: 21. Other stats: (step = 84887040, mean_episode_return = 244.42, mean_episode_step = 741.97, total_loss = 346.14, pg_loss = 185.75, baseline_loss = 166.55, entropy_loss = -6.1636, learner_queue_size = 6, _tick = 27025, _time = 1.654e+09, train_seconds = 1.287e+04)
[2022-05-31 17:44:56,250][root][INFO] - Step 84920320 @ 6647.9 SPS. Inference batcher size: 140. Learner queue size: 15. Other stats: (step = 84920320, mean_episode_return = None, mean_episode_step = 612.91, total_loss = 257.71, pg_loss = 136.18, baseline_loss = 128.08, entropy_loss = -6.5505, learner_queue_size = 25, _tick = 27035, _time = 1.654e+09, train_seconds = 1.2875e+04)
[2022-05-31 17:45:01,255][root][INFO] - Step 84953600 @ 6650.0 SPS. Inference batcher size: 131. Learner queue size: 6. Other stats: (step = 84953600, mean_episode_return = 210.9, mean_episode_step = 1192.5, total_loss = 186.09, pg_loss = 44.318, baseline_loss = 148.06, entropy_loss = -6.2817, learner_queue_size = 21, _tick = 27046, _time = 1.654e+09, train_seconds = 1.288e+04)
[2022-05-31 17:45:06,258][root][INFO] - Step 84986880 @ 6651.4 SPS. Inference batcher size: 166. Learner queue size: 1. Other stats: (step = 84986880, mean_episode_return = 275.93, mean_episode_step = 802.95, total_loss = 351.2, pg_loss = 169.45, baseline_loss = 188.1, entropy_loss = -6.3474, learner_queue_size = 24, _tick = 27059, _time = 1.654e+09, train_seconds = 1.2885e+04)
[2022-05-31 17:45:11,262][root][INFO] - Step 85020160 @ 6650.7 SPS. Inference batcher size: 0. Learner queue size: 27. Other stats: (step = 85020160, mean_episode_return = 381.28, mean_episode_step = 582.17, total_loss = -13.663, pg_loss = -40.748, baseline_loss = 33.474, entropy_loss = -6.3892, learner_queue_size = 18, _tick = 27072, _time = 1.654e+09, train_seconds = 1.289e+04)
[2022-05-31 17:45:16,266][root][INFO] - Step 85053440 @ 6650.6 SPS. Inference batcher size: 46. Learner queue size: 0. Other stats: (step = 85053440, mean_episode_return = 200.75, mean_episode_step = 767.24, total_loss = 298.14, pg_loss = 218.45, baseline_loss = 86.348, entropy_loss = -6.6625, learner_queue_size = 28, _tick = 27083, _time = 1.654e+09, train_seconds = 1.2895e+04)
[2022-05-31 17:45:21,270][root][INFO] - Step 85084160 @ 6138.7 SPS. Inference batcher size: 129. Learner queue size: 19. Other stats: (step = 85084160, mean_episode_return = 143.75, mean_episode_step = 690.5, total_loss = 106.67, pg_loss = 21.753, baseline_loss = 91.162, entropy_loss = -6.2486, learner_queue_size = 32, _tick = 27093, _time = 1.654e+09, train_seconds = 1.29e+04)
[2022-05-31 17:45:26,274][root][INFO] - Step 85120000 @ 7162.6 SPS. Inference batcher size: 25. Learner queue size: 12. Other stats: (step = 85120000, mean_episode_return = 250.77, mean_episode_step = 827.74, total_loss = 246.94, pg_loss = -41.738, baseline_loss = 295.3, entropy_loss = -6.6233, learner_queue_size = 12, _tick = 27106, _time = 1.654e+09, train_seconds = 1.2905e+04)
[2022-05-31 17:45:31,280][root][INFO] - Step 85150720 @ 6136.1 SPS. Inference batcher size: 163. Learner queue size: 14. Other stats: (step = 85150720, mean_episode_return = 114.17, mean_episode_step = 1029.7, total_loss = 402.19, pg_loss = 273.44, baseline_loss = 135.1, entropy_loss = -6.3543, learner_queue_size = 26, _tick = 27117, _time = 1.654e+09, train_seconds = 1.291e+04)
[2022-05-31 17:45:36,286][root][INFO] - Step 85184000 @ 6648.8 SPS. Inference batcher size: 36. Learner queue size: 21. Other stats: (step = 85184000, mean_episode_return = 155.2, mean_episode_step = 683.0, total_loss = 2.3515, pg_loss = -104.81, baseline_loss = 113.39, entropy_loss = -6.2203, learner_queue_size = 16, _tick = 27129, _time = 1.654e+09, train_seconds = 1.2915e+04)
[2022-05-31 17:45:41,292][root][INFO] - Step 85217280 @ 6647.5 SPS. Inference batcher size: 120. Learner queue size: 15. Other stats: (step = 85217280, mean_episode_return = 161.9, mean_episode_step = 1250.6, total_loss = 86.729, pg_loss = -32.229, baseline_loss = 124.74, entropy_loss = -5.783, learner_queue_size = 23, _tick = 27140, _time = 1.654e+09, train_seconds = 1.292e+04)
[2022-05-31 17:45:46,298][root][INFO] - Step 85250560 @ 6648.6 SPS. Inference batcher size: 102. Learner queue size: 12. Other stats: (step = 85250560, mean_episode_return = 267.94, mean_episode_step = 738.84, total_loss = 68.931, pg_loss = 2.3934, baseline_loss = 72.968, entropy_loss = -6.4311, learner_queue_size = 22, _tick = 27150, _time = 1.654e+09, train_seconds = 1.2925e+04)
[2022-05-31 17:45:51,304][root][INFO] - Step 85283840 @ 6648.5 SPS. Inference batcher size: 98. Learner queue size: 28. Other stats: (step = 85283840, mean_episode_return = 61.221, mean_episode_step = 574.67, total_loss = 20.292, pg_loss = -54.752, baseline_loss = 81.429, entropy_loss = -6.3847, learner_queue_size = 16, _tick = 27162, _time = 1.654e+09, train_seconds = 1.293e+04)
[2022-05-31 17:45:56,306][root][INFO] - Step 85317120 @ 6652.9 SPS. Inference batcher size: 122. Learner queue size: 27. Other stats: (step = 85317120, mean_episode_return = 369.72, mean_episode_step = 1274.8, total_loss = 97.757, pg_loss = 64.404, baseline_loss = 39.625, entropy_loss = -6.2716, learner_queue_size = 19, _tick = 27174, _time = 1.654e+09, train_seconds = 1.2935e+04)
[2022-05-31 17:46:01,312][root][INFO] - Step 85347840 @ 6136.6 SPS. Inference batcher size: 163. Learner queue size: 15. Other stats: (step = 85347840, mean_episode_return = 43.105, mean_episode_step = 609.49, total_loss = 408.58, pg_loss = 223.79, baseline_loss = 190.98, entropy_loss = -6.1868, learner_queue_size = 19, _tick = 27185, _time = 1.654e+09, train_seconds = 1.294e+04)
[2022-05-31 17:46:06,315][root][INFO] - Step 85381120 @ 6651.5 SPS. Inference batcher size: 91. Learner queue size: 11. Other stats: (step = 85381120, mean_episode_return = 251.28, mean_episode_step = 731.34, total_loss = -142.44, pg_loss = -217.88, baseline_loss = 81.35, entropy_loss = -5.9123, learner_queue_size = 17, _tick = 27198, _time = 1.654e+09, train_seconds = 1.2945e+04)
[2022-05-31 17:46:11,318][root][INFO] - Step 85414400 @ 6652.4 SPS. Inference batcher size: 115. Learner queue size: 17. Other stats: (step = 85414400, mean_episode_return = 235.96, mean_episode_step = 539.24, total_loss = 170.65, pg_loss = 19.152, baseline_loss = 157.33, entropy_loss = -5.8336, learner_queue_size = 25, _tick = 27211, _time = 1.654e+09, train_seconds = 1.295e+04)
[2022-05-31 17:46:16,322][root][INFO] - Step 85447680 @ 6650.8 SPS. Inference batcher size: 112. Learner queue size: 1. Other stats: (step = 85447680, mean_episode_return = 180.12, mean_episode_step = 671.82, total_loss = 218.28, pg_loss = -132.66, baseline_loss = 356.77, entropy_loss = -5.8355, learner_queue_size = 13, _tick = 27223, _time = 1.654e+09, train_seconds = 1.2955e+04)
[2022-05-31 17:46:21,326][root][INFO] - Step 85480960 @ 6650.6 SPS. Inference batcher size: 123. Learner queue size: 1. Other stats: (step = 85480960, mean_episode_return = 182.17, mean_episode_step = 607.33, total_loss = 98.138, pg_loss = 36.893, baseline_loss = 67.743, entropy_loss = -6.4987, learner_queue_size = 8, _tick = 27236, _time = 1.654e+09, train_seconds = 1.296e+04)
[2022-05-31 17:46:26,332][root][INFO] - Step 85511680 @ 6136.5 SPS. Inference batcher size: 102. Learner queue size: 20. Other stats: (step = 85511680, mean_episode_return = 191.04, mean_episode_step = 576.69, total_loss = -30.788, pg_loss = -98.948, baseline_loss = 74.285, entropy_loss = -6.1249, learner_queue_size = 16, _tick = 27246, _time = 1.654e+09, train_seconds = 1.2965e+04)
[2022-05-31 17:46:31,334][root][INFO] - Step 85544960 @ 6653.5 SPS. Inference batcher size: 169. Learner queue size: 18. Other stats: (step = 85544960, mean_episode_return = None, mean_episode_step = 629.09, total_loss = 80.687, pg_loss = 5.7475, baseline_loss = 81.466, entropy_loss = -6.5268, learner_queue_size = 19, _tick = 27257, _time = 1.654e+09, train_seconds = 1.297e+04)
[2022-05-31 17:46:36,338][root][INFO] - Step 85578240 @ 6650.8 SPS. Inference batcher size: 33. Learner queue size: 8. Other stats: (step = 85578240, mean_episode_return = 252.73, mean_episode_step = 733.86, total_loss = 226.68, pg_loss = 117.04, baseline_loss = 115.9, entropy_loss = -6.2555, learner_queue_size = 28, _tick = 27268, _time = 1.654e+09, train_seconds = 1.2975e+04)
[2022-05-31 17:46:41,342][root][INFO] - Step 85611520 @ 6650.2 SPS. Inference batcher size: 11. Learner queue size: 0. Other stats: (step = 85611520, mean_episode_return = 317.27, mean_episode_step = 665.99, total_loss = 143.35, pg_loss = 69.003, baseline_loss = 80.295, entropy_loss = -5.9442, learner_queue_size = 15, _tick = 27279, _time = 1.654e+09, train_seconds = 1.298e+04)
[2022-05-31 17:46:46,346][root][INFO] - Step 85644800 @ 6651.2 SPS. Inference batcher size: 11. Learner queue size: 26. Other stats: (step = 85644800, mean_episode_return = 57.91, mean_episode_step = 740.32, total_loss = -54.494, pg_loss = -116.29, baseline_loss = 68.176, entropy_loss = -6.3751, learner_queue_size = 13, _tick = 27291, _time = 1.654e+09, train_seconds = 1.2985e+04)
[2022-05-31 17:46:51,350][root][INFO] - Step 85675520 @ 6139.1 SPS. Inference batcher size: 174. Learner queue size: 9. Other stats: (step = 85675520, mean_episode_return = None, mean_episode_step = 889.62, total_loss = -150.23, pg_loss = -163.44, baseline_loss = 20.084, entropy_loss = -6.8647, learner_queue_size = 14, _tick = 27301, _time = 1.654e+09, train_seconds = 1.299e+04)
[2022-05-31 17:46:56,352][root][INFO] - Step 85708800 @ 6653.2 SPS. Inference batcher size: 148. Learner queue size: 9. Other stats: (step = 85708800, mean_episode_return = 63.87, mean_episode_step = 846.17, total_loss = 111.69, pg_loss = -218.74, baseline_loss = 336.98, entropy_loss = -6.5474, learner_queue_size = 19, _tick = 27313, _time = 1.654e+09, train_seconds = 1.2995e+04)
[2022-05-31 17:47:01,358][root][INFO] - Step 85742080 @ 6648.2 SPS. Inference batcher size: 150. Learner queue size: 10. Other stats: (step = 85742080, mean_episode_return = 189.94, mean_episode_step = 1654.7, total_loss = 621.66, pg_loss = 68.855, baseline_loss = 559.48, entropy_loss = -6.6679, learner_queue_size = 26, _tick = 27326, _time = 1.654e+09, train_seconds = 1.3e+04)
[2022-05-31 17:47:06,362][root][INFO] - Step 85775360 @ 6650.7 SPS. Inference batcher size: 127. Learner queue size: 0. Other stats: (step = 85775360, mean_episode_return = 306.63, mean_episode_step = 655.77, total_loss = -22.133, pg_loss = -70.216, baseline_loss = 54.256, entropy_loss = -6.1729, learner_queue_size = 14, _tick = 27337, _time = 1.654e+09, train_seconds = 1.3005e+04)
[2022-05-31 17:47:11,367][root][INFO] - Step 85808640 @ 6648.5 SPS. Inference batcher size: 115. Learner queue size: 1. Other stats: (step = 85808640, mean_episode_return = 134.48, mean_episode_step = 864.24, total_loss = 46.666, pg_loss = 10.319, baseline_loss = 42.884, entropy_loss = -6.5372, learner_queue_size = 25, _tick = 27350, _time = 1.654e+09, train_seconds = 1.301e+04)
[2022-05-31 17:47:16,373][root][INFO] - Step 85839360 @ 6137.1 SPS. Inference batcher size: 129. Learner queue size: 20. Other stats: (step = 85839360, mean_episode_return = 183.5, mean_episode_step = 636.31, total_loss = 605.21, pg_loss = 353.22, baseline_loss = 258.0, entropy_loss = -6.0183, learner_queue_size = 24, _tick = 27362, _time = 1.654e+09, train_seconds = 1.3015e+04)
[2022-05-31 17:47:21,378][root][INFO] - Step 85872640 @ 6649.5 SPS. Inference batcher size: 83. Learner queue size: 18. Other stats: (step = 85872640, mean_episode_return = 210.27, mean_episode_step = 580.61, total_loss = 59.203, pg_loss = -11.441, baseline_loss = 76.509, entropy_loss = -5.8651, learner_queue_size = 18, _tick = 27375, _time = 1.654e+09, train_seconds = 1.302e+04)
[2022-05-31 17:47:26,382][root][INFO] - Step 85905920 @ 6650.8 SPS. Inference batcher size: 113. Learner queue size: 15. Other stats: (step = 85905920, mean_episode_return = 221.16, mean_episode_step = 611.51, total_loss = 42.73, pg_loss = -244.5, baseline_loss = 293.13, entropy_loss = -5.8991, learner_queue_size = 20, _tick = 27386, _time = 1.654e+09, train_seconds = 1.3025e+04)
[2022-05-31 17:47:31,386][root][INFO] - Step 85939200 @ 6650.7 SPS. Inference batcher size: 69. Learner queue size: 7. Other stats: (step = 85939200, mean_episode_return = 81.735, mean_episode_step = 661.14, total_loss = 197.59, pg_loss = 78.236, baseline_loss = 125.86, entropy_loss = -6.5136, learner_queue_size = 15, _tick = 27399, _time = 1.654e+09, train_seconds = 1.303e+04)
[2022-05-31 17:47:36,390][root][INFO] - Step 85972480 @ 6650.8 SPS. Inference batcher size: 103. Learner queue size: 5. Other stats: (step = 85972480, mean_episode_return = 149.96, mean_episode_step = 581.94, total_loss = -73.58, pg_loss = -209.65, baseline_loss = 142.65, entropy_loss = -6.585, learner_queue_size = 31, _tick = 27411, _time = 1.654e+09, train_seconds = 1.3035e+04)
[2022-05-31 17:47:41,394][root][INFO] - Step 86005760 @ 6650.6 SPS. Inference batcher size: 155. Learner queue size: 30. Other stats: (step = 86005760, mean_episode_return = 404.35, mean_episode_step = 1381.5, total_loss = 63.94, pg_loss = -38.653, baseline_loss = 109.11, entropy_loss = -6.5178, learner_queue_size = 13, _tick = 27423, _time = 1.654e+09, train_seconds = 1.304e+04)
[2022-05-31 17:47:46,398][root][INFO] - Step 86039040 @ 6650.7 SPS. Inference batcher size: 107. Learner queue size: 20. Other stats: (step = 86039040, mean_episode_return = 2.9796, mean_episode_step = 578.47, total_loss = -57.634, pg_loss = -111.25, baseline_loss = 60.232, entropy_loss = -6.6189, learner_queue_size = 16, _tick = 27434, _time = 1.654e+09, train_seconds = 1.3045e+04)
[2022-05-31 17:47:51,402][root][INFO] - Step 86072320 @ 6650.8 SPS. Inference batcher size: 118. Learner queue size: 19. Other stats: (step = 86072320, mean_episode_return = 241.53, mean_episode_step = 605.88, total_loss = 453.58, pg_loss = 154.97, baseline_loss = 304.66, entropy_loss = -6.0457, learner_queue_size = 19, _tick = 27446, _time = 1.654e+09, train_seconds = 1.305e+04)
[2022-05-31 17:47:56,408][root][INFO] - Step 86103040 @ 6136.4 SPS. Inference batcher size: 81. Learner queue size: 11. Other stats: (step = 86103040, mean_episode_return = 316.12, mean_episode_step = 510.9, total_loss = -219.49, pg_loss = -274.97, baseline_loss = 61.673, entropy_loss = -6.1859, learner_queue_size = 15, _tick = 27457, _time = 1.654e+09, train_seconds = 1.3055e+04)
[2022-05-31 17:48:01,414][root][INFO] - Step 86136320 @ 6648.3 SPS. Inference batcher size: 89. Learner queue size: 11. Other stats: (step = 86136320, mean_episode_return = 108.11, mean_episode_step = 854.44, total_loss = 320.33, pg_loss = 162.79, baseline_loss = 163.62, entropy_loss = -6.0788, learner_queue_size = 13, _tick = 27469, _time = 1.654e+09, train_seconds = 1.306e+04)
[2022-05-31 17:48:06,418][root][INFO] - Step 86169600 @ 6650.5 SPS. Inference batcher size: 130. Learner queue size: 11. Other stats: (step = 86169600, mean_episode_return = 236.23, mean_episode_step = 549.89, total_loss = 125.68, pg_loss = 34.243, baseline_loss = 97.695, entropy_loss = -6.2599, learner_queue_size = 21, _tick = 27482, _time = 1.654e+09, train_seconds = 1.3065e+04)
[2022-05-31 17:48:11,422][root][INFO] - Step 86202880 @ 6650.7 SPS. Inference batcher size: 150. Learner queue size: 6. Other stats: (step = 86202880, mean_episode_return = 161.38, mean_episode_step = 495.36, total_loss = 462.75, pg_loss = 242.76, baseline_loss = 225.98, entropy_loss = -5.9914, learner_queue_size = 13, _tick = 27493, _time = 1.654e+09, train_seconds = 1.307e+04)
[2022-05-31 17:48:16,428][root][INFO] - Step 86236160 @ 6648.0 SPS. Inference batcher size: 108. Learner queue size: 7. Other stats: (step = 86236160, mean_episode_return = 199.92, mean_episode_step = 608.68, total_loss = 282.32, pg_loss = 166.43, baseline_loss = 122.21, entropy_loss = -6.3142, learner_queue_size = 28, _tick = 27505, _time = 1.654e+09, train_seconds = 1.3075e+04)
[2022-05-31 17:48:21,434][root][INFO] - Step 86269440 @ 6648.2 SPS. Inference batcher size: 135. Learner queue size: 31. Other stats: (step = 86269440, mean_episode_return = 455.91, mean_episode_step = 1372.2, total_loss = 378.47, pg_loss = 160.73, baseline_loss = 223.15, entropy_loss = -5.4109, learner_queue_size = 19, _tick = 27516, _time = 1.654e+09, train_seconds = 1.308e+04)
[2022-05-31 17:48:26,438][root][INFO] - Step 86302720 @ 6650.6 SPS. Inference batcher size: 116. Learner queue size: 31. Other stats: (step = 86302720, mean_episode_return = 476.13, mean_episode_step = 550.71, total_loss = 379.62, pg_loss = 142.8, baseline_loss = 242.41, entropy_loss = -5.5844, learner_queue_size = 12, _tick = 27528, _time = 1.654e+09, train_seconds = 1.3085e+04)
[2022-05-31 17:48:31,444][root][INFO] - Step 86333440 @ 6136.7 SPS. Inference batcher size: 86. Learner queue size: 15. Other stats: (step = 86333440, mean_episode_return = 235.42, mean_episode_step = 677.21, total_loss = 208.96, pg_loss = -93.957, baseline_loss = 308.9, entropy_loss = -5.9844, learner_queue_size = 19, _tick = 27540, _time = 1.654e+09, train_seconds = 1.309e+04)
[2022-05-31 17:48:36,446][root][INFO] - Step 86366720 @ 6653.4 SPS. Inference batcher size: 130. Learner queue size: 15. Other stats: (step = 86366720, mean_episode_return = 151.8, mean_episode_step = 623.53, total_loss = 88.034, pg_loss = -45.123, baseline_loss = 139.41, entropy_loss = -6.2513, learner_queue_size = 29, _tick = 27553, _time = 1.654e+09, train_seconds = 1.3095e+04)
[2022-05-31 17:48:41,452][root][INFO] - Step 86400000 @ 6648.1 SPS. Inference batcher size: 75. Learner queue size: 13. Other stats: (step = 86400000, mean_episode_return = 408.04, mean_episode_step = 418.34, total_loss = 265.14, pg_loss = 151.46, baseline_loss = 119.46, entropy_loss = -5.781, learner_queue_size = 26, _tick = 27565, _time = 1.654e+09, train_seconds = 1.31e+04)
[2022-05-31 17:48:46,458][root][INFO] - Step 86433280 @ 6648.1 SPS. Inference batcher size: 52. Learner queue size: 2. Other stats: (step = 86433280, mean_episode_return = 236.87, mean_episode_step = 584.86, total_loss = -33.644, pg_loss = -158.8, baseline_loss = 131.38, entropy_loss = -6.2269, learner_queue_size = 14, _tick = 27578, _time = 1.654e+09, train_seconds = 1.3105e+04)
[2022-05-31 17:48:51,462][root][INFO] - Step 86466560 @ 6650.5 SPS. Inference batcher size: 145. Learner queue size: 3. Other stats: (step = 86466560, mean_episode_return = 256.89, mean_episode_step = 498.67, total_loss = 23.8, pg_loss = -106.81, baseline_loss = 136.34, entropy_loss = -5.7213, learner_queue_size = 12, _tick = 27590, _time = 1.654e+09, train_seconds = 1.311e+04)
[2022-05-31 17:48:56,468][root][INFO] - Step 86497280 @ 6136.6 SPS. Inference batcher size: 115. Learner queue size: 13. Other stats: (step = 86497280, mean_episode_return = None, mean_episode_step = 854.56, total_loss = 235.18, pg_loss = 140.94, baseline_loss = 100.76, entropy_loss = -6.5233, learner_queue_size = 11, _tick = 27600, _time = 1.654e+09, train_seconds = 1.3115e+04)
[2022-05-31 17:49:01,474][root][INFO] - Step 86530560 @ 6648.2 SPS. Inference batcher size: 131. Learner queue size: 11. Other stats: (step = 86530560, mean_episode_return = 182.72, mean_episode_step = 685.69, total_loss = 287.54, pg_loss = 199.69, baseline_loss = 94.23, entropy_loss = -6.3824, learner_queue_size = 21, _tick = 27611, _time = 1.654e+09, train_seconds = 1.312e+04)
[2022-05-31 17:49:06,479][root][INFO] - Step 86563840 @ 6648.6 SPS. Inference batcher size: 116. Learner queue size: 22. Other stats: (step = 86563840, mean_episode_return = 196.5, mean_episode_step = 737.05, total_loss = -213.79, pg_loss = -235.13, baseline_loss = 28.134, entropy_loss = -6.7933, learner_queue_size = 21, _tick = 27623, _time = 1.654e+09, train_seconds = 1.3125e+04)
[2022-05-31 17:49:11,482][root][INFO] - Step 86597120 @ 6652.5 SPS. Inference batcher size: 91. Learner queue size: 28. Other stats: (step = 86597120, mean_episode_return = 61.93, mean_episode_step = 589.67, total_loss = 216.26, pg_loss = 114.16, baseline_loss = 108.54, entropy_loss = -6.433, learner_queue_size = 14, _tick = 27634, _time = 1.654e+09, train_seconds = 1.313e+04)
[2022-05-31 17:49:16,486][root][INFO] - Step 86630400 @ 6650.7 SPS. Inference batcher size: 26. Learner queue size: 24. Other stats: (step = 86630400, mean_episode_return = 112.54, mean_episode_step = 665.78, total_loss = 584.05, pg_loss = 352.39, baseline_loss = 237.63, entropy_loss = -5.9666, learner_queue_size = 18, _tick = 27646, _time = 1.654e+09, train_seconds = 1.3135e+04)
[2022-05-31 17:49:21,490][root][INFO] - Step 86661120 @ 6139.2 SPS. Inference batcher size: 129. Learner queue size: 18. Other stats: (step = 86661120, mean_episode_return = 89.761, mean_episode_step = 509.24, total_loss = -32.349, pg_loss = -145.51, baseline_loss = 119.02, entropy_loss = -5.8649, learner_queue_size = 19, _tick = 27656, _time = 1.654e+09, train_seconds = 1.314e+04)
[2022-05-31 17:49:26,494][root][INFO] - Step 86694400 @ 6650.6 SPS. Inference batcher size: 127. Learner queue size: 25. Other stats: (step = 86694400, mean_episode_return = 253.03, mean_episode_step = 1436.1, total_loss = 540.96, pg_loss = 214.95, baseline_loss = 332.05, entropy_loss = -6.0391, learner_queue_size = 14, _tick = 27669, _time = 1.654e+09, train_seconds = 1.3145e+04)
[2022-05-31 17:49:31,496][root][INFO] - Step 86727680 @ 6653.1 SPS. Inference batcher size: 141. Learner queue size: 28. Other stats: (step = 86727680, mean_episode_return = None, mean_episode_step = 569.62, total_loss = 514.25, pg_loss = 305.53, baseline_loss = 214.65, entropy_loss = -5.9194, learner_queue_size = 21, _tick = 27681, _time = 1.654e+09, train_seconds = 1.315e+04)
[2022-05-31 17:49:36,502][root][INFO] - Step 86760960 @ 6648.4 SPS. Inference batcher size: 104. Learner queue size: 11. Other stats: (step = 86760960, mean_episode_return = 235.39, mean_episode_step = 538.34, total_loss = 694.96, pg_loss = 288.16, baseline_loss = 412.2, entropy_loss = -5.4077, learner_queue_size = 16, _tick = 27693, _time = 1.654e+09, train_seconds = 1.3155e+04)
[2022-05-31 17:49:41,506][root][INFO] - Step 86794240 @ 6650.6 SPS. Inference batcher size: 131. Learner queue size: 12. Other stats: (step = 86794240, mean_episode_return = 310.83, mean_episode_step = 719.13, total_loss = 593.7, pg_loss = 298.14, baseline_loss = 301.54, entropy_loss = -5.9762, learner_queue_size = 19, _tick = 27705, _time = 1.654e+09, train_seconds = 1.316e+04)
[2022-05-31 17:49:46,510][root][INFO] - Step 86827520 @ 6650.7 SPS. Inference batcher size: 34. Learner queue size: 6. Other stats: (step = 86827520, mean_episode_return = 236.53, mean_episode_step = 634.6, total_loss = -7.7083, pg_loss = -120.67, baseline_loss = 118.94, entropy_loss = -5.9702, learner_queue_size = 20, _tick = 27718, _time = 1.654e+09, train_seconds = 1.3165e+04)
[2022-05-31 17:49:51,516][root][INFO] - Step 86860800 @ 6648.1 SPS. Inference batcher size: 118. Learner queue size: 2. Other stats: (step = 86860800, mean_episode_return = 244.31, mean_episode_step = 817.47, total_loss = 45.061, pg_loss = -53.771, baseline_loss = 105.29, entropy_loss = -6.459, learner_queue_size = 26, _tick = 27730, _time = 1.654e+09, train_seconds = 1.317e+04)
[2022-05-31 17:49:56,518][root][INFO] - Step 86894080 @ 6652.9 SPS. Inference batcher size: 144. Learner queue size: 19. Other stats: (step = 86894080, mean_episode_return = 554.58, mean_episode_step = 469.38, total_loss = 496.99, pg_loss = 46.245, baseline_loss = 456.44, entropy_loss = -5.6977, learner_queue_size = 24, _tick = 27742, _time = 1.654e+09, train_seconds = 1.3175e+04)
[2022-05-31 17:50:01,525][root][INFO] - Step 86924800 @ 6136.2 SPS. Inference batcher size: 93. Learner queue size: 16. Other stats: (step = 86924800, mean_episode_return = 180.38, mean_episode_step = 581.92, total_loss = 2.5657, pg_loss = -312.88, baseline_loss = 320.82, entropy_loss = -5.3773, learner_queue_size = 12, _tick = 27754, _time = 1.654e+09, train_seconds = 1.318e+04)
[2022-05-31 17:50:06,531][root][INFO] - Step 86958080 @ 6648.1 SPS. Inference batcher size: 164. Learner queue size: 14. Other stats: (step = 86958080, mean_episode_return = None, mean_episode_step = 636.91, total_loss = -344.46, pg_loss = -495.98, baseline_loss = 157.91, entropy_loss = -6.3889, learner_queue_size = 9, _tick = 27765, _time = 1.654e+09, train_seconds = 1.3185e+04)
[2022-05-31 17:50:11,536][root][INFO] - Step 86991360 @ 6648.5 SPS. Inference batcher size: 79. Learner queue size: 10. Other stats: (step = 86991360, mean_episode_return = 230.22, mean_episode_step = 490.62, total_loss = 25.009, pg_loss = -84.016, baseline_loss = 115.23, entropy_loss = -6.2007, learner_queue_size = 13, _tick = 27777, _time = 1.654e+09, train_seconds = 1.319e+04)
[2022-05-31 17:50:16,542][root][INFO] - Step 87024640 @ 6648.3 SPS. Inference batcher size: 127. Learner queue size: 9. Other stats: (step = 87024640, mean_episode_return = 45.89, mean_episode_step = 536.55, total_loss = 83.549, pg_loss = -61.341, baseline_loss = 151.08, entropy_loss = -6.1914, learner_queue_size = 17, _tick = 27789, _time = 1.654e+09, train_seconds = 1.3195e+04)
[2022-05-31 17:50:21,546][root][INFO] - Step 87057920 @ 6650.6 SPS. Inference batcher size: 108. Learner queue size: 10. Other stats: (step = 87057920, mean_episode_return = 518.57, mean_episode_step = 514.79, total_loss = 245.77, pg_loss = 144.62, baseline_loss = 107.21, entropy_loss = -6.0616, learner_queue_size = 29, _tick = 27801, _time = 1.654e+09, train_seconds = 1.32e+04)
[2022-05-31 17:50:26,548][root][INFO] - Step 87091200 @ 6653.8 SPS. Inference batcher size: 162. Learner queue size: 3. Other stats: (step = 87091200, mean_episode_return = 280.44, mean_episode_step = 574.33, total_loss = 95.541, pg_loss = -0.46989, baseline_loss = 101.44, entropy_loss = -5.4283, learner_queue_size = 22, _tick = 27812, _time = 1.654e+09, train_seconds = 1.3205e+04)
[2022-05-31 17:50:31,550][root][INFO] - Step 87124480 @ 6653.0 SPS. Inference batcher size: 100. Learner queue size: 1. Other stats: (step = 87124480, mean_episode_return = 79.741, mean_episode_step = 1591.6, total_loss = 184.49, pg_loss = 87.541, baseline_loss = 102.53, entropy_loss = -5.5735, learner_queue_size = 19, _tick = 27824, _time = 1.654e+09, train_seconds = 1.321e+04)
[2022-05-31 17:50:36,556][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 17:50:36,698][root][INFO] - Step 87155200 @ 6136.3 SPS. Inference batcher size: 96. Learner queue size: 26. Other stats: (step = 87157760, mean_episode_return = 153.8, mean_episode_step = 582.78, total_loss = 461.42, pg_loss = -16.302, baseline_loss = 483.28, entropy_loss = -5.5571, learner_queue_size = 24, _tick = 27836, _time = 1.654e+09, train_seconds = 1.3215e+04)
[2022-05-31 17:50:41,702][root][INFO] - Step 87191040 @ 6965.0 SPS. Inference batcher size: 103. Learner queue size: 23. Other stats: (step = 87191040, mean_episode_return = 263.64, mean_episode_step = 739.4, total_loss = 179.01, pg_loss = 78.822, baseline_loss = 105.73, entropy_loss = -5.5479, learner_queue_size = 17, _tick = 27849, _time = 1.654e+09, train_seconds = 1.322e+04)
[2022-05-31 17:50:46,707][root][INFO] - Step 87221760 @ 6138.2 SPS. Inference batcher size: 41. Learner queue size: 8. Other stats: (step = 87221760, mean_episode_return = 194.36, mean_episode_step = 456.8, total_loss = 174.47, pg_loss = -66.189, baseline_loss = 246.05, entropy_loss = -5.3879, learner_queue_size = 16, _tick = 27860, _time = 1.654e+09, train_seconds = 1.3225e+04)
[2022-05-31 17:50:51,710][root][INFO] - Step 87255040 @ 6651.3 SPS. Inference batcher size: 75. Learner queue size: 12. Other stats: (step = 87255040, mean_episode_return = 433.89, mean_episode_step = 588.87, total_loss = -142.01, pg_loss = -211.44, baseline_loss = 75.739, entropy_loss = -6.3115, learner_queue_size = 13, _tick = 27872, _time = 1.654e+09, train_seconds = 1.323e+04)
[2022-05-31 17:50:56,714][root][INFO] - Step 87288320 @ 6651.0 SPS. Inference batcher size: 82. Learner queue size: 12. Other stats: (step = 87288320, mean_episode_return = 155.14, mean_episode_step = 642.25, total_loss = 528.63, pg_loss = 308.11, baseline_loss = 226.73, entropy_loss = -6.2076, learner_queue_size = 21, _tick = 27884, _time = 1.654e+09, train_seconds = 1.3235e+04)
[2022-05-31 17:51:01,719][root][INFO] - Step 87321600 @ 6648.6 SPS. Inference batcher size: 51. Learner queue size: 4. Other stats: (step = 87321600, mean_episode_return = 261.9, mean_episode_step = 723.61, total_loss = 379.44, pg_loss = 267.22, baseline_loss = 118.7, entropy_loss = -6.4792, learner_queue_size = 23, _tick = 27897, _time = 1.654e+09, train_seconds = 1.324e+04)
[2022-05-31 17:51:06,722][root][INFO] - Step 87354880 @ 6652.8 SPS. Inference batcher size: 145. Learner queue size: 29. Other stats: (step = 87354880, mean_episode_return = 193.36, mean_episode_step = 559.06, total_loss = -113.85, pg_loss = -171.55, baseline_loss = 64.023, entropy_loss = -6.3191, learner_queue_size = 23, _tick = 27909, _time = 1.654e+09, train_seconds = 1.3245e+04)
[2022-05-31 17:51:11,726][root][INFO] - Step 87388160 @ 6650.7 SPS. Inference batcher size: 187. Learner queue size: 20. Other stats: (step = 87388160, mean_episode_return = None, mean_episode_step = 782.47, total_loss = 126.81, pg_loss = 105.55, baseline_loss = 28.204, entropy_loss = -6.9501, learner_queue_size = 17, _tick = 27920, _time = 1.654e+09, train_seconds = 1.325e+04)
[2022-05-31 17:51:16,732][root][INFO] - Step 87421440 @ 6648.0 SPS. Inference batcher size: 28. Learner queue size: 12. Other stats: (step = 87421440, mean_episode_return = 114.25, mean_episode_step = 667.6, total_loss = -90.476, pg_loss = -105.73, baseline_loss = 21.582, entropy_loss = -6.3326, learner_queue_size = 11, _tick = 27929, _time = 1.654e+09, train_seconds = 1.3255e+04)
[2022-05-31 17:51:21,738][root][INFO] - Step 87452160 @ 6136.6 SPS. Inference batcher size: 174. Learner queue size: 13. Other stats: (step = 87452160, mean_episode_return = 133.01, mean_episode_step = 732.54, total_loss = -55.149, pg_loss = -85.009, baseline_loss = 36.199, entropy_loss = -6.3385, learner_queue_size = 14, _tick = 27939, _time = 1.654e+09, train_seconds = 1.326e+04)
[2022-05-31 17:51:26,744][root][INFO] - Step 87485440 @ 6648.1 SPS. Inference batcher size: 142. Learner queue size: 26. Other stats: (step = 87485440, mean_episode_return = 106.57, mean_episode_step = 1494.2, total_loss = 1081.4, pg_loss = 658.12, baseline_loss = 428.99, entropy_loss = -5.698, learner_queue_size = 17, _tick = 27952, _time = 1.654e+09, train_seconds = 1.3265e+04)
[2022-05-31 17:51:31,747][root][INFO] - Step 87518720 @ 6652.5 SPS. Inference batcher size: 22. Learner queue size: 22. Other stats: (step = 87518720, mean_episode_return = 264.5, mean_episode_step = 629.32, total_loss = -63.219, pg_loss = -124.84, baseline_loss = 67.151, entropy_loss = -5.5335, learner_queue_size = 23, _tick = 27964, _time = 1.654e+09, train_seconds = 1.327e+04)
[2022-05-31 17:51:36,753][root][INFO] - Step 87552000 @ 6647.5 SPS. Inference batcher size: 103. Learner queue size: 15. Other stats: (step = 87552000, mean_episode_return = 219.84, mean_episode_step = 535.39, total_loss = 121.96, pg_loss = -52.313, baseline_loss = 179.68, entropy_loss = -5.4113, learner_queue_size = 25, _tick = 27976, _time = 1.654e+09, train_seconds = 1.3275e+04)
[2022-05-31 17:51:41,759][root][INFO] - Step 87585280 @ 6648.2 SPS. Inference batcher size: 129. Learner queue size: 1. Other stats: (step = 87585280, mean_episode_return = 272.32, mean_episode_step = 638.2, total_loss = -15.276, pg_loss = -39.15, baseline_loss = 29.922, entropy_loss = -6.0482, learner_queue_size = 13, _tick = 27989, _time = 1.654e+09, train_seconds = 1.328e+04)
[2022-05-31 17:51:46,762][root][INFO] - Step 87618560 @ 6651.9 SPS. Inference batcher size: 115. Learner queue size: 20. Other stats: (step = 87618560, mean_episode_return = 151.07, mean_episode_step = 738.19, total_loss = 360.16, pg_loss = 292.4, baseline_loss = 73.454, entropy_loss = -5.6889, learner_queue_size = 8, _tick = 28002, _time = 1.654e+09, train_seconds = 1.3285e+04)
[2022-05-31 17:51:51,765][root][INFO] - Step 87649280 @ 6139.7 SPS. Inference batcher size: 141. Learner queue size: 20. Other stats: (step = 87649280, mean_episode_return = 268.45, mean_episode_step = 588.31, total_loss = 169.01, pg_loss = -22.683, baseline_loss = 197.04, entropy_loss = -5.3375, learner_queue_size = 31, _tick = 28013, _time = 1.654e+09, train_seconds = 1.329e+04)
[2022-05-31 17:51:56,771][root][INFO] - Step 87682560 @ 6648.0 SPS. Inference batcher size: 126. Learner queue size: 13. Other stats: (step = 87682560, mean_episode_return = 205.82, mean_episode_step = 705.3, total_loss = -23.36, pg_loss = -112.61, baseline_loss = 95.175, entropy_loss = -5.9296, learner_queue_size = 23, _tick = 28025, _time = 1.654e+09, train_seconds = 1.3296e+04)
[2022-05-31 17:52:01,778][root][INFO] - Step 87715840 @ 6648.0 SPS. Inference batcher size: 67. Learner queue size: 19. Other stats: (step = 87715840, mean_episode_return = 156.33, mean_episode_step = 714.66, total_loss = 61.656, pg_loss = -20.64, baseline_loss = 88.263, entropy_loss = -5.9667, learner_queue_size = 29, _tick = 28037, _time = 1.654e+09, train_seconds = 1.33e+04)
[2022-05-31 17:52:06,782][root][INFO] - Step 87749120 @ 6650.0 SPS. Inference batcher size: 103. Learner queue size: 20. Other stats: (step = 87749120, mean_episode_return = 320.52, mean_episode_step = 1554.2, total_loss = 167.98, pg_loss = 74.043, baseline_loss = 99.807, entropy_loss = -5.8661, learner_queue_size = 19, _tick = 28047, _time = 1.654e+09, train_seconds = 1.3306e+04)
[2022-05-31 17:52:11,786][root][INFO] - Step 87782400 @ 6650.8 SPS. Inference batcher size: 112. Learner queue size: 15. Other stats: (step = 87782400, mean_episode_return = 1274.3, mean_episode_step = 913.69, total_loss = 96.998, pg_loss = 30.271, baseline_loss = 72.838, entropy_loss = -6.1115, learner_queue_size = 22, _tick = 28058, _time = 1.654e+09, train_seconds = 1.331e+04)
[2022-05-31 17:52:16,790][root][INFO] - Step 87815680 @ 6650.5 SPS. Inference batcher size: 6. Learner queue size: 4. Other stats: (step = 87815680, mean_episode_return = 302.49, mean_episode_step = 696.4, total_loss = -58.778, pg_loss = -218.41, baseline_loss = 166.01, entropy_loss = -6.3759, learner_queue_size = 20, _tick = 28070, _time = 1.654e+09, train_seconds = 1.3316e+04)
[2022-05-31 17:52:21,794][root][INFO] - Step 87848960 @ 6650.9 SPS. Inference batcher size: 23. Learner queue size: 27. Other stats: (step = 87848960, mean_episode_return = 107.98, mean_episode_step = 649.75, total_loss = -54.94, pg_loss = -90.89, baseline_loss = 42.195, entropy_loss = -6.2452, learner_queue_size = 19, _tick = 28082, _time = 1.654e+09, train_seconds = 1.332e+04)
[2022-05-31 17:52:26,798][root][INFO] - Step 87882240 @ 6650.6 SPS. Inference batcher size: 98. Learner queue size: 25. Other stats: (step = 87882240, mean_episode_return = 180.99, mean_episode_step = 619.64, total_loss = 54.017, pg_loss = 13.118, baseline_loss = 47.302, entropy_loss = -6.4035, learner_queue_size = 19, _tick = 28094, _time = 1.654e+09, train_seconds = 1.3326e+04)
[2022-05-31 17:52:31,802][root][INFO] - Step 87915520 @ 6650.8 SPS. Inference batcher size: 171. Learner queue size: 28. Other stats: (step = 87915520, mean_episode_return = 118.56, mean_episode_step = 747.79, total_loss = 137.61, pg_loss = 1.3448, baseline_loss = 142.25, entropy_loss = -5.9815, learner_queue_size = 24, _tick = 28106, _time = 1.654e+09, train_seconds = 1.333e+04)
[2022-05-31 17:52:36,806][root][INFO] - Step 87948800 @ 6650.7 SPS. Inference batcher size: 80. Learner queue size: 23. Other stats: (step = 87948800, mean_episode_return = 117.43, mean_episode_step = 619.23, total_loss = 63.128, pg_loss = 2.5801, baseline_loss = 66.623, entropy_loss = -6.0749, learner_queue_size = 22, _tick = 28118, _time = 1.654e+09, train_seconds = 1.3336e+04)
[2022-05-31 17:52:41,812][root][INFO] - Step 87979520 @ 6136.6 SPS. Inference batcher size: 165. Learner queue size: 19. Other stats: (step = 87979520, mean_episode_return = 245.58, mean_episode_step = 607.74, total_loss = 223.6, pg_loss = 80.795, baseline_loss = 148.64, entropy_loss = -5.8358, learner_queue_size = 10, _tick = 28130, _time = 1.654e+09, train_seconds = 1.334e+04)
[2022-05-31 17:52:46,814][root][INFO] - Step 88012800 @ 6653.3 SPS. Inference batcher size: 145. Learner queue size: 21. Other stats: (step = 88012800, mean_episode_return = 141.27, mean_episode_step = 489.82, total_loss = -97.654, pg_loss = -169.14, baseline_loss = 77.372, entropy_loss = -5.8903, learner_queue_size = 13, _tick = 28142, _time = 1.654e+09, train_seconds = 1.3346e+04)
[2022-05-31 17:52:51,820][root][INFO] - Step 88046080 @ 6647.9 SPS. Inference batcher size: 111. Learner queue size: 17. Other stats: (step = 88046080, mean_episode_return = 294.01, mean_episode_step = 605.64, total_loss = 132.92, pg_loss = -35.278, baseline_loss = 174.27, entropy_loss = -6.0761, learner_queue_size = 17, _tick = 28154, _time = 1.654e+09, train_seconds = 1.335e+04)
[2022-05-31 17:52:56,826][root][INFO] - Step 88079360 @ 6648.0 SPS. Inference batcher size: 158. Learner queue size: 11. Other stats: (step = 88079360, mean_episode_return = 131.79, mean_episode_step = 627.6, total_loss = -55.09, pg_loss = -92.739, baseline_loss = 43.635, entropy_loss = -5.985, learner_queue_size = 19, _tick = 28167, _time = 1.654e+09, train_seconds = 1.3356e+04)
[2022-05-31 17:53:01,830][root][INFO] - Step 88112640 @ 6650.8 SPS. Inference batcher size: 89. Learner queue size: 6. Other stats: (step = 88112640, mean_episode_return = None, mean_episode_step = 649.22, total_loss = 212.3, pg_loss = 88.481, baseline_loss = 129.53, entropy_loss = -5.7075, learner_queue_size = 23, _tick = 28178, _time = 1.654e+09, train_seconds = 1.336e+04)
[2022-05-31 17:53:06,836][root][INFO] - Step 88145920 @ 6648.3 SPS. Inference batcher size: 94. Learner queue size: 4. Other stats: (step = 88145920, mean_episode_return = 239.9, mean_episode_step = 606.87, total_loss = 190.58, pg_loss = 41.565, baseline_loss = 154.97, entropy_loss = -5.9576, learner_queue_size = 12, _tick = 28189, _time = 1.654e+09, train_seconds = 1.3366e+04)
[2022-05-31 17:53:11,842][root][INFO] - Step 88176640 @ 6136.5 SPS. Inference batcher size: 122. Learner queue size: 19. Other stats: (step = 88176640, mean_episode_return = 283.37, mean_episode_step = 697.42, total_loss = 2.2804, pg_loss = -93.033, baseline_loss = 101.11, entropy_loss = -5.7937, learner_queue_size = 8, _tick = 28201, _time = 1.654e+09, train_seconds = 1.337e+04)
[2022-05-31 17:53:16,848][root][INFO] - Step 88209920 @ 6648.0 SPS. Inference batcher size: 111. Learner queue size: 25. Other stats: (step = 88209920, mean_episode_return = 223.58, mean_episode_step = 490.29, total_loss = 364.56, pg_loss = 81.693, baseline_loss = 288.83, entropy_loss = -5.9591, learner_queue_size = 21, _tick = 28213, _time = 1.654e+09, train_seconds = 1.3376e+04)
[2022-05-31 17:53:21,854][root][INFO] - Step 88243200 @ 6648.0 SPS. Inference batcher size: 93. Learner queue size: 16. Other stats: (step = 88243200, mean_episode_return = 197.39, mean_episode_step = 664.81, total_loss = 108.16, pg_loss = -140.54, baseline_loss = 254.8, entropy_loss = -6.102, learner_queue_size = 21, _tick = 28223, _time = 1.654e+09, train_seconds = 1.338e+04)
[2022-05-31 17:53:26,858][root][INFO] - Step 88276480 @ 6650.7 SPS. Inference batcher size: 48. Learner queue size: 14. Other stats: (step = 88276480, mean_episode_return = None, mean_episode_step = 744.44, total_loss = 756.76, pg_loss = 540.09, baseline_loss = 222.76, entropy_loss = -6.0826, learner_queue_size = 20, _tick = 28233, _time = 1.654e+09, train_seconds = 1.3386e+04)
[2022-05-31 17:53:31,863][root][INFO] - Step 88309760 @ 6649.8 SPS. Inference batcher size: 41. Learner queue size: 31. Other stats: (step = 88309760, mean_episode_return = 367.45, mean_episode_step = 691.49, total_loss = 176.05, pg_loss = -19.171, baseline_loss = 201.15, entropy_loss = -5.9231, learner_queue_size = 22, _tick = 28245, _time = 1.654e+09, train_seconds = 1.339e+04)
[2022-05-31 17:53:36,866][root][INFO] - Step 88343040 @ 6651.6 SPS. Inference batcher size: 58. Learner queue size: 28. Other stats: (step = 88343040, mean_episode_return = 139.56, mean_episode_step = 913.41, total_loss = 51.518, pg_loss = -11.557, baseline_loss = 69.252, entropy_loss = -6.1769, learner_queue_size = 19, _tick = 28256, _time = 1.654e+09, train_seconds = 1.3396e+04)
[2022-05-31 17:53:41,870][root][INFO] - Step 88373760 @ 6139.1 SPS. Inference batcher size: 114. Learner queue size: 18. Other stats: (step = 88373760, mean_episode_return = 44.3, mean_episode_step = 600.4, total_loss = 51.87, pg_loss = -21.692, baseline_loss = 79.468, entropy_loss = -5.9054, learner_queue_size = 10, _tick = 28268, _time = 1.654e+09, train_seconds = 1.3401e+04)
[2022-05-31 17:53:46,874][root][INFO] - Step 88407040 @ 6650.7 SPS. Inference batcher size: 49. Learner queue size: 20. Other stats: (step = 88407040, mean_episode_return = 169.35, mean_episode_step = 654.86, total_loss = 526.39, pg_loss = 280.9, baseline_loss = 251.27, entropy_loss = -5.7871, learner_queue_size = 24, _tick = 28280, _time = 1.654e+09, train_seconds = 1.3406e+04)
[2022-05-31 17:53:51,882][root][INFO] - Step 88440320 @ 6645.4 SPS. Inference batcher size: 130. Learner queue size: 7. Other stats: (step = 88440320, mean_episode_return = 266.94, mean_episode_step = 575.06, total_loss = 290.46, pg_loss = -292.4, baseline_loss = 588.87, entropy_loss = -6.0126, learner_queue_size = 20, _tick = 28291, _time = 1.654e+09, train_seconds = 1.3411e+04)
[2022-05-31 17:53:56,886][root][INFO] - Step 88473600 @ 6650.6 SPS. Inference batcher size: 111. Learner queue size: 11. Other stats: (step = 88473600, mean_episode_return = 211.87, mean_episode_step = 572.48, total_loss = 498.53, pg_loss = 282.96, baseline_loss = 221.62, entropy_loss = -6.0552, learner_queue_size = 17, _tick = 28302, _time = 1.654e+09, train_seconds = 1.3416e+04)
[2022-05-31 17:54:01,892][root][INFO] - Step 88506880 @ 6647.8 SPS. Inference batcher size: 149. Learner queue size: 3. Other stats: (step = 88506880, mean_episode_return = 125.09, mean_episode_step = 767.88, total_loss = 236.85, pg_loss = 45.555, baseline_loss = 197.52, entropy_loss = -6.2222, learner_queue_size = 18, _tick = 28314, _time = 1.654e+09, train_seconds = 1.3421e+04)
[2022-05-31 17:54:06,898][root][INFO] - Step 88540160 @ 6648.1 SPS. Inference batcher size: 96. Learner queue size: 0. Other stats: (step = 88540160, mean_episode_return = 521.9, mean_episode_step = 648.25, total_loss = 253.94, pg_loss = 144.18, baseline_loss = 115.76, entropy_loss = -5.9974, learner_queue_size = 25, _tick = 28326, _time = 1.654e+09, train_seconds = 1.3426e+04)
[2022-05-31 17:54:11,904][root][INFO] - Step 88570880 @ 6136.4 SPS. Inference batcher size: 95. Learner queue size: 20. Other stats: (step = 88570880, mean_episode_return = 257.06, mean_episode_step = 787.64, total_loss = 284.05, pg_loss = 151.42, baseline_loss = 138.8, entropy_loss = -6.1693, learner_queue_size = 12, _tick = 28336, _time = 1.654e+09, train_seconds = 1.3431e+04)
[2022-05-31 17:54:16,910][root][INFO] - Step 88604160 @ 6648.0 SPS. Inference batcher size: 156. Learner queue size: 15. Other stats: (step = 88604160, mean_episode_return = None, mean_episode_step = 683.06, total_loss = 158.89, pg_loss = 116.23, baseline_loss = 48.88, entropy_loss = -6.2193, learner_queue_size = 20, _tick = 28347, _time = 1.654e+09, train_seconds = 1.3436e+04)
[2022-05-31 17:54:21,916][root][INFO] - Step 88637440 @ 6648.0 SPS. Inference batcher size: 99. Learner queue size: 9. Other stats: (step = 88637440, mean_episode_return = 67.491, mean_episode_step = 846.07, total_loss = -84.957, pg_loss = -132.4, baseline_loss = 53.497, entropy_loss = -6.053, learner_queue_size = 21, _tick = 28360, _time = 1.654e+09, train_seconds = 1.3441e+04)
[2022-05-31 17:54:26,920][root][INFO] - Step 88670720 @ 6651.1 SPS. Inference batcher size: 147. Learner queue size: 2. Other stats: (step = 88670720, mean_episode_return = 67.513, mean_episode_step = 785.09, total_loss = -190.86, pg_loss = -323.25, baseline_loss = 138.32, entropy_loss = -5.9264, learner_queue_size = 18, _tick = 28372, _time = 1.654e+09, train_seconds = 1.3446e+04)
[2022-05-31 17:54:31,922][root][INFO] - Step 88704000 @ 6653.1 SPS. Inference batcher size: 42. Learner queue size: 6. Other stats: (step = 88704000, mean_episode_return = 172.51, mean_episode_step = 667.31, total_loss = 117.23, pg_loss = 3.9473, baseline_loss = 119.61, entropy_loss = -6.3243, learner_queue_size = 21, _tick = 28384, _time = 1.654e+09, train_seconds = 1.3451e+04)
[2022-05-31 17:54:36,926][root][INFO] - Step 88737280 @ 6650.8 SPS. Inference batcher size: 81. Learner queue size: 3. Other stats: (step = 88737280, mean_episode_return = 59.061, mean_episode_step = 471.35, total_loss = 388.82, pg_loss = 213.79, baseline_loss = 181.15, entropy_loss = -6.118, learner_queue_size = 23, _tick = 28395, _time = 1.654e+09, train_seconds = 1.3456e+04)
[2022-05-31 17:54:41,932][root][INFO] - Step 88770560 @ 6647.9 SPS. Inference batcher size: 92. Learner queue size: 22. Other stats: (step = 88770560, mean_episode_return = 109.97, mean_episode_step = 709.02, total_loss = 761.09, pg_loss = 155.41, baseline_loss = 612.1, entropy_loss = -6.4204, learner_queue_size = 20, _tick = 28408, _time = 1.654e+09, train_seconds = 1.3461e+04)
[2022-05-31 17:54:46,938][root][INFO] - Step 88801280 @ 6136.9 SPS. Inference batcher size: 29. Learner queue size: 13. Other stats: (step = 88801280, mean_episode_return = None, mean_episode_step = 771.94, total_loss = 118.53, pg_loss = 34.963, baseline_loss = 89.289, entropy_loss = -5.7261, learner_queue_size = 21, _tick = 28418, _time = 1.654e+09, train_seconds = 1.3466e+04)
[2022-05-31 17:54:51,945][root][INFO] - Step 88834560 @ 6646.6 SPS. Inference batcher size: 160. Learner queue size: 18. Other stats: (step = 88834560, mean_episode_return = 197.35, mean_episode_step = 623.3, total_loss = -33.618, pg_loss = -186.41, baseline_loss = 158.12, entropy_loss = -5.3192, learner_queue_size = 30, _tick = 28431, _time = 1.654e+09, train_seconds = 1.3471e+04)
[2022-05-31 17:54:56,950][root][INFO] - Step 88867840 @ 6649.4 SPS. Inference batcher size: 125. Learner queue size: 15. Other stats: (step = 88867840, mean_episode_return = 281.72, mean_episode_step = 579.6, total_loss = 131.45, pg_loss = 42.463, baseline_loss = 95.274, entropy_loss = -6.2902, learner_queue_size = 29, _tick = 28443, _time = 1.654e+09, train_seconds = 1.3476e+04)
[2022-05-31 17:55:01,955][root][INFO] - Step 88901120 @ 6650.1 SPS. Inference batcher size: 204. Learner queue size: 9. Other stats: (step = 88901120, mean_episode_return = 136.37, mean_episode_step = 706.36, total_loss = 36.954, pg_loss = -45.996, baseline_loss = 89.444, entropy_loss = -6.4946, learner_queue_size = 14, _tick = 28455, _time = 1.654e+09, train_seconds = 1.3481e+04)
[2022-05-31 17:55:06,958][root][INFO] - Step 88934400 @ 6651.4 SPS. Inference batcher size: 39. Learner queue size: 8. Other stats: (step = 88934400, mean_episode_return = 212.06, mean_episode_step = 654.21, total_loss = -89.95, pg_loss = -95.284, baseline_loss = 11.977, entropy_loss = -6.6422, learner_queue_size = 19, _tick = 28467, _time = 1.654e+09, train_seconds = 1.3486e+04)
[2022-05-31 17:55:11,962][root][INFO] - Step 88967680 @ 6650.7 SPS. Inference batcher size: 45. Learner queue size: 2. Other stats: (step = 88967680, mean_episode_return = 359.0, mean_episode_step = 607.35, total_loss = 718.18, pg_loss = 300.52, baseline_loss = 423.82, entropy_loss = -6.1542, learner_queue_size = 26, _tick = 28477, _time = 1.654e+09, train_seconds = 1.3491e+04)
[2022-05-31 17:55:16,970][root][INFO] - Step 89000960 @ 6645.4 SPS. Inference batcher size: 32. Learner queue size: 1. Other stats: (step = 89000960, mean_episode_return = 148.59, mean_episode_step = 739.46, total_loss = -179.67, pg_loss = -253.14, baseline_loss = 79.678, entropy_loss = -6.2098, learner_queue_size = 24, _tick = 28488, _time = 1.654e+09, train_seconds = 1.3496e+04)
[2022-05-31 17:55:21,974][root][INFO] - Step 89034240 @ 6650.7 SPS. Inference batcher size: 133. Learner queue size: 1. Other stats: (step = 89034240, mean_episode_return = 169.57, mean_episode_step = 645.29, total_loss = 113.21, pg_loss = 5.6481, baseline_loss = 113.38, entropy_loss = -5.8155, learner_queue_size = 25, _tick = 28499, _time = 1.654e+09, train_seconds = 1.3501e+04)
[2022-05-31 17:55:26,978][root][INFO] - Step 89064960 @ 6139.1 SPS. Inference batcher size: 124. Learner queue size: 18. Other stats: (step = 89064960, mean_episode_return = 168.89, mean_episode_step = 642.72, total_loss = 94.831, pg_loss = -43.215, baseline_loss = 144.23, entropy_loss = -6.1876, learner_queue_size = 18, _tick = 28510, _time = 1.654e+09, train_seconds = 1.3506e+04)
[2022-05-31 17:55:31,984][root][INFO] - Step 89100800 @ 7159.3 SPS. Inference batcher size: 132. Learner queue size: 7. Other stats: (step = 89100800, mean_episode_return = 281.85, mean_episode_step = 642.42, total_loss = -110.97, pg_loss = -150.49, baseline_loss = 45.619, entropy_loss = -6.0996, learner_queue_size = 7, _tick = 28524, _time = 1.654e+09, train_seconds = 1.3511e+04)
[2022-05-31 17:55:36,990][root][INFO] - Step 89131520 @ 6136.7 SPS. Inference batcher size: 28. Learner queue size: 5. Other stats: (step = 89131520, mean_episode_return = None, mean_episode_step = 584.91, total_loss = 96.161, pg_loss = 22.328, baseline_loss = 79.704, entropy_loss = -5.8708, learner_queue_size = 23, _tick = 28535, _time = 1.654e+09, train_seconds = 1.3516e+04)
[2022-05-31 17:55:41,996][root][INFO] - Step 89164800 @ 6648.2 SPS. Inference batcher size: 115. Learner queue size: 4. Other stats: (step = 89164800, mean_episode_return = 147.76, mean_episode_step = 626.76, total_loss = 54.171, pg_loss = -58.282, baseline_loss = 118.26, entropy_loss = -5.8045, learner_queue_size = 17, _tick = 28547, _time = 1.654e+09, train_seconds = 1.3521e+04)
[2022-05-31 17:55:46,998][root][INFO] - Step 89198080 @ 6652.8 SPS. Inference batcher size: 41. Learner queue size: 2. Other stats: (step = 89198080, mean_episode_return = None, mean_episode_step = 745.34, total_loss = 258.63, pg_loss = 186.72, baseline_loss = 77.297, entropy_loss = -5.3825, learner_queue_size = 29, _tick = 28558, _time = 1.654e+09, train_seconds = 1.3526e+04)
[2022-05-31 17:55:52,004][root][INFO] - Step 89228800 @ 6136.2 SPS. Inference batcher size: 143. Learner queue size: 17. Other stats: (step = 89228800, mean_episode_return = 292.01, mean_episode_step = 622.64, total_loss = 347.0, pg_loss = 150.94, baseline_loss = 201.85, entropy_loss = -5.7832, learner_queue_size = 9, _tick = 28569, _time = 1.654e+09, train_seconds = 1.3531e+04)
[2022-05-31 17:55:57,010][root][INFO] - Step 89262080 @ 6648.1 SPS. Inference batcher size: 156. Learner queue size: 12. Other stats: (step = 89262080, mean_episode_return = 259.76, mean_episode_step = 597.4, total_loss = -256.01, pg_loss = -468.23, baseline_loss = 218.03, entropy_loss = -5.8003, learner_queue_size = 19, _tick = 28581, _time = 1.654e+09, train_seconds = 1.3536e+04)
[2022-05-31 17:56:02,014][root][INFO] - Step 89295360 @ 6651.4 SPS. Inference batcher size: 146. Learner queue size: 2. Other stats: (step = 89295360, mean_episode_return = 105.36, mean_episode_step = 676.0, total_loss = 74.241, pg_loss = -96.863, baseline_loss = 176.9, entropy_loss = -5.794, learner_queue_size = 19, _tick = 28593, _time = 1.654e+09, train_seconds = 1.3541e+04)
[2022-05-31 17:56:07,020][root][INFO] - Step 89328640 @ 6648.0 SPS. Inference batcher size: 109. Learner queue size: 1. Other stats: (step = 89328640, mean_episode_return = 232.51, mean_episode_step = 639.6, total_loss = 153.34, pg_loss = 34.994, baseline_loss = 124.4, entropy_loss = -6.0526, learner_queue_size = 15, _tick = 28604, _time = 1.654e+09, train_seconds = 1.3546e+04)
[2022-05-31 17:56:12,026][root][INFO] - Step 89359360 @ 6136.6 SPS. Inference batcher size: 133. Learner queue size: 24. Other stats: (step = 89359360, mean_episode_return = 121.0, mean_episode_step = 815.21, total_loss = 566.2, pg_loss = 355.11, baseline_loss = 216.79, entropy_loss = -5.6989, learner_queue_size = 15, _tick = 28614, _time = 1.654e+09, train_seconds = 1.3551e+04)
[2022-05-31 17:56:17,032][root][INFO] - Step 89392640 @ 6647.9 SPS. Inference batcher size: 111. Learner queue size: 18. Other stats: (step = 89392640, mean_episode_return = 78.178, mean_episode_step = 571.58, total_loss = 257.33, pg_loss = 87.29, baseline_loss = 175.72, entropy_loss = -5.6842, learner_queue_size = 10, _tick = 28627, _time = 1.654e+09, train_seconds = 1.3556e+04)
[2022-05-31 17:56:22,038][root][INFO] - Step 89425920 @ 6648.2 SPS. Inference batcher size: 39. Learner queue size: 13. Other stats: (step = 89425920, mean_episode_return = None, mean_episode_step = 576.28, total_loss = 344.89, pg_loss = 139.26, baseline_loss = 211.24, entropy_loss = -5.6183, learner_queue_size = 25, _tick = 28636, _time = 1.654e+09, train_seconds = 1.3561e+04)
[2022-05-31 17:56:27,042][root][INFO] - Step 89459200 @ 6650.7 SPS. Inference batcher size: 111. Learner queue size: 0. Other stats: (step = 89459200, mean_episode_return = 396.11, mean_episode_step = 737.09, total_loss = -181.99, pg_loss = -232.58, baseline_loss = 56.583, entropy_loss = -5.9964, learner_queue_size = 23, _tick = 28649, _time = 1.654e+09, train_seconds = 1.3566e+04)
[2022-05-31 17:56:32,046][root][INFO] - Step 89492480 @ 6650.6 SPS. Inference batcher size: 106. Learner queue size: 30. Other stats: (step = 89492480, mean_episode_return = 61.51, mean_episode_step = 616.7, total_loss = 88.709, pg_loss = -41.721, baseline_loss = 136.95, entropy_loss = -6.5165, learner_queue_size = 22, _tick = 28662, _time = 1.654e+09, train_seconds = 1.3571e+04)
[2022-05-31 17:56:37,052][root][INFO] - Step 89523200 @ 6136.5 SPS. Inference batcher size: 111. Learner queue size: 27. Other stats: (step = 89523200, mean_episode_return = 84.306, mean_episode_step = 664.75, total_loss = 66.799, pg_loss = 21.851, baseline_loss = 51.414, entropy_loss = -6.466, learner_queue_size = 16, _tick = 28672, _time = 1.654e+09, train_seconds = 1.3576e+04)
[2022-05-31 17:56:42,058][root][INFO] - Step 89556480 @ 6648.2 SPS. Inference batcher size: 69. Learner queue size: 14. Other stats: (step = 89556480, mean_episode_return = 159.45, mean_episode_step = 785.67, total_loss = -51.649, pg_loss = -66.623, baseline_loss = 21.333, entropy_loss = -6.3594, learner_queue_size = 17, _tick = 28684, _time = 1.654e+09, train_seconds = 1.3581e+04)
[2022-05-31 17:56:47,062][root][INFO] - Step 89589760 @ 6650.6 SPS. Inference batcher size: 67. Learner queue size: 10. Other stats: (step = 89589760, mean_episode_return = 350.35, mean_episode_step = 806.36, total_loss = 584.88, pg_loss = 417.15, baseline_loss = 173.53, entropy_loss = -5.7989, learner_queue_size = 19, _tick = 28696, _time = 1.654e+09, train_seconds = 1.3586e+04)
[2022-05-31 17:56:52,066][root][INFO] - Step 89623040 @ 6650.5 SPS. Inference batcher size: 25. Learner queue size: 5. Other stats: (step = 89623040, mean_episode_return = 229.4, mean_episode_step = 804.87, total_loss = 352.76, pg_loss = 128.97, baseline_loss = 229.26, entropy_loss = -5.4722, learner_queue_size = 21, _tick = 28708, _time = 1.654e+09, train_seconds = 1.3591e+04)
[2022-05-31 17:56:57,073][root][INFO] - Step 89656320 @ 6647.4 SPS. Inference batcher size: 103. Learner queue size: 1. Other stats: (step = 89656320, mean_episode_return = 209.69, mean_episode_step = 740.03, total_loss = 6.9943, pg_loss = -58.432, baseline_loss = 71.587, entropy_loss = -6.16, learner_queue_size = 13, _tick = 28721, _time = 1.654e+09, train_seconds = 1.3596e+04)
[2022-05-31 17:57:02,078][root][INFO] - Step 89689600 @ 6648.8 SPS. Inference batcher size: 120. Learner queue size: 11. Other stats: (step = 89689600, mean_episode_return = 184.01, mean_episode_step = 712.99, total_loss = 70.409, pg_loss = -57.856, baseline_loss = 133.59, entropy_loss = -5.3286, learner_queue_size = 20, _tick = 28733, _time = 1.654e+09, train_seconds = 1.3601e+04)
[2022-05-31 17:57:07,082][root][INFO] - Step 89722880 @ 6650.7 SPS. Inference batcher size: 78. Learner queue size: 7. Other stats: (step = 89722880, mean_episode_return = 141.92, mean_episode_step = 619.56, total_loss = 257.88, pg_loss = 80.749, baseline_loss = 182.66, entropy_loss = -5.5334, learner_queue_size = 17, _tick = 28746, _time = 1.654e+09, train_seconds = 1.3606e+04)
[2022-05-31 17:57:12,090][root][INFO] - Step 89756160 @ 6645.4 SPS. Inference batcher size: 73. Learner queue size: 1. Other stats: (step = 89756160, mean_episode_return = 151.07, mean_episode_step = 572.0, total_loss = 151.58, pg_loss = -0.046679, baseline_loss = 157.38, entropy_loss = -5.7625, learner_queue_size = 19, _tick = 28757, _time = 1.654e+09, train_seconds = 1.3611e+04)
[2022-05-31 17:57:17,094][root][INFO] - Step 89789440 @ 6650.6 SPS. Inference batcher size: 123. Learner queue size: 4. Other stats: (step = 89789440, mean_episode_return = 562.51, mean_episode_step = 596.47, total_loss = 73.427, pg_loss = 31.781, baseline_loss = 48.315, entropy_loss = -6.6687, learner_queue_size = 24, _tick = 28769, _time = 1.654e+09, train_seconds = 1.3616e+04)
[2022-05-31 17:57:22,098][root][INFO] - Step 89822720 @ 6650.6 SPS. Inference batcher size: 20. Learner queue size: 31. Other stats: (step = 89822720, mean_episode_return = 140.16, mean_episode_step = 606.62, total_loss = -168.39, pg_loss = -209.6, baseline_loss = 47.28, entropy_loss = -6.0714, learner_queue_size = 19, _tick = 28781, _time = 1.654e+09, train_seconds = 1.3621e+04)
[2022-05-31 17:57:27,102][root][INFO] - Step 89856000 @ 6650.8 SPS. Inference batcher size: 114. Learner queue size: 2. Other stats: (step = 89856000, mean_episode_return = 220.12, mean_episode_step = 726.47, total_loss = 3.2677, pg_loss = -53.34, baseline_loss = 62.671, entropy_loss = -6.0632, learner_queue_size = 18, _tick = 28792, _time = 1.654e+09, train_seconds = 1.3626e+04)
[2022-05-31 17:57:32,108][root][INFO] - Step 89886720 @ 6137.0 SPS. Inference batcher size: 93. Learner queue size: 22. Other stats: (step = 89886720, mean_episode_return = 76.34, mean_episode_step = 831.28, total_loss = 132.1, pg_loss = 53.874, baseline_loss = 84.073, entropy_loss = -5.8463, learner_queue_size = 20, _tick = 28804, _time = 1.654e+09, train_seconds = 1.3631e+04)
[2022-05-31 17:57:37,110][root][INFO] - Step 89920000 @ 6653.0 SPS. Inference batcher size: 66. Learner queue size: 13. Other stats: (step = 89920000, mean_episode_return = 210.16, mean_episode_step = 764.06, total_loss = 200.41, pg_loss = 94.616, baseline_loss = 112.56, entropy_loss = -6.7601, learner_queue_size = 13, _tick = 28817, _time = 1.654e+09, train_seconds = 1.3636e+04)
[2022-05-31 17:57:42,114][root][INFO] - Step 89953280 @ 6650.6 SPS. Inference batcher size: 132. Learner queue size: 21. Other stats: (step = 89953280, mean_episode_return = 115.57, mean_episode_step = 624.89, total_loss = -237.35, pg_loss = -284.18, baseline_loss = 53.061, entropy_loss = -6.2241, learner_queue_size = 29, _tick = 28830, _time = 1.654e+09, train_seconds = 1.3641e+04)
[2022-05-31 17:57:47,118][root][INFO] - Step 89986560 @ 6650.7 SPS. Inference batcher size: 139. Learner queue size: 6. Other stats: (step = 89986560, mean_episode_return = 135.6, mean_episode_step = 972.62, total_loss = 73.891, pg_loss = 26.128, baseline_loss = 53.865, entropy_loss = -6.1017, learner_queue_size = 16, _tick = 28841, _time = 1.654e+09, train_seconds = 1.3646e+04)
[2022-05-31 17:57:52,122][root][INFO] - Step 90019840 @ 6650.6 SPS. Inference batcher size: 146. Learner queue size: 6. Other stats: (step = 90019840, mean_episode_return = 63.36, mean_episode_step = 606.79, total_loss = 45.173, pg_loss = -9.7476, baseline_loss = 61.435, entropy_loss = -6.5146, learner_queue_size = 14, _tick = 28852, _time = 1.654e+09, train_seconds = 1.3651e+04)
[2022-05-31 17:57:57,126][root][INFO] - Step 90053120 @ 6650.9 SPS. Inference batcher size: 118. Learner queue size: 0. Other stats: (step = 90053120, mean_episode_return = 133.79, mean_episode_step = 499.71, total_loss = -188.88, pg_loss = -237.7, baseline_loss = 54.892, entropy_loss = -6.0672, learner_queue_size = 30, _tick = 28865, _time = 1.654e+09, train_seconds = 1.3656e+04)
[2022-05-31 17:58:02,130][root][INFO] - Step 90086400 @ 6650.7 SPS. Inference batcher size: 48. Learner queue size: 25. Other stats: (step = 90086400, mean_episode_return = 186.16, mean_episode_step = 671.44, total_loss = 301.16, pg_loss = 159.14, baseline_loss = 148.05, entropy_loss = -6.0299, learner_queue_size = 12, _tick = 28877, _time = 1.654e+09, train_seconds = 1.3661e+04)
[2022-05-31 17:58:07,137][root][INFO] - Step 90117120 @ 6135.3 SPS. Inference batcher size: 114. Learner queue size: 28. Other stats: (step = 90117120, mean_episode_return = 193.7, mean_episode_step = 615.04, total_loss = -13.417, pg_loss = -58.784, baseline_loss = 51.339, entropy_loss = -5.9717, learner_queue_size = 26, _tick = 28888, _time = 1.654e+09, train_seconds = 1.3666e+04)
[2022-05-31 17:58:12,143][root][INFO] - Step 90150400 @ 6648.6 SPS. Inference batcher size: 99. Learner queue size: 3. Other stats: (step = 90150400, mean_episode_return = 89.104, mean_episode_step = 849.73, total_loss = 0.88187, pg_loss = -70.695, baseline_loss = 77.451, entropy_loss = -5.8735, learner_queue_size = 14, _tick = 28900, _time = 1.654e+09, train_seconds = 1.3671e+04)
[2022-05-31 17:58:17,150][root][INFO] - Step 90183680 @ 6645.8 SPS. Inference batcher size: 102. Learner queue size: 2. Other stats: (step = 90183680, mean_episode_return = 50.612, mean_episode_step = 495.63, total_loss = 1494.6, pg_loss = 673.28, baseline_loss = 826.9, entropy_loss = -5.5448, learner_queue_size = 17, _tick = 28913, _time = 1.654e+09, train_seconds = 1.3676e+04)
[2022-05-31 17:58:22,156][root][INFO] - Step 90214400 @ 6136.6 SPS. Inference batcher size: 121. Learner queue size: 11. Other stats: (step = 90214400, mean_episode_return = 139.09, mean_episode_step = 878.15, total_loss = -58.86, pg_loss = -212.1, baseline_loss = 158.84, entropy_loss = -5.5995, learner_queue_size = 22, _tick = 28924, _time = 1.654e+09, train_seconds = 1.3681e+04)
[2022-05-31 17:58:27,162][root][INFO] - Step 90247680 @ 6648.0 SPS. Inference batcher size: 139. Learner queue size: 5. Other stats: (step = 90247680, mean_episode_return = 346.99, mean_episode_step = 511.55, total_loss = 604.67, pg_loss = 236.94, baseline_loss = 373.16, entropy_loss = -5.4271, learner_queue_size = 28, _tick = 28937, _time = 1.654e+09, train_seconds = 1.3686e+04)
[2022-05-31 17:58:32,166][root][INFO] - Step 90280960 @ 6651.1 SPS. Inference batcher size: 108. Learner queue size: 21. Other stats: (step = 90280960, mean_episode_return = 227.39, mean_episode_step = 558.79, total_loss = -213.29, pg_loss = -286.37, baseline_loss = 78.824, entropy_loss = -5.7456, learner_queue_size = 19, _tick = 28949, _time = 1.654e+09, train_seconds = 1.3691e+04)
[2022-05-31 17:58:37,170][root][INFO] - Step 90314240 @ 6650.7 SPS. Inference batcher size: 144. Learner queue size: 11. Other stats: (step = 90314240, mean_episode_return = 411.28, mean_episode_step = 765.74, total_loss = 40.635, pg_loss = -148.5, baseline_loss = 194.57, entropy_loss = -5.4389, learner_queue_size = 20, _tick = 28960, _time = 1.654e+09, train_seconds = 1.3696e+04)
[2022-05-31 17:58:42,174][root][INFO] - Step 90347520 @ 6650.8 SPS. Inference batcher size: 14. Learner queue size: 9. Other stats: (step = 90347520, mean_episode_return = 107.07, mean_episode_step = 594.25, total_loss = 216.5, pg_loss = 88.431, baseline_loss = 134.24, entropy_loss = -6.1657, learner_queue_size = 15, _tick = 28973, _time = 1.654e+09, train_seconds = 1.3701e+04)
[2022-05-31 17:58:47,178][root][INFO] - Step 90380800 @ 6650.6 SPS. Inference batcher size: 169. Learner queue size: 5. Other stats: (step = 90380800, mean_episode_return = 519.48, mean_episode_step = 579.74, total_loss = 242.34, pg_loss = -78.959, baseline_loss = 327.13, entropy_loss = -5.8307, learner_queue_size = 23, _tick = 28986, _time = 1.654e+09, train_seconds = 1.3706e+04)
[2022-05-31 17:58:52,183][root][INFO] - Step 90414080 @ 6650.0 SPS. Inference batcher size: 112. Learner queue size: 27. Other stats: (step = 90414080, mean_episode_return = 199.04, mean_episode_step = 498.72, total_loss = 157.61, pg_loss = -94.289, baseline_loss = 257.96, entropy_loss = -6.0643, learner_queue_size = 21, _tick = 28997, _time = 1.654e+09, train_seconds = 1.3711e+04)
[2022-05-31 17:58:57,189][root][INFO] - Step 90444800 @ 6135.8 SPS. Inference batcher size: 129. Learner queue size: 16. Other stats: (step = 90444800, mean_episode_return = 109.1, mean_episode_step = 599.04, total_loss = 402.25, pg_loss = 149.29, baseline_loss = 259.23, entropy_loss = -6.267, learner_queue_size = 21, _tick = 29009, _time = 1.654e+09, train_seconds = 1.3716e+04)
[2022-05-31 17:59:02,195][root][INFO] - Step 90478080 @ 6648.8 SPS. Inference batcher size: 87. Learner queue size: 16. Other stats: (step = 90478080, mean_episode_return = 135.91, mean_episode_step = 954.71, total_loss = 140.58, pg_loss = -94.24, baseline_loss = 241.09, entropy_loss = -6.276, learner_queue_size = 11, _tick = 29020, _time = 1.654e+09, train_seconds = 1.3721e+04)
[2022-05-31 17:59:07,200][root][INFO] - Step 90511360 @ 6648.5 SPS. Inference batcher size: 157. Learner queue size: 11. Other stats: (step = 90511360, mean_episode_return = 153.99, mean_episode_step = 586.12, total_loss = 164.76, pg_loss = 72.297, baseline_loss = 98.507, entropy_loss = -6.0419, learner_queue_size = 28, _tick = 29032, _time = 1.654e+09, train_seconds = 1.3726e+04)
[2022-05-31 17:59:12,206][root][INFO] - Step 90544640 @ 6648.2 SPS. Inference batcher size: 34. Learner queue size: 16. Other stats: (step = 90544640, mean_episode_return = 185.21, mean_episode_step = 678.55, total_loss = -198.37, pg_loss = -255.25, baseline_loss = 63.134, entropy_loss = -6.2492, learner_queue_size = 18, _tick = 29044, _time = 1.654e+09, train_seconds = 1.3731e+04)
[2022-05-31 17:59:17,210][root][INFO] - Step 90577920 @ 6650.9 SPS. Inference batcher size: 170. Learner queue size: 14. Other stats: (step = 90577920, mean_episode_return = None, mean_episode_step = 633.84, total_loss = 376.53, pg_loss = 41.32, baseline_loss = 341.68, entropy_loss = -6.4691, learner_queue_size = 24, _tick = 29055, _time = 1.654e+09, train_seconds = 1.3736e+04)
[2022-05-31 17:59:22,216][root][INFO] - Step 90611200 @ 6647.3 SPS. Inference batcher size: 106. Learner queue size: 11. Other stats: (step = 90611200, mean_episode_return = 109.45, mean_episode_step = 611.23, total_loss = 365.92, pg_loss = 296.45, baseline_loss = 75.95, entropy_loss = -6.4796, learner_queue_size = 20, _tick = 29068, _time = 1.654e+09, train_seconds = 1.3741e+04)
[2022-05-31 17:59:27,222][root][INFO] - Step 90644480 @ 6648.7 SPS. Inference batcher size: 24. Learner queue size: 29. Other stats: (step = 90644480, mean_episode_return = 566.36, mean_episode_step = 605.34, total_loss = -42.419, pg_loss = -104.82, baseline_loss = 68.727, entropy_loss = -6.3249, learner_queue_size = 12, _tick = 29078, _time = 1.654e+09, train_seconds = 1.3746e+04)
[2022-05-31 17:59:32,228][root][INFO] - Step 90677760 @ 6647.4 SPS. Inference batcher size: 136. Learner queue size: 4. Other stats: (step = 90677760, mean_episode_return = 205.13, mean_episode_step = 679.6, total_loss = 92.826, pg_loss = 13.132, baseline_loss = 85.575, entropy_loss = -5.8812, learner_queue_size = 18, _tick = 29088, _time = 1.654e+09, train_seconds = 1.3751e+04)
[2022-05-31 17:59:37,234][root][INFO] - Step 90711040 @ 6648.4 SPS. Inference batcher size: 142. Learner queue size: 31. Other stats: (step = 90711040, mean_episode_return = None, mean_episode_step = 578.72, total_loss = 58.318, pg_loss = 17.205, baseline_loss = 46.698, entropy_loss = -5.5851, learner_queue_size = 23, _tick = 29100, _time = 1.654e+09, train_seconds = 1.3756e+04)
[2022-05-31 17:59:42,238][root][INFO] - Step 90744320 @ 6651.0 SPS. Inference batcher size: 108. Learner queue size: 18. Other stats: (step = 90744320, mean_episode_return = 196.41, mean_episode_step = 894.35, total_loss = 470.35, pg_loss = 184.73, baseline_loss = 291.29, entropy_loss = -5.6684, learner_queue_size = 12, _tick = 29111, _time = 1.654e+09, train_seconds = 1.3761e+04)
[2022-05-31 17:59:47,244][root][INFO] - Step 90777600 @ 6647.7 SPS. Inference batcher size: 20. Learner queue size: 22. Other stats: (step = 90777600, mean_episode_return = 200.76, mean_episode_step = 682.39, total_loss = -95.391, pg_loss = -142.34, baseline_loss = 53.276, entropy_loss = -6.3229, learner_queue_size = 22, _tick = 29124, _time = 1.654e+09, train_seconds = 1.3766e+04)
[2022-05-31 17:59:52,250][root][INFO] - Step 90808320 @ 6137.0 SPS. Inference batcher size: 135. Learner queue size: 14. Other stats: (step = 90808320, mean_episode_return = 186.78, mean_episode_step = 617.39, total_loss = 81.186, pg_loss = 37.779, baseline_loss = 49.294, entropy_loss = -5.887, learner_queue_size = 12, _tick = 29136, _time = 1.654e+09, train_seconds = 1.3771e+04)
[2022-05-31 17:59:57,251][root][INFO] - Step 90841600 @ 6654.3 SPS. Inference batcher size: 87. Learner queue size: 16. Other stats: (step = 90841600, mean_episode_return = 116.21, mean_episode_step = 594.81, total_loss = -5.7911, pg_loss = -74.53, baseline_loss = 74.555, entropy_loss = -5.8163, learner_queue_size = 12, _tick = 29147, _time = 1.654e+09, train_seconds = 1.3776e+04)
[2022-05-31 18:00:02,257][root][INFO] - Step 90874880 @ 6648.0 SPS. Inference batcher size: 105. Learner queue size: 17. Other stats: (step = 90874880, mean_episode_return = 437.1, mean_episode_step = 720.82, total_loss = -210.13, pg_loss = -281.38, baseline_loss = 77.495, entropy_loss = -6.2506, learner_queue_size = 30, _tick = 29158, _time = 1.654e+09, train_seconds = 1.3781e+04)
[2022-05-31 18:00:07,262][root][INFO] - Step 90908160 @ 6649.6 SPS. Inference batcher size: 119. Learner queue size: 11. Other stats: (step = 90908160, mean_episode_return = 280.4, mean_episode_step = 929.47, total_loss = -186.47, pg_loss = -459.73, baseline_loss = 279.39, entropy_loss = -6.1295, learner_queue_size = 10, _tick = 29170, _time = 1.654e+09, train_seconds = 1.3786e+04)
[2022-05-31 18:00:12,266][root][INFO] - Step 90941440 @ 6650.7 SPS. Inference batcher size: 172. Learner queue size: 10. Other stats: (step = 90941440, mean_episode_return = 115.4, mean_episode_step = 713.08, total_loss = 467.85, pg_loss = 338.44, baseline_loss = 135.37, entropy_loss = -5.9554, learner_queue_size = 27, _tick = 29182, _time = 1.654e+09, train_seconds = 1.3791e+04)
[2022-05-31 18:00:17,272][root][INFO] - Step 90974720 @ 6648.0 SPS. Inference batcher size: 140. Learner queue size: 2. Other stats: (step = 90974720, mean_episode_return = 83.099, mean_episode_step = 562.95, total_loss = 31.27, pg_loss = -49.965, baseline_loss = 87.274, entropy_loss = -6.0381, learner_queue_size = 17, _tick = 29191, _time = 1.654e+09, train_seconds = 1.3796e+04)
[2022-05-31 18:00:22,274][root][INFO] - Step 91008000 @ 6653.4 SPS. Inference batcher size: 142. Learner queue size: 2. Other stats: (step = 91008000, mean_episode_return = 104.47, mean_episode_step = 627.8, total_loss = 249.77, pg_loss = 96.173, baseline_loss = 159.63, entropy_loss = -6.0383, learner_queue_size = 22, _tick = 29202, _time = 1.654e+09, train_seconds = 1.3801e+04)
[2022-05-31 18:00:27,280][root][INFO] - Step 91038720 @ 6136.3 SPS. Inference batcher size: 104. Learner queue size: 18. Other stats: (step = 91038720, mean_episode_return = None, mean_episode_step = 588.06, total_loss = 308.17, pg_loss = 142.63, baseline_loss = 171.72, entropy_loss = -6.1725, learner_queue_size = 15, _tick = 29210, _time = 1.654e+09, train_seconds = 1.3806e+04)
[2022-05-31 18:00:32,287][root][INFO] - Step 91072000 @ 6647.5 SPS. Inference batcher size: 59. Learner queue size: 18. Other stats: (step = 91072000, mean_episode_return = 186.67, mean_episode_step = 773.92, total_loss = 549.04, pg_loss = 372.62, baseline_loss = 182.33, entropy_loss = -5.9121, learner_queue_size = 15, _tick = 29221, _time = 1.654e+09, train_seconds = 1.3811e+04)
[2022-05-31 18:00:37,290][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 18:00:37,470][root][INFO] - Step 91105280 @ 6651.4 SPS. Inference batcher size: 50. Learner queue size: 23. Other stats: (step = 91107840, mean_episode_return = 196.27, mean_episode_step = 702.61, total_loss = 208.45, pg_loss = 67.057, baseline_loss = 147.26, entropy_loss = -5.8699, learner_queue_size = 23, _tick = 29235, _time = 1.654e+09, train_seconds = 1.3816e+04)
[2022-05-31 18:00:42,474][root][INFO] - Step 91138560 @ 6419.8 SPS. Inference batcher size: 78. Learner queue size: 18. Other stats: (step = 91138560, mean_episode_return = 176.31, mean_episode_step = 662.76, total_loss = 85.414, pg_loss = -1.9654, baseline_loss = 93.311, entropy_loss = -5.9309, learner_queue_size = 16, _tick = 29247, _time = 1.654e+09, train_seconds = 1.3821e+04)
[2022-05-31 18:00:47,478][root][INFO] - Step 91171840 @ 6650.8 SPS. Inference batcher size: 115. Learner queue size: 4. Other stats: (step = 91171840, mean_episode_return = 165.51, mean_episode_step = 559.55, total_loss = -69.841, pg_loss = -159.11, baseline_loss = 94.88, entropy_loss = -5.6083, learner_queue_size = 17, _tick = 29259, _time = 1.654e+09, train_seconds = 1.3826e+04)
[2022-05-31 18:00:52,484][root][INFO] - Step 91205120 @ 6647.5 SPS. Inference batcher size: 117. Learner queue size: 5. Other stats: (step = 91205120, mean_episode_return = 112.34, mean_episode_step = 632.27, total_loss = 81.835, pg_loss = -12.917, baseline_loss = 100.42, entropy_loss = -5.6677, learner_queue_size = 12, _tick = 29271, _time = 1.654e+09, train_seconds = 1.3831e+04)
[2022-05-31 18:00:57,490][root][INFO] - Step 91238400 @ 6648.4 SPS. Inference batcher size: 54. Learner queue size: 27. Other stats: (step = 91238400, mean_episode_return = 235.41, mean_episode_step = 546.43, total_loss = 301.53, pg_loss = 172.6, baseline_loss = 134.26, entropy_loss = -5.3285, learner_queue_size = 21, _tick = 29283, _time = 1.654e+09, train_seconds = 1.3836e+04)
[2022-05-31 18:01:02,495][root][INFO] - Step 91269120 @ 6138.2 SPS. Inference batcher size: 112. Learner queue size: 17. Other stats: (step = 91269120, mean_episode_return = None, mean_episode_step = 596.78, total_loss = 513.85, pg_loss = 247.88, baseline_loss = 271.66, entropy_loss = -5.6911, learner_queue_size = 20, _tick = 29294, _time = 1.654e+09, train_seconds = 1.3841e+04)
[2022-05-31 18:01:07,498][root][INFO] - Step 91302400 @ 6651.6 SPS. Inference batcher size: 99. Learner queue size: 13. Other stats: (step = 91302400, mean_episode_return = 217.28, mean_episode_step = 730.53, total_loss = 547.44, pg_loss = 369.05, baseline_loss = 184.25, entropy_loss = -5.8685, learner_queue_size = 20, _tick = 29307, _time = 1.654e+09, train_seconds = 1.3846e+04)
[2022-05-31 18:01:12,502][root][INFO] - Step 91335680 @ 6650.7 SPS. Inference batcher size: 125. Learner queue size: 9. Other stats: (step = 91335680, mean_episode_return = None, mean_episode_step = 756.31, total_loss = 178.7, pg_loss = 119.17, baseline_loss = 65.362, entropy_loss = -5.8286, learner_queue_size = 24, _tick = 29318, _time = 1.654e+09, train_seconds = 1.3851e+04)
[2022-05-31 18:01:17,506][root][INFO] - Step 91368960 @ 6650.7 SPS. Inference batcher size: 102. Learner queue size: 25. Other stats: (step = 91368960, mean_episode_return = 139.53, mean_episode_step = 509.52, total_loss = 336.22, pg_loss = 221.75, baseline_loss = 120.04, entropy_loss = -5.5726, learner_queue_size = 22, _tick = 29329, _time = 1.654e+09, train_seconds = 1.3856e+04)
[2022-05-31 18:01:22,512][root][INFO] - Step 91399680 @ 6136.6 SPS. Inference batcher size: 129. Learner queue size: 20. Other stats: (step = 91399680, mean_episode_return = 500.53, mean_episode_step = 490.82, total_loss = 228.15, pg_loss = 93.076, baseline_loss = 140.65, entropy_loss = -5.5795, learner_queue_size = 16, _tick = 29339, _time = 1.654e+09, train_seconds = 1.3861e+04)
[2022-05-31 18:01:27,518][root][INFO] - Step 91432960 @ 6648.0 SPS. Inference batcher size: 145. Learner queue size: 15. Other stats: (step = 91432960, mean_episode_return = None, mean_episode_step = 990.25, total_loss = 566.53, pg_loss = 209.03, baseline_loss = 362.96, entropy_loss = -5.4643, learner_queue_size = 20, _tick = 29351, _time = 1.654e+09, train_seconds = 1.3866e+04)
[2022-05-31 18:01:32,524][root][INFO] - Step 91466240 @ 6648.0 SPS. Inference batcher size: 121. Learner queue size: 13. Other stats: (step = 91466240, mean_episode_return = 150.06, mean_episode_step = 914.95, total_loss = 115.2, pg_loss = -12.242, baseline_loss = 132.99, entropy_loss = -5.5518, learner_queue_size = 31, _tick = 29364, _time = 1.654e+09, train_seconds = 1.3871e+04)
[2022-05-31 18:01:37,530][root][INFO] - Step 91502080 @ 7159.5 SPS. Inference batcher size: 26. Learner queue size: 15. Other stats: (step = 91502080, mean_episode_return = 298.52, mean_episode_step = 595.11, total_loss = 343.86, pg_loss = 73.587, baseline_loss = 275.54, entropy_loss = -5.2633, learner_queue_size = 12, _tick = 29378, _time = 1.654e+09, train_seconds = 1.3876e+04)
[2022-05-31 18:01:42,534][root][INFO] - Step 91532800 @ 6139.0 SPS. Inference batcher size: 156. Learner queue size: 24. Other stats: (step = 91532800, mean_episode_return = 192.3, mean_episode_step = 642.59, total_loss = -101.99, pg_loss = -209.0, baseline_loss = 112.59, entropy_loss = -5.5853, learner_queue_size = 32, _tick = 29389, _time = 1.654e+09, train_seconds = 1.3881e+04)
[2022-05-31 18:01:47,538][root][INFO] - Step 91566080 @ 6650.7 SPS. Inference batcher size: 147. Learner queue size: 20. Other stats: (step = 91566080, mean_episode_return = 227.47, mean_episode_step = 769.12, total_loss = 203.73, pg_loss = 77.603, baseline_loss = 131.85, entropy_loss = -5.7229, learner_queue_size = 19, _tick = 29402, _time = 1.654e+09, train_seconds = 1.3886e+04)
[2022-05-31 18:01:52,544][root][INFO] - Step 91599360 @ 6647.9 SPS. Inference batcher size: 107. Learner queue size: 15. Other stats: (step = 91599360, mean_episode_return = 234.84, mean_episode_step = 843.02, total_loss = -148.2, pg_loss = -201.49, baseline_loss = 59.564, entropy_loss = -6.2676, learner_queue_size = 27, _tick = 29415, _time = 1.654e+09, train_seconds = 1.3891e+04)
[2022-05-31 18:01:57,550][root][INFO] - Step 91632640 @ 6648.1 SPS. Inference batcher size: 97. Learner queue size: 10. Other stats: (step = 91632640, mean_episode_return = 208.56, mean_episode_step = 620.02, total_loss = 114.0, pg_loss = 84.289, baseline_loss = 35.715, entropy_loss = -6.0041, learner_queue_size = 24, _tick = 29426, _time = 1.654e+09, train_seconds = 1.3896e+04)
[2022-05-31 18:02:02,556][root][INFO] - Step 91665920 @ 6648.0 SPS. Inference batcher size: 112. Learner queue size: 5. Other stats: (step = 91665920, mean_episode_return = 193.16, mean_episode_step = 612.15, total_loss = 99.855, pg_loss = 15.632, baseline_loss = 89.969, entropy_loss = -5.7464, learner_queue_size = 23, _tick = 29439, _time = 1.654e+09, train_seconds = 1.3901e+04)
[2022-05-31 18:02:07,562][root][INFO] - Step 91699200 @ 6648.2 SPS. Inference batcher size: 55. Learner queue size: 24. Other stats: (step = 91699200, mean_episode_return = None, mean_episode_step = 969.31, total_loss = 89.62, pg_loss = 35.947, baseline_loss = 59.828, entropy_loss = -6.1544, learner_queue_size = 12, _tick = 29451, _time = 1.654e+09, train_seconds = 1.3906e+04)
[2022-05-31 18:02:12,568][root][INFO] - Step 91732480 @ 6647.5 SPS. Inference batcher size: 111. Learner queue size: 19. Other stats: (step = 91732480, mean_episode_return = 214.52, mean_episode_step = 809.2, total_loss = -81.177, pg_loss = -201.28, baseline_loss = 126.26, entropy_loss = -6.1484, learner_queue_size = 17, _tick = 29464, _time = 1.654e+09, train_seconds = 1.3911e+04)
[2022-05-31 18:02:17,574][root][INFO] - Step 91763200 @ 6136.5 SPS. Inference batcher size: 134. Learner queue size: 18. Other stats: (step = 91763200, mean_episode_return = 161.93, mean_episode_step = 638.61, total_loss = -14.274, pg_loss = -130.87, baseline_loss = 122.67, entropy_loss = -6.0819, learner_queue_size = 23, _tick = 29475, _time = 1.654e+09, train_seconds = 1.3916e+04)
[2022-05-31 18:02:22,578][root][INFO] - Step 91796480 @ 6651.3 SPS. Inference batcher size: 114. Learner queue size: 13. Other stats: (step = 91796480, mean_episode_return = None, mean_episode_step = 661.22, total_loss = 2079.5, pg_loss = 662.91, baseline_loss = 1422.3, entropy_loss = -5.7583, learner_queue_size = 31, _tick = 29485, _time = 1.654e+09, train_seconds = 1.3921e+04)
[2022-05-31 18:02:27,582][root][INFO] - Step 91832320 @ 7162.4 SPS. Inference batcher size: 4. Learner queue size: 14. Other stats: (step = 91832320, mean_episode_return = 176.42, mean_episode_step = 636.16, total_loss = 23.661, pg_loss = -164.92, baseline_loss = 194.68, entropy_loss = -6.1027, learner_queue_size = 13, _tick = 29498, _time = 1.654e+09, train_seconds = 1.3926e+04)
[2022-05-31 18:02:32,588][root][INFO] - Step 91863040 @ 6136.2 SPS. Inference batcher size: 149. Learner queue size: 24. Other stats: (step = 91863040, mean_episode_return = 412.2, mean_episode_step = 1026.3, total_loss = 138.55, pg_loss = 34.486, baseline_loss = 110.11, entropy_loss = -6.0472, learner_queue_size = 19, _tick = 29508, _time = 1.654e+09, train_seconds = 1.3931e+04)
[2022-05-31 18:02:37,594][root][INFO] - Step 91896320 @ 6648.5 SPS. Inference batcher size: 60. Learner queue size: 9. Other stats: (step = 91896320, mean_episode_return = 219.93, mean_episode_step = 727.93, total_loss = 321.91, pg_loss = 158.1, baseline_loss = 169.73, entropy_loss = -5.9207, learner_queue_size = 14, _tick = 29518, _time = 1.654e+09, train_seconds = 1.3936e+04)
[2022-05-31 18:02:42,598][root][INFO] - Step 91929600 @ 6650.7 SPS. Inference batcher size: 200. Learner queue size: 5. Other stats: (step = 91929600, mean_episode_return = 84.937, mean_episode_step = 730.6, total_loss = 28.56, pg_loss = -42.748, baseline_loss = 77.545, entropy_loss = -6.2368, learner_queue_size = 18, _tick = 29529, _time = 1.654e+09, train_seconds = 1.3941e+04)
[2022-05-31 18:02:47,602][root][INFO] - Step 91962880 @ 6650.5 SPS. Inference batcher size: 0. Learner queue size: 2. Other stats: (step = 91962880, mean_episode_return = 147.43, mean_episode_step = 701.93, total_loss = 475.93, pg_loss = 222.88, baseline_loss = 258.69, entropy_loss = -5.641, learner_queue_size = 16, _tick = 29542, _time = 1.654e+09, train_seconds = 1.3946e+04)
[2022-05-31 18:02:52,606][root][INFO] - Step 91996160 @ 6650.8 SPS. Inference batcher size: 121. Learner queue size: 31. Other stats: (step = 91996160, mean_episode_return = 185.08, mean_episode_step = 860.78, total_loss = 299.75, pg_loss = 140.11, baseline_loss = 165.48, entropy_loss = -5.8373, learner_queue_size = 17, _tick = 29554, _time = 1.654e+09, train_seconds = 1.3951e+04)
[2022-05-31 18:02:57,610][root][INFO] - Step 92029440 @ 6650.8 SPS. Inference batcher size: 150. Learner queue size: 7. Other stats: (step = 92029440, mean_episode_return = 139.93, mean_episode_step = 789.07, total_loss = -124.77, pg_loss = -178.18, baseline_loss = 59.356, entropy_loss = -5.9549, learner_queue_size = 20, _tick = 29567, _time = 1.654e+09, train_seconds = 1.3956e+04)
[2022-05-31 18:03:02,615][root][INFO] - Step 92062720 @ 6649.0 SPS. Inference batcher size: 62. Learner queue size: 21. Other stats: (step = 92062720, mean_episode_return = 258.76, mean_episode_step = 895.74, total_loss = -120.27, pg_loss = -145.97, baseline_loss = 31.859, entropy_loss = -6.1604, learner_queue_size = 21, _tick = 29579, _time = 1.654e+09, train_seconds = 1.3961e+04)
[2022-05-31 18:03:07,622][root][INFO] - Step 92096000 @ 6647.0 SPS. Inference batcher size: 109. Learner queue size: 0. Other stats: (step = 92096000, mean_episode_return = 222.1, mean_episode_step = 741.23, total_loss = 76.629, pg_loss = 7.5953, baseline_loss = 74.931, entropy_loss = -5.8977, learner_queue_size = 29, _tick = 29590, _time = 1.654e+09, train_seconds = 1.3966e+04)
[2022-05-31 18:03:12,638][root][INFO] - Step 92129280 @ 6634.7 SPS. Inference batcher size: 42. Learner queue size: 21. Other stats: (step = 92129280, mean_episode_return = 183.81, mean_episode_step = 1146.1, total_loss = -141.62, pg_loss = -210.82, baseline_loss = 75.31, entropy_loss = -6.1103, learner_queue_size = 20, _tick = 29601, _time = 1.654e+09, train_seconds = 1.3971e+04)
[2022-05-31 18:03:17,642][root][INFO] - Step 92160000 @ 6139.2 SPS. Inference batcher size: 71. Learner queue size: 17. Other stats: (step = 92160000, mean_episode_return = 471.07, mean_episode_step = 923.45, total_loss = -187.79, pg_loss = -362.29, baseline_loss = 180.35, entropy_loss = -5.8444, learner_queue_size = 13, _tick = 29613, _time = 1.654e+09, train_seconds = 1.3976e+04)
[2022-05-31 18:03:22,646][root][INFO] - Step 92193280 @ 6650.6 SPS. Inference batcher size: 20. Learner queue size: 13. Other stats: (step = 92193280, mean_episode_return = 417.94, mean_episode_step = 612.38, total_loss = -7.9219, pg_loss = -289.65, baseline_loss = 287.4, entropy_loss = -5.6751, learner_queue_size = 18, _tick = 29625, _time = 1.654e+09, train_seconds = 1.3981e+04)
[2022-05-31 18:03:27,652][root][INFO] - Step 92226560 @ 6648.3 SPS. Inference batcher size: 113. Learner queue size: 3. Other stats: (step = 92226560, mean_episode_return = 201.67, mean_episode_step = 753.73, total_loss = -290.33, pg_loss = -320.65, baseline_loss = 36.548, entropy_loss = -6.2326, learner_queue_size = 22, _tick = 29638, _time = 1.654e+09, train_seconds = 1.3986e+04)
[2022-05-31 18:03:32,654][root][INFO] - Step 92259840 @ 6653.1 SPS. Inference batcher size: 147. Learner queue size: 3. Other stats: (step = 92259840, mean_episode_return = 83.96, mean_episode_step = 826.78, total_loss = 39.133, pg_loss = -66.874, baseline_loss = 112.18, entropy_loss = -6.1725, learner_queue_size = 21, _tick = 29650, _time = 1.654e+09, train_seconds = 1.3991e+04)
[2022-05-31 18:03:37,658][root][INFO] - Step 92293120 @ 6650.7 SPS. Inference batcher size: 98. Learner queue size: 4. Other stats: (step = 92293120, mean_episode_return = 450.61, mean_episode_step = 740.49, total_loss = 92.348, pg_loss = -75.607, baseline_loss = 173.59, entropy_loss = -5.6352, learner_queue_size = 13, _tick = 29662, _time = 1.654e+09, train_seconds = 1.3996e+04)
[2022-05-31 18:03:42,662][root][INFO] - Step 92326400 @ 6650.6 SPS. Inference batcher size: 78. Learner queue size: 19. Other stats: (step = 92326400, mean_episode_return = 312.62, mean_episode_step = 1024.1, total_loss = -217.1, pg_loss = -264.8, baseline_loss = 53.367, entropy_loss = -5.6678, learner_queue_size = 17, _tick = 29674, _time = 1.654e+09, train_seconds = 1.4001e+04)
[2022-05-31 18:03:47,666][root][INFO] - Step 92357120 @ 6139.1 SPS. Inference batcher size: 141. Learner queue size: 13. Other stats: (step = 92357120, mean_episode_return = 200.86, mean_episode_step = 607.61, total_loss = 24.82, pg_loss = -42.414, baseline_loss = 73.11, entropy_loss = -5.8765, learner_queue_size = 31, _tick = 29684, _time = 1.654e+09, train_seconds = 1.4006e+04)
[2022-05-31 18:03:52,670][root][INFO] - Step 92390400 @ 6650.6 SPS. Inference batcher size: 83. Learner queue size: 13. Other stats: (step = 92390400, mean_episode_return = 368.36, mean_episode_step = 1186.4, total_loss = -116.01, pg_loss = -171.87, baseline_loss = 61.968, entropy_loss = -6.1086, learner_queue_size = 17, _tick = 29697, _time = 1.654e+09, train_seconds = 1.4011e+04)
[2022-05-31 18:03:57,676][root][INFO] - Step 92423680 @ 6648.0 SPS. Inference batcher size: 109. Learner queue size: 2. Other stats: (step = 92423680, mean_episode_return = 308.75, mean_episode_step = 622.74, total_loss = 460.6, pg_loss = 309.39, baseline_loss = 157.05, entropy_loss = -5.8384, learner_queue_size = 24, _tick = 29708, _time = 1.654e+09, train_seconds = 1.4016e+04)
[2022-05-31 18:04:02,678][root][INFO] - Step 92456960 @ 6653.4 SPS. Inference batcher size: 94. Learner queue size: 25. Other stats: (step = 92456960, mean_episode_return = 193.45, mean_episode_step = 620.4, total_loss = 115.48, pg_loss = -0.92568, baseline_loss = 121.98, entropy_loss = -5.5817, learner_queue_size = 25, _tick = 29719, _time = 1.654e+09, train_seconds = 1.4021e+04)
[2022-05-31 18:04:07,684][root][INFO] - Step 92487680 @ 6136.5 SPS. Inference batcher size: 123. Learner queue size: 15. Other stats: (step = 92487680, mean_episode_return = 183.75, mean_episode_step = 791.3, total_loss = 252.43, pg_loss = 160.07, baseline_loss = 97.988, entropy_loss = -5.6329, learner_queue_size = 10, _tick = 29731, _time = 1.654e+09, train_seconds = 1.4026e+04)
[2022-05-31 18:04:12,690][root][INFO] - Step 92520960 @ 6647.9 SPS. Inference batcher size: 106. Learner queue size: 15. Other stats: (step = 92520960, mean_episode_return = 195.8, mean_episode_step = 614.76, total_loss = -115.21, pg_loss = -197.4, baseline_loss = 87.921, entropy_loss = -5.7289, learner_queue_size = 15, _tick = 29743, _time = 1.654e+09, train_seconds = 1.4031e+04)
[2022-05-31 18:04:17,694][root][INFO] - Step 92554240 @ 6651.0 SPS. Inference batcher size: 126. Learner queue size: 17. Other stats: (step = 92554240, mean_episode_return = 319.73, mean_episode_step = 533.12, total_loss = 176.59, pg_loss = 93.387, baseline_loss = 88.731, entropy_loss = -5.5272, learner_queue_size = 10, _tick = 29756, _time = 1.654e+09, train_seconds = 1.4036e+04)
[2022-05-31 18:04:22,700][root][INFO] - Step 92587520 @ 6647.9 SPS. Inference batcher size: 101. Learner queue size: 13. Other stats: (step = 92587520, mean_episode_return = 151.39, mean_episode_step = 576.83, total_loss = -85.75, pg_loss = -201.51, baseline_loss = 121.28, entropy_loss = -5.5229, learner_queue_size = 10, _tick = 29769, _time = 1.654e+09, train_seconds = 1.4041e+04)
[2022-05-31 18:04:27,706][root][INFO] - Step 92620800 @ 6648.0 SPS. Inference batcher size: 74. Learner queue size: 1. Other stats: (step = 92620800, mean_episode_return = 50.906, mean_episode_step = 690.96, total_loss = -152.52, pg_loss = -245.68, baseline_loss = 98.746, entropy_loss = -5.5877, learner_queue_size = 17, _tick = 29782, _time = 1.654e+09, train_seconds = 1.4046e+04)
[2022-05-31 18:04:32,712][root][INFO] - Step 92651520 @ 6137.0 SPS. Inference batcher size: 112. Learner queue size: 19. Other stats: (step = 92651520, mean_episode_return = 230.46, mean_episode_step = 596.54, total_loss = 265.83, pg_loss = 113.31, baseline_loss = 158.0, entropy_loss = -5.4878, learner_queue_size = 19, _tick = 29794, _time = 1.654e+09, train_seconds = 1.4051e+04)
[2022-05-31 18:04:37,718][root][INFO] - Step 92684800 @ 6648.0 SPS. Inference batcher size: 89. Learner queue size: 17. Other stats: (step = 92684800, mean_episode_return = 101.36, mean_episode_step = 748.57, total_loss = 57.844, pg_loss = -136.39, baseline_loss = 199.84, entropy_loss = -5.6004, learner_queue_size = 16, _tick = 29807, _time = 1.654e+09, train_seconds = 1.4056e+04)
[2022-05-31 18:04:42,722][root][INFO] - Step 92718080 @ 6650.5 SPS. Inference batcher size: 85. Learner queue size: 14. Other stats: (step = 92718080, mean_episode_return = 60.71, mean_episode_step = 592.62, total_loss = -84.174, pg_loss = -147.49, baseline_loss = 68.467, entropy_loss = -5.1549, learner_queue_size = 27, _tick = 29818, _time = 1.654e+09, train_seconds = 1.4061e+04)
[2022-05-31 18:04:47,726][root][INFO] - Step 92751360 @ 6650.7 SPS. Inference batcher size: 70. Learner queue size: 10. Other stats: (step = 92751360, mean_episode_return = None, mean_episode_step = 904.72, total_loss = 103.89, pg_loss = 40.825, baseline_loss = 68.707, entropy_loss = -5.6457, learner_queue_size = 20, _tick = 29829, _time = 1.654e+09, train_seconds = 1.4066e+04)
[2022-05-31 18:04:52,732][root][INFO] - Step 92784640 @ 6647.8 SPS. Inference batcher size: 104. Learner queue size: 1. Other stats: (step = 92784640, mean_episode_return = 526.99, mean_episode_step = 685.14, total_loss = -43.665, pg_loss = -159.43, baseline_loss = 121.74, entropy_loss = -5.9761, learner_queue_size = 14, _tick = 29840, _time = 1.654e+09, train_seconds = 1.4071e+04)
[2022-05-31 18:04:57,738][root][INFO] - Step 92817920 @ 6648.2 SPS. Inference batcher size: 132. Learner queue size: 20. Other stats: (step = 92817920, mean_episode_return = 99.04, mean_episode_step = 984.53, total_loss = -18.632, pg_loss = -109.17, baseline_loss = 95.942, entropy_loss = -5.4072, learner_queue_size = 17, _tick = 29853, _time = 1.654e+09, train_seconds = 1.4076e+04)
[2022-05-31 18:05:02,744][root][INFO] - Step 92848640 @ 6136.1 SPS. Inference batcher size: 99. Learner queue size: 28. Other stats: (step = 92848640, mean_episode_return = 308.94, mean_episode_step = 852.23, total_loss = -20.738, pg_loss = -134.01, baseline_loss = 118.64, entropy_loss = -5.367, learner_queue_size = 13, _tick = 29864, _time = 1.654e+09, train_seconds = 1.4081e+04)
[2022-05-31 18:05:07,750][root][INFO] - Step 92884480 @ 7160.0 SPS. Inference batcher size: 130. Learner queue size: 22. Other stats: (step = 92884480, mean_episode_return = 274.72, mean_episode_step = 533.04, total_loss = 846.93, pg_loss = 417.3, baseline_loss = 435.08, entropy_loss = -5.4542, learner_queue_size = 12, _tick = 29878, _time = 1.654e+09, train_seconds = 1.4086e+04)
[2022-05-31 18:05:12,756][root][INFO] - Step 92915200 @ 6136.6 SPS. Inference batcher size: 102. Learner queue size: 17. Other stats: (step = 92915200, mean_episode_return = 44.52, mean_episode_step = 954.94, total_loss = 28.637, pg_loss = -181.16, baseline_loss = 215.83, entropy_loss = -6.0255, learner_queue_size = 23, _tick = 29889, _time = 1.654e+09, train_seconds = 1.4091e+04)
[2022-05-31 18:05:17,762][root][INFO] - Step 92948480 @ 6648.0 SPS. Inference batcher size: 116. Learner queue size: 11. Other stats: (step = 92948480, mean_episode_return = 370.25, mean_episode_step = 882.8, total_loss = -64.8, pg_loss = -365.85, baseline_loss = 306.98, entropy_loss = -5.9233, learner_queue_size = 15, _tick = 29902, _time = 1.654e+09, train_seconds = 1.4096e+04)
[2022-05-31 18:05:22,768][root][INFO] - Step 92981760 @ 6648.0 SPS. Inference batcher size: 129. Learner queue size: 11. Other stats: (step = 92981760, mean_episode_return = None, mean_episode_step = 851.88, total_loss = 10.606, pg_loss = -191.44, baseline_loss = 207.72, entropy_loss = -5.6716, learner_queue_size = 20, _tick = 29912, _time = 1.654e+09, train_seconds = 1.4102e+04)
[2022-05-31 18:05:27,774][root][INFO] - Step 93015040 @ 6648.1 SPS. Inference batcher size: 57. Learner queue size: 24. Other stats: (step = 93015040, mean_episode_return = 562.97, mean_episode_step = 961.29, total_loss = 548.59, pg_loss = 215.15, baseline_loss = 338.98, entropy_loss = -5.5281, learner_queue_size = 23, _tick = 29923, _time = 1.654e+09, train_seconds = 1.4106e+04)
[2022-05-31 18:05:32,778][root][INFO] - Step 93048320 @ 6650.5 SPS. Inference batcher size: 149. Learner queue size: 11. Other stats: (step = 93048320, mean_episode_return = None, mean_episode_step = 901.47, total_loss = 394.53, pg_loss = 225.64, baseline_loss = 174.47, entropy_loss = -5.5879, learner_queue_size = 21, _tick = 29933, _time = 1.654e+09, train_seconds = 1.4112e+04)
[2022-05-31 18:05:37,782][root][INFO] - Step 93081600 @ 6650.8 SPS. Inference batcher size: 123. Learner queue size: 10. Other stats: (step = 93081600, mean_episode_return = 245.08, mean_episode_step = 528.45, total_loss = 218.38, pg_loss = 60.08, baseline_loss = 164.15, entropy_loss = -5.8496, learner_queue_size = 13, _tick = 29942, _time = 1.654e+09, train_seconds = 1.4116e+04)
[2022-05-31 18:05:42,789][root][INFO] - Step 93114880 @ 6646.9 SPS. Inference batcher size: 33. Learner queue size: 1. Other stats: (step = 93114880, mean_episode_return = 343.62, mean_episode_step = 607.25, total_loss = 1135.5, pg_loss = 393.47, baseline_loss = 747.39, entropy_loss = -5.3951, learner_queue_size = 20, _tick = 29955, _time = 1.654e+09, train_seconds = 1.4122e+04)
[2022-05-31 18:05:47,794][root][INFO] - Step 93148160 @ 6649.2 SPS. Inference batcher size: 114. Learner queue size: 11. Other stats: (step = 93148160, mean_episode_return = 216.42, mean_episode_step = 545.88, total_loss = 350.26, pg_loss = 161.74, baseline_loss = 194.1, entropy_loss = -5.5804, learner_queue_size = 20, _tick = 29967, _time = 1.654e+09, train_seconds = 1.4126e+04)
[2022-05-31 18:05:52,798][root][INFO] - Step 93181440 @ 6650.7 SPS. Inference batcher size: 90. Learner queue size: 8. Other stats: (step = 93181440, mean_episode_return = 342.53, mean_episode_step = 1228.9, total_loss = 155.34, pg_loss = -116.71, baseline_loss = 278.06, entropy_loss = -6.0113, learner_queue_size = 24, _tick = 29980, _time = 1.654e+09, train_seconds = 1.4132e+04)
[2022-05-31 18:05:57,802][root][INFO] - Step 93214720 @ 6650.6 SPS. Inference batcher size: 146. Learner queue size: 5. Other stats: (step = 93214720, mean_episode_return = 345.2, mean_episode_step = 628.15, total_loss = -183.47, pg_loss = -278.0, baseline_loss = 100.03, entropy_loss = -5.5014, learner_queue_size = 16, _tick = 29993, _time = 1.654e+09, train_seconds = 1.4136e+04)
[2022-05-31 18:06:02,806][root][INFO] - Step 93248000 @ 6650.7 SPS. Inference batcher size: 49. Learner queue size: 30. Other stats: (step = 93248000, mean_episode_return = 228.28, mean_episode_step = 631.86, total_loss = 41.116, pg_loss = -87.185, baseline_loss = 134.05, entropy_loss = -5.7525, learner_queue_size = 25, _tick = 30004, _time = 1.654e+09, train_seconds = 1.4142e+04)
[2022-05-31 18:06:07,810][root][INFO] - Step 93278720 @ 6139.0 SPS. Inference batcher size: 89. Learner queue size: 23. Other stats: (step = 93278720, mean_episode_return = 212.78, mean_episode_step = 1285.3, total_loss = -53.316, pg_loss = -103.57, baseline_loss = 56.314, entropy_loss = -6.0623, learner_queue_size = 16, _tick = 30015, _time = 1.654e+09, train_seconds = 1.4146e+04)
[2022-05-31 18:06:12,816][root][INFO] - Step 93312000 @ 6647.7 SPS. Inference batcher size: 141. Learner queue size: 18. Other stats: (step = 93312000, mean_episode_return = 178.4, mean_episode_step = 709.5, total_loss = 75.917, pg_loss = 68.91, baseline_loss = 13.873, entropy_loss = -6.8655, learner_queue_size = 15, _tick = 30028, _time = 1.654e+09, train_seconds = 1.4152e+04)
[2022-05-31 18:06:17,822][root][INFO] - Step 93345280 @ 6648.1 SPS. Inference batcher size: 146. Learner queue size: 18. Other stats: (step = 93345280, mean_episode_return = -10.288, mean_episode_step = 818.13, total_loss = 208.08, pg_loss = 170.0, baseline_loss = 44.245, entropy_loss = -6.1697, learner_queue_size = 19, _tick = 30040, _time = 1.654e+09, train_seconds = 1.4156e+04)
[2022-05-31 18:06:22,826][root][INFO] - Step 93378560 @ 6650.9 SPS. Inference batcher size: 53. Learner queue size: 6. Other stats: (step = 93378560, mean_episode_return = 180.5, mean_episode_step = 686.35, total_loss = 27.83, pg_loss = -24.918, baseline_loss = 58.394, entropy_loss = -5.6461, learner_queue_size = 16, _tick = 30053, _time = 1.654e+09, train_seconds = 1.4162e+04)
[2022-05-31 18:06:27,832][root][INFO] - Step 93411840 @ 6647.9 SPS. Inference batcher size: 96. Learner queue size: 3. Other stats: (step = 93411840, mean_episode_return = None, mean_episode_step = 663.69, total_loss = -152.78, pg_loss = -218.32, baseline_loss = 71.227, entropy_loss = -5.6825, learner_queue_size = 22, _tick = 30064, _time = 1.654e+09, train_seconds = 1.4166e+04)
[2022-05-31 18:06:32,838][root][INFO] - Step 93445120 @ 6648.2 SPS. Inference batcher size: 87. Learner queue size: 22. Other stats: (step = 93445120, mean_episode_return = 406.49, mean_episode_step = 861.39, total_loss = -157.81, pg_loss = -191.15, baseline_loss = 39.697, entropy_loss = -6.3622, learner_queue_size = 22, _tick = 30077, _time = 1.654e+09, train_seconds = 1.4172e+04)
[2022-05-31 18:06:37,844][root][INFO] - Step 93475840 @ 6136.6 SPS. Inference batcher size: 104. Learner queue size: 23. Other stats: (step = 93475840, mean_episode_return = 61.249, mean_episode_step = 695.51, total_loss = 361.94, pg_loss = 233.05, baseline_loss = 135.11, entropy_loss = -6.2185, learner_queue_size = 13, _tick = 30086, _time = 1.654e+09, train_seconds = 1.4176e+04)
[2022-05-31 18:06:42,850][root][INFO] - Step 93509120 @ 6648.0 SPS. Inference batcher size: 162. Learner queue size: 17. Other stats: (step = 93509120, mean_episode_return = 137.33, mean_episode_step = 624.59, total_loss = -63.698, pg_loss = -123.77, baseline_loss = 66.534, entropy_loss = -6.4616, learner_queue_size = 18, _tick = 30098, _time = 1.654e+09, train_seconds = 1.4182e+04)
[2022-05-31 18:06:47,856][root][INFO] - Step 93542400 @ 6648.0 SPS. Inference batcher size: 133. Learner queue size: 19. Other stats: (step = 93542400, mean_episode_return = 106.57, mean_episode_step = 957.23, total_loss = -218.29, pg_loss = -277.85, baseline_loss = 65.515, entropy_loss = -5.9558, learner_queue_size = 23, _tick = 30110, _time = 1.654e+09, train_seconds = 1.4186e+04)
[2022-05-31 18:06:52,862][root][INFO] - Step 93575680 @ 6648.0 SPS. Inference batcher size: 131. Learner queue size: 11. Other stats: (step = 93575680, mean_episode_return = 164.81, mean_episode_step = 619.47, total_loss = 307.26, pg_loss = 54.837, baseline_loss = 258.35, entropy_loss = -5.9237, learner_queue_size = 25, _tick = 30122, _time = 1.654e+09, train_seconds = 1.4192e+04)
[2022-05-31 18:06:57,868][root][INFO] - Step 93608960 @ 6648.0 SPS. Inference batcher size: 50. Learner queue size: 18. Other stats: (step = 93608960, mean_episode_return = None, mean_episode_step = 923.66, total_loss = 162.3, pg_loss = 63.46, baseline_loss = 104.86, entropy_loss = -6.0213, learner_queue_size = 21, _tick = 30134, _time = 1.654e+09, train_seconds = 1.4197e+04)
[2022-05-31 18:07:02,874][root][INFO] - Step 93642240 @ 6648.2 SPS. Inference batcher size: 146. Learner queue size: 12. Other stats: (step = 93642240, mean_episode_return = 97.941, mean_episode_step = 951.3, total_loss = 354.12, pg_loss = 62.946, baseline_loss = 296.91, entropy_loss = -5.7383, learner_queue_size = 13, _tick = 30146, _time = 1.654e+09, train_seconds = 1.4202e+04)
[2022-05-31 18:07:07,878][root][INFO] - Step 93675520 @ 6650.6 SPS. Inference batcher size: 115. Learner queue size: 4. Other stats: (step = 93675520, mean_episode_return = 224.26, mean_episode_step = 820.15, total_loss = -375.41, pg_loss = -426.36, baseline_loss = 56.551, entropy_loss = -5.6075, learner_queue_size = 15, _tick = 30157, _time = 1.654e+09, train_seconds = 1.4207e+04)
[2022-05-31 18:07:12,882][root][INFO] - Step 93708800 @ 6650.8 SPS. Inference batcher size: 156. Learner queue size: 30. Other stats: (step = 93708800, mean_episode_return = 189.27, mean_episode_step = 619.6, total_loss = 414.11, pg_loss = 131.3, baseline_loss = 288.31, entropy_loss = -5.5027, learner_queue_size = 14, _tick = 30168, _time = 1.654e+09, train_seconds = 1.4212e+04)
[2022-05-31 18:07:17,886][root][INFO] - Step 93739520 @ 6139.0 SPS. Inference batcher size: 75. Learner queue size: 23. Other stats: (step = 93739520, mean_episode_return = 197.68, mean_episode_step = 659.72, total_loss = 31.263, pg_loss = -41.242, baseline_loss = 78.221, entropy_loss = -5.7161, learner_queue_size = 18, _tick = 30176, _time = 1.654e+09, train_seconds = 1.4217e+04)
[2022-05-31 18:07:22,892][root][INFO] - Step 93772800 @ 6647.9 SPS. Inference batcher size: 141. Learner queue size: 17. Other stats: (step = 93772800, mean_episode_return = 225.64, mean_episode_step = 679.95, total_loss = 514.77, pg_loss = 240.95, baseline_loss = 279.07, entropy_loss = -5.247, learner_queue_size = 23, _tick = 30187, _time = 1.654e+09, train_seconds = 1.4222e+04)
[2022-05-31 18:07:27,898][root][INFO] - Step 93806080 @ 6648.0 SPS. Inference batcher size: 112. Learner queue size: 19. Other stats: (step = 93806080, mean_episode_return = None, mean_episode_step = 768.81, total_loss = 29.159, pg_loss = -9.7391, baseline_loss = 44.979, entropy_loss = -6.0816, learner_queue_size = 21, _tick = 30197, _time = 1.654e+09, train_seconds = 1.4227e+04)
[2022-05-31 18:07:32,902][root][INFO] - Step 93839360 @ 6651.0 SPS. Inference batcher size: 174. Learner queue size: 6. Other stats: (step = 93839360, mean_episode_return = 311.39, mean_episode_step = 665.03, total_loss = 481.28, pg_loss = 216.42, baseline_loss = 270.47, entropy_loss = -5.6097, learner_queue_size = 22, _tick = 30209, _time = 1.654e+09, train_seconds = 1.4232e+04)
[2022-05-31 18:07:37,906][root][INFO] - Step 93872640 @ 6650.7 SPS. Inference batcher size: 120. Learner queue size: 28. Other stats: (step = 93872640, mean_episode_return = None, mean_episode_step = 645.19, total_loss = -48.585, pg_loss = -167.97, baseline_loss = 124.73, entropy_loss = -5.3383, learner_queue_size = 12, _tick = 30220, _time = 1.654e+09, train_seconds = 1.4237e+04)
[2022-05-31 18:07:42,908][root][INFO] - Step 93905920 @ 6654.0 SPS. Inference batcher size: 88. Learner queue size: 25. Other stats: (step = 93905920, mean_episode_return = None, mean_episode_step = 695.84, total_loss = 16.63, pg_loss = -49.321, baseline_loss = 72.002, entropy_loss = -6.0507, learner_queue_size = 24, _tick = 30231, _time = 1.654e+09, train_seconds = 1.4242e+04)
[2022-05-31 18:07:47,914][root][INFO] - Step 93936640 @ 6136.5 SPS. Inference batcher size: 165. Learner queue size: 16. Other stats: (step = 93936640, mean_episode_return = None, mean_episode_step = 551.47, total_loss = 112.67, pg_loss = -3.6959, baseline_loss = 122.04, entropy_loss = -5.6722, learner_queue_size = 14, _tick = 30239, _time = 1.654e+09, train_seconds = 1.4247e+04)
[2022-05-31 18:07:52,920][root][INFO] - Step 93969920 @ 6647.9 SPS. Inference batcher size: 128. Learner queue size: 25. Other stats: (step = 93969920, mean_episode_return = 236.37, mean_episode_step = 868.33, total_loss = 298.4, pg_loss = 111.68, baseline_loss = 192.09, entropy_loss = -5.3742, learner_queue_size = 12, _tick = 30252, _time = 1.654e+09, train_seconds = 1.4252e+04)
[2022-05-31 18:07:57,926][root][INFO] - Step 94003200 @ 6648.0 SPS. Inference batcher size: 211. Learner queue size: 22. Other stats: (step = 94003200, mean_episode_return = 192.01, mean_episode_step = 678.0, total_loss = 421.32, pg_loss = 186.61, baseline_loss = 240.43, entropy_loss = -5.7269, learner_queue_size = 22, _tick = 30263, _time = 1.654e+09, train_seconds = 1.4257e+04)
[2022-05-31 18:08:02,930][root][INFO] - Step 94036480 @ 6650.2 SPS. Inference batcher size: 81. Learner queue size: 7. Other stats: (step = 94036480, mean_episode_return = 198.34, mean_episode_step = 659.8, total_loss = 355.28, pg_loss = 118.92, baseline_loss = 241.45, entropy_loss = -5.0854, learner_queue_size = 12, _tick = 30276, _time = 1.654e+09, train_seconds = 1.4262e+04)
[2022-05-31 18:08:07,936][root][INFO] - Step 94069760 @ 6647.8 SPS. Inference batcher size: 79. Learner queue size: 11. Other stats: (step = 94069760, mean_episode_return = 84.563, mean_episode_step = 595.4, total_loss = 112.36, pg_loss = -84.186, baseline_loss = 201.94, entropy_loss = -5.3985, learner_queue_size = 24, _tick = 30288, _time = 1.654e+09, train_seconds = 1.4267e+04)
[2022-05-31 18:08:12,942][root][INFO] - Step 94103040 @ 6648.3 SPS. Inference batcher size: 141. Learner queue size: 4. Other stats: (step = 94103040, mean_episode_return = 148.26, mean_episode_step = 578.84, total_loss = 367.76, pg_loss = 193.62, baseline_loss = 179.46, entropy_loss = -5.3283, learner_queue_size = 11, _tick = 30299, _time = 1.654e+09, train_seconds = 1.4272e+04)
[2022-05-31 18:08:17,948][root][INFO] - Step 94136320 @ 6647.9 SPS. Inference batcher size: 68. Learner queue size: 4. Other stats: (step = 94136320, mean_episode_return = 143.86, mean_episode_step = 859.94, total_loss = 188.35, pg_loss = 67.8, baseline_loss = 126.1, entropy_loss = -5.5501, learner_queue_size = 27, _tick = 30310, _time = 1.654e+09, train_seconds = 1.4277e+04)
[2022-05-31 18:08:22,950][root][INFO] - Step 94169600 @ 6653.6 SPS. Inference batcher size: 27. Learner queue size: 26. Other stats: (step = 94169600, mean_episode_return = 302.98, mean_episode_step = 673.46, total_loss = 297.98, pg_loss = 197.68, baseline_loss = 106.11, entropy_loss = -5.8052, learner_queue_size = 23, _tick = 30321, _time = 1.654e+09, train_seconds = 1.4282e+04)
[2022-05-31 18:08:27,954][root][INFO] - Step 94200320 @ 6139.1 SPS. Inference batcher size: 97. Learner queue size: 14. Other stats: (step = 94200320, mean_episode_return = 81.621, mean_episode_step = 905.43, total_loss = 281.25, pg_loss = 167.13, baseline_loss = 118.96, entropy_loss = -4.8307, learner_queue_size = 17, _tick = 30333, _time = 1.654e+09, train_seconds = 1.4287e+04)
[2022-05-31 18:08:32,960][root][INFO] - Step 94233600 @ 6647.4 SPS. Inference batcher size: 109. Learner queue size: 12. Other stats: (step = 94233600, mean_episode_return = 329.64, mean_episode_step = 984.62, total_loss = 220.32, pg_loss = -64.193, baseline_loss = 289.48, entropy_loss = -4.9675, learner_queue_size = 16, _tick = 30345, _time = 1.654e+09, train_seconds = 1.4292e+04)
[2022-05-31 18:08:37,966][root][INFO] - Step 94266880 @ 6648.6 SPS. Inference batcher size: 116. Learner queue size: 9. Other stats: (step = 94266880, mean_episode_return = 253.51, mean_episode_step = 677.92, total_loss = -13.309, pg_loss = -80.036, baseline_loss = 72.432, entropy_loss = -5.7048, learner_queue_size = 22, _tick = 30358, _time = 1.654e+09, train_seconds = 1.4297e+04)
[2022-05-31 18:08:42,970][root][INFO] - Step 94300160 @ 6650.8 SPS. Inference batcher size: 128. Learner queue size: 13. Other stats: (step = 94300160, mean_episode_return = 290.99, mean_episode_step = 752.15, total_loss = 109.52, pg_loss = 3.4047, baseline_loss = 112.16, entropy_loss = -6.0438, learner_queue_size = 13, _tick = 30370, _time = 1.654e+09, train_seconds = 1.4302e+04)
[2022-05-31 18:08:47,976][root][INFO] - Step 94333440 @ 6647.9 SPS. Inference batcher size: 137. Learner queue size: 3. Other stats: (step = 94333440, mean_episode_return = 126.69, mean_episode_step = 669.82, total_loss = 243.1, pg_loss = 116.01, baseline_loss = 132.73, entropy_loss = -5.6382, learner_queue_size = 20, _tick = 30382, _time = 1.654e+09, train_seconds = 1.4307e+04)
[2022-05-31 18:08:52,979][root][INFO] - Step 94366720 @ 6652.6 SPS. Inference batcher size: 22. Learner queue size: 28. Other stats: (step = 94366720, mean_episode_return = 222.27, mean_episode_step = 704.2, total_loss = 180.36, pg_loss = 112.96, baseline_loss = 72.679, entropy_loss = -5.2747, learner_queue_size = 14, _tick = 30394, _time = 1.654e+09, train_seconds = 1.4312e+04)
[2022-05-31 18:08:57,982][root][INFO] - Step 94400000 @ 6651.4 SPS. Inference batcher size: 136. Learner queue size: 30. Other stats: (step = 94400000, mean_episode_return = 132.23, mean_episode_step = 681.23, total_loss = 137.47, pg_loss = -90.425, baseline_loss = 233.35, entropy_loss = -5.4603, learner_queue_size = 21, _tick = 30406, _time = 1.654e+09, train_seconds = 1.4317e+04)
[2022-05-31 18:09:02,984][root][INFO] - Step 94430720 @ 6142.2 SPS. Inference batcher size: 126. Learner queue size: 19. Other stats: (step = 94430720, mean_episode_return = 192.69, mean_episode_step = 745.56, total_loss = -104.75, pg_loss = -132.74, baseline_loss = 34.095, entropy_loss = -6.1068, learner_queue_size = 14, _tick = 30418, _time = 1.654e+09, train_seconds = 1.4322e+04)
[2022-05-31 18:09:07,990][root][INFO] - Step 94464000 @ 6647.9 SPS. Inference batcher size: 163. Learner queue size: 9. Other stats: (step = 94464000, mean_episode_return = 317.47, mean_episode_step = 547.49, total_loss = 95.384, pg_loss = 58.217, baseline_loss = 43.413, entropy_loss = -6.2455, learner_queue_size = 15, _tick = 30430, _time = 1.654e+09, train_seconds = 1.4327e+04)
[2022-05-31 18:09:12,996][root][INFO] - Step 94497280 @ 6648.0 SPS. Inference batcher size: 105. Learner queue size: 19. Other stats: (step = 94497280, mean_episode_return = 146.45, mean_episode_step = 512.96, total_loss = 507.35, pg_loss = 320.79, baseline_loss = 192.21, entropy_loss = -5.6552, learner_queue_size = 18, _tick = 30442, _time = 1.654e+09, train_seconds = 1.4332e+04)
[2022-05-31 18:09:18,000][root][INFO] - Step 94530560 @ 6650.4 SPS. Inference batcher size: 51. Learner queue size: 4. Other stats: (step = 94530560, mean_episode_return = 139.79, mean_episode_step = 604.66, total_loss = 492.07, pg_loss = 325.41, baseline_loss = 172.47, entropy_loss = -5.8109, learner_queue_size = 15, _tick = 30452, _time = 1.654e+09, train_seconds = 1.4337e+04)
[2022-05-31 18:09:23,006][root][INFO] - Step 94563840 @ 6647.6 SPS. Inference batcher size: 72. Learner queue size: 10. Other stats: (step = 94563840, mean_episode_return = 118.45, mean_episode_step = 539.86, total_loss = 49.878, pg_loss = 7.0335, baseline_loss = 48.584, entropy_loss = -5.7392, learner_queue_size = 20, _tick = 30463, _time = 1.654e+09, train_seconds = 1.4342e+04)
[2022-05-31 18:09:28,012][root][INFO] - Step 94597120 @ 6648.2 SPS. Inference batcher size: 69. Learner queue size: 3. Other stats: (step = 94597120, mean_episode_return = 413.27, mean_episode_step = 691.63, total_loss = 22.608, pg_loss = -74.125, baseline_loss = 102.69, entropy_loss = -5.9534, learner_queue_size = 23, _tick = 30476, _time = 1.654e+09, train_seconds = 1.4347e+04)
[2022-05-31 18:09:33,014][root][INFO] - Step 94630400 @ 6653.1 SPS. Inference batcher size: 70. Learner queue size: 29. Other stats: (step = 94630400, mean_episode_return = 283.32, mean_episode_step = 734.12, total_loss = 949.36, pg_loss = 366.33, baseline_loss = 588.76, entropy_loss = -5.7325, learner_queue_size = 19, _tick = 30487, _time = 1.654e+09, train_seconds = 1.4352e+04)
[2022-05-31 18:09:38,018][root][INFO] - Step 94663680 @ 6650.8 SPS. Inference batcher size: 16. Learner queue size: 28. Other stats: (step = 94663680, mean_episode_return = None, mean_episode_step = 702.28, total_loss = 22.494, pg_loss = -44.298, baseline_loss = 72.869, entropy_loss = -6.0767, learner_queue_size = 25, _tick = 30497, _time = 1.654e+09, train_seconds = 1.4357e+04)
[2022-05-31 18:09:43,025][root][INFO] - Step 94694400 @ 6135.5 SPS. Inference batcher size: 151. Learner queue size: 22. Other stats: (step = 94694400, mean_episode_return = 107.18, mean_episode_step = 777.92, total_loss = 116.09, pg_loss = 52.627, baseline_loss = 69.722, entropy_loss = -6.2586, learner_queue_size = 16, _tick = 30508, _time = 1.654e+09, train_seconds = 1.4362e+04)
[2022-05-31 18:09:48,030][root][INFO] - Step 94727680 @ 6649.3 SPS. Inference batcher size: 120. Learner queue size: 12. Other stats: (step = 94727680, mean_episode_return = 93.309, mean_episode_step = 1012.8, total_loss = 58.828, pg_loss = 17.915, baseline_loss = 47.237, entropy_loss = -6.3235, learner_queue_size = 15, _tick = 30521, _time = 1.654e+09, train_seconds = 1.4367e+04)
[2022-05-31 18:09:53,034][root][INFO] - Step 94760960 @ 6650.7 SPS. Inference batcher size: 180. Learner queue size: 10. Other stats: (step = 94760960, mean_episode_return = 345.3, mean_episode_step = 944.56, total_loss = 212.93, pg_loss = 126.38, baseline_loss = 92.737, entropy_loss = -6.188, learner_queue_size = 22, _tick = 30534, _time = 1.654e+09, train_seconds = 1.4372e+04)
[2022-05-31 18:09:58,038][root][INFO] - Step 94794240 @ 6650.6 SPS. Inference batcher size: 73. Learner queue size: 17. Other stats: (step = 94794240, mean_episode_return = 464.01, mean_episode_step = 625.24, total_loss = 14.97, pg_loss = -26.846, baseline_loss = 48.211, entropy_loss = -6.395, learner_queue_size = 23, _tick = 30546, _time = 1.654e+09, train_seconds = 1.4377e+04)
[2022-05-31 18:10:03,042][root][INFO] - Step 94827520 @ 6650.7 SPS. Inference batcher size: 55. Learner queue size: 7. Other stats: (step = 94827520, mean_episode_return = 251.88, mean_episode_step = 1008.6, total_loss = -7.2031, pg_loss = -91.356, baseline_loss = 90.421, entropy_loss = -6.2678, learner_queue_size = 15, _tick = 30559, _time = 1.654e+09, train_seconds = 1.4382e+04)
[2022-05-31 18:10:08,046][root][INFO] - Step 94860800 @ 6650.8 SPS. Inference batcher size: 51. Learner queue size: 20. Other stats: (step = 94860800, mean_episode_return = 139.2, mean_episode_step = 578.06, total_loss = 500.55, pg_loss = 372.76, baseline_loss = 133.67, entropy_loss = -5.882, learner_queue_size = 9, _tick = 30572, _time = 1.654e+09, train_seconds = 1.4387e+04)
[2022-05-31 18:10:13,050][root][INFO] - Step 94894080 @ 6650.8 SPS. Inference batcher size: 140. Learner queue size: 23. Other stats: (step = 94894080, mean_episode_return = 233.93, mean_episode_step = 536.8, total_loss = 266.98, pg_loss = 151.68, baseline_loss = 120.83, entropy_loss = -5.5286, learner_queue_size = 23, _tick = 30584, _time = 1.654e+09, train_seconds = 1.4392e+04)
[2022-05-31 18:10:18,056][root][INFO] - Step 94924800 @ 6136.7 SPS. Inference batcher size: 75. Learner queue size: 20. Other stats: (step = 94924800, mean_episode_return = 141.67, mean_episode_step = 673.26, total_loss = 231.45, pg_loss = 115.52, baseline_loss = 121.72, entropy_loss = -5.792, learner_queue_size = 26, _tick = 30596, _time = 1.654e+09, train_seconds = 1.4397e+04)
[2022-05-31 18:10:23,062][root][INFO] - Step 94958080 @ 6647.9 SPS. Inference batcher size: 70. Learner queue size: 8. Other stats: (step = 94958080, mean_episode_return = 601.16, mean_episode_step = 575.17, total_loss = 161.62, pg_loss = -143.86, baseline_loss = 311.27, entropy_loss = -5.7969, learner_queue_size = 12, _tick = 30606, _time = 1.654e+09, train_seconds = 1.4402e+04)
[2022-05-31 18:10:28,068][root][INFO] - Step 94991360 @ 6648.1 SPS. Inference batcher size: 151. Learner queue size: 13. Other stats: (step = 94991360, mean_episode_return = 10.29, mean_episode_step = 726.84, total_loss = -87.58, pg_loss = -172.68, baseline_loss = 90.919, entropy_loss = -5.8166, learner_queue_size = 23, _tick = 30618, _time = 1.654e+09, train_seconds = 1.4407e+04)
[2022-05-31 18:10:33,074][root][INFO] - Step 95024640 @ 6648.3 SPS. Inference batcher size: 113. Learner queue size: 1. Other stats: (step = 95024640, mean_episode_return = None, mean_episode_step = 631.19, total_loss = -322.41, pg_loss = -344.85, baseline_loss = 28.468, entropy_loss = -6.0234, learner_queue_size = 23, _tick = 30628, _time = 1.654e+09, train_seconds = 1.4412e+04)
[2022-05-31 18:10:38,078][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 18:10:38,147][root][INFO] - Step 95057920 @ 6650.3 SPS. Inference batcher size: 1. Learner queue size: 8. Other stats: (step = 95057920, mean_episode_return = 244.08, mean_episode_step = 762.33, total_loss = -171.51, pg_loss = -204.49, baseline_loss = 39.357, entropy_loss = -6.3785, learner_queue_size = 15, _tick = 30640, _time = 1.654e+09, train_seconds = 1.4417e+04)
[2022-05-31 18:10:43,150][root][INFO] - Step 95091200 @ 6561.4 SPS. Inference batcher size: 124. Learner queue size: 1. Other stats: (step = 95091200, mean_episode_return = 165.48, mean_episode_step = 773.99, total_loss = 103.63, pg_loss = 67.937, baseline_loss = 42.007, entropy_loss = -6.3118, learner_queue_size = 17, _tick = 30651, _time = 1.654e+09, train_seconds = 1.4422e+04)
[2022-05-31 18:10:48,154][root][INFO] - Step 95124480 @ 6650.8 SPS. Inference batcher size: 156. Learner queue size: 31. Other stats: (step = 95124480, mean_episode_return = 135.66, mean_episode_step = 879.24, total_loss = -119.7, pg_loss = -158.48, baseline_loss = 44.992, entropy_loss = -6.2081, learner_queue_size = 14, _tick = 30664, _time = 1.654e+09, train_seconds = 1.4427e+04)
[2022-05-31 18:10:53,161][root][INFO] - Step 95157760 @ 6647.1 SPS. Inference batcher size: 60. Learner queue size: 27. Other stats: (step = 95157760, mean_episode_return = 206.93, mean_episode_step = 979.28, total_loss = 141.72, pg_loss = 30.132, baseline_loss = 117.45, entropy_loss = -5.8621, learner_queue_size = 18, _tick = 30677, _time = 1.654e+09, train_seconds = 1.4432e+04)
[2022-05-31 18:10:58,168][root][INFO] - Step 95188480 @ 6135.1 SPS. Inference batcher size: 68. Learner queue size: 24. Other stats: (step = 95188480, mean_episode_return = 160.03, mean_episode_step = 809.57, total_loss = 162.56, pg_loss = 104.86, baseline_loss = 63.99, entropy_loss = -6.2986, learner_queue_size = 21, _tick = 30688, _time = 1.654e+09, train_seconds = 1.4437e+04)
[2022-05-31 18:11:03,170][root][INFO] - Step 95221760 @ 6653.2 SPS. Inference batcher size: 164. Learner queue size: 21. Other stats: (step = 95221760, mean_episode_return = 172.57, mean_episode_step = 588.83, total_loss = 319.26, pg_loss = 198.86, baseline_loss = 126.23, entropy_loss = -5.8207, learner_queue_size = 17, _tick = 30701, _time = 1.654e+09, train_seconds = 1.4442e+04)
[2022-05-31 18:11:08,174][root][INFO] - Step 95255040 @ 6650.5 SPS. Inference batcher size: 54. Learner queue size: 24. Other stats: (step = 95255040, mean_episode_return = 116.61, mean_episode_step = 702.68, total_loss = 642.65, pg_loss = 454.51, baseline_loss = 193.8, entropy_loss = -5.6512, learner_queue_size = 24, _tick = 30714, _time = 1.654e+09, train_seconds = 1.4447e+04)
[2022-05-31 18:11:13,178][root][INFO] - Step 95288320 @ 6651.0 SPS. Inference batcher size: 50. Learner queue size: 4. Other stats: (step = 95288320, mean_episode_return = 291.11, mean_episode_step = 615.8, total_loss = -47.258, pg_loss = -105.09, baseline_loss = 63.687, entropy_loss = -5.8531, learner_queue_size = 18, _tick = 30726, _time = 1.654e+09, train_seconds = 1.4452e+04)
[2022-05-31 18:11:18,182][root][INFO] - Step 95321600 @ 6650.7 SPS. Inference batcher size: 76. Learner queue size: 31. Other stats: (step = 95321600, mean_episode_return = None, mean_episode_step = 566.09, total_loss = 145.89, pg_loss = 85.36, baseline_loss = 66.127, entropy_loss = -5.5967, learner_queue_size = 11, _tick = 30738, _time = 1.654e+09, train_seconds = 1.4457e+04)
[2022-05-31 18:11:23,186][root][INFO] - Step 95352320 @ 6139.0 SPS. Inference batcher size: 155. Learner queue size: 24. Other stats: (step = 95352320, mean_episode_return = 157.44, mean_episode_step = 748.08, total_loss = 207.15, pg_loss = 28.131, baseline_loss = 184.63, entropy_loss = -5.6063, learner_queue_size = 16, _tick = 30748, _time = 1.654e+09, train_seconds = 1.4462e+04)
[2022-05-31 18:11:28,192][root][INFO] - Step 95385600 @ 6647.9 SPS. Inference batcher size: 143. Learner queue size: 20. Other stats: (step = 95385600, mean_episode_return = 238.56, mean_episode_step = 543.34, total_loss = 200.94, pg_loss = 96.665, baseline_loss = 110.57, entropy_loss = -6.2929, learner_queue_size = 25, _tick = 30760, _time = 1.654e+09, train_seconds = 1.4467e+04)
[2022-05-31 18:11:33,198][root][INFO] - Step 95418880 @ 6648.2 SPS. Inference batcher size: 114. Learner queue size: 18. Other stats: (step = 95418880, mean_episode_return = 334.92, mean_episode_step = 624.27, total_loss = 202.49, pg_loss = 59.15, baseline_loss = 148.93, entropy_loss = -5.5921, learner_queue_size = 19, _tick = 30771, _time = 1.654e+09, train_seconds = 1.4472e+04)
[2022-05-31 18:11:38,204][root][INFO] - Step 95452160 @ 6647.5 SPS. Inference batcher size: 167. Learner queue size: 4. Other stats: (step = 95452160, mean_episode_return = 189.14, mean_episode_step = 593.88, total_loss = 104.82, pg_loss = -137.87, baseline_loss = 248.25, entropy_loss = -5.5674, learner_queue_size = 17, _tick = 30782, _time = 1.654e+09, train_seconds = 1.4477e+04)
[2022-05-31 18:11:43,210][root][INFO] - Step 95485440 @ 6648.1 SPS. Inference batcher size: 123. Learner queue size: 25. Other stats: (step = 95485440, mean_episode_return = 58.837, mean_episode_step = 763.97, total_loss = -177.58, pg_loss = -283.09, baseline_loss = 111.89, entropy_loss = -6.3787, learner_queue_size = 25, _tick = 30795, _time = 1.654e+09, train_seconds = 1.4482e+04)
[2022-05-31 18:11:48,217][root][INFO] - Step 95516160 @ 6136.1 SPS. Inference batcher size: 101. Learner queue size: 23. Other stats: (step = 95516160, mean_episode_return = 256.29, mean_episode_step = 743.56, total_loss = 78.468, pg_loss = -110.24, baseline_loss = 194.87, entropy_loss = -6.1585, learner_queue_size = 26, _tick = 30805, _time = 1.654e+09, train_seconds = 1.4487e+04)
[2022-05-31 18:11:53,223][root][INFO] - Step 95549440 @ 6648.0 SPS. Inference batcher size: 114. Learner queue size: 19. Other stats: (step = 95549440, mean_episode_return = None, mean_episode_step = 801.78, total_loss = -42.095, pg_loss = -85.102, baseline_loss = 49.456, entropy_loss = -6.4486, learner_queue_size = 20, _tick = 30816, _time = 1.654e+09, train_seconds = 1.4492e+04)
[2022-05-31 18:11:58,226][root][INFO] - Step 95582720 @ 6651.4 SPS. Inference batcher size: 15. Learner queue size: 15. Other stats: (step = 95582720, mean_episode_return = 136.06, mean_episode_step = 718.08, total_loss = 18.035, pg_loss = -57.977, baseline_loss = 82.126, entropy_loss = -6.1144, learner_queue_size = 11, _tick = 30829, _time = 1.654e+09, train_seconds = 1.4497e+04)
[2022-05-31 18:12:03,230][root][INFO] - Step 95616000 @ 6650.7 SPS. Inference batcher size: 116. Learner queue size: 28. Other stats: (step = 95616000, mean_episode_return = 297.36, mean_episode_step = 721.35, total_loss = 150.53, pg_loss = 25.293, baseline_loss = 131.16, entropy_loss = -5.9233, learner_queue_size = 21, _tick = 30841, _time = 1.654e+09, train_seconds = 1.4502e+04)
[2022-05-31 18:12:08,236][root][INFO] - Step 95646720 @ 6136.4 SPS. Inference batcher size: 80. Learner queue size: 21. Other stats: (step = 95646720, mean_episode_return = 183.17, mean_episode_step = 860.84, total_loss = 706.87, pg_loss = 454.0, baseline_loss = 258.7, entropy_loss = -5.8202, learner_queue_size = 16, _tick = 30851, _time = 1.654e+09, train_seconds = 1.4507e+04)
[2022-05-31 18:12:13,240][root][INFO] - Step 95680000 @ 6650.9 SPS. Inference batcher size: 110. Learner queue size: 17. Other stats: (step = 95680000, mean_episode_return = None, mean_episode_step = 781.44, total_loss = -19.608, pg_loss = -61.193, baseline_loss = 48.069, entropy_loss = -6.4845, learner_queue_size = 19, _tick = 30861, _time = 1.654e+09, train_seconds = 1.4512e+04)
[2022-05-31 18:12:18,246][root][INFO] - Step 95713280 @ 6648.4 SPS. Inference batcher size: 85. Learner queue size: 8. Other stats: (step = 95713280, mean_episode_return = 74.491, mean_episode_step = 767.87, total_loss = -286.26, pg_loss = -333.76, baseline_loss = 53.633, entropy_loss = -6.1374, learner_queue_size = 20, _tick = 30873, _time = 1.654e+09, train_seconds = 1.4517e+04)
[2022-05-31 18:12:23,250][root][INFO] - Step 95746560 @ 6650.6 SPS. Inference batcher size: 116. Learner queue size: 16. Other stats: (step = 95746560, mean_episode_return = 239.47, mean_episode_step = 737.88, total_loss = -71.067, pg_loss = -211.72, baseline_loss = 146.64, entropy_loss = -5.9919, learner_queue_size = 18, _tick = 30885, _time = 1.654e+09, train_seconds = 1.4522e+04)
[2022-05-31 18:12:28,256][root][INFO] - Step 95779840 @ 6648.0 SPS. Inference batcher size: 133. Learner queue size: 12. Other stats: (step = 95779840, mean_episode_return = 408.9, mean_episode_step = 542.67, total_loss = 47.145, pg_loss = -158.71, baseline_loss = 211.81, entropy_loss = -5.955, learner_queue_size = 15, _tick = 30897, _time = 1.654e+09, train_seconds = 1.4527e+04)
[2022-05-31 18:12:33,262][root][INFO] - Step 95813120 @ 6648.1 SPS. Inference batcher size: 151. Learner queue size: 15. Other stats: (step = 95813120, mean_episode_return = 55.761, mean_episode_step = 745.97, total_loss = 116.05, pg_loss = 38.716, baseline_loss = 83.523, entropy_loss = -6.1837, learner_queue_size = 28, _tick = 30910, _time = 1.654e+09, train_seconds = 1.4532e+04)
[2022-05-31 18:12:38,268][root][INFO] - Step 95846400 @ 6647.9 SPS. Inference batcher size: 3. Learner queue size: 7. Other stats: (step = 95846400, mean_episode_return = 278.78, mean_episode_step = 694.57, total_loss = 245.38, pg_loss = 29.95, baseline_loss = 221.39, entropy_loss = -5.9595, learner_queue_size = 19, _tick = 30920, _time = 1.654e+09, train_seconds = 1.4537e+04)
[2022-05-31 18:12:43,274][root][INFO] - Step 95879680 @ 6648.2 SPS. Inference batcher size: 102. Learner queue size: 28. Other stats: (step = 95879680, mean_episode_return = 352.98, mean_episode_step = 833.14, total_loss = 42.099, pg_loss = -37.586, baseline_loss = 85.695, entropy_loss = -6.011, learner_queue_size = 20, _tick = 30930, _time = 1.654e+09, train_seconds = 1.4542e+04)
[2022-05-31 18:12:48,278][root][INFO] - Step 95912960 @ 6650.6 SPS. Inference batcher size: 138. Learner queue size: 23. Other stats: (step = 95912960, mean_episode_return = 195.75, mean_episode_step = 888.17, total_loss = 427.95, pg_loss = 221.88, baseline_loss = 211.67, entropy_loss = -5.6021, learner_queue_size = 18, _tick = 30943, _time = 1.654e+09, train_seconds = 1.4547e+04)
[2022-05-31 18:12:53,284][root][INFO] - Step 95943680 @ 6136.5 SPS. Inference batcher size: 131. Learner queue size: 20. Other stats: (step = 95943680, mean_episode_return = 133.55, mean_episode_step = 678.25, total_loss = 91.66, pg_loss = 11.988, baseline_loss = 85.855, entropy_loss = -6.183, learner_queue_size = 12, _tick = 30953, _time = 1.654e+09, train_seconds = 1.4552e+04)
[2022-05-31 18:12:58,290][root][INFO] - Step 95976960 @ 6648.0 SPS. Inference batcher size: 149. Learner queue size: 25. Other stats: (step = 95976960, mean_episode_return = 326.45, mean_episode_step = 629.87, total_loss = 10.988, pg_loss = -98.153, baseline_loss = 115.06, entropy_loss = -5.9152, learner_queue_size = 23, _tick = 30966, _time = 1.654e+09, train_seconds = 1.4557e+04)
[2022-05-31 18:13:03,294][root][INFO] - Step 96010240 @ 6650.8 SPS. Inference batcher size: 112. Learner queue size: 9. Other stats: (step = 96010240, mean_episode_return = 406.67, mean_episode_step = 778.37, total_loss = 413.95, pg_loss = 275.59, baseline_loss = 144.39, entropy_loss = -6.0366, learner_queue_size = 28, _tick = 30978, _time = 1.654e+09, train_seconds = 1.4562e+04)
[2022-05-31 18:13:08,298][root][INFO] - Step 96043520 @ 6650.5 SPS. Inference batcher size: 29. Learner queue size: 10. Other stats: (step = 96043520, mean_episode_return = None, mean_episode_step = 891.94, total_loss = 368.14, pg_loss = 268.21, baseline_loss = 105.69, entropy_loss = -5.7636, learner_queue_size = 13, _tick = 30989, _time = 1.654e+09, train_seconds = 1.4567e+04)
[2022-05-31 18:13:13,302][root][INFO] - Step 96076800 @ 6651.0 SPS. Inference batcher size: 106. Learner queue size: 5. Other stats: (step = 96076800, mean_episode_return = 129.11, mean_episode_step = 517.63, total_loss = -137.08, pg_loss = -186.19, baseline_loss = 54.903, entropy_loss = -5.8004, learner_queue_size = 24, _tick = 31002, _time = 1.654e+09, train_seconds = 1.4572e+04)
[2022-05-31 18:13:18,309][root][INFO] - Step 96110080 @ 6646.1 SPS. Inference batcher size: 54. Learner queue size: 2. Other stats: (step = 96110080, mean_episode_return = 534.92, mean_episode_step = 591.52, total_loss = -63.276, pg_loss = -129.15, baseline_loss = 71.847, entropy_loss = -5.9747, learner_queue_size = 20, _tick = 31014, _time = 1.654e+09, train_seconds = 1.4577e+04)
[2022-05-31 18:13:23,314][root][INFO] - Step 96143360 @ 6649.9 SPS. Inference batcher size: 123. Learner queue size: 24. Other stats: (step = 96143360, mean_episode_return = 159.28, mean_episode_step = 671.95, total_loss = 278.94, pg_loss = 118.33, baseline_loss = 166.59, entropy_loss = -5.9757, learner_queue_size = 17, _tick = 31026, _time = 1.654e+09, train_seconds = 1.4582e+04)
[2022-05-31 18:13:28,320][root][INFO] - Step 96174080 @ 6136.5 SPS. Inference batcher size: 132. Learner queue size: 22. Other stats: (step = 96174080, mean_episode_return = 195.86, mean_episode_step = 591.68, total_loss = 100.39, pg_loss = 3.5473, baseline_loss = 103.18, entropy_loss = -6.3415, learner_queue_size = 21, _tick = 31036, _time = 1.654e+09, train_seconds = 1.4587e+04)
[2022-05-31 18:13:33,326][root][INFO] - Step 96207360 @ 6648.1 SPS. Inference batcher size: 96. Learner queue size: 15. Other stats: (step = 96207360, mean_episode_return = 393.69, mean_episode_step = 798.05, total_loss = 144.8, pg_loss = -35.119, baseline_loss = 186.15, entropy_loss = -6.2269, learner_queue_size = 21, _tick = 31047, _time = 1.654e+09, train_seconds = 1.4592e+04)
[2022-05-31 18:13:38,330][root][INFO] - Step 96240640 @ 6650.8 SPS. Inference batcher size: 134. Learner queue size: 0. Other stats: (step = 96240640, mean_episode_return = 154.82, mean_episode_step = 673.79, total_loss = 12.41, pg_loss = -53.869, baseline_loss = 72.568, entropy_loss = -6.289, learner_queue_size = 16, _tick = 31059, _time = 1.654e+09, train_seconds = 1.4597e+04)
[2022-05-31 18:13:43,334][root][INFO] - Step 96273920 @ 6650.7 SPS. Inference batcher size: 138. Learner queue size: 4. Other stats: (step = 96273920, mean_episode_return = 429.84, mean_episode_step = 547.19, total_loss = -26.194, pg_loss = -123.01, baseline_loss = 102.68, entropy_loss = -5.8561, learner_queue_size = 16, _tick = 31071, _time = 1.654e+09, train_seconds = 1.4602e+04)
[2022-05-31 18:13:48,338][root][INFO] - Step 96307200 @ 6650.6 SPS. Inference batcher size: 77. Learner queue size: 31. Other stats: (step = 96307200, mean_episode_return = 27.41, mean_episode_step = 946.08, total_loss = -49.57, pg_loss = -78.256, baseline_loss = 34.957, entropy_loss = -6.2711, learner_queue_size = 14, _tick = 31083, _time = 1.654e+09, train_seconds = 1.4607e+04)
[2022-05-31 18:13:53,342][root][INFO] - Step 96340480 @ 6650.6 SPS. Inference batcher size: 101. Learner queue size: 26. Other stats: (step = 96340480, mean_episode_return = 294.26, mean_episode_step = 496.15, total_loss = 0.98909, pg_loss = -77.683, baseline_loss = 84.729, entropy_loss = -6.0563, learner_queue_size = 16, _tick = 31095, _time = 1.654e+09, train_seconds = 1.4612e+04)
[2022-05-31 18:13:58,346][root][INFO] - Step 96373760 @ 6650.8 SPS. Inference batcher size: 51. Learner queue size: 17. Other stats: (step = 96373760, mean_episode_return = 214.46, mean_episode_step = 624.91, total_loss = -134.79, pg_loss = -157.89, baseline_loss = 29.459, entropy_loss = -6.3503, learner_queue_size = 14, _tick = 31108, _time = 1.654e+09, train_seconds = 1.4617e+04)
[2022-05-31 18:14:03,347][root][INFO] - Step 96404480 @ 6142.4 SPS. Inference batcher size: 118. Learner queue size: 20. Other stats: (step = 96404480, mean_episode_return = 108.18, mean_episode_step = 710.04, total_loss = 497.02, pg_loss = 302.44, baseline_loss = 200.73, entropy_loss = -6.1406, learner_queue_size = 15, _tick = 31119, _time = 1.654e+09, train_seconds = 1.4622e+04)
[2022-05-31 18:14:08,349][root][INFO] - Step 96437760 @ 6653.1 SPS. Inference batcher size: 138. Learner queue size: 15. Other stats: (step = 96437760, mean_episode_return = 262.33, mean_episode_step = 757.32, total_loss = -203.08, pg_loss = -240.39, baseline_loss = 43.66, entropy_loss = -6.3555, learner_queue_size = 19, _tick = 31132, _time = 1.654e+09, train_seconds = 1.4627e+04)
[2022-05-31 18:14:13,356][root][INFO] - Step 96473600 @ 7159.3 SPS. Inference batcher size: 68. Learner queue size: 18. Other stats: (step = 96473600, mean_episode_return = None, mean_episode_step = 810.78, total_loss = -102.15, pg_loss = -110.08, baseline_loss = 14.849, entropy_loss = -6.912, learner_queue_size = 18, _tick = 31141, _time = 1.654e+09, train_seconds = 1.4632e+04)
[2022-05-31 18:14:18,362][root][INFO] - Step 96504320 @ 6136.5 SPS. Inference batcher size: 35. Learner queue size: 19. Other stats: (step = 96504320, mean_episode_return = 220.74, mean_episode_step = 658.23, total_loss = 134.28, pg_loss = 83.327, baseline_loss = 57.453, entropy_loss = -6.5003, learner_queue_size = 17, _tick = 31153, _time = 1.654e+09, train_seconds = 1.4637e+04)
[2022-05-31 18:14:23,366][root][INFO] - Step 96537600 @ 6650.1 SPS. Inference batcher size: 148. Learner queue size: 18. Other stats: (step = 96537600, mean_episode_return = 220.1, mean_episode_step = 832.99, total_loss = 741.66, pg_loss = 329.92, baseline_loss = 417.65, entropy_loss = -5.9032, learner_queue_size = 22, _tick = 31166, _time = 1.654e+09, train_seconds = 1.4642e+04)
[2022-05-31 18:14:28,372][root][INFO] - Step 96570880 @ 6647.9 SPS. Inference batcher size: 110. Learner queue size: 16. Other stats: (step = 96570880, mean_episode_return = None, mean_episode_step = 683.75, total_loss = -62.951, pg_loss = -155.86, baseline_loss = 98.951, entropy_loss = -6.0433, learner_queue_size = 24, _tick = 31177, _time = 1.654e+09, train_seconds = 1.4647e+04)
[2022-05-31 18:14:33,378][root][INFO] - Step 96604160 @ 6648.0 SPS. Inference batcher size: 154. Learner queue size: 12. Other stats: (step = 96604160, mean_episode_return = 432.96, mean_episode_step = 671.86, total_loss = 538.91, pg_loss = 143.41, baseline_loss = 401.46, entropy_loss = -5.9601, learner_queue_size = 18, _tick = 31190, _time = 1.654e+09, train_seconds = 1.4652e+04)
[2022-05-31 18:14:38,382][root][INFO] - Step 96637440 @ 6650.8 SPS. Inference batcher size: 61. Learner queue size: 7. Other stats: (step = 96637440, mean_episode_return = 191.37, mean_episode_step = 553.44, total_loss = 11.063, pg_loss = -156.4, baseline_loss = 173.3, entropy_loss = -5.8351, learner_queue_size = 23, _tick = 31203, _time = 1.654e+09, train_seconds = 1.4657e+04)
[2022-05-31 18:14:43,386][root][INFO] - Step 96670720 @ 6650.7 SPS. Inference batcher size: 42. Learner queue size: 0. Other stats: (step = 96670720, mean_episode_return = 191.25, mean_episode_step = 816.99, total_loss = 306.47, pg_loss = 147.04, baseline_loss = 165.21, entropy_loss = -5.7762, learner_queue_size = 20, _tick = 31215, _time = 1.654e+09, train_seconds = 1.4662e+04)
[2022-05-31 18:14:48,390][root][INFO] - Step 96704000 @ 6650.7 SPS. Inference batcher size: 225. Learner queue size: 3. Other stats: (step = 96704000, mean_episode_return = None, mean_episode_step = 820.28, total_loss = -125.99, pg_loss = -150.04, baseline_loss = 30.129, entropy_loss = -6.0797, learner_queue_size = 24, _tick = 31226, _time = 1.654e+09, train_seconds = 1.4667e+04)
[2022-05-31 18:14:53,394][root][INFO] - Step 96737280 @ 6650.6 SPS. Inference batcher size: 99. Learner queue size: 29. Other stats: (step = 96737280, mean_episode_return = 359.99, mean_episode_step = 733.52, total_loss = -271.11, pg_loss = -315.02, baseline_loss = 50.224, entropy_loss = -6.3179, learner_queue_size = 26, _tick = 31237, _time = 1.654e+09, train_seconds = 1.4672e+04)
[2022-05-31 18:14:58,398][root][INFO] - Step 96770560 @ 6650.8 SPS. Inference batcher size: 70. Learner queue size: 31. Other stats: (step = 96770560, mean_episode_return = 82.02, mean_episode_step = 657.59, total_loss = 425.84, pg_loss = 259.06, baseline_loss = 172.81, entropy_loss = -6.0339, learner_queue_size = 23, _tick = 31249, _time = 1.654e+09, train_seconds = 1.4677e+04)
[2022-05-31 18:15:03,402][root][INFO] - Step 96803840 @ 6650.5 SPS. Inference batcher size: 127. Learner queue size: 22. Other stats: (step = 96803840, mean_episode_return = 551.54, mean_episode_step = 603.87, total_loss = 299.85, pg_loss = 179.59, baseline_loss = 126.09, entropy_loss = -5.8281, learner_queue_size = 12, _tick = 31261, _time = 1.654e+09, train_seconds = 1.4682e+04)
[2022-05-31 18:15:08,406][root][INFO] - Step 96834560 @ 6139.2 SPS. Inference batcher size: 117. Learner queue size: 20. Other stats: (step = 96834560, mean_episode_return = 165.15, mean_episode_step = 654.69, total_loss = 90.226, pg_loss = -116.84, baseline_loss = 212.92, entropy_loss = -5.8564, learner_queue_size = 26, _tick = 31273, _time = 1.654e+09, train_seconds = 1.4687e+04)
[2022-05-31 18:15:13,413][root][INFO] - Step 96867840 @ 6647.3 SPS. Inference batcher size: 58. Learner queue size: 11. Other stats: (step = 96867840, mean_episode_return = None, mean_episode_step = 878.5, total_loss = 1172.1, pg_loss = 793.73, baseline_loss = 384.58, entropy_loss = -6.233, learner_queue_size = 20, _tick = 31284, _time = 1.654e+09, train_seconds = 1.4692e+04)
[2022-05-31 18:15:18,419][root][INFO] - Step 96901120 @ 6648.0 SPS. Inference batcher size: 107. Learner queue size: 11. Other stats: (step = 96901120, mean_episode_return = 107.24, mean_episode_step = 778.87, total_loss = -205.95, pg_loss = -223.61, baseline_loss = 23.945, entropy_loss = -6.2867, learner_queue_size = 25, _tick = 31296, _time = 1.654e+09, train_seconds = 1.4697e+04)
[2022-05-31 18:15:23,422][root][INFO] - Step 96934400 @ 6651.4 SPS. Inference batcher size: 109. Learner queue size: 24. Other stats: (step = 96934400, mean_episode_return = 205.74, mean_episode_step = 832.3, total_loss = -11.582, pg_loss = -143.5, baseline_loss = 138.06, entropy_loss = -6.1407, learner_queue_size = 18, _tick = 31309, _time = 1.654e+09, train_seconds = 1.4702e+04)
[2022-05-31 18:15:28,426][root][INFO] - Step 96967680 @ 6650.8 SPS. Inference batcher size: 92. Learner queue size: 12. Other stats: (step = 96967680, mean_episode_return = 257.38, mean_episode_step = 702.77, total_loss = 52.076, pg_loss = -428.03, baseline_loss = 486.07, entropy_loss = -5.9679, learner_queue_size = 12, _tick = 31321, _time = 1.654e+09, train_seconds = 1.4707e+04)
[2022-05-31 18:15:33,432][root][INFO] - Step 97000960 @ 6648.3 SPS. Inference batcher size: 182. Learner queue size: 12. Other stats: (step = 97000960, mean_episode_return = 109.35, mean_episode_step = 764.5, total_loss = 27.165, pg_loss = -93.158, baseline_loss = 126.81, entropy_loss = -6.4872, learner_queue_size = 29, _tick = 31333, _time = 1.654e+09, train_seconds = 1.4712e+04)
[2022-05-31 18:15:38,438][root][INFO] - Step 97031680 @ 6136.5 SPS. Inference batcher size: 142. Learner queue size: 22. Other stats: (step = 97031680, mean_episode_return = 696.98, mean_episode_step = 613.08, total_loss = -182.65, pg_loss = -218.32, baseline_loss = 41.553, entropy_loss = -5.8876, learner_queue_size = 12, _tick = 31345, _time = 1.654e+09, train_seconds = 1.4717e+04)
[2022-05-31 18:15:43,442][root][INFO] - Step 97067520 @ 7162.0 SPS. Inference batcher size: 107. Learner queue size: 29. Other stats: (step = 97067520, mean_episode_return = None, mean_episode_step = 586.22, total_loss = 47.209, pg_loss = -18.262, baseline_loss = 71.735, entropy_loss = -6.263, learner_queue_size = 18, _tick = 31358, _time = 1.654e+09, train_seconds = 1.4722e+04)
[2022-05-31 18:15:48,446][root][INFO] - Step 97098240 @ 6139.2 SPS. Inference batcher size: 73. Learner queue size: 20. Other stats: (step = 97098240, mean_episode_return = 420.08, mean_episode_step = 683.59, total_loss = -113.05, pg_loss = -176.8, baseline_loss = 70.213, entropy_loss = -6.4622, learner_queue_size = 25, _tick = 31369, _time = 1.654e+09, train_seconds = 1.4727e+04)
[2022-05-31 18:15:53,452][root][INFO] - Step 97131520 @ 6647.7 SPS. Inference batcher size: 194. Learner queue size: 14. Other stats: (step = 97131520, mean_episode_return = 498.13, mean_episode_step = 581.13, total_loss = 359.88, pg_loss = 127.96, baseline_loss = 237.48, entropy_loss = -5.5626, learner_queue_size = 15, _tick = 31381, _time = 1.654e+09, train_seconds = 1.4732e+04)
[2022-05-31 18:15:58,458][root][INFO] - Step 97164800 @ 6648.0 SPS. Inference batcher size: 42. Learner queue size: 14. Other stats: (step = 97164800, mean_episode_return = 194.72, mean_episode_step = 699.76, total_loss = 275.87, pg_loss = 157.98, baseline_loss = 123.44, entropy_loss = -5.5422, learner_queue_size = 19, _tick = 31394, _time = 1.654e+09, train_seconds = 1.4737e+04)
[2022-05-31 18:16:03,464][root][INFO] - Step 97198080 @ 6647.9 SPS. Inference batcher size: 80. Learner queue size: 2. Other stats: (step = 97198080, mean_episode_return = 115.16, mean_episode_step = 621.32, total_loss = 119.5, pg_loss = -9.7682, baseline_loss = 134.74, entropy_loss = -5.4707, learner_queue_size = 22, _tick = 31405, _time = 1.654e+09, train_seconds = 1.4742e+04)
[2022-05-31 18:16:08,470][root][INFO] - Step 97231360 @ 6648.3 SPS. Inference batcher size: 42. Learner queue size: 5. Other stats: (step = 97231360, mean_episode_return = 195.73, mean_episode_step = 568.07, total_loss = -38.436, pg_loss = -129.36, baseline_loss = 96.554, entropy_loss = -5.633, learner_queue_size = 21, _tick = 31416, _time = 1.654e+09, train_seconds = 1.4747e+04)
[2022-05-31 18:16:13,478][root][INFO] - Step 97264640 @ 6645.2 SPS. Inference batcher size: 169. Learner queue size: 6. Other stats: (step = 97264640, mean_episode_return = 100.13, mean_episode_step = 604.06, total_loss = 356.06, pg_loss = 103.05, baseline_loss = 259.28, entropy_loss = -6.2741, learner_queue_size = 23, _tick = 31429, _time = 1.654e+09, train_seconds = 1.4752e+04)
[2022-05-31 18:16:18,482][root][INFO] - Step 97297920 @ 6651.1 SPS. Inference batcher size: 132. Learner queue size: 17. Other stats: (step = 97297920, mean_episode_return = 203.64, mean_episode_step = 610.83, total_loss = 60.704, pg_loss = -42.337, baseline_loss = 108.85, entropy_loss = -5.8098, learner_queue_size = 9, _tick = 31442, _time = 1.654e+09, train_seconds = 1.4757e+04)
[2022-05-31 18:16:23,486][root][INFO] - Step 97331200 @ 6650.7 SPS. Inference batcher size: 88. Learner queue size: 20. Other stats: (step = 97331200, mean_episode_return = 241.75, mean_episode_step = 701.17, total_loss = 31.958, pg_loss = -90.135, baseline_loss = 127.93, entropy_loss = -5.84, learner_queue_size = 18, _tick = 31455, _time = 1.654e+09, train_seconds = 1.4762e+04)
[2022-05-31 18:16:28,490][root][INFO] - Step 97361920 @ 6139.0 SPS. Inference batcher size: 79. Learner queue size: 21. Other stats: (step = 97361920, mean_episode_return = 218.24, mean_episode_step = 626.52, total_loss = -23.361, pg_loss = -96.838, baseline_loss = 79.657, entropy_loss = -6.1798, learner_queue_size = 9, _tick = 31466, _time = 1.654e+09, train_seconds = 1.4767e+04)
[2022-05-31 18:16:33,496][root][INFO] - Step 97395200 @ 6647.9 SPS. Inference batcher size: 99. Learner queue size: 12. Other stats: (step = 97395200, mean_episode_return = 236.98, mean_episode_step = 629.95, total_loss = 619.44, pg_loss = 274.22, baseline_loss = 350.89, entropy_loss = -5.6717, learner_queue_size = 23, _tick = 31478, _time = 1.654e+09, train_seconds = 1.4772e+04)
[2022-05-31 18:16:38,502][root][INFO] - Step 97428480 @ 6648.0 SPS. Inference batcher size: 87. Learner queue size: 15. Other stats: (step = 97428480, mean_episode_return = 185.8, mean_episode_step = 596.42, total_loss = 461.94, pg_loss = 310.61, baseline_loss = 157.12, entropy_loss = -5.7884, learner_queue_size = 23, _tick = 31491, _time = 1.654e+09, train_seconds = 1.4777e+04)
[2022-05-31 18:16:43,506][root][INFO] - Step 97461760 @ 6650.9 SPS. Inference batcher size: 136. Learner queue size: 11. Other stats: (step = 97461760, mean_episode_return = 107.73, mean_episode_step = 529.91, total_loss = 550.9, pg_loss = 402.08, baseline_loss = 154.67, entropy_loss = -5.8469, learner_queue_size = 13, _tick = 31504, _time = 1.654e+09, train_seconds = 1.4782e+04)
[2022-05-31 18:16:48,510][root][INFO] - Step 97495040 @ 6650.7 SPS. Inference batcher size: 152. Learner queue size: 15. Other stats: (step = 97495040, mean_episode_return = 180.77, mean_episode_step = 643.3, total_loss = 57.344, pg_loss = -91.932, baseline_loss = 155.25, entropy_loss = -5.9711, learner_queue_size = 18, _tick = 31514, _time = 1.654e+09, train_seconds = 1.4787e+04)
[2022-05-31 18:16:53,514][root][INFO] - Step 97528320 @ 6650.6 SPS. Inference batcher size: 126. Learner queue size: 12. Other stats: (step = 97528320, mean_episode_return = 147.86, mean_episode_step = 673.58, total_loss = 547.49, pg_loss = 440.18, baseline_loss = 113.67, entropy_loss = -6.3611, learner_queue_size = 20, _tick = 31527, _time = 1.654e+09, train_seconds = 1.4792e+04)
[2022-05-31 18:16:58,518][root][INFO] - Step 97561600 @ 6650.8 SPS. Inference batcher size: 129. Learner queue size: 5. Other stats: (step = 97561600, mean_episode_return = 521.22, mean_episode_step = 573.14, total_loss = -77.36, pg_loss = -139.93, baseline_loss = 68.346, entropy_loss = -5.7771, learner_queue_size = 16, _tick = 31538, _time = 1.654e+09, train_seconds = 1.4797e+04)
[2022-05-31 18:17:03,522][root][INFO] - Step 97594880 @ 6650.7 SPS. Inference batcher size: 172. Learner queue size: 8. Other stats: (step = 97594880, mean_episode_return = 236.86, mean_episode_step = 654.25, total_loss = 452.71, pg_loss = 309.39, baseline_loss = 149.32, entropy_loss = -6.0048, learner_queue_size = 15, _tick = 31548, _time = 1.654e+09, train_seconds = 1.4802e+04)
[2022-05-31 18:17:08,526][root][INFO] - Step 97628160 @ 6650.6 SPS. Inference batcher size: 80. Learner queue size: 28. Other stats: (step = 97628160, mean_episode_return = 76.004, mean_episode_step = 729.9, total_loss = 109.07, pg_loss = 61.651, baseline_loss = 53.642, entropy_loss = -6.2188, learner_queue_size = 20, _tick = 31560, _time = 1.654e+09, train_seconds = 1.4807e+04)
[2022-05-31 18:17:13,532][root][INFO] - Step 97661440 @ 6647.7 SPS. Inference batcher size: 152. Learner queue size: 28. Other stats: (step = 97661440, mean_episode_return = 184.74, mean_episode_step = 651.22, total_loss = 218.6, pg_loss = -9.4734, baseline_loss = 234.15, entropy_loss = -6.0756, learner_queue_size = 20, _tick = 31572, _time = 1.654e+09, train_seconds = 1.4812e+04)
[2022-05-31 18:17:18,539][root][INFO] - Step 97692160 @ 6136.1 SPS. Inference batcher size: 133. Learner queue size: 22. Other stats: (step = 97692160, mean_episode_return = 468.87, mean_episode_step = 712.88, total_loss = 544.02, pg_loss = 269.85, baseline_loss = 280.01, entropy_loss = -5.8372, learner_queue_size = 27, _tick = 31584, _time = 1.654e+09, train_seconds = 1.4817e+04)
[2022-05-31 18:17:23,546][root][INFO] - Step 97725440 @ 6646.3 SPS. Inference batcher size: 48. Learner queue size: 7. Other stats: (step = 97725440, mean_episode_return = None, mean_episode_step = 722.34, total_loss = -115.01, pg_loss = -140.02, baseline_loss = 31.126, entropy_loss = -6.1156, learner_queue_size = 16, _tick = 31596, _time = 1.654e+09, train_seconds = 1.4822e+04)
[2022-05-31 18:17:28,550][root][INFO] - Step 97758720 @ 6650.8 SPS. Inference batcher size: 174. Learner queue size: 17. Other stats: (step = 97758720, mean_episode_return = 370.31, mean_episode_step = 576.44, total_loss = -111.74, pg_loss = -261.18, baseline_loss = 155.46, entropy_loss = -6.0244, learner_queue_size = 21, _tick = 31609, _time = 1.654e+09, train_seconds = 1.4827e+04)
[2022-05-31 18:17:33,556][root][INFO] - Step 97792000 @ 6647.8 SPS. Inference batcher size: 106. Learner queue size: 6. Other stats: (step = 97792000, mean_episode_return = 174.0, mean_episode_step = 632.43, total_loss = -49.791, pg_loss = -208.88, baseline_loss = 165.26, entropy_loss = -6.1698, learner_queue_size = 15, _tick = 31620, _time = 1.654e+09, train_seconds = 1.4832e+04)
[2022-05-31 18:17:38,562][root][INFO] - Step 97825280 @ 6648.2 SPS. Inference batcher size: 121. Learner queue size: 2. Other stats: (step = 97825280, mean_episode_return = 103.09, mean_episode_step = 596.88, total_loss = -114.57, pg_loss = -171.78, baseline_loss = 63.299, entropy_loss = -6.085, learner_queue_size = 22, _tick = 31633, _time = 1.654e+09, train_seconds = 1.4837e+04)
[2022-05-31 18:17:43,566][root][INFO] - Step 97858560 @ 6650.6 SPS. Inference batcher size: 56. Learner queue size: 1. Other stats: (step = 97858560, mean_episode_return = None, mean_episode_step = 694.38, total_loss = 2058.0, pg_loss = 1186.7, baseline_loss = 878.18, entropy_loss = -6.9258, learner_queue_size = 16, _tick = 31643, _time = 1.654e+09, train_seconds = 1.4842e+04)
[2022-05-31 18:17:48,570][root][INFO] - Step 97891840 @ 6650.7 SPS. Inference batcher size: 37. Learner queue size: 15. Other stats: (step = 97891840, mean_episode_return = None, mean_episode_step = 834.78, total_loss = 273.32, pg_loss = 182.02, baseline_loss = 97.762, entropy_loss = -6.4568, learner_queue_size = 7, _tick = 31655, _time = 1.654e+09, train_seconds = 1.4847e+04)
[2022-05-31 18:17:53,575][root][INFO] - Step 97925120 @ 6648.9 SPS. Inference batcher size: 53. Learner queue size: 11. Other stats: (step = 97925120, mean_episode_return = 317.2, mean_episode_step = 651.31, total_loss = 257.75, pg_loss = 145.7, baseline_loss = 118.51, entropy_loss = -6.4598, learner_queue_size = 11, _tick = 31666, _time = 1.654e+09, train_seconds = 1.4852e+04)
[2022-05-31 18:17:58,582][root][INFO] - Step 97955840 @ 6136.2 SPS. Inference batcher size: 108. Learner queue size: 16. Other stats: (step = 97955840, mean_episode_return = None, mean_episode_step = 1042.6, total_loss = 167.5, pg_loss = 104.4, baseline_loss = 70.025, entropy_loss = -6.9245, learner_queue_size = 26, _tick = 31676, _time = 1.654e+09, train_seconds = 1.4857e+04)
[2022-05-31 18:18:03,586][root][INFO] - Step 97989120 @ 6650.3 SPS. Inference batcher size: 88. Learner queue size: 19. Other stats: (step = 97989120, mean_episode_return = 242.46, mean_episode_step = 751.17, total_loss = -193.03, pg_loss = -421.04, baseline_loss = 234.31, entropy_loss = -6.3007, learner_queue_size = 22, _tick = 31686, _time = 1.654e+09, train_seconds = 1.4862e+04)
[2022-05-31 18:18:08,590][root][INFO] - Step 98022400 @ 6650.7 SPS. Inference batcher size: 87. Learner queue size: 12. Other stats: (step = 98022400, mean_episode_return = 212.02, mean_episode_step = 677.32, total_loss = 146.52, pg_loss = 31.518, baseline_loss = 121.31, entropy_loss = -6.3082, learner_queue_size = 22, _tick = 31697, _time = 1.654e+09, train_seconds = 1.4867e+04)
[2022-05-31 18:18:13,594][root][INFO] - Step 98055680 @ 6650.7 SPS. Inference batcher size: 89. Learner queue size: 2. Other stats: (step = 98055680, mean_episode_return = 119.05, mean_episode_step = 730.9, total_loss = -30.971, pg_loss = -71.464, baseline_loss = 47.187, entropy_loss = -6.6944, learner_queue_size = 19, _tick = 31710, _time = 1.654e+09, train_seconds = 1.4872e+04)
[2022-05-31 18:18:18,598][root][INFO] - Step 98088960 @ 6650.7 SPS. Inference batcher size: 70. Learner queue size: 26. Other stats: (step = 98088960, mean_episode_return = 190.7, mean_episode_step = 627.34, total_loss = 61.685, pg_loss = -112.68, baseline_loss = 180.92, entropy_loss = -6.5492, learner_queue_size = 18, _tick = 31722, _time = 1.654e+09, train_seconds = 1.4877e+04)
[2022-05-31 18:18:23,604][root][INFO] - Step 98119680 @ 6136.5 SPS. Inference batcher size: 144. Learner queue size: 25. Other stats: (step = 98119680, mean_episode_return = 389.96, mean_episode_step = 888.21, total_loss = -124.94, pg_loss = -215.88, baseline_loss = 97.552, entropy_loss = -6.6078, learner_queue_size = 20, _tick = 31733, _time = 1.654e+09, train_seconds = 1.4882e+04)
[2022-05-31 18:18:28,610][root][INFO] - Step 98152960 @ 6648.2 SPS. Inference batcher size: 59. Learner queue size: 11. Other stats: (step = 98152960, mean_episode_return = 120.37, mean_episode_step = 724.9, total_loss = -31.831, pg_loss = -57.956, baseline_loss = 32.421, entropy_loss = -6.296, learner_queue_size = 26, _tick = 31746, _time = 1.654e+09, train_seconds = 1.4887e+04)
[2022-05-31 18:18:33,614][root][INFO] - Step 98186240 @ 6650.6 SPS. Inference batcher size: 85. Learner queue size: 12. Other stats: (step = 98186240, mean_episode_return = 192.92, mean_episode_step = 744.51, total_loss = -52.22, pg_loss = -142.83, baseline_loss = 96.753, entropy_loss = -6.1427, learner_queue_size = 19, _tick = 31757, _time = 1.654e+09, train_seconds = 1.4892e+04)
[2022-05-31 18:18:38,618][root][INFO] - Step 98219520 @ 6650.7 SPS. Inference batcher size: 70. Learner queue size: 8. Other stats: (step = 98219520, mean_episode_return = 88.525, mean_episode_step = 697.8, total_loss = 138.67, pg_loss = 82.902, baseline_loss = 62.258, entropy_loss = -6.4877, learner_queue_size = 14, _tick = 31767, _time = 1.654e+09, train_seconds = 1.4897e+04)
[2022-05-31 18:18:43,624][root][INFO] - Step 98252800 @ 6647.9 SPS. Inference batcher size: 167. Learner queue size: 7. Other stats: (step = 98252800, mean_episode_return = 202.41, mean_episode_step = 595.51, total_loss = 219.8, pg_loss = 83.994, baseline_loss = 141.84, entropy_loss = -6.0337, learner_queue_size = 22, _tick = 31778, _time = 1.654e+09, train_seconds = 1.4902e+04)
[2022-05-31 18:18:48,630][root][INFO] - Step 98286080 @ 6648.1 SPS. Inference batcher size: 99. Learner queue size: 1. Other stats: (step = 98286080, mean_episode_return = 124.12, mean_episode_step = 592.82, total_loss = -70.356, pg_loss = -121.57, baseline_loss = 57.656, entropy_loss = -6.4419, learner_queue_size = 17, _tick = 31789, _time = 1.654e+09, train_seconds = 1.4907e+04)
[2022-05-31 18:18:53,634][root][INFO] - Step 98319360 @ 6650.7 SPS. Inference batcher size: 63. Learner queue size: 27. Other stats: (step = 98319360, mean_episode_return = 189.28, mean_episode_step = 742.92, total_loss = 137.26, pg_loss = 39.359, baseline_loss = 104.58, entropy_loss = -6.6789, learner_queue_size = 18, _tick = 31802, _time = 1.654e+09, train_seconds = 1.4912e+04)
[2022-05-31 18:18:58,641][root][INFO] - Step 98352640 @ 6646.8 SPS. Inference batcher size: 52. Learner queue size: 22. Other stats: (step = 98352640, mean_episode_return = 280.31, mean_episode_step = 763.01, total_loss = -38.967, pg_loss = -82.584, baseline_loss = 49.612, entropy_loss = -5.9948, learner_queue_size = 17, _tick = 31814, _time = 1.654e+09, train_seconds = 1.4917e+04)
[2022-05-31 18:19:03,648][root][INFO] - Step 98383360 @ 6135.3 SPS. Inference batcher size: 158. Learner queue size: 18. Other stats: (step = 98383360, mean_episode_return = 136.65, mean_episode_step = 713.4, total_loss = 206.98, pg_loss = 109.03, baseline_loss = 104.07, entropy_loss = -6.1116, learner_queue_size = 19, _tick = 31826, _time = 1.654e+09, train_seconds = 1.4922e+04)
[2022-05-31 18:19:08,654][root][INFO] - Step 98416640 @ 6648.1 SPS. Inference batcher size: 0. Learner queue size: 8. Other stats: (step = 98416640, mean_episode_return = 346.66, mean_episode_step = 879.04, total_loss = -184.56, pg_loss = -230.59, baseline_loss = 52.113, entropy_loss = -6.0825, learner_queue_size = 20, _tick = 31837, _time = 1.654e+09, train_seconds = 1.4927e+04)
[2022-05-31 18:19:13,660][root][INFO] - Step 98449920 @ 6647.4 SPS. Inference batcher size: 136. Learner queue size: 8. Other stats: (step = 98449920, mean_episode_return = 367.93, mean_episode_step = 621.76, total_loss = 509.1, pg_loss = 97.861, baseline_loss = 416.78, entropy_loss = -5.5423, learner_queue_size = 30, _tick = 31849, _time = 1.654e+09, train_seconds = 1.4932e+04)
[2022-05-31 18:19:18,666][root][INFO] - Step 98483200 @ 6648.6 SPS. Inference batcher size: 135. Learner queue size: 4. Other stats: (step = 98483200, mean_episode_return = 117.46, mean_episode_step = 807.63, total_loss = 192.99, pg_loss = 11.971, baseline_loss = 187.65, entropy_loss = -6.6277, learner_queue_size = 28, _tick = 31861, _time = 1.654e+09, train_seconds = 1.4937e+04)
[2022-05-31 18:19:23,670][root][INFO] - Step 98516480 @ 6650.8 SPS. Inference batcher size: 88. Learner queue size: 4. Other stats: (step = 98516480, mean_episode_return = None, mean_episode_step = 742.97, total_loss = -37.314, pg_loss = -86.839, baseline_loss = 56.276, entropy_loss = -6.7516, learner_queue_size = 15, _tick = 31872, _time = 1.654e+09, train_seconds = 1.4942e+04)
[2022-05-31 18:19:28,674][root][INFO] - Step 98549760 @ 6650.8 SPS. Inference batcher size: 1. Learner queue size: 25. Other stats: (step = 98549760, mean_episode_return = 848.99, mean_episode_step = 583.47, total_loss = -13.613, pg_loss = -120.93, baseline_loss = 113.46, entropy_loss = -6.143, learner_queue_size = 15, _tick = 31884, _time = 1.654e+09, train_seconds = 1.4947e+04)
[2022-05-31 18:19:33,678][root][INFO] - Step 98580480 @ 6139.0 SPS. Inference batcher size: 135. Learner queue size: 23. Other stats: (step = 98580480, mean_episode_return = 166.04, mean_episode_step = 729.62, total_loss = 448.96, pg_loss = 287.89, baseline_loss = 166.8, entropy_loss = -5.7261, learner_queue_size = 16, _tick = 31895, _time = 1.654e+09, train_seconds = 1.4952e+04)
[2022-05-31 18:19:38,684][root][INFO] - Step 98613760 @ 6647.9 SPS. Inference batcher size: 120. Learner queue size: 9. Other stats: (step = 98613760, mean_episode_return = 147.56, mean_episode_step = 532.69, total_loss = 89.824, pg_loss = -44.863, baseline_loss = 140.26, entropy_loss = -5.5776, learner_queue_size = 22, _tick = 31907, _time = 1.654e+09, train_seconds = 1.4957e+04)
[2022-05-31 18:19:43,690][root][INFO] - Step 98647040 @ 6648.1 SPS. Inference batcher size: 47. Learner queue size: 19. Other stats: (step = 98647040, mean_episode_return = 136.61, mean_episode_step = 537.51, total_loss = 307.48, pg_loss = 155.07, baseline_loss = 158.25, entropy_loss = -5.836, learner_queue_size = 24, _tick = 31920, _time = 1.654e+09, train_seconds = 1.4962e+04)
[2022-05-31 18:19:48,694][root][INFO] - Step 98680320 @ 6650.8 SPS. Inference batcher size: 142. Learner queue size: 30. Other stats: (step = 98680320, mean_episode_return = 181.58, mean_episode_step = 774.85, total_loss = -65.369, pg_loss = -101.68, baseline_loss = 42.218, entropy_loss = -5.9111, learner_queue_size = 15, _tick = 31929, _time = 1.654e+09, train_seconds = 1.4967e+04)
[2022-05-31 18:19:53,698][root][INFO] - Step 98713600 @ 6650.7 SPS. Inference batcher size: 57. Learner queue size: 26. Other stats: (step = 98713600, mean_episode_return = 148.56, mean_episode_step = 710.34, total_loss = 536.96, pg_loss = 306.89, baseline_loss = 236.34, entropy_loss = -6.2751, learner_queue_size = 21, _tick = 31941, _time = 1.654e+09, train_seconds = 1.4972e+04)
[2022-05-31 18:19:58,702][root][INFO] - Step 98744320 @ 6138.9 SPS. Inference batcher size: 98. Learner queue size: 9. Other stats: (step = 98744320, mean_episode_return = 78.35, mean_episode_step = 731.87, total_loss = 844.92, pg_loss = 578.83, baseline_loss = 272.01, entropy_loss = -5.9097, learner_queue_size = 17, _tick = 31952, _time = 1.654e+09, train_seconds = 1.4977e+04)
[2022-05-31 18:20:03,709][root][INFO] - Step 98780160 @ 7158.3 SPS. Inference batcher size: 57. Learner queue size: 20. Other stats: (step = 98780160, mean_episode_return = 113.46, mean_episode_step = 683.88, total_loss = -366.56, pg_loss = -409.45, baseline_loss = 48.823, entropy_loss = -5.9305, learner_queue_size = 14, _tick = 31965, _time = 1.654e+09, train_seconds = 1.4982e+04)
[2022-05-31 18:20:08,714][root][INFO] - Step 98813440 @ 6649.2 SPS. Inference batcher size: 92. Learner queue size: 0. Other stats: (step = 98813440, mean_episode_return = 191.84, mean_episode_step = 919.25, total_loss = 82.366, pg_loss = -17.459, baseline_loss = 105.87, entropy_loss = -6.0488, learner_queue_size = 20, _tick = 31975, _time = 1.654e+09, train_seconds = 1.4987e+04)
[2022-05-31 18:20:13,720][root][INFO] - Step 98844160 @ 6136.5 SPS. Inference batcher size: 117. Learner queue size: 15. Other stats: (step = 98844160, mean_episode_return = 325.47, mean_episode_step = 698.04, total_loss = 382.32, pg_loss = 224.84, baseline_loss = 163.62, entropy_loss = -6.1392, learner_queue_size = 14, _tick = 31985, _time = 1.654e+09, train_seconds = 1.4992e+04)
[2022-05-31 18:20:18,726][root][INFO] - Step 98877440 @ 6648.0 SPS. Inference batcher size: 147. Learner queue size: 23. Other stats: (step = 98877440, mean_episode_return = 128.97, mean_episode_step = 695.05, total_loss = 236.74, pg_loss = 134.97, baseline_loss = 107.62, entropy_loss = -5.8515, learner_queue_size = 19, _tick = 31998, _time = 1.654e+09, train_seconds = 1.4997e+04)
[2022-05-31 18:20:23,731][root][INFO] - Step 98910720 @ 6650.2 SPS. Inference batcher size: 187. Learner queue size: 5. Other stats: (step = 98910720, mean_episode_return = 150.66, mean_episode_step = 686.71, total_loss = 71.451, pg_loss = -33.903, baseline_loss = 111.87, entropy_loss = -6.5191, learner_queue_size = 19, _tick = 32011, _time = 1.654e+09, train_seconds = 1.5002e+04)
[2022-05-31 18:20:28,734][root][INFO] - Step 98944000 @ 6651.3 SPS. Inference batcher size: 99. Learner queue size: 29. Other stats: (step = 98944000, mean_episode_return = None, mean_episode_step = 785.03, total_loss = 124.0, pg_loss = 31.404, baseline_loss = 98.935, entropy_loss = -6.3391, learner_queue_size = 18, _tick = 32022, _time = 1.654e+09, train_seconds = 1.5007e+04)
[2022-05-31 18:20:33,738][root][INFO] - Step 98977280 @ 6650.7 SPS. Inference batcher size: 76. Learner queue size: 27. Other stats: (step = 98977280, mean_episode_return = 144.97, mean_episode_step = 673.7, total_loss = 84.168, pg_loss = -2.0107, baseline_loss = 92.65, entropy_loss = -6.4718, learner_queue_size = 14, _tick = 32035, _time = 1.654e+09, train_seconds = 1.5012e+04)
[2022-05-31 18:20:38,742][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 18:20:38,825][root][INFO] - Step 99010560 @ 6650.7 SPS. Inference batcher size: 79. Learner queue size: 23. Other stats: (step = 99010560, mean_episode_return = 221.01, mean_episode_step = 621.09, total_loss = -71.32, pg_loss = -154.97, baseline_loss = 90.007, entropy_loss = -6.3562, learner_queue_size = 15, _tick = 32048, _time = 1.654e+09, train_seconds = 1.5017e+04)
[2022-05-31 18:20:43,830][root][INFO] - Step 99041280 @ 6037.2 SPS. Inference batcher size: 113. Learner queue size: 14. Other stats: (step = 99041280, mean_episode_return = 190.45, mean_episode_step = 512.59, total_loss = -14.562, pg_loss = -182.2, baseline_loss = 174.13, entropy_loss = -6.4915, learner_queue_size = 20, _tick = 32058, _time = 1.654e+09, train_seconds = 1.5022e+04)
[2022-05-31 18:20:48,834][root][INFO] - Step 99074560 @ 6651.2 SPS. Inference batcher size: 13. Learner queue size: 20. Other stats: (step = 99074560, mean_episode_return = 133.86, mean_episode_step = 701.31, total_loss = 91.871, pg_loss = 50.586, baseline_loss = 47.892, entropy_loss = -6.6066, learner_queue_size = 18, _tick = 32069, _time = 1.654e+09, train_seconds = 1.5028e+04)
[2022-05-31 18:20:53,838][root][INFO] - Step 99107840 @ 6650.5 SPS. Inference batcher size: 138. Learner queue size: 10. Other stats: (step = 99107840, mean_episode_return = 142.86, mean_episode_step = 613.25, total_loss = 187.42, pg_loss = 112.82, baseline_loss = 80.07, entropy_loss = -5.4709, learner_queue_size = 21, _tick = 32081, _time = 1.654e+09, train_seconds = 1.5032e+04)
[2022-05-31 18:20:58,842][root][INFO] - Step 99141120 @ 6650.8 SPS. Inference batcher size: 125. Learner queue size: 11. Other stats: (step = 99141120, mean_episode_return = 237.49, mean_episode_step = 695.94, total_loss = -180.56, pg_loss = -238.84, baseline_loss = 64.415, entropy_loss = -6.1304, learner_queue_size = 17, _tick = 32091, _time = 1.654e+09, train_seconds = 1.5038e+04)
[2022-05-31 18:21:03,847][root][INFO] - Step 99174400 @ 6649.7 SPS. Inference batcher size: 48. Learner queue size: 23. Other stats: (step = 99174400, mean_episode_return = 211.4, mean_episode_step = 506.31, total_loss = 162.55, pg_loss = 48.591, baseline_loss = 119.58, entropy_loss = -5.6183, learner_queue_size = 10, _tick = 32104, _time = 1.654e+09, train_seconds = 1.5042e+04)
[2022-05-31 18:21:08,854][root][INFO] - Step 99207680 @ 6646.5 SPS. Inference batcher size: 59. Learner queue size: 22. Other stats: (step = 99207680, mean_episode_return = 594.43, mean_episode_step = 597.08, total_loss = -235.58, pg_loss = -271.83, baseline_loss = 42.215, entropy_loss = -5.9641, learner_queue_size = 13, _tick = 32117, _time = 1.654e+09, train_seconds = 1.5048e+04)
[2022-05-31 18:21:13,860][root][INFO] - Step 99238400 @ 6136.7 SPS. Inference batcher size: 101. Learner queue size: 27. Other stats: (step = 99238400, mean_episode_return = 96.397, mean_episode_step = 678.32, total_loss = 274.94, pg_loss = 161.62, baseline_loss = 120.09, entropy_loss = -6.7719, learner_queue_size = 23, _tick = 32128, _time = 1.654e+09, train_seconds = 1.5052e+04)
[2022-05-31 18:21:18,862][root][INFO] - Step 99274240 @ 7164.8 SPS. Inference batcher size: 62. Learner queue size: 22. Other stats: (step = 99274240, mean_episode_return = 291.95, mean_episode_step = 618.35, total_loss = 437.53, pg_loss = 292.61, baseline_loss = 151.17, entropy_loss = -6.2485, learner_queue_size = 16, _tick = 32140, _time = 1.654e+09, train_seconds = 1.5058e+04)
[2022-05-31 18:21:23,870][root][INFO] - Step 99307520 @ 6645.4 SPS. Inference batcher size: 137. Learner queue size: 24. Other stats: (step = 99307520, mean_episode_return = 153.72, mean_episode_step = 635.62, total_loss = 39.864, pg_loss = -8.3721, baseline_loss = 54.021, entropy_loss = -5.7844, learner_queue_size = 22, _tick = 32150, _time = 1.654e+09, train_seconds = 1.5063e+04)
[2022-05-31 18:21:28,877][root][INFO] - Step 99338240 @ 6135.3 SPS. Inference batcher size: 142. Learner queue size: 13. Other stats: (step = 99338240, mean_episode_return = None, mean_episode_step = 574.69, total_loss = 31.093, pg_loss = -46.629, baseline_loss = 82.96, entropy_loss = -5.2371, learner_queue_size = 20, _tick = 32160, _time = 1.654e+09, train_seconds = 1.5068e+04)
[2022-05-31 18:21:33,883][root][INFO] - Step 99371520 @ 6648.0 SPS. Inference batcher size: 184. Learner queue size: 10. Other stats: (step = 99371520, mean_episode_return = 464.01, mean_episode_step = 591.79, total_loss = 241.97, pg_loss = 55.074, baseline_loss = 192.77, entropy_loss = -5.8796, learner_queue_size = 16, _tick = 32173, _time = 1.654e+09, train_seconds = 1.5073e+04)
[2022-05-31 18:21:38,889][root][INFO] - Step 99404800 @ 6647.9 SPS. Inference batcher size: 127. Learner queue size: 18. Other stats: (step = 99404800, mean_episode_return = 115.52, mean_episode_step = 736.97, total_loss = 275.47, pg_loss = 192.97, baseline_loss = 89.319, entropy_loss = -6.8167, learner_queue_size = 23, _tick = 32186, _time = 1.654e+09, train_seconds = 1.5078e+04)
[2022-05-31 18:21:43,894][root][INFO] - Step 99438080 @ 6649.3 SPS. Inference batcher size: 90. Learner queue size: 7. Other stats: (step = 99438080, mean_episode_return = 171.08, mean_episode_step = 618.79, total_loss = 78.184, pg_loss = -9.4678, baseline_loss = 93.736, entropy_loss = -6.0848, learner_queue_size = 24, _tick = 32197, _time = 1.654e+09, train_seconds = 1.5083e+04)
[2022-05-31 18:21:48,898][root][INFO] - Step 99471360 @ 6651.0 SPS. Inference batcher size: 94. Learner queue size: 7. Other stats: (step = 99471360, mean_episode_return = 138.94, mean_episode_step = 625.78, total_loss = 847.41, pg_loss = 153.68, baseline_loss = 700.63, entropy_loss = -6.8941, learner_queue_size = 20, _tick = 32210, _time = 1.654e+09, train_seconds = 1.5088e+04)
[2022-05-31 18:21:53,903][root][INFO] - Step 99504640 @ 6650.1 SPS. Inference batcher size: 38. Learner queue size: 17. Other stats: (step = 99504640, mean_episode_return = 112.86, mean_episode_step = 873.24, total_loss = 78.995, pg_loss = -9.71, baseline_loss = 95.148, entropy_loss = -6.443, learner_queue_size = 10, _tick = 32222, _time = 1.654e+09, train_seconds = 1.5093e+04)
[2022-05-31 18:21:58,906][root][INFO] - Step 99537920 @ 6651.4 SPS. Inference batcher size: 180. Learner queue size: 19. Other stats: (step = 99537920, mean_episode_return = 106.94, mean_episode_step = 784.1, total_loss = 366.82, pg_loss = 233.44, baseline_loss = 139.37, entropy_loss = -5.9805, learner_queue_size = 15, _tick = 32235, _time = 1.654e+09, train_seconds = 1.5098e+04)
[2022-05-31 18:22:03,912][root][INFO] - Step 99568640 @ 6136.6 SPS. Inference batcher size: 128. Learner queue size: 17. Other stats: (step = 99568640, mean_episode_return = 211.42, mean_episode_step = 771.04, total_loss = 238.8, pg_loss = 12.814, baseline_loss = 231.98, entropy_loss = -5.9909, learner_queue_size = 9, _tick = 32244, _time = 1.654e+09, train_seconds = 1.5103e+04)
[2022-05-31 18:22:08,918][root][INFO] - Step 99601920 @ 6648.0 SPS. Inference batcher size: 89. Learner queue size: 11. Other stats: (step = 99601920, mean_episode_return = 824.49, mean_episode_step = 683.06, total_loss = 70.752, pg_loss = -47.769, baseline_loss = 124.51, entropy_loss = -5.9853, learner_queue_size = 17, _tick = 32256, _time = 1.654e+09, train_seconds = 1.5108e+04)
[2022-05-31 18:22:13,922][root][INFO] - Step 99635200 @ 6650.8 SPS. Inference batcher size: 94. Learner queue size: 29. Other stats: (step = 99635200, mean_episode_return = 226.72, mean_episode_step = 628.84, total_loss = -52.329, pg_loss = -157.71, baseline_loss = 111.62, entropy_loss = -6.2425, learner_queue_size = 19, _tick = 32269, _time = 1.654e+09, train_seconds = 1.5113e+04)
[2022-05-31 18:22:18,926][root][INFO] - Step 99668480 @ 6650.6 SPS. Inference batcher size: 84. Learner queue size: 24. Other stats: (step = 99668480, mean_episode_return = 154.0, mean_episode_step = 790.63, total_loss = 957.67, pg_loss = 422.9, baseline_loss = 540.94, entropy_loss = -6.1712, learner_queue_size = 24, _tick = 32282, _time = 1.654e+09, train_seconds = 1.5118e+04)
[2022-05-31 18:22:23,930][root][INFO] - Step 99701760 @ 6650.4 SPS. Inference batcher size: 17. Learner queue size: 26. Other stats: (step = 99701760, mean_episode_return = 246.67, mean_episode_step = 661.15, total_loss = 179.74, pg_loss = -131.51, baseline_loss = 317.26, entropy_loss = -6.023, learner_queue_size = 26, _tick = 32295, _time = 1.654e+09, train_seconds = 1.5123e+04)
[2022-05-31 18:22:28,937][root][INFO] - Step 99732480 @ 6136.2 SPS. Inference batcher size: 149. Learner queue size: 31. Other stats: (step = 99732480, mean_episode_return = 236.63, mean_episode_step = 661.15, total_loss = 43.595, pg_loss = -142.69, baseline_loss = 192.04, entropy_loss = -5.7551, learner_queue_size = 18, _tick = 32307, _time = 1.654e+09, train_seconds = 1.5128e+04)
[2022-05-31 18:22:33,942][root][INFO] - Step 99768320 @ 7160.2 SPS. Inference batcher size: 112. Learner queue size: 15. Other stats: (step = 99768320, mean_episode_return = 402.22, mean_episode_step = 712.7, total_loss = 604.92, pg_loss = 389.59, baseline_loss = 221.44, entropy_loss = -6.1109, learner_queue_size = 13, _tick = 32319, _time = 1.654e+09, train_seconds = 1.5133e+04)
[2022-05-31 18:22:38,948][root][INFO] - Step 99799040 @ 6136.5 SPS. Inference batcher size: 111. Learner queue size: 21. Other stats: (step = 99799040, mean_episode_return = 291.57, mean_episode_step = 653.42, total_loss = 126.24, pg_loss = -25.389, baseline_loss = 157.92, entropy_loss = -6.2877, learner_queue_size = 16, _tick = 32328, _time = 1.654e+09, train_seconds = 1.5138e+04)
[2022-05-31 18:22:43,954][root][INFO] - Step 99832320 @ 6648.0 SPS. Inference batcher size: 133. Learner queue size: 17. Other stats: (step = 99832320, mean_episode_return = 687.36, mean_episode_step = 635.79, total_loss = 476.22, pg_loss = 373.24, baseline_loss = 109.93, entropy_loss = -6.95, learner_queue_size = 16, _tick = 32339, _time = 1.654e+09, train_seconds = 1.5143e+04)
[2022-05-31 18:22:48,958][root][INFO] - Step 99865600 @ 6650.8 SPS. Inference batcher size: 132. Learner queue size: 22. Other stats: (step = 99865600, mean_episode_return = 138.99, mean_episode_step = 826.96, total_loss = 20.148, pg_loss = -0.32297, baseline_loss = 27.144, entropy_loss = -6.6722, learner_queue_size = 14, _tick = 32352, _time = 1.654e+09, train_seconds = 1.5148e+04)
[2022-05-31 18:22:53,964][root][INFO] - Step 99901440 @ 7159.0 SPS. Inference batcher size: 35. Learner queue size: 22. Other stats: (step = 99901440, mean_episode_return = 293.81, mean_episode_step = 833.7, total_loss = 157.18, pg_loss = 73.993, baseline_loss = 88.69, entropy_loss = -5.5055, learner_queue_size = 22, _tick = 32366, _time = 1.654e+09, train_seconds = 1.5153e+04)
[2022-05-31 18:22:58,970][root][INFO] - Step 99932160 @ 6137.0 SPS. Inference batcher size: 158. Learner queue size: 17. Other stats: (step = 99932160, mean_episode_return = 126.61, mean_episode_step = 834.57, total_loss = 24.134, pg_loss = -103.35, baseline_loss = 133.38, entropy_loss = -5.898, learner_queue_size = 20, _tick = 32378, _time = 1.654e+09, train_seconds = 1.5158e+04)
[2022-05-31 18:23:03,974][root][INFO] - Step 99965440 @ 6650.8 SPS. Inference batcher size: 122. Learner queue size: 12. Other stats: (step = 99965440, mean_episode_return = 142.21, mean_episode_step = 635.17, total_loss = -78.571, pg_loss = -116.08, baseline_loss = 43.712, entropy_loss = -6.2056, learner_queue_size = 19, _tick = 32390, _time = 1.654e+09, train_seconds = 1.5163e+04)
[2022-05-31 18:23:08,978][root][INFO] - Step 99998720 @ 6650.6 SPS. Inference batcher size: 128. Learner queue size: 6. Other stats: (step = 99998720, mean_episode_return = 223.22, mean_episode_step = 752.79, total_loss = 204.01, pg_loss = 89.352, baseline_loss = 120.66, entropy_loss = -6.0067, learner_queue_size = 17, _tick = 32401, _time = 1.654e+09, train_seconds = 1.5168e+04)
[2022-05-31 18:23:13,984][root][INFO] - Step 100032000 @ 6647.8 SPS. Inference batcher size: 171. Learner queue size: 6. Other stats: (step = 100032000, mean_episode_return = 271.15, mean_episode_step = 710.51, total_loss = 45.49, pg_loss = -125.46, baseline_loss = 176.91, entropy_loss = -5.9672, learner_queue_size = 23, _tick = 32414, _time = 1.654e+09, train_seconds = 1.5173e+04)
[2022-05-31 18:23:18,990][root][INFO] - Step 100065280 @ 6648.2 SPS. Inference batcher size: 145. Learner queue size: 3. Other stats: (step = 100065280, mean_episode_return = 256.06, mean_episode_step = 619.37, total_loss = -99.857, pg_loss = -123.77, baseline_loss = 30.414, entropy_loss = -6.5023, learner_queue_size = 23, _tick = 32427, _time = 1.654e+09, train_seconds = 1.5178e+04)
[2022-05-31 18:23:23,996][root][INFO] - Step 100096000 @ 6136.6 SPS. Inference batcher size: 125. Learner queue size: 15. Other stats: (step = 100096000, mean_episode_return = 287.3, mean_episode_step = 925.4, total_loss = -53.651, pg_loss = -80.645, baseline_loss = 33.198, entropy_loss = -6.2034, learner_queue_size = 21, _tick = 32438, _time = 1.654e+09, train_seconds = 1.5183e+04)
[2022-05-31 18:23:29,002][root][INFO] - Step 100129280 @ 6648.0 SPS. Inference batcher size: 175. Learner queue size: 18. Other stats: (step = 100129280, mean_episode_return = None, mean_episode_step = 595.0, total_loss = 497.33, pg_loss = 352.75, baseline_loss = 150.13, entropy_loss = -5.5518, learner_queue_size = 21, _tick = 32448, _time = 1.654e+09, train_seconds = 1.5188e+04)
[2022-05-31 18:23:34,008][root][INFO] - Step 100162560 @ 6648.0 SPS. Inference batcher size: 103. Learner queue size: 23. Other stats: (step = 100162560, mean_episode_return = 219.35, mean_episode_step = 739.69, total_loss = 18.76, pg_loss = -163.31, baseline_loss = 187.69, entropy_loss = -5.6169, learner_queue_size = 28, _tick = 32460, _time = 1.654e+09, train_seconds = 1.5193e+04)
[2022-05-31 18:23:39,014][root][INFO] - Step 100195840 @ 6648.1 SPS. Inference batcher size: 116. Learner queue size: 19. Other stats: (step = 100195840, mean_episode_return = 398.04, mean_episode_step = 690.14, total_loss = -159.3, pg_loss = -233.61, baseline_loss = 80.442, entropy_loss = -6.1249, learner_queue_size = 17, _tick = 32473, _time = 1.654e+09, train_seconds = 1.5198e+04)
[2022-05-31 18:23:44,018][root][INFO] - Step 100229120 @ 6650.9 SPS. Inference batcher size: 110. Learner queue size: 20. Other stats: (step = 100229120, mean_episode_return = 152.94, mean_episode_step = 660.08, total_loss = 59.853, pg_loss = -60.152, baseline_loss = 126.36, entropy_loss = -6.3536, learner_queue_size = 14, _tick = 32486, _time = 1.654e+09, train_seconds = 1.5203e+04)
[2022-05-31 18:23:49,022][root][INFO] - Step 100262400 @ 6650.2 SPS. Inference batcher size: 28. Learner queue size: 10. Other stats: (step = 100262400, mean_episode_return = 165.99, mean_episode_step = 764.29, total_loss = 11.327, pg_loss = -28.961, baseline_loss = 46.529, entropy_loss = -6.242, learner_queue_size = 21, _tick = 32496, _time = 1.654e+09, train_seconds = 1.5208e+04)
[2022-05-31 18:23:54,026][root][INFO] - Step 100295680 @ 6651.0 SPS. Inference batcher size: 143. Learner queue size: 6. Other stats: (step = 100295680, mean_episode_return = 170.98, mean_episode_step = 897.8, total_loss = -84.695, pg_loss = -128.19, baseline_loss = 50.131, entropy_loss = -6.6391, learner_queue_size = 17, _tick = 32508, _time = 1.654e+09, train_seconds = 1.5213e+04)
[2022-05-31 18:23:59,032][root][INFO] - Step 100328960 @ 6647.9 SPS. Inference batcher size: 83. Learner queue size: 4. Other stats: (step = 100328960, mean_episode_return = 260.64, mean_episode_step = 729.68, total_loss = 571.94, pg_loss = 400.72, baseline_loss = 177.69, entropy_loss = -6.4735, learner_queue_size = 14, _tick = 32517, _time = 1.654e+09, train_seconds = 1.5218e+04)
[2022-05-31 18:24:04,038][root][INFO] - Step 100362240 @ 6648.0 SPS. Inference batcher size: 78. Learner queue size: 5. Other stats: (step = 100362240, mean_episode_return = 159.96, mean_episode_step = 662.74, total_loss = -57.214, pg_loss = -115.76, baseline_loss = 64.579, entropy_loss = -6.0327, learner_queue_size = 19, _tick = 32527, _time = 1.654e+09, train_seconds = 1.5223e+04)
[2022-05-31 18:24:09,042][root][INFO] - Step 100395520 @ 6650.9 SPS. Inference batcher size: 128. Learner queue size: 0. Other stats: (step = 100395520, mean_episode_return = 341.65, mean_episode_step = 946.56, total_loss = 191.62, pg_loss = 85.315, baseline_loss = 112.69, entropy_loss = -6.3811, learner_queue_size = 16, _tick = 32538, _time = 1.654e+09, train_seconds = 1.5228e+04)
[2022-05-31 18:24:14,046][root][INFO] - Step 100428800 @ 6650.7 SPS. Inference batcher size: 98. Learner queue size: 29. Other stats: (step = 100428800, mean_episode_return = 380.88, mean_episode_step = 781.12, total_loss = -131.67, pg_loss = -161.72, baseline_loss = 36.064, entropy_loss = -6.0184, learner_queue_size = 14, _tick = 32549, _time = 1.654e+09, train_seconds = 1.5233e+04)
[2022-05-31 18:24:19,052][root][INFO] - Step 100459520 @ 6136.6 SPS. Inference batcher size: 111. Learner queue size: 27. Other stats: (step = 100459520, mean_episode_return = 267.97, mean_episode_step = 809.48, total_loss = -167.34, pg_loss = -205.77, baseline_loss = 44.673, entropy_loss = -6.238, learner_queue_size = 17, _tick = 32561, _time = 1.654e+09, train_seconds = 1.5238e+04)
[2022-05-31 18:24:24,058][root][INFO] - Step 100495360 @ 7159.6 SPS. Inference batcher size: 131. Learner queue size: 21. Other stats: (step = 100495360, mean_episode_return = 356.79, mean_episode_step = 618.01, total_loss = 365.89, pg_loss = -28.498, baseline_loss = 400.08, entropy_loss = -5.696, learner_queue_size = 19, _tick = 32574, _time = 1.654e+09, train_seconds = 1.5243e+04)
[2022-05-31 18:24:29,064][root][INFO] - Step 100526080 @ 6136.6 SPS. Inference batcher size: 173. Learner queue size: 24. Other stats: (step = 100526080, mean_episode_return = 210.97, mean_episode_step = 662.78, total_loss = 269.72, pg_loss = 62.429, baseline_loss = 213.0, entropy_loss = -5.7022, learner_queue_size = 12, _tick = 32586, _time = 1.654e+09, train_seconds = 1.5248e+04)
[2022-05-31 18:24:34,071][root][INFO] - Step 100559360 @ 6647.0 SPS. Inference batcher size: 28. Learner queue size: 7. Other stats: (step = 100559360, mean_episode_return = 125.87, mean_episode_step = 629.29, total_loss = 281.49, pg_loss = 77.137, baseline_loss = 210.43, entropy_loss = -6.082, learner_queue_size = 17, _tick = 32598, _time = 1.654e+09, train_seconds = 1.5253e+04)
[2022-05-31 18:24:39,078][root][INFO] - Step 100592640 @ 6646.5 SPS. Inference batcher size: 121. Learner queue size: 15. Other stats: (step = 100592640, mean_episode_return = 83.118, mean_episode_step = 695.21, total_loss = 68.064, pg_loss = 17.211, baseline_loss = 57.362, entropy_loss = -6.509, learner_queue_size = 17, _tick = 32611, _time = 1.654e+09, train_seconds = 1.5258e+04)
[2022-05-31 18:24:44,082][root][INFO] - Step 100625920 @ 6650.5 SPS. Inference batcher size: 119. Learner queue size: 5. Other stats: (step = 100625920, mean_episode_return = 284.62, mean_episode_step = 620.25, total_loss = 134.22, pg_loss = 100.83, baseline_loss = 39.882, entropy_loss = -6.4931, learner_queue_size = 24, _tick = 32621, _time = 1.654e+09, train_seconds = 1.5263e+04)
[2022-05-31 18:24:49,089][root][INFO] - Step 100659200 @ 6647.0 SPS. Inference batcher size: 144. Learner queue size: 4. Other stats: (step = 100659200, mean_episode_return = 223.66, mean_episode_step = 656.6, total_loss = -96.471, pg_loss = -134.98, baseline_loss = 45.079, entropy_loss = -6.567, learner_queue_size = 19, _tick = 32632, _time = 1.654e+09, train_seconds = 1.5268e+04)
[2022-05-31 18:24:54,094][root][INFO] - Step 100692480 @ 6648.5 SPS. Inference batcher size: 84. Learner queue size: 1. Other stats: (step = 100692480, mean_episode_return = 154.82, mean_episode_step = 584.59, total_loss = -44.502, pg_loss = -63.732, baseline_loss = 25.776, entropy_loss = -6.5465, learner_queue_size = 14, _tick = 32644, _time = 1.654e+09, train_seconds = 1.5273e+04)
[2022-05-31 18:24:59,102][root][INFO] - Step 100725760 @ 6647.1 SPS. Inference batcher size: 52. Learner queue size: 16. Other stats: (step = 100725760, mean_episode_return = 112.32, mean_episode_step = 714.13, total_loss = 59.223, pg_loss = 8.5078, baseline_loss = 56.338, entropy_loss = -5.623, learner_queue_size = 12, _tick = 32656, _time = 1.654e+09, train_seconds = 1.5278e+04)
[2022-05-31 18:25:04,106][root][INFO] - Step 100759040 @ 6649.4 SPS. Inference batcher size: 130. Learner queue size: 27. Other stats: (step = 100759040, mean_episode_return = 68.209, mean_episode_step = 634.96, total_loss = 140.0, pg_loss = 88.781, baseline_loss = 57.44, entropy_loss = -6.2243, learner_queue_size = 24, _tick = 32669, _time = 1.654e+09, train_seconds = 1.5283e+04)
[2022-05-31 18:25:09,110][root][INFO] - Step 100792320 @ 6650.6 SPS. Inference batcher size: 18. Learner queue size: 22. Other stats: (step = 100792320, mean_episode_return = 269.44, mean_episode_step = 706.17, total_loss = -244.48, pg_loss = -305.59, baseline_loss = 68.004, entropy_loss = -6.8946, learner_queue_size = 22, _tick = 32679, _time = 1.654e+09, train_seconds = 1.5288e+04)
[2022-05-31 18:25:14,114][root][INFO] - Step 100823040 @ 6139.2 SPS. Inference batcher size: 137. Learner queue size: 17. Other stats: (step = 100823040, mean_episode_return = None, mean_episode_step = 622.66, total_loss = 578.17, pg_loss = 384.85, baseline_loss = 200.08, entropy_loss = -6.7596, learner_queue_size = 15, _tick = 32686, _time = 1.654e+09, train_seconds = 1.5293e+04)
[2022-05-31 18:25:19,119][root][INFO] - Step 100856320 @ 6649.8 SPS. Inference batcher size: 14. Learner queue size: 15. Other stats: (step = 100856320, mean_episode_return = 101.13, mean_episode_step = 731.79, total_loss = -91.143, pg_loss = -139.73, baseline_loss = 54.946, entropy_loss = -6.364, learner_queue_size = 25, _tick = 32697, _time = 1.654e+09, train_seconds = 1.5298e+04)
[2022-05-31 18:25:24,122][root][INFO] - Step 100889600 @ 6651.5 SPS. Inference batcher size: 115. Learner queue size: 11. Other stats: (step = 100889600, mean_episode_return = 297.03, mean_episode_step = 835.85, total_loss = -42.284, pg_loss = -113.95, baseline_loss = 78.506, entropy_loss = -6.8432, learner_queue_size = 26, _tick = 32710, _time = 1.654e+09, train_seconds = 1.5303e+04)
[2022-05-31 18:25:29,126][root][INFO] - Step 100922880 @ 6650.7 SPS. Inference batcher size: 160. Learner queue size: 9. Other stats: (step = 100922880, mean_episode_return = 300.75, mean_episode_step = 675.07, total_loss = 523.36, pg_loss = 315.49, baseline_loss = 213.67, entropy_loss = -5.7963, learner_queue_size = 23, _tick = 32722, _time = 1.654e+09, train_seconds = 1.5308e+04)
[2022-05-31 18:25:34,130][root][INFO] - Step 100956160 @ 6650.7 SPS. Inference batcher size: 85. Learner queue size: 0. Other stats: (step = 100956160, mean_episode_return = 201.41, mean_episode_step = 865.5, total_loss = 301.78, pg_loss = 131.08, baseline_loss = 177.12, entropy_loss = -6.4222, learner_queue_size = 16, _tick = 32734, _time = 1.654e+09, train_seconds = 1.5313e+04)
[2022-05-31 18:25:39,136][root][INFO] - Step 100989440 @ 6647.6 SPS. Inference batcher size: 138. Learner queue size: 23. Other stats: (step = 100989440, mean_episode_return = 126.39, mean_episode_step = 548.16, total_loss = 746.27, pg_loss = 444.67, baseline_loss = 307.53, entropy_loss = -5.9248, learner_queue_size = 23, _tick = 32747, _time = 1.654e+09, train_seconds = 1.5318e+04)
[2022-05-31 18:25:44,142][root][INFO] - Step 101022720 @ 6648.1 SPS. Inference batcher size: 112. Learner queue size: 28. Other stats: (step = 101022720, mean_episode_return = None, mean_episode_step = 624.66, total_loss = 472.64, pg_loss = 364.7, baseline_loss = 114.13, entropy_loss = -6.182, learner_queue_size = 24, _tick = 32758, _time = 1.654e+09, train_seconds = 1.5323e+04)
[2022-05-31 18:25:49,146][root][INFO] - Step 101053440 @ 6139.3 SPS. Inference batcher size: 130. Learner queue size: 12. Other stats: (step = 101053440, mean_episode_return = 293.28, mean_episode_step = 621.69, total_loss = 122.45, pg_loss = 3.2185, baseline_loss = 125.39, entropy_loss = -6.158, learner_queue_size = 13, _tick = 32770, _time = 1.654e+09, train_seconds = 1.5328e+04)
[2022-05-31 18:25:54,152][root][INFO] - Step 101086720 @ 6647.9 SPS. Inference batcher size: 89. Learner queue size: 15. Other stats: (step = 101086720, mean_episode_return = 312.88, mean_episode_step = 639.49, total_loss = 103.74, pg_loss = 29.943, baseline_loss = 79.75, entropy_loss = -5.9582, learner_queue_size = 23, _tick = 32783, _time = 1.654e+09, train_seconds = 1.5333e+04)
[2022-05-31 18:25:59,158][root][INFO] - Step 101120000 @ 6648.0 SPS. Inference batcher size: 126. Learner queue size: 14. Other stats: (step = 101120000, mean_episode_return = 251.36, mean_episode_step = 683.19, total_loss = 187.55, pg_loss = 55.203, baseline_loss = 138.17, entropy_loss = -5.8265, learner_queue_size = 29, _tick = 32793, _time = 1.654e+09, train_seconds = 1.5338e+04)
[2022-05-31 18:26:04,162][root][INFO] - Step 101153280 @ 6650.8 SPS. Inference batcher size: 137. Learner queue size: 16. Other stats: (step = 101153280, mean_episode_return = 189.86, mean_episode_step = 735.56, total_loss = 255.17, pg_loss = 76.601, baseline_loss = 184.24, entropy_loss = -5.6658, learner_queue_size = 16, _tick = 32804, _time = 1.654e+09, train_seconds = 1.5343e+04)
[2022-05-31 18:26:09,166][root][INFO] - Step 101186560 @ 6650.8 SPS. Inference batcher size: 0. Learner queue size: 9. Other stats: (step = 101186560, mean_episode_return = 132.03, mean_episode_step = 522.31, total_loss = -317.28, pg_loss = -416.51, baseline_loss = 104.9, entropy_loss = -5.673, learner_queue_size = 22, _tick = 32817, _time = 1.654e+09, train_seconds = 1.5348e+04)
[2022-05-31 18:26:14,170][root][INFO] - Step 101219840 @ 6650.7 SPS. Inference batcher size: 117. Learner queue size: 0. Other stats: (step = 101219840, mean_episode_return = 177.25, mean_episode_step = 705.68, total_loss = 371.41, pg_loss = 227.85, baseline_loss = 148.91, entropy_loss = -5.3523, learner_queue_size = 14, _tick = 32830, _time = 1.654e+09, train_seconds = 1.5353e+04)
[2022-05-31 18:26:19,174][root][INFO] - Step 101253120 @ 6650.6 SPS. Inference batcher size: 116. Learner queue size: 18. Other stats: (step = 101253120, mean_episode_return = 273.94, mean_episode_step = 696.14, total_loss = -48.094, pg_loss = -201.58, baseline_loss = 159.19, entropy_loss = -5.7031, learner_queue_size = 12, _tick = 32841, _time = 1.654e+09, train_seconds = 1.5358e+04)
[2022-05-31 18:26:24,180][root][INFO] - Step 101283840 @ 6136.9 SPS. Inference batcher size: 128. Learner queue size: 15. Other stats: (step = 101283840, mean_episode_return = 148.64, mean_episode_step = 554.45, total_loss = -48.645, pg_loss = -154.3, baseline_loss = 111.33, entropy_loss = -5.6752, learner_queue_size = 16, _tick = 32853, _time = 1.654e+09, train_seconds = 1.5363e+04)
[2022-05-31 18:26:29,182][root][INFO] - Step 101317120 @ 6653.0 SPS. Inference batcher size: 118. Learner queue size: 10. Other stats: (step = 101317120, mean_episode_return = 218.01, mean_episode_step = 601.4, total_loss = 332.76, pg_loss = 149.65, baseline_loss = 188.61, entropy_loss = -5.5027, learner_queue_size = 25, _tick = 32866, _time = 1.654e+09, train_seconds = 1.5368e+04)
[2022-05-31 18:26:34,186][root][INFO] - Step 101350400 @ 6650.7 SPS. Inference batcher size: 102. Learner queue size: 12. Other stats: (step = 101350400, mean_episode_return = 166.29, mean_episode_step = 562.06, total_loss = 232.39, pg_loss = 79.474, baseline_loss = 158.64, entropy_loss = -5.7317, learner_queue_size = 20, _tick = 32878, _time = 1.654e+09, train_seconds = 1.5373e+04)
[2022-05-31 18:26:39,190][root][INFO] - Step 101383680 @ 6650.7 SPS. Inference batcher size: 126. Learner queue size: 0. Other stats: (step = 101383680, mean_episode_return = None, mean_episode_step = 786.16, total_loss = 12.976, pg_loss = -53.854, baseline_loss = 72.337, entropy_loss = -5.5069, learner_queue_size = 10, _tick = 32890, _time = 1.654e+09, train_seconds = 1.5378e+04)
[2022-05-31 18:26:44,194][root][INFO] - Step 101416960 @ 6650.8 SPS. Inference batcher size: 121. Learner queue size: 22. Other stats: (step = 101416960, mean_episode_return = 153.58, mean_episode_step = 665.22, total_loss = -25.344, pg_loss = -97.439, baseline_loss = 77.649, entropy_loss = -5.5532, learner_queue_size = 13, _tick = 32902, _time = 1.654e+09, train_seconds = 1.5383e+04)
[2022-05-31 18:26:49,198][root][INFO] - Step 101450240 @ 6650.5 SPS. Inference batcher size: 106. Learner queue size: 21. Other stats: (step = 101450240, mean_episode_return = 329.04, mean_episode_step = 635.25, total_loss = -153.51, pg_loss = -226.49, baseline_loss = 79.244, entropy_loss = -6.2641, learner_queue_size = 19, _tick = 32912, _time = 1.654e+09, train_seconds = 1.5388e+04)
[2022-05-31 18:26:54,204][root][INFO] - Step 101480960 @ 6136.5 SPS. Inference batcher size: 102. Learner queue size: 18. Other stats: (step = 101480960, mean_episode_return = 507.62, mean_episode_step = 584.01, total_loss = 494.81, pg_loss = 279.44, baseline_loss = 221.28, entropy_loss = -5.9128, learner_queue_size = 18, _tick = 32923, _time = 1.654e+09, train_seconds = 1.5393e+04)
[2022-05-31 18:26:59,210][root][INFO] - Step 101514240 @ 6648.0 SPS. Inference batcher size: 91. Learner queue size: 13. Other stats: (step = 101514240, mean_episode_return = 157.62, mean_episode_step = 514.28, total_loss = 115.63, pg_loss = 41.055, baseline_loss = 79.877, entropy_loss = -5.3039, learner_queue_size = 22, _tick = 32935, _time = 1.654e+09, train_seconds = 1.5398e+04)
[2022-05-31 18:27:04,214][root][INFO] - Step 101547520 @ 6650.9 SPS. Inference batcher size: 62. Learner queue size: 13. Other stats: (step = 101547520, mean_episode_return = 112.79, mean_episode_step = 593.45, total_loss = 99.314, pg_loss = -10.13, baseline_loss = 114.68, entropy_loss = -5.2348, learner_queue_size = 16, _tick = 32947, _time = 1.654e+09, train_seconds = 1.5403e+04)
[2022-05-31 18:27:09,218][root][INFO] - Step 101580800 @ 6650.8 SPS. Inference batcher size: 129. Learner queue size: 3. Other stats: (step = 101580800, mean_episode_return = 139.77, mean_episode_step = 642.27, total_loss = 84.269, pg_loss = 33.033, baseline_loss = 56.209, entropy_loss = -4.9725, learner_queue_size = 15, _tick = 32959, _time = 1.654e+09, train_seconds = 1.5408e+04)
[2022-05-31 18:27:14,222][root][INFO] - Step 101614080 @ 6650.7 SPS. Inference batcher size: 93. Learner queue size: 3. Other stats: (step = 101614080, mean_episode_return = None, mean_episode_step = 633.41, total_loss = 227.86, pg_loss = 42.254, baseline_loss = 191.46, entropy_loss = -5.8544, learner_queue_size = 12, _tick = 32971, _time = 1.654e+09, train_seconds = 1.5413e+04)
[2022-05-31 18:27:19,226][root][INFO] - Step 101647360 @ 6650.6 SPS. Inference batcher size: 57. Learner queue size: 25. Other stats: (step = 101647360, mean_episode_return = 129.34, mean_episode_step = 743.26, total_loss = 121.2, pg_loss = 49.902, baseline_loss = 77.428, entropy_loss = -6.1275, learner_queue_size = 22, _tick = 32984, _time = 1.654e+09, train_seconds = 1.5418e+04)
[2022-05-31 18:27:24,234][root][INFO] - Step 101680640 @ 6645.3 SPS. Inference batcher size: 99. Learner queue size: 22. Other stats: (step = 101680640, mean_episode_return = 196.54, mean_episode_step = 755.42, total_loss = 45.589, pg_loss = 16.781, baseline_loss = 35.411, entropy_loss = -6.6033, learner_queue_size = 20, _tick = 32996, _time = 1.654e+09, train_seconds = 1.5423e+04)
[2022-05-31 18:27:29,238][root][INFO] - Step 101711360 @ 6139.2 SPS. Inference batcher size: 126. Learner queue size: 14. Other stats: (step = 101711360, mean_episode_return = 512.63, mean_episode_step = 630.05, total_loss = -26.817, pg_loss = -46.967, baseline_loss = 26.991, entropy_loss = -6.8413, learner_queue_size = 17, _tick = 33007, _time = 1.654e+09, train_seconds = 1.5428e+04)
[2022-05-31 18:27:34,244][root][INFO] - Step 101744640 @ 6648.0 SPS. Inference batcher size: 88. Learner queue size: 25. Other stats: (step = 101744640, mean_episode_return = None, mean_episode_step = 669.44, total_loss = 127.51, pg_loss = 62.424, baseline_loss = 71.16, entropy_loss = -6.0737, learner_queue_size = 19, _tick = 33016, _time = 1.654e+09, train_seconds = 1.5433e+04)
[2022-05-31 18:27:39,248][root][INFO] - Step 101777920 @ 6650.5 SPS. Inference batcher size: 119. Learner queue size: 29. Other stats: (step = 101777920, mean_episode_return = 203.5, mean_episode_step = 646.76, total_loss = -8.9861, pg_loss = -64.802, baseline_loss = 61.81, entropy_loss = -5.9937, learner_queue_size = 24, _tick = 33027, _time = 1.654e+09, train_seconds = 1.5438e+04)
[2022-05-31 18:27:44,254][root][INFO] - Step 101811200 @ 6648.2 SPS. Inference batcher size: 91. Learner queue size: 11. Other stats: (step = 101811200, mean_episode_return = 196.63, mean_episode_step = 911.14, total_loss = 260.28, pg_loss = 161.17, baseline_loss = 104.93, entropy_loss = -5.8178, learner_queue_size = 15, _tick = 33039, _time = 1.654e+09, train_seconds = 1.5443e+04)
[2022-05-31 18:27:49,258][root][INFO] - Step 101844480 @ 6650.6 SPS. Inference batcher size: 107. Learner queue size: 8. Other stats: (step = 101844480, mean_episode_return = 181.04, mean_episode_step = 807.26, total_loss = 209.26, pg_loss = -81.574, baseline_loss = 297.0, entropy_loss = -6.1687, learner_queue_size = 13, _tick = 33050, _time = 1.654e+09, train_seconds = 1.5448e+04)
[2022-05-31 18:27:54,262][root][INFO] - Step 101877760 @ 6650.8 SPS. Inference batcher size: 146. Learner queue size: 3. Other stats: (step = 101877760, mean_episode_return = 94.063, mean_episode_step = 662.58, total_loss = 263.78, pg_loss = 127.34, baseline_loss = 142.28, entropy_loss = -5.8338, learner_queue_size = 23, _tick = 33062, _time = 1.654e+09, train_seconds = 1.5453e+04)
[2022-05-31 18:27:59,268][root][INFO] - Step 101911040 @ 6648.0 SPS. Inference batcher size: 37. Learner queue size: 31. Other stats: (step = 101911040, mean_episode_return = 238.22, mean_episode_step = 893.35, total_loss = -183.82, pg_loss = -221.41, baseline_loss = 43.742, entropy_loss = -6.15, learner_queue_size = 19, _tick = 33075, _time = 1.654e+09, train_seconds = 1.5458e+04)
[2022-05-31 18:28:04,274][root][INFO] - Step 101944320 @ 6648.1 SPS. Inference batcher size: 86. Learner queue size: 1. Other stats: (step = 101944320, mean_episode_return = 396.2, mean_episode_step = 622.62, total_loss = -102.22, pg_loss = -168.66, baseline_loss = 72.761, entropy_loss = -6.3215, learner_queue_size = 29, _tick = 33087, _time = 1.654e+09, train_seconds = 1.5463e+04)
[2022-05-31 18:28:09,280][root][INFO] - Step 101975040 @ 6136.4 SPS. Inference batcher size: 96. Learner queue size: 17. Other stats: (step = 101975040, mean_episode_return = 323.7, mean_episode_step = 744.33, total_loss = -118.68, pg_loss = -195.77, baseline_loss = 82.779, entropy_loss = -5.687, learner_queue_size = 14, _tick = 33099, _time = 1.654e+09, train_seconds = 1.5468e+04)
[2022-05-31 18:28:14,286][root][INFO] - Step 102008320 @ 6648.2 SPS. Inference batcher size: 83. Learner queue size: 18. Other stats: (step = 102008320, mean_episode_return = 204.62, mean_episode_step = 740.34, total_loss = 129.05, pg_loss = 46.736, baseline_loss = 88.546, entropy_loss = -6.2333, learner_queue_size = 24, _tick = 33111, _time = 1.654e+09, train_seconds = 1.5473e+04)
[2022-05-31 18:28:19,290][root][INFO] - Step 102041600 @ 6650.8 SPS. Inference batcher size: 101. Learner queue size: 9. Other stats: (step = 102041600, mean_episode_return = None, mean_episode_step = 589.41, total_loss = -67.423, pg_loss = -95.498, baseline_loss = 34.349, entropy_loss = -6.2736, learner_queue_size = 31, _tick = 33121, _time = 1.654e+09, train_seconds = 1.5478e+04)
[2022-05-31 18:28:24,295][root][INFO] - Step 102074880 @ 6649.7 SPS. Inference batcher size: 134. Learner queue size: 0. Other stats: (step = 102074880, mean_episode_return = 182.66, mean_episode_step = 562.76, total_loss = 52.949, pg_loss = 3.5151, baseline_loss = 55.338, entropy_loss = -5.9039, learner_queue_size = 19, _tick = 33134, _time = 1.654e+09, train_seconds = 1.5483e+04)
[2022-05-31 18:28:29,298][root][INFO] - Step 102108160 @ 6651.6 SPS. Inference batcher size: 81. Learner queue size: 7. Other stats: (step = 102108160, mean_episode_return = 231.17, mean_episode_step = 630.53, total_loss = 239.8, pg_loss = 89.832, baseline_loss = 155.46, entropy_loss = -5.4969, learner_queue_size = 27, _tick = 33143, _time = 1.654e+09, train_seconds = 1.5488e+04)
[2022-05-31 18:28:34,302][root][INFO] - Step 102141440 @ 6650.5 SPS. Inference batcher size: 115. Learner queue size: 28. Other stats: (step = 102141440, mean_episode_return = 106.65, mean_episode_step = 737.51, total_loss = 1069.9, pg_loss = 561.51, baseline_loss = 514.11, entropy_loss = -5.7343, learner_queue_size = 18, _tick = 33156, _time = 1.654e+09, train_seconds = 1.5493e+04)
[2022-05-31 18:28:39,306][root][INFO] - Step 102174720 @ 6650.9 SPS. Inference batcher size: 16. Learner queue size: 3. Other stats: (step = 102174720, mean_episode_return = 384.85, mean_episode_step = 581.13, total_loss = 232.23, pg_loss = 105.52, baseline_loss = 132.05, entropy_loss = -5.343, learner_queue_size = 26, _tick = 33167, _time = 1.654e+09, train_seconds = 1.5498e+04)
[2022-05-31 18:28:44,310][root][INFO] - Step 102208000 @ 6650.5 SPS. Inference batcher size: 135. Learner queue size: 18. Other stats: (step = 102208000, mean_episode_return = 238.95, mean_episode_step = 762.49, total_loss = -155.93, pg_loss = -245.82, baseline_loss = 95.322, entropy_loss = -5.4284, learner_queue_size = 15, _tick = 33180, _time = 1.654e+09, train_seconds = 1.5503e+04)
[2022-05-31 18:28:49,314][root][INFO] - Step 102238720 @ 6139.1 SPS. Inference batcher size: 133. Learner queue size: 18. Other stats: (step = 102238720, mean_episode_return = 324.81, mean_episode_step = 751.75, total_loss = 37.031, pg_loss = -64.505, baseline_loss = 107.2, entropy_loss = -5.6658, learner_queue_size = 16, _tick = 33191, _time = 1.654e+09, train_seconds = 1.5508e+04)
[2022-05-31 18:28:54,318][root][INFO] - Step 102272000 @ 6650.7 SPS. Inference batcher size: 146. Learner queue size: 15. Other stats: (step = 102272000, mean_episode_return = 225.48, mean_episode_step = 756.01, total_loss = 105.37, pg_loss = 25.452, baseline_loss = 85.719, entropy_loss = -5.805, learner_queue_size = 28, _tick = 33202, _time = 1.654e+09, train_seconds = 1.5513e+04)
[2022-05-31 18:28:59,324][root][INFO] - Step 102305280 @ 6647.3 SPS. Inference batcher size: 177. Learner queue size: 1. Other stats: (step = 102305280, mean_episode_return = 169.43, mean_episode_step = 535.92, total_loss = 338.42, pg_loss = 159.18, baseline_loss = 184.6, entropy_loss = -5.3497, learner_queue_size = 19, _tick = 33215, _time = 1.654e+09, train_seconds = 1.5518e+04)
[2022-05-31 18:29:04,330][root][INFO] - Step 102338560 @ 6648.3 SPS. Inference batcher size: 81. Learner queue size: 8. Other stats: (step = 102338560, mean_episode_return = 81.275, mean_episode_step = 576.55, total_loss = 228.24, pg_loss = 9.6569, baseline_loss = 224.48, entropy_loss = -5.8915, learner_queue_size = 21, _tick = 33228, _time = 1.654e+09, train_seconds = 1.5523e+04)
[2022-05-31 18:29:09,334][root][INFO] - Step 102371840 @ 6651.2 SPS. Inference batcher size: 124. Learner queue size: 22. Other stats: (step = 102371840, mean_episode_return = 330.02, mean_episode_step = 561.27, total_loss = 115.79, pg_loss = 0.8275, baseline_loss = 120.81, entropy_loss = -5.846, learner_queue_size = 18, _tick = 33239, _time = 1.654e+09, train_seconds = 1.5528e+04)
[2022-05-31 18:29:14,340][root][INFO] - Step 102402560 @ 6137.0 SPS. Inference batcher size: 73. Learner queue size: 30. Other stats: (step = 102402560, mean_episode_return = 492.19, mean_episode_step = 967.66, total_loss = -0.91259, pg_loss = -62.381, baseline_loss = 67.859, entropy_loss = -6.3911, learner_queue_size = 21, _tick = 33251, _time = 1.654e+09, train_seconds = 1.5533e+04)
[2022-05-31 18:29:19,342][root][INFO] - Step 102438400 @ 7164.7 SPS. Inference batcher size: 79. Learner queue size: 22. Other stats: (step = 102438400, mean_episode_return = 331.21, mean_episode_step = 560.25, total_loss = 656.97, pg_loss = 429.81, baseline_loss = 233.09, entropy_loss = -5.9378, learner_queue_size = 21, _tick = 33264, _time = 1.654e+09, train_seconds = 1.5538e+04)
[2022-05-31 18:29:24,348][root][INFO] - Step 102469120 @ 6136.6 SPS. Inference batcher size: 72. Learner queue size: 23. Other stats: (step = 102469120, mean_episode_return = 469.77, mean_episode_step = 699.41, total_loss = -77.197, pg_loss = -160.99, baseline_loss = 89.779, entropy_loss = -5.9905, learner_queue_size = 19, _tick = 33276, _time = 1.654e+09, train_seconds = 1.5543e+04)
[2022-05-31 18:29:29,354][root][INFO] - Step 102504960 @ 7159.6 SPS. Inference batcher size: 46. Learner queue size: 20. Other stats: (step = 102504960, mean_episode_return = None, mean_episode_step = 600.09, total_loss = 72.83, pg_loss = 16.915, baseline_loss = 62.257, entropy_loss = -6.3417, learner_queue_size = 19, _tick = 33287, _time = 1.654e+09, train_seconds = 1.5548e+04)
[2022-05-31 18:29:34,360][root][INFO] - Step 102535680 @ 6136.6 SPS. Inference batcher size: 99. Learner queue size: 11. Other stats: (step = 102535680, mean_episode_return = 259.74, mean_episode_step = 808.13, total_loss = 700.56, pg_loss = 460.31, baseline_loss = 246.13, entropy_loss = -5.8803, learner_queue_size = 9, _tick = 33297, _time = 1.654e+09, train_seconds = 1.5553e+04)
[2022-05-31 18:29:39,362][root][INFO] - Step 102568960 @ 6653.2 SPS. Inference batcher size: 158. Learner queue size: 22. Other stats: (step = 102568960, mean_episode_return = 190.89, mean_episode_step = 628.53, total_loss = 36.891, pg_loss = -50.574, baseline_loss = 93.313, entropy_loss = -5.8483, learner_queue_size = 22, _tick = 33308, _time = 1.654e+09, train_seconds = 1.5558e+04)
[2022-05-31 18:29:44,366][root][INFO] - Step 102602240 @ 6650.7 SPS. Inference batcher size: 126. Learner queue size: 8. Other stats: (step = 102602240, mean_episode_return = 110.78, mean_episode_step = 729.23, total_loss = 16.908, pg_loss = -72.192, baseline_loss = 94.747, entropy_loss = -5.6472, learner_queue_size = 23, _tick = 33321, _time = 1.654e+09, train_seconds = 1.5563e+04)
[2022-05-31 18:29:49,370][root][INFO] - Step 102635520 @ 6650.8 SPS. Inference batcher size: 90. Learner queue size: 3. Other stats: (step = 102635520, mean_episode_return = 44.847, mean_episode_step = 733.59, total_loss = 136.93, pg_loss = 74.819, baseline_loss = 67.612, entropy_loss = -5.4963, learner_queue_size = 24, _tick = 33334, _time = 1.654e+09, train_seconds = 1.5568e+04)
[2022-05-31 18:29:54,374][root][INFO] - Step 102668800 @ 6650.5 SPS. Inference batcher size: 49. Learner queue size: 2. Other stats: (step = 102668800, mean_episode_return = 338.19, mean_episode_step = 538.35, total_loss = 399.54, pg_loss = 92.822, baseline_loss = 312.47, entropy_loss = -5.7565, learner_queue_size = 6, _tick = 33347, _time = 1.654e+09, train_seconds = 1.5573e+04)
[2022-05-31 18:29:59,378][root][INFO] - Step 102702080 @ 6650.9 SPS. Inference batcher size: 36. Learner queue size: 22. Other stats: (step = 102702080, mean_episode_return = 334.39, mean_episode_step = 611.52, total_loss = 8.8693, pg_loss = -66.699, baseline_loss = 81.31, entropy_loss = -5.7415, learner_queue_size = 20, _tick = 33359, _time = 1.654e+09, train_seconds = 1.5578e+04)
[2022-05-31 18:30:04,383][root][INFO] - Step 102732800 @ 6138.4 SPS. Inference batcher size: 105. Learner queue size: 17. Other stats: (step = 102732800, mean_episode_return = 232.59, mean_episode_step = 586.14, total_loss = 80.757, pg_loss = -9.6197, baseline_loss = 95.791, entropy_loss = -5.414, learner_queue_size = 18, _tick = 33371, _time = 1.654e+09, train_seconds = 1.5583e+04)
[2022-05-31 18:30:09,386][root][INFO] - Step 102768640 @ 7162.6 SPS. Inference batcher size: 77. Learner queue size: 21. Other stats: (step = 102768640, mean_episode_return = 203.31, mean_episode_step = 591.45, total_loss = 19.935, pg_loss = -112.96, baseline_loss = 138.59, entropy_loss = -5.6935, learner_queue_size = 14, _tick = 33383, _time = 1.654e+09, train_seconds = 1.5588e+04)
[2022-05-31 18:30:14,393][root][INFO] - Step 102799360 @ 6136.0 SPS. Inference batcher size: 163. Learner queue size: 24. Other stats: (step = 102799360, mean_episode_return = 199.68, mean_episode_step = 608.37, total_loss = -100.22, pg_loss = -131.84, baseline_loss = 37.461, entropy_loss = -5.8377, learner_queue_size = 7, _tick = 33394, _time = 1.654e+09, train_seconds = 1.5593e+04)
[2022-05-31 18:30:19,399][root][INFO] - Step 102832640 @ 6648.0 SPS. Inference batcher size: 136. Learner queue size: 19. Other stats: (step = 102832640, mean_episode_return = 190.14, mean_episode_step = 572.78, total_loss = 167.49, pg_loss = 125.96, baseline_loss = 47.931, entropy_loss = -6.4004, learner_queue_size = 11, _tick = 33406, _time = 1.654e+09, train_seconds = 1.5598e+04)
[2022-05-31 18:30:24,405][root][INFO] - Step 102865920 @ 6648.0 SPS. Inference batcher size: 134. Learner queue size: 28. Other stats: (step = 102865920, mean_episode_return = 162.01, mean_episode_step = 735.31, total_loss = 266.85, pg_loss = 172.38, baseline_loss = 100.3, entropy_loss = -5.8301, learner_queue_size = 24, _tick = 33419, _time = 1.654e+09, train_seconds = 1.5603e+04)
[2022-05-31 18:30:29,411][root][INFO] - Step 102899200 @ 6648.0 SPS. Inference batcher size: 167. Learner queue size: 12. Other stats: (step = 102899200, mean_episode_return = 243.5, mean_episode_step = 716.04, total_loss = 149.83, pg_loss = 63.881, baseline_loss = 91.913, entropy_loss = -5.9641, learner_queue_size = 17, _tick = 33429, _time = 1.654e+09, train_seconds = 1.5608e+04)
[2022-05-31 18:30:34,417][root][INFO] - Step 102932480 @ 6648.0 SPS. Inference batcher size: 123. Learner queue size: 21. Other stats: (step = 102932480, mean_episode_return = 300.22, mean_episode_step = 687.39, total_loss = 431.54, pg_loss = 267.5, baseline_loss = 169.97, entropy_loss = -5.927, learner_queue_size = 10, _tick = 33442, _time = 1.654e+09, train_seconds = 1.5613e+04)
[2022-05-31 18:30:39,422][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 18:30:39,582][root][INFO] - Step 102965760 @ 6649.2 SPS. Inference batcher size: 144. Learner queue size: 7. Other stats: (step = 102965760, mean_episode_return = 158.0, mean_episode_step = 570.07, total_loss = -16.087, pg_loss = -106.28, baseline_loss = 96.188, entropy_loss = -5.9994, learner_queue_size = 15, _tick = 33454, _time = 1.654e+09, train_seconds = 1.5618e+04)
[2022-05-31 18:30:44,586][root][INFO] - Step 103001600 @ 6940.4 SPS. Inference batcher size: 85. Learner queue size: 25. Other stats: (step = 103001600, mean_episode_return = 149.84, mean_episode_step = 673.27, total_loss = 274.65, pg_loss = 187.37, baseline_loss = 93.605, entropy_loss = -6.3177, learner_queue_size = 19, _tick = 33466, _time = 1.654e+09, train_seconds = 1.5623e+04)
[2022-05-31 18:30:49,590][root][INFO] - Step 103034880 @ 6650.7 SPS. Inference batcher size: 120. Learner queue size: 23. Other stats: (step = 103034880, mean_episode_return = 246.94, mean_episode_step = 521.37, total_loss = 218.65, pg_loss = 3.2397, baseline_loss = 220.84, entropy_loss = -5.4357, learner_queue_size = 19, _tick = 33479, _time = 1.654e+09, train_seconds = 1.5628e+04)
[2022-05-31 18:30:54,594][root][INFO] - Step 103065600 @ 6139.0 SPS. Inference batcher size: 90. Learner queue size: 25. Other stats: (step = 103065600, mean_episode_return = 163.34, mean_episode_step = 543.33, total_loss = 339.02, pg_loss = 193.1, baseline_loss = 151.2, entropy_loss = -5.2755, learner_queue_size = 21, _tick = 33490, _time = 1.654e+09, train_seconds = 1.5633e+04)
[2022-05-31 18:30:59,598][root][INFO] - Step 103098880 @ 6650.7 SPS. Inference batcher size: 33. Learner queue size: 17. Other stats: (step = 103098880, mean_episode_return = 479.84, mean_episode_step = 480.91, total_loss = -48.846, pg_loss = -279.79, baseline_loss = 236.64, entropy_loss = -5.6916, learner_queue_size = 20, _tick = 33502, _time = 1.654e+09, train_seconds = 1.5638e+04)
[2022-05-31 18:31:04,605][root][INFO] - Step 103132160 @ 6646.5 SPS. Inference batcher size: 100. Learner queue size: 23. Other stats: (step = 103132160, mean_episode_return = 280.48, mean_episode_step = 661.73, total_loss = 678.43, pg_loss = 481.65, baseline_loss = 203.18, entropy_loss = -6.3982, learner_queue_size = 17, _tick = 33514, _time = 1.654e+09, train_seconds = 1.5643e+04)
[2022-05-31 18:31:09,611][root][INFO] - Step 103165440 @ 6648.0 SPS. Inference batcher size: 113. Learner queue size: 16. Other stats: (step = 103165440, mean_episode_return = 84.83, mean_episode_step = 652.6, total_loss = -123.92, pg_loss = -198.85, baseline_loss = 81.383, entropy_loss = -6.4517, learner_queue_size = 13, _tick = 33526, _time = 1.654e+09, train_seconds = 1.5648e+04)
[2022-05-31 18:31:14,614][root][INFO] - Step 103198720 @ 6652.3 SPS. Inference batcher size: 164. Learner queue size: 9. Other stats: (step = 103198720, mean_episode_return = 454.0, mean_episode_step = 584.34, total_loss = 81.542, pg_loss = -169.98, baseline_loss = 257.87, entropy_loss = -6.3536, learner_queue_size = 14, _tick = 33535, _time = 1.654e+09, train_seconds = 1.5653e+04)
[2022-05-31 18:31:19,618][root][INFO] - Step 103232000 @ 6650.6 SPS. Inference batcher size: 96. Learner queue size: 3. Other stats: (step = 103232000, mean_episode_return = 269.97, mean_episode_step = 774.15, total_loss = -204.49, pg_loss = -238.17, baseline_loss = 39.969, entropy_loss = -6.2975, learner_queue_size = 16, _tick = 33548, _time = 1.654e+09, train_seconds = 1.5658e+04)
[2022-05-31 18:31:24,622][root][INFO] - Step 103265280 @ 6650.7 SPS. Inference batcher size: 120. Learner queue size: 30. Other stats: (step = 103265280, mean_episode_return = 168.59, mean_episode_step = 611.03, total_loss = 163.9, pg_loss = -32.426, baseline_loss = 202.07, entropy_loss = -5.7475, learner_queue_size = 14, _tick = 33556, _time = 1.654e+09, train_seconds = 1.5663e+04)
[2022-05-31 18:31:29,626][root][INFO] - Step 103296000 @ 6139.0 SPS. Inference batcher size: 53. Learner queue size: 27. Other stats: (step = 103296000, mean_episode_return = 459.56, mean_episode_step = 727.12, total_loss = -159.54, pg_loss = -266.96, baseline_loss = 113.49, entropy_loss = -6.0707, learner_queue_size = 17, _tick = 33567, _time = 1.654e+09, train_seconds = 1.5668e+04)
[2022-05-31 18:31:34,632][root][INFO] - Step 103329280 @ 6647.8 SPS. Inference batcher size: 166. Learner queue size: 13. Other stats: (step = 103329280, mean_episode_return = 161.92, mean_episode_step = 823.2, total_loss = -104.01, pg_loss = -143.73, baseline_loss = 46.005, entropy_loss = -6.2792, learner_queue_size = 14, _tick = 33578, _time = 1.654e+09, train_seconds = 1.5673e+04)
[2022-05-31 18:31:39,638][root][INFO] - Step 103362560 @ 6648.2 SPS. Inference batcher size: 131. Learner queue size: 10. Other stats: (step = 103362560, mean_episode_return = 142.05, mean_episode_step = 711.22, total_loss = 473.45, pg_loss = 279.86, baseline_loss = 199.99, entropy_loss = -6.4049, learner_queue_size = 21, _tick = 33590, _time = 1.654e+09, train_seconds = 1.5678e+04)
[2022-05-31 18:31:44,642][root][INFO] - Step 103395840 @ 6650.8 SPS. Inference batcher size: 42. Learner queue size: 5. Other stats: (step = 103395840, mean_episode_return = 178.19, mean_episode_step = 815.24, total_loss = 299.34, pg_loss = 110.65, baseline_loss = 194.92, entropy_loss = -6.2346, learner_queue_size = 19, _tick = 33601, _time = 1.654e+09, train_seconds = 1.5683e+04)
[2022-05-31 18:31:49,648][root][INFO] - Step 103429120 @ 6647.5 SPS. Inference batcher size: 139. Learner queue size: 24. Other stats: (step = 103429120, mean_episode_return = 187.78, mean_episode_step = 621.75, total_loss = -103.22, pg_loss = -153.07, baseline_loss = 55.807, entropy_loss = -5.9549, learner_queue_size = 21, _tick = 33612, _time = 1.654e+09, train_seconds = 1.5688e+04)
[2022-05-31 18:31:54,654][root][INFO] - Step 103462400 @ 6648.0 SPS. Inference batcher size: 96. Learner queue size: 15. Other stats: (step = 103462400, mean_episode_return = 180.01, mean_episode_step = 623.21, total_loss = 381.31, pg_loss = 233.71, baseline_loss = 153.69, entropy_loss = -6.0881, learner_queue_size = 19, _tick = 33622, _time = 1.654e+09, train_seconds = 1.5693e+04)
[2022-05-31 18:31:59,658][root][INFO] - Step 103495680 @ 6651.2 SPS. Inference batcher size: 116. Learner queue size: 4. Other stats: (step = 103495680, mean_episode_return = 136.7, mean_episode_step = 695.99, total_loss = 51.453, pg_loss = -24.749, baseline_loss = 82.628, entropy_loss = -6.4262, learner_queue_size = 17, _tick = 33635, _time = 1.654e+09, train_seconds = 1.5698e+04)
[2022-05-31 18:32:04,662][root][INFO] - Step 103528960 @ 6650.6 SPS. Inference batcher size: 106. Learner queue size: 31. Other stats: (step = 103528960, mean_episode_return = 120.25, mean_episode_step = 644.89, total_loss = -57.83, pg_loss = -141.78, baseline_loss = 90.47, entropy_loss = -6.5171, learner_queue_size = 15, _tick = 33648, _time = 1.654e+09, train_seconds = 1.5703e+04)
[2022-05-31 18:32:09,668][root][INFO] - Step 103559680 @ 6136.4 SPS. Inference batcher size: 139. Learner queue size: 15. Other stats: (step = 103559680, mean_episode_return = 36.49, mean_episode_step = 757.61, total_loss = 708.45, pg_loss = 327.77, baseline_loss = 386.4, entropy_loss = -5.7152, learner_queue_size = 16, _tick = 33658, _time = 1.654e+09, train_seconds = 1.5708e+04)
[2022-05-31 18:32:14,674][root][INFO] - Step 103592960 @ 6648.0 SPS. Inference batcher size: 165. Learner queue size: 17. Other stats: (step = 103592960, mean_episode_return = 98.059, mean_episode_step = 698.83, total_loss = 174.3, pg_loss = -15.863, baseline_loss = 196.06, entropy_loss = -5.8923, learner_queue_size = 14, _tick = 33671, _time = 1.654e+09, train_seconds = 1.5713e+04)
[2022-05-31 18:32:19,680][root][INFO] - Step 103626240 @ 6648.1 SPS. Inference batcher size: 162. Learner queue size: 7. Other stats: (step = 103626240, mean_episode_return = 350.54, mean_episode_step = 696.63, total_loss = 295.02, pg_loss = 139.06, baseline_loss = 161.91, entropy_loss = -5.9533, learner_queue_size = 27, _tick = 33681, _time = 1.654e+09, train_seconds = 1.5718e+04)
[2022-05-31 18:32:24,686][root][INFO] - Step 103659520 @ 6648.0 SPS. Inference batcher size: 102. Learner queue size: 13. Other stats: (step = 103659520, mean_episode_return = 197.63, mean_episode_step = 790.79, total_loss = -89.102, pg_loss = -260.52, baseline_loss = 177.28, entropy_loss = -5.8628, learner_queue_size = 21, _tick = 33693, _time = 1.654e+09, train_seconds = 1.5723e+04)
[2022-05-31 18:32:29,690][root][INFO] - Step 103692800 @ 6650.9 SPS. Inference batcher size: 104. Learner queue size: 8. Other stats: (step = 103692800, mean_episode_return = 114.27, mean_episode_step = 830.44, total_loss = -332.09, pg_loss = -431.57, baseline_loss = 106.01, entropy_loss = -6.5306, learner_queue_size = 16, _tick = 33705, _time = 1.654e+09, train_seconds = 1.5728e+04)
[2022-05-31 18:32:34,694][root][INFO] - Step 103726080 @ 6650.6 SPS. Inference batcher size: 133. Learner queue size: 3. Other stats: (step = 103726080, mean_episode_return = 96.675, mean_episode_step = 666.33, total_loss = 734.29, pg_loss = 494.21, baseline_loss = 246.67, entropy_loss = -6.5882, learner_queue_size = 22, _tick = 33718, _time = 1.654e+09, train_seconds = 1.5733e+04)
[2022-05-31 18:32:39,698][root][INFO] - Step 103759360 @ 6650.7 SPS. Inference batcher size: 122. Learner queue size: 0. Other stats: (step = 103759360, mean_episode_return = 532.16, mean_episode_step = 755.01, total_loss = -142.18, pg_loss = -256.96, baseline_loss = 120.84, entropy_loss = -6.0689, learner_queue_size = 18, _tick = 33729, _time = 1.654e+09, train_seconds = 1.5738e+04)
[2022-05-31 18:32:44,702][root][INFO] - Step 103792640 @ 6650.6 SPS. Inference batcher size: 109. Learner queue size: 28. Other stats: (step = 103792640, mean_episode_return = 294.62, mean_episode_step = 744.16, total_loss = -136.38, pg_loss = -231.48, baseline_loss = 101.7, entropy_loss = -6.601, learner_queue_size = 18, _tick = 33739, _time = 1.654e+09, train_seconds = 1.5743e+04)
[2022-05-31 18:32:49,706][root][INFO] - Step 103823360 @ 6139.1 SPS. Inference batcher size: 164. Learner queue size: 17. Other stats: (step = 103823360, mean_episode_return = 487.64, mean_episode_step = 804.35, total_loss = -67.091, pg_loss = -108.45, baseline_loss = 47.702, entropy_loss = -6.3449, learner_queue_size = 22, _tick = 33750, _time = 1.654e+09, train_seconds = 1.5748e+04)
[2022-05-31 18:32:54,710][root][INFO] - Step 103856640 @ 6650.7 SPS. Inference batcher size: 120. Learner queue size: 9. Other stats: (step = 103856640, mean_episode_return = 243.05, mean_episode_step = 664.58, total_loss = 299.22, pg_loss = 171.78, baseline_loss = 133.84, entropy_loss = -6.4066, learner_queue_size = 18, _tick = 33762, _time = 1.654e+09, train_seconds = 1.5753e+04)
[2022-05-31 18:32:59,714][root][INFO] - Step 103889920 @ 6650.8 SPS. Inference batcher size: 27. Learner queue size: 4. Other stats: (step = 103889920, mean_episode_return = None, mean_episode_step = 632.84, total_loss = 450.37, pg_loss = 270.73, baseline_loss = 185.81, entropy_loss = -6.1708, learner_queue_size = 11, _tick = 33773, _time = 1.654e+09, train_seconds = 1.5758e+04)
[2022-05-31 18:33:04,718][root][INFO] - Step 103923200 @ 6650.6 SPS. Inference batcher size: 135. Learner queue size: 31. Other stats: (step = 103923200, mean_episode_return = 249.48, mean_episode_step = 677.86, total_loss = -28.108, pg_loss = -168.57, baseline_loss = 146.22, entropy_loss = -5.7605, learner_queue_size = 18, _tick = 33784, _time = 1.654e+09, train_seconds = 1.5763e+04)
[2022-05-31 18:33:09,722][root][INFO] - Step 103956480 @ 6650.7 SPS. Inference batcher size: 80. Learner queue size: 3. Other stats: (step = 103956480, mean_episode_return = 551.93, mean_episode_step = 749.47, total_loss = 274.06, pg_loss = 122.79, baseline_loss = 157.4, entropy_loss = -6.1241, learner_queue_size = 24, _tick = 33794, _time = 1.654e+09, train_seconds = 1.5768e+04)
[2022-05-31 18:33:14,728][root][INFO] - Step 103987200 @ 6136.4 SPS. Inference batcher size: 123. Learner queue size: 27. Other stats: (step = 103987200, mean_episode_return = 196.81, mean_episode_step = 597.38, total_loss = -254.87, pg_loss = -411.86, baseline_loss = 162.97, entropy_loss = -5.9894, learner_queue_size = 23, _tick = 33805, _time = 1.654e+09, train_seconds = 1.5773e+04)
[2022-05-31 18:33:19,734][root][INFO] - Step 104020480 @ 6648.2 SPS. Inference batcher size: 62. Learner queue size: 20. Other stats: (step = 104020480, mean_episode_return = 113.97, mean_episode_step = 621.35, total_loss = 349.78, pg_loss = 178.57, baseline_loss = 177.15, entropy_loss = -5.9475, learner_queue_size = 23, _tick = 33818, _time = 1.654e+09, train_seconds = 1.5778e+04)
[2022-05-31 18:33:24,738][root][INFO] - Step 104053760 @ 6650.7 SPS. Inference batcher size: 96. Learner queue size: 25. Other stats: (step = 104053760, mean_episode_return = 623.56, mean_episode_step = 788.85, total_loss = 537.51, pg_loss = 340.89, baseline_loss = 202.69, entropy_loss = -6.065, learner_queue_size = 18, _tick = 33829, _time = 1.654e+09, train_seconds = 1.5783e+04)
[2022-05-31 18:33:29,742][root][INFO] - Step 104087040 @ 6650.6 SPS. Inference batcher size: 170. Learner queue size: 17. Other stats: (step = 104087040, mean_episode_return = 56.371, mean_episode_step = 739.45, total_loss = 37.856, pg_loss = -119.49, baseline_loss = 163.4, entropy_loss = -6.0514, learner_queue_size = 23, _tick = 33841, _time = 1.654e+09, train_seconds = 1.5788e+04)
[2022-05-31 18:33:34,748][root][INFO] - Step 104120320 @ 6647.9 SPS. Inference batcher size: 104. Learner queue size: 23. Other stats: (step = 104120320, mean_episode_return = 144.14, mean_episode_step = 665.96, total_loss = 332.06, pg_loss = 237.72, baseline_loss = 101.09, entropy_loss = -6.7478, learner_queue_size = 23, _tick = 33854, _time = 1.654e+09, train_seconds = 1.5793e+04)
[2022-05-31 18:33:39,750][root][INFO] - Step 104153600 @ 6653.6 SPS. Inference batcher size: 35. Learner queue size: 4. Other stats: (step = 104153600, mean_episode_return = 521.67, mean_episode_step = 703.15, total_loss = 402.31, pg_loss = -126.39, baseline_loss = 535.04, entropy_loss = -6.343, learner_queue_size = 26, _tick = 33865, _time = 1.654e+09, train_seconds = 1.5798e+04)
[2022-05-31 18:33:44,754][root][INFO] - Step 104186880 @ 6650.6 SPS. Inference batcher size: 86. Learner queue size: 9. Other stats: (step = 104186880, mean_episode_return = 220.59, mean_episode_step = 586.68, total_loss = 349.01, pg_loss = 98.098, baseline_loss = 256.6, entropy_loss = -5.6838, learner_queue_size = 22, _tick = 33878, _time = 1.654e+09, train_seconds = 1.5803e+04)
[2022-05-31 18:33:49,758][root][INFO] - Step 104220160 @ 6650.7 SPS. Inference batcher size: 69. Learner queue size: 10. Other stats: (step = 104220160, mean_episode_return = None, mean_episode_step = 553.88, total_loss = -17.334, pg_loss = -87.777, baseline_loss = 76.526, entropy_loss = -6.0837, learner_queue_size = 26, _tick = 33885, _time = 1.654e+09, train_seconds = 1.5808e+04)
[2022-05-31 18:33:54,762][root][INFO] - Step 104253440 @ 6650.7 SPS. Inference batcher size: 140. Learner queue size: 0. Other stats: (step = 104253440, mean_episode_return = 76.71, mean_episode_step = 692.6, total_loss = 4.8543, pg_loss = -36.943, baseline_loss = 48.192, entropy_loss = -6.3953, learner_queue_size = 24, _tick = 33896, _time = 1.654e+09, train_seconds = 1.5813e+04)
[2022-05-31 18:33:59,766][root][INFO] - Step 104286720 @ 6650.7 SPS. Inference batcher size: 107. Learner queue size: 3. Other stats: (step = 104286720, mean_episode_return = 391.78, mean_episode_step = 652.16, total_loss = 166.63, pg_loss = 87.178, baseline_loss = 85.481, entropy_loss = -6.0277, learner_queue_size = 22, _tick = 33909, _time = 1.654e+09, train_seconds = 1.5818e+04)
[2022-05-31 18:34:04,770][root][INFO] - Step 104320000 @ 6650.8 SPS. Inference batcher size: 34. Learner queue size: 15. Other stats: (step = 104320000, mean_episode_return = 171.09, mean_episode_step = 739.89, total_loss = 512.57, pg_loss = 299.87, baseline_loss = 218.55, entropy_loss = -5.8553, learner_queue_size = 10, _tick = 33922, _time = 1.654e+09, train_seconds = 1.5824e+04)
[2022-05-31 18:34:09,774][root][INFO] - Step 104353280 @ 6650.7 SPS. Inference batcher size: 120. Learner queue size: 18. Other stats: (step = 104353280, mean_episode_return = 342.7, mean_episode_step = 554.59, total_loss = -116.85, pg_loss = -203.88, baseline_loss = 93.048, entropy_loss = -6.0101, learner_queue_size = 16, _tick = 33935, _time = 1.654e+09, train_seconds = 1.5828e+04)
[2022-05-31 18:34:14,778][root][INFO] - Step 104386560 @ 6650.7 SPS. Inference batcher size: 156. Learner queue size: 30. Other stats: (step = 104386560, mean_episode_return = 240.27, mean_episode_step = 701.85, total_loss = -463.67, pg_loss = -665.92, baseline_loss = 208.42, entropy_loss = -6.1737, learner_queue_size = 25, _tick = 33947, _time = 1.654e+09, train_seconds = 1.5834e+04)
[2022-05-31 18:34:19,784][root][INFO] - Step 104417280 @ 6136.6 SPS. Inference batcher size: 138. Learner queue size: 17. Other stats: (step = 104417280, mean_episode_return = 246.6, mean_episode_step = 707.04, total_loss = 151.27, pg_loss = -136.22, baseline_loss = 293.68, entropy_loss = -6.1829, learner_queue_size = 18, _tick = 33959, _time = 1.654e+09, train_seconds = 1.5838e+04)
[2022-05-31 18:34:24,790][root][INFO] - Step 104450560 @ 6648.1 SPS. Inference batcher size: 87. Learner queue size: 16. Other stats: (step = 104450560, mean_episode_return = 70.771, mean_episode_step = 543.9, total_loss = 422.11, pg_loss = 210.75, baseline_loss = 216.71, entropy_loss = -5.3578, learner_queue_size = 17, _tick = 33972, _time = 1.654e+09, train_seconds = 1.5844e+04)
[2022-05-31 18:34:29,796][root][INFO] - Step 104483840 @ 6648.0 SPS. Inference batcher size: 52. Learner queue size: 14. Other stats: (step = 104483840, mean_episode_return = 638.44, mean_episode_step = 658.28, total_loss = -99.202, pg_loss = -381.08, baseline_loss = 287.43, entropy_loss = -5.5487, learner_queue_size = 9, _tick = 33982, _time = 1.654e+09, train_seconds = 1.5848e+04)
[2022-05-31 18:34:34,802][root][INFO] - Step 104517120 @ 6648.0 SPS. Inference batcher size: 64. Learner queue size: 9. Other stats: (step = 104517120, mean_episode_return = 265.48, mean_episode_step = 595.06, total_loss = 282.27, pg_loss = 95.782, baseline_loss = 192.26, entropy_loss = -5.774, learner_queue_size = 19, _tick = 33994, _time = 1.654e+09, train_seconds = 1.5854e+04)
[2022-05-31 18:34:39,806][root][INFO] - Step 104550400 @ 6650.7 SPS. Inference batcher size: 8. Learner queue size: 6. Other stats: (step = 104550400, mean_episode_return = 152.5, mean_episode_step = 788.6, total_loss = 434.94, pg_loss = 139.2, baseline_loss = 301.81, entropy_loss = -6.0675, learner_queue_size = 21, _tick = 34007, _time = 1.654e+09, train_seconds = 1.5858e+04)
[2022-05-31 18:34:44,810][root][INFO] - Step 104583680 @ 6650.7 SPS. Inference batcher size: 115. Learner queue size: 23. Other stats: (step = 104583680, mean_episode_return = 62.0, mean_episode_step = 748.15, total_loss = -303.42, pg_loss = -321.2, baseline_loss = 24.533, entropy_loss = -6.7464, learner_queue_size = 11, _tick = 34019, _time = 1.654e+09, train_seconds = 1.5864e+04)
[2022-05-31 18:34:49,814][root][INFO] - Step 104616960 @ 6650.7 SPS. Inference batcher size: 144. Learner queue size: 17. Other stats: (step = 104616960, mean_episode_return = 197.33, mean_episode_step = 770.37, total_loss = -183.2, pg_loss = -198.81, baseline_loss = 22.403, entropy_loss = -6.7943, learner_queue_size = 17, _tick = 34032, _time = 1.654e+09, train_seconds = 1.5868e+04)
[2022-05-31 18:34:54,820][root][INFO] - Step 104647680 @ 6136.9 SPS. Inference batcher size: 135. Learner queue size: 16. Other stats: (step = 104647680, mean_episode_return = 240.62, mean_episode_step = 771.98, total_loss = 65.706, pg_loss = -4.4215, baseline_loss = 77.118, entropy_loss = -6.9908, learner_queue_size = 18, _tick = 34042, _time = 1.654e+09, train_seconds = 1.5874e+04)
[2022-05-31 18:34:59,822][root][INFO] - Step 104680960 @ 6653.0 SPS. Inference batcher size: 108. Learner queue size: 9. Other stats: (step = 104680960, mean_episode_return = 978.77, mean_episode_step = 652.51, total_loss = 215.74, pg_loss = 141.47, baseline_loss = 80.31, entropy_loss = -6.0364, learner_queue_size = 21, _tick = 34053, _time = 1.654e+09, train_seconds = 1.5878e+04)
[2022-05-31 18:35:04,828][root][INFO] - Step 104714240 @ 6648.0 SPS. Inference batcher size: 181. Learner queue size: 12. Other stats: (step = 104714240, mean_episode_return = 127.7, mean_episode_step = 883.97, total_loss = 203.26, pg_loss = 138.49, baseline_loss = 70.553, entropy_loss = -5.7837, learner_queue_size = 22, _tick = 34065, _time = 1.654e+09, train_seconds = 1.5884e+04)
[2022-05-31 18:35:09,833][root][INFO] - Step 104747520 @ 6649.3 SPS. Inference batcher size: 84. Learner queue size: 1. Other stats: (step = 104747520, mean_episode_return = 112.72, mean_episode_step = 572.08, total_loss = -139.94, pg_loss = -182.12, baseline_loss = 48.419, entropy_loss = -6.2361, learner_queue_size = 10, _tick = 34078, _time = 1.654e+09, train_seconds = 1.5888e+04)
[2022-05-31 18:35:14,838][root][INFO] - Step 104780800 @ 6649.4 SPS. Inference batcher size: 94. Learner queue size: 21. Other stats: (step = 104780800, mean_episode_return = None, mean_episode_step = 679.62, total_loss = 184.5, pg_loss = 90.937, baseline_loss = 99.49, entropy_loss = -5.9281, learner_queue_size = 14, _tick = 34089, _time = 1.654e+09, train_seconds = 1.5894e+04)
[2022-05-31 18:35:19,842][root][INFO] - Step 104811520 @ 6139.2 SPS. Inference batcher size: 61. Learner queue size: 22. Other stats: (step = 104811520, mean_episode_return = 128.24, mean_episode_step = 514.34, total_loss = -153.55, pg_loss = -181.25, baseline_loss = 33.599, entropy_loss = -5.8994, learner_queue_size = 23, _tick = 34101, _time = 1.654e+09, train_seconds = 1.5898e+04)
[2022-05-31 18:35:24,846][root][INFO] - Step 104847360 @ 7162.3 SPS. Inference batcher size: 26. Learner queue size: 27. Other stats: (step = 104847360, mean_episode_return = 342.17, mean_episode_step = 639.28, total_loss = 1165.5, pg_loss = 581.97, baseline_loss = 589.74, entropy_loss = -6.2623, learner_queue_size = 23, _tick = 34113, _time = 1.654e+09, train_seconds = 1.5904e+04)
[2022-05-31 18:35:29,853][root][INFO] - Step 104878080 @ 6135.4 SPS. Inference batcher size: 112. Learner queue size: 13. Other stats: (step = 104878080, mean_episode_return = 202.69, mean_episode_step = 672.82, total_loss = 66.323, pg_loss = -90.359, baseline_loss = 162.33, entropy_loss = -5.653, learner_queue_size = 16, _tick = 34125, _time = 1.654e+09, train_seconds = 1.5908e+04)
[2022-05-31 18:35:34,858][root][INFO] - Step 104911360 @ 6649.3 SPS. Inference batcher size: 208. Learner queue size: 8. Other stats: (step = 104911360, mean_episode_return = 268.67, mean_episode_step = 656.62, total_loss = 575.98, pg_loss = 436.86, baseline_loss = 145.51, entropy_loss = -6.3872, learner_queue_size = 14, _tick = 34138, _time = 1.654e+09, train_seconds = 1.5914e+04)
[2022-05-31 18:35:39,862][root][INFO] - Step 104944640 @ 6650.7 SPS. Inference batcher size: 32. Learner queue size: 5. Other stats: (step = 104944640, mean_episode_return = 260.86, mean_episode_step = 508.67, total_loss = 251.61, pg_loss = 140.07, baseline_loss = 117.54, entropy_loss = -6.0078, learner_queue_size = 16, _tick = 34149, _time = 1.654e+09, train_seconds = 1.5918e+04)
[2022-05-31 18:35:44,866][root][INFO] - Step 104977920 @ 6650.7 SPS. Inference batcher size: 61. Learner queue size: 3. Other stats: (step = 104977920, mean_episode_return = 149.63, mean_episode_step = 705.55, total_loss = -116.18, pg_loss = -223.85, baseline_loss = 113.46, entropy_loss = -5.7872, learner_queue_size = 22, _tick = 34162, _time = 1.654e+09, train_seconds = 1.5924e+04)
[2022-05-31 18:35:49,870][root][INFO] - Step 105011200 @ 6650.6 SPS. Inference batcher size: 146. Learner queue size: 31. Other stats: (step = 105011200, mean_episode_return = 72.57, mean_episode_step = 706.64, total_loss = 204.23, pg_loss = 91.158, baseline_loss = 119.28, entropy_loss = -6.2087, learner_queue_size = 15, _tick = 34171, _time = 1.654e+09, train_seconds = 1.5929e+04)
[2022-05-31 18:35:54,876][root][INFO] - Step 105044480 @ 6648.0 SPS. Inference batcher size: 108. Learner queue size: 3. Other stats: (step = 105044480, mean_episode_return = 186.19, mean_episode_step = 830.82, total_loss = -83.248, pg_loss = -129.64, baseline_loss = 52.943, entropy_loss = -6.5534, learner_queue_size = 11, _tick = 34182, _time = 1.654e+09, train_seconds = 1.5934e+04)
[2022-05-31 18:35:59,882][root][INFO] - Step 105077760 @ 6648.1 SPS. Inference batcher size: 101. Learner queue size: 1. Other stats: (step = 105077760, mean_episode_return = 186.04, mean_episode_step = 686.14, total_loss = 87.772, pg_loss = 12.507, baseline_loss = 81.204, entropy_loss = -5.9389, learner_queue_size = 27, _tick = 34194, _time = 1.654e+09, train_seconds = 1.5939e+04)
[2022-05-31 18:36:04,886][root][INFO] - Step 105111040 @ 6650.6 SPS. Inference batcher size: 51. Learner queue size: 7. Other stats: (step = 105111040, mean_episode_return = 166.32, mean_episode_step = 788.26, total_loss = 57.163, pg_loss = 4.1139, baseline_loss = 59.007, entropy_loss = -5.9577, learner_queue_size = 19, _tick = 34207, _time = 1.654e+09, train_seconds = 1.5944e+04)
[2022-05-31 18:36:09,892][root][INFO] - Step 105144320 @ 6647.8 SPS. Inference batcher size: 117. Learner queue size: 21. Other stats: (step = 105144320, mean_episode_return = 141.76, mean_episode_step = 625.58, total_loss = 270.01, pg_loss = 22.163, baseline_loss = 253.82, entropy_loss = -5.9706, learner_queue_size = 21, _tick = 34220, _time = 1.654e+09, train_seconds = 1.5949e+04)
[2022-05-31 18:36:14,898][root][INFO] - Step 105175040 @ 6136.7 SPS. Inference batcher size: 143. Learner queue size: 18. Other stats: (step = 105175040, mean_episode_return = None, mean_episode_step = 484.38, total_loss = 625.33, pg_loss = 437.58, baseline_loss = 192.9, entropy_loss = -5.1517, learner_queue_size = 14, _tick = 34230, _time = 1.654e+09, train_seconds = 1.5954e+04)
[2022-05-31 18:36:19,904][root][INFO] - Step 105210880 @ 7159.3 SPS. Inference batcher size: 148. Learner queue size: 18. Other stats: (step = 105210880, mean_episode_return = 99.698, mean_episode_step = 728.13, total_loss = 58.774, pg_loss = -34.608, baseline_loss = 98.813, entropy_loss = -5.4316, learner_queue_size = 14, _tick = 34243, _time = 1.654e+09, train_seconds = 1.5959e+04)
[2022-05-31 18:36:24,910][root][INFO] - Step 105241600 @ 6136.5 SPS. Inference batcher size: 95. Learner queue size: 10. Other stats: (step = 105241600, mean_episode_return = 398.3, mean_episode_step = 776.2, total_loss = 94.208, pg_loss = 16.996, baseline_loss = 83.008, entropy_loss = -5.7966, learner_queue_size = 22, _tick = 34255, _time = 1.654e+09, train_seconds = 1.5964e+04)
[2022-05-31 18:36:29,914][root][INFO] - Step 105274880 @ 6651.0 SPS. Inference batcher size: 122. Learner queue size: 4. Other stats: (step = 105274880, mean_episode_return = 223.25, mean_episode_step = 589.76, total_loss = 22.681, pg_loss = -34.241, baseline_loss = 63.019, entropy_loss = -6.097, learner_queue_size = 21, _tick = 34267, _time = 1.654e+09, train_seconds = 1.5969e+04)
[2022-05-31 18:36:34,922][root][INFO] - Step 105308160 @ 6645.3 SPS. Inference batcher size: 139. Learner queue size: 6. Other stats: (step = 105308160, mean_episode_return = 173.21, mean_episode_step = 864.45, total_loss = 114.45, pg_loss = 69.667, baseline_loss = 51.342, entropy_loss = -6.5593, learner_queue_size = 16, _tick = 34278, _time = 1.654e+09, train_seconds = 1.5974e+04)
[2022-05-31 18:36:39,930][root][INFO] - Step 105341440 @ 6645.3 SPS. Inference batcher size: 102. Learner queue size: 23. Other stats: (step = 105341440, mean_episode_return = 288.08, mean_episode_step = 594.0, total_loss = 247.13, pg_loss = 182.74, baseline_loss = 70.86, entropy_loss = -6.4716, learner_queue_size = 20, _tick = 34290, _time = 1.654e+09, train_seconds = 1.5979e+04)
[2022-05-31 18:36:44,934][root][INFO] - Step 105374720 @ 6650.9 SPS. Inference batcher size: 92. Learner queue size: 0. Other stats: (step = 105374720, mean_episode_return = 353.27, mean_episode_step = 725.94, total_loss = 17.674, pg_loss = -72.509, baseline_loss = 96.348, entropy_loss = -6.1652, learner_queue_size = 27, _tick = 34302, _time = 1.654e+09, train_seconds = 1.5984e+04)
[2022-05-31 18:36:49,938][root][INFO] - Step 105405440 @ 6139.0 SPS. Inference batcher size: 65. Learner queue size: 16. Other stats: (step = 105405440, mean_episode_return = 253.15, mean_episode_step = 869.37, total_loss = 245.09, pg_loss = 116.24, baseline_loss = 134.29, entropy_loss = -5.4324, learner_queue_size = 13, _tick = 34312, _time = 1.654e+09, train_seconds = 1.5989e+04)
[2022-05-31 18:36:54,942][root][INFO] - Step 105438720 @ 6650.7 SPS. Inference batcher size: 88. Learner queue size: 15. Other stats: (step = 105438720, mean_episode_return = 137.28, mean_episode_step = 572.34, total_loss = 303.94, pg_loss = 115.76, baseline_loss = 193.97, entropy_loss = -5.7839, learner_queue_size = 19, _tick = 34324, _time = 1.654e+09, train_seconds = 1.5994e+04)
[2022-05-31 18:36:59,946][root][INFO] - Step 105472000 @ 6650.6 SPS. Inference batcher size: 121. Learner queue size: 10. Other stats: (step = 105472000, mean_episode_return = 235.39, mean_episode_step = 450.99, total_loss = 32.833, pg_loss = -27.082, baseline_loss = 64.937, entropy_loss = -5.0216, learner_queue_size = 19, _tick = 34337, _time = 1.654e+09, train_seconds = 1.5999e+04)
[2022-05-31 18:37:04,948][root][INFO] - Step 105505280 @ 6653.4 SPS. Inference batcher size: 77. Learner queue size: 1. Other stats: (step = 105505280, mean_episode_return = 165.9, mean_episode_step = 521.19, total_loss = -74.647, pg_loss = -176.36, baseline_loss = 107.26, entropy_loss = -5.5443, learner_queue_size = 22, _tick = 34349, _time = 1.654e+09, train_seconds = 1.6004e+04)
[2022-05-31 18:37:09,950][root][INFO] - Step 105538560 @ 6653.3 SPS. Inference batcher size: 120. Learner queue size: 4. Other stats: (step = 105538560, mean_episode_return = 341.26, mean_episode_step = 564.32, total_loss = 777.05, pg_loss = 427.22, baseline_loss = 355.33, entropy_loss = -5.5045, learner_queue_size = 18, _tick = 34362, _time = 1.654e+09, train_seconds = 1.6009e+04)
[2022-05-31 18:37:14,954][root][INFO] - Step 105571840 @ 6650.8 SPS. Inference batcher size: 33. Learner queue size: 25. Other stats: (step = 105571840, mean_episode_return = 217.44, mean_episode_step = 698.02, total_loss = 246.41, pg_loss = 142.42, baseline_loss = 109.6, entropy_loss = -5.6224, learner_queue_size = 25, _tick = 34374, _time = 1.654e+09, train_seconds = 1.6014e+04)
[2022-05-31 18:37:19,961][root][INFO] - Step 105605120 @ 6647.0 SPS. Inference batcher size: 43. Learner queue size: 20. Other stats: (step = 105605120, mean_episode_return = 267.32, mean_episode_step = 582.1, total_loss = 369.23, pg_loss = 118.16, baseline_loss = 256.88, entropy_loss = -5.8111, learner_queue_size = 20, _tick = 34386, _time = 1.654e+09, train_seconds = 1.6019e+04)
[2022-05-31 18:37:24,966][root][INFO] - Step 105638400 @ 6649.0 SPS. Inference batcher size: 79. Learner queue size: 15. Other stats: (step = 105638400, mean_episode_return = 63.14, mean_episode_step = 673.26, total_loss = -156.41, pg_loss = -197.81, baseline_loss = 47.342, entropy_loss = -5.9409, learner_queue_size = 15, _tick = 34396, _time = 1.654e+09, train_seconds = 1.6024e+04)
[2022-05-31 18:37:29,970][root][INFO] - Step 105669120 @ 6139.0 SPS. Inference batcher size: 51. Learner queue size: 5. Other stats: (step = 105669120, mean_episode_return = 154.17, mean_episode_step = 686.88, total_loss = -138.8, pg_loss = -250.06, baseline_loss = 117.51, entropy_loss = -6.2498, learner_queue_size = 16, _tick = 34405, _time = 1.654e+09, train_seconds = 1.6029e+04)
[2022-05-31 18:37:34,974][root][INFO] - Step 105702400 @ 6650.8 SPS. Inference batcher size: 116. Learner queue size: 14. Other stats: (step = 105702400, mean_episode_return = 306.47, mean_episode_step = 565.23, total_loss = 65.695, pg_loss = 18.811, baseline_loss = 53.205, entropy_loss = -6.3206, learner_queue_size = 13, _tick = 34415, _time = 1.654e+09, train_seconds = 1.6034e+04)
[2022-05-31 18:37:39,977][root][INFO] - Step 105735680 @ 6651.6 SPS. Inference batcher size: 140. Learner queue size: 8. Other stats: (step = 105735680, mean_episode_return = 237.2, mean_episode_step = 581.72, total_loss = 283.04, pg_loss = 201.86, baseline_loss = 87.45, entropy_loss = -6.2678, learner_queue_size = 29, _tick = 34426, _time = 1.654e+09, train_seconds = 1.6039e+04)
[2022-05-31 18:37:44,982][root][INFO] - Step 105768960 @ 6649.8 SPS. Inference batcher size: 107. Learner queue size: 1. Other stats: (step = 105768960, mean_episode_return = 335.76, mean_episode_step = 625.57, total_loss = 205.84, pg_loss = 134.54, baseline_loss = 77.371, entropy_loss = -6.0628, learner_queue_size = 14, _tick = 34439, _time = 1.654e+09, train_seconds = 1.6044e+04)
[2022-05-31 18:37:49,986][root][INFO] - Step 105802240 @ 6650.7 SPS. Inference batcher size: 71. Learner queue size: 4. Other stats: (step = 105802240, mean_episode_return = 345.71, mean_episode_step = 732.39, total_loss = 53.687, pg_loss = -31.673, baseline_loss = 91.06, entropy_loss = -5.7008, learner_queue_size = 20, _tick = 34452, _time = 1.654e+09, train_seconds = 1.6049e+04)
[2022-05-31 18:37:54,990][root][INFO] - Step 105835520 @ 6650.7 SPS. Inference batcher size: 41. Learner queue size: 27. Other stats: (step = 105835520, mean_episode_return = 330.1, mean_episode_step = 588.15, total_loss = 199.78, pg_loss = 90.375, baseline_loss = 114.95, entropy_loss = -5.5474, learner_queue_size = 20, _tick = 34463, _time = 1.654e+09, train_seconds = 1.6054e+04)
[2022-05-31 18:37:59,994][root][INFO] - Step 105868800 @ 6650.7 SPS. Inference batcher size: 26. Learner queue size: 21. Other stats: (step = 105868800, mean_episode_return = 238.59, mean_episode_step = 742.05, total_loss = -71.04, pg_loss = -166.64, baseline_loss = 101.47, entropy_loss = -5.8708, learner_queue_size = 16, _tick = 34475, _time = 1.654e+09, train_seconds = 1.6059e+04)
[2022-05-31 18:38:05,001][root][INFO] - Step 105902080 @ 6646.6 SPS. Inference batcher size: 17. Learner queue size: 18. Other stats: (step = 105902080, mean_episode_return = 131.82, mean_episode_step = 698.88, total_loss = 153.8, pg_loss = 81.954, baseline_loss = 78.119, entropy_loss = -6.271, learner_queue_size = 18, _tick = 34487, _time = 1.654e+09, train_seconds = 1.6064e+04)
[2022-05-31 18:38:10,006][root][INFO] - Step 105932800 @ 6138.0 SPS. Inference batcher size: 31. Learner queue size: 9. Other stats: (step = 105932800, mean_episode_return = 118.45, mean_episode_step = 427.75, total_loss = 225.64, pg_loss = -26.898, baseline_loss = 258.35, entropy_loss = -5.8105, learner_queue_size = 21, _tick = 34499, _time = 1.654e+09, train_seconds = 1.6069e+04)
[2022-05-31 18:38:15,013][root][INFO] - Step 105966080 @ 6646.3 SPS. Inference batcher size: 104. Learner queue size: 12. Other stats: (step = 105966080, mean_episode_return = 165.03, mean_episode_step = 596.67, total_loss = 286.92, pg_loss = 168.81, baseline_loss = 124.27, entropy_loss = -6.1624, learner_queue_size = 20, _tick = 34510, _time = 1.654e+09, train_seconds = 1.6074e+04)
[2022-05-31 18:38:20,018][root][INFO] - Step 105999360 @ 6649.7 SPS. Inference batcher size: 41. Learner queue size: 2. Other stats: (step = 105999360, mean_episode_return = 158.63, mean_episode_step = 658.62, total_loss = 398.01, pg_loss = 229.09, baseline_loss = 174.71, entropy_loss = -5.7876, learner_queue_size = 23, _tick = 34522, _time = 1.654e+09, train_seconds = 1.6079e+04)
[2022-05-31 18:38:25,022][root][INFO] - Step 106032640 @ 6650.8 SPS. Inference batcher size: 162. Learner queue size: 0. Other stats: (step = 106032640, mean_episode_return = 101.34, mean_episode_step = 579.4, total_loss = -66.511, pg_loss = -123.98, baseline_loss = 63.535, entropy_loss = -6.0614, learner_queue_size = 15, _tick = 34533, _time = 1.654e+09, train_seconds = 1.6084e+04)
[2022-05-31 18:38:30,028][root][INFO] - Step 106063360 @ 6137.1 SPS. Inference batcher size: 190. Learner queue size: 22. Other stats: (step = 106063360, mean_episode_return = 123.49, mean_episode_step = 598.01, total_loss = -173.37, pg_loss = -240.24, baseline_loss = 73.024, entropy_loss = -6.1452, learner_queue_size = 26, _tick = 34543, _time = 1.654e+09, train_seconds = 1.6089e+04)
[2022-05-31 18:38:35,034][root][INFO] - Step 106099200 @ 7158.9 SPS. Inference batcher size: 77. Learner queue size: 13. Other stats: (step = 106099200, mean_episode_return = 208.03, mean_episode_step = 625.39, total_loss = 834.04, pg_loss = 587.7, baseline_loss = 252.39, entropy_loss = -6.0414, learner_queue_size = 13, _tick = 34554, _time = 1.654e+09, train_seconds = 1.6094e+04)
[2022-05-31 18:38:40,040][root][INFO] - Step 106129920 @ 6136.2 SPS. Inference batcher size: 96. Learner queue size: 17. Other stats: (step = 106129920, mean_episode_return = None, mean_episode_step = 746.31, total_loss = 106.23, pg_loss = 29.202, baseline_loss = 83.382, entropy_loss = -6.3546, learner_queue_size = 12, _tick = 34564, _time = 1.654e+09, train_seconds = 1.6099e+04)
[2022-05-31 18:38:45,046][root][INFO] - Step 106163200 @ 6648.5 SPS. Inference batcher size: 65. Learner queue size: 8. Other stats: (step = 106163200, mean_episode_return = 208.73, mean_episode_step = 573.1, total_loss = -110.19, pg_loss = -147.95, baseline_loss = 43.921, entropy_loss = -6.1602, learner_queue_size = 14, _tick = 34576, _time = 1.654e+09, train_seconds = 1.6104e+04)
[2022-05-31 18:38:50,050][root][INFO] - Step 106196480 @ 6650.6 SPS. Inference batcher size: 114. Learner queue size: 2. Other stats: (step = 106196480, mean_episode_return = 545.92, mean_episode_step = 528.03, total_loss = -43.417, pg_loss = -97.061, baseline_loss = 59.851, entropy_loss = -6.2068, learner_queue_size = 13, _tick = 34589, _time = 1.654e+09, train_seconds = 1.6109e+04)
[2022-05-31 18:38:55,054][root][INFO] - Step 106229760 @ 6650.2 SPS. Inference batcher size: 32. Learner queue size: 27. Other stats: (step = 106229760, mean_episode_return = 184.2, mean_episode_step = 553.48, total_loss = 71.745, pg_loss = 6.1089, baseline_loss = 71.46, entropy_loss = -5.8238, learner_queue_size = 26, _tick = 34602, _time = 1.654e+09, train_seconds = 1.6114e+04)
[2022-05-31 18:39:00,061][root][INFO] - Step 106260480 @ 6136.1 SPS. Inference batcher size: 138. Learner queue size: 17. Other stats: (step = 106260480, mean_episode_return = 411.37, mean_episode_step = 589.4, total_loss = -209.39, pg_loss = -466.44, baseline_loss = 263.07, entropy_loss = -6.0244, learner_queue_size = 20, _tick = 34611, _time = 1.654e+09, train_seconds = 1.6119e+04)
[2022-05-31 18:39:05,067][root][INFO] - Step 106293760 @ 6647.9 SPS. Inference batcher size: 114. Learner queue size: 21. Other stats: (step = 106293760, mean_episode_return = None, mean_episode_step = 621.09, total_loss = 72.363, pg_loss = -34.316, baseline_loss = 113.2, entropy_loss = -6.5211, learner_queue_size = 16, _tick = 34622, _time = 1.654e+09, train_seconds = 1.6124e+04)
[2022-05-31 18:39:10,073][root][INFO] - Step 106327040 @ 6648.0 SPS. Inference batcher size: 34. Learner queue size: 3. Other stats: (step = 106327040, mean_episode_return = None, mean_episode_step = 683.56, total_loss = 1269.2, pg_loss = 701.31, baseline_loss = 574.13, entropy_loss = -6.2752, learner_queue_size = 19, _tick = 34634, _time = 1.654e+09, train_seconds = 1.6129e+04)
[2022-05-31 18:39:15,078][root][INFO] - Step 106360320 @ 6649.2 SPS. Inference batcher size: 82. Learner queue size: 24. Other stats: (step = 106360320, mean_episode_return = 223.16, mean_episode_step = 720.13, total_loss = -82.37, pg_loss = -128.09, baseline_loss = 52.188, entropy_loss = -6.4678, learner_queue_size = 14, _tick = 34647, _time = 1.654e+09, train_seconds = 1.6134e+04)
[2022-05-31 18:39:20,081][root][INFO] - Step 106391040 @ 6140.4 SPS. Inference batcher size: 184. Learner queue size: 16. Other stats: (step = 106391040, mean_episode_return = 230.13, mean_episode_step = 669.53, total_loss = 53.936, pg_loss = -46.352, baseline_loss = 106.49, entropy_loss = -6.1989, learner_queue_size = 16, _tick = 34656, _time = 1.654e+09, train_seconds = 1.6139e+04)
[2022-05-31 18:39:25,087][root][INFO] - Step 106424320 @ 6648.0 SPS. Inference batcher size: 131. Learner queue size: 22. Other stats: (step = 106424320, mean_episode_return = None, mean_episode_step = 730.62, total_loss = -15.98, pg_loss = -91.973, baseline_loss = 82.481, entropy_loss = -6.4886, learner_queue_size = 14, _tick = 34666, _time = 1.654e+09, train_seconds = 1.6144e+04)
[2022-05-31 18:39:30,093][root][INFO] - Step 106457600 @ 6648.0 SPS. Inference batcher size: 108. Learner queue size: 19. Other stats: (step = 106457600, mean_episode_return = 181.26, mean_episode_step = 760.84, total_loss = 165.43, pg_loss = 79.123, baseline_loss = 93.061, entropy_loss = -6.7538, learner_queue_size = 18, _tick = 34677, _time = 1.654e+09, train_seconds = 1.6149e+04)
[2022-05-31 18:39:35,099][root][INFO] - Step 106490880 @ 6648.0 SPS. Inference batcher size: 153. Learner queue size: 15. Other stats: (step = 106490880, mean_episode_return = 137.73, mean_episode_step = 809.6, total_loss = 348.95, pg_loss = 249.76, baseline_loss = 105.52, entropy_loss = -6.3262, learner_queue_size = 19, _tick = 34690, _time = 1.654e+09, train_seconds = 1.6154e+04)
[2022-05-31 18:39:40,103][root][INFO] - Step 106524160 @ 6650.1 SPS. Inference batcher size: 66. Learner queue size: 4. Other stats: (step = 106524160, mean_episode_return = 284.25, mean_episode_step = 619.1, total_loss = -122.37, pg_loss = -139.2, baseline_loss = 22.956, entropy_loss = -6.1293, learner_queue_size = 17, _tick = 34703, _time = 1.654e+09, train_seconds = 1.6159e+04)
[2022-05-31 18:39:45,106][root][INFO] - Step 106557440 @ 6652.5 SPS. Inference batcher size: 107. Learner queue size: 1. Other stats: (step = 106557440, mean_episode_return = 107.41, mean_episode_step = 661.38, total_loss = 285.8, pg_loss = 211.15, baseline_loss = 81.002, entropy_loss = -6.3501, learner_queue_size = 19, _tick = 34715, _time = 1.654e+09, train_seconds = 1.6164e+04)
[2022-05-31 18:39:50,110][root][INFO] - Step 106590720 @ 6650.8 SPS. Inference batcher size: 43. Learner queue size: 30. Other stats: (step = 106590720, mean_episode_return = 189.74, mean_episode_step = 737.61, total_loss = 75.475, pg_loss = 14.287, baseline_loss = 67.158, entropy_loss = -5.9708, learner_queue_size = 15, _tick = 34726, _time = 1.654e+09, train_seconds = 1.6169e+04)
[2022-05-31 18:39:55,116][root][INFO] - Step 106624000 @ 6647.4 SPS. Inference batcher size: 98. Learner queue size: 3. Other stats: (step = 106624000, mean_episode_return = None, mean_episode_step = 667.25, total_loss = 14.157, pg_loss = -146.44, baseline_loss = 166.48, entropy_loss = -5.879, learner_queue_size = 26, _tick = 34736, _time = 1.654e+09, train_seconds = 1.6174e+04)
[2022-05-31 18:40:00,122][root][INFO] - Step 106657280 @ 6648.6 SPS. Inference batcher size: 181. Learner queue size: 28. Other stats: (step = 106657280, mean_episode_return = 351.82, mean_episode_step = 604.06, total_loss = 97.907, pg_loss = -330.48, baseline_loss = 433.92, entropy_loss = -5.5267, learner_queue_size = 25, _tick = 34749, _time = 1.654e+09, train_seconds = 1.6179e+04)
[2022-05-31 18:40:05,126][root][INFO] - Step 106688000 @ 6139.1 SPS. Inference batcher size: 115. Learner queue size: 13. Other stats: (step = 106688000, mean_episode_return = 160.72, mean_episode_step = 673.51, total_loss = 720.93, pg_loss = 428.52, baseline_loss = 297.78, entropy_loss = -5.3738, learner_queue_size = 18, _tick = 34760, _time = 1.654e+09, train_seconds = 1.6184e+04)
[2022-05-31 18:40:10,130][root][INFO] - Step 106723840 @ 7162.2 SPS. Inference batcher size: 132. Learner queue size: 15. Other stats: (step = 106723840, mean_episode_return = 101.36, mean_episode_step = 724.69, total_loss = -156.4, pg_loss = -225.36, baseline_loss = 75.062, entropy_loss = -6.1014, learner_queue_size = 12, _tick = 34774, _time = 1.654e+09, train_seconds = 1.6189e+04)
[2022-05-31 18:40:15,134][root][INFO] - Step 106754560 @ 6139.1 SPS. Inference batcher size: 126. Learner queue size: 19. Other stats: (step = 106754560, mean_episode_return = 637.53, mean_episode_step = 761.39, total_loss = 11.306, pg_loss = -43.379, baseline_loss = 61.093, entropy_loss = -6.4084, learner_queue_size = 15, _tick = 34785, _time = 1.654e+09, train_seconds = 1.6194e+04)
[2022-05-31 18:40:20,138][root][INFO] - Step 106787840 @ 6650.7 SPS. Inference batcher size: 127. Learner queue size: 13. Other stats: (step = 106787840, mean_episode_return = None, mean_episode_step = 908.06, total_loss = 77.495, pg_loss = 51.697, baseline_loss = 32.404, entropy_loss = -6.6064, learner_queue_size = 17, _tick = 34796, _time = 1.654e+09, train_seconds = 1.6199e+04)
[2022-05-31 18:40:25,140][root][INFO] - Step 106821120 @ 6653.6 SPS. Inference batcher size: 146. Learner queue size: 5. Other stats: (step = 106821120, mean_episode_return = 187.94, mean_episode_step = 748.92, total_loss = -283.23, pg_loss = -332.36, baseline_loss = 55.451, entropy_loss = -6.3273, learner_queue_size = 28, _tick = 34809, _time = 1.654e+09, train_seconds = 1.6204e+04)
[2022-05-31 18:40:30,146][root][INFO] - Step 106854400 @ 6648.2 SPS. Inference batcher size: 189. Learner queue size: 3. Other stats: (step = 106854400, mean_episode_return = 112.29, mean_episode_step = 705.9, total_loss = 423.74, pg_loss = 300.45, baseline_loss = 129.39, entropy_loss = -6.1031, learner_queue_size = 20, _tick = 34821, _time = 1.654e+09, train_seconds = 1.6209e+04)
[2022-05-31 18:40:35,150][root][INFO] - Step 106887680 @ 6650.3 SPS. Inference batcher size: 27. Learner queue size: 9. Other stats: (step = 106887680, mean_episode_return = 281.96, mean_episode_step = 681.05, total_loss = -36.134, pg_loss = -102.89, baseline_loss = 72.046, entropy_loss = -5.2868, learner_queue_size = 12, _tick = 34832, _time = 1.654e+09, train_seconds = 1.6214e+04)
[2022-05-31 18:40:40,154][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 18:40:40,262][root][INFO] - Step 106920960 @ 6650.5 SPS. Inference batcher size: 6. Learner queue size: 6. Other stats: (step = 106920960, mean_episode_return = 187.72, mean_episode_step = 840.76, total_loss = 28.726, pg_loss = -60.704, baseline_loss = 94.719, entropy_loss = -5.2881, learner_queue_size = 14, _tick = 34845, _time = 1.654e+09, train_seconds = 1.6219e+04)
[2022-05-31 18:40:45,266][root][INFO] - Step 106954240 @ 6510.2 SPS. Inference batcher size: 94. Learner queue size: 2. Other stats: (step = 106954240, mean_episode_return = 170.3, mean_episode_step = 680.67, total_loss = 41.295, pg_loss = -89.81, baseline_loss = 136.9, entropy_loss = -5.7921, learner_queue_size = 10, _tick = 34857, _time = 1.654e+09, train_seconds = 1.6224e+04)
[2022-05-31 18:40:50,270][root][INFO] - Step 106987520 @ 6650.8 SPS. Inference batcher size: 110. Learner queue size: 27. Other stats: (step = 106987520, mean_episode_return = 169.71, mean_episode_step = 658.68, total_loss = 650.16, pg_loss = 461.24, baseline_loss = 194.79, entropy_loss = -5.8754, learner_queue_size = 18, _tick = 34869, _time = 1.654e+09, train_seconds = 1.6229e+04)
[2022-05-31 18:40:55,276][root][INFO] - Step 107018240 @ 6137.0 SPS. Inference batcher size: 116. Learner queue size: 16. Other stats: (step = 107018240, mean_episode_return = 324.04, mean_episode_step = 755.5, total_loss = 32.012, pg_loss = -130.49, baseline_loss = 168.39, entropy_loss = -5.8904, learner_queue_size = 10, _tick = 34881, _time = 1.654e+09, train_seconds = 1.6234e+04)
[2022-05-31 18:41:00,278][root][INFO] - Step 107051520 @ 6652.9 SPS. Inference batcher size: 126. Learner queue size: 15. Other stats: (step = 107051520, mean_episode_return = 221.5, mean_episode_step = 687.56, total_loss = 757.1, pg_loss = 478.36, baseline_loss = 284.58, entropy_loss = -5.8403, learner_queue_size = 19, _tick = 34892, _time = 1.654e+09, train_seconds = 1.6239e+04)
[2022-05-31 18:41:05,284][root][INFO] - Step 107084800 @ 6648.0 SPS. Inference batcher size: 96. Learner queue size: 18. Other stats: (step = 107084800, mean_episode_return = 232.72, mean_episode_step = 759.48, total_loss = -128.21, pg_loss = -178.2, baseline_loss = 56.652, entropy_loss = -6.6649, learner_queue_size = 20, _tick = 34905, _time = 1.654e+09, train_seconds = 1.6244e+04)
[2022-05-31 18:41:10,290][root][INFO] - Step 107118080 @ 6648.1 SPS. Inference batcher size: 170. Learner queue size: 12. Other stats: (step = 107118080, mean_episode_return = 168.46, mean_episode_step = 620.17, total_loss = -106.79, pg_loss = -145.81, baseline_loss = 45.408, entropy_loss = -6.3878, learner_queue_size = 17, _tick = 34917, _time = 1.654e+09, train_seconds = 1.6249e+04)
[2022-05-31 18:41:15,294][root][INFO] - Step 107151360 @ 6650.4 SPS. Inference batcher size: 186. Learner queue size: 20. Other stats: (step = 107151360, mean_episode_return = 189.7, mean_episode_step = 834.2, total_loss = 36.187, pg_loss = -47.866, baseline_loss = 90.184, entropy_loss = -6.1305, learner_queue_size = 27, _tick = 34929, _time = 1.654e+09, train_seconds = 1.6254e+04)
[2022-05-31 18:41:20,298][root][INFO] - Step 107184640 @ 6651.0 SPS. Inference batcher size: 164. Learner queue size: 24. Other stats: (step = 107184640, mean_episode_return = 296.47, mean_episode_step = 753.01, total_loss = 60.929, pg_loss = -146.32, baseline_loss = 213.77, entropy_loss = -6.5203, learner_queue_size = 24, _tick = 34942, _time = 1.654e+09, train_seconds = 1.6259e+04)
[2022-05-31 18:41:25,305][root][INFO] - Step 107217920 @ 6647.3 SPS. Inference batcher size: 140. Learner queue size: 9. Other stats: (step = 107217920, mean_episode_return = 368.91, mean_episode_step = 729.84, total_loss = 84.722, pg_loss = -85.323, baseline_loss = 176.97, entropy_loss = -6.9252, learner_queue_size = 20, _tick = 34951, _time = 1.654e+09, train_seconds = 1.6264e+04)
[2022-05-31 18:41:30,310][root][INFO] - Step 107251200 @ 6648.8 SPS. Inference batcher size: 131. Learner queue size: 23. Other stats: (step = 107251200, mean_episode_return = 273.22, mean_episode_step = 954.29, total_loss = 11.158, pg_loss = -1.9531, baseline_loss = 20.02, entropy_loss = -6.9087, learner_queue_size = 17, _tick = 34961, _time = 1.654e+09, train_seconds = 1.6269e+04)
[2022-05-31 18:41:35,314][root][INFO] - Step 107284480 @ 6650.5 SPS. Inference batcher size: 2. Learner queue size: 19. Other stats: (step = 107284480, mean_episode_return = 117.52, mean_episode_step = 805.22, total_loss = 367.2, pg_loss = 177.08, baseline_loss = 196.37, entropy_loss = -6.2431, learner_queue_size = 16, _tick = 34974, _time = 1.654e+09, train_seconds = 1.6274e+04)
[2022-05-31 18:41:40,321][root][INFO] - Step 107315200 @ 6136.1 SPS. Inference batcher size: 103. Learner queue size: 14. Other stats: (step = 107315200, mean_episode_return = 366.63, mean_episode_step = 1013.1, total_loss = 309.54, pg_loss = 164.3, baseline_loss = 151.17, entropy_loss = -5.9244, learner_queue_size = 18, _tick = 34984, _time = 1.654e+09, train_seconds = 1.6279e+04)
[2022-05-31 18:41:45,327][root][INFO] - Step 107348480 @ 6648.0 SPS. Inference batcher size: 168. Learner queue size: 24. Other stats: (step = 107348480, mean_episode_return = 264.54, mean_episode_step = 798.16, total_loss = 94.598, pg_loss = 27.317, baseline_loss = 73.538, entropy_loss = -6.2565, learner_queue_size = 16, _tick = 34995, _time = 1.654e+09, train_seconds = 1.6284e+04)
[2022-05-31 18:41:50,333][root][INFO] - Step 107381760 @ 6648.0 SPS. Inference batcher size: 142. Learner queue size: 16. Other stats: (step = 107381760, mean_episode_return = 281.23, mean_episode_step = 558.82, total_loss = 297.68, pg_loss = 172.87, baseline_loss = 130.85, entropy_loss = -6.0318, learner_queue_size = 17, _tick = 35007, _time = 1.654e+09, train_seconds = 1.6289e+04)
[2022-05-31 18:41:55,339][root][INFO] - Step 107415040 @ 6647.9 SPS. Inference batcher size: 134. Learner queue size: 7. Other stats: (step = 107415040, mean_episode_return = 216.39, mean_episode_step = 610.42, total_loss = 89.94, pg_loss = -68.759, baseline_loss = 163.89, entropy_loss = -5.19, learner_queue_size = 6, _tick = 35019, _time = 1.654e+09, train_seconds = 1.6294e+04)
[2022-05-31 18:42:00,342][root][INFO] - Step 107448320 @ 6651.6 SPS. Inference batcher size: 118. Learner queue size: 4. Other stats: (step = 107448320, mean_episode_return = 148.63, mean_episode_step = 653.51, total_loss = -93.554, pg_loss = -180.46, baseline_loss = 92.963, entropy_loss = -6.0565, learner_queue_size = 19, _tick = 35031, _time = 1.654e+09, train_seconds = 1.6299e+04)
[2022-05-31 18:42:05,346][root][INFO] - Step 107481600 @ 6650.6 SPS. Inference batcher size: 52. Learner queue size: 3. Other stats: (step = 107481600, mean_episode_return = 341.77, mean_episode_step = 779.83, total_loss = 30.891, pg_loss = -209.24, baseline_loss = 245.99, entropy_loss = -5.8539, learner_queue_size = 28, _tick = 35044, _time = 1.654e+09, train_seconds = 1.6304e+04)
[2022-05-31 18:42:10,350][root][INFO] - Step 107514880 @ 6650.7 SPS. Inference batcher size: 77. Learner queue size: 0. Other stats: (step = 107514880, mean_episode_return = 327.5, mean_episode_step = 511.57, total_loss = 172.89, pg_loss = 7.5301, baseline_loss = 171.18, entropy_loss = -5.8216, learner_queue_size = 25, _tick = 35056, _time = 1.654e+09, train_seconds = 1.6309e+04)
[2022-05-31 18:42:15,354][root][INFO] - Step 107548160 @ 6650.7 SPS. Inference batcher size: 45. Learner queue size: 17. Other stats: (step = 107548160, mean_episode_return = 358.27, mean_episode_step = 728.96, total_loss = -123.05, pg_loss = -185.62, baseline_loss = 69.347, entropy_loss = -6.7829, learner_queue_size = 16, _tick = 35066, _time = 1.654e+09, train_seconds = 1.6314e+04)
[2022-05-31 18:42:20,360][root][INFO] - Step 107578880 @ 6136.5 SPS. Inference batcher size: 85. Learner queue size: 7. Other stats: (step = 107578880, mean_episode_return = 337.22, mean_episode_step = 670.34, total_loss = 31.222, pg_loss = -69.345, baseline_loss = 106.68, entropy_loss = -6.1104, learner_queue_size = 14, _tick = 35076, _time = 1.654e+09, train_seconds = 1.6319e+04)
[2022-05-31 18:42:25,366][root][INFO] - Step 107612160 @ 6648.2 SPS. Inference batcher size: 101. Learner queue size: 14. Other stats: (step = 107612160, mean_episode_return = 150.38, mean_episode_step = 650.44, total_loss = 697.46, pg_loss = 369.74, baseline_loss = 333.37, entropy_loss = -5.6534, learner_queue_size = 22, _tick = 35087, _time = 1.654e+09, train_seconds = 1.6324e+04)
[2022-05-31 18:42:30,370][root][INFO] - Step 107645440 @ 6650.6 SPS. Inference batcher size: 131. Learner queue size: 1. Other stats: (step = 107645440, mean_episode_return = 254.35, mean_episode_step = 627.5, total_loss = -163.66, pg_loss = -226.75, baseline_loss = 68.808, entropy_loss = -5.7197, learner_queue_size = 18, _tick = 35098, _time = 1.654e+09, train_seconds = 1.6329e+04)
[2022-05-31 18:42:35,376][root][INFO] - Step 107678720 @ 6647.9 SPS. Inference batcher size: 114. Learner queue size: 3. Other stats: (step = 107678720, mean_episode_return = 280.43, mean_episode_step = 669.51, total_loss = 329.72, pg_loss = 59.873, baseline_loss = 275.89, entropy_loss = -6.0421, learner_queue_size = 14, _tick = 35111, _time = 1.654e+09, train_seconds = 1.6334e+04)
[2022-05-31 18:42:40,382][root][INFO] - Step 107709440 @ 6136.7 SPS. Inference batcher size: 187. Learner queue size: 13. Other stats: (step = 107709440, mean_episode_return = 255.52, mean_episode_step = 593.16, total_loss = 609.81, pg_loss = 313.6, baseline_loss = 302.22, entropy_loss = -6.0033, learner_queue_size = 24, _tick = 35122, _time = 1.654e+09, train_seconds = 1.6339e+04)
[2022-05-31 18:42:45,386][root][INFO] - Step 107742720 @ 6650.8 SPS. Inference batcher size: 101. Learner queue size: 4. Other stats: (step = 107742720, mean_episode_return = 144.28, mean_episode_step = 519.83, total_loss = 132.21, pg_loss = -6.6308, baseline_loss = 145.17, entropy_loss = -6.3266, learner_queue_size = 19, _tick = 35135, _time = 1.654e+09, train_seconds = 1.6344e+04)
[2022-05-31 18:42:50,390][root][INFO] - Step 107776000 @ 6650.7 SPS. Inference batcher size: 41. Learner queue size: 12. Other stats: (step = 107776000, mean_episode_return = 302.98, mean_episode_step = 534.68, total_loss = -157.14, pg_loss = -209.71, baseline_loss = 58.713, entropy_loss = -6.1418, learner_queue_size = 24, _tick = 35147, _time = 1.654e+09, train_seconds = 1.6349e+04)
[2022-05-31 18:42:55,394][root][INFO] - Step 107809280 @ 6650.6 SPS. Inference batcher size: 95. Learner queue size: 4. Other stats: (step = 107809280, mean_episode_return = 177.27, mean_episode_step = 618.8, total_loss = 243.6, pg_loss = 178.01, baseline_loss = 72.227, entropy_loss = -6.635, learner_queue_size = 22, _tick = 35159, _time = 1.654e+09, train_seconds = 1.6354e+04)
[2022-05-31 18:43:00,398][root][INFO] - Step 107842560 @ 6650.7 SPS. Inference batcher size: 121. Learner queue size: 10. Other stats: (step = 107842560, mean_episode_return = 363.43, mean_episode_step = 529.85, total_loss = 18.939, pg_loss = -17.682, baseline_loss = 42.557, entropy_loss = -5.936, learner_queue_size = 23, _tick = 35172, _time = 1.654e+09, train_seconds = 1.6359e+04)
[2022-05-31 18:43:05,402][root][INFO] - Step 107875840 @ 6650.7 SPS. Inference batcher size: 102. Learner queue size: 10. Other stats: (step = 107875840, mean_episode_return = 125.29, mean_episode_step = 722.1, total_loss = 256.05, pg_loss = 186.85, baseline_loss = 75.58, entropy_loss = -6.3794, learner_queue_size = 21, _tick = 35184, _time = 1.654e+09, train_seconds = 1.6364e+04)
[2022-05-31 18:43:10,406][root][INFO] - Step 107909120 @ 6650.8 SPS. Inference batcher size: 96. Learner queue size: 0. Other stats: (step = 107909120, mean_episode_return = 78.44, mean_episode_step = 548.48, total_loss = 198.92, pg_loss = 56.709, baseline_loss = 148.06, entropy_loss = -5.8488, learner_queue_size = 13, _tick = 35197, _time = 1.654e+09, train_seconds = 1.6369e+04)
[2022-05-31 18:43:15,412][root][INFO] - Step 107942400 @ 6648.1 SPS. Inference batcher size: 98. Learner queue size: 4. Other stats: (step = 107942400, mean_episode_return = 125.09, mean_episode_step = 654.54, total_loss = 22.227, pg_loss = -12.894, baseline_loss = 41.397, entropy_loss = -6.2762, learner_queue_size = 15, _tick = 35210, _time = 1.654e+09, train_seconds = 1.6374e+04)
[2022-05-31 18:43:20,413][root][INFO] - Step 107975680 @ 6654.4 SPS. Inference batcher size: 102. Learner queue size: 6. Other stats: (step = 107975680, mean_episode_return = 515.56, mean_episode_step = 559.2, total_loss = -7.7871, pg_loss = -135.17, baseline_loss = 133.27, entropy_loss = -5.8865, learner_queue_size = 32, _tick = 35222, _time = 1.654e+09, train_seconds = 1.6379e+04)
[2022-05-31 18:43:25,419][root][INFO] - Step 108008960 @ 6647.9 SPS. Inference batcher size: 94. Learner queue size: 2. Other stats: (step = 108008960, mean_episode_return = 291.73, mean_episode_step = 770.07, total_loss = -151.01, pg_loss = -239.68, baseline_loss = 94.818, entropy_loss = -6.1496, learner_queue_size = 19, _tick = 35234, _time = 1.654e+09, train_seconds = 1.6384e+04)
[2022-05-31 18:43:30,425][root][INFO] - Step 108042240 @ 6647.8 SPS. Inference batcher size: 110. Learner queue size: 3. Other stats: (step = 108042240, mean_episode_return = None, mean_episode_step = 761.03, total_loss = 174.62, pg_loss = 125.43, baseline_loss = 55.445, entropy_loss = -6.2547, learner_queue_size = 23, _tick = 35244, _time = 1.654e+09, train_seconds = 1.6389e+04)
[2022-05-31 18:43:35,430][root][INFO] - Step 108072960 @ 6138.3 SPS. Inference batcher size: 157. Learner queue size: 14. Other stats: (step = 108072960, mean_episode_return = 470.04, mean_episode_step = 703.21, total_loss = 169.43, pg_loss = -33.016, baseline_loss = 208.01, entropy_loss = -5.5585, learner_queue_size = 23, _tick = 35256, _time = 1.654e+09, train_seconds = 1.6394e+04)
[2022-05-31 18:43:40,433][root][INFO] - Step 108106240 @ 6652.1 SPS. Inference batcher size: 129. Learner queue size: 13. Other stats: (step = 108106240, mean_episode_return = 245.98, mean_episode_step = 635.75, total_loss = -57.462, pg_loss = -109.24, baseline_loss = 58.125, entropy_loss = -6.3449, learner_queue_size = 22, _tick = 35269, _time = 1.654e+09, train_seconds = 1.6399e+04)
[2022-05-31 18:43:45,439][root][INFO] - Step 108139520 @ 6648.0 SPS. Inference batcher size: 183. Learner queue size: 20. Other stats: (step = 108139520, mean_episode_return = 203.53, mean_episode_step = 559.31, total_loss = 128.25, pg_loss = 62.49, baseline_loss = 72.119, entropy_loss = -6.3568, learner_queue_size = 20, _tick = 35280, _time = 1.654e+09, train_seconds = 1.6404e+04)
[2022-05-31 18:43:50,445][root][INFO] - Step 108172800 @ 6647.9 SPS. Inference batcher size: 146. Learner queue size: 15. Other stats: (step = 108172800, mean_episode_return = 143.55, mean_episode_step = 495.72, total_loss = 89.772, pg_loss = -99.122, baseline_loss = 195.16, entropy_loss = -6.2665, learner_queue_size = 24, _tick = 35291, _time = 1.654e+09, train_seconds = 1.6409e+04)
[2022-05-31 18:43:55,451][root][INFO] - Step 108206080 @ 6648.0 SPS. Inference batcher size: 116. Learner queue size: 16. Other stats: (step = 108206080, mean_episode_return = 311.82, mean_episode_step = 687.51, total_loss = -48.675, pg_loss = -123.14, baseline_loss = 81.18, entropy_loss = -6.7186, learner_queue_size = 21, _tick = 35303, _time = 1.654e+09, train_seconds = 1.6414e+04)
[2022-05-31 18:44:00,454][root][INFO] - Step 108239360 @ 6652.3 SPS. Inference batcher size: 107. Learner queue size: 19. Other stats: (step = 108239360, mean_episode_return = 358.29, mean_episode_step = 560.87, total_loss = 243.46, pg_loss = -23.477, baseline_loss = 273.44, entropy_loss = -6.5065, learner_queue_size = 13, _tick = 35314, _time = 1.654e+09, train_seconds = 1.6419e+04)
[2022-05-31 18:44:05,460][root][INFO] - Step 108272640 @ 6648.0 SPS. Inference batcher size: 130. Learner queue size: 5. Other stats: (step = 108272640, mean_episode_return = 200.06, mean_episode_step = 621.33, total_loss = 445.38, pg_loss = 270.23, baseline_loss = 181.52, entropy_loss = -6.3603, learner_queue_size = 9, _tick = 35325, _time = 1.654e+09, train_seconds = 1.6424e+04)
[2022-05-31 18:44:10,466][root][INFO] - Step 108305920 @ 6648.0 SPS. Inference batcher size: 139. Learner queue size: 0. Other stats: (step = 108305920, mean_episode_return = 140.13, mean_episode_step = 943.3, total_loss = 745.84, pg_loss = 535.85, baseline_loss = 216.57, entropy_loss = -6.5745, learner_queue_size = 14, _tick = 35335, _time = 1.654e+09, train_seconds = 1.6429e+04)
[2022-05-31 18:44:15,470][root][INFO] - Step 108339200 @ 6650.8 SPS. Inference batcher size: 90. Learner queue size: 30. Other stats: (step = 108339200, mean_episode_return = 179.61, mean_episode_step = 705.47, total_loss = 134.15, pg_loss = -72.974, baseline_loss = 213.26, entropy_loss = -6.1353, learner_queue_size = 17, _tick = 35346, _time = 1.654e+09, train_seconds = 1.6434e+04)
[2022-05-31 18:44:20,476][root][INFO] - Step 108372480 @ 6647.7 SPS. Inference batcher size: 125. Learner queue size: 14. Other stats: (step = 108372480, mean_episode_return = 260.18, mean_episode_step = 716.53, total_loss = 159.52, pg_loss = 68.494, baseline_loss = 97.07, entropy_loss = -6.0428, learner_queue_size = 13, _tick = 35355, _time = 1.654e+09, train_seconds = 1.6439e+04)
[2022-05-31 18:44:25,482][root][INFO] - Step 108403200 @ 6136.5 SPS. Inference batcher size: 89. Learner queue size: 23. Other stats: (step = 108403200, mean_episode_return = 284.26, mean_episode_step = 608.5, total_loss = -25.686, pg_loss = -111.95, baseline_loss = 92.169, entropy_loss = -5.9088, learner_queue_size = 11, _tick = 35366, _time = 1.654e+09, train_seconds = 1.6444e+04)
[2022-05-31 18:44:30,488][root][INFO] - Step 108436480 @ 6648.0 SPS. Inference batcher size: 85. Learner queue size: 13. Other stats: (step = 108436480, mean_episode_return = 167.91, mean_episode_step = 615.08, total_loss = 250.42, pg_loss = 183.32, baseline_loss = 73.266, entropy_loss = -6.1698, learner_queue_size = 17, _tick = 35379, _time = 1.654e+09, train_seconds = 1.6449e+04)
[2022-05-31 18:44:35,494][root][INFO] - Step 108469760 @ 6648.5 SPS. Inference batcher size: 64. Learner queue size: 12. Other stats: (step = 108469760, mean_episode_return = 369.47, mean_episode_step = 446.54, total_loss = -31.082, pg_loss = -85.245, baseline_loss = 59.574, entropy_loss = -5.412, learner_queue_size = 9, _tick = 35392, _time = 1.654e+09, train_seconds = 1.6454e+04)
[2022-05-31 18:44:40,502][root][INFO] - Step 108503040 @ 6645.4 SPS. Inference batcher size: 130. Learner queue size: 2. Other stats: (step = 108503040, mean_episode_return = 171.93, mean_episode_step = 670.67, total_loss = 185.85, pg_loss = 99.107, baseline_loss = 92.464, entropy_loss = -5.7168, learner_queue_size = 14, _tick = 35404, _time = 1.654e+09, train_seconds = 1.6459e+04)
[2022-05-31 18:44:45,506][root][INFO] - Step 108536320 @ 6650.7 SPS. Inference batcher size: 167. Learner queue size: 21. Other stats: (step = 108536320, mean_episode_return = 175.66, mean_episode_step = 624.72, total_loss = 224.22, pg_loss = 122.44, baseline_loss = 107.77, entropy_loss = -5.9911, learner_queue_size = 16, _tick = 35415, _time = 1.654e+09, train_seconds = 1.6464e+04)
[2022-05-31 18:44:50,512][root][INFO] - Step 108567040 @ 6137.0 SPS. Inference batcher size: 160. Learner queue size: 22. Other stats: (step = 108567040, mean_episode_return = 135.58, mean_episode_step = 476.5, total_loss = 178.75, pg_loss = 5.2494, baseline_loss = 178.86, entropy_loss = -5.3604, learner_queue_size = 19, _tick = 35427, _time = 1.654e+09, train_seconds = 1.6469e+04)
[2022-05-31 18:44:55,514][root][INFO] - Step 108600320 @ 6652.9 SPS. Inference batcher size: 109. Learner queue size: 14. Other stats: (step = 108600320, mean_episode_return = 81.024, mean_episode_step = 563.4, total_loss = 6.3906, pg_loss = -71.231, baseline_loss = 83.311, entropy_loss = -5.6891, learner_queue_size = 19, _tick = 35440, _time = 1.654e+09, train_seconds = 1.6474e+04)
[2022-05-31 18:45:00,518][root][INFO] - Step 108633600 @ 6650.7 SPS. Inference batcher size: 30. Learner queue size: 10. Other stats: (step = 108633600, mean_episode_return = 362.56, mean_episode_step = 601.25, total_loss = -62.175, pg_loss = -171.72, baseline_loss = 115.3, entropy_loss = -5.7526, learner_queue_size = 23, _tick = 35451, _time = 1.654e+09, train_seconds = 1.6479e+04)
[2022-05-31 18:45:05,522][root][INFO] - Step 108666880 @ 6650.5 SPS. Inference batcher size: 77. Learner queue size: 0. Other stats: (step = 108666880, mean_episode_return = 147.06, mean_episode_step = 511.81, total_loss = 150.86, pg_loss = 45.726, baseline_loss = 111.04, entropy_loss = -5.9008, learner_queue_size = 15, _tick = 35464, _time = 1.654e+09, train_seconds = 1.6484e+04)
[2022-05-31 18:45:10,526][root][INFO] - Step 108700160 @ 6650.9 SPS. Inference batcher size: 50. Learner queue size: 18. Other stats: (step = 108700160, mean_episode_return = 229.84, mean_episode_step = 568.33, total_loss = 30.988, pg_loss = -81.241, baseline_loss = 118.44, entropy_loss = -6.2101, learner_queue_size = 17, _tick = 35476, _time = 1.654e+09, train_seconds = 1.6489e+04)
[2022-05-31 18:45:15,532][root][INFO] - Step 108730880 @ 6136.0 SPS. Inference batcher size: 61. Learner queue size: 24. Other stats: (step = 108730880, mean_episode_return = 250.41, mean_episode_step = 653.94, total_loss = 90.237, pg_loss = 2.9268, baseline_loss = 93.471, entropy_loss = -6.1605, learner_queue_size = 17, _tick = 35488, _time = 1.654e+09, train_seconds = 1.6494e+04)
[2022-05-31 18:45:20,538][root][INFO] - Step 108766720 @ 7160.1 SPS. Inference batcher size: 94. Learner queue size: 13. Other stats: (step = 108766720, mean_episode_return = 279.1, mean_episode_step = 595.41, total_loss = 173.89, pg_loss = 15.262, baseline_loss = 164.87, entropy_loss = -6.2473, learner_queue_size = 11, _tick = 35498, _time = 1.654e+09, train_seconds = 1.6499e+04)
[2022-05-31 18:45:25,545][root][INFO] - Step 108797440 @ 6135.4 SPS. Inference batcher size: 22. Learner queue size: 14. Other stats: (step = 108797440, mean_episode_return = 61.901, mean_episode_step = 677.98, total_loss = 6.728, pg_loss = -35.185, baseline_loss = 48.42, entropy_loss = -6.507, learner_queue_size = 20, _tick = 35509, _time = 1.654e+09, train_seconds = 1.6504e+04)
[2022-05-31 18:45:30,552][root][INFO] - Step 108830720 @ 6647.4 SPS. Inference batcher size: 146. Learner queue size: 16. Other stats: (step = 108830720, mean_episode_return = 214.69, mean_episode_step = 722.93, total_loss = 326.35, pg_loss = 181.16, baseline_loss = 151.11, entropy_loss = -5.9243, learner_queue_size = 18, _tick = 35518, _time = 1.654e+09, train_seconds = 1.6509e+04)
[2022-05-31 18:45:35,554][root][INFO] - Step 108864000 @ 6652.7 SPS. Inference batcher size: 111. Learner queue size: 5. Other stats: (step = 108864000, mean_episode_return = 354.09, mean_episode_step = 700.91, total_loss = 115.89, pg_loss = -57.273, baseline_loss = 179.27, entropy_loss = -6.1088, learner_queue_size = 26, _tick = 35530, _time = 1.654e+09, train_seconds = 1.6514e+04)
[2022-05-31 18:45:40,558][root][INFO] - Step 108897280 @ 6650.6 SPS. Inference batcher size: 66. Learner queue size: 3. Other stats: (step = 108897280, mean_episode_return = 501.16, mean_episode_step = 768.23, total_loss = 215.61, pg_loss = 2.1212, baseline_loss = 219.37, entropy_loss = -5.8777, learner_queue_size = 16, _tick = 35543, _time = 1.654e+09, train_seconds = 1.6519e+04)
[2022-05-31 18:45:45,562][root][INFO] - Step 108930560 @ 6650.8 SPS. Inference batcher size: 119. Learner queue size: 0. Other stats: (step = 108930560, mean_episode_return = 464.85, mean_episode_step = 697.17, total_loss = -35.758, pg_loss = -72.643, baseline_loss = 43.246, entropy_loss = -6.3602, learner_queue_size = 21, _tick = 35555, _time = 1.654e+09, train_seconds = 1.6524e+04)
[2022-05-31 18:45:50,566][root][INFO] - Step 108963840 @ 6651.1 SPS. Inference batcher size: 134. Learner queue size: 2. Other stats: (step = 108963840, mean_episode_return = 332.22, mean_episode_step = 679.45, total_loss = -14.855, pg_loss = -47.772, baseline_loss = 39.758, entropy_loss = -6.8408, learner_queue_size = 14, _tick = 35568, _time = 1.654e+09, train_seconds = 1.6529e+04)
[2022-05-31 18:45:55,570][root][INFO] - Step 108997120 @ 6650.1 SPS. Inference batcher size: 91. Learner queue size: 29. Other stats: (step = 108997120, mean_episode_return = 335.01, mean_episode_step = 677.71, total_loss = 143.49, pg_loss = 124.1, baseline_loss = 26.55, entropy_loss = -7.1685, learner_queue_size = 19, _tick = 35579, _time = 1.654e+09, train_seconds = 1.6534e+04)
[2022-05-31 18:46:00,574][root][INFO] - Step 109030400 @ 6650.8 SPS. Inference batcher size: 124. Learner queue size: 24. Other stats: (step = 109030400, mean_episode_return = 275.27, mean_episode_step = 638.57, total_loss = 239.29, pg_loss = 199.26, baseline_loss = 46.374, entropy_loss = -6.3442, learner_queue_size = 12, _tick = 35590, _time = 1.654e+09, train_seconds = 1.6539e+04)
[2022-05-31 18:46:05,580][root][INFO] - Step 109061120 @ 6136.5 SPS. Inference batcher size: 96. Learner queue size: 21. Other stats: (step = 109061120, mean_episode_return = 305.19, mean_episode_step = 694.7, total_loss = -21.154, pg_loss = -33.087, baseline_loss = 18.129, entropy_loss = -6.1968, learner_queue_size = 19, _tick = 35599, _time = 1.654e+09, train_seconds = 1.6544e+04)
[2022-05-31 18:46:10,586][root][INFO] - Step 109094400 @ 6648.1 SPS. Inference batcher size: 114. Learner queue size: 19. Other stats: (step = 109094400, mean_episode_return = None, mean_episode_step = 631.19, total_loss = -9.844, pg_loss = -62.36, baseline_loss = 58.318, entropy_loss = -5.8026, learner_queue_size = 21, _tick = 35610, _time = 1.654e+09, train_seconds = 1.6549e+04)
[2022-05-31 18:46:15,590][root][INFO] - Step 109127680 @ 6650.7 SPS. Inference batcher size: 120. Learner queue size: 12. Other stats: (step = 109127680, mean_episode_return = 180.44, mean_episode_step = 727.57, total_loss = 252.21, pg_loss = 68.803, baseline_loss = 189.71, entropy_loss = -6.3046, learner_queue_size = 13, _tick = 35622, _time = 1.654e+09, train_seconds = 1.6554e+04)
[2022-05-31 18:46:20,594][root][INFO] - Step 109160960 @ 6650.8 SPS. Inference batcher size: 46. Learner queue size: 7. Other stats: (step = 109160960, mean_episode_return = 245.21, mean_episode_step = 676.08, total_loss = -109.16, pg_loss = -197.31, baseline_loss = 93.928, entropy_loss = -5.7836, learner_queue_size = 17, _tick = 35635, _time = 1.654e+09, train_seconds = 1.6559e+04)
[2022-05-31 18:46:25,600][root][INFO] - Step 109194240 @ 6647.9 SPS. Inference batcher size: 64. Learner queue size: 5. Other stats: (step = 109194240, mean_episode_return = 144.19, mean_episode_step = 485.87, total_loss = -190.79, pg_loss = -266.46, baseline_loss = 81.144, entropy_loss = -5.476, learner_queue_size = 17, _tick = 35648, _time = 1.654e+09, train_seconds = 1.6564e+04)
[2022-05-31 18:46:30,606][root][INFO] - Step 109227520 @ 6647.9 SPS. Inference batcher size: 51. Learner queue size: 3. Other stats: (step = 109227520, mean_episode_return = 176.68, mean_episode_step = 549.72, total_loss = 172.96, pg_loss = 38.539, baseline_loss = 140.06, entropy_loss = -5.6415, learner_queue_size = 29, _tick = 35661, _time = 1.654e+09, train_seconds = 1.6569e+04)
[2022-05-31 18:46:35,610][root][INFO] - Step 109260800 @ 6650.9 SPS. Inference batcher size: 101. Learner queue size: 28. Other stats: (step = 109260800, mean_episode_return = 474.37, mean_episode_step = 553.98, total_loss = 90.445, pg_loss = -8.9062, baseline_loss = 104.86, entropy_loss = -5.5061, learner_queue_size = 16, _tick = 35673, _time = 1.654e+09, train_seconds = 1.6574e+04)
[2022-05-31 18:46:40,616][root][INFO] - Step 109291520 @ 6136.0 SPS. Inference batcher size: 111. Learner queue size: 14. Other stats: (step = 109291520, mean_episode_return = 296.67, mean_episode_step = 570.63, total_loss = -145.6, pg_loss = -211.93, baseline_loss = 72.541, entropy_loss = -6.2051, learner_queue_size = 22, _tick = 35685, _time = 1.654e+09, train_seconds = 1.6579e+04)
[2022-05-31 18:46:45,623][root][INFO] - Step 109324800 @ 6647.9 SPS. Inference batcher size: 129. Learner queue size: 15. Other stats: (step = 109324800, mean_episode_return = 284.08, mean_episode_step = 628.85, total_loss = -170.01, pg_loss = -231.72, baseline_loss = 67.951, entropy_loss = -6.2425, learner_queue_size = 13, _tick = 35697, _time = 1.654e+09, train_seconds = 1.6584e+04)
[2022-05-31 18:46:50,629][root][INFO] - Step 109358080 @ 6648.0 SPS. Inference batcher size: 117. Learner queue size: 14. Other stats: (step = 109358080, mean_episode_return = None, mean_episode_step = 483.12, total_loss = 27.925, pg_loss = -66.597, baseline_loss = 100.25, entropy_loss = -5.7255, learner_queue_size = 23, _tick = 35707, _time = 1.654e+09, train_seconds = 1.6589e+04)
[2022-05-31 18:46:55,634][root][INFO] - Step 109391360 @ 6648.8 SPS. Inference batcher size: 98. Learner queue size: 7. Other stats: (step = 109391360, mean_episode_return = 203.61, mean_episode_step = 503.87, total_loss = 8.025, pg_loss = -236.78, baseline_loss = 249.92, entropy_loss = -5.1119, learner_queue_size = 16, _tick = 35720, _time = 1.654e+09, train_seconds = 1.6594e+04)
[2022-05-31 18:47:00,638][root][INFO] - Step 109424640 @ 6650.7 SPS. Inference batcher size: 5. Learner queue size: 2. Other stats: (step = 109424640, mean_episode_return = 262.65, mean_episode_step = 578.67, total_loss = 326.27, pg_loss = 176.51, baseline_loss = 154.98, entropy_loss = -5.2202, learner_queue_size = 21, _tick = 35730, _time = 1.654e+09, train_seconds = 1.6599e+04)
[2022-05-31 18:47:05,642][root][INFO] - Step 109457920 @ 6650.6 SPS. Inference batcher size: 17. Learner queue size: 9. Other stats: (step = 109457920, mean_episode_return = 243.79, mean_episode_step = 544.55, total_loss = -15.162, pg_loss = -83.207, baseline_loss = 73.601, entropy_loss = -5.5557, learner_queue_size = 22, _tick = 35742, _time = 1.654e+09, train_seconds = 1.6604e+04)
[2022-05-31 18:47:10,646][root][INFO] - Step 109491200 @ 6650.5 SPS. Inference batcher size: 64. Learner queue size: 29. Other stats: (step = 109491200, mean_episode_return = 225.45, mean_episode_step = 578.37, total_loss = 533.91, pg_loss = 305.68, baseline_loss = 233.81, entropy_loss = -5.5833, learner_queue_size = 18, _tick = 35754, _time = 1.654e+09, train_seconds = 1.6609e+04)
[2022-05-31 18:47:15,650][root][INFO] - Step 109524480 @ 6651.0 SPS. Inference batcher size: 109. Learner queue size: 28. Other stats: (step = 109524480, mean_episode_return = 240.9, mean_episode_step = 644.9, total_loss = -124.56, pg_loss = -236.86, baseline_loss = 117.75, entropy_loss = -5.4456, learner_queue_size = 23, _tick = 35765, _time = 1.654e+09, train_seconds = 1.6614e+04)
[2022-05-31 18:47:20,656][root][INFO] - Step 109555200 @ 6137.0 SPS. Inference batcher size: 133. Learner queue size: 25. Other stats: (step = 109555200, mean_episode_return = 293.13, mean_episode_step = 594.19, total_loss = 30.27, pg_loss = -83.292, baseline_loss = 119.31, entropy_loss = -5.7439, learner_queue_size = 16, _tick = 35777, _time = 1.654e+09, train_seconds = 1.6619e+04)
[2022-05-31 18:47:25,661][root][INFO] - Step 109588480 @ 6648.8 SPS. Inference batcher size: 154. Learner queue size: 20. Other stats: (step = 109588480, mean_episode_return = 237.06, mean_episode_step = 581.69, total_loss = 327.44, pg_loss = 92.182, baseline_loss = 240.2, entropy_loss = -4.9409, learner_queue_size = 24, _tick = 35787, _time = 1.654e+09, train_seconds = 1.6624e+04)
[2022-05-31 18:47:30,667][root][INFO] - Step 109621760 @ 6648.0 SPS. Inference batcher size: 78. Learner queue size: 20. Other stats: (step = 109621760, mean_episode_return = 351.83, mean_episode_step = 675.63, total_loss = -162.62, pg_loss = -290.13, baseline_loss = 133.22, entropy_loss = -5.7115, learner_queue_size = 29, _tick = 35799, _time = 1.654e+09, train_seconds = 1.6629e+04)
[2022-05-31 18:47:35,670][root][INFO] - Step 109655040 @ 6652.1 SPS. Inference batcher size: 123. Learner queue size: 11. Other stats: (step = 109655040, mean_episode_return = 413.2, mean_episode_step = 501.75, total_loss = 692.66, pg_loss = 177.68, baseline_loss = 520.22, entropy_loss = -5.2473, learner_queue_size = 18, _tick = 35810, _time = 1.654e+09, train_seconds = 1.6634e+04)
[2022-05-31 18:47:40,674][root][INFO] - Step 109688320 @ 6650.8 SPS. Inference batcher size: 10. Learner queue size: 0. Other stats: (step = 109688320, mean_episode_return = 143.51, mean_episode_step = 705.14, total_loss = 68.163, pg_loss = -21.219, baseline_loss = 95.125, entropy_loss = -5.7436, learner_queue_size = 21, _tick = 35822, _time = 1.654e+09, train_seconds = 1.6639e+04)
[2022-05-31 18:47:45,678][root][INFO] - Step 109721600 @ 6650.6 SPS. Inference batcher size: 81. Learner queue size: 2. Other stats: (step = 109721600, mean_episode_return = 366.09, mean_episode_step = 645.1, total_loss = -37.958, pg_loss = -117.66, baseline_loss = 85.404, entropy_loss = -5.7038, learner_queue_size = 16, _tick = 35834, _time = 1.654e+09, train_seconds = 1.6644e+04)
[2022-05-31 18:47:50,682][root][INFO] - Step 109754880 @ 6650.8 SPS. Inference batcher size: 58. Learner queue size: 31. Other stats: (step = 109754880, mean_episode_return = 199.81, mean_episode_step = 652.39, total_loss = 130.51, pg_loss = 31.388, baseline_loss = 104.83, entropy_loss = -5.7138, learner_queue_size = 20, _tick = 35845, _time = 1.654e+09, train_seconds = 1.6649e+04)
[2022-05-31 18:47:55,686][root][INFO] - Step 109788160 @ 6650.5 SPS. Inference batcher size: 74. Learner queue size: 0. Other stats: (step = 109788160, mean_episode_return = 201.21, mean_episode_step = 581.68, total_loss = 345.79, pg_loss = 210.13, baseline_loss = 140.98, entropy_loss = -5.3237, learner_queue_size = 32, _tick = 35858, _time = 1.654e+09, train_seconds = 1.6654e+04)
[2022-05-31 18:48:00,690][root][INFO] - Step 109821440 @ 6650.7 SPS. Inference batcher size: 95. Learner queue size: 28. Other stats: (step = 109821440, mean_episode_return = 126.7, mean_episode_step = 690.34, total_loss = -61.053, pg_loss = -90.787, baseline_loss = 35.949, entropy_loss = -6.2141, learner_queue_size = 26, _tick = 35868, _time = 1.654e+09, train_seconds = 1.6659e+04)
[2022-05-31 18:48:05,695][root][INFO] - Step 109854720 @ 6649.8 SPS. Inference batcher size: 105. Learner queue size: 21. Other stats: (step = 109854720, mean_episode_return = 244.34, mean_episode_step = 595.31, total_loss = 138.65, pg_loss = 54.257, baseline_loss = 90.404, entropy_loss = -6.0089, learner_queue_size = 12, _tick = 35878, _time = 1.654e+09, train_seconds = 1.6664e+04)
[2022-05-31 18:48:10,701][root][INFO] - Step 109885440 @ 6136.0 SPS. Inference batcher size: 114. Learner queue size: 23. Other stats: (step = 109885440, mean_episode_return = 165.41, mean_episode_step = 649.06, total_loss = 239.94, pg_loss = 127.06, baseline_loss = 119.34, entropy_loss = -6.4592, learner_queue_size = 19, _tick = 35890, _time = 1.654e+09, train_seconds = 1.6669e+04)
[2022-05-31 18:48:15,707][root][INFO] - Step 109918720 @ 6647.9 SPS. Inference batcher size: 107. Learner queue size: 16. Other stats: (step = 109918720, mean_episode_return = 169.02, mean_episode_step = 700.21, total_loss = 398.86, pg_loss = 213.56, baseline_loss = 191.44, entropy_loss = -6.1467, learner_queue_size = 14, _tick = 35901, _time = 1.654e+09, train_seconds = 1.6674e+04)
[2022-05-31 18:48:20,713][root][INFO] - Step 109952000 @ 6648.0 SPS. Inference batcher size: 100. Learner queue size: 18. Other stats: (step = 109952000, mean_episode_return = 192.75, mean_episode_step = 808.49, total_loss = 245.2, pg_loss = 169.38, baseline_loss = 81.834, entropy_loss = -6.014, learner_queue_size = 26, _tick = 35914, _time = 1.654e+09, train_seconds = 1.6679e+04)
[2022-05-31 18:48:25,719][root][INFO] - Step 109985280 @ 6648.0 SPS. Inference batcher size: 80. Learner queue size: 11. Other stats: (step = 109985280, mean_episode_return = 410.56, mean_episode_step = 514.33, total_loss = 272.91, pg_loss = 72.882, baseline_loss = 205.72, entropy_loss = -5.6862, learner_queue_size = 11, _tick = 35926, _time = 1.654e+09, train_seconds = 1.6684e+04)
[2022-05-31 18:48:30,722][root][INFO] - Step 110018560 @ 6652.4 SPS. Inference batcher size: 107. Learner queue size: 6. Other stats: (step = 110018560, mean_episode_return = 163.89, mean_episode_step = 583.63, total_loss = -149.32, pg_loss = -227.74, baseline_loss = 83.612, entropy_loss = -5.2002, learner_queue_size = 16, _tick = 35939, _time = 1.654e+09, train_seconds = 1.6689e+04)
[2022-05-31 18:48:35,726][root][INFO] - Step 110051840 @ 6650.7 SPS. Inference batcher size: 88. Learner queue size: 8. Other stats: (step = 110051840, mean_episode_return = 186.08, mean_episode_step = 553.07, total_loss = 219.49, pg_loss = -19.265, baseline_loss = 244.51, entropy_loss = -5.754, learner_queue_size = 27, _tick = 35950, _time = 1.654e+09, train_seconds = 1.6694e+04)
[2022-05-31 18:48:40,730][root][INFO] - Step 110085120 @ 6650.7 SPS. Inference batcher size: 126. Learner queue size: 24. Other stats: (step = 110085120, mean_episode_return = 134.82, mean_episode_step = 745.0, total_loss = 163.22, pg_loss = 67.729, baseline_loss = 102.08, entropy_loss = -6.5939, learner_queue_size = 17, _tick = 35962, _time = 1.654e+09, train_seconds = 1.6699e+04)
[2022-05-31 18:48:45,734][root][INFO] - Step 110118400 @ 6650.6 SPS. Inference batcher size: 88. Learner queue size: 18. Other stats: (step = 110118400, mean_episode_return = 637.86, mean_episode_step = 668.49, total_loss = 115.23, pg_loss = 6.2506, baseline_loss = 115.37, entropy_loss = -6.3864, learner_queue_size = 14, _tick = 35974, _time = 1.654e+09, train_seconds = 1.6704e+04)
[2022-05-31 18:48:50,738][root][INFO] - Step 110149120 @ 6139.2 SPS. Inference batcher size: 95. Learner queue size: 11. Other stats: (step = 110149120, mean_episode_return = 86.966, mean_episode_step = 633.01, total_loss = 13.675, pg_loss = -34.878, baseline_loss = 55.098, entropy_loss = -6.5454, learner_queue_size = 20, _tick = 35985, _time = 1.654e+09, train_seconds = 1.6709e+04)
[2022-05-31 18:48:55,742][root][INFO] - Step 110182400 @ 6650.2 SPS. Inference batcher size: 134. Learner queue size: 4. Other stats: (step = 110182400, mean_episode_return = 184.21, mean_episode_step = 633.34, total_loss = -2.6849, pg_loss = -11.136, baseline_loss = 15.061, entropy_loss = -6.6097, learner_queue_size = 15, _tick = 35996, _time = 1.654e+09, train_seconds = 1.6714e+04)
[2022-05-31 18:49:00,746][root][INFO] - Step 110215680 @ 6651.2 SPS. Inference batcher size: 110. Learner queue size: 0. Other stats: (step = 110215680, mean_episode_return = 285.69, mean_episode_step = 672.72, total_loss = 256.14, pg_loss = 160.12, baseline_loss = 102.31, entropy_loss = -6.3035, learner_queue_size = 17, _tick = 36008, _time = 1.654e+09, train_seconds = 1.6719e+04)
[2022-05-31 18:49:05,752][root][INFO] - Step 110248960 @ 6648.3 SPS. Inference batcher size: 108. Learner queue size: 2. Other stats: (step = 110248960, mean_episode_return = 98.85, mean_episode_step = 639.37, total_loss = 177.04, pg_loss = 154.11, baseline_loss = 29.177, entropy_loss = -6.2472, learner_queue_size = 17, _tick = 36021, _time = 1.654e+09, train_seconds = 1.6724e+04)
[2022-05-31 18:49:10,754][root][INFO] - Step 110282240 @ 6653.2 SPS. Inference batcher size: 102. Learner queue size: 31. Other stats: (step = 110282240, mean_episode_return = 252.68, mean_episode_step = 855.47, total_loss = 103.6, pg_loss = -16.934, baseline_loss = 126.35, entropy_loss = -5.8085, learner_queue_size = 21, _tick = 36032, _time = 1.654e+09, train_seconds = 1.6729e+04)
[2022-05-31 18:49:15,758][root][INFO] - Step 110315520 @ 6650.7 SPS. Inference batcher size: 106. Learner queue size: 19. Other stats: (step = 110315520, mean_episode_return = 133.43, mean_episode_step = 583.85, total_loss = 16.382, pg_loss = -34.908, baseline_loss = 56.733, entropy_loss = -5.4425, learner_queue_size = 13, _tick = 36045, _time = 1.654e+09, train_seconds = 1.6734e+04)
[2022-05-31 18:49:20,762][root][INFO] - Step 110346240 @ 6139.0 SPS. Inference batcher size: 136. Learner queue size: 20. Other stats: (step = 110346240, mean_episode_return = 125.09, mean_episode_step = 506.97, total_loss = 72.704, pg_loss = -21.262, baseline_loss = 99.6, entropy_loss = -5.6328, learner_queue_size = 14, _tick = 36056, _time = 1.654e+09, train_seconds = 1.6739e+04)
[2022-05-31 18:49:25,766][root][INFO] - Step 110379520 @ 6650.8 SPS. Inference batcher size: 122. Learner queue size: 18. Other stats: (step = 110379520, mean_episode_return = 125.76, mean_episode_step = 543.12, total_loss = 444.45, pg_loss = 163.26, baseline_loss = 286.75, entropy_loss = -5.5691, learner_queue_size = 32, _tick = 36068, _time = 1.654e+09, train_seconds = 1.6744e+04)
[2022-05-31 18:49:30,770][root][INFO] - Step 110412800 @ 6650.3 SPS. Inference batcher size: 69. Learner queue size: 4. Other stats: (step = 110412800, mean_episode_return = 200.85, mean_episode_step = 586.11, total_loss = 129.49, pg_loss = 4.2272, baseline_loss = 131.51, entropy_loss = -6.2543, learner_queue_size = 23, _tick = 36081, _time = 1.654e+09, train_seconds = 1.675e+04)
[2022-05-31 18:49:35,774][root][INFO] - Step 110446080 @ 6650.9 SPS. Inference batcher size: 125. Learner queue size: 4. Other stats: (step = 110446080, mean_episode_return = 300.87, mean_episode_step = 627.49, total_loss = 498.38, pg_loss = 401.2, baseline_loss = 103.37, entropy_loss = -6.1867, learner_queue_size = 13, _tick = 36094, _time = 1.654e+09, train_seconds = 1.6754e+04)
[2022-05-31 18:49:40,778][root][INFO] - Step 110479360 @ 6650.7 SPS. Inference batcher size: 30. Learner queue size: 26. Other stats: (step = 110479360, mean_episode_return = 122.72, mean_episode_step = 584.26, total_loss = 142.26, pg_loss = 2.4661, baseline_loss = 145.52, entropy_loss = -5.7235, learner_queue_size = 13, _tick = 36106, _time = 1.654e+09, train_seconds = 1.676e+04)
[2022-05-31 18:49:45,782][root][INFO] - Step 110512640 @ 6650.6 SPS. Inference batcher size: 41. Learner queue size: 24. Other stats: (step = 110512640, mean_episode_return = 182.03, mean_episode_step = 727.76, total_loss = 69.038, pg_loss = -106.5, baseline_loss = 181.19, entropy_loss = -5.6582, learner_queue_size = 17, _tick = 36116, _time = 1.654e+09, train_seconds = 1.6764e+04)
[2022-05-31 18:49:50,789][root][INFO] - Step 110545920 @ 6647.1 SPS. Inference batcher size: 122. Learner queue size: 3. Other stats: (step = 110545920, mean_episode_return = 426.8, mean_episode_step = 646.72, total_loss = 680.69, pg_loss = 425.14, baseline_loss = 261.56, entropy_loss = -6.0055, learner_queue_size = 20, _tick = 36129, _time = 1.654e+09, train_seconds = 1.677e+04)
[2022-05-31 18:49:55,794][root][INFO] - Step 110579200 @ 6648.8 SPS. Inference batcher size: 34. Learner queue size: 18. Other stats: (step = 110579200, mean_episode_return = 391.0, mean_episode_step = 541.37, total_loss = 54.047, pg_loss = -29.667, baseline_loss = 89.393, entropy_loss = -5.679, learner_queue_size = 18, _tick = 36142, _time = 1.654e+09, train_seconds = 1.6774e+04)
[2022-05-31 18:50:00,802][root][INFO] - Step 110612480 @ 6645.7 SPS. Inference batcher size: 86. Learner queue size: 23. Other stats: (step = 110612480, mean_episode_return = 160.68, mean_episode_step = 505.58, total_loss = 141.53, pg_loss = 42.046, baseline_loss = 104.91, entropy_loss = -5.4278, learner_queue_size = 23, _tick = 36154, _time = 1.654e+09, train_seconds = 1.678e+04)
[2022-05-31 18:50:05,808][root][INFO] - Step 110643200 @ 6136.9 SPS. Inference batcher size: 167. Learner queue size: 15. Other stats: (step = 110643200, mean_episode_return = 287.97, mean_episode_step = 661.82, total_loss = -392.96, pg_loss = -489.65, baseline_loss = 102.48, entropy_loss = -5.791, learner_queue_size = 18, _tick = 36163, _time = 1.654e+09, train_seconds = 1.6784e+04)
[2022-05-31 18:50:10,811][root][INFO] - Step 110676480 @ 6652.3 SPS. Inference batcher size: 213. Learner queue size: 15. Other stats: (step = 110676480, mean_episode_return = 126.6, mean_episode_step = 821.28, total_loss = 69.256, pg_loss = 22.792, baseline_loss = 53.022, entropy_loss = -6.5578, learner_queue_size = 14, _tick = 36175, _time = 1.654e+09, train_seconds = 1.679e+04)
[2022-05-31 18:50:15,814][root][INFO] - Step 110709760 @ 6651.3 SPS. Inference batcher size: 25. Learner queue size: 27. Other stats: (step = 110709760, mean_episode_return = 308.81, mean_episode_step = 718.87, total_loss = 10.628, pg_loss = -66.795, baseline_loss = 83.169, entropy_loss = -5.7458, learner_queue_size = 21, _tick = 36186, _time = 1.654e+09, train_seconds = 1.6794e+04)
[2022-05-31 18:50:20,818][root][INFO] - Step 110745600 @ 7162.4 SPS. Inference batcher size: 48. Learner queue size: 16. Other stats: (step = 110745600, mean_episode_return = 134.15, mean_episode_step = 646.18, total_loss = 279.96, pg_loss = 176.53, baseline_loss = 109.47, entropy_loss = -6.0425, learner_queue_size = 16, _tick = 36200, _time = 1.654e+09, train_seconds = 1.68e+04)
[2022-05-31 18:50:25,822][root][INFO] - Step 110776320 @ 6139.0 SPS. Inference batcher size: 145. Learner queue size: 22. Other stats: (step = 110776320, mean_episode_return = 187.72, mean_episode_step = 663.81, total_loss = 243.35, pg_loss = 110.63, baseline_loss = 138.46, entropy_loss = -5.7378, learner_queue_size = 17, _tick = 36212, _time = 1.654e+09, train_seconds = 1.6804e+04)
[2022-05-31 18:50:30,826][root][INFO] - Step 110809600 @ 6650.7 SPS. Inference batcher size: 94. Learner queue size: 9. Other stats: (step = 110809600, mean_episode_return = 47.51, mean_episode_step = 515.31, total_loss = -38.603, pg_loss = -104.07, baseline_loss = 70.848, entropy_loss = -5.3788, learner_queue_size = 24, _tick = 36225, _time = 1.654e+09, train_seconds = 1.681e+04)
[2022-05-31 18:50:35,830][root][INFO] - Step 110842880 @ 6650.8 SPS. Inference batcher size: 107. Learner queue size: 14. Other stats: (step = 110842880, mean_episode_return = 692.09, mean_episode_step = 674.0, total_loss = 105.76, pg_loss = 50.212, baseline_loss = 61.505, entropy_loss = -5.9623, learner_queue_size = 21, _tick = 36237, _time = 1.654e+09, train_seconds = 1.6814e+04)
[2022-05-31 18:50:40,836][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 18:50:40,949][root][INFO] - Step 110876160 @ 6647.6 SPS. Inference batcher size: 59. Learner queue size: 18. Other stats: (step = 110878720, mean_episode_return = 389.17, mean_episode_step = 611.95, total_loss = -33.129, pg_loss = -47.183, baseline_loss = 20.859, entropy_loss = -6.8059, learner_queue_size = 14, _tick = 36250, _time = 1.654e+09, train_seconds = 1.682e+04)
[2022-05-31 18:50:45,954][root][INFO] - Step 110909440 @ 6503.0 SPS. Inference batcher size: 116. Learner queue size: 23. Other stats: (step = 110909440, mean_episode_return = 186.89, mean_episode_step = 591.46, total_loss = -160.52, pg_loss = -200.29, baseline_loss = 45.729, entropy_loss = -5.9624, learner_queue_size = 12, _tick = 36260, _time = 1.654e+09, train_seconds = 1.6825e+04)
[2022-05-31 18:50:50,958][root][INFO] - Step 110942720 @ 6650.6 SPS. Inference batcher size: 113. Learner queue size: 13. Other stats: (step = 110942720, mean_episode_return = 20.53, mean_episode_step = 682.39, total_loss = -89.636, pg_loss = -126.57, baseline_loss = 43.04, entropy_loss = -6.103, learner_queue_size = 13, _tick = 36273, _time = 1.654e+09, train_seconds = 1.683e+04)
[2022-05-31 18:50:55,964][root][INFO] - Step 110976000 @ 6648.0 SPS. Inference batcher size: 132. Learner queue size: 23. Other stats: (step = 110976000, mean_episode_return = 198.62, mean_episode_step = 693.85, total_loss = -5.3011, pg_loss = -76.324, baseline_loss = 77.251, entropy_loss = -6.2286, learner_queue_size = 20, _tick = 36285, _time = 1.654e+09, train_seconds = 1.6835e+04)
[2022-05-31 18:51:00,970][root][INFO] - Step 111009280 @ 6648.2 SPS. Inference batcher size: 107. Learner queue size: 14. Other stats: (step = 111009280, mean_episode_return = 290.49, mean_episode_step = 665.08, total_loss = 279.57, pg_loss = 135.2, baseline_loss = 150.29, entropy_loss = -5.9169, learner_queue_size = 16, _tick = 36298, _time = 1.654e+09, train_seconds = 1.684e+04)
[2022-05-31 18:51:05,974][root][INFO] - Step 111042560 @ 6650.6 SPS. Inference batcher size: 130. Learner queue size: 8. Other stats: (step = 111042560, mean_episode_return = None, mean_episode_step = 593.09, total_loss = 556.72, pg_loss = 351.86, baseline_loss = 211.11, entropy_loss = -6.2424, learner_queue_size = 20, _tick = 36308, _time = 1.654e+09, train_seconds = 1.6845e+04)
[2022-05-31 18:51:10,980][root][INFO] - Step 111075840 @ 6648.0 SPS. Inference batcher size: 187. Learner queue size: 5. Other stats: (step = 111075840, mean_episode_return = 182.49, mean_episode_step = 526.75, total_loss = 378.86, pg_loss = 219.62, baseline_loss = 164.68, entropy_loss = -5.4482, learner_queue_size = 18, _tick = 36320, _time = 1.654e+09, train_seconds = 1.685e+04)
[2022-05-31 18:51:15,986][root][INFO] - Step 111106560 @ 6137.2 SPS. Inference batcher size: 105. Learner queue size: 13. Other stats: (step = 111106560, mean_episode_return = 969.61, mean_episode_step = 612.45, total_loss = 237.57, pg_loss = 55.594, baseline_loss = 187.62, entropy_loss = -5.6478, learner_queue_size = 16, _tick = 36332, _time = 1.654e+09, train_seconds = 1.6855e+04)
[2022-05-31 18:51:20,992][root][INFO] - Step 111142400 @ 7159.3 SPS. Inference batcher size: 84. Learner queue size: 24. Other stats: (step = 111142400, mean_episode_return = 298.04, mean_episode_step = 700.83, total_loss = -3.5539, pg_loss = -89.744, baseline_loss = 92.48, entropy_loss = -6.2901, learner_queue_size = 13, _tick = 36344, _time = 1.654e+09, train_seconds = 1.686e+04)
[2022-05-31 18:51:25,998][root][INFO] - Step 111173120 @ 6136.1 SPS. Inference batcher size: 125. Learner queue size: 22. Other stats: (step = 111173120, mean_episode_return = 141.48, mean_episode_step = 691.18, total_loss = 1320.1, pg_loss = 491.5, baseline_loss = 834.24, entropy_loss = -5.6199, learner_queue_size = 15, _tick = 36355, _time = 1.654e+09, train_seconds = 1.6865e+04)
[2022-05-31 18:51:31,003][root][INFO] - Step 111208960 @ 7161.5 SPS. Inference batcher size: 62. Learner queue size: 12. Other stats: (step = 111208960, mean_episode_return = 164.65, mean_episode_step = 508.24, total_loss = 298.65, pg_loss = 145.27, baseline_loss = 158.65, entropy_loss = -5.2799, learner_queue_size = 10, _tick = 36369, _time = 1.654e+09, train_seconds = 1.687e+04)
[2022-05-31 18:51:36,009][root][INFO] - Step 111239680 @ 6136.1 SPS. Inference batcher size: 82. Learner queue size: 20. Other stats: (step = 111239680, mean_episode_return = 144.69, mean_episode_step = 692.15, total_loss = 297.55, pg_loss = -448.49, baseline_loss = 751.64, entropy_loss = -5.6026, learner_queue_size = 21, _tick = 36379, _time = 1.654e+09, train_seconds = 1.6875e+04)
[2022-05-31 18:51:41,015][root][INFO] - Step 111272960 @ 6648.0 SPS. Inference batcher size: 18. Learner queue size: 10. Other stats: (step = 111272960, mean_episode_return = 276.72, mean_episode_step = 593.57, total_loss = 51.842, pg_loss = -147.33, baseline_loss = 205.44, entropy_loss = -6.2655, learner_queue_size = 26, _tick = 36392, _time = 1.654e+09, train_seconds = 1.688e+04)
[2022-05-31 18:51:46,021][root][INFO] - Step 111306240 @ 6647.9 SPS. Inference batcher size: 50. Learner queue size: 5. Other stats: (step = 111306240, mean_episode_return = 351.11, mean_episode_step = 526.36, total_loss = 234.43, pg_loss = 121.15, baseline_loss = 119.09, entropy_loss = -5.8109, learner_queue_size = 21, _tick = 36404, _time = 1.654e+09, train_seconds = 1.6885e+04)
[2022-05-31 18:51:51,026][root][INFO] - Step 111339520 @ 6649.5 SPS. Inference batcher size: 144. Learner queue size: 10. Other stats: (step = 111339520, mean_episode_return = 399.72, mean_episode_step = 641.95, total_loss = 118.67, pg_loss = -83.71, baseline_loss = 208.44, entropy_loss = -6.056, learner_queue_size = 17, _tick = 36417, _time = 1.654e+09, train_seconds = 1.689e+04)
[2022-05-31 18:51:56,030][root][INFO] - Step 111372800 @ 6650.5 SPS. Inference batcher size: 76. Learner queue size: 31. Other stats: (step = 111372800, mean_episode_return = None, mean_episode_step = 728.28, total_loss = 434.98, pg_loss = 238.55, baseline_loss = 202.02, entropy_loss = -5.5839, learner_queue_size = 25, _tick = 36429, _time = 1.654e+09, train_seconds = 1.6895e+04)
[2022-05-31 18:52:01,034][root][INFO] - Step 111406080 @ 6650.8 SPS. Inference batcher size: 84. Learner queue size: 30. Other stats: (step = 111406080, mean_episode_return = 705.09, mean_episode_step = 625.3, total_loss = -71.483, pg_loss = -178.36, baseline_loss = 112.67, entropy_loss = -5.7893, learner_queue_size = 14, _tick = 36441, _time = 1.654e+09, train_seconds = 1.69e+04)
[2022-05-31 18:52:06,041][root][INFO] - Step 111436800 @ 6135.7 SPS. Inference batcher size: 135. Learner queue size: 14. Other stats: (step = 111436800, mean_episode_return = None, mean_episode_step = 709.25, total_loss = -125.2, pg_loss = -264.62, baseline_loss = 144.75, entropy_loss = -5.3277, learner_queue_size = 25, _tick = 36452, _time = 1.654e+09, train_seconds = 1.6905e+04)
[2022-05-31 18:52:11,046][root][INFO] - Step 111472640 @ 7160.4 SPS. Inference batcher size: 88. Learner queue size: 13. Other stats: (step = 111472640, mean_episode_return = 477.91, mean_episode_step = 499.24, total_loss = 195.22, pg_loss = -235.82, baseline_loss = 436.28, entropy_loss = -5.2449, learner_queue_size = 13, _tick = 36466, _time = 1.654e+09, train_seconds = 1.691e+04)
[2022-05-31 18:52:16,054][root][INFO] - Step 111503360 @ 6134.7 SPS. Inference batcher size: 115. Learner queue size: 15. Other stats: (step = 111503360, mean_episode_return = 86.524, mean_episode_step = 658.26, total_loss = 346.64, pg_loss = 219.89, baseline_loss = 132.94, entropy_loss = -6.1962, learner_queue_size = 17, _tick = 36478, _time = 1.654e+09, train_seconds = 1.6915e+04)
[2022-05-31 18:52:21,058][root][INFO] - Step 111536640 @ 6650.1 SPS. Inference batcher size: 48. Learner queue size: 3. Other stats: (step = 111536640, mean_episode_return = 405.56, mean_episode_step = 773.49, total_loss = 323.66, pg_loss = 160.38, baseline_loss = 169.12, entropy_loss = -5.8374, learner_queue_size = 14, _tick = 36491, _time = 1.654e+09, train_seconds = 1.692e+04)
[2022-05-31 18:52:26,062][root][INFO] - Step 111569920 @ 6650.8 SPS. Inference batcher size: 101. Learner queue size: 19. Other stats: (step = 111569920, mean_episode_return = 371.01, mean_episode_step = 667.31, total_loss = 214.93, pg_loss = -7.7942, baseline_loss = 228.07, entropy_loss = -5.3487, learner_queue_size = 16, _tick = 36503, _time = 1.654e+09, train_seconds = 1.6925e+04)
[2022-05-31 18:52:31,068][root][INFO] - Step 111603200 @ 6647.8 SPS. Inference batcher size: 61. Learner queue size: 4. Other stats: (step = 111603200, mean_episode_return = 237.0, mean_episode_step = 558.64, total_loss = -136.78, pg_loss = -177.39, baseline_loss = 46.714, entropy_loss = -6.1074, learner_queue_size = 19, _tick = 36516, _time = 1.654e+09, train_seconds = 1.693e+04)
[2022-05-31 18:52:36,070][root][INFO] - Step 111636480 @ 6653.5 SPS. Inference batcher size: 141. Learner queue size: 31. Other stats: (step = 111636480, mean_episode_return = 207.37, mean_episode_step = 634.22, total_loss = 80.353, pg_loss = 37.832, baseline_loss = 48.663, entropy_loss = -6.142, learner_queue_size = 16, _tick = 36528, _time = 1.654e+09, train_seconds = 1.6935e+04)
[2022-05-31 18:52:41,074][root][INFO] - Step 111667200 @ 6139.1 SPS. Inference batcher size: 96. Learner queue size: 23. Other stats: (step = 111667200, mean_episode_return = 173.06, mean_episode_step = 750.49, total_loss = 65.124, pg_loss = 35.248, baseline_loss = 36.067, entropy_loss = -6.1906, learner_queue_size = 12, _tick = 36540, _time = 1.654e+09, train_seconds = 1.694e+04)
[2022-05-31 18:52:46,080][root][INFO] - Step 111700480 @ 6647.9 SPS. Inference batcher size: 143. Learner queue size: 17. Other stats: (step = 111700480, mean_episode_return = 120.48, mean_episode_step = 711.69, total_loss = 101.17, pg_loss = 57.608, baseline_loss = 49.378, entropy_loss = -5.818, learner_queue_size = 12, _tick = 36552, _time = 1.654e+09, train_seconds = 1.6945e+04)
[2022-05-31 18:52:51,086][root][INFO] - Step 111736320 @ 7159.6 SPS. Inference batcher size: 12. Learner queue size: 22. Other stats: (step = 111736320, mean_episode_return = None, mean_episode_step = 574.72, total_loss = 102.02, pg_loss = 43.739, baseline_loss = 64.472, entropy_loss = -6.1888, learner_queue_size = 19, _tick = 36565, _time = 1.654e+09, train_seconds = 1.695e+04)
[2022-05-31 18:52:56,092][root][INFO] - Step 111767040 @ 6136.1 SPS. Inference batcher size: 139. Learner queue size: 16. Other stats: (step = 111767040, mean_episode_return = 88.633, mean_episode_step = 771.23, total_loss = 47.344, pg_loss = 8.2036, baseline_loss = 45.802, entropy_loss = -6.6617, learner_queue_size = 13, _tick = 36574, _time = 1.654e+09, train_seconds = 1.6955e+04)
[2022-05-31 18:53:01,098][root][INFO] - Step 111800320 @ 6648.5 SPS. Inference batcher size: 21. Learner queue size: 7. Other stats: (step = 111800320, mean_episode_return = 236.02, mean_episode_step = 654.81, total_loss = 32.648, pg_loss = -14.071, baseline_loss = 52.497, entropy_loss = -5.7779, learner_queue_size = 22, _tick = 36586, _time = 1.654e+09, train_seconds = 1.696e+04)
[2022-05-31 18:53:06,106][root][INFO] - Step 111833600 @ 6644.9 SPS. Inference batcher size: 80. Learner queue size: 2. Other stats: (step = 111833600, mean_episode_return = 153.7, mean_episode_step = 538.17, total_loss = 2.1938, pg_loss = -137.25, baseline_loss = 145.14, entropy_loss = -5.6932, learner_queue_size = 11, _tick = 36598, _time = 1.654e+09, train_seconds = 1.6965e+04)
[2022-05-31 18:53:11,110][root][INFO] - Step 111866880 @ 6651.3 SPS. Inference batcher size: 32. Learner queue size: 22. Other stats: (step = 111866880, mean_episode_return = 247.03, mean_episode_step = 777.04, total_loss = -12.298, pg_loss = -79.847, baseline_loss = 73.418, entropy_loss = -5.8688, learner_queue_size = 18, _tick = 36610, _time = 1.654e+09, train_seconds = 1.697e+04)
[2022-05-31 18:53:16,114][root][INFO] - Step 111900160 @ 6650.6 SPS. Inference batcher size: 72. Learner queue size: 24. Other stats: (step = 111900160, mean_episode_return = 131.89, mean_episode_step = 665.34, total_loss = 230.26, pg_loss = 151.93, baseline_loss = 83.758, entropy_loss = -5.4232, learner_queue_size = 16, _tick = 36622, _time = 1.654e+09, train_seconds = 1.6975e+04)
[2022-05-31 18:53:21,118][root][INFO] - Step 111933440 @ 6650.7 SPS. Inference batcher size: 135. Learner queue size: 31. Other stats: (step = 111933440, mean_episode_return = 165.14, mean_episode_step = 722.42, total_loss = 128.63, pg_loss = -26.35, baseline_loss = 160.58, entropy_loss = -5.5934, learner_queue_size = 25, _tick = 36634, _time = 1.654e+09, train_seconds = 1.698e+04)
[2022-05-31 18:53:26,122][root][INFO] - Step 111966720 @ 6650.8 SPS. Inference batcher size: 120. Learner queue size: 18. Other stats: (step = 111966720, mean_episode_return = 134.61, mean_episode_step = 690.31, total_loss = -149.99, pg_loss = -221.09, baseline_loss = 77.013, entropy_loss = -5.9142, learner_queue_size = 8, _tick = 36646, _time = 1.654e+09, train_seconds = 1.6985e+04)
[2022-05-31 18:53:31,124][root][INFO] - Step 112000000 @ 6653.0 SPS. Inference batcher size: 63. Learner queue size: 13. Other stats: (step = 112000000, mean_episode_return = 195.28, mean_episode_step = 629.37, total_loss = 453.02, pg_loss = 282.11, baseline_loss = 176.62, entropy_loss = -5.7201, learner_queue_size = 11, _tick = 36659, _time = 1.654e+09, train_seconds = 1.699e+04)
[2022-05-31 18:53:36,130][root][INFO] - Step 112030720 @ 6137.0 SPS. Inference batcher size: 74. Learner queue size: 20. Other stats: (step = 112030720, mean_episode_return = 619.2, mean_episode_step = 665.74, total_loss = 290.47, pg_loss = 94.54, baseline_loss = 201.52, entropy_loss = -5.5914, learner_queue_size = 22, _tick = 36669, _time = 1.654e+09, train_seconds = 1.6995e+04)
[2022-05-31 18:53:41,136][root][INFO] - Step 112064000 @ 6647.6 SPS. Inference batcher size: 119. Learner queue size: 16. Other stats: (step = 112064000, mean_episode_return = None, mean_episode_step = 909.06, total_loss = 122.49, pg_loss = 64.341, baseline_loss = 64.102, entropy_loss = -5.9574, learner_queue_size = 27, _tick = 36679, _time = 1.654e+09, train_seconds = 1.7e+04)
[2022-05-31 18:53:46,141][root][INFO] - Step 112097280 @ 6649.9 SPS. Inference batcher size: 97. Learner queue size: 3. Other stats: (step = 112097280, mean_episode_return = 297.19, mean_episode_step = 732.42, total_loss = 147.84, pg_loss = 52.178, baseline_loss = 101.26, entropy_loss = -5.6019, learner_queue_size = 12, _tick = 36691, _time = 1.654e+09, train_seconds = 1.7005e+04)
[2022-05-31 18:53:51,146][root][INFO] - Step 112130560 @ 6649.2 SPS. Inference batcher size: 134. Learner queue size: 0. Other stats: (step = 112130560, mean_episode_return = 132.49, mean_episode_step = 761.63, total_loss = 636.39, pg_loss = 327.14, baseline_loss = 315.22, entropy_loss = -5.9662, learner_queue_size = 12, _tick = 36704, _time = 1.654e+09, train_seconds = 1.701e+04)
[2022-05-31 18:53:56,150][root][INFO] - Step 112163840 @ 6650.6 SPS. Inference batcher size: 95. Learner queue size: 6. Other stats: (step = 112163840, mean_episode_return = 96.421, mean_episode_step = 787.92, total_loss = -155.02, pg_loss = -262.09, baseline_loss = 113.01, entropy_loss = -5.9443, learner_queue_size = 15, _tick = 36716, _time = 1.654e+09, train_seconds = 1.7015e+04)
[2022-05-31 18:54:01,156][root][INFO] - Step 112197120 @ 6648.1 SPS. Inference batcher size: 37. Learner queue size: 28. Other stats: (step = 112197120, mean_episode_return = 287.32, mean_episode_step = 495.11, total_loss = 301.11, pg_loss = 181.49, baseline_loss = 124.81, entropy_loss = -5.1842, learner_queue_size = 26, _tick = 36729, _time = 1.654e+09, train_seconds = 1.702e+04)
[2022-05-31 18:54:06,162][root][INFO] - Step 112230400 @ 6648.0 SPS. Inference batcher size: 76. Learner queue size: 31. Other stats: (step = 112230400, mean_episode_return = 201.0, mean_episode_step = 516.07, total_loss = 154.51, pg_loss = 33.925, baseline_loss = 126.23, entropy_loss = -5.6412, learner_queue_size = 24, _tick = 36741, _time = 1.654e+09, train_seconds = 1.7025e+04)
[2022-05-31 18:54:11,166][root][INFO] - Step 112263680 @ 6650.6 SPS. Inference batcher size: 104. Learner queue size: 24. Other stats: (step = 112263680, mean_episode_return = 186.4, mean_episode_step = 669.9, total_loss = -27.155, pg_loss = -67.412, baseline_loss = 46.585, entropy_loss = -6.3283, learner_queue_size = 19, _tick = 36752, _time = 1.654e+09, train_seconds = 1.703e+04)
[2022-05-31 18:54:16,172][root][INFO] - Step 112294400 @ 6136.5 SPS. Inference batcher size: 102. Learner queue size: 11. Other stats: (step = 112294400, mean_episode_return = 335.01, mean_episode_step = 643.36, total_loss = 108.11, pg_loss = 59.061, baseline_loss = 55.186, entropy_loss = -6.1374, learner_queue_size = 17, _tick = 36763, _time = 1.654e+09, train_seconds = 1.7035e+04)
[2022-05-31 18:54:21,178][root][INFO] - Step 112330240 @ 7159.6 SPS. Inference batcher size: 155. Learner queue size: 19. Other stats: (step = 112330240, mean_episode_return = 157.55, mean_episode_step = 595.67, total_loss = 72.618, pg_loss = 14.136, baseline_loss = 64.445, entropy_loss = -5.9638, learner_queue_size = 16, _tick = 36776, _time = 1.654e+09, train_seconds = 1.704e+04)
[2022-05-31 18:54:26,184][root][INFO] - Step 112360960 @ 6136.6 SPS. Inference batcher size: 95. Learner queue size: 21. Other stats: (step = 112360960, mean_episode_return = 247.18, mean_episode_step = 631.8, total_loss = -74.864, pg_loss = -146.9, baseline_loss = 77.99, entropy_loss = -5.9487, learner_queue_size = 23, _tick = 36788, _time = 1.654e+09, train_seconds = 1.7045e+04)
[2022-05-31 18:54:31,190][root][INFO] - Step 112394240 @ 6648.0 SPS. Inference batcher size: 26. Learner queue size: 18. Other stats: (step = 112394240, mean_episode_return = 490.94, mean_episode_step = 722.82, total_loss = -88.048, pg_loss = -131.07, baseline_loss = 49.25, entropy_loss = -6.2269, learner_queue_size = 15, _tick = 36797, _time = 1.654e+09, train_seconds = 1.705e+04)
[2022-05-31 18:54:36,197][root][INFO] - Step 112427520 @ 6646.7 SPS. Inference batcher size: 125. Learner queue size: 10. Other stats: (step = 112427520, mean_episode_return = 270.78, mean_episode_step = 772.19, total_loss = 29.288, pg_loss = -85.291, baseline_loss = 120.25, entropy_loss = -5.6733, learner_queue_size = 16, _tick = 36807, _time = 1.654e+09, train_seconds = 1.7055e+04)
[2022-05-31 18:54:41,202][root][INFO] - Step 112460800 @ 6649.5 SPS. Inference batcher size: 66. Learner queue size: 8. Other stats: (step = 112460800, mean_episode_return = 259.28, mean_episode_step = 748.3, total_loss = 195.73, pg_loss = 85.72, baseline_loss = 115.93, entropy_loss = -5.9225, learner_queue_size = 15, _tick = 36820, _time = 1.654e+09, train_seconds = 1.706e+04)
[2022-05-31 18:54:46,208][root][INFO] - Step 112494080 @ 6648.1 SPS. Inference batcher size: 149. Learner queue size: 3. Other stats: (step = 112494080, mean_episode_return = 282.43, mean_episode_step = 712.42, total_loss = 132.33, pg_loss = 18.339, baseline_loss = 119.76, entropy_loss = -5.7683, learner_queue_size = 24, _tick = 36831, _time = 1.654e+09, train_seconds = 1.7065e+04)
[2022-05-31 18:54:51,210][root][INFO] - Step 112527360 @ 6652.7 SPS. Inference batcher size: 126. Learner queue size: 0. Other stats: (step = 112527360, mean_episode_return = 210.15, mean_episode_step = 532.1, total_loss = -17.941, pg_loss = -128.12, baseline_loss = 115.64, entropy_loss = -5.4704, learner_queue_size = 23, _tick = 36842, _time = 1.654e+09, train_seconds = 1.707e+04)
[2022-05-31 18:54:56,217][root][INFO] - Step 112560640 @ 6647.5 SPS. Inference batcher size: 87. Learner queue size: 29. Other stats: (step = 112560640, mean_episode_return = 260.05, mean_episode_step = 658.51, total_loss = 447.93, pg_loss = 292.53, baseline_loss = 160.36, entropy_loss = -4.9616, learner_queue_size = 25, _tick = 36855, _time = 1.654e+09, train_seconds = 1.7075e+04)
[2022-05-31 18:55:01,223][root][INFO] - Step 112591360 @ 6136.5 SPS. Inference batcher size: 106. Learner queue size: 16. Other stats: (step = 112591360, mean_episode_return = 270.44, mean_episode_step = 680.26, total_loss = -67.462, pg_loss = -125.93, baseline_loss = 64.161, entropy_loss = -5.6921, learner_queue_size = 13, _tick = 36865, _time = 1.654e+09, train_seconds = 1.708e+04)
[2022-05-31 18:55:06,226][root][INFO] - Step 112624640 @ 6651.9 SPS. Inference batcher size: 139. Learner queue size: 14. Other stats: (step = 112624640, mean_episode_return = None, mean_episode_step = 630.41, total_loss = 196.95, pg_loss = 142.93, baseline_loss = 60.008, entropy_loss = -5.9823, learner_queue_size = 20, _tick = 36876, _time = 1.654e+09, train_seconds = 1.7085e+04)
[2022-05-31 18:55:11,230][root][INFO] - Step 112657920 @ 6650.6 SPS. Inference batcher size: 77. Learner queue size: 3. Other stats: (step = 112657920, mean_episode_return = 270.81, mean_episode_step = 517.68, total_loss = 64.005, pg_loss = -74.988, baseline_loss = 144.61, entropy_loss = -5.617, learner_queue_size = 12, _tick = 36889, _time = 1.654e+09, train_seconds = 1.709e+04)
[2022-05-31 18:55:16,236][root][INFO] - Step 112691200 @ 6648.0 SPS. Inference batcher size: 117. Learner queue size: 6. Other stats: (step = 112691200, mean_episode_return = 232.04, mean_episode_step = 589.59, total_loss = 175.26, pg_loss = 6.5912, baseline_loss = 173.81, entropy_loss = -5.148, learner_queue_size = 15, _tick = 36899, _time = 1.654e+09, train_seconds = 1.7095e+04)
[2022-05-31 18:55:21,238][root][INFO] - Step 112724480 @ 6653.5 SPS. Inference batcher size: 121. Learner queue size: 2. Other stats: (step = 112724480, mean_episode_return = 185.09, mean_episode_step = 768.96, total_loss = 92.307, pg_loss = 32.824, baseline_loss = 65.199, entropy_loss = -5.7161, learner_queue_size = 9, _tick = 36911, _time = 1.654e+09, train_seconds = 1.71e+04)
[2022-05-31 18:55:26,242][root][INFO] - Step 112757760 @ 6650.8 SPS. Inference batcher size: 135. Learner queue size: 30. Other stats: (step = 112757760, mean_episode_return = 307.82, mean_episode_step = 722.22, total_loss = 296.51, pg_loss = 71.34, baseline_loss = 230.57, entropy_loss = -5.3975, learner_queue_size = 16, _tick = 36924, _time = 1.654e+09, train_seconds = 1.7105e+04)
[2022-05-31 18:55:31,246][root][INFO] - Step 112791040 @ 6650.6 SPS. Inference batcher size: 24. Learner queue size: 13. Other stats: (step = 112791040, mean_episode_return = 302.5, mean_episode_step = 689.16, total_loss = -34.228, pg_loss = -167.75, baseline_loss = 138.88, entropy_loss = -5.3579, learner_queue_size = 13, _tick = 36937, _time = 1.654e+09, train_seconds = 1.711e+04)
[2022-05-31 18:55:36,250][root][INFO] - Step 112824320 @ 6650.7 SPS. Inference batcher size: 89. Learner queue size: 15. Other stats: (step = 112824320, mean_episode_return = 55.282, mean_episode_step = 613.1, total_loss = -4.2849, pg_loss = -61.714, baseline_loss = 62.925, entropy_loss = -5.4956, learner_queue_size = 15, _tick = 36950, _time = 1.654e+09, train_seconds = 1.7115e+04)
[2022-05-31 18:55:41,256][root][INFO] - Step 112855040 @ 6136.6 SPS. Inference batcher size: 164. Learner queue size: 16. Other stats: (step = 112855040, mean_episode_return = 527.7, mean_episode_step = 659.56, total_loss = -389.86, pg_loss = -465.02, baseline_loss = 80.701, entropy_loss = -5.5421, learner_queue_size = 20, _tick = 36959, _time = 1.654e+09, train_seconds = 1.712e+04)
[2022-05-31 18:55:46,262][root][INFO] - Step 112888320 @ 6648.1 SPS. Inference batcher size: 112. Learner queue size: 11. Other stats: (step = 112888320, mean_episode_return = 173.35, mean_episode_step = 609.33, total_loss = 95.222, pg_loss = -31.022, baseline_loss = 131.84, entropy_loss = -5.5962, learner_queue_size = 11, _tick = 36972, _time = 1.654e+09, train_seconds = 1.7125e+04)
[2022-05-31 18:55:51,266][root][INFO] - Step 112921600 @ 6650.5 SPS. Inference batcher size: 38. Learner queue size: 30. Other stats: (step = 112921600, mean_episode_return = 216.32, mean_episode_step = 687.57, total_loss = -188.26, pg_loss = -242.38, baseline_loss = 60.243, entropy_loss = -6.1275, learner_queue_size = 25, _tick = 36984, _time = 1.654e+09, train_seconds = 1.713e+04)
[2022-05-31 18:55:56,270][root][INFO] - Step 112954880 @ 6650.7 SPS. Inference batcher size: 149. Learner queue size: 13. Other stats: (step = 112954880, mean_episode_return = None, mean_episode_step = 772.5, total_loss = -117.97, pg_loss = -122.48, baseline_loss = 11.234, entropy_loss = -6.7188, learner_queue_size = 25, _tick = 36995, _time = 1.654e+09, train_seconds = 1.7135e+04)
[2022-05-31 18:56:01,276][root][INFO] - Step 112988160 @ 6648.0 SPS. Inference batcher size: 141. Learner queue size: 12. Other stats: (step = 112988160, mean_episode_return = 909.62, mean_episode_step = 625.87, total_loss = 79.215, pg_loss = 71.32, baseline_loss = 14.911, entropy_loss = -7.0158, learner_queue_size = 16, _tick = 37007, _time = 1.654e+09, train_seconds = 1.714e+04)
[2022-05-31 18:56:06,282][root][INFO] - Step 113021440 @ 6648.0 SPS. Inference batcher size: 141. Learner queue size: 27. Other stats: (step = 113021440, mean_episode_return = 98.936, mean_episode_step = 660.72, total_loss = 195.6, pg_loss = 154.79, baseline_loss = 47.014, entropy_loss = -6.2048, learner_queue_size = 17, _tick = 37020, _time = 1.654e+09, train_seconds = 1.7145e+04)
[2022-05-31 18:56:11,288][root][INFO] - Step 113054720 @ 6648.0 SPS. Inference batcher size: 176. Learner queue size: 13. Other stats: (step = 113054720, mean_episode_return = 126.49, mean_episode_step = 714.17, total_loss = -65.774, pg_loss = -101.46, baseline_loss = 41.957, entropy_loss = -6.2687, learner_queue_size = 23, _tick = 37031, _time = 1.654e+09, train_seconds = 1.715e+04)
[2022-05-31 18:56:16,294][root][INFO] - Step 113088000 @ 6648.0 SPS. Inference batcher size: 112. Learner queue size: 21. Other stats: (step = 113088000, mean_episode_return = 145.08, mean_episode_step = 773.9, total_loss = 373.07, pg_loss = 222.22, baseline_loss = 156.85, entropy_loss = -6.0017, learner_queue_size = 15, _tick = 37043, _time = 1.654e+09, train_seconds = 1.7155e+04)
[2022-05-31 18:56:21,300][root][INFO] - Step 113121280 @ 6648.0 SPS. Inference batcher size: 108. Learner queue size: 1. Other stats: (step = 113121280, mean_episode_return = 195.98, mean_episode_step = 644.65, total_loss = 96.319, pg_loss = -63.218, baseline_loss = 165.37, entropy_loss = -5.8323, learner_queue_size = 18, _tick = 37055, _time = 1.654e+09, train_seconds = 1.716e+04)
[2022-05-31 18:56:26,306][root][INFO] - Step 113154560 @ 6648.2 SPS. Inference batcher size: 131. Learner queue size: 26. Other stats: (step = 113154560, mean_episode_return = 609.26, mean_episode_step = 692.82, total_loss = 277.22, pg_loss = 146.17, baseline_loss = 136.55, entropy_loss = -5.4903, learner_queue_size = 18, _tick = 37067, _time = 1.654e+09, train_seconds = 1.7165e+04)
[2022-05-31 18:56:31,312][root][INFO] - Step 113187840 @ 6647.4 SPS. Inference batcher size: 145. Learner queue size: 21. Other stats: (step = 113187840, mean_episode_return = 90.81, mean_episode_step = 643.4, total_loss = 127.07, pg_loss = 7.7423, baseline_loss = 125.06, entropy_loss = -5.7313, learner_queue_size = 21, _tick = 37080, _time = 1.654e+09, train_seconds = 1.717e+04)
[2022-05-31 18:56:36,318][root][INFO] - Step 113218560 @ 6136.6 SPS. Inference batcher size: 92. Learner queue size: 25. Other stats: (step = 113218560, mean_episode_return = 439.29, mean_episode_step = 512.42, total_loss = 372.02, pg_loss = 229.86, baseline_loss = 147.52, entropy_loss = -5.3634, learner_queue_size = 14, _tick = 37091, _time = 1.654e+09, train_seconds = 1.7175e+04)
[2022-05-31 18:56:41,324][root][INFO] - Step 113251840 @ 6648.0 SPS. Inference batcher size: 78. Learner queue size: 15. Other stats: (step = 113251840, mean_episode_return = 648.91, mean_episode_step = 719.55, total_loss = 236.16, pg_loss = 107.33, baseline_loss = 134.54, entropy_loss = -5.7112, learner_queue_size = 12, _tick = 37102, _time = 1.654e+09, train_seconds = 1.718e+04)
[2022-05-31 18:56:46,330][root][INFO] - Step 113285120 @ 6648.6 SPS. Inference batcher size: 35. Learner queue size: 12. Other stats: (step = 113285120, mean_episode_return = 149.89, mean_episode_step = 561.32, total_loss = 105.17, pg_loss = 13.101, baseline_loss = 98.096, entropy_loss = -6.0267, learner_queue_size = 7, _tick = 37113, _time = 1.654e+09, train_seconds = 1.7185e+04)
[2022-05-31 18:56:51,334][root][INFO] - Step 113318400 @ 6650.6 SPS. Inference batcher size: 32. Learner queue size: 12. Other stats: (step = 113318400, mean_episode_return = 768.18, mean_episode_step = 606.76, total_loss = 219.45, pg_loss = 38.924, baseline_loss = 186.06, entropy_loss = -5.5269, learner_queue_size = 18, _tick = 37126, _time = 1.654e+09, train_seconds = 1.719e+04)
[2022-05-31 18:56:56,340][root][INFO] - Step 113351680 @ 6647.4 SPS. Inference batcher size: 84. Learner queue size: 7. Other stats: (step = 113351680, mean_episode_return = 283.16, mean_episode_step = 762.16, total_loss = 170.83, pg_loss = -236.85, baseline_loss = 413.33, entropy_loss = -5.6517, learner_queue_size = 15, _tick = 37138, _time = 1.654e+09, train_seconds = 1.7195e+04)
[2022-05-31 18:57:01,347][root][INFO] - Step 113384960 @ 6647.2 SPS. Inference batcher size: 80. Learner queue size: 24. Other stats: (step = 113384960, mean_episode_return = 159.74, mean_episode_step = 549.1, total_loss = 296.03, pg_loss = 104.97, baseline_loss = 196.83, entropy_loss = -5.7611, learner_queue_size = 23, _tick = 37151, _time = 1.654e+09, train_seconds = 1.72e+04)
[2022-05-31 18:57:06,354][root][INFO] - Step 113418240 @ 6647.0 SPS. Inference batcher size: 92. Learner queue size: 21. Other stats: (step = 113418240, mean_episode_return = 662.09, mean_episode_step = 450.48, total_loss = 305.55, pg_loss = 140.4, baseline_loss = 171.12, entropy_loss = -5.9669, learner_queue_size = 14, _tick = 37163, _time = 1.654e+09, train_seconds = 1.7205e+04)
[2022-05-31 18:57:11,358][root][INFO] - Step 113448960 @ 6139.0 SPS. Inference batcher size: 98. Learner queue size: 17. Other stats: (step = 113448960, mean_episode_return = 170.36, mean_episode_step = 617.77, total_loss = -14.577, pg_loss = -81.347, baseline_loss = 73.189, entropy_loss = -6.4189, learner_queue_size = 25, _tick = 37174, _time = 1.654e+09, train_seconds = 1.721e+04)
[2022-05-31 18:57:16,362][root][INFO] - Step 113482240 @ 6650.7 SPS. Inference batcher size: 128. Learner queue size: 8. Other stats: (step = 113482240, mean_episode_return = 175.17, mean_episode_step = 684.88, total_loss = 129.72, pg_loss = 58.287, baseline_loss = 77.656, entropy_loss = -6.2245, learner_queue_size = 9, _tick = 37187, _time = 1.654e+09, train_seconds = 1.7215e+04)
[2022-05-31 18:57:21,366][root][INFO] - Step 113515520 @ 6650.7 SPS. Inference batcher size: 43. Learner queue size: 15. Other stats: (step = 113515520, mean_episode_return = 181.27, mean_episode_step = 688.09, total_loss = 560.41, pg_loss = 442.53, baseline_loss = 123.73, entropy_loss = -5.8569, learner_queue_size = 19, _tick = 37199, _time = 1.654e+09, train_seconds = 1.722e+04)
[2022-05-31 18:57:26,373][root][INFO] - Step 113548800 @ 6646.4 SPS. Inference batcher size: 78. Learner queue size: 5. Other stats: (step = 113548800, mean_episode_return = 245.91, mean_episode_step = 587.1, total_loss = 157.88, pg_loss = 25.069, baseline_loss = 138.29, entropy_loss = -5.4826, learner_queue_size = 23, _tick = 37211, _time = 1.654e+09, train_seconds = 1.7225e+04)
[2022-05-31 18:57:31,378][root][INFO] - Step 113582080 @ 6649.6 SPS. Inference batcher size: 162. Learner queue size: 2. Other stats: (step = 113582080, mean_episode_return = 452.41, mean_episode_step = 569.74, total_loss = 210.53, pg_loss = 78.172, baseline_loss = 138.61, entropy_loss = -6.2469, learner_queue_size = 17, _tick = 37224, _time = 1.654e+09, train_seconds = 1.723e+04)
[2022-05-31 18:57:36,384][root][INFO] - Step 113615360 @ 6647.9 SPS. Inference batcher size: 17. Learner queue size: 3. Other stats: (step = 113615360, mean_episode_return = None, mean_episode_step = 924.84, total_loss = 54.128, pg_loss = 23.532, baseline_loss = 37.077, entropy_loss = -6.481, learner_queue_size = 24, _tick = 37236, _time = 1.654e+09, train_seconds = 1.7235e+04)
[2022-05-31 18:57:41,390][root][INFO] - Step 113648640 @ 6648.4 SPS. Inference batcher size: 38. Learner queue size: 20. Other stats: (step = 113648640, mean_episode_return = 365.1, mean_episode_step = 730.49, total_loss = 21.373, pg_loss = -42.324, baseline_loss = 69.653, entropy_loss = -5.9567, learner_queue_size = 13, _tick = 37249, _time = 1.654e+09, train_seconds = 1.724e+04)
[2022-05-31 18:57:46,396][root][INFO] - Step 113679360 @ 6136.0 SPS. Inference batcher size: 107. Learner queue size: 20. Other stats: (step = 113679360, mean_episode_return = 447.66, mean_episode_step = 484.1, total_loss = -288.28, pg_loss = -452.15, baseline_loss = 169.45, entropy_loss = -5.5834, learner_queue_size = 20, _tick = 37260, _time = 1.654e+09, train_seconds = 1.7245e+04)
[2022-05-31 18:57:51,402][root][INFO] - Step 113712640 @ 6648.5 SPS. Inference batcher size: 142. Learner queue size: 10. Other stats: (step = 113712640, mean_episode_return = 253.81, mean_episode_step = 514.86, total_loss = -181.89, pg_loss = -363.6, baseline_loss = 187.0, entropy_loss = -5.2904, learner_queue_size = 23, _tick = 37273, _time = 1.654e+09, train_seconds = 1.725e+04)
[2022-05-31 18:57:56,406][root][INFO] - Step 113745920 @ 6650.7 SPS. Inference batcher size: 87. Learner queue size: 14. Other stats: (step = 113745920, mean_episode_return = 172.7, mean_episode_step = 538.05, total_loss = 388.78, pg_loss = 130.04, baseline_loss = 264.34, entropy_loss = -5.5984, learner_queue_size = 20, _tick = 37284, _time = 1.654e+09, train_seconds = 1.7255e+04)
[2022-05-31 18:58:01,410][root][INFO] - Step 113779200 @ 6650.7 SPS. Inference batcher size: 147. Learner queue size: 8. Other stats: (step = 113779200, mean_episode_return = 343.94, mean_episode_step = 654.07, total_loss = 665.89, pg_loss = 409.45, baseline_loss = 262.16, entropy_loss = -5.723, learner_queue_size = 14, _tick = 37297, _time = 1.654e+09, train_seconds = 1.726e+04)
[2022-05-31 18:58:06,414][root][INFO] - Step 113812480 @ 6650.6 SPS. Inference batcher size: 166. Learner queue size: 4. Other stats: (step = 113812480, mean_episode_return = 97.448, mean_episode_step = 692.5, total_loss = -300.07, pg_loss = -345.03, baseline_loss = 51.67, entropy_loss = -6.7054, learner_queue_size = 16, _tick = 37310, _time = 1.654e+09, train_seconds = 1.7265e+04)
[2022-05-31 18:58:11,418][root][INFO] - Step 113845760 @ 6650.7 SPS. Inference batcher size: 63. Learner queue size: 23. Other stats: (step = 113845760, mean_episode_return = 470.95, mean_episode_step = 707.31, total_loss = 158.76, pg_loss = 88.199, baseline_loss = 77.304, entropy_loss = -6.7468, learner_queue_size = 17, _tick = 37321, _time = 1.654e+09, train_seconds = 1.727e+04)
[2022-05-31 18:58:16,422][root][INFO] - Step 113879040 @ 6650.7 SPS. Inference batcher size: 87. Learner queue size: 26. Other stats: (step = 113879040, mean_episode_return = 211.14, mean_episode_step = 1028.0, total_loss = 4.9687, pg_loss = -54.075, baseline_loss = 66.019, entropy_loss = -6.975, learner_queue_size = 18, _tick = 37332, _time = 1.654e+09, train_seconds = 1.7275e+04)
[2022-05-31 18:58:21,426][root][INFO] - Step 113912320 @ 6650.7 SPS. Inference batcher size: 0. Learner queue size: 18. Other stats: (step = 113912320, mean_episode_return = 111.07, mean_episode_step = 584.15, total_loss = 88.503, pg_loss = 33.301, baseline_loss = 61.314, entropy_loss = -6.1122, learner_queue_size = 14, _tick = 37343, _time = 1.654e+09, train_seconds = 1.728e+04)
[2022-05-31 18:58:26,432][root][INFO] - Step 113943040 @ 6136.2 SPS. Inference batcher size: 90. Learner queue size: 21. Other stats: (step = 113943040, mean_episode_return = 29.241, mean_episode_step = 735.55, total_loss = 238.32, pg_loss = 98.141, baseline_loss = 146.15, entropy_loss = -5.9753, learner_queue_size = 16, _tick = 37355, _time = 1.654e+09, train_seconds = 1.7285e+04)
[2022-05-31 18:58:31,438][root][INFO] - Step 113978880 @ 7160.0 SPS. Inference batcher size: 106. Learner queue size: 22. Other stats: (step = 113978880, mean_episode_return = 183.8, mean_episode_step = 1194.9, total_loss = -109.95, pg_loss = -215.03, baseline_loss = 111.46, entropy_loss = -6.3879, learner_queue_size = 20, _tick = 37369, _time = 1.654e+09, train_seconds = 1.729e+04)
[2022-05-31 18:58:36,442][root][INFO] - Step 114009600 @ 6139.0 SPS. Inference batcher size: 149. Learner queue size: 24. Other stats: (step = 114009600, mean_episode_return = None, mean_episode_step = 692.03, total_loss = -58.894, pg_loss = -94.672, baseline_loss = 42.232, entropy_loss = -6.4539, learner_queue_size = 12, _tick = 37379, _time = 1.654e+09, train_seconds = 1.7295e+04)
[2022-05-31 18:58:41,446][root][INFO] - Step 114045440 @ 7162.4 SPS. Inference batcher size: 60. Learner queue size: 9. Other stats: (step = 114045440, mean_episode_return = 154.82, mean_episode_step = 847.42, total_loss = 193.58, pg_loss = 120.49, baseline_loss = 79.489, entropy_loss = -6.4018, learner_queue_size = 9, _tick = 37390, _time = 1.654e+09, train_seconds = 1.73e+04)
[2022-05-31 18:58:46,449][root][INFO] - Step 114076160 @ 6139.7 SPS. Inference batcher size: 98. Learner queue size: 11. Other stats: (step = 114076160, mean_episode_return = 107.64, mean_episode_step = 694.96, total_loss = 295.26, pg_loss = 161.14, baseline_loss = 140.08, entropy_loss = -5.9591, learner_queue_size = 20, _tick = 37401, _time = 1.654e+09, train_seconds = 1.7305e+04)
[2022-05-31 18:58:51,455][root][INFO] - Step 114109440 @ 6648.0 SPS. Inference batcher size: 130. Learner queue size: 14. Other stats: (step = 114109440, mean_episode_return = 230.99, mean_episode_step = 705.74, total_loss = 78.872, pg_loss = 0.14079, baseline_loss = 84.498, entropy_loss = -5.7666, learner_queue_size = 19, _tick = 37414, _time = 1.654e+09, train_seconds = 1.731e+04)
[2022-05-31 18:58:56,462][root][INFO] - Step 114142720 @ 6648.0 SPS. Inference batcher size: 108. Learner queue size: 15. Other stats: (step = 114142720, mean_episode_return = 39.32, mean_episode_step = 827.24, total_loss = 27.339, pg_loss = -34.646, baseline_loss = 67.921, entropy_loss = -5.9354, learner_queue_size = 17, _tick = 37427, _time = 1.654e+09, train_seconds = 1.7315e+04)
[2022-05-31 18:59:01,466][root][INFO] - Step 114176000 @ 6650.0 SPS. Inference batcher size: 136. Learner queue size: 9. Other stats: (step = 114176000, mean_episode_return = 477.16, mean_episode_step = 769.7, total_loss = 166.6, pg_loss = 25.383, baseline_loss = 147.26, entropy_loss = -6.0427, learner_queue_size = 22, _tick = 37439, _time = 1.654e+09, train_seconds = 1.732e+04)
[2022-05-31 18:59:06,470][root][INFO] - Step 114209280 @ 6650.7 SPS. Inference batcher size: 201. Learner queue size: 4. Other stats: (step = 114209280, mean_episode_return = 369.34, mean_episode_step = 638.02, total_loss = -100.34, pg_loss = -150.18, baseline_loss = 55.459, entropy_loss = -5.6148, learner_queue_size = 17, _tick = 37451, _time = 1.654e+09, train_seconds = 1.7325e+04)
[2022-05-31 18:59:11,474][root][INFO] - Step 114242560 @ 6650.7 SPS. Inference batcher size: 141. Learner queue size: 5. Other stats: (step = 114242560, mean_episode_return = 176.69, mean_episode_step = 986.42, total_loss = 341.18, pg_loss = 228.67, baseline_loss = 118.74, entropy_loss = -6.2341, learner_queue_size = 24, _tick = 37462, _time = 1.654e+09, train_seconds = 1.733e+04)
[2022-05-31 18:59:16,478][root][INFO] - Step 114275840 @ 6650.8 SPS. Inference batcher size: 141. Learner queue size: 1. Other stats: (step = 114275840, mean_episode_return = None, mean_episode_step = 465.22, total_loss = -4.6989, pg_loss = -43.004, baseline_loss = 44.097, entropy_loss = -5.7911, learner_queue_size = 21, _tick = 37473, _time = 1.654e+09, train_seconds = 1.7335e+04)
[2022-05-31 18:59:21,482][root][INFO] - Step 114306560 @ 6139.0 SPS. Inference batcher size: 73. Learner queue size: 19. Other stats: (step = 114306560, mean_episode_return = None, mean_episode_step = 672.47, total_loss = -18.828, pg_loss = -54.583, baseline_loss = 41.493, entropy_loss = -5.7379, learner_queue_size = 26, _tick = 37483, _time = 1.654e+09, train_seconds = 1.734e+04)
[2022-05-31 18:59:26,488][root][INFO] - Step 114339840 @ 6647.8 SPS. Inference batcher size: 146. Learner queue size: 12. Other stats: (step = 114339840, mean_episode_return = 68.63, mean_episode_step = 702.62, total_loss = 28.44, pg_loss = -121.56, baseline_loss = 155.98, entropy_loss = -5.9843, learner_queue_size = 19, _tick = 37495, _time = 1.654e+09, train_seconds = 1.7345e+04)
[2022-05-31 18:59:31,494][root][INFO] - Step 114373120 @ 6648.2 SPS. Inference batcher size: 134. Learner queue size: 2. Other stats: (step = 114373120, mean_episode_return = 158.05, mean_episode_step = 687.39, total_loss = -81.02, pg_loss = -102.41, baseline_loss = 27.73, entropy_loss = -6.3438, learner_queue_size = 17, _tick = 37507, _time = 1.654e+09, train_seconds = 1.735e+04)
[2022-05-31 18:59:36,498][root][INFO] - Step 114406400 @ 6650.7 SPS. Inference batcher size: 133. Learner queue size: 1. Other stats: (step = 114406400, mean_episode_return = 449.43, mean_episode_step = 953.44, total_loss = 123.78, pg_loss = -31.474, baseline_loss = 160.63, entropy_loss = -5.3812, learner_queue_size = 21, _tick = 37519, _time = 1.654e+09, train_seconds = 1.7355e+04)
[2022-05-31 18:59:41,502][root][INFO] - Step 114437120 @ 6139.1 SPS. Inference batcher size: 98. Learner queue size: 10. Other stats: (step = 114437120, mean_episode_return = 190.93, mean_episode_step = 691.12, total_loss = 59.959, pg_loss = -60.824, baseline_loss = 126.49, entropy_loss = -5.7079, learner_queue_size = 15, _tick = 37531, _time = 1.654e+09, train_seconds = 1.736e+04)
[2022-05-31 18:59:46,506][root][INFO] - Step 114470400 @ 6650.6 SPS. Inference batcher size: 97. Learner queue size: 17. Other stats: (step = 114470400, mean_episode_return = 419.5, mean_episode_step = 687.69, total_loss = 40.704, pg_loss = 28.492, baseline_loss = 18.499, entropy_loss = -6.2877, learner_queue_size = 19, _tick = 37543, _time = 1.654e+09, train_seconds = 1.7365e+04)
[2022-05-31 18:59:51,510][root][INFO] - Step 114503680 @ 6650.5 SPS. Inference batcher size: 168. Learner queue size: 16. Other stats: (step = 114503680, mean_episode_return = 183.7, mean_episode_step = 696.98, total_loss = -95.985, pg_loss = -116.4, baseline_loss = 26.53, entropy_loss = -6.1191, learner_queue_size = 20, _tick = 37555, _time = 1.654e+09, train_seconds = 1.737e+04)
[2022-05-31 18:59:56,516][root][INFO] - Step 114536960 @ 6647.9 SPS. Inference batcher size: 89. Learner queue size: 16. Other stats: (step = 114536960, mean_episode_return = 334.88, mean_episode_step = 715.6, total_loss = 74.216, pg_loss = 7.3415, baseline_loss = 72.846, entropy_loss = -5.9722, learner_queue_size = 12, _tick = 37563, _time = 1.654e+09, train_seconds = 1.7375e+04)
[2022-05-31 19:00:01,522][root][INFO] - Step 114570240 @ 6648.3 SPS. Inference batcher size: 113. Learner queue size: 18. Other stats: (step = 114570240, mean_episode_return = 375.96, mean_episode_step = 855.17, total_loss = 92.318, pg_loss = -67.41, baseline_loss = 166.08, entropy_loss = -6.3504, learner_queue_size = 14, _tick = 37575, _time = 1.654e+09, train_seconds = 1.738e+04)
[2022-05-31 19:00:06,528][root][INFO] - Step 114603520 @ 6647.8 SPS. Inference batcher size: 137. Learner queue size: 15. Other stats: (step = 114603520, mean_episode_return = 344.98, mean_episode_step = 817.14, total_loss = 499.88, pg_loss = 165.06, baseline_loss = 341.41, entropy_loss = -6.5939, learner_queue_size = 13, _tick = 37586, _time = 1.654e+09, train_seconds = 1.7385e+04)
[2022-05-31 19:00:11,534][root][INFO] - Step 114636800 @ 6648.3 SPS. Inference batcher size: 67. Learner queue size: 11. Other stats: (step = 114636800, mean_episode_return = 268.67, mean_episode_step = 775.05, total_loss = 163.46, pg_loss = 7.5064, baseline_loss = 161.96, entropy_loss = -6.0114, learner_queue_size = 17, _tick = 37598, _time = 1.654e+09, train_seconds = 1.739e+04)
[2022-05-31 19:00:16,540][root][INFO] - Step 114670080 @ 6648.0 SPS. Inference batcher size: 102. Learner queue size: 2. Other stats: (step = 114670080, mean_episode_return = 229.91, mean_episode_step = 671.42, total_loss = 75.685, pg_loss = -10.82, baseline_loss = 92.335, entropy_loss = -5.8298, learner_queue_size = 24, _tick = 37610, _time = 1.654e+09, train_seconds = 1.7395e+04)
[2022-05-31 19:00:21,546][root][INFO] - Step 114703360 @ 6648.1 SPS. Inference batcher size: 166. Learner queue size: 5. Other stats: (step = 114703360, mean_episode_return = 238.23, mean_episode_step = 750.01, total_loss = 114.45, pg_loss = 60.491, baseline_loss = 60.008, entropy_loss = -6.0507, learner_queue_size = 19, _tick = 37621, _time = 1.654e+09, train_seconds = 1.74e+04)
[2022-05-31 19:00:26,552][root][INFO] - Step 114736640 @ 6648.0 SPS. Inference batcher size: 129. Learner queue size: 3. Other stats: (step = 114736640, mean_episode_return = 201.32, mean_episode_step = 876.5, total_loss = -134.15, pg_loss = -175.21, baseline_loss = 46.942, entropy_loss = -5.8806, learner_queue_size = 19, _tick = 37633, _time = 1.654e+09, train_seconds = 1.7405e+04)
[2022-05-31 19:00:31,554][root][INFO] - Step 114769920 @ 6653.4 SPS. Inference batcher size: 132. Learner queue size: 2. Other stats: (step = 114769920, mean_episode_return = 156.1, mean_episode_step = 879.58, total_loss = 230.94, pg_loss = 104.22, baseline_loss = 132.83, entropy_loss = -6.1074, learner_queue_size = 20, _tick = 37646, _time = 1.654e+09, train_seconds = 1.741e+04)
[2022-05-31 19:00:36,558][root][INFO] - Step 114803200 @ 6650.7 SPS. Inference batcher size: 106. Learner queue size: 28. Other stats: (step = 114803200, mean_episode_return = 244.67, mean_episode_step = 771.65, total_loss = 47.729, pg_loss = -83.943, baseline_loss = 137.94, entropy_loss = -6.2691, learner_queue_size = 18, _tick = 37657, _time = 1.654e+09, train_seconds = 1.7415e+04)
[2022-05-31 19:00:41,562][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 19:00:41,640][root][INFO] - Step 114836480 @ 6650.6 SPS. Inference batcher size: 85. Learner queue size: 20. Other stats: (step = 114836480, mean_episode_return = 411.65, mean_episode_step = 787.55, total_loss = 399.97, pg_loss = 202.94, baseline_loss = 203.03, entropy_loss = -5.9949, learner_queue_size = 13, _tick = 37669, _time = 1.654e+09, train_seconds = 1.742e+04)
[2022-05-31 19:00:46,642][root][INFO] - Step 114867200 @ 6047.3 SPS. Inference batcher size: 118. Learner queue size: 21. Other stats: (step = 114867200, mean_episode_return = 159.71, mean_episode_step = 692.33, total_loss = -198.4, pg_loss = -246.75, baseline_loss = 54.105, entropy_loss = -5.7484, learner_queue_size = 21, _tick = 37679, _time = 1.654e+09, train_seconds = 1.7425e+04)
[2022-05-31 19:00:51,648][root][INFO] - Step 114900480 @ 6647.9 SPS. Inference batcher size: 151. Learner queue size: 15. Other stats: (step = 114900480, mean_episode_return = 49.63, mean_episode_step = 649.36, total_loss = -153.93, pg_loss = -205.65, baseline_loss = 57.463, entropy_loss = -5.7427, learner_queue_size = 16, _tick = 37691, _time = 1.654e+09, train_seconds = 1.743e+04)
[2022-05-31 19:00:56,654][root][INFO] - Step 114933760 @ 6648.0 SPS. Inference batcher size: 118. Learner queue size: 15. Other stats: (step = 114933760, mean_episode_return = 125.24, mean_episode_step = 619.09, total_loss = -29.501, pg_loss = -52.48, baseline_loss = 29.226, entropy_loss = -6.2467, learner_queue_size = 19, _tick = 37703, _time = 1.654e+09, train_seconds = 1.7435e+04)
[2022-05-31 19:01:01,660][root][INFO] - Step 114967040 @ 6648.2 SPS. Inference batcher size: 114. Learner queue size: 5. Other stats: (step = 114967040, mean_episode_return = 92.054, mean_episode_step = 612.76, total_loss = 45.575, pg_loss = -1.0324, baseline_loss = 52.749, entropy_loss = -6.1416, learner_queue_size = 17, _tick = 37715, _time = 1.654e+09, train_seconds = 1.744e+04)
[2022-05-31 19:01:06,662][root][INFO] - Step 115000320 @ 6653.3 SPS. Inference batcher size: 154. Learner queue size: 15. Other stats: (step = 115000320, mean_episode_return = 178.88, mean_episode_step = 763.7, total_loss = 87.698, pg_loss = 51.739, baseline_loss = 42.281, entropy_loss = -6.3227, learner_queue_size = 19, _tick = 37725, _time = 1.654e+09, train_seconds = 1.7445e+04)
[2022-05-31 19:01:11,668][root][INFO] - Step 115033600 @ 6648.1 SPS. Inference batcher size: 53. Learner queue size: 10. Other stats: (step = 115033600, mean_episode_return = 156.77, mean_episode_step = 669.94, total_loss = 354.66, pg_loss = 208.92, baseline_loss = 151.32, entropy_loss = -5.5779, learner_queue_size = 15, _tick = 37736, _time = 1.654e+09, train_seconds = 1.745e+04)
[2022-05-31 19:01:16,674][root][INFO] - Step 115066880 @ 6648.0 SPS. Inference batcher size: 176. Learner queue size: 4. Other stats: (step = 115066880, mean_episode_return = 351.42, mean_episode_step = 669.28, total_loss = 674.48, pg_loss = 369.33, baseline_loss = 311.03, entropy_loss = -5.8822, learner_queue_size = 19, _tick = 37749, _time = 1.654e+09, train_seconds = 1.7455e+04)
[2022-05-31 19:01:21,678][root][INFO] - Step 115100160 @ 6650.7 SPS. Inference batcher size: 125. Learner queue size: 1. Other stats: (step = 115100160, mean_episode_return = 173.95, mean_episode_step = 717.95, total_loss = -34.014, pg_loss = -139.04, baseline_loss = 110.85, entropy_loss = -5.828, learner_queue_size = 25, _tick = 37762, _time = 1.654e+09, train_seconds = 1.746e+04)
[2022-05-31 19:01:26,682][root][INFO] - Step 115133440 @ 6650.7 SPS. Inference batcher size: 44. Learner queue size: 30. Other stats: (step = 115133440, mean_episode_return = 175.1, mean_episode_step = 737.42, total_loss = 143.98, pg_loss = 0.99114, baseline_loss = 148.66, entropy_loss = -5.67, learner_queue_size = 28, _tick = 37773, _time = 1.654e+09, train_seconds = 1.7465e+04)
[2022-05-31 19:01:31,686][root][INFO] - Step 115164160 @ 6139.0 SPS. Inference batcher size: 162. Learner queue size: 18. Other stats: (step = 115164160, mean_episode_return = 33.491, mean_episode_step = 745.76, total_loss = 98.483, pg_loss = 34.691, baseline_loss = 69.683, entropy_loss = -5.8914, learner_queue_size = 19, _tick = 37785, _time = 1.654e+09, train_seconds = 1.747e+04)
[2022-05-31 19:01:36,692][root][INFO] - Step 115197440 @ 6648.1 SPS. Inference batcher size: 176. Learner queue size: 17. Other stats: (step = 115197440, mean_episode_return = 232.23, mean_episode_step = 808.2, total_loss = 55.396, pg_loss = 8.9203, baseline_loss = 52.642, entropy_loss = -6.1665, learner_queue_size = 22, _tick = 37797, _time = 1.654e+09, train_seconds = 1.7475e+04)
[2022-05-31 19:01:41,698][root][INFO] - Step 115230720 @ 6648.1 SPS. Inference batcher size: 163. Learner queue size: 9. Other stats: (step = 115230720, mean_episode_return = 79.6, mean_episode_step = 538.6, total_loss = 471.16, pg_loss = 249.28, baseline_loss = 227.61, entropy_loss = -5.727, learner_queue_size = 28, _tick = 37809, _time = 1.654e+09, train_seconds = 1.748e+04)
[2022-05-31 19:01:46,702][root][INFO] - Step 115264000 @ 6650.5 SPS. Inference batcher size: 145. Learner queue size: 18. Other stats: (step = 115264000, mean_episode_return = 308.98, mean_episode_step = 624.56, total_loss = 117.39, pg_loss = 38.587, baseline_loss = 84.453, entropy_loss = -5.6535, learner_queue_size = 14, _tick = 37821, _time = 1.654e+09, train_seconds = 1.7485e+04)
[2022-05-31 19:01:51,708][root][INFO] - Step 115297280 @ 6648.0 SPS. Inference batcher size: 140. Learner queue size: 14. Other stats: (step = 115297280, mean_episode_return = 221.08, mean_episode_step = 669.59, total_loss = 382.49, pg_loss = 75.012, baseline_loss = 313.11, entropy_loss = -5.6371, learner_queue_size = 25, _tick = 37831, _time = 1.654e+09, train_seconds = 1.749e+04)
[2022-05-31 19:01:56,710][root][INFO] - Step 115330560 @ 6653.3 SPS. Inference batcher size: 126. Learner queue size: 17. Other stats: (step = 115330560, mean_episode_return = None, mean_episode_step = 729.59, total_loss = 217.37, pg_loss = 136.36, baseline_loss = 86.465, entropy_loss = -5.454, learner_queue_size = 9, _tick = 37843, _time = 1.654e+09, train_seconds = 1.7495e+04)
[2022-05-31 19:02:01,714][root][INFO] - Step 115363840 @ 6650.7 SPS. Inference batcher size: 63. Learner queue size: 14. Other stats: (step = 115363840, mean_episode_return = 270.04, mean_episode_step = 672.13, total_loss = 130.92, pg_loss = -13.444, baseline_loss = 149.98, entropy_loss = -5.6152, learner_queue_size = 22, _tick = 37855, _time = 1.654e+09, train_seconds = 1.75e+04)
[2022-05-31 19:02:06,718][root][INFO] - Step 115397120 @ 6650.7 SPS. Inference batcher size: 97. Learner queue size: 16. Other stats: (step = 115397120, mean_episode_return = 118.56, mean_episode_step = 670.86, total_loss = -40.5, pg_loss = -113.6, baseline_loss = 79.407, entropy_loss = -6.3082, learner_queue_size = 18, _tick = 37867, _time = 1.654e+09, train_seconds = 1.7505e+04)
[2022-05-31 19:02:11,722][root][INFO] - Step 115430400 @ 6650.7 SPS. Inference batcher size: 137. Learner queue size: 6. Other stats: (step = 115430400, mean_episode_return = 284.71, mean_episode_step = 750.57, total_loss = 888.06, pg_loss = 680.32, baseline_loss = 213.8, entropy_loss = -6.0656, learner_queue_size = 26, _tick = 37879, _time = 1.654e+09, train_seconds = 1.751e+04)
[2022-05-31 19:02:16,726][root][INFO] - Step 115463680 @ 6650.8 SPS. Inference batcher size: 63. Learner queue size: 1. Other stats: (step = 115463680, mean_episode_return = 130.64, mean_episode_step = 743.54, total_loss = 418.05, pg_loss = 305.28, baseline_loss = 119.13, entropy_loss = -6.3644, learner_queue_size = 21, _tick = 37892, _time = 1.654e+09, train_seconds = 1.7515e+04)
[2022-05-31 19:02:21,730][root][INFO] - Step 115494400 @ 6139.0 SPS. Inference batcher size: 51. Learner queue size: 25. Other stats: (step = 115494400, mean_episode_return = 130.68, mean_episode_step = 524.78, total_loss = 15.143, pg_loss = -133.97, baseline_loss = 154.52, entropy_loss = -5.4064, learner_queue_size = 17, _tick = 37902, _time = 1.654e+09, train_seconds = 1.752e+04)
[2022-05-31 19:02:26,734][root][INFO] - Step 115530240 @ 7162.3 SPS. Inference batcher size: 148. Learner queue size: 13. Other stats: (step = 115530240, mean_episode_return = 298.96, mean_episode_step = 633.88, total_loss = 237.51, pg_loss = -187.0, baseline_loss = 430.23, entropy_loss = -5.7228, learner_queue_size = 13, _tick = 37916, _time = 1.654e+09, train_seconds = 1.7525e+04)
[2022-05-31 19:02:31,738][root][INFO] - Step 115560960 @ 6139.1 SPS. Inference batcher size: 168. Learner queue size: 13. Other stats: (step = 115560960, mean_episode_return = 130.2, mean_episode_step = 821.12, total_loss = 163.05, pg_loss = 68.201, baseline_loss = 100.84, entropy_loss = -5.9948, learner_queue_size = 14, _tick = 37926, _time = 1.654e+09, train_seconds = 1.753e+04)
[2022-05-31 19:02:36,742][root][INFO] - Step 115594240 @ 6650.7 SPS. Inference batcher size: 129. Learner queue size: 7. Other stats: (step = 115594240, mean_episode_return = 323.29, mean_episode_step = 684.69, total_loss = -142.6, pg_loss = -223.71, baseline_loss = 86.884, entropy_loss = -5.7703, learner_queue_size = 30, _tick = 37939, _time = 1.654e+09, train_seconds = 1.7535e+04)
[2022-05-31 19:02:41,748][root][INFO] - Step 115627520 @ 6648.1 SPS. Inference batcher size: 82. Learner queue size: 3. Other stats: (step = 115627520, mean_episode_return = 129.28, mean_episode_step = 788.13, total_loss = 94.943, pg_loss = 3.4877, baseline_loss = 97.064, entropy_loss = -5.6089, learner_queue_size = 23, _tick = 37950, _time = 1.654e+09, train_seconds = 1.754e+04)
[2022-05-31 19:02:46,750][root][INFO] - Step 115660800 @ 6653.3 SPS. Inference batcher size: 31. Learner queue size: 30. Other stats: (step = 115660800, mean_episode_return = 215.35, mean_episode_step = 600.63, total_loss = 355.36, pg_loss = 108.22, baseline_loss = 252.15, entropy_loss = -5.0107, learner_queue_size = 8, _tick = 37962, _time = 1.654e+09, train_seconds = 1.7545e+04)
[2022-05-31 19:02:51,754][root][INFO] - Step 115694080 @ 6650.7 SPS. Inference batcher size: 103. Learner queue size: 22. Other stats: (step = 115694080, mean_episode_return = 194.38, mean_episode_step = 956.31, total_loss = 164.34, pg_loss = -48.953, baseline_loss = 218.89, entropy_loss = -5.6009, learner_queue_size = 17, _tick = 37975, _time = 1.654e+09, train_seconds = 1.755e+04)
[2022-05-31 19:02:56,758][root][INFO] - Step 115727360 @ 6650.7 SPS. Inference batcher size: 198. Learner queue size: 1. Other stats: (step = 115727360, mean_episode_return = 139.1, mean_episode_step = 545.3, total_loss = 355.03, pg_loss = 168.97, baseline_loss = 190.99, entropy_loss = -4.9251, learner_queue_size = 23, _tick = 37988, _time = 1.654e+09, train_seconds = 1.7555e+04)
[2022-05-31 19:03:01,762][root][INFO] - Step 115760640 @ 6650.7 SPS. Inference batcher size: 124. Learner queue size: 24. Other stats: (step = 115760640, mean_episode_return = 441.49, mean_episode_step = 513.85, total_loss = -118.38, pg_loss = -246.16, baseline_loss = 133.36, entropy_loss = -5.5743, learner_queue_size = 22, _tick = 37999, _time = 1.654e+09, train_seconds = 1.756e+04)
[2022-05-31 19:03:06,766][root][INFO] - Step 115793920 @ 6650.6 SPS. Inference batcher size: 42. Learner queue size: 29. Other stats: (step = 115793920, mean_episode_return = 856.83, mean_episode_step = 558.29, total_loss = 256.23, pg_loss = 116.17, baseline_loss = 145.93, entropy_loss = -5.8798, learner_queue_size = 27, _tick = 38009, _time = 1.654e+09, train_seconds = 1.7566e+04)
[2022-05-31 19:03:11,772][root][INFO] - Step 115824640 @ 6136.3 SPS. Inference batcher size: 81. Learner queue size: 20. Other stats: (step = 115824640, mean_episode_return = 161.7, mean_episode_step = 683.39, total_loss = 33.68, pg_loss = -11.316, baseline_loss = 51.622, entropy_loss = -6.6262, learner_queue_size = 12, _tick = 38018, _time = 1.654e+09, train_seconds = 1.757e+04)
[2022-05-31 19:03:16,778][root][INFO] - Step 115857920 @ 6648.2 SPS. Inference batcher size: 58. Learner queue size: 12. Other stats: (step = 115857920, mean_episode_return = None, mean_episode_step = 848.62, total_loss = 49.408, pg_loss = 23.074, baseline_loss = 33.002, entropy_loss = -6.6684, learner_queue_size = 22, _tick = 38026, _time = 1.654e+09, train_seconds = 1.7576e+04)
[2022-05-31 19:03:21,785][root][INFO] - Step 115891200 @ 6647.3 SPS. Inference batcher size: 136. Learner queue size: 14. Other stats: (step = 115891200, mean_episode_return = 306.49, mean_episode_step = 925.96, total_loss = 292.17, pg_loss = 196.41, baseline_loss = 102.01, entropy_loss = -6.2533, learner_queue_size = 17, _tick = 38035, _time = 1.654e+09, train_seconds = 1.758e+04)
[2022-05-31 19:03:26,790][root][INFO] - Step 115924480 @ 6649.1 SPS. Inference batcher size: 114. Learner queue size: 3. Other stats: (step = 115924480, mean_episode_return = 117.68, mean_episode_step = 772.69, total_loss = 72.363, pg_loss = 21.143, baseline_loss = 57.838, entropy_loss = -6.6181, learner_queue_size = 25, _tick = 38047, _time = 1.654e+09, train_seconds = 1.7586e+04)
[2022-05-31 19:03:31,794][root][INFO] - Step 115957760 @ 6650.6 SPS. Inference batcher size: 138. Learner queue size: 5. Other stats: (step = 115957760, mean_episode_return = None, mean_episode_step = 775.97, total_loss = 125.82, pg_loss = 63.446, baseline_loss = 68.719, entropy_loss = -6.3405, learner_queue_size = 15, _tick = 38059, _time = 1.654e+09, train_seconds = 1.759e+04)
[2022-05-31 19:03:36,798][root][INFO] - Step 115988480 @ 6139.0 SPS. Inference batcher size: 67. Learner queue size: 20. Other stats: (step = 115988480, mean_episode_return = None, mean_episode_step = 699.56, total_loss = 139.97, pg_loss = 57.294, baseline_loss = 89.451, entropy_loss = -6.7785, learner_queue_size = 13, _tick = 38068, _time = 1.654e+09, train_seconds = 1.7596e+04)
[2022-05-31 19:03:41,806][root][INFO] - Step 116021760 @ 6645.4 SPS. Inference batcher size: 113. Learner queue size: 29. Other stats: (step = 116021760, mean_episode_return = 155.58, mean_episode_step = 620.59, total_loss = -16.44, pg_loss = -63.035, baseline_loss = 53.086, entropy_loss = -6.4917, learner_queue_size = 14, _tick = 38079, _time = 1.654e+09, train_seconds = 1.76e+04)
[2022-05-31 19:03:46,812][root][INFO] - Step 116055040 @ 6648.0 SPS. Inference batcher size: 138. Learner queue size: 22. Other stats: (step = 116055040, mean_episode_return = 150.04, mean_episode_step = 849.63, total_loss = 55.236, pg_loss = -65.058, baseline_loss = 126.21, entropy_loss = -5.9153, learner_queue_size = 16, _tick = 38090, _time = 1.654e+09, train_seconds = 1.7606e+04)
[2022-05-31 19:03:51,818][root][INFO] - Step 116088320 @ 6647.9 SPS. Inference batcher size: 106. Learner queue size: 13. Other stats: (step = 116088320, mean_episode_return = 297.98, mean_episode_step = 678.13, total_loss = 92.432, pg_loss = 18.444, baseline_loss = 80.442, entropy_loss = -6.4536, learner_queue_size = 20, _tick = 38103, _time = 1.654e+09, train_seconds = 1.761e+04)
[2022-05-31 19:03:56,824][root][INFO] - Step 116121600 @ 6648.0 SPS. Inference batcher size: 83. Learner queue size: 11. Other stats: (step = 116121600, mean_episode_return = 98.014, mean_episode_step = 925.93, total_loss = -14.366, pg_loss = -44.723, baseline_loss = 36.831, entropy_loss = -6.4732, learner_queue_size = 24, _tick = 38113, _time = 1.654e+09, train_seconds = 1.7616e+04)
[2022-05-31 19:04:01,826][root][INFO] - Step 116154880 @ 6653.5 SPS. Inference batcher size: 122. Learner queue size: 5. Other stats: (step = 116154880, mean_episode_return = 21.63, mean_episode_step = 706.88, total_loss = 405.21, pg_loss = 331.08, baseline_loss = 80.88, entropy_loss = -6.7522, learner_queue_size = 20, _tick = 38126, _time = 1.654e+09, train_seconds = 1.762e+04)
[2022-05-31 19:04:06,830][root][INFO] - Step 116188160 @ 6650.7 SPS. Inference batcher size: 94. Learner queue size: 6. Other stats: (step = 116188160, mean_episode_return = 124.4, mean_episode_step = 672.72, total_loss = 166.41, pg_loss = 109.78, baseline_loss = 63.429, entropy_loss = -6.7932, learner_queue_size = 21, _tick = 38138, _time = 1.654e+09, train_seconds = 1.7626e+04)
[2022-05-31 19:04:11,836][root][INFO] - Step 116221440 @ 6648.0 SPS. Inference batcher size: 104. Learner queue size: 7. Other stats: (step = 116221440, mean_episode_return = 279.31, mean_episode_step = 741.7, total_loss = 103.74, pg_loss = -19.164, baseline_loss = 128.45, entropy_loss = -5.5505, learner_queue_size = 24, _tick = 38149, _time = 1.654e+09, train_seconds = 1.763e+04)
[2022-05-31 19:04:16,842][root][INFO] - Step 116254720 @ 6648.1 SPS. Inference batcher size: 182. Learner queue size: 21. Other stats: (step = 116254720, mean_episode_return = 137.04, mean_episode_step = 679.73, total_loss = 207.99, pg_loss = 73.94, baseline_loss = 139.57, entropy_loss = -5.5226, learner_queue_size = 19, _tick = 38160, _time = 1.654e+09, train_seconds = 1.7636e+04)
[2022-05-31 19:04:21,847][root][INFO] - Step 116285440 @ 6138.4 SPS. Inference batcher size: 145. Learner queue size: 11. Other stats: (step = 116285440, mean_episode_return = 630.47, mean_episode_step = 901.13, total_loss = 288.04, pg_loss = 103.31, baseline_loss = 190.36, entropy_loss = -5.6275, learner_queue_size = 27, _tick = 38169, _time = 1.654e+09, train_seconds = 1.764e+04)
[2022-05-31 19:04:26,850][root][INFO] - Step 116318720 @ 6651.0 SPS. Inference batcher size: 102. Learner queue size: 15. Other stats: (step = 116318720, mean_episode_return = 338.66, mean_episode_step = 811.96, total_loss = -80.33, pg_loss = -191.77, baseline_loss = 117.2, entropy_loss = -5.7607, learner_queue_size = 23, _tick = 38182, _time = 1.654e+09, train_seconds = 1.7646e+04)
[2022-05-31 19:04:31,858][root][INFO] - Step 116352000 @ 6645.6 SPS. Inference batcher size: 127. Learner queue size: 18. Other stats: (step = 116352000, mean_episode_return = 148.99, mean_episode_step = 621.41, total_loss = -142.78, pg_loss = -184.03, baseline_loss = 47.378, entropy_loss = -6.1261, learner_queue_size = 24, _tick = 38194, _time = 1.654e+09, train_seconds = 1.765e+04)
[2022-05-31 19:04:36,864][root][INFO] - Step 116385280 @ 6647.9 SPS. Inference batcher size: 135. Learner queue size: 5. Other stats: (step = 116385280, mean_episode_return = 216.99, mean_episode_step = 630.68, total_loss = 229.36, pg_loss = 139.57, baseline_loss = 95.872, entropy_loss = -6.0773, learner_queue_size = 22, _tick = 38207, _time = 1.654e+09, train_seconds = 1.7656e+04)
[2022-05-31 19:04:41,866][root][INFO] - Step 116416000 @ 6141.6 SPS. Inference batcher size: 115. Learner queue size: 16. Other stats: (step = 116416000, mean_episode_return = 414.57, mean_episode_step = 654.96, total_loss = 615.66, pg_loss = 348.1, baseline_loss = 273.77, entropy_loss = -6.216, learner_queue_size = 15, _tick = 38217, _time = 1.654e+09, train_seconds = 1.7661e+04)
[2022-05-31 19:04:46,872][root][INFO] - Step 116449280 @ 6647.9 SPS. Inference batcher size: 144. Learner queue size: 9. Other stats: (step = 116449280, mean_episode_return = 130.65, mean_episode_step = 642.22, total_loss = -128.99, pg_loss = -200.1, baseline_loss = 77.202, entropy_loss = -6.0919, learner_queue_size = 16, _tick = 38229, _time = 1.654e+09, train_seconds = 1.7666e+04)
[2022-05-31 19:04:51,880][root][INFO] - Step 116482560 @ 6645.5 SPS. Inference batcher size: 125. Learner queue size: 14. Other stats: (step = 116482560, mean_episode_return = 176.14, mean_episode_step = 909.56, total_loss = 103.76, pg_loss = 10.308, baseline_loss = 99.615, entropy_loss = -6.1669, learner_queue_size = 19, _tick = 38241, _time = 1.654e+09, train_seconds = 1.7671e+04)
[2022-05-31 19:04:56,886][root][INFO] - Step 116515840 @ 6648.1 SPS. Inference batcher size: 83. Learner queue size: 31. Other stats: (step = 116515840, mean_episode_return = 262.92, mean_episode_step = 624.81, total_loss = 179.4, pg_loss = 112.54, baseline_loss = 72.426, entropy_loss = -5.57, learner_queue_size = 21, _tick = 38253, _time = 1.654e+09, train_seconds = 1.7676e+04)
[2022-05-31 19:05:01,890][root][INFO] - Step 116549120 @ 6650.8 SPS. Inference batcher size: 36. Learner queue size: 29. Other stats: (step = 116549120, mean_episode_return = 180.95, mean_episode_step = 743.57, total_loss = 198.42, pg_loss = 87.207, baseline_loss = 116.76, entropy_loss = -5.5501, learner_queue_size = 14, _tick = 38266, _time = 1.654e+09, train_seconds = 1.7681e+04)
[2022-05-31 19:05:06,894][root][INFO] - Step 116582400 @ 6650.7 SPS. Inference batcher size: 136. Learner queue size: 18. Other stats: (step = 116582400, mean_episode_return = 163.42, mean_episode_step = 677.11, total_loss = 36.909, pg_loss = -173.58, baseline_loss = 215.9, entropy_loss = -5.4066, learner_queue_size = 15, _tick = 38278, _time = 1.654e+09, train_seconds = 1.7686e+04)
[2022-05-31 19:05:11,898][root][INFO] - Step 116615680 @ 6650.7 SPS. Inference batcher size: 73. Learner queue size: 18. Other stats: (step = 116615680, mean_episode_return = 246.98, mean_episode_step = 668.84, total_loss = -88.051, pg_loss = -359.39, baseline_loss = 277.17, entropy_loss = -5.8278, learner_queue_size = 17, _tick = 38287, _time = 1.654e+09, train_seconds = 1.7691e+04)
[2022-05-31 19:05:16,902][root][INFO] - Step 116648960 @ 6650.7 SPS. Inference batcher size: 127. Learner queue size: 4. Other stats: (step = 116648960, mean_episode_return = 57.665, mean_episode_step = 710.83, total_loss = 305.38, pg_loss = 185.39, baseline_loss = 125.92, entropy_loss = -5.9255, learner_queue_size = 27, _tick = 38299, _time = 1.654e+09, train_seconds = 1.7696e+04)
[2022-05-31 19:05:21,906][root][INFO] - Step 116679680 @ 6139.1 SPS. Inference batcher size: 159. Learner queue size: 21. Other stats: (step = 116679680, mean_episode_return = None, mean_episode_step = 776.12, total_loss = 379.16, pg_loss = 272.94, baseline_loss = 112.33, entropy_loss = -6.1147, learner_queue_size = 27, _tick = 38307, _time = 1.654e+09, train_seconds = 1.7701e+04)
[2022-05-31 19:05:26,910][root][INFO] - Step 116715520 @ 7162.2 SPS. Inference batcher size: 134. Learner queue size: 25. Other stats: (step = 116715520, mean_episode_return = 175.09, mean_episode_step = 547.04, total_loss = 154.79, pg_loss = 20.13, baseline_loss = 140.56, entropy_loss = -5.9034, learner_queue_size = 19, _tick = 38321, _time = 1.654e+09, train_seconds = 1.7706e+04)
[2022-05-31 19:05:31,914][root][INFO] - Step 116746240 @ 6139.0 SPS. Inference batcher size: 151. Learner queue size: 20. Other stats: (step = 116746240, mean_episode_return = None, mean_episode_step = 907.19, total_loss = 279.0, pg_loss = 161.03, baseline_loss = 124.3, entropy_loss = -6.3364, learner_queue_size = 21, _tick = 38329, _time = 1.654e+09, train_seconds = 1.7711e+04)
[2022-05-31 19:05:36,918][root][INFO] - Step 116779520 @ 6650.9 SPS. Inference batcher size: 100. Learner queue size: 17. Other stats: (step = 116779520, mean_episode_return = 220.39, mean_episode_step = 477.71, total_loss = 835.57, pg_loss = 384.79, baseline_loss = 456.58, entropy_loss = -5.8032, learner_queue_size = 18, _tick = 38342, _time = 1.654e+09, train_seconds = 1.7716e+04)
[2022-05-31 19:05:41,922][root][INFO] - Step 116812800 @ 6650.6 SPS. Inference batcher size: 61. Learner queue size: 21. Other stats: (step = 116812800, mean_episode_return = 389.24, mean_episode_step = 720.98, total_loss = 470.73, pg_loss = 239.13, baseline_loss = 237.79, entropy_loss = -6.1881, learner_queue_size = 22, _tick = 38354, _time = 1.654e+09, train_seconds = 1.7721e+04)
[2022-05-31 19:05:46,926][root][INFO] - Step 116846080 @ 6650.6 SPS. Inference batcher size: 139. Learner queue size: 12. Other stats: (step = 116846080, mean_episode_return = 192.89, mean_episode_step = 695.45, total_loss = 355.23, pg_loss = 144.71, baseline_loss = 215.84, entropy_loss = -5.3227, learner_queue_size = 23, _tick = 38366, _time = 1.654e+09, train_seconds = 1.7726e+04)
[2022-05-31 19:05:51,930][root][INFO] - Step 116879360 @ 6650.6 SPS. Inference batcher size: 114. Learner queue size: 3. Other stats: (step = 116879360, mean_episode_return = 128.75, mean_episode_step = 629.07, total_loss = 487.15, pg_loss = 230.68, baseline_loss = 262.19, entropy_loss = -5.7297, learner_queue_size = 23, _tick = 38377, _time = 1.654e+09, train_seconds = 1.7731e+04)
[2022-05-31 19:05:56,934][root][INFO] - Step 116912640 @ 6650.7 SPS. Inference batcher size: 77. Learner queue size: 12. Other stats: (step = 116912640, mean_episode_return = None, mean_episode_step = 729.28, total_loss = -9.3736, pg_loss = -35.326, baseline_loss = 32.3, entropy_loss = -6.3476, learner_queue_size = 26, _tick = 38389, _time = 1.654e+09, train_seconds = 1.7736e+04)
[2022-05-31 19:06:01,938][root][INFO] - Step 116945920 @ 6650.8 SPS. Inference batcher size: 136. Learner queue size: 19. Other stats: (step = 116945920, mean_episode_return = None, mean_episode_step = 962.78, total_loss = -125.59, pg_loss = -177.98, baseline_loss = 57.865, entropy_loss = -5.4719, learner_queue_size = 22, _tick = 38398, _time = 1.654e+09, train_seconds = 1.7741e+04)
[2022-05-31 19:06:06,942][root][INFO] - Step 116979200 @ 6650.6 SPS. Inference batcher size: 63. Learner queue size: 15. Other stats: (step = 116979200, mean_episode_return = 297.19, mean_episode_step = 814.44, total_loss = 84.772, pg_loss = -71.631, baseline_loss = 162.32, entropy_loss = -5.9127, learner_queue_size = 23, _tick = 38407, _time = 1.654e+09, train_seconds = 1.7746e+04)
[2022-05-31 19:06:11,946][root][INFO] - Step 117012480 @ 6650.7 SPS. Inference batcher size: 90. Learner queue size: 5. Other stats: (step = 117012480, mean_episode_return = 162.99, mean_episode_step = 705.82, total_loss = 73.172, pg_loss = 23.57, baseline_loss = 55.667, entropy_loss = -6.0646, learner_queue_size = 21, _tick = 38418, _time = 1.654e+09, train_seconds = 1.7751e+04)
[2022-05-31 19:06:16,950][root][INFO] - Step 117045760 @ 6650.6 SPS. Inference batcher size: 157. Learner queue size: 5. Other stats: (step = 117045760, mean_episode_return = 425.42, mean_episode_step = 647.18, total_loss = 684.15, pg_loss = 250.23, baseline_loss = 439.72, entropy_loss = -5.8101, learner_queue_size = 9, _tick = 38430, _time = 1.654e+09, train_seconds = 1.7756e+04)
[2022-05-31 19:06:21,954][root][INFO] - Step 117079040 @ 6650.8 SPS. Inference batcher size: 54. Learner queue size: 5. Other stats: (step = 117079040, mean_episode_return = 316.17, mean_episode_step = 840.37, total_loss = 243.46, pg_loss = 2.1887, baseline_loss = 247.37, entropy_loss = -6.1006, learner_queue_size = 28, _tick = 38442, _time = 1.654e+09, train_seconds = 1.7761e+04)
[2022-05-31 19:06:26,958][root][INFO] - Step 117112320 @ 6650.6 SPS. Inference batcher size: 82. Learner queue size: 29. Other stats: (step = 117112320, mean_episode_return = 571.35, mean_episode_step = 813.91, total_loss = 215.05, pg_loss = 124.38, baseline_loss = 96.771, entropy_loss = -6.1016, learner_queue_size = 14, _tick = 38453, _time = 1.654e+09, train_seconds = 1.7766e+04)
[2022-05-31 19:06:31,962][root][INFO] - Step 117145600 @ 6650.6 SPS. Inference batcher size: 123. Learner queue size: 28. Other stats: (step = 117145600, mean_episode_return = 248.07, mean_episode_step = 744.91, total_loss = 366.22, pg_loss = 264.58, baseline_loss = 107.89, entropy_loss = -6.2502, learner_queue_size = 17, _tick = 38465, _time = 1.654e+09, train_seconds = 1.7771e+04)
[2022-05-31 19:06:36,968][root][INFO] - Step 117178880 @ 6648.0 SPS. Inference batcher size: 6. Learner queue size: 24. Other stats: (step = 117178880, mean_episode_return = 107.82, mean_episode_step = 799.68, total_loss = 215.65, pg_loss = 19.806, baseline_loss = 201.85, entropy_loss = -6.0111, learner_queue_size = 13, _tick = 38476, _time = 1.654e+09, train_seconds = 1.7776e+04)
[2022-05-31 19:06:41,974][root][INFO] - Step 117209600 @ 6136.6 SPS. Inference batcher size: 70. Learner queue size: 21. Other stats: (step = 117209600, mean_episode_return = 172.28, mean_episode_step = 567.8, total_loss = 52.857, pg_loss = -25.492, baseline_loss = 84.323, entropy_loss = -5.9732, learner_queue_size = 25, _tick = 38487, _time = 1.654e+09, train_seconds = 1.7781e+04)
[2022-05-31 19:06:46,978][root][INFO] - Step 117242880 @ 6650.7 SPS. Inference batcher size: 101. Learner queue size: 18. Other stats: (step = 117242880, mean_episode_return = 158.01, mean_episode_step = 597.53, total_loss = 167.09, pg_loss = 86.211, baseline_loss = 86.876, entropy_loss = -6.0007, learner_queue_size = 22, _tick = 38497, _time = 1.654e+09, train_seconds = 1.7786e+04)
[2022-05-31 19:06:51,984][root][INFO] - Step 117276160 @ 6648.0 SPS. Inference batcher size: 102. Learner queue size: 29. Other stats: (step = 117276160, mean_episode_return = 247.9, mean_episode_step = 670.84, total_loss = 253.42, pg_loss = 78.882, baseline_loss = 179.93, entropy_loss = -5.3907, learner_queue_size = 23, _tick = 38508, _time = 1.654e+09, train_seconds = 1.7791e+04)
[2022-05-31 19:06:56,990][root][INFO] - Step 117309440 @ 6648.0 SPS. Inference batcher size: 108. Learner queue size: 6. Other stats: (step = 117309440, mean_episode_return = 157.68, mean_episode_step = 809.38, total_loss = 237.41, pg_loss = 127.51, baseline_loss = 116.03, entropy_loss = -6.1271, learner_queue_size = 20, _tick = 38518, _time = 1.654e+09, train_seconds = 1.7796e+04)
[2022-05-31 19:07:01,996][root][INFO] - Step 117342720 @ 6648.0 SPS. Inference batcher size: 149. Learner queue size: 17. Other stats: (step = 117342720, mean_episode_return = 214.6, mean_episode_step = 779.43, total_loss = 114.97, pg_loss = -100.12, baseline_loss = 220.78, entropy_loss = -5.6926, learner_queue_size = 12, _tick = 38531, _time = 1.654e+09, train_seconds = 1.7801e+04)
[2022-05-31 19:07:07,002][root][INFO] - Step 117376000 @ 6648.1 SPS. Inference batcher size: 129. Learner queue size: 14. Other stats: (step = 117376000, mean_episode_return = 331.83, mean_episode_step = 754.75, total_loss = 198.56, pg_loss = -179.86, baseline_loss = 383.6, entropy_loss = -5.1835, learner_queue_size = 16, _tick = 38544, _time = 1.654e+09, train_seconds = 1.7806e+04)
[2022-05-31 19:07:12,006][root][INFO] - Step 117409280 @ 6650.8 SPS. Inference batcher size: 137. Learner queue size: 12. Other stats: (step = 117409280, mean_episode_return = 328.44, mean_episode_step = 662.12, total_loss = 119.2, pg_loss = -113.14, baseline_loss = 237.94, entropy_loss = -5.6005, learner_queue_size = 20, _tick = 38555, _time = 1.654e+09, train_seconds = 1.7811e+04)
[2022-05-31 19:07:17,010][root][INFO] - Step 117442560 @ 6650.5 SPS. Inference batcher size: 137. Learner queue size: 9. Other stats: (step = 117442560, mean_episode_return = 655.67, mean_episode_step = 839.09, total_loss = -13.467, pg_loss = -89.204, baseline_loss = 81.469, entropy_loss = -5.732, learner_queue_size = 27, _tick = 38566, _time = 1.654e+09, train_seconds = 1.7816e+04)
[2022-05-31 19:07:22,014][root][INFO] - Step 117475840 @ 6650.6 SPS. Inference batcher size: 17. Learner queue size: 0. Other stats: (step = 117475840, mean_episode_return = 178.58, mean_episode_step = 701.84, total_loss = 39.112, pg_loss = -234.26, baseline_loss = 278.9, entropy_loss = -5.5298, learner_queue_size = 15, _tick = 38578, _time = 1.654e+09, train_seconds = 1.7821e+04)
[2022-05-31 19:07:27,022][root][INFO] - Step 117509120 @ 6645.6 SPS. Inference batcher size: 90. Learner queue size: 3. Other stats: (step = 117509120, mean_episode_return = 106.4, mean_episode_step = 680.07, total_loss = 106.93, pg_loss = 2.6463, baseline_loss = 109.99, entropy_loss = -5.7098, learner_queue_size = 23, _tick = 38589, _time = 1.654e+09, train_seconds = 1.7826e+04)
[2022-05-31 19:07:32,026][root][INFO] - Step 117542400 @ 6650.5 SPS. Inference batcher size: 136. Learner queue size: 27. Other stats: (step = 117542400, mean_episode_return = 261.12, mean_episode_step = 696.7, total_loss = -218.83, pg_loss = -267.13, baseline_loss = 54.259, entropy_loss = -5.9581, learner_queue_size = 21, _tick = 38601, _time = 1.654e+09, train_seconds = 1.7831e+04)
[2022-05-31 19:07:37,030][root][INFO] - Step 117573120 @ 6139.1 SPS. Inference batcher size: 86. Learner queue size: 8. Other stats: (step = 117573120, mean_episode_return = 280.66, mean_episode_step = 702.01, total_loss = 39.606, pg_loss = -29.906, baseline_loss = 75.934, entropy_loss = -6.422, learner_queue_size = 22, _tick = 38613, _time = 1.654e+09, train_seconds = 1.7836e+04)
[2022-05-31 19:07:42,034][root][INFO] - Step 117606400 @ 6650.7 SPS. Inference batcher size: 126. Learner queue size: 23. Other stats: (step = 117606400, mean_episode_return = 513.74, mean_episode_step = 604.06, total_loss = -48.566, pg_loss = -111.47, baseline_loss = 69.0, entropy_loss = -6.0956, learner_queue_size = 22, _tick = 38625, _time = 1.654e+09, train_seconds = 1.7841e+04)
[2022-05-31 19:07:47,038][root][INFO] - Step 117639680 @ 6650.8 SPS. Inference batcher size: 121. Learner queue size: 6. Other stats: (step = 117639680, mean_episode_return = None, mean_episode_step = 647.28, total_loss = 392.32, pg_loss = 285.45, baseline_loss = 113.02, entropy_loss = -6.1575, learner_queue_size = 22, _tick = 38636, _time = 1.654e+09, train_seconds = 1.7846e+04)
[2022-05-31 19:07:52,044][root][INFO] - Step 117672960 @ 6648.0 SPS. Inference batcher size: 24. Learner queue size: 13. Other stats: (step = 117672960, mean_episode_return = 99.81, mean_episode_step = 854.54, total_loss = 377.38, pg_loss = 275.4, baseline_loss = 108.46, entropy_loss = -6.4796, learner_queue_size = 22, _tick = 38647, _time = 1.654e+09, train_seconds = 1.7851e+04)
[2022-05-31 19:07:57,050][root][INFO] - Step 117706240 @ 6648.0 SPS. Inference batcher size: 48. Learner queue size: 13. Other stats: (step = 117706240, mean_episode_return = 165.29, mean_episode_step = 683.49, total_loss = -219.7, pg_loss = -358.45, baseline_loss = 144.5, entropy_loss = -5.7412, learner_queue_size = 25, _tick = 38660, _time = 1.654e+09, train_seconds = 1.7856e+04)
[2022-05-31 19:08:02,056][root][INFO] - Step 117739520 @ 6647.8 SPS. Inference batcher size: 70. Learner queue size: 0. Other stats: (step = 117739520, mean_episode_return = None, mean_episode_step = 643.62, total_loss = 184.01, pg_loss = 109.73, baseline_loss = 80.219, entropy_loss = -5.942, learner_queue_size = 9, _tick = 38670, _time = 1.654e+09, train_seconds = 1.7861e+04)
[2022-05-31 19:08:07,059][root][INFO] - Step 117772800 @ 6652.1 SPS. Inference batcher size: 53. Learner queue size: 29. Other stats: (step = 117772800, mean_episode_return = 214.36, mean_episode_step = 564.2, total_loss = -85.559, pg_loss = -136.62, baseline_loss = 57.003, entropy_loss = -5.9466, learner_queue_size = 25, _tick = 38683, _time = 1.654e+09, train_seconds = 1.7866e+04)
[2022-05-31 19:08:12,062][root][INFO] - Step 117803520 @ 6140.4 SPS. Inference batcher size: 97. Learner queue size: 19. Other stats: (step = 117803520, mean_episode_return = 161.1, mean_episode_step = 707.15, total_loss = -168.38, pg_loss = -236.14, baseline_loss = 74.098, entropy_loss = -6.3382, learner_queue_size = 20, _tick = 38690, _time = 1.654e+09, train_seconds = 1.7871e+04)
[2022-05-31 19:08:17,068][root][INFO] - Step 117836800 @ 6647.5 SPS. Inference batcher size: 113. Learner queue size: 18. Other stats: (step = 117836800, mean_episode_return = 191.84, mean_episode_step = 802.68, total_loss = 295.95, pg_loss = 152.15, baseline_loss = 149.7, entropy_loss = -5.9063, learner_queue_size = 23, _tick = 38703, _time = 1.654e+09, train_seconds = 1.7876e+04)
[2022-05-31 19:08:22,074][root][INFO] - Step 117870080 @ 6647.9 SPS. Inference batcher size: 124. Learner queue size: 16. Other stats: (step = 117870080, mean_episode_return = 204.76, mean_episode_step = 801.22, total_loss = 63.174, pg_loss = 36.971, baseline_loss = 32.344, entropy_loss = -6.1413, learner_queue_size = 14, _tick = 38716, _time = 1.654e+09, train_seconds = 1.7881e+04)
[2022-05-31 19:08:27,078][root][INFO] - Step 117903360 @ 6651.2 SPS. Inference batcher size: 115. Learner queue size: 13. Other stats: (step = 117903360, mean_episode_return = 243.15, mean_episode_step = 658.17, total_loss = -179.41, pg_loss = -354.54, baseline_loss = 180.93, entropy_loss = -5.7997, learner_queue_size = 14, _tick = 38728, _time = 1.654e+09, train_seconds = 1.7886e+04)
[2022-05-31 19:08:32,084][root][INFO] - Step 117936640 @ 6648.2 SPS. Inference batcher size: 106. Learner queue size: 4. Other stats: (step = 117936640, mean_episode_return = 189.29, mean_episode_step = 715.92, total_loss = 672.36, pg_loss = 299.13, baseline_loss = 379.06, entropy_loss = -5.8241, learner_queue_size = 21, _tick = 38740, _time = 1.654e+09, train_seconds = 1.7891e+04)
[2022-05-31 19:08:37,086][root][INFO] - Step 117969920 @ 6653.2 SPS. Inference batcher size: 97. Learner queue size: 0. Other stats: (step = 117969920, mean_episode_return = 198.19, mean_episode_step = 515.09, total_loss = 325.32, pg_loss = 142.82, baseline_loss = 188.29, entropy_loss = -5.792, learner_queue_size = 15, _tick = 38751, _time = 1.654e+09, train_seconds = 1.7896e+04)
[2022-05-31 19:08:42,090][root][INFO] - Step 118003200 @ 6650.7 SPS. Inference batcher size: 202. Learner queue size: 27. Other stats: (step = 118003200, mean_episode_return = 204.59, mean_episode_step = 785.8, total_loss = 217.84, pg_loss = 83.096, baseline_loss = 141.19, entropy_loss = -6.4458, learner_queue_size = 23, _tick = 38762, _time = 1.654e+09, train_seconds = 1.7901e+04)
[2022-05-31 19:08:47,094][root][INFO] - Step 118036480 @ 6650.7 SPS. Inference batcher size: 140. Learner queue size: 0. Other stats: (step = 118036480, mean_episode_return = 102.29, mean_episode_step = 686.04, total_loss = 52.276, pg_loss = 3.197, baseline_loss = 55.281, entropy_loss = -6.2021, learner_queue_size = 18, _tick = 38773, _time = 1.654e+09, train_seconds = 1.7906e+04)
[2022-05-31 19:08:52,098][root][INFO] - Step 118069760 @ 6650.6 SPS. Inference batcher size: 28. Learner queue size: 19. Other stats: (step = 118069760, mean_episode_return = 182.88, mean_episode_step = 579.54, total_loss = 83.931, pg_loss = -20.885, baseline_loss = 110.39, entropy_loss = -5.5747, learner_queue_size = 16, _tick = 38785, _time = 1.654e+09, train_seconds = 1.7911e+04)
[2022-05-31 19:08:57,105][root][INFO] - Step 118100480 @ 6135.9 SPS. Inference batcher size: 116. Learner queue size: 10. Other stats: (step = 118100480, mean_episode_return = 396.3, mean_episode_step = 750.56, total_loss = 380.5, pg_loss = 228.37, baseline_loss = 157.65, entropy_loss = -5.5235, learner_queue_size = 21, _tick = 38797, _time = 1.654e+09, train_seconds = 1.7916e+04)
[2022-05-31 19:09:02,111][root][INFO] - Step 118133760 @ 6648.0 SPS. Inference batcher size: 84. Learner queue size: 16. Other stats: (step = 118133760, mean_episode_return = 203.17, mean_episode_step = 728.27, total_loss = -40.18, pg_loss = -88.297, baseline_loss = 53.817, entropy_loss = -5.6991, learner_queue_size = 20, _tick = 38808, _time = 1.654e+09, train_seconds = 1.7921e+04)
[2022-05-31 19:09:07,115][root][INFO] - Step 118167040 @ 6650.9 SPS. Inference batcher size: 41. Learner queue size: 16. Other stats: (step = 118167040, mean_episode_return = 182.55, mean_episode_step = 452.82, total_loss = 353.51, pg_loss = 213.35, baseline_loss = 145.59, entropy_loss = -5.4378, learner_queue_size = 13, _tick = 38820, _time = 1.654e+09, train_seconds = 1.7926e+04)
[2022-05-31 19:09:12,118][root][INFO] - Step 118200320 @ 6651.3 SPS. Inference batcher size: 78. Learner queue size: 9. Other stats: (step = 118200320, mean_episode_return = 180.55, mean_episode_step = 514.18, total_loss = -413.59, pg_loss = -542.19, baseline_loss = 133.96, entropy_loss = -5.3579, learner_queue_size = 16, _tick = 38832, _time = 1.654e+09, train_seconds = 1.7931e+04)
[2022-05-31 19:09:17,122][root][INFO] - Step 118233600 @ 6650.7 SPS. Inference batcher size: 127. Learner queue size: 16. Other stats: (step = 118233600, mean_episode_return = 279.29, mean_episode_step = 566.27, total_loss = 172.58, pg_loss = 39.066, baseline_loss = 139.02, entropy_loss = -5.4993, learner_queue_size = 10, _tick = 38845, _time = 1.654e+09, train_seconds = 1.7936e+04)
[2022-05-31 19:09:22,126][root][INFO] - Step 118266880 @ 6650.6 SPS. Inference batcher size: 152. Learner queue size: 9. Other stats: (step = 118266880, mean_episode_return = None, mean_episode_step = 607.84, total_loss = 170.47, pg_loss = 15.517, baseline_loss = 160.2, entropy_loss = -5.255, learner_queue_size = 20, _tick = 38856, _time = 1.654e+09, train_seconds = 1.7941e+04)
[2022-05-31 19:09:27,130][root][INFO] - Step 118300160 @ 6650.8 SPS. Inference batcher size: 85. Learner queue size: 1. Other stats: (step = 118300160, mean_episode_return = 362.98, mean_episode_step = 694.29, total_loss = 291.57, pg_loss = 133.99, baseline_loss = 163.43, entropy_loss = -5.8501, learner_queue_size = 15, _tick = 38868, _time = 1.654e+09, train_seconds = 1.7946e+04)
[2022-05-31 19:09:32,136][root][INFO] - Step 118330880 @ 6136.7 SPS. Inference batcher size: 117. Learner queue size: 23. Other stats: (step = 118330880, mean_episode_return = 207.23, mean_episode_step = 671.91, total_loss = 241.53, pg_loss = 37.15, baseline_loss = 210.19, entropy_loss = -5.8099, learner_queue_size = 24, _tick = 38879, _time = 1.654e+09, train_seconds = 1.7951e+04)
[2022-05-31 19:09:37,138][root][INFO] - Step 118364160 @ 6653.2 SPS. Inference batcher size: 110. Learner queue size: 23. Other stats: (step = 118364160, mean_episode_return = 176.4, mean_episode_step = 572.99, total_loss = -27.37, pg_loss = -146.87, baseline_loss = 125.16, entropy_loss = -5.66, learner_queue_size = 26, _tick = 38891, _time = 1.654e+09, train_seconds = 1.7956e+04)
[2022-05-31 19:09:42,144][root][INFO] - Step 118397440 @ 6648.0 SPS. Inference batcher size: 78. Learner queue size: 17. Other stats: (step = 118397440, mean_episode_return = 54.601, mean_episode_step = 588.04, total_loss = -21.61, pg_loss = -101.97, baseline_loss = 86.508, entropy_loss = -6.1485, learner_queue_size = 20, _tick = 38903, _time = 1.654e+09, train_seconds = 1.7961e+04)
[2022-05-31 19:09:47,146][root][INFO] - Step 118430720 @ 6653.4 SPS. Inference batcher size: 139. Learner queue size: 22. Other stats: (step = 118430720, mean_episode_return = 715.98, mean_episode_step = 668.49, total_loss = 266.85, pg_loss = 160.98, baseline_loss = 111.7, entropy_loss = -5.8284, learner_queue_size = 15, _tick = 38915, _time = 1.654e+09, train_seconds = 1.7966e+04)
[2022-05-31 19:09:52,152][root][INFO] - Step 118464000 @ 6648.2 SPS. Inference batcher size: 89. Learner queue size: 21. Other stats: (step = 118464000, mean_episode_return = 230.46, mean_episode_step = 714.99, total_loss = -103.74, pg_loss = -163.01, baseline_loss = 65.384, entropy_loss = -6.1161, learner_queue_size = 20, _tick = 38927, _time = 1.654e+09, train_seconds = 1.7971e+04)
[2022-05-31 19:09:57,154][root][INFO] - Step 118497280 @ 6653.2 SPS. Inference batcher size: 63. Learner queue size: 12. Other stats: (step = 118497280, mean_episode_return = 311.95, mean_episode_step = 637.89, total_loss = 164.1, pg_loss = 5.9279, baseline_loss = 164.18, entropy_loss = -6.0095, learner_queue_size = 22, _tick = 38939, _time = 1.654e+09, train_seconds = 1.7976e+04)
[2022-05-31 19:10:02,158][root][INFO] - Step 118530560 @ 6650.6 SPS. Inference batcher size: 89. Learner queue size: 8. Other stats: (step = 118530560, mean_episode_return = 282.71, mean_episode_step = 727.23, total_loss = 302.97, pg_loss = 68.247, baseline_loss = 240.48, entropy_loss = -5.752, learner_queue_size = 21, _tick = 38948, _time = 1.654e+09, train_seconds = 1.7981e+04)
[2022-05-31 19:10:07,162][root][INFO] - Step 118563840 @ 6650.7 SPS. Inference batcher size: 28. Learner queue size: 28. Other stats: (step = 118563840, mean_episode_return = 313.45, mean_episode_step = 652.17, total_loss = -162.32, pg_loss = -192.49, baseline_loss = 36.038, entropy_loss = -5.8663, learner_queue_size = 23, _tick = 38961, _time = 1.654e+09, train_seconds = 1.7986e+04)
[2022-05-31 19:10:12,168][root][INFO] - Step 118597120 @ 6648.4 SPS. Inference batcher size: 53. Learner queue size: 18. Other stats: (step = 118597120, mean_episode_return = 523.19, mean_episode_step = 794.06, total_loss = 443.13, pg_loss = 207.92, baseline_loss = 240.25, entropy_loss = -5.043, learner_queue_size = 15, _tick = 38973, _time = 1.654e+09, train_seconds = 1.7991e+04)
[2022-05-31 19:10:17,170][root][INFO] - Step 118627840 @ 6141.2 SPS. Inference batcher size: 139. Learner queue size: 22. Other stats: (step = 118627840, mean_episode_return = 251.07, mean_episode_step = 567.31, total_loss = 123.98, pg_loss = 66.823, baseline_loss = 62.618, entropy_loss = -5.4618, learner_queue_size = 16, _tick = 38984, _time = 1.654e+09, train_seconds = 1.7996e+04)
[2022-05-31 19:10:22,176][root][INFO] - Step 118661120 @ 6648.5 SPS. Inference batcher size: 96. Learner queue size: 9. Other stats: (step = 118661120, mean_episode_return = None, mean_episode_step = 565.09, total_loss = 47.742, pg_loss = -24.862, baseline_loss = 78.55, entropy_loss = -5.9455, learner_queue_size = 23, _tick = 38995, _time = 1.654e+09, train_seconds = 1.8001e+04)
[2022-05-31 19:10:27,178][root][INFO] - Step 118694400 @ 6652.8 SPS. Inference batcher size: 104. Learner queue size: 11. Other stats: (step = 118694400, mean_episode_return = 56.49, mean_episode_step = 670.56, total_loss = 244.49, pg_loss = 144.22, baseline_loss = 106.7, entropy_loss = -6.4324, learner_queue_size = 15, _tick = 39008, _time = 1.654e+09, train_seconds = 1.8006e+04)
[2022-05-31 19:10:32,184][root][INFO] - Step 118727680 @ 6648.0 SPS. Inference batcher size: 95. Learner queue size: 5. Other stats: (step = 118727680, mean_episode_return = 203.26, mean_episode_step = 664.65, total_loss = -100.14, pg_loss = -120.33, baseline_loss = 27.214, entropy_loss = -7.0324, learner_queue_size = 15, _tick = 39019, _time = 1.654e+09, train_seconds = 1.8011e+04)
[2022-05-31 19:10:37,189][root][INFO] - Step 118760960 @ 6648.5 SPS. Inference batcher size: 57. Learner queue size: 1. Other stats: (step = 118760960, mean_episode_return = None, mean_episode_step = 704.62, total_loss = 198.36, pg_loss = 162.5, baseline_loss = 42.532, entropy_loss = -6.6669, learner_queue_size = 23, _tick = 39030, _time = 1.654e+09, train_seconds = 1.8016e+04)
[2022-05-31 19:10:42,194][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 19:10:42,255][root][INFO] - Step 118794240 @ 6650.2 SPS. Inference batcher size: 139. Learner queue size: 6. Other stats: (step = 118794240, mean_episode_return = 506.63, mean_episode_step = 728.62, total_loss = 17.722, pg_loss = -34.268, baseline_loss = 58.312, entropy_loss = -6.3224, learner_queue_size = 23, _tick = 39040, _time = 1.654e+09, train_seconds = 1.8021e+04)
[2022-05-31 19:10:47,261][root][INFO] - Step 118827520 @ 6568.3 SPS. Inference batcher size: 89. Learner queue size: 6. Other stats: (step = 118827520, mean_episode_return = 633.03, mean_episode_step = 581.73, total_loss = 124.96, pg_loss = 41.629, baseline_loss = 89.052, entropy_loss = -5.7255, learner_queue_size = 16, _tick = 39053, _time = 1.654e+09, train_seconds = 1.8026e+04)
[2022-05-31 19:10:52,266][root][INFO] - Step 118860800 @ 6649.0 SPS. Inference batcher size: 155. Learner queue size: 4. Other stats: (step = 118860800, mean_episode_return = 272.55, mean_episode_step = 739.42, total_loss = 100.7, pg_loss = 25.624, baseline_loss = 81.102, entropy_loss = -6.0249, learner_queue_size = 21, _tick = 39064, _time = 1.654e+09, train_seconds = 1.8031e+04)
[2022-05-31 19:10:57,270][root][INFO] - Step 118894080 @ 6650.6 SPS. Inference batcher size: 110. Learner queue size: 28. Other stats: (step = 118894080, mean_episode_return = 119.62, mean_episode_step = 625.44, total_loss = 392.6, pg_loss = 246.02, baseline_loss = 151.67, entropy_loss = -5.0973, learner_queue_size = 14, _tick = 39075, _time = 1.654e+09, train_seconds = 1.8036e+04)
[2022-05-31 19:11:02,274][root][INFO] - Step 118927360 @ 6650.6 SPS. Inference batcher size: 27. Learner queue size: 0. Other stats: (step = 118927360, mean_episode_return = 154.68, mean_episode_step = 841.34, total_loss = -187.18, pg_loss = -213.61, baseline_loss = 32.537, entropy_loss = -6.1079, learner_queue_size = 23, _tick = 39087, _time = 1.654e+09, train_seconds = 1.8041e+04)
[2022-05-31 19:11:07,280][root][INFO] - Step 118960640 @ 6647.6 SPS. Inference batcher size: 139. Learner queue size: 3. Other stats: (step = 118960640, mean_episode_return = 305.53, mean_episode_step = 690.25, total_loss = 627.65, pg_loss = 459.53, baseline_loss = 173.85, entropy_loss = -5.728, learner_queue_size = 17, _tick = 39100, _time = 1.654e+09, train_seconds = 1.8046e+04)
[2022-05-31 19:11:12,286][root][INFO] - Step 118993920 @ 6648.5 SPS. Inference batcher size: 32. Learner queue size: 30. Other stats: (step = 118993920, mean_episode_return = 384.08, mean_episode_step = 685.63, total_loss = -85.545, pg_loss = -145.91, baseline_loss = 66.11, entropy_loss = -5.7422, learner_queue_size = 16, _tick = 39112, _time = 1.654e+09, train_seconds = 1.8051e+04)
[2022-05-31 19:11:17,290][root][INFO] - Step 119027200 @ 6650.7 SPS. Inference batcher size: 8. Learner queue size: 27. Other stats: (step = 119027200, mean_episode_return = 295.38, mean_episode_step = 638.17, total_loss = 47.084, pg_loss = -56.837, baseline_loss = 109.47, entropy_loss = -5.5461, learner_queue_size = 24, _tick = 39125, _time = 1.654e+09, train_seconds = 1.8056e+04)
[2022-05-31 19:11:22,296][root][INFO] - Step 119057920 @ 6136.0 SPS. Inference batcher size: 104. Learner queue size: 22. Other stats: (step = 119057920, mean_episode_return = None, mean_episode_step = 606.44, total_loss = 71.673, pg_loss = -22.667, baseline_loss = 99.96, entropy_loss = -5.6206, learner_queue_size = 15, _tick = 39136, _time = 1.654e+09, train_seconds = 1.8061e+04)
[2022-05-31 19:11:27,302][root][INFO] - Step 119091200 @ 6648.1 SPS. Inference batcher size: 147. Learner queue size: 17. Other stats: (step = 119091200, mean_episode_return = 49.33, mean_episode_step = 623.34, total_loss = -138.37, pg_loss = -224.72, baseline_loss = 92.06, entropy_loss = -5.7115, learner_queue_size = 13, _tick = 39147, _time = 1.654e+09, train_seconds = 1.8066e+04)
[2022-05-31 19:11:32,309][root][INFO] - Step 119124480 @ 6647.9 SPS. Inference batcher size: 99. Learner queue size: 16. Other stats: (step = 119124480, mean_episode_return = 255.64, mean_episode_step = 632.79, total_loss = 353.19, pg_loss = 213.99, baseline_loss = 144.98, entropy_loss = -5.7805, learner_queue_size = 26, _tick = 39158, _time = 1.654e+09, train_seconds = 1.8071e+04)
[2022-05-31 19:11:37,314][root][INFO] - Step 119157760 @ 6648.8 SPS. Inference batcher size: 132. Learner queue size: 29. Other stats: (step = 119157760, mean_episode_return = 198.13, mean_episode_step = 650.63, total_loss = 98.095, pg_loss = 25.41, baseline_loss = 77.796, entropy_loss = -5.1112, learner_queue_size = 16, _tick = 39169, _time = 1.654e+09, train_seconds = 1.8076e+04)
[2022-05-31 19:11:42,318][root][INFO] - Step 119191040 @ 6650.7 SPS. Inference batcher size: 122. Learner queue size: 31. Other stats: (step = 119191040, mean_episode_return = 256.42, mean_episode_step = 792.8, total_loss = 371.91, pg_loss = 159.01, baseline_loss = 218.9, entropy_loss = -5.9935, learner_queue_size = 19, _tick = 39181, _time = 1.654e+09, train_seconds = 1.8081e+04)
[2022-05-31 19:11:47,322][root][INFO] - Step 119221760 @ 6139.0 SPS. Inference batcher size: 136. Learner queue size: 17. Other stats: (step = 119221760, mean_episode_return = 130.99, mean_episode_step = 933.61, total_loss = -170.98, pg_loss = -265.96, baseline_loss = 101.19, entropy_loss = -6.2129, learner_queue_size = 20, _tick = 39193, _time = 1.654e+09, train_seconds = 1.8086e+04)
[2022-05-31 19:11:52,328][root][INFO] - Step 119255040 @ 6648.0 SPS. Inference batcher size: 90. Learner queue size: 18. Other stats: (step = 119255040, mean_episode_return = 359.62, mean_episode_step = 614.88, total_loss = 41.455, pg_loss = -93.889, baseline_loss = 140.99, entropy_loss = -5.6484, learner_queue_size = 13, _tick = 39205, _time = 1.654e+09, train_seconds = 1.8091e+04)
[2022-05-31 19:11:57,333][root][INFO] - Step 119288320 @ 6649.3 SPS. Inference batcher size: 94. Learner queue size: 17. Other stats: (step = 119288320, mean_episode_return = 51.261, mean_episode_step = 620.15, total_loss = 343.9, pg_loss = 227.26, baseline_loss = 122.31, entropy_loss = -5.6713, learner_queue_size = 15, _tick = 39217, _time = 1.654e+09, train_seconds = 1.8096e+04)
[2022-05-31 19:12:02,338][root][INFO] - Step 119321600 @ 6649.4 SPS. Inference batcher size: 138. Learner queue size: 7. Other stats: (step = 119321600, mean_episode_return = 397.53, mean_episode_step = 646.43, total_loss = 144.25, pg_loss = -36.353, baseline_loss = 186.54, entropy_loss = -5.937, learner_queue_size = 16, _tick = 39230, _time = 1.654e+09, train_seconds = 1.8101e+04)
[2022-05-31 19:12:07,344][root][INFO] - Step 119354880 @ 6647.9 SPS. Inference batcher size: 65. Learner queue size: 3. Other stats: (step = 119354880, mean_episode_return = 254.16, mean_episode_step = 541.8, total_loss = -140.38, pg_loss = -199.2, baseline_loss = 64.328, entropy_loss = -5.5119, learner_queue_size = 16, _tick = 39243, _time = 1.654e+09, train_seconds = 1.8106e+04)
[2022-05-31 19:12:12,351][root][INFO] - Step 119388160 @ 6647.5 SPS. Inference batcher size: 41. Learner queue size: 2. Other stats: (step = 119388160, mean_episode_return = 132.26, mean_episode_step = 659.02, total_loss = 122.92, pg_loss = 37.74, baseline_loss = 90.521, entropy_loss = -5.3396, learner_queue_size = 17, _tick = 39256, _time = 1.654e+09, train_seconds = 1.8111e+04)
[2022-05-31 19:12:17,354][root][INFO] - Step 119421440 @ 6651.4 SPS. Inference batcher size: 98. Learner queue size: 3. Other stats: (step = 119421440, mean_episode_return = 188.35, mean_episode_step = 741.45, total_loss = -32.095, pg_loss = -137.9, baseline_loss = 111.68, entropy_loss = -5.8687, learner_queue_size = 20, _tick = 39268, _time = 1.654e+09, train_seconds = 1.8116e+04)
[2022-05-31 19:12:22,358][root][INFO] - Step 119454720 @ 6650.6 SPS. Inference batcher size: 128. Learner queue size: 4. Other stats: (step = 119454720, mean_episode_return = 608.15, mean_episode_step = 750.76, total_loss = -85.46, pg_loss = -151.0, baseline_loss = 71.198, entropy_loss = -5.6625, learner_queue_size = 21, _tick = 39280, _time = 1.654e+09, train_seconds = 1.8121e+04)
[2022-05-31 19:12:27,364][root][INFO] - Step 119485440 @ 6136.8 SPS. Inference batcher size: 67. Learner queue size: 20. Other stats: (step = 119485440, mean_episode_return = 50.225, mean_episode_step = 692.29, total_loss = 32.111, pg_loss = -12.27, baseline_loss = 49.929, entropy_loss = -5.5479, learner_queue_size = 20, _tick = 39290, _time = 1.654e+09, train_seconds = 1.8126e+04)
[2022-05-31 19:12:32,370][root][INFO] - Step 119521280 @ 7159.4 SPS. Inference batcher size: 122. Learner queue size: 13. Other stats: (step = 119521280, mean_episode_return = 144.65, mean_episode_step = 745.44, total_loss = -112.56, pg_loss = -192.63, baseline_loss = 85.792, entropy_loss = -5.7205, learner_queue_size = 11, _tick = 39303, _time = 1.654e+09, train_seconds = 1.8131e+04)
[2022-05-31 19:12:37,376][root][INFO] - Step 119552000 @ 6136.1 SPS. Inference batcher size: 98. Learner queue size: 18. Other stats: (step = 119552000, mean_episode_return = 154.23, mean_episode_step = 832.06, total_loss = 45.752, pg_loss = -3.0991, baseline_loss = 55.438, entropy_loss = -6.5875, learner_queue_size = 16, _tick = 39313, _time = 1.654e+09, train_seconds = 1.8136e+04)
[2022-05-31 19:12:42,378][root][INFO] - Step 119585280 @ 6654.2 SPS. Inference batcher size: 141. Learner queue size: 15. Other stats: (step = 119585280, mean_episode_return = 129.47, mean_episode_step = 642.21, total_loss = 302.1, pg_loss = 240.08, baseline_loss = 68.029, entropy_loss = -6.005, learner_queue_size = 25, _tick = 39322, _time = 1.654e+09, train_seconds = 1.8141e+04)
[2022-05-31 19:12:47,384][root][INFO] - Step 119618560 @ 6648.0 SPS. Inference batcher size: 161. Learner queue size: 12. Other stats: (step = 119618560, mean_episode_return = 325.64, mean_episode_step = 860.9, total_loss = -82.341, pg_loss = -168.38, baseline_loss = 92.039, entropy_loss = -5.997, learner_queue_size = 24, _tick = 39334, _time = 1.654e+09, train_seconds = 1.8146e+04)
[2022-05-31 19:12:52,386][root][INFO] - Step 119651840 @ 6652.8 SPS. Inference batcher size: 20. Learner queue size: 3. Other stats: (step = 119651840, mean_episode_return = 158.35, mean_episode_step = 743.63, total_loss = -52.906, pg_loss = -80.758, baseline_loss = 33.845, entropy_loss = -5.9936, learner_queue_size = 24, _tick = 39347, _time = 1.654e+09, train_seconds = 1.8151e+04)
[2022-05-31 19:12:57,390][root][INFO] - Step 119685120 @ 6650.6 SPS. Inference batcher size: 86. Learner queue size: 0. Other stats: (step = 119685120, mean_episode_return = 287.23, mean_episode_step = 722.4, total_loss = -174.77, pg_loss = -223.0, baseline_loss = 54.157, entropy_loss = -5.9281, learner_queue_size = 17, _tick = 39358, _time = 1.654e+09, train_seconds = 1.8156e+04)
[2022-05-31 19:13:02,394][root][INFO] - Step 119718400 @ 6650.7 SPS. Inference batcher size: 103. Learner queue size: 31. Other stats: (step = 119718400, mean_episode_return = 748.61, mean_episode_step = 640.69, total_loss = 85.011, pg_loss = -4.967, baseline_loss = 95.591, entropy_loss = -5.6123, learner_queue_size = 10, _tick = 39371, _time = 1.654e+09, train_seconds = 1.8161e+04)
[2022-05-31 19:13:07,401][root][INFO] - Step 119749120 @ 6135.9 SPS. Inference batcher size: 97. Learner queue size: 24. Other stats: (step = 119749120, mean_episode_return = 336.42, mean_episode_step = 684.21, total_loss = -83.851, pg_loss = -187.84, baseline_loss = 109.61, entropy_loss = -5.6191, learner_queue_size = 18, _tick = 39382, _time = 1.654e+09, train_seconds = 1.8166e+04)
[2022-05-31 19:13:12,406][root][INFO] - Step 119782400 @ 6648.7 SPS. Inference batcher size: 100. Learner queue size: 19. Other stats: (step = 119782400, mean_episode_return = 94.686, mean_episode_step = 731.09, total_loss = 133.59, pg_loss = -20.538, baseline_loss = 159.59, entropy_loss = -5.4604, learner_queue_size = 27, _tick = 39392, _time = 1.654e+09, train_seconds = 1.8171e+04)
[2022-05-31 19:13:17,410][root][INFO] - Step 119815680 @ 6650.7 SPS. Inference batcher size: 140. Learner queue size: 20. Other stats: (step = 119815680, mean_episode_return = 56.84, mean_episode_step = 656.21, total_loss = 75.714, pg_loss = -39.488, baseline_loss = 120.18, entropy_loss = -4.9775, learner_queue_size = 16, _tick = 39405, _time = 1.654e+09, train_seconds = 1.8176e+04)
[2022-05-31 19:13:22,414][root][INFO] - Step 119848960 @ 6650.7 SPS. Inference batcher size: 151. Learner queue size: 2. Other stats: (step = 119848960, mean_episode_return = 369.58, mean_episode_step = 553.47, total_loss = -195.3, pg_loss = -374.24, baseline_loss = 184.1, entropy_loss = -5.156, learner_queue_size = 19, _tick = 39416, _time = 1.654e+09, train_seconds = 1.8181e+04)
[2022-05-31 19:13:27,418][root][INFO] - Step 119882240 @ 6650.7 SPS. Inference batcher size: 126. Learner queue size: 27. Other stats: (step = 119882240, mean_episode_return = 159.93, mean_episode_step = 651.81, total_loss = 98.255, pg_loss = 33.356, baseline_loss = 70.512, entropy_loss = -5.6139, learner_queue_size = 18, _tick = 39427, _time = 1.654e+09, train_seconds = 1.8186e+04)
[2022-05-31 19:13:32,422][root][INFO] - Step 119912960 @ 6139.0 SPS. Inference batcher size: 71. Learner queue size: 21. Other stats: (step = 119912960, mean_episode_return = 250.11, mean_episode_step = 576.32, total_loss = -119.01, pg_loss = -219.21, baseline_loss = 105.64, entropy_loss = -5.4488, learner_queue_size = 20, _tick = 39438, _time = 1.654e+09, train_seconds = 1.8191e+04)
[2022-05-31 19:13:37,426][root][INFO] - Step 119946240 @ 6650.6 SPS. Inference batcher size: 131. Learner queue size: 19. Other stats: (step = 119946240, mean_episode_return = None, mean_episode_step = 564.69, total_loss = 15.601, pg_loss = -24.517, baseline_loss = 46.316, entropy_loss = -6.1978, learner_queue_size = 27, _tick = 39450, _time = 1.654e+09, train_seconds = 1.8196e+04)
[2022-05-31 19:13:42,430][root][INFO] - Step 119979520 @ 6650.8 SPS. Inference batcher size: 81. Learner queue size: 17. Other stats: (step = 119979520, mean_episode_return = 371.55, mean_episode_step = 622.08, total_loss = 45.035, pg_loss = -38.359, baseline_loss = 89.78, entropy_loss = -6.3854, learner_queue_size = 24, _tick = 39460, _time = 1.654e+09, train_seconds = 1.8201e+04)
[2022-05-31 19:13:47,434][root][INFO] - Step 120012800 @ 6650.6 SPS. Inference batcher size: 101. Learner queue size: 9. Other stats: (step = 120012800, mean_episode_return = 58.254, mean_episode_step = 585.69, total_loss = -50.561, pg_loss = -91.42, baseline_loss = 46.647, entropy_loss = -5.7883, learner_queue_size = 16, _tick = 39472, _time = 1.654e+09, train_seconds = 1.8206e+04)
[2022-05-31 19:13:52,438][root][INFO] - Step 120046080 @ 6650.4 SPS. Inference batcher size: 9. Learner queue size: 12. Other stats: (step = 120046080, mean_episode_return = None, mean_episode_step = 884.03, total_loss = -170.21, pg_loss = -214.87, baseline_loss = 50.604, entropy_loss = -5.95, learner_queue_size = 14, _tick = 39480, _time = 1.654e+09, train_seconds = 1.8211e+04)
[2022-05-31 19:13:57,442][root][INFO] - Step 120079360 @ 6650.9 SPS. Inference batcher size: 98. Learner queue size: 5. Other stats: (step = 120079360, mean_episode_return = 276.34, mean_episode_step = 717.14, total_loss = 54.625, pg_loss = -13.193, baseline_loss = 73.489, entropy_loss = -5.6713, learner_queue_size = 23, _tick = 39492, _time = 1.654e+09, train_seconds = 1.8216e+04)
[2022-05-31 19:14:02,446][root][INFO] - Step 120112640 @ 6650.7 SPS. Inference batcher size: 98. Learner queue size: 30. Other stats: (step = 120112640, mean_episode_return = 185.1, mean_episode_step = 753.0, total_loss = 91.493, pg_loss = -149.48, baseline_loss = 246.87, entropy_loss = -5.8911, learner_queue_size = 13, _tick = 39502, _time = 1.654e+09, train_seconds = 1.8221e+04)
[2022-05-31 19:14:07,450][root][INFO] - Step 120145920 @ 6650.3 SPS. Inference batcher size: 8. Learner queue size: 23. Other stats: (step = 120145920, mean_episode_return = 158.86, mean_episode_step = 676.76, total_loss = 30.37, pg_loss = -51.347, baseline_loss = 87.989, entropy_loss = -6.2713, learner_queue_size = 18, _tick = 39515, _time = 1.654e+09, train_seconds = 1.8226e+04)
[2022-05-31 19:14:12,457][root][INFO] - Step 120176640 @ 6136.1 SPS. Inference batcher size: 161. Learner queue size: 17. Other stats: (step = 120176640, mean_episode_return = 248.94, mean_episode_step = 724.89, total_loss = 246.48, pg_loss = 139.41, baseline_loss = 113.03, entropy_loss = -5.9641, learner_queue_size = 19, _tick = 39527, _time = 1.654e+09, train_seconds = 1.8231e+04)
[2022-05-31 19:14:17,463][root][INFO] - Step 120212480 @ 7159.4 SPS. Inference batcher size: 107. Learner queue size: 14. Other stats: (step = 120212480, mean_episode_return = 458.0, mean_episode_step = 715.72, total_loss = -251.87, pg_loss = -302.62, baseline_loss = 56.864, entropy_loss = -6.116, learner_queue_size = 12, _tick = 39540, _time = 1.654e+09, train_seconds = 1.8236e+04)
[2022-05-31 19:14:22,466][root][INFO] - Step 120243200 @ 6139.9 SPS. Inference batcher size: 124. Learner queue size: 23. Other stats: (step = 120243200, mean_episode_return = 386.5, mean_episode_step = 546.82, total_loss = 45.539, pg_loss = -41.446, baseline_loss = 92.403, entropy_loss = -5.4185, learner_queue_size = 15, _tick = 39550, _time = 1.654e+09, train_seconds = 1.8241e+04)
[2022-05-31 19:14:27,472][root][INFO] - Step 120276480 @ 6647.9 SPS. Inference batcher size: 77. Learner queue size: 10. Other stats: (step = 120276480, mean_episode_return = 37.49, mean_episode_step = 625.49, total_loss = 846.77, pg_loss = 525.69, baseline_loss = 326.5, entropy_loss = -5.4203, learner_queue_size = 20, _tick = 39562, _time = 1.654e+09, train_seconds = 1.8246e+04)
[2022-05-31 19:14:32,474][root][INFO] - Step 120309760 @ 6653.4 SPS. Inference batcher size: 84. Learner queue size: 7. Other stats: (step = 120309760, mean_episode_return = 139.96, mean_episode_step = 723.39, total_loss = 232.03, pg_loss = -6.2746, baseline_loss = 244.18, entropy_loss = -5.8813, learner_queue_size = 21, _tick = 39572, _time = 1.654e+09, train_seconds = 1.8251e+04)
[2022-05-31 19:14:37,478][root][INFO] - Step 120343040 @ 6650.8 SPS. Inference batcher size: 49. Learner queue size: 29. Other stats: (step = 120343040, mean_episode_return = 323.42, mean_episode_step = 539.13, total_loss = 953.67, pg_loss = 584.5, baseline_loss = 374.91, entropy_loss = -5.7336, learner_queue_size = 24, _tick = 39584, _time = 1.654e+09, train_seconds = 1.8256e+04)
[2022-05-31 19:14:42,482][root][INFO] - Step 120376320 @ 6650.7 SPS. Inference batcher size: 85. Learner queue size: 0. Other stats: (step = 120376320, mean_episode_return = 187.01, mean_episode_step = 616.35, total_loss = 414.79, pg_loss = 201.05, baseline_loss = 219.04, entropy_loss = -5.2938, learner_queue_size = 25, _tick = 39596, _time = 1.654e+09, train_seconds = 1.8261e+04)
[2022-05-31 19:14:47,486][root][INFO] - Step 120409600 @ 6650.4 SPS. Inference batcher size: 59. Learner queue size: 24. Other stats: (step = 120409600, mean_episode_return = 344.24, mean_episode_step = 835.81, total_loss = 414.04, pg_loss = 271.11, baseline_loss = 148.84, entropy_loss = -5.9066, learner_queue_size = 24, _tick = 39609, _time = 1.654e+09, train_seconds = 1.8266e+04)
[2022-05-31 19:14:52,493][root][INFO] - Step 120440320 @ 6135.7 SPS. Inference batcher size: 81. Learner queue size: 21. Other stats: (step = 120440320, mean_episode_return = 380.55, mean_episode_step = 487.74, total_loss = 130.34, pg_loss = 1.3584, baseline_loss = 134.68, entropy_loss = -5.6927, learner_queue_size = 18, _tick = 39619, _time = 1.654e+09, train_seconds = 1.8271e+04)
[2022-05-31 19:14:57,498][root][INFO] - Step 120473600 @ 6649.2 SPS. Inference batcher size: 145. Learner queue size: 15. Other stats: (step = 120473600, mean_episode_return = 184.5, mean_episode_step = 624.7, total_loss = -234.67, pg_loss = -278.38, baseline_loss = 49.289, entropy_loss = -5.5726, learner_queue_size = 24, _tick = 39630, _time = 1.654e+09, train_seconds = 1.8276e+04)
[2022-05-31 19:15:02,502][root][INFO] - Step 120506880 @ 6650.8 SPS. Inference batcher size: 132. Learner queue size: 9. Other stats: (step = 120506880, mean_episode_return = 243.06, mean_episode_step = 774.68, total_loss = 188.45, pg_loss = 23.104, baseline_loss = 171.75, entropy_loss = -6.4083, learner_queue_size = 28, _tick = 39639, _time = 1.654e+09, train_seconds = 1.8281e+04)
[2022-05-31 19:15:07,506][root][INFO] - Step 120540160 @ 6650.6 SPS. Inference batcher size: 4. Learner queue size: 8. Other stats: (step = 120540160, mean_episode_return = 375.11, mean_episode_step = 670.07, total_loss = 54.575, pg_loss = -81.509, baseline_loss = 142.26, entropy_loss = -6.173, learner_queue_size = 24, _tick = 39651, _time = 1.654e+09, train_seconds = 1.8286e+04)
[2022-05-31 19:15:12,510][root][INFO] - Step 120573440 @ 6650.7 SPS. Inference batcher size: 100. Learner queue size: 10. Other stats: (step = 120573440, mean_episode_return = 216.24, mean_episode_step = 916.55, total_loss = 112.88, pg_loss = 6.0676, baseline_loss = 113.37, entropy_loss = -6.5634, learner_queue_size = 28, _tick = 39662, _time = 1.654e+09, train_seconds = 1.8291e+04)
[2022-05-31 19:15:17,516][root][INFO] - Step 120606720 @ 6648.0 SPS. Inference batcher size: 104. Learner queue size: 2. Other stats: (step = 120606720, mean_episode_return = 839.65, mean_episode_step = 830.12, total_loss = 494.84, pg_loss = 283.05, baseline_loss = 217.94, entropy_loss = -6.1398, learner_queue_size = 19, _tick = 39675, _time = 1.654e+09, train_seconds = 1.8296e+04)
[2022-05-31 19:15:22,518][root][INFO] - Step 120640000 @ 6653.4 SPS. Inference batcher size: 125. Learner queue size: 3. Other stats: (step = 120640000, mean_episode_return = 561.08, mean_episode_step = 717.92, total_loss = 288.26, pg_loss = 93.486, baseline_loss = 200.75, entropy_loss = -5.9792, learner_queue_size = 23, _tick = 39687, _time = 1.654e+09, train_seconds = 1.8301e+04)
[2022-05-31 19:15:27,522][root][INFO] - Step 120673280 @ 6650.4 SPS. Inference batcher size: 39. Learner queue size: 18. Other stats: (step = 120673280, mean_episode_return = 256.94, mean_episode_step = 725.21, total_loss = -1.5391, pg_loss = -62.827, baseline_loss = 66.882, entropy_loss = -5.5947, learner_queue_size = 16, _tick = 39699, _time = 1.654e+09, train_seconds = 1.8306e+04)
[2022-05-31 19:15:32,526][root][INFO] - Step 120706560 @ 6650.9 SPS. Inference batcher size: 155. Learner queue size: 19. Other stats: (step = 120706560, mean_episode_return = 529.97, mean_episode_step = 696.42, total_loss = -141.31, pg_loss = -185.06, baseline_loss = 49.757, entropy_loss = -6.0122, learner_queue_size = 13, _tick = 39712, _time = 1.654e+09, train_seconds = 1.8311e+04)
[2022-05-31 19:15:37,532][root][INFO] - Step 120737280 @ 6136.6 SPS. Inference batcher size: 149. Learner queue size: 11. Other stats: (step = 120737280, mean_episode_return = 65.024, mean_episode_step = 739.4, total_loss = 163.15, pg_loss = 44.185, baseline_loss = 124.85, entropy_loss = -5.8904, learner_queue_size = 21, _tick = 39722, _time = 1.654e+09, train_seconds = 1.8316e+04)
[2022-05-31 19:15:42,538][root][INFO] - Step 120770560 @ 6648.0 SPS. Inference batcher size: 134. Learner queue size: 19. Other stats: (step = 120770560, mean_episode_return = 475.99, mean_episode_step = 497.0, total_loss = 196.1, pg_loss = 145.36, baseline_loss = 56.952, entropy_loss = -6.2118, learner_queue_size = 19, _tick = 39734, _time = 1.654e+09, train_seconds = 1.8321e+04)
[2022-05-31 19:15:47,544][root][INFO] - Step 120803840 @ 6648.0 SPS. Inference batcher size: 120. Learner queue size: 17. Other stats: (step = 120803840, mean_episode_return = 171.62, mean_episode_step = 665.23, total_loss = 207.8, pg_loss = 87.366, baseline_loss = 126.2, entropy_loss = -5.7682, learner_queue_size = 26, _tick = 39743, _time = 1.654e+09, train_seconds = 1.8326e+04)
[2022-05-31 19:15:52,550][root][INFO] - Step 120837120 @ 6648.1 SPS. Inference batcher size: 112. Learner queue size: 12. Other stats: (step = 120837120, mean_episode_return = 131.33, mean_episode_step = 674.61, total_loss = 220.18, pg_loss = 137.42, baseline_loss = 88.984, entropy_loss = -6.2284, learner_queue_size = 6, _tick = 39753, _time = 1.654e+09, train_seconds = 1.8331e+04)
[2022-05-31 19:15:57,554][root][INFO] - Step 120870400 @ 6650.8 SPS. Inference batcher size: 58. Learner queue size: 0. Other stats: (step = 120870400, mean_episode_return = 367.15, mean_episode_step = 628.71, total_loss = 450.04, pg_loss = 186.53, baseline_loss = 269.74, entropy_loss = -6.2173, learner_queue_size = 20, _tick = 39764, _time = 1.654e+09, train_seconds = 1.8336e+04)
[2022-05-31 19:16:02,558][root][INFO] - Step 120903680 @ 6650.5 SPS. Inference batcher size: 54. Learner queue size: 30. Other stats: (step = 120903680, mean_episode_return = 624.11, mean_episode_step = 728.6, total_loss = 174.82, pg_loss = 80.475, baseline_loss = 100.32, entropy_loss = -5.9832, learner_queue_size = 22, _tick = 39777, _time = 1.654e+09, train_seconds = 1.8341e+04)
[2022-05-31 19:16:07,564][root][INFO] - Step 120934400 @ 6136.6 SPS. Inference batcher size: 101. Learner queue size: 14. Other stats: (step = 120934400, mean_episode_return = 321.62, mean_episode_step = 638.73, total_loss = 70.366, pg_loss = -87.737, baseline_loss = 163.44, entropy_loss = -5.3367, learner_queue_size = 17, _tick = 39789, _time = 1.654e+09, train_seconds = 1.8346e+04)
[2022-05-31 19:16:12,570][root][INFO] - Step 120967680 @ 6648.3 SPS. Inference batcher size: 83. Learner queue size: 13. Other stats: (step = 120967680, mean_episode_return = 199.21, mean_episode_step = 661.03, total_loss = 119.03, pg_loss = 21.268, baseline_loss = 103.93, entropy_loss = -6.1668, learner_queue_size = 30, _tick = 39800, _time = 1.654e+09, train_seconds = 1.8351e+04)
[2022-05-31 19:16:17,574][root][INFO] - Step 121000960 @ 6650.7 SPS. Inference batcher size: 111. Learner queue size: 31. Other stats: (step = 121000960, mean_episode_return = 223.99, mean_episode_step = 516.77, total_loss = -66.632, pg_loss = -114.76, baseline_loss = 54.396, entropy_loss = -6.2718, learner_queue_size = 19, _tick = 39811, _time = 1.654e+09, train_seconds = 1.8356e+04)
[2022-05-31 19:16:22,581][root][INFO] - Step 121034240 @ 6647.2 SPS. Inference batcher size: 73. Learner queue size: 30. Other stats: (step = 121034240, mean_episode_return = 200.77, mean_episode_step = 618.37, total_loss = 1404.7, pg_loss = 764.87, baseline_loss = 646.04, entropy_loss = -6.1698, learner_queue_size = 13, _tick = 39823, _time = 1.654e+09, train_seconds = 1.8361e+04)
[2022-05-31 19:16:27,587][root][INFO] - Step 121064960 @ 6136.6 SPS. Inference batcher size: 123. Learner queue size: 20. Other stats: (step = 121064960, mean_episode_return = 383.17, mean_episode_step = 780.31, total_loss = -78.401, pg_loss = -100.29, baseline_loss = 28.246, entropy_loss = -6.3583, learner_queue_size = 13, _tick = 39835, _time = 1.654e+09, train_seconds = 1.8366e+04)
[2022-05-31 19:16:32,590][root][INFO] - Step 121098240 @ 6651.5 SPS. Inference batcher size: 152. Learner queue size: 17. Other stats: (step = 121098240, mean_episode_return = 105.37, mean_episode_step = 815.2, total_loss = 730.7, pg_loss = 536.95, baseline_loss = 199.73, entropy_loss = -5.9736, learner_queue_size = 12, _tick = 39847, _time = 1.654e+09, train_seconds = 1.8371e+04)
[2022-05-31 19:16:37,594][root][INFO] - Step 121134080 @ 7161.9 SPS. Inference batcher size: 0. Learner queue size: 15. Other stats: (step = 121134080, mean_episode_return = 237.37, mean_episode_step = 741.09, total_loss = 339.31, pg_loss = 258.7, baseline_loss = 86.759, entropy_loss = -6.1459, learner_queue_size = 15, _tick = 39859, _time = 1.654e+09, train_seconds = 1.8376e+04)
[2022-05-31 19:16:42,599][root][INFO] - Step 121164800 @ 6138.4 SPS. Inference batcher size: 151. Learner queue size: 19. Other stats: (step = 121164800, mean_episode_return = None, mean_episode_step = 626.0, total_loss = 16.291, pg_loss = -38.936, baseline_loss = 60.996, entropy_loss = -5.769, learner_queue_size = 19, _tick = 39870, _time = 1.654e+09, train_seconds = 1.8381e+04)
[2022-05-31 19:16:47,602][root][INFO] - Step 121198080 @ 6651.9 SPS. Inference batcher size: 82. Learner queue size: 16. Other stats: (step = 121198080, mean_episode_return = None, mean_episode_step = 659.91, total_loss = -5.9715, pg_loss = -48.454, baseline_loss = 48.225, entropy_loss = -5.7428, learner_queue_size = 13, _tick = 39881, _time = 1.654e+09, train_seconds = 1.8386e+04)
[2022-05-31 19:16:52,607][root][INFO] - Step 121231360 @ 6650.0 SPS. Inference batcher size: 99. Learner queue size: 6. Other stats: (step = 121231360, mean_episode_return = None, mean_episode_step = 787.72, total_loss = 101.49, pg_loss = 33.608, baseline_loss = 74.399, entropy_loss = -6.5199, learner_queue_size = 16, _tick = 39893, _time = 1.654e+09, train_seconds = 1.8391e+04)
[2022-05-31 19:16:57,610][root][INFO] - Step 121264640 @ 6651.4 SPS. Inference batcher size: 111. Learner queue size: 7. Other stats: (step = 121264640, mean_episode_return = 87.785, mean_episode_step = 677.01, total_loss = 549.5, pg_loss = 366.67, baseline_loss = 188.97, entropy_loss = -6.1397, learner_queue_size = 17, _tick = 39906, _time = 1.654e+09, train_seconds = 1.8396e+04)
[2022-05-31 19:17:02,614][root][INFO] - Step 121297920 @ 6650.6 SPS. Inference batcher size: 121. Learner queue size: 11. Other stats: (step = 121297920, mean_episode_return = 194.99, mean_episode_step = 571.64, total_loss = -28.079, pg_loss = -161.86, baseline_loss = 139.62, entropy_loss = -5.8428, learner_queue_size = 23, _tick = 39918, _time = 1.654e+09, train_seconds = 1.8401e+04)
[2022-05-31 19:17:07,618][root][INFO] - Step 121331200 @ 6650.6 SPS. Inference batcher size: 82. Learner queue size: 28. Other stats: (step = 121331200, mean_episode_return = 330.65, mean_episode_step = 746.6, total_loss = -176.98, pg_loss = -243.33, baseline_loss = 72.586, entropy_loss = -6.2338, learner_queue_size = 24, _tick = 39930, _time = 1.654e+09, train_seconds = 1.8406e+04)
[2022-05-31 19:17:12,622][root][INFO] - Step 121364480 @ 6650.9 SPS. Inference batcher size: 111. Learner queue size: 22. Other stats: (step = 121364480, mean_episode_return = 306.78, mean_episode_step = 676.96, total_loss = -66.976, pg_loss = -152.7, baseline_loss = 91.558, entropy_loss = -5.8289, learner_queue_size = 13, _tick = 39943, _time = 1.654e+09, train_seconds = 1.8411e+04)
[2022-05-31 19:17:17,626][root][INFO] - Step 121397760 @ 6650.6 SPS. Inference batcher size: 78. Learner queue size: 25. Other stats: (step = 121397760, mean_episode_return = 166.53, mean_episode_step = 515.12, total_loss = 277.47, pg_loss = 109.94, baseline_loss = 173.1, entropy_loss = -5.5687, learner_queue_size = 15, _tick = 39954, _time = 1.654e+09, train_seconds = 1.8416e+04)
[2022-05-31 19:17:22,632][root][INFO] - Step 121428480 @ 6136.5 SPS. Inference batcher size: 84. Learner queue size: 15. Other stats: (step = 121428480, mean_episode_return = 254.53, mean_episode_step = 646.08, total_loss = -233.81, pg_loss = -294.69, baseline_loss = 66.842, entropy_loss = -5.9582, learner_queue_size = 20, _tick = 39966, _time = 1.654e+09, train_seconds = 1.8421e+04)
[2022-05-31 19:17:27,638][root][INFO] - Step 121461760 @ 6648.0 SPS. Inference batcher size: 73. Learner queue size: 10. Other stats: (step = 121461760, mean_episode_return = None, mean_episode_step = 729.59, total_loss = 232.19, pg_loss = 90.256, baseline_loss = 147.41, entropy_loss = -5.4759, learner_queue_size = 20, _tick = 39976, _time = 1.654e+09, train_seconds = 1.8426e+04)
[2022-05-31 19:17:32,642][root][INFO] - Step 121495040 @ 6650.9 SPS. Inference batcher size: 114. Learner queue size: 20. Other stats: (step = 121495040, mean_episode_return = 161.18, mean_episode_step = 689.19, total_loss = -37.756, pg_loss = -154.56, baseline_loss = 122.98, entropy_loss = -6.1761, learner_queue_size = 21, _tick = 39988, _time = 1.654e+09, train_seconds = 1.8431e+04)
[2022-05-31 19:17:37,646][root][INFO] - Step 121528320 @ 6650.1 SPS. Inference batcher size: 30. Learner queue size: 5. Other stats: (step = 121528320, mean_episode_return = 161.24, mean_episode_step = 644.35, total_loss = 155.88, pg_loss = 49.137, baseline_loss = 112.92, entropy_loss = -6.18, learner_queue_size = 21, _tick = 40000, _time = 1.654e+09, train_seconds = 1.8436e+04)
[2022-05-31 19:17:42,653][root][INFO] - Step 121561600 @ 6647.0 SPS. Inference batcher size: 128. Learner queue size: 10. Other stats: (step = 121561600, mean_episode_return = 101.72, mean_episode_step = 661.11, total_loss = 249.81, pg_loss = 11.949, baseline_loss = 244.28, entropy_loss = -6.4216, learner_queue_size = 26, _tick = 40011, _time = 1.654e+09, train_seconds = 1.8441e+04)
[2022-05-31 19:17:47,659][root][INFO] - Step 121594880 @ 6648.0 SPS. Inference batcher size: 128. Learner queue size: 2. Other stats: (step = 121594880, mean_episode_return = 465.21, mean_episode_step = 671.18, total_loss = -222.99, pg_loss = -292.72, baseline_loss = 75.968, entropy_loss = -6.2382, learner_queue_size = 20, _tick = 40023, _time = 1.654e+09, train_seconds = 1.8446e+04)
[2022-05-31 19:17:52,663][root][INFO] - Step 121628160 @ 6651.6 SPS. Inference batcher size: 58. Learner queue size: 4. Other stats: (step = 121628160, mean_episode_return = 239.32, mean_episode_step = 623.95, total_loss = 161.13, pg_loss = -5.8945, baseline_loss = 172.94, entropy_loss = -5.9143, learner_queue_size = 19, _tick = 40036, _time = 1.654e+09, train_seconds = 1.8451e+04)
[2022-05-31 19:17:57,669][root][INFO] - Step 121661440 @ 6647.5 SPS. Inference batcher size: 120. Learner queue size: 7. Other stats: (step = 121661440, mean_episode_return = 252.6, mean_episode_step = 643.67, total_loss = -25.288, pg_loss = -124.87, baseline_loss = 105.81, entropy_loss = -6.2261, learner_queue_size = 16, _tick = 40049, _time = 1.654e+09, train_seconds = 1.8456e+04)
[2022-05-31 19:18:02,674][root][INFO] - Step 121694720 @ 6649.3 SPS. Inference batcher size: 129. Learner queue size: 4. Other stats: (step = 121694720, mean_episode_return = 261.86, mean_episode_step = 644.47, total_loss = 594.39, pg_loss = 332.32, baseline_loss = 268.06, entropy_loss = -5.9867, learner_queue_size = 19, _tick = 40061, _time = 1.654e+09, train_seconds = 1.8461e+04)
[2022-05-31 19:18:07,678][root][INFO] - Step 121728000 @ 6650.6 SPS. Inference batcher size: 101. Learner queue size: 14. Other stats: (step = 121728000, mean_episode_return = None, mean_episode_step = 612.31, total_loss = 61.761, pg_loss = 12.513, baseline_loss = 55.967, entropy_loss = -6.7192, learner_queue_size = 17, _tick = 40073, _time = 1.654e+09, train_seconds = 1.8466e+04)
[2022-05-31 19:18:12,682][root][INFO] - Step 121761280 @ 6650.7 SPS. Inference batcher size: 97. Learner queue size: 29. Other stats: (step = 121761280, mean_episode_return = 208.85, mean_episode_step = 667.57, total_loss = 89.331, pg_loss = 19.265, baseline_loss = 76.016, entropy_loss = -5.9498, learner_queue_size = 8, _tick = 40084, _time = 1.654e+09, train_seconds = 1.8471e+04)
[2022-05-31 19:18:17,686][root][INFO] - Step 121794560 @ 6650.6 SPS. Inference batcher size: 107. Learner queue size: 2. Other stats: (step = 121794560, mean_episode_return = 203.56, mean_episode_step = 544.52, total_loss = 24.992, pg_loss = -94.126, baseline_loss = 124.94, entropy_loss = -5.8227, learner_queue_size = 21, _tick = 40096, _time = 1.654e+09, train_seconds = 1.8476e+04)
[2022-05-31 19:18:22,692][root][INFO] - Step 121827840 @ 6648.3 SPS. Inference batcher size: 159. Learner queue size: 1. Other stats: (step = 121827840, mean_episode_return = 323.81, mean_episode_step = 810.48, total_loss = 466.47, pg_loss = 280.89, baseline_loss = 192.08, entropy_loss = -6.5043, learner_queue_size = 27, _tick = 40107, _time = 1.654e+09, train_seconds = 1.8481e+04)
[2022-05-31 19:18:27,694][root][INFO] - Step 121861120 @ 6653.2 SPS. Inference batcher size: 111. Learner queue size: 24. Other stats: (step = 121861120, mean_episode_return = 148.32, mean_episode_step = 875.99, total_loss = 300.31, pg_loss = 227.48, baseline_loss = 79.853, entropy_loss = -7.0185, learner_queue_size = 24, _tick = 40118, _time = 1.654e+09, train_seconds = 1.8486e+04)
[2022-05-31 19:18:32,698][root][INFO] - Step 121894400 @ 6650.7 SPS. Inference batcher size: 129. Learner queue size: 21. Other stats: (step = 121894400, mean_episode_return = 218.38, mean_episode_step = 681.96, total_loss = 124.94, pg_loss = 11.788, baseline_loss = 119.59, entropy_loss = -6.4408, learner_queue_size = 15, _tick = 40131, _time = 1.654e+09, train_seconds = 1.8491e+04)
[2022-05-31 19:18:37,704][root][INFO] - Step 121925120 @ 6137.1 SPS. Inference batcher size: 148. Learner queue size: 17. Other stats: (step = 121925120, mean_episode_return = 146.6, mean_episode_step = 780.38, total_loss = 29.868, pg_loss = -15.701, baseline_loss = 52.233, entropy_loss = -6.6643, learner_queue_size = 24, _tick = 40143, _time = 1.654e+09, train_seconds = 1.8496e+04)
[2022-05-31 19:18:42,709][root][INFO] - Step 121958400 @ 6648.0 SPS. Inference batcher size: 144. Learner queue size: 9. Other stats: (step = 121958400, mean_episode_return = 400.39, mean_episode_step = 779.74, total_loss = 56.085, pg_loss = 6.4758, baseline_loss = 56.053, entropy_loss = -6.444, learner_queue_size = 24, _tick = 40155, _time = 1.654e+09, train_seconds = 1.8501e+04)
[2022-05-31 19:18:47,712][root][INFO] - Step 121991680 @ 6653.3 SPS. Inference batcher size: 122. Learner queue size: 8. Other stats: (step = 121991680, mean_episode_return = 382.27, mean_episode_step = 770.77, total_loss = 93.577, pg_loss = -190.88, baseline_loss = 290.71, entropy_loss = -6.2545, learner_queue_size = 25, _tick = 40166, _time = 1.654e+09, train_seconds = 1.8506e+04)
[2022-05-31 19:18:52,717][root][INFO] - Step 122024960 @ 6648.4 SPS. Inference batcher size: 82. Learner queue size: 3. Other stats: (step = 122024960, mean_episode_return = 101.12, mean_episode_step = 692.0, total_loss = 106.7, pg_loss = -24.31, baseline_loss = 137.02, entropy_loss = -6.0176, learner_queue_size = 23, _tick = 40176, _time = 1.654e+09, train_seconds = 1.8511e+04)
[2022-05-31 19:18:57,723][root][INFO] - Step 122058240 @ 6648.0 SPS. Inference batcher size: 115. Learner queue size: 8. Other stats: (step = 122058240, mean_episode_return = 360.01, mean_episode_step = 786.27, total_loss = -233.23, pg_loss = -291.72, baseline_loss = 64.75, entropy_loss = -6.2624, learner_queue_size = 17, _tick = 40188, _time = 1.654e+09, train_seconds = 1.8516e+04)
[2022-05-31 19:19:02,726][root][INFO] - Step 122091520 @ 6652.4 SPS. Inference batcher size: 33. Learner queue size: 4. Other stats: (step = 122091520, mean_episode_return = 347.82, mean_episode_step = 871.23, total_loss = -82.18, pg_loss = -152.47, baseline_loss = 77.084, entropy_loss = -6.7936, learner_queue_size = 19, _tick = 40200, _time = 1.654e+09, train_seconds = 1.8521e+04)
[2022-05-31 19:19:07,730][root][INFO] - Step 122124800 @ 6650.8 SPS. Inference batcher size: 143. Learner queue size: 22. Other stats: (step = 122124800, mean_episode_return = 139.79, mean_episode_step = 961.2, total_loss = 18.306, pg_loss = 13.14, baseline_loss = 12.496, entropy_loss = -7.3296, learner_queue_size = 8, _tick = 40212, _time = 1.654e+09, train_seconds = 1.8526e+04)
[2022-05-31 19:19:12,734][root][INFO] - Step 122158080 @ 6650.5 SPS. Inference batcher size: 67. Learner queue size: 24. Other stats: (step = 122158080, mean_episode_return = 420.54, mean_episode_step = 579.31, total_loss = -56.994, pg_loss = -104.95, baseline_loss = 54.95, entropy_loss = -6.9922, learner_queue_size = 21, _tick = 40223, _time = 1.654e+09, train_seconds = 1.8531e+04)
[2022-05-31 19:19:17,740][root][INFO] - Step 122188800 @ 6136.5 SPS. Inference batcher size: 148. Learner queue size: 21. Other stats: (step = 122188800, mean_episode_return = 227.0, mean_episode_step = 666.19, total_loss = 198.49, pg_loss = 161.86, baseline_loss = 43.432, entropy_loss = -6.8019, learner_queue_size = 19, _tick = 40234, _time = 1.654e+09, train_seconds = 1.8536e+04)
[2022-05-31 19:19:22,746][root][INFO] - Step 122222080 @ 6648.0 SPS. Inference batcher size: 151. Learner queue size: 8. Other stats: (step = 122222080, mean_episode_return = 85.299, mean_episode_step = 872.2, total_loss = 287.32, pg_loss = 238.92, baseline_loss = 54.431, entropy_loss = -6.03, learner_queue_size = 23, _tick = 40244, _time = 1.654e+09, train_seconds = 1.8541e+04)
[2022-05-31 19:19:27,750][root][INFO] - Step 122255360 @ 6650.9 SPS. Inference batcher size: 108. Learner queue size: 6. Other stats: (step = 122255360, mean_episode_return = 311.17, mean_episode_step = 677.95, total_loss = 41.076, pg_loss = -104.85, baseline_loss = 152.14, entropy_loss = -6.2079, learner_queue_size = 23, _tick = 40256, _time = 1.654e+09, train_seconds = 1.8546e+04)
[2022-05-31 19:19:32,754][root][INFO] - Step 122288640 @ 6650.8 SPS. Inference batcher size: 84. Learner queue size: 30. Other stats: (step = 122288640, mean_episode_return = -12.571, mean_episode_step = 674.44, total_loss = -206.88, pg_loss = -262.53, baseline_loss = 61.831, entropy_loss = -6.1815, learner_queue_size = 14, _tick = 40269, _time = 1.654e+09, train_seconds = 1.8551e+04)
[2022-05-31 19:19:37,758][root][INFO] - Step 122319360 @ 6139.1 SPS. Inference batcher size: 113. Learner queue size: 19. Other stats: (step = 122319360, mean_episode_return = 226.6, mean_episode_step = 601.63, total_loss = -14.881, pg_loss = -125.9, baseline_loss = 117.35, entropy_loss = -6.3312, learner_queue_size = 17, _tick = 40280, _time = 1.654e+09, train_seconds = 1.8556e+04)
[2022-05-31 19:19:42,762][root][INFO] - Step 122355200 @ 7162.4 SPS. Inference batcher size: 107. Learner queue size: 26. Other stats: (step = 122355200, mean_episode_return = 72.299, mean_episode_step = 772.45, total_loss = -13.119, pg_loss = -48.853, baseline_loss = 41.84, entropy_loss = -6.106, learner_queue_size = 22, _tick = 40290, _time = 1.654e+09, train_seconds = 1.8561e+04)
[2022-05-31 19:19:47,768][root][INFO] - Step 122385920 @ 6136.4 SPS. Inference batcher size: 108. Learner queue size: 32. Other stats: (step = 122385920, mean_episode_return = 443.43, mean_episode_step = 739.61, total_loss = -11.106, pg_loss = -123.99, baseline_loss = 119.24, entropy_loss = -6.3579, learner_queue_size = 26, _tick = 40302, _time = 1.654e+09, train_seconds = 1.8566e+04)
[2022-05-31 19:19:52,774][root][INFO] - Step 122419200 @ 6648.0 SPS. Inference batcher size: 133. Learner queue size: 14. Other stats: (step = 122419200, mean_episode_return = 251.69, mean_episode_step = 796.27, total_loss = -13.741, pg_loss = -29.285, baseline_loss = 22.294, entropy_loss = -6.749, learner_queue_size = 21, _tick = 40314, _time = 1.654e+09, train_seconds = 1.8572e+04)
[2022-05-31 19:19:57,778][root][INFO] - Step 122452480 @ 6650.8 SPS. Inference batcher size: 92. Learner queue size: 13. Other stats: (step = 122452480, mean_episode_return = 680.94, mean_episode_step = 638.93, total_loss = 17.533, pg_loss = -54.937, baseline_loss = 79.12, entropy_loss = -6.6498, learner_queue_size = 18, _tick = 40325, _time = 1.654e+09, train_seconds = 1.8576e+04)
[2022-05-31 19:20:02,784][root][INFO] - Step 122485760 @ 6647.7 SPS. Inference batcher size: 67. Learner queue size: 14. Other stats: (step = 122485760, mean_episode_return = 192.72, mean_episode_step = 749.31, total_loss = 60.021, pg_loss = -45.284, baseline_loss = 112.14, entropy_loss = -6.84, learner_queue_size = 13, _tick = 40338, _time = 1.654e+09, train_seconds = 1.8582e+04)
[2022-05-31 19:20:07,790][root][INFO] - Step 122519040 @ 6648.0 SPS. Inference batcher size: 115. Learner queue size: 9. Other stats: (step = 122519040, mean_episode_return = 393.28, mean_episode_step = 747.73, total_loss = 163.62, pg_loss = 104.99, baseline_loss = 65.086, entropy_loss = -6.4609, learner_queue_size = 18, _tick = 40350, _time = 1.654e+09, train_seconds = 1.8586e+04)
[2022-05-31 19:20:12,796][root][INFO] - Step 122552320 @ 6648.1 SPS. Inference batcher size: 149. Learner queue size: 15. Other stats: (step = 122552320, mean_episode_return = 214.83, mean_episode_step = 657.16, total_loss = -72.513, pg_loss = -117.03, baseline_loss = 50.958, entropy_loss = -6.4413, learner_queue_size = 23, _tick = 40362, _time = 1.654e+09, train_seconds = 1.8592e+04)
[2022-05-31 19:20:17,802][root][INFO] - Step 122585600 @ 6648.3 SPS. Inference batcher size: 130. Learner queue size: 16. Other stats: (step = 122585600, mean_episode_return = 108.43, mean_episode_step = 603.33, total_loss = 194.1, pg_loss = 80.073, baseline_loss = 120.55, entropy_loss = -6.5296, learner_queue_size = 29, _tick = 40375, _time = 1.654e+09, train_seconds = 1.8596e+04)
[2022-05-31 19:20:22,806][root][INFO] - Step 122618880 @ 6650.8 SPS. Inference batcher size: 140. Learner queue size: 12. Other stats: (step = 122618880, mean_episode_return = 135.52, mean_episode_step = 651.62, total_loss = 93.129, pg_loss = 51.465, baseline_loss = 48.374, entropy_loss = -6.7098, learner_queue_size = 19, _tick = 40387, _time = 1.654e+09, train_seconds = 1.8602e+04)
[2022-05-31 19:20:27,810][root][INFO] - Step 122652160 @ 6650.6 SPS. Inference batcher size: 129. Learner queue size: 18. Other stats: (step = 122652160, mean_episode_return = 246.38, mean_episode_step = 635.56, total_loss = 78.053, pg_loss = -26.628, baseline_loss = 110.84, entropy_loss = -6.1553, learner_queue_size = 30, _tick = 40399, _time = 1.654e+09, train_seconds = 1.8606e+04)
[2022-05-31 19:20:32,814][root][INFO] - Step 122685440 @ 6650.6 SPS. Inference batcher size: 133. Learner queue size: 28. Other stats: (step = 122685440, mean_episode_return = 199.38, mean_episode_step = 776.47, total_loss = -128.27, pg_loss = -168.16, baseline_loss = 46.426, entropy_loss = -6.5364, learner_queue_size = 20, _tick = 40411, _time = 1.654e+09, train_seconds = 1.8612e+04)
[2022-05-31 19:20:37,818][root][INFO] - Step 122718720 @ 6650.7 SPS. Inference batcher size: 73. Learner queue size: 24. Other stats: (step = 122718720, mean_episode_return = 259.81, mean_episode_step = 640.29, total_loss = 10.233, pg_loss = -54.47, baseline_loss = 71.453, entropy_loss = -6.7504, learner_queue_size = 15, _tick = 40422, _time = 1.654e+09, train_seconds = 1.8616e+04)
[2022-05-31 19:20:42,822][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 19:20:42,892][root][INFO] - Step 122752000 @ 6650.8 SPS. Inference batcher size: 101. Learner queue size: 26. Other stats: (step = 122752000, mean_episode_return = 450.49, mean_episode_step = 615.26, total_loss = 101.93, pg_loss = -8.3777, baseline_loss = 116.93, entropy_loss = -6.6257, learner_queue_size = 20, _tick = 40435, _time = 1.654e+09, train_seconds = 1.8622e+04)
[2022-05-31 19:20:47,898][root][INFO] - Step 122782720 @ 6052.0 SPS. Inference batcher size: 86. Learner queue size: 11. Other stats: (step = 122782720, mean_episode_return = 95.5, mean_episode_step = 669.94, total_loss = 203.07, pg_loss = 146.15, baseline_loss = 63.467, entropy_loss = -6.5487, learner_queue_size = 11, _tick = 40444, _time = 1.654e+09, train_seconds = 1.8627e+04)
[2022-05-31 19:20:52,904][root][INFO] - Step 122816000 @ 6648.1 SPS. Inference batcher size: 73. Learner queue size: 20. Other stats: (step = 122816000, mean_episode_return = 413.91, mean_episode_step = 857.94, total_loss = -59.257, pg_loss = -81.322, baseline_loss = 28.641, entropy_loss = -6.5762, learner_queue_size = 20, _tick = 40457, _time = 1.654e+09, train_seconds = 1.8632e+04)
[2022-05-31 19:20:57,910][root][INFO] - Step 122849280 @ 6648.1 SPS. Inference batcher size: 71. Learner queue size: 10. Other stats: (step = 122849280, mean_episode_return = 297.67, mean_episode_step = 620.44, total_loss = -303.98, pg_loss = -326.42, baseline_loss = 28.431, entropy_loss = -5.9814, learner_queue_size = 18, _tick = 40470, _time = 1.654e+09, train_seconds = 1.8637e+04)
[2022-05-31 19:21:02,914][root][INFO] - Step 122882560 @ 6650.5 SPS. Inference batcher size: 157. Learner queue size: 10. Other stats: (step = 122882560, mean_episode_return = None, mean_episode_step = 647.5, total_loss = 130.74, pg_loss = 41.709, baseline_loss = 94.803, entropy_loss = -5.775, learner_queue_size = 16, _tick = 40482, _time = 1.654e+09, train_seconds = 1.8642e+04)
[2022-05-31 19:21:07,918][root][INFO] - Step 122915840 @ 6650.8 SPS. Inference batcher size: 51. Learner queue size: 10. Other stats: (step = 122915840, mean_episode_return = 84.29, mean_episode_step = 658.67, total_loss = -124.84, pg_loss = -208.83, baseline_loss = 89.71, entropy_loss = -5.7198, learner_queue_size = 30, _tick = 40494, _time = 1.654e+09, train_seconds = 1.8647e+04)
[2022-05-31 19:21:12,922][root][INFO] - Step 122949120 @ 6650.7 SPS. Inference batcher size: 56. Learner queue size: 20. Other stats: (step = 122949120, mean_episode_return = 142.18, mean_episode_step = 857.83, total_loss = -236.4, pg_loss = -297.41, baseline_loss = 66.869, entropy_loss = -5.8576, learner_queue_size = 20, _tick = 40507, _time = 1.654e+09, train_seconds = 1.8652e+04)
[2022-05-31 19:21:17,926][root][INFO] - Step 122982400 @ 6650.4 SPS. Inference batcher size: 96. Learner queue size: 21. Other stats: (step = 122982400, mean_episode_return = 223.69, mean_episode_step = 577.12, total_loss = 397.06, pg_loss = 240.96, baseline_loss = 162.15, entropy_loss = -6.046, learner_queue_size = 14, _tick = 40519, _time = 1.654e+09, train_seconds = 1.8657e+04)
[2022-05-31 19:21:22,930][root][INFO] - Step 123013120 @ 6139.3 SPS. Inference batcher size: 129. Learner queue size: 15. Other stats: (step = 123013120, mean_episode_return = 247.38, mean_episode_step = 757.69, total_loss = 25.31, pg_loss = -100.98, baseline_loss = 132.64, entropy_loss = -6.3565, learner_queue_size = 23, _tick = 40529, _time = 1.654e+09, train_seconds = 1.8662e+04)
[2022-05-31 19:21:27,936][root][INFO] - Step 123046400 @ 6648.0 SPS. Inference batcher size: 107. Learner queue size: 10. Other stats: (step = 123046400, mean_episode_return = 70.598, mean_episode_step = 600.9, total_loss = 283.17, pg_loss = 146.93, baseline_loss = 142.6, entropy_loss = -6.3511, learner_queue_size = 17, _tick = 40541, _time = 1.654e+09, train_seconds = 1.8667e+04)
[2022-05-31 19:21:32,938][root][INFO] - Step 123079680 @ 6653.3 SPS. Inference batcher size: 114. Learner queue size: 17. Other stats: (step = 123079680, mean_episode_return = 336.88, mean_episode_step = 689.66, total_loss = 81.228, pg_loss = -3.2002, baseline_loss = 90.397, entropy_loss = -5.9689, learner_queue_size = 25, _tick = 40553, _time = 1.654e+09, train_seconds = 1.8672e+04)
[2022-05-31 19:21:37,942][root][INFO] - Step 123112960 @ 6650.6 SPS. Inference batcher size: 131. Learner queue size: 13. Other stats: (step = 123112960, mean_episode_return = 142.42, mean_episode_step = 699.9, total_loss = 2.5236, pg_loss = -104.99, baseline_loss = 113.31, entropy_loss = -5.8011, learner_queue_size = 20, _tick = 40562, _time = 1.654e+09, train_seconds = 1.8677e+04)
[2022-05-31 19:21:42,946][root][INFO] - Step 123146240 @ 6650.7 SPS. Inference batcher size: 127. Learner queue size: 22. Other stats: (step = 123146240, mean_episode_return = 472.04, mean_episode_step = 569.05, total_loss = -20.03, pg_loss = -94.09, baseline_loss = 80.212, entropy_loss = -6.1524, learner_queue_size = 8, _tick = 40575, _time = 1.654e+09, train_seconds = 1.8682e+04)
[2022-05-31 19:21:47,950][root][INFO] - Step 123179520 @ 6650.7 SPS. Inference batcher size: 87. Learner queue size: 7. Other stats: (step = 123179520, mean_episode_return = 327.15, mean_episode_step = 703.04, total_loss = -73.992, pg_loss = -140.13, baseline_loss = 72.014, entropy_loss = -5.8753, learner_queue_size = 22, _tick = 40588, _time = 1.654e+09, train_seconds = 1.8687e+04)
[2022-05-31 19:21:52,954][root][INFO] - Step 123212800 @ 6650.8 SPS. Inference batcher size: 130. Learner queue size: 1. Other stats: (step = 123212800, mean_episode_return = 112.82, mean_episode_step = 843.19, total_loss = 56.854, pg_loss = -14.172, baseline_loss = 77.108, entropy_loss = -6.0818, learner_queue_size = 11, _tick = 40600, _time = 1.654e+09, train_seconds = 1.8692e+04)
[2022-05-31 19:21:57,958][root][INFO] - Step 123246080 @ 6650.5 SPS. Inference batcher size: 164. Learner queue size: 7. Other stats: (step = 123246080, mean_episode_return = 64.837, mean_episode_step = 649.96, total_loss = 39.659, pg_loss = -14.84, baseline_loss = 60.434, entropy_loss = -5.9348, learner_queue_size = 16, _tick = 40613, _time = 1.654e+09, train_seconds = 1.8697e+04)
[2022-05-31 19:22:02,962][root][INFO] - Step 123279360 @ 6650.8 SPS. Inference batcher size: 128. Learner queue size: 22. Other stats: (step = 123279360, mean_episode_return = 111.43, mean_episode_step = 540.56, total_loss = -362.92, pg_loss = -393.66, baseline_loss = 37.1, entropy_loss = -6.3546, learner_queue_size = 14, _tick = 40626, _time = 1.654e+09, train_seconds = 1.8702e+04)
[2022-05-31 19:22:07,966][root][INFO] - Step 123312640 @ 6650.6 SPS. Inference batcher size: 118. Learner queue size: 25. Other stats: (step = 123312640, mean_episode_return = 403.32, mean_episode_step = 715.72, total_loss = -144.91, pg_loss = -386.67, baseline_loss = 247.73, entropy_loss = -5.9761, learner_queue_size = 18, _tick = 40638, _time = 1.654e+09, train_seconds = 1.8707e+04)
[2022-05-31 19:22:12,972][root][INFO] - Step 123343360 @ 6136.7 SPS. Inference batcher size: 115. Learner queue size: 17. Other stats: (step = 123343360, mean_episode_return = 140.02, mean_episode_step = 509.42, total_loss = 68.203, pg_loss = -14.731, baseline_loss = 89.102, entropy_loss = -6.1676, learner_queue_size = 20, _tick = 40650, _time = 1.654e+09, train_seconds = 1.8712e+04)
[2022-05-31 19:22:17,978][root][INFO] - Step 123376640 @ 6648.1 SPS. Inference batcher size: 31. Learner queue size: 10. Other stats: (step = 123376640, mean_episode_return = 234.42, mean_episode_step = 497.99, total_loss = -81.947, pg_loss = -155.62, baseline_loss = 79.336, entropy_loss = -5.6648, learner_queue_size = 21, _tick = 40663, _time = 1.654e+09, train_seconds = 1.8717e+04)
[2022-05-31 19:22:22,985][root][INFO] - Step 123409920 @ 6647.0 SPS. Inference batcher size: 7. Learner queue size: 20. Other stats: (step = 123409920, mean_episode_return = 208.09, mean_episode_step = 686.5, total_loss = 241.57, pg_loss = 130.34, baseline_loss = 117.84, entropy_loss = -6.6095, learner_queue_size = 22, _tick = 40675, _time = 1.654e+09, train_seconds = 1.8722e+04)
[2022-05-31 19:22:27,990][root][INFO] - Step 123443200 @ 6649.0 SPS. Inference batcher size: 161. Learner queue size: 16. Other stats: (step = 123443200, mean_episode_return = 456.98, mean_episode_step = 645.88, total_loss = 100.63, pg_loss = -5.7699, baseline_loss = 112.46, entropy_loss = -6.0568, learner_queue_size = 19, _tick = 40687, _time = 1.654e+09, train_seconds = 1.8727e+04)
[2022-05-31 19:22:32,996][root][INFO] - Step 123476480 @ 6647.7 SPS. Inference batcher size: 135. Learner queue size: 18. Other stats: (step = 123476480, mean_episode_return = 372.59, mean_episode_step = 669.8, total_loss = -51.163, pg_loss = -214.31, baseline_loss = 169.31, entropy_loss = -6.1603, learner_queue_size = 20, _tick = 40699, _time = 1.654e+09, train_seconds = 1.8732e+04)
[2022-05-31 19:22:38,002][root][INFO] - Step 123509760 @ 6648.2 SPS. Inference batcher size: 118. Learner queue size: 21. Other stats: (step = 123509760, mean_episode_return = 150.53, mean_episode_step = 698.79, total_loss = 229.01, pg_loss = 73.576, baseline_loss = 160.91, entropy_loss = -5.4819, learner_queue_size = 15, _tick = 40711, _time = 1.654e+09, train_seconds = 1.8737e+04)
[2022-05-31 19:22:43,006][root][INFO] - Step 123543040 @ 6650.8 SPS. Inference batcher size: 142. Learner queue size: 4. Other stats: (step = 123543040, mean_episode_return = 165.09, mean_episode_step = 577.67, total_loss = 167.99, pg_loss = 12.182, baseline_loss = 161.62, entropy_loss = -5.8116, learner_queue_size = 17, _tick = 40723, _time = 1.654e+09, train_seconds = 1.8742e+04)
[2022-05-31 19:22:48,012][root][INFO] - Step 123576320 @ 6647.9 SPS. Inference batcher size: 81. Learner queue size: 17. Other stats: (step = 123576320, mean_episode_return = 315.92, mean_episode_step = 671.63, total_loss = -104.68, pg_loss = -126.99, baseline_loss = 28.232, entropy_loss = -5.9283, learner_queue_size = 22, _tick = 40735, _time = 1.654e+09, train_seconds = 1.8747e+04)
[2022-05-31 19:22:53,018][root][INFO] - Step 123609600 @ 6648.2 SPS. Inference batcher size: 101. Learner queue size: 9. Other stats: (step = 123609600, mean_episode_return = None, mean_episode_step = 589.84, total_loss = 361.91, pg_loss = 217.53, baseline_loss = 149.92, entropy_loss = -5.5402, learner_queue_size = 32, _tick = 40744, _time = 1.654e+09, train_seconds = 1.8752e+04)
[2022-05-31 19:22:58,022][root][INFO] - Step 123642880 @ 6650.7 SPS. Inference batcher size: 126. Learner queue size: 2. Other stats: (step = 123642880, mean_episode_return = 134.29, mean_episode_step = 893.34, total_loss = -61.946, pg_loss = -107.18, baseline_loss = 51.153, entropy_loss = -5.9171, learner_queue_size = 24, _tick = 40756, _time = 1.654e+09, train_seconds = 1.8757e+04)
[2022-05-31 19:23:03,026][root][INFO] - Step 123676160 @ 6650.6 SPS. Inference batcher size: 157. Learner queue size: 29. Other stats: (step = 123676160, mean_episode_return = 378.85, mean_episode_step = 649.97, total_loss = 532.08, pg_loss = 238.25, baseline_loss = 299.42, entropy_loss = -5.5827, learner_queue_size = 26, _tick = 40767, _time = 1.654e+09, train_seconds = 1.8762e+04)
[2022-05-31 19:23:08,032][root][INFO] - Step 123706880 @ 6136.6 SPS. Inference batcher size: 119. Learner queue size: 13. Other stats: (step = 123706880, mean_episode_return = 360.46, mean_episode_step = 895.77, total_loss = -188.17, pg_loss = -289.61, baseline_loss = 108.03, entropy_loss = -6.5897, learner_queue_size = 15, _tick = 40778, _time = 1.654e+09, train_seconds = 1.8767e+04)
[2022-05-31 19:23:13,038][root][INFO] - Step 123740160 @ 6647.9 SPS. Inference batcher size: 147. Learner queue size: 22. Other stats: (step = 123740160, mean_episode_return = 565.19, mean_episode_step = 708.22, total_loss = -34.4, pg_loss = -142.29, baseline_loss = 114.21, entropy_loss = -6.3196, learner_queue_size = 17, _tick = 40790, _time = 1.654e+09, train_seconds = 1.8772e+04)
[2022-05-31 19:23:18,044][root][INFO] - Step 123773440 @ 6648.0 SPS. Inference batcher size: 90. Learner queue size: 20. Other stats: (step = 123773440, mean_episode_return = 296.05, mean_episode_step = 606.75, total_loss = 516.21, pg_loss = 272.65, baseline_loss = 249.3, entropy_loss = -5.7365, learner_queue_size = 32, _tick = 40802, _time = 1.654e+09, train_seconds = 1.8777e+04)
[2022-05-31 19:23:23,050][root][INFO] - Step 123806720 @ 6648.0 SPS. Inference batcher size: 142. Learner queue size: 13. Other stats: (step = 123806720, mean_episode_return = 169.79, mean_episode_step = 906.48, total_loss = -202.43, pg_loss = -247.2, baseline_loss = 50.83, entropy_loss = -6.0625, learner_queue_size = 17, _tick = 40815, _time = 1.654e+09, train_seconds = 1.8782e+04)
[2022-05-31 19:23:28,051][root][INFO] - Step 123840000 @ 6654.3 SPS. Inference batcher size: 99. Learner queue size: 12. Other stats: (step = 123840000, mean_episode_return = 82.446, mean_episode_step = 516.76, total_loss = -26.233, pg_loss = -108.01, baseline_loss = 87.467, entropy_loss = -5.6892, learner_queue_size = 13, _tick = 40828, _time = 1.654e+09, train_seconds = 1.8787e+04)
[2022-05-31 19:23:33,054][root][INFO] - Step 123873280 @ 6652.6 SPS. Inference batcher size: 128. Learner queue size: 25. Other stats: (step = 123873280, mean_episode_return = 214.33, mean_episode_step = 704.82, total_loss = 16.117, pg_loss = -55.89, baseline_loss = 78.354, entropy_loss = -6.347, learner_queue_size = 18, _tick = 40836, _time = 1.654e+09, train_seconds = 1.8792e+04)
[2022-05-31 19:23:38,058][root][INFO] - Step 123906560 @ 6650.6 SPS. Inference batcher size: 102. Learner queue size: 12. Other stats: (step = 123906560, mean_episode_return = 56.549, mean_episode_step = 773.39, total_loss = -183.58, pg_loss = -247.37, baseline_loss = 70.021, entropy_loss = -6.2334, learner_queue_size = 16, _tick = 40847, _time = 1.654e+09, train_seconds = 1.8797e+04)
[2022-05-31 19:23:43,062][root][INFO] - Step 123939840 @ 6650.7 SPS. Inference batcher size: 71. Learner queue size: 2. Other stats: (step = 123939840, mean_episode_return = 156.44, mean_episode_step = 539.33, total_loss = 9.2293, pg_loss = -141.28, baseline_loss = 156.23, entropy_loss = -5.7239, learner_queue_size = 31, _tick = 40858, _time = 1.654e+09, train_seconds = 1.8802e+04)
[2022-05-31 19:23:48,066][root][INFO] - Step 123973120 @ 6650.2 SPS. Inference batcher size: 21. Learner queue size: 20. Other stats: (step = 123973120, mean_episode_return = 221.11, mean_episode_step = 610.62, total_loss = 27.411, pg_loss = -69.102, baseline_loss = 102.4, entropy_loss = -5.8857, learner_queue_size = 12, _tick = 40870, _time = 1.654e+09, train_seconds = 1.8807e+04)
[2022-05-31 19:23:53,070][root][INFO] - Step 124006400 @ 6651.1 SPS. Inference batcher size: 155. Learner queue size: 24. Other stats: (step = 124006400, mean_episode_return = 159.93, mean_episode_step = 678.36, total_loss = -260.09, pg_loss = -368.82, baseline_loss = 114.91, entropy_loss = -6.188, learner_queue_size = 21, _tick = 40882, _time = 1.654e+09, train_seconds = 1.8812e+04)
[2022-05-31 19:23:58,074][root][INFO] - Step 124037120 @ 6139.1 SPS. Inference batcher size: 117. Learner queue size: 13. Other stats: (step = 124037120, mean_episode_return = 292.96, mean_episode_step = 625.47, total_loss = 206.72, pg_loss = 129.96, baseline_loss = 83.121, entropy_loss = -6.3574, learner_queue_size = 20, _tick = 40893, _time = 1.654e+09, train_seconds = 1.8817e+04)
[2022-05-31 19:24:03,079][root][INFO] - Step 124070400 @ 6649.4 SPS. Inference batcher size: 149. Learner queue size: 22. Other stats: (step = 124070400, mean_episode_return = 60.83, mean_episode_step = 689.34, total_loss = -216.55, pg_loss = -254.06, baseline_loss = 43.978, entropy_loss = -6.4646, learner_queue_size = 13, _tick = 40905, _time = 1.654e+09, train_seconds = 1.8822e+04)
[2022-05-31 19:24:08,082][root][INFO] - Step 124103680 @ 6652.0 SPS. Inference batcher size: 109. Learner queue size: 9. Other stats: (step = 124103680, mean_episode_return = 162.08, mean_episode_step = 613.93, total_loss = 26.664, pg_loss = -48.417, baseline_loss = 81.44, entropy_loss = -6.3591, learner_queue_size = 21, _tick = 40918, _time = 1.654e+09, train_seconds = 1.8827e+04)
[2022-05-31 19:24:13,086][root][INFO] - Step 124136960 @ 6650.6 SPS. Inference batcher size: 108. Learner queue size: 27. Other stats: (step = 124136960, mean_episode_return = 339.65, mean_episode_step = 610.87, total_loss = 10.534, pg_loss = -205.38, baseline_loss = 221.96, entropy_loss = -6.0466, learner_queue_size = 17, _tick = 40930, _time = 1.654e+09, train_seconds = 1.8832e+04)
[2022-05-31 19:24:18,090][root][INFO] - Step 124170240 @ 6650.7 SPS. Inference batcher size: 76. Learner queue size: 28. Other stats: (step = 124170240, mean_episode_return = 222.85, mean_episode_step = 622.75, total_loss = -2.9408, pg_loss = -227.26, baseline_loss = 230.69, entropy_loss = -6.3726, learner_queue_size = 19, _tick = 40940, _time = 1.654e+09, train_seconds = 1.8837e+04)
[2022-05-31 19:24:23,094][root][INFO] - Step 124200960 @ 6139.0 SPS. Inference batcher size: 143. Learner queue size: 13. Other stats: (step = 124200960, mean_episode_return = 38.48, mean_episode_step = 716.22, total_loss = 170.9, pg_loss = 103.83, baseline_loss = 73.575, entropy_loss = -6.5029, learner_queue_size = 23, _tick = 40949, _time = 1.654e+09, train_seconds = 1.8842e+04)
[2022-05-31 19:24:28,099][root][INFO] - Step 124234240 @ 6650.1 SPS. Inference batcher size: 11. Learner queue size: 20. Other stats: (step = 124234240, mean_episode_return = 44.685, mean_episode_step = 715.88, total_loss = 25.663, pg_loss = -42.903, baseline_loss = 74.982, entropy_loss = -6.4156, learner_queue_size = 21, _tick = 40959, _time = 1.654e+09, train_seconds = 1.8847e+04)
[2022-05-31 19:24:33,105][root][INFO] - Step 124267520 @ 6647.4 SPS. Inference batcher size: 119. Learner queue size: 22. Other stats: (step = 124267520, mean_episode_return = 141.04, mean_episode_step = 740.53, total_loss = -63.123, pg_loss = -139.49, baseline_loss = 82.654, entropy_loss = -6.2911, learner_queue_size = 15, _tick = 40972, _time = 1.654e+09, train_seconds = 1.8852e+04)
[2022-05-31 19:24:38,111][root][INFO] - Step 124300800 @ 6648.0 SPS. Inference batcher size: 134. Learner queue size: 13. Other stats: (step = 124300800, mean_episode_return = None, mean_episode_step = 661.72, total_loss = -7.4315, pg_loss = -40.015, baseline_loss = 39.167, entropy_loss = -6.5834, learner_queue_size = 20, _tick = 40982, _time = 1.654e+09, train_seconds = 1.8857e+04)
[2022-05-31 19:24:43,114][root][INFO] - Step 124334080 @ 6651.9 SPS. Inference batcher size: 114. Learner queue size: 22. Other stats: (step = 124334080, mean_episode_return = 390.52, mean_episode_step = 695.11, total_loss = -33.669, pg_loss = -78.5, baseline_loss = 51.48, entropy_loss = -6.6491, learner_queue_size = 19, _tick = 40994, _time = 1.654e+09, train_seconds = 1.8862e+04)
[2022-05-31 19:24:48,118][root][INFO] - Step 124367360 @ 6650.7 SPS. Inference batcher size: 110. Learner queue size: 25. Other stats: (step = 124367360, mean_episode_return = 622.36, mean_episode_step = 789.06, total_loss = 68.197, pg_loss = -17.627, baseline_loss = 92.598, entropy_loss = -6.7747, learner_queue_size = 24, _tick = 41006, _time = 1.654e+09, train_seconds = 1.8867e+04)
[2022-05-31 19:24:53,122][root][INFO] - Step 124400640 @ 6650.5 SPS. Inference batcher size: 25. Learner queue size: 27. Other stats: (step = 124400640, mean_episode_return = 143.87, mean_episode_step = 565.24, total_loss = -159.51, pg_loss = -169.61, baseline_loss = 16.828, entropy_loss = -6.7366, learner_queue_size = 10, _tick = 41018, _time = 1.654e+09, train_seconds = 1.8872e+04)
[2022-05-31 19:24:58,126][root][INFO] - Step 124431360 @ 6139.2 SPS. Inference batcher size: 100. Learner queue size: 21. Other stats: (step = 124431360, mean_episode_return = 38.74, mean_episode_step = 680.27, total_loss = 101.56, pg_loss = 80.218, baseline_loss = 28.097, entropy_loss = -6.7599, learner_queue_size = 21, _tick = 41029, _time = 1.654e+09, train_seconds = 1.8877e+04)
[2022-05-31 19:25:03,130][root][INFO] - Step 124464640 @ 6650.7 SPS. Inference batcher size: 98. Learner queue size: 13. Other stats: (step = 124464640, mean_episode_return = 224.98, mean_episode_step = 927.97, total_loss = 34.869, pg_loss = -4.383, baseline_loss = 45.245, entropy_loss = -5.9924, learner_queue_size = 24, _tick = 41039, _time = 1.654e+09, train_seconds = 1.8882e+04)
[2022-05-31 19:25:08,136][root][INFO] - Step 124497920 @ 6647.9 SPS. Inference batcher size: 61. Learner queue size: 9. Other stats: (step = 124497920, mean_episode_return = 275.89, mean_episode_step = 640.13, total_loss = -78.202, pg_loss = -321.89, baseline_loss = 249.74, entropy_loss = -6.0463, learner_queue_size = 24, _tick = 41050, _time = 1.654e+09, train_seconds = 1.8887e+04)
[2022-05-31 19:25:13,142][root][INFO] - Step 124531200 @ 6648.2 SPS. Inference batcher size: 75. Learner queue size: 30. Other stats: (step = 124531200, mean_episode_return = 32.985, mean_episode_step = 651.61, total_loss = 59.899, pg_loss = 2.9428, baseline_loss = 63.258, entropy_loss = -6.3018, learner_queue_size = 21, _tick = 41062, _time = 1.654e+09, train_seconds = 1.8892e+04)
[2022-05-31 19:25:18,146][root][INFO] - Step 124564480 @ 6650.7 SPS. Inference batcher size: 56. Learner queue size: 25. Other stats: (step = 124564480, mean_episode_return = 195.66, mean_episode_step = 568.99, total_loss = 177.47, pg_loss = 129.76, baseline_loss = 54.188, entropy_loss = -6.4774, learner_queue_size = 23, _tick = 41074, _time = 1.654e+09, train_seconds = 1.8897e+04)
[2022-05-31 19:25:23,150][root][INFO] - Step 124595200 @ 6139.0 SPS. Inference batcher size: 105. Learner queue size: 13. Other stats: (step = 124595200, mean_episode_return = 269.91, mean_episode_step = 562.87, total_loss = -22.688, pg_loss = -35.539, baseline_loss = 19.339, entropy_loss = -6.4882, learner_queue_size = 22, _tick = 41086, _time = 1.654e+09, train_seconds = 1.8902e+04)
[2022-05-31 19:25:28,154][root][INFO] - Step 124628480 @ 6650.7 SPS. Inference batcher size: 162. Learner queue size: 6. Other stats: (step = 124628480, mean_episode_return = 142.59, mean_episode_step = 750.11, total_loss = 26.441, pg_loss = -10.463, baseline_loss = 43.724, entropy_loss = -6.82, learner_queue_size = 13, _tick = 41097, _time = 1.654e+09, train_seconds = 1.8907e+04)
[2022-05-31 19:25:33,158][root][INFO] - Step 124661760 @ 6650.7 SPS. Inference batcher size: 115. Learner queue size: 31. Other stats: (step = 124661760, mean_episode_return = None, mean_episode_step = 754.88, total_loss = 122.29, pg_loss = 76.307, baseline_loss = 52.528, entropy_loss = -6.5481, learner_queue_size = 23, _tick = 41109, _time = 1.654e+09, train_seconds = 1.8912e+04)
[2022-05-31 19:25:38,162][root][INFO] - Step 124695040 @ 6650.6 SPS. Inference batcher size: 139. Learner queue size: 20. Other stats: (step = 124695040, mean_episode_return = 139.77, mean_episode_step = 668.13, total_loss = 22.411, pg_loss = -36.828, baseline_loss = 65.573, entropy_loss = -6.334, learner_queue_size = 17, _tick = 41120, _time = 1.654e+09, train_seconds = 1.8917e+04)
[2022-05-31 19:25:43,168][root][INFO] - Step 124725760 @ 6136.5 SPS. Inference batcher size: 39. Learner queue size: 18. Other stats: (step = 124725760, mean_episode_return = 91.88, mean_episode_step = 838.95, total_loss = 172.46, pg_loss = 92.163, baseline_loss = 85.914, entropy_loss = -5.6133, learner_queue_size = 19, _tick = 41131, _time = 1.654e+09, train_seconds = 1.8922e+04)
[2022-05-31 19:25:48,174][root][INFO] - Step 124759040 @ 6648.2 SPS. Inference batcher size: 47. Learner queue size: 14. Other stats: (step = 124759040, mean_episode_return = None, mean_episode_step = 789.22, total_loss = -149.52, pg_loss = -214.42, baseline_loss = 71.271, entropy_loss = -6.3685, learner_queue_size = 15, _tick = 41142, _time = 1.654e+09, train_seconds = 1.8927e+04)
[2022-05-31 19:25:53,178][root][INFO] - Step 124792320 @ 6650.7 SPS. Inference batcher size: 54. Learner queue size: 12. Other stats: (step = 124792320, mean_episode_return = None, mean_episode_step = 796.38, total_loss = 213.24, pg_loss = 127.49, baseline_loss = 92.628, entropy_loss = -6.8777, learner_queue_size = 16, _tick = 41152, _time = 1.654e+09, train_seconds = 1.8932e+04)
[2022-05-31 19:25:58,182][root][INFO] - Step 124825600 @ 6650.1 SPS. Inference batcher size: 3. Learner queue size: 7. Other stats: (step = 124825600, mean_episode_return = 206.46, mean_episode_step = 729.28, total_loss = 79.59, pg_loss = 1.1155, baseline_loss = 85.358, entropy_loss = -6.8839, learner_queue_size = 19, _tick = 41162, _time = 1.654e+09, train_seconds = 1.8937e+04)
[2022-05-31 19:26:03,186][root][INFO] - Step 124858880 @ 6651.2 SPS. Inference batcher size: 45. Learner queue size: 4. Other stats: (step = 124858880, mean_episode_return = 260.02, mean_episode_step = 734.98, total_loss = 201.86, pg_loss = 96.536, baseline_loss = 111.87, entropy_loss = -6.5522, learner_queue_size = 15, _tick = 41174, _time = 1.654e+09, train_seconds = 1.8942e+04)
[2022-05-31 19:26:08,190][root][INFO] - Step 124892160 @ 6650.6 SPS. Inference batcher size: 145. Learner queue size: 2. Other stats: (step = 124892160, mean_episode_return = None, mean_episode_step = 781.91, total_loss = -208.35, pg_loss = -236.62, baseline_loss = 34.983, entropy_loss = -6.7203, learner_queue_size = 15, _tick = 41184, _time = 1.654e+09, train_seconds = 1.8947e+04)
[2022-05-31 19:26:13,196][root][INFO] - Step 124925440 @ 6648.0 SPS. Inference batcher size: 99. Learner queue size: 1. Other stats: (step = 124925440, mean_episode_return = 138.24, mean_episode_step = 794.68, total_loss = 128.8, pg_loss = 68.47, baseline_loss = 67.024, entropy_loss = -6.6939, learner_queue_size = 25, _tick = 41196, _time = 1.654e+09, train_seconds = 1.8952e+04)
[2022-05-31 19:26:18,198][root][INFO] - Step 124958720 @ 6653.2 SPS. Inference batcher size: 19. Learner queue size: 27. Other stats: (step = 124958720, mean_episode_return = 169.67, mean_episode_step = 794.19, total_loss = 244.03, pg_loss = 160.58, baseline_loss = 89.991, entropy_loss = -6.5453, learner_queue_size = 23, _tick = 41206, _time = 1.654e+09, train_seconds = 1.8957e+04)
[2022-05-31 19:26:23,202][root][INFO] - Step 124992000 @ 6651.0 SPS. Inference batcher size: 78. Learner queue size: 22. Other stats: (step = 124992000, mean_episode_return = None, mean_episode_step = 807.0, total_loss = 56.107, pg_loss = -11.72, baseline_loss = 73.833, entropy_loss = -6.006, learner_queue_size = 22, _tick = 41216, _time = 1.654e+09, train_seconds = 1.8962e+04)
[2022-05-31 19:26:28,206][root][INFO] - Step 125022720 @ 6139.0 SPS. Inference batcher size: 64. Learner queue size: 13. Other stats: (step = 125022720, mean_episode_return = 285.18, mean_episode_step = 596.72, total_loss = -40.36, pg_loss = -96.829, baseline_loss = 62.379, entropy_loss = -5.9107, learner_queue_size = 18, _tick = 41227, _time = 1.654e+09, train_seconds = 1.8967e+04)
[2022-05-31 19:26:33,210][root][INFO] - Step 125056000 @ 6650.7 SPS. Inference batcher size: 115. Learner queue size: 10. Other stats: (step = 125056000, mean_episode_return = 201.38, mean_episode_step = 852.2, total_loss = 42.706, pg_loss = -41.23, baseline_loss = 89.889, entropy_loss = -5.9534, learner_queue_size = 15, _tick = 41237, _time = 1.654e+09, train_seconds = 1.8972e+04)
[2022-05-31 19:26:38,214][root][INFO] - Step 125089280 @ 6650.7 SPS. Inference batcher size: 85. Learner queue size: 7. Other stats: (step = 125089280, mean_episode_return = None, mean_episode_step = 712.06, total_loss = 78.902, pg_loss = 25.862, baseline_loss = 59.347, entropy_loss = -6.3081, learner_queue_size = 27, _tick = 41248, _time = 1.654e+09, train_seconds = 1.8977e+04)
[2022-05-31 19:26:43,218][root][INFO] - Step 125122560 @ 6650.8 SPS. Inference batcher size: 135. Learner queue size: 2. Other stats: (step = 125122560, mean_episode_return = 212.42, mean_episode_step = 775.67, total_loss = -188.74, pg_loss = -223.23, baseline_loss = 40.749, entropy_loss = -6.2548, learner_queue_size = 20, _tick = 41260, _time = 1.654e+09, train_seconds = 1.8982e+04)
[2022-05-31 19:26:48,224][root][INFO] - Step 125155840 @ 6648.5 SPS. Inference batcher size: 135. Learner queue size: 18. Other stats: (step = 125155840, mean_episode_return = None, mean_episode_step = 515.97, total_loss = 116.08, pg_loss = 67.063, baseline_loss = 55.151, entropy_loss = -6.1359, learner_queue_size = 18, _tick = 41271, _time = 1.654e+09, train_seconds = 1.8987e+04)
[2022-05-31 19:26:53,226][root][INFO] - Step 125186560 @ 6141.0 SPS. Inference batcher size: 98. Learner queue size: 20. Other stats: (step = 125186560, mean_episode_return = 178.81, mean_episode_step = 680.32, total_loss = 48.573, pg_loss = 22.21, baseline_loss = 32.988, entropy_loss = -6.6254, learner_queue_size = 19, _tick = 41282, _time = 1.654e+09, train_seconds = 1.8992e+04)
[2022-05-31 19:26:58,230][root][INFO] - Step 125219840 @ 6650.8 SPS. Inference batcher size: 116. Learner queue size: 28. Other stats: (step = 125219840, mean_episode_return = None, mean_episode_step = 876.72, total_loss = 168.79, pg_loss = 115.17, baseline_loss = 59.535, entropy_loss = -5.914, learner_queue_size = 23, _tick = 41292, _time = 1.654e+09, train_seconds = 1.8997e+04)
[2022-05-31 19:27:03,234][root][INFO] - Step 125253120 @ 6650.6 SPS. Inference batcher size: 103. Learner queue size: 8. Other stats: (step = 125253120, mean_episode_return = 155.37, mean_episode_step = 711.87, total_loss = 92.945, pg_loss = -9.7377, baseline_loss = 108.88, entropy_loss = -6.1988, learner_queue_size = 19, _tick = 41304, _time = 1.654e+09, train_seconds = 1.9002e+04)
[2022-05-31 19:27:08,238][root][INFO] - Step 125286400 @ 6650.6 SPS. Inference batcher size: 88. Learner queue size: 3. Other stats: (step = 125286400, mean_episode_return = 312.41, mean_episode_step = 667.92, total_loss = -135.44, pg_loss = -229.14, baseline_loss = 99.255, entropy_loss = -5.5462, learner_queue_size = 14, _tick = 41316, _time = 1.654e+09, train_seconds = 1.9007e+04)
[2022-05-31 19:27:13,242][root][INFO] - Step 125319680 @ 6650.7 SPS. Inference batcher size: 57. Learner queue size: 1. Other stats: (step = 125319680, mean_episode_return = 424.63, mean_episode_step = 589.27, total_loss = 50.914, pg_loss = -42.013, baseline_loss = 98.565, entropy_loss = -5.6388, learner_queue_size = 21, _tick = 41328, _time = 1.654e+09, train_seconds = 1.9012e+04)
[2022-05-31 19:27:18,246][root][INFO] - Step 125352960 @ 6650.7 SPS. Inference batcher size: 72. Learner queue size: 26. Other stats: (step = 125352960, mean_episode_return = 111.01, mean_episode_step = 674.42, total_loss = 168.22, pg_loss = 115.88, baseline_loss = 58.614, entropy_loss = -6.2802, learner_queue_size = 15, _tick = 41338, _time = 1.654e+09, train_seconds = 1.9017e+04)
[2022-05-31 19:27:23,250][root][INFO] - Step 125383680 @ 6139.0 SPS. Inference batcher size: 48. Learner queue size: 27. Other stats: (step = 125383680, mean_episode_return = 251.72, mean_episode_step = 940.95, total_loss = 85.849, pg_loss = 31.724, baseline_loss = 60.15, entropy_loss = -6.0247, learner_queue_size = 19, _tick = 41350, _time = 1.654e+09, train_seconds = 1.9022e+04)
[2022-05-31 19:27:28,254][root][INFO] - Step 125416960 @ 6650.7 SPS. Inference batcher size: 119. Learner queue size: 13. Other stats: (step = 125416960, mean_episode_return = 61.686, mean_episode_step = 916.29, total_loss = -138.92, pg_loss = -142.09, baseline_loss = 9.7759, entropy_loss = -6.6095, learner_queue_size = 22, _tick = 41362, _time = 1.654e+09, train_seconds = 1.9027e+04)
[2022-05-31 19:27:33,260][root][INFO] - Step 125450240 @ 6648.0 SPS. Inference batcher size: 69. Learner queue size: 18. Other stats: (step = 125450240, mean_episode_return = 205.93, mean_episode_step = 605.62, total_loss = 324.78, pg_loss = 245.03, baseline_loss = 86.022, entropy_loss = -6.2668, learner_queue_size = 15, _tick = 41373, _time = 1.654e+09, train_seconds = 1.9032e+04)
[2022-05-31 19:27:38,266][root][INFO] - Step 125483520 @ 6648.1 SPS. Inference batcher size: 154. Learner queue size: 18. Other stats: (step = 125483520, mean_episode_return = 511.61, mean_episode_step = 672.85, total_loss = 268.76, pg_loss = 169.61, baseline_loss = 104.81, entropy_loss = -5.6594, learner_queue_size = 31, _tick = 41386, _time = 1.654e+09, train_seconds = 1.9037e+04)
[2022-05-31 19:27:43,270][root][INFO] - Step 125516800 @ 6650.6 SPS. Inference batcher size: 95. Learner queue size: 8. Other stats: (step = 125516800, mean_episode_return = 226.67, mean_episode_step = 764.33, total_loss = 483.13, pg_loss = 257.87, baseline_loss = 231.07, entropy_loss = -5.8089, learner_queue_size = 17, _tick = 41397, _time = 1.654e+09, train_seconds = 1.9042e+04)
[2022-05-31 19:27:48,276][root][INFO] - Step 125550080 @ 6647.9 SPS. Inference batcher size: 109. Learner queue size: 7. Other stats: (step = 125550080, mean_episode_return = 238.07, mean_episode_step = 553.72, total_loss = 535.79, pg_loss = 50.865, baseline_loss = 489.8, entropy_loss = -4.8768, learner_queue_size = 32, _tick = 41409, _time = 1.654e+09, train_seconds = 1.9047e+04)
[2022-05-31 19:27:53,282][root][INFO] - Step 125583360 @ 6648.0 SPS. Inference batcher size: 129. Learner queue size: 20. Other stats: (step = 125583360, mean_episode_return = 189.11, mean_episode_step = 1156.5, total_loss = 571.58, pg_loss = 406.42, baseline_loss = 170.89, entropy_loss = -5.7311, learner_queue_size = 18, _tick = 41422, _time = 1.654e+09, train_seconds = 1.9052e+04)
[2022-05-31 19:27:58,288][root][INFO] - Step 125616640 @ 6648.0 SPS. Inference batcher size: 103. Learner queue size: 21. Other stats: (step = 125616640, mean_episode_return = 41.28, mean_episode_step = 596.18, total_loss = -146.16, pg_loss = -206.25, baseline_loss = 66.077, entropy_loss = -5.9902, learner_queue_size = 12, _tick = 41435, _time = 1.654e+09, train_seconds = 1.9057e+04)
[2022-05-31 19:28:03,294][root][INFO] - Step 125649920 @ 6648.2 SPS. Inference batcher size: 124. Learner queue size: 19. Other stats: (step = 125649920, mean_episode_return = 196.56, mean_episode_step = 716.53, total_loss = 52.058, pg_loss = 15.66, baseline_loss = 42.964, entropy_loss = -6.5662, learner_queue_size = 20, _tick = 41447, _time = 1.654e+09, train_seconds = 1.9062e+04)
[2022-05-31 19:28:08,298][root][INFO] - Step 125683200 @ 6650.7 SPS. Inference batcher size: 108. Learner queue size: 7. Other stats: (step = 125683200, mean_episode_return = 125.51, mean_episode_step = 1035.7, total_loss = 188.4, pg_loss = 82.526, baseline_loss = 111.85, entropy_loss = -5.9734, learner_queue_size = 13, _tick = 41460, _time = 1.654e+09, train_seconds = 1.9067e+04)
[2022-05-31 19:28:13,302][root][INFO] - Step 125716480 @ 6650.8 SPS. Inference batcher size: 71. Learner queue size: 8. Other stats: (step = 125716480, mean_episode_return = 486.65, mean_episode_step = 652.16, total_loss = 124.73, pg_loss = -69.343, baseline_loss = 200.54, entropy_loss = -6.467, learner_queue_size = 13, _tick = 41473, _time = 1.654e+09, train_seconds = 1.9072e+04)
[2022-05-31 19:28:18,308][root][INFO] - Step 125749760 @ 6647.8 SPS. Inference batcher size: 126. Learner queue size: 2. Other stats: (step = 125749760, mean_episode_return = 176.21, mean_episode_step = 712.03, total_loss = 35.202, pg_loss = -5.1038, baseline_loss = 46.556, entropy_loss = -6.2504, learner_queue_size = 20, _tick = 41485, _time = 1.654e+09, train_seconds = 1.9077e+04)
[2022-05-31 19:28:23,315][root][INFO] - Step 125783040 @ 6647.0 SPS. Inference batcher size: 33. Learner queue size: 22. Other stats: (step = 125783040, mean_episode_return = 298.9, mean_episode_step = 994.57, total_loss = 78.936, pg_loss = 23.543, baseline_loss = 61.168, entropy_loss = -5.7742, learner_queue_size = 20, _tick = 41498, _time = 1.654e+09, train_seconds = 1.9082e+04)
[2022-05-31 19:28:28,319][root][INFO] - Step 125816320 @ 6651.2 SPS. Inference batcher size: 139. Learner queue size: 15. Other stats: (step = 125816320, mean_episode_return = 123.11, mean_episode_step = 532.86, total_loss = -91.246, pg_loss = -106.03, baseline_loss = 20.015, entropy_loss = -5.2318, learner_queue_size = 10, _tick = 41511, _time = 1.654e+09, train_seconds = 1.9087e+04)
[2022-05-31 19:28:33,325][root][INFO] - Step 125847040 @ 6135.8 SPS. Inference batcher size: 168. Learner queue size: 7. Other stats: (step = 125847040, mean_episode_return = 111.29, mean_episode_step = 660.66, total_loss = 102.02, pg_loss = 64.152, baseline_loss = 43.423, entropy_loss = -5.5603, learner_queue_size = 22, _tick = 41520, _time = 1.654e+09, train_seconds = 1.9092e+04)
[2022-05-31 19:28:38,330][root][INFO] - Step 125880320 @ 6649.6 SPS. Inference batcher size: 108. Learner queue size: 18. Other stats: (step = 125880320, mean_episode_return = None, mean_episode_step = 457.16, total_loss = 108.64, pg_loss = 54.695, baseline_loss = 59.678, entropy_loss = -5.7331, learner_queue_size = 25, _tick = 41532, _time = 1.654e+09, train_seconds = 1.9097e+04)
[2022-05-31 19:28:43,337][root][INFO] - Step 125913600 @ 6647.3 SPS. Inference batcher size: 68. Learner queue size: 17. Other stats: (step = 125913600, mean_episode_return = 239.31, mean_episode_step = 681.11, total_loss = -146.39, pg_loss = -260.3, baseline_loss = 119.79, entropy_loss = -5.8813, learner_queue_size = 19, _tick = 41544, _time = 1.654e+09, train_seconds = 1.9102e+04)
[2022-05-31 19:28:48,343][root][INFO] - Step 125946880 @ 6647.5 SPS. Inference batcher size: 99. Learner queue size: 15. Other stats: (step = 125946880, mean_episode_return = None, mean_episode_step = 696.69, total_loss = 290.35, pg_loss = 196.15, baseline_loss = 100.6, entropy_loss = -6.3988, learner_queue_size = 17, _tick = 41552, _time = 1.654e+09, train_seconds = 1.9107e+04)
[2022-05-31 19:28:53,349][root][INFO] - Step 125980160 @ 6647.5 SPS. Inference batcher size: 22. Learner queue size: 4. Other stats: (step = 125980160, mean_episode_return = 171.59, mean_episode_step = 657.07, total_loss = 90.57, pg_loss = -47.144, baseline_loss = 143.92, entropy_loss = -6.2016, learner_queue_size = 17, _tick = 41561, _time = 1.654e+09, train_seconds = 1.9112e+04)
[2022-05-31 19:28:58,355][root][INFO] - Step 126013440 @ 6649.1 SPS. Inference batcher size: 109. Learner queue size: 2. Other stats: (step = 126013440, mean_episode_return = 139.34, mean_episode_step = 676.75, total_loss = 177.25, pg_loss = 73.357, baseline_loss = 109.71, entropy_loss = -5.8244, learner_queue_size = 23, _tick = 41573, _time = 1.654e+09, train_seconds = 1.9117e+04)
[2022-05-31 19:29:03,361][root][INFO] - Step 126046720 @ 6647.3 SPS. Inference batcher size: 159. Learner queue size: 7. Other stats: (step = 126046720, mean_episode_return = 125.38, mean_episode_step = 1041.8, total_loss = 114.05, pg_loss = 8.871, baseline_loss = 111.21, entropy_loss = -6.0244, learner_queue_size = 25, _tick = 41586, _time = 1.654e+09, train_seconds = 1.9122e+04)
[2022-05-31 19:29:08,366][root][INFO] - Step 126080000 @ 6649.5 SPS. Inference batcher size: 118. Learner queue size: 23. Other stats: (step = 126080000, mean_episode_return = 52.701, mean_episode_step = 894.4, total_loss = -8.6368, pg_loss = -36.747, baseline_loss = 34.193, entropy_loss = -6.0821, learner_queue_size = 11, _tick = 41597, _time = 1.654e+09, train_seconds = 1.9127e+04)
[2022-05-31 19:29:13,370][root][INFO] - Step 126110720 @ 6139.1 SPS. Inference batcher size: 116. Learner queue size: 18. Other stats: (step = 126110720, mean_episode_return = 600.44, mean_episode_step = 704.05, total_loss = 185.38, pg_loss = 105.35, baseline_loss = 86.279, entropy_loss = -6.2528, learner_queue_size = 19, _tick = 41608, _time = 1.654e+09, train_seconds = 1.9132e+04)
[2022-05-31 19:29:18,374][root][INFO] - Step 126144000 @ 6650.3 SPS. Inference batcher size: 1. Learner queue size: 11. Other stats: (step = 126144000, mean_episode_return = 299.05, mean_episode_step = 713.22, total_loss = -55.74, pg_loss = -160.73, baseline_loss = 111.04, entropy_loss = -6.0577, learner_queue_size = 18, _tick = 41620, _time = 1.654e+09, train_seconds = 1.9137e+04)
[2022-05-31 19:29:23,378][root][INFO] - Step 126177280 @ 6650.9 SPS. Inference batcher size: 80. Learner queue size: 16. Other stats: (step = 126177280, mean_episode_return = None, mean_episode_step = 740.5, total_loss = -36.804, pg_loss = -85.341, baseline_loss = 54.639, entropy_loss = -6.1017, learner_queue_size = 17, _tick = 41632, _time = 1.654e+09, train_seconds = 1.9142e+04)
[2022-05-31 19:29:28,382][root][INFO] - Step 126210560 @ 6650.6 SPS. Inference batcher size: 190. Learner queue size: 13. Other stats: (step = 126210560, mean_episode_return = 398.61, mean_episode_step = 737.98, total_loss = 231.86, pg_loss = -58.277, baseline_loss = 296.38, entropy_loss = -6.2441, learner_queue_size = 22, _tick = 41642, _time = 1.654e+09, train_seconds = 1.9147e+04)
[2022-05-31 19:29:33,386][root][INFO] - Step 126243840 @ 6650.7 SPS. Inference batcher size: 98. Learner queue size: 6. Other stats: (step = 126243840, mean_episode_return = 470.96, mean_episode_step = 652.5, total_loss = -124.47, pg_loss = -167.76, baseline_loss = 49.371, entropy_loss = -6.0793, learner_queue_size = 15, _tick = 41652, _time = 1.654e+09, train_seconds = 1.9152e+04)
[2022-05-31 19:29:38,394][root][INFO] - Step 126277120 @ 6645.5 SPS. Inference batcher size: 92. Learner queue size: 4. Other stats: (step = 126277120, mean_episode_return = 167.36, mean_episode_step = 685.15, total_loss = 264.03, pg_loss = 105.9, baseline_loss = 163.9, entropy_loss = -5.7769, learner_queue_size = 21, _tick = 41665, _time = 1.654e+09, train_seconds = 1.9157e+04)
[2022-05-31 19:29:43,399][root][INFO] - Step 126310400 @ 6648.7 SPS. Inference batcher size: 177. Learner queue size: 9. Other stats: (step = 126310400, mean_episode_return = 183.45, mean_episode_step = 1063.9, total_loss = 1073.6, pg_loss = 667.57, baseline_loss = 411.76, entropy_loss = -5.7583, learner_queue_size = 18, _tick = 41678, _time = 1.654e+09, train_seconds = 1.9162e+04)
[2022-05-31 19:29:48,402][root][INFO] - Step 126343680 @ 6652.6 SPS. Inference batcher size: 52. Learner queue size: 1. Other stats: (step = 126343680, mean_episode_return = 265.21, mean_episode_step = 603.39, total_loss = 109.81, pg_loss = -1.7678, baseline_loss = 117.74, entropy_loss = -6.1688, learner_queue_size = 19, _tick = 41689, _time = 1.654e+09, train_seconds = 1.9167e+04)
[2022-05-31 19:29:53,406][root][INFO] - Step 126376960 @ 6650.8 SPS. Inference batcher size: 101. Learner queue size: 3. Other stats: (step = 126376960, mean_episode_return = 194.05, mean_episode_step = 548.11, total_loss = 69.784, pg_loss = -222.94, baseline_loss = 298.65, entropy_loss = -5.9218, learner_queue_size = 22, _tick = 41700, _time = 1.654e+09, train_seconds = 1.9172e+04)
[2022-05-31 19:29:58,412][root][INFO] - Step 126410240 @ 6648.2 SPS. Inference batcher size: 90. Learner queue size: 2. Other stats: (step = 126410240, mean_episode_return = 128.16, mean_episode_step = 733.49, total_loss = 272.8, pg_loss = 193.73, baseline_loss = 85.057, entropy_loss = -5.9867, learner_queue_size = 21, _tick = 41712, _time = 1.654e+09, train_seconds = 1.9177e+04)
[2022-05-31 19:30:03,414][root][INFO] - Step 126443520 @ 6653.1 SPS. Inference batcher size: 106. Learner queue size: 22. Other stats: (step = 126443520, mean_episode_return = 176.74, mean_episode_step = 572.59, total_loss = 241.58, pg_loss = 174.08, baseline_loss = 73.211, entropy_loss = -5.716, learner_queue_size = 14, _tick = 41724, _time = 1.654e+09, train_seconds = 1.9182e+04)
[2022-05-31 19:30:08,418][root][INFO] - Step 126476800 @ 6650.7 SPS. Inference batcher size: 96. Learner queue size: 17. Other stats: (step = 126476800, mean_episode_return = 128.41, mean_episode_step = 694.0, total_loss = 132.24, pg_loss = 59.563, baseline_loss = 78.288, entropy_loss = -5.6133, learner_queue_size = 16, _tick = 41736, _time = 1.654e+09, train_seconds = 1.9187e+04)
[2022-05-31 19:30:13,425][root][INFO] - Step 126507520 @ 6135.6 SPS. Inference batcher size: 130. Learner queue size: 11. Other stats: (step = 126507520, mean_episode_return = None, mean_episode_step = 722.03, total_loss = -73.156, pg_loss = -97.444, baseline_loss = 30.306, entropy_loss = -6.0171, learner_queue_size = 25, _tick = 41747, _time = 1.654e+09, train_seconds = 1.9192e+04)
[2022-05-31 19:30:18,430][root][INFO] - Step 126540800 @ 6649.2 SPS. Inference batcher size: 118. Learner queue size: 13. Other stats: (step = 126540800, mean_episode_return = 231.85, mean_episode_step = 652.8, total_loss = 162.03, pg_loss = 97.07, baseline_loss = 70.947, entropy_loss = -5.985, learner_queue_size = 30, _tick = 41760, _time = 1.654e+09, train_seconds = 1.9197e+04)
[2022-05-31 19:30:23,434][root][INFO] - Step 126574080 @ 6650.7 SPS. Inference batcher size: 117. Learner queue size: 8. Other stats: (step = 126574080, mean_episode_return = 251.29, mean_episode_step = 541.45, total_loss = 85.575, pg_loss = 23.25, baseline_loss = 68.029, entropy_loss = -5.7035, learner_queue_size = 21, _tick = 41772, _time = 1.654e+09, train_seconds = 1.9202e+04)
[2022-05-31 19:30:28,440][root][INFO] - Step 126607360 @ 6647.7 SPS. Inference batcher size: 80. Learner queue size: 3. Other stats: (step = 126607360, mean_episode_return = 224.66, mean_episode_step = 675.26, total_loss = -39.951, pg_loss = -119.41, baseline_loss = 85.346, entropy_loss = -5.8868, learner_queue_size = 14, _tick = 41783, _time = 1.654e+09, train_seconds = 1.9207e+04)
[2022-05-31 19:30:33,446][root][INFO] - Step 126640640 @ 6648.3 SPS. Inference batcher size: 151. Learner queue size: 6. Other stats: (step = 126640640, mean_episode_return = 169.93, mean_episode_step = 626.96, total_loss = 398.74, pg_loss = 257.06, baseline_loss = 147.74, entropy_loss = -6.0601, learner_queue_size = 19, _tick = 41794, _time = 1.654e+09, train_seconds = 1.9212e+04)
[2022-05-31 19:30:38,450][root][INFO] - Step 126673920 @ 6650.6 SPS. Inference batcher size: 120. Learner queue size: 8. Other stats: (step = 126673920, mean_episode_return = 260.57, mean_episode_step = 1016.6, total_loss = -112.2, pg_loss = -184.94, baseline_loss = 78.268, entropy_loss = -5.528, learner_queue_size = 22, _tick = 41806, _time = 1.654e+09, train_seconds = 1.9217e+04)
[2022-05-31 19:30:43,454][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 19:30:43,588][root][INFO] - Step 126707200 @ 6650.6 SPS. Inference batcher size: 74. Learner queue size: 2. Other stats: (step = 126707200, mean_episode_return = 907.17, mean_episode_step = 643.58, total_loss = 114.88, pg_loss = 2.3958, baseline_loss = 118.2, entropy_loss = -5.7184, learner_queue_size = 18, _tick = 41818, _time = 1.654e+09, train_seconds = 1.9222e+04)
[2022-05-31 19:30:48,594][root][INFO] - Step 126740480 @ 6474.7 SPS. Inference batcher size: 197. Learner queue size: 7. Other stats: (step = 126740480, mean_episode_return = None, mean_episode_step = 877.34, total_loss = -156.89, pg_loss = -212.93, baseline_loss = 62.209, entropy_loss = -6.173, learner_queue_size = 14, _tick = 41829, _time = 1.654e+09, train_seconds = 1.9227e+04)
[2022-05-31 19:30:53,598][root][INFO] - Step 126773760 @ 6650.8 SPS. Inference batcher size: 90. Learner queue size: 6. Other stats: (step = 126773760, mean_episode_return = 142.57, mean_episode_step = 801.35, total_loss = 34.874, pg_loss = -44.825, baseline_loss = 86.096, entropy_loss = -6.3972, learner_queue_size = 27, _tick = 41842, _time = 1.654e+09, train_seconds = 1.9232e+04)
[2022-05-31 19:30:58,604][root][INFO] - Step 126807040 @ 6648.0 SPS. Inference batcher size: 49. Learner queue size: 3. Other stats: (step = 126807040, mean_episode_return = 456.9, mean_episode_step = 681.5, total_loss = 165.34, pg_loss = 85.983, baseline_loss = 85.81, entropy_loss = -6.4577, learner_queue_size = 17, _tick = 41854, _time = 1.654e+09, train_seconds = 1.9237e+04)
[2022-05-31 19:31:03,606][root][INFO] - Step 126840320 @ 6653.3 SPS. Inference batcher size: 126. Learner queue size: 6. Other stats: (step = 126840320, mean_episode_return = 262.97, mean_episode_step = 784.5, total_loss = -249.7, pg_loss = -313.67, baseline_loss = 70.364, entropy_loss = -6.3896, learner_queue_size = 19, _tick = 41866, _time = 1.654e+09, train_seconds = 1.9242e+04)
[2022-05-31 19:31:08,610][root][INFO] - Step 126873600 @ 6650.8 SPS. Inference batcher size: 78. Learner queue size: 20. Other stats: (step = 126873600, mean_episode_return = 131.15, mean_episode_step = 693.98, total_loss = 231.26, pg_loss = 138.93, baseline_loss = 98.253, entropy_loss = -5.9231, learner_queue_size = 18, _tick = 41877, _time = 1.654e+09, train_seconds = 1.9247e+04)
[2022-05-31 19:31:13,614][root][INFO] - Step 126906880 @ 6650.6 SPS. Inference batcher size: 96. Learner queue size: 27. Other stats: (step = 126906880, mean_episode_return = 344.78, mean_episode_step = 787.99, total_loss = -50.418, pg_loss = -95.943, baseline_loss = 51.873, entropy_loss = -6.3476, learner_queue_size = 20, _tick = 41889, _time = 1.654e+09, train_seconds = 1.9252e+04)
[2022-05-31 19:31:18,618][root][INFO] - Step 126940160 @ 6650.7 SPS. Inference batcher size: 116. Learner queue size: 24. Other stats: (step = 126940160, mean_episode_return = None, mean_episode_step = 711.56, total_loss = 114.29, pg_loss = 32.781, baseline_loss = 87.521, entropy_loss = -6.0148, learner_queue_size = 22, _tick = 41898, _time = 1.654e+09, train_seconds = 1.9257e+04)
[2022-05-31 19:31:23,624][root][INFO] - Step 126970880 @ 6136.6 SPS. Inference batcher size: 69. Learner queue size: 14. Other stats: (step = 126970880, mean_episode_return = 270.72, mean_episode_step = 674.05, total_loss = 62.921, pg_loss = 19.888, baseline_loss = 49.58, entropy_loss = -6.5475, learner_queue_size = 13, _tick = 41910, _time = 1.654e+09, train_seconds = 1.9262e+04)
[2022-05-31 19:31:28,630][root][INFO] - Step 127004160 @ 6648.0 SPS. Inference batcher size: 117. Learner queue size: 12. Other stats: (step = 127004160, mean_episode_return = 160.68, mean_episode_step = 543.92, total_loss = 321.11, pg_loss = 247.44, baseline_loss = 79.484, entropy_loss = -5.814, learner_queue_size = 17, _tick = 41923, _time = 1.654e+09, train_seconds = 1.9267e+04)
[2022-05-31 19:31:33,634][root][INFO] - Step 127037440 @ 6650.7 SPS. Inference batcher size: 147. Learner queue size: 19. Other stats: (step = 127037440, mean_episode_return = 213.4, mean_episode_step = 578.4, total_loss = 35.331, pg_loss = -59.725, baseline_loss = 100.5, entropy_loss = -5.4442, learner_queue_size = 29, _tick = 41933, _time = 1.654e+09, train_seconds = 1.9272e+04)
[2022-05-31 19:31:38,640][root][INFO] - Step 127070720 @ 6648.1 SPS. Inference batcher size: 35. Learner queue size: 2. Other stats: (step = 127070720, mean_episode_return = 117.3, mean_episode_step = 622.18, total_loss = -121.06, pg_loss = -226.55, baseline_loss = 111.16, entropy_loss = -5.6726, learner_queue_size = 27, _tick = 41944, _time = 1.654e+09, train_seconds = 1.9277e+04)
[2022-05-31 19:31:43,646][root][INFO] - Step 127104000 @ 6648.0 SPS. Inference batcher size: 103. Learner queue size: 1. Other stats: (step = 127104000, mean_episode_return = 156.79, mean_episode_step = 533.59, total_loss = -93.318, pg_loss = -170.33, baseline_loss = 82.538, entropy_loss = -5.5225, learner_queue_size = 19, _tick = 41955, _time = 1.654e+09, train_seconds = 1.9282e+04)
[2022-05-31 19:31:48,650][root][INFO] - Step 127137280 @ 6650.8 SPS. Inference batcher size: 83. Learner queue size: 0. Other stats: (step = 127137280, mean_episode_return = 198.17, mean_episode_step = 599.13, total_loss = 328.34, pg_loss = 210.89, baseline_loss = 123.11, entropy_loss = -5.6617, learner_queue_size = 29, _tick = 41967, _time = 1.654e+09, train_seconds = 1.9287e+04)
[2022-05-31 19:31:53,654][root][INFO] - Step 127170560 @ 6650.7 SPS. Inference batcher size: 176. Learner queue size: 31. Other stats: (step = 127170560, mean_episode_return = 192.39, mean_episode_step = 618.42, total_loss = 135.04, pg_loss = 64.46, baseline_loss = 76.863, entropy_loss = -6.2805, learner_queue_size = 25, _tick = 41979, _time = 1.654e+09, train_seconds = 1.9292e+04)
[2022-05-31 19:31:58,658][root][INFO] - Step 127203840 @ 6650.6 SPS. Inference batcher size: 72. Learner queue size: 2. Other stats: (step = 127203840, mean_episode_return = 346.82, mean_episode_step = 578.48, total_loss = 240.7, pg_loss = 112.09, baseline_loss = 134.85, entropy_loss = -6.2444, learner_queue_size = 17, _tick = 41991, _time = 1.654e+09, train_seconds = 1.9297e+04)
[2022-05-31 19:32:03,664][root][INFO] - Step 127234560 @ 6136.6 SPS. Inference batcher size: 53. Learner queue size: 25. Other stats: (step = 127234560, mean_episode_return = None, mean_episode_step = 582.84, total_loss = 110.01, pg_loss = 48.483, baseline_loss = 67.407, entropy_loss = -5.885, learner_queue_size = 23, _tick = 42001, _time = 1.654e+09, train_seconds = 1.9302e+04)
[2022-05-31 19:32:08,670][root][INFO] - Step 127267840 @ 6648.0 SPS. Inference batcher size: 107. Learner queue size: 6. Other stats: (step = 127267840, mean_episode_return = 76.05, mean_episode_step = 609.92, total_loss = 216.27, pg_loss = 91.197, baseline_loss = 130.88, entropy_loss = -5.8053, learner_queue_size = 27, _tick = 42013, _time = 1.654e+09, train_seconds = 1.9307e+04)
[2022-05-31 19:32:13,671][root][INFO] - Step 127301120 @ 6654.4 SPS. Inference batcher size: 75. Learner queue size: 16. Other stats: (step = 127301120, mean_episode_return = 265.8, mean_episode_step = 615.06, total_loss = 346.37, pg_loss = 265.11, baseline_loss = 87.093, entropy_loss = -5.8341, learner_queue_size = 22, _tick = 42025, _time = 1.654e+09, train_seconds = 1.9312e+04)
[2022-05-31 19:32:18,674][root][INFO] - Step 127336960 @ 7164.1 SPS. Inference batcher size: 131. Learner queue size: 17. Other stats: (step = 127336960, mean_episode_return = 209.95, mean_episode_step = 638.72, total_loss = -184.99, pg_loss = -246.37, baseline_loss = 66.98, entropy_loss = -5.6032, learner_queue_size = 15, _tick = 42039, _time = 1.654e+09, train_seconds = 1.9317e+04)
[2022-05-31 19:32:23,678][root][INFO] - Step 127367680 @ 6139.1 SPS. Inference batcher size: 55. Learner queue size: 26. Other stats: (step = 127367680, mean_episode_return = 91.801, mean_episode_step = 588.05, total_loss = 103.21, pg_loss = -87.269, baseline_loss = 195.86, entropy_loss = -5.3861, learner_queue_size = 12, _tick = 42051, _time = 1.654e+09, train_seconds = 1.9322e+04)
[2022-05-31 19:32:28,683][root][INFO] - Step 127400960 @ 6649.7 SPS. Inference batcher size: 23. Learner queue size: 8. Other stats: (step = 127400960, mean_episode_return = 527.46, mean_episode_step = 696.31, total_loss = 208.4, pg_loss = -48.566, baseline_loss = 262.16, entropy_loss = -5.2007, learner_queue_size = 27, _tick = 42063, _time = 1.654e+09, train_seconds = 1.9327e+04)
[2022-05-31 19:32:33,686][root][INFO] - Step 127434240 @ 6651.2 SPS. Inference batcher size: 100. Learner queue size: 6. Other stats: (step = 127434240, mean_episode_return = 221.91, mean_episode_step = 611.84, total_loss = 580.79, pg_loss = 268.78, baseline_loss = 317.59, entropy_loss = -5.5775, learner_queue_size = 14, _tick = 42076, _time = 1.654e+09, train_seconds = 1.9332e+04)
[2022-05-31 19:32:38,694][root][INFO] - Step 127467520 @ 6645.7 SPS. Inference batcher size: 141. Learner queue size: 6. Other stats: (step = 127467520, mean_episode_return = 170.72, mean_episode_step = 610.04, total_loss = -124.03, pg_loss = -188.04, baseline_loss = 69.989, entropy_loss = -5.9751, learner_queue_size = 13, _tick = 42087, _time = 1.654e+09, train_seconds = 1.9337e+04)
[2022-05-31 19:32:43,698][root][INFO] - Step 127500800 @ 6650.8 SPS. Inference batcher size: 132. Learner queue size: 29. Other stats: (step = 127500800, mean_episode_return = 113.47, mean_episode_step = 657.06, total_loss = 62.566, pg_loss = 12.129, baseline_loss = 56.881, entropy_loss = -6.4447, learner_queue_size = 20, _tick = 42099, _time = 1.654e+09, train_seconds = 1.9342e+04)
[2022-05-31 19:32:48,702][root][INFO] - Step 127534080 @ 6650.6 SPS. Inference batcher size: 99. Learner queue size: 23. Other stats: (step = 127534080, mean_episode_return = 254.96, mean_episode_step = 567.41, total_loss = 131.44, pg_loss = 13.479, baseline_loss = 123.98, entropy_loss = -6.0155, learner_queue_size = 21, _tick = 42110, _time = 1.654e+09, train_seconds = 1.9347e+04)
[2022-05-31 19:32:53,706][root][INFO] - Step 127564800 @ 6139.1 SPS. Inference batcher size: 142. Learner queue size: 20. Other stats: (step = 127564800, mean_episode_return = 201.57, mean_episode_step = 609.53, total_loss = 535.86, pg_loss = 325.66, baseline_loss = 216.37, entropy_loss = -6.1673, learner_queue_size = 14, _tick = 42122, _time = 1.654e+09, train_seconds = 1.9352e+04)
[2022-05-31 19:32:58,710][root][INFO] - Step 127598080 @ 6650.7 SPS. Inference batcher size: 98. Learner queue size: 13. Other stats: (step = 127598080, mean_episode_return = 59.191, mean_episode_step = 578.55, total_loss = 256.54, pg_loss = 103.03, baseline_loss = 159.66, entropy_loss = -6.1549, learner_queue_size = 16, _tick = 42135, _time = 1.654e+09, train_seconds = 1.9357e+04)
[2022-05-31 19:33:03,715][root][INFO] - Step 127631360 @ 6650.0 SPS. Inference batcher size: 137. Learner queue size: 12. Other stats: (step = 127631360, mean_episode_return = 168.28, mean_episode_step = 645.79, total_loss = 238.72, pg_loss = 125.67, baseline_loss = 119.47, entropy_loss = -6.4173, learner_queue_size = 29, _tick = 42148, _time = 1.654e+09, train_seconds = 1.9362e+04)
[2022-05-31 19:33:08,718][root][INFO] - Step 127664640 @ 6651.5 SPS. Inference batcher size: 165. Learner queue size: 25. Other stats: (step = 127664640, mean_episode_return = 294.76, mean_episode_step = 629.49, total_loss = 316.25, pg_loss = 197.87, baseline_loss = 124.51, entropy_loss = -6.142, learner_queue_size = 21, _tick = 42159, _time = 1.654e+09, train_seconds = 1.9367e+04)
[2022-05-31 19:33:13,722][root][INFO] - Step 127697920 @ 6650.3 SPS. Inference batcher size: 141. Learner queue size: 18. Other stats: (step = 127697920, mean_episode_return = 449.84, mean_episode_step = 705.21, total_loss = 117.96, pg_loss = 38.289, baseline_loss = 85.624, entropy_loss = -5.9579, learner_queue_size = 18, _tick = 42172, _time = 1.654e+09, train_seconds = 1.9372e+04)
[2022-05-31 19:33:18,726][root][INFO] - Step 127731200 @ 6651.1 SPS. Inference batcher size: 117. Learner queue size: 24. Other stats: (step = 127731200, mean_episode_return = 184.23, mean_episode_step = 738.51, total_loss = 415.85, pg_loss = 283.35, baseline_loss = 138.27, entropy_loss = -5.779, learner_queue_size = 18, _tick = 42183, _time = 1.654e+09, train_seconds = 1.9377e+04)
[2022-05-31 19:33:23,730][root][INFO] - Step 127761920 @ 6139.1 SPS. Inference batcher size: 127. Learner queue size: 18. Other stats: (step = 127761920, mean_episode_return = 139.29, mean_episode_step = 730.05, total_loss = -44.645, pg_loss = -170.06, baseline_loss = 131.86, entropy_loss = -6.4396, learner_queue_size = 19, _tick = 42195, _time = 1.654e+09, train_seconds = 1.9382e+04)
[2022-05-31 19:33:28,734][root][INFO] - Step 127797760 @ 7161.9 SPS. Inference batcher size: 68. Learner queue size: 24. Other stats: (step = 127797760, mean_episode_return = 46.643, mean_episode_step = 534.17, total_loss = 95.626, pg_loss = -13.775, baseline_loss = 115.03, entropy_loss = -5.6266, learner_queue_size = 13, _tick = 42207, _time = 1.654e+09, train_seconds = 1.9387e+04)
[2022-05-31 19:33:33,741][root][INFO] - Step 127828480 @ 6136.1 SPS. Inference batcher size: 118. Learner queue size: 19. Other stats: (step = 127828480, mean_episode_return = 192.82, mean_episode_step = 676.42, total_loss = 285.54, pg_loss = 167.88, baseline_loss = 123.95, entropy_loss = -6.2919, learner_queue_size = 20, _tick = 42219, _time = 1.654e+09, train_seconds = 1.9392e+04)
[2022-05-31 19:33:38,746][root][INFO] - Step 127861760 @ 6648.1 SPS. Inference batcher size: 139. Learner queue size: 20. Other stats: (step = 127861760, mean_episode_return = 193.36, mean_episode_step = 777.18, total_loss = -86.949, pg_loss = -123.08, baseline_loss = 42.787, entropy_loss = -6.6576, learner_queue_size = 23, _tick = 42231, _time = 1.654e+09, train_seconds = 1.9397e+04)
[2022-05-31 19:33:43,750][root][INFO] - Step 127895040 @ 6651.3 SPS. Inference batcher size: 97. Learner queue size: 9. Other stats: (step = 127895040, mean_episode_return = 123.11, mean_episode_step = 521.68, total_loss = 494.8, pg_loss = 286.36, baseline_loss = 214.66, entropy_loss = -6.2233, learner_queue_size = 28, _tick = 42244, _time = 1.654e+09, train_seconds = 1.9402e+04)
[2022-05-31 19:33:48,756][root][INFO] - Step 127928320 @ 6648.1 SPS. Inference batcher size: 73. Learner queue size: 3. Other stats: (step = 127928320, mean_episode_return = 205.59, mean_episode_step = 712.92, total_loss = 21.151, pg_loss = -33.84, baseline_loss = 61.115, entropy_loss = -6.1235, learner_queue_size = 19, _tick = 42255, _time = 1.654e+09, train_seconds = 1.9407e+04)
[2022-05-31 19:33:53,758][root][INFO] - Step 127961600 @ 6653.4 SPS. Inference batcher size: 129. Learner queue size: 4. Other stats: (step = 127961600, mean_episode_return = 210.71, mean_episode_step = 768.96, total_loss = 727.97, pg_loss = 404.04, baseline_loss = 329.53, entropy_loss = -5.6015, learner_queue_size = 19, _tick = 42267, _time = 1.654e+09, train_seconds = 1.9412e+04)
[2022-05-31 19:33:58,762][root][INFO] - Step 127994880 @ 6650.6 SPS. Inference batcher size: 46. Learner queue size: 4. Other stats: (step = 127994880, mean_episode_return = 328.4, mean_episode_step = 717.42, total_loss = -24.043, pg_loss = -87.833, baseline_loss = 69.89, entropy_loss = -6.1009, learner_queue_size = 22, _tick = 42280, _time = 1.654e+09, train_seconds = 1.9417e+04)
[2022-05-31 19:34:03,766][root][INFO] - Step 128028160 @ 6650.8 SPS. Inference batcher size: 98. Learner queue size: 1. Other stats: (step = 128028160, mean_episode_return = 48.241, mean_episode_step = 632.77, total_loss = -25.55, pg_loss = -86.217, baseline_loss = 66.293, entropy_loss = -5.6257, learner_queue_size = 26, _tick = 42292, _time = 1.654e+09, train_seconds = 1.9422e+04)
[2022-05-31 19:34:08,772][root][INFO] - Step 128061440 @ 6647.9 SPS. Inference batcher size: 71. Learner queue size: 3. Other stats: (step = 128061440, mean_episode_return = None, mean_episode_step = 737.56, total_loss = 309.07, pg_loss = 210.26, baseline_loss = 105.02, entropy_loss = -6.2008, learner_queue_size = 29, _tick = 42304, _time = 1.654e+09, train_seconds = 1.9428e+04)
[2022-05-31 19:34:13,774][root][INFO] - Step 128092160 @ 6141.5 SPS. Inference batcher size: 53. Learner queue size: 12. Other stats: (step = 128092160, mean_episode_return = 84.64, mean_episode_step = 783.77, total_loss = -25.562, pg_loss = -104.14, baseline_loss = 84.484, entropy_loss = -5.9057, learner_queue_size = 19, _tick = 42316, _time = 1.654e+09, train_seconds = 1.9432e+04)
[2022-05-31 19:34:18,778][root][INFO] - Step 128125440 @ 6650.7 SPS. Inference batcher size: 127. Learner queue size: 12. Other stats: (step = 128125440, mean_episode_return = 48.462, mean_episode_step = 618.53, total_loss = -220.94, pg_loss = -249.93, baseline_loss = 35.416, entropy_loss = -6.4248, learner_queue_size = 21, _tick = 42327, _time = 1.654e+09, train_seconds = 1.9438e+04)
[2022-05-31 19:34:23,782][root][INFO] - Step 128158720 @ 6650.8 SPS. Inference batcher size: 125. Learner queue size: 24. Other stats: (step = 128158720, mean_episode_return = 331.06, mean_episode_step = 660.6, total_loss = 266.06, pg_loss = 167.09, baseline_loss = 105.52, entropy_loss = -6.5574, learner_queue_size = 23, _tick = 42340, _time = 1.654e+09, train_seconds = 1.9442e+04)
[2022-05-31 19:34:28,786][root][INFO] - Step 128192000 @ 6650.5 SPS. Inference batcher size: 179. Learner queue size: 17. Other stats: (step = 128192000, mean_episode_return = 169.27, mean_episode_step = 659.04, total_loss = 25.839, pg_loss = -29.648, baseline_loss = 61.524, entropy_loss = -6.0371, learner_queue_size = 21, _tick = 42350, _time = 1.654e+09, train_seconds = 1.9448e+04)
[2022-05-31 19:34:33,790][root][INFO] - Step 128225280 @ 6650.7 SPS. Inference batcher size: 104. Learner queue size: 15. Other stats: (step = 128225280, mean_episode_return = 118.27, mean_episode_step = 646.99, total_loss = 25.142, pg_loss = -4.9569, baseline_loss = 36.223, entropy_loss = -6.1234, learner_queue_size = 31, _tick = 42360, _time = 1.654e+09, train_seconds = 1.9452e+04)
[2022-05-31 19:34:38,794][root][INFO] - Step 128258560 @ 6650.4 SPS. Inference batcher size: 82. Learner queue size: 5. Other stats: (step = 128258560, mean_episode_return = 158.96, mean_episode_step = 637.27, total_loss = 691.9, pg_loss = 419.1, baseline_loss = 278.42, entropy_loss = -5.6242, learner_queue_size = 15, _tick = 42370, _time = 1.654e+09, train_seconds = 1.9458e+04)
[2022-05-31 19:34:43,798][root][INFO] - Step 128291840 @ 6651.0 SPS. Inference batcher size: 137. Learner queue size: 24. Other stats: (step = 128291840, mean_episode_return = 189.32, mean_episode_step = 707.4, total_loss = 163.79, pg_loss = 113.35, baseline_loss = 56.218, entropy_loss = -5.776, learner_queue_size = 13, _tick = 42383, _time = 1.654e+09, train_seconds = 1.9462e+04)
[2022-05-31 19:34:48,802][root][INFO] - Step 128325120 @ 6650.7 SPS. Inference batcher size: 1. Learner queue size: 26. Other stats: (step = 128325120, mean_episode_return = 968.69, mean_episode_step = 769.19, total_loss = -101.23, pg_loss = -126.52, baseline_loss = 31.61, entropy_loss = -6.3201, learner_queue_size = 15, _tick = 42396, _time = 1.654e+09, train_seconds = 1.9468e+04)
[2022-05-31 19:34:53,809][root][INFO] - Step 128355840 @ 6135.2 SPS. Inference batcher size: 131. Learner queue size: 19. Other stats: (step = 128355840, mean_episode_return = 117.96, mean_episode_step = 751.35, total_loss = 98.63, pg_loss = 60.183, baseline_loss = 44.669, entropy_loss = -6.2222, learner_queue_size = 17, _tick = 42408, _time = 1.654e+09, train_seconds = 1.9472e+04)
[2022-05-31 19:34:58,815][root][INFO] - Step 128389120 @ 6648.0 SPS. Inference batcher size: 105. Learner queue size: 20. Other stats: (step = 128389120, mean_episode_return = None, mean_episode_step = 611.22, total_loss = -65.747, pg_loss = -81.406, baseline_loss = 22.012, entropy_loss = -6.3527, learner_queue_size = 14, _tick = 42420, _time = 1.654e+09, train_seconds = 1.9478e+04)
[2022-05-31 19:35:03,818][root][INFO] - Step 128422400 @ 6652.4 SPS. Inference batcher size: 85. Learner queue size: 14. Other stats: (step = 128422400, mean_episode_return = 384.71, mean_episode_step = 601.85, total_loss = -27.541, pg_loss = -94.885, baseline_loss = 73.668, entropy_loss = -6.3233, learner_queue_size = 19, _tick = 42432, _time = 1.654e+09, train_seconds = 1.9482e+04)
[2022-05-31 19:35:08,822][root][INFO] - Step 128455680 @ 6650.7 SPS. Inference batcher size: 101. Learner queue size: 3. Other stats: (step = 128455680, mean_episode_return = 89.089, mean_episode_step = 839.67, total_loss = -72.942, pg_loss = -90.48, baseline_loss = 24.242, entropy_loss = -6.7045, learner_queue_size = 17, _tick = 42445, _time = 1.654e+09, train_seconds = 1.9488e+04)
[2022-05-31 19:35:13,826][root][INFO] - Step 128488960 @ 6650.7 SPS. Inference batcher size: 119. Learner queue size: 1. Other stats: (step = 128488960, mean_episode_return = 402.82, mean_episode_step = 573.44, total_loss = 456.55, pg_loss = 255.96, baseline_loss = 206.43, entropy_loss = -5.8457, learner_queue_size = 20, _tick = 42457, _time = 1.654e+09, train_seconds = 1.9492e+04)
[2022-05-31 19:35:18,830][root][INFO] - Step 128522240 @ 6650.7 SPS. Inference batcher size: 8. Learner queue size: 31. Other stats: (step = 128522240, mean_episode_return = 550.77, mean_episode_step = 583.43, total_loss = -220.7, pg_loss = -283.8, baseline_loss = 68.828, entropy_loss = -5.722, learner_queue_size = 29, _tick = 42470, _time = 1.654e+09, train_seconds = 1.9498e+04)
[2022-05-31 19:35:23,836][root][INFO] - Step 128555520 @ 6647.5 SPS. Inference batcher size: 47. Learner queue size: 21. Other stats: (step = 128555520, mean_episode_return = 147.02, mean_episode_step = 735.71, total_loss = -52.647, pg_loss = -106.17, baseline_loss = 60.213, entropy_loss = -6.6948, learner_queue_size = 18, _tick = 42479, _time = 1.654e+09, train_seconds = 1.9502e+04)
[2022-05-31 19:35:28,842][root][INFO] - Step 128586240 @ 6136.9 SPS. Inference batcher size: 124. Learner queue size: 17. Other stats: (step = 128586240, mean_episode_return = 259.28, mean_episode_step = 773.51, total_loss = 66.099, pg_loss = 18.097, baseline_loss = 54.375, entropy_loss = -6.3723, learner_queue_size = 17, _tick = 42489, _time = 1.654e+09, train_seconds = 1.9508e+04)
[2022-05-31 19:35:33,848][root][INFO] - Step 128619520 @ 6647.8 SPS. Inference batcher size: 97. Learner queue size: 16. Other stats: (step = 128619520, mean_episode_return = 315.09, mean_episode_step = 928.35, total_loss = 377.78, pg_loss = 286.27, baseline_loss = 97.903, entropy_loss = -6.4009, learner_queue_size = 13, _tick = 42502, _time = 1.654e+09, train_seconds = 1.9512e+04)
[2022-05-31 19:35:38,854][root][INFO] - Step 128652800 @ 6648.4 SPS. Inference batcher size: 128. Learner queue size: 18. Other stats: (step = 128652800, mean_episode_return = 69.25, mean_episode_step = 629.97, total_loss = 89.628, pg_loss = 48.257, baseline_loss = 47.414, entropy_loss = -6.0433, learner_queue_size = 28, _tick = 42515, _time = 1.654e+09, train_seconds = 1.9518e+04)
[2022-05-31 19:35:43,860][root][INFO] - Step 128686080 @ 6648.0 SPS. Inference batcher size: 163. Learner queue size: 19. Other stats: (step = 128686080, mean_episode_return = 197.2, mean_episode_step = 755.69, total_loss = 357.18, pg_loss = 163.38, baseline_loss = 199.84, entropy_loss = -6.0375, learner_queue_size = 19, _tick = 42526, _time = 1.654e+09, train_seconds = 1.9522e+04)
[2022-05-31 19:35:48,866][root][INFO] - Step 128719360 @ 6648.0 SPS. Inference batcher size: 151. Learner queue size: 2. Other stats: (step = 128719360, mean_episode_return = 167.54, mean_episode_step = 820.23, total_loss = 259.99, pg_loss = 10.589, baseline_loss = 255.12, entropy_loss = -5.7214, learner_queue_size = 22, _tick = 42539, _time = 1.654e+09, train_seconds = 1.9528e+04)
[2022-05-31 19:35:53,870][root][INFO] - Step 128752640 @ 6650.8 SPS. Inference batcher size: 64. Learner queue size: 23. Other stats: (step = 128752640, mean_episode_return = 211.38, mean_episode_step = 633.14, total_loss = -310.39, pg_loss = -368.95, baseline_loss = 64.245, entropy_loss = -5.6904, learner_queue_size = 16, _tick = 42552, _time = 1.654e+09, train_seconds = 1.9533e+04)
[2022-05-31 19:35:58,874][root][INFO] - Step 128785920 @ 6650.8 SPS. Inference batcher size: 73. Learner queue size: 30. Other stats: (step = 128785920, mean_episode_return = 124.76, mean_episode_step = 651.29, total_loss = 198.0, pg_loss = 60.289, baseline_loss = 143.66, entropy_loss = -5.9479, learner_queue_size = 22, _tick = 42564, _time = 1.654e+09, train_seconds = 1.9538e+04)
[2022-05-31 19:36:03,878][root][INFO] - Step 128819200 @ 6650.7 SPS. Inference batcher size: 123. Learner queue size: 29. Other stats: (step = 128819200, mean_episode_return = 198.15, mean_episode_step = 758.14, total_loss = 139.8, pg_loss = -47.412, baseline_loss = 193.31, entropy_loss = -6.0982, learner_queue_size = 18, _tick = 42577, _time = 1.654e+09, train_seconds = 1.9543e+04)
[2022-05-31 19:36:08,882][root][INFO] - Step 128852480 @ 6650.7 SPS. Inference batcher size: 117. Learner queue size: 20. Other stats: (step = 128852480, mean_episode_return = 133.99, mean_episode_step = 680.75, total_loss = 403.25, pg_loss = 246.78, baseline_loss = 162.59, entropy_loss = -6.1132, learner_queue_size = 14, _tick = 42590, _time = 1.654e+09, train_seconds = 1.9548e+04)
[2022-05-31 19:36:13,888][root][INFO] - Step 128883200 @ 6136.4 SPS. Inference batcher size: 171. Learner queue size: 21. Other stats: (step = 128883200, mean_episode_return = 259.21, mean_episode_step = 690.72, total_loss = 22.273, pg_loss = -29.647, baseline_loss = 58.614, entropy_loss = -6.6941, learner_queue_size = 16, _tick = 42601, _time = 1.654e+09, train_seconds = 1.9553e+04)
[2022-05-31 19:36:18,889][root][INFO] - Step 128916480 @ 6654.2 SPS. Inference batcher size: 93. Learner queue size: 2. Other stats: (step = 128916480, mean_episode_return = 164.94, mean_episode_step = 620.3, total_loss = 25.968, pg_loss = -92.104, baseline_loss = 124.21, entropy_loss = -6.1372, learner_queue_size = 19, _tick = 42614, _time = 1.654e+09, train_seconds = 1.9558e+04)
[2022-05-31 19:36:23,895][root][INFO] - Step 128949760 @ 6649.4 SPS. Inference batcher size: 145. Learner queue size: 21. Other stats: (step = 128949760, mean_episode_return = 268.92, mean_episode_step = 549.71, total_loss = 106.18, pg_loss = 26.688, baseline_loss = 86.105, entropy_loss = -6.613, learner_queue_size = 14, _tick = 42627, _time = 1.654e+09, train_seconds = 1.9563e+04)
[2022-05-31 19:36:28,898][root][INFO] - Step 128983040 @ 6651.3 SPS. Inference batcher size: 44. Learner queue size: 10. Other stats: (step = 128983040, mean_episode_return = 376.77, mean_episode_step = 702.9, total_loss = 348.17, pg_loss = 183.12, baseline_loss = 171.17, entropy_loss = -6.1144, learner_queue_size = 26, _tick = 42640, _time = 1.654e+09, train_seconds = 1.9568e+04)
[2022-05-31 19:36:33,908][root][INFO] - Step 129016320 @ 6642.4 SPS. Inference batcher size: 88. Learner queue size: 4. Other stats: (step = 129016320, mean_episode_return = 88.58, mean_episode_step = 688.95, total_loss = 28.86, pg_loss = -44.757, baseline_loss = 79.699, entropy_loss = -6.0817, learner_queue_size = 21, _tick = 42653, _time = 1.654e+09, train_seconds = 1.9573e+04)
[2022-05-31 19:36:38,914][root][INFO] - Step 129049600 @ 6648.0 SPS. Inference batcher size: 76. Learner queue size: 0. Other stats: (step = 129049600, mean_episode_return = 289.15, mean_episode_step = 701.51, total_loss = 129.7, pg_loss = 93.49, baseline_loss = 43.162, entropy_loss = -6.9471, learner_queue_size = 24, _tick = 42665, _time = 1.654e+09, train_seconds = 1.9578e+04)
[2022-05-31 19:36:43,918][root][INFO] - Step 129082880 @ 6651.1 SPS. Inference batcher size: 24. Learner queue size: 25. Other stats: (step = 129082880, mean_episode_return = 79.548, mean_episode_step = 585.9, total_loss = 113.35, pg_loss = 78.9, baseline_loss = 40.966, entropy_loss = -6.5205, learner_queue_size = 25, _tick = 42677, _time = 1.654e+09, train_seconds = 1.9583e+04)
[2022-05-31 19:36:48,922][root][INFO] - Step 129116160 @ 6650.6 SPS. Inference batcher size: 139. Learner queue size: 21. Other stats: (step = 129116160, mean_episode_return = None, mean_episode_step = 651.38, total_loss = 842.9, pg_loss = 492.15, baseline_loss = 356.69, entropy_loss = -5.9474, learner_queue_size = 17, _tick = 42688, _time = 1.654e+09, train_seconds = 1.9588e+04)
[2022-05-31 19:36:53,926][root][INFO] - Step 129149440 @ 6650.3 SPS. Inference batcher size: 61. Learner queue size: 22. Other stats: (step = 129149440, mean_episode_return = 195.7, mean_episode_step = 594.06, total_loss = 72.015, pg_loss = -14.666, baseline_loss = 92.38, entropy_loss = -5.6994, learner_queue_size = 18, _tick = 42700, _time = 1.654e+09, train_seconds = 1.9593e+04)
[2022-05-31 19:36:58,930][root][INFO] - Step 129180160 @ 6139.5 SPS. Inference batcher size: 109. Learner queue size: 16. Other stats: (step = 129180160, mean_episode_return = 301.57, mean_episode_step = 590.03, total_loss = 261.4, pg_loss = 32.262, baseline_loss = 234.35, entropy_loss = -5.217, learner_queue_size = 22, _tick = 42711, _time = 1.654e+09, train_seconds = 1.9598e+04)
[2022-05-31 19:37:03,934][root][INFO] - Step 129213440 @ 6650.6 SPS. Inference batcher size: 95. Learner queue size: 16. Other stats: (step = 129213440, mean_episode_return = 308.28, mean_episode_step = 703.69, total_loss = -114.73, pg_loss = -295.51, baseline_loss = 186.52, entropy_loss = -5.7338, learner_queue_size = 18, _tick = 42723, _time = 1.654e+09, train_seconds = 1.9603e+04)
[2022-05-31 19:37:08,938][root][INFO] - Step 129246720 @ 6650.7 SPS. Inference batcher size: 117. Learner queue size: 2. Other stats: (step = 129246720, mean_episode_return = 256.16, mean_episode_step = 774.09, total_loss = 73.879, pg_loss = -78.077, baseline_loss = 157.86, entropy_loss = -5.9004, learner_queue_size = 20, _tick = 42736, _time = 1.654e+09, train_seconds = 1.9608e+04)
[2022-05-31 19:37:13,942][root][INFO] - Step 129280000 @ 6650.7 SPS. Inference batcher size: 101. Learner queue size: 24. Other stats: (step = 129280000, mean_episode_return = 98.71, mean_episode_step = 779.05, total_loss = -146.08, pg_loss = -191.38, baseline_loss = 51.89, entropy_loss = -6.5901, learner_queue_size = 18, _tick = 42747, _time = 1.654e+09, train_seconds = 1.9613e+04)
[2022-05-31 19:37:18,949][root][INFO] - Step 129310720 @ 6135.2 SPS. Inference batcher size: 139. Learner queue size: 20. Other stats: (step = 129310720, mean_episode_return = 169.23, mean_episode_step = 623.95, total_loss = -125.98, pg_loss = -173.77, baseline_loss = 53.578, entropy_loss = -5.781, learner_queue_size = 25, _tick = 42757, _time = 1.654e+09, train_seconds = 1.9618e+04)
[2022-05-31 19:37:23,954][root][INFO] - Step 129344000 @ 6649.6 SPS. Inference batcher size: 141. Learner queue size: 18. Other stats: (step = 129344000, mean_episode_return = 124.62, mean_episode_step = 558.66, total_loss = 83.584, pg_loss = 21.746, baseline_loss = 67.625, entropy_loss = -5.787, learner_queue_size = 31, _tick = 42770, _time = 1.654e+09, train_seconds = 1.9623e+04)
[2022-05-31 19:37:28,958][root][INFO] - Step 129377280 @ 6650.8 SPS. Inference batcher size: 109. Learner queue size: 19. Other stats: (step = 129377280, mean_episode_return = None, mean_episode_step = 616.91, total_loss = 33.568, pg_loss = -13.627, baseline_loss = 53.15, entropy_loss = -5.9549, learner_queue_size = 15, _tick = 42781, _time = 1.654e+09, train_seconds = 1.9628e+04)
[2022-05-31 19:37:33,964][root][INFO] - Step 129410560 @ 6648.1 SPS. Inference batcher size: 84. Learner queue size: 3. Other stats: (step = 129410560, mean_episode_return = 123.32, mean_episode_step = 572.85, total_loss = -135.17, pg_loss = -145.2, baseline_loss = 16.18, entropy_loss = -6.1539, learner_queue_size = 26, _tick = 42792, _time = 1.654e+09, train_seconds = 1.9633e+04)
[2022-05-31 19:37:38,970][root][INFO] - Step 129443840 @ 6648.2 SPS. Inference batcher size: 127. Learner queue size: 7. Other stats: (step = 129443840, mean_episode_return = 270.51, mean_episode_step = 699.57, total_loss = -104.94, pg_loss = -196.05, baseline_loss = 97.233, entropy_loss = -6.123, learner_queue_size = 22, _tick = 42804, _time = 1.654e+09, train_seconds = 1.9638e+04)
[2022-05-31 19:37:43,974][root][INFO] - Step 129477120 @ 6650.3 SPS. Inference batcher size: 131. Learner queue size: 2. Other stats: (step = 129477120, mean_episode_return = None, mean_episode_step = 785.28, total_loss = 133.35, pg_loss = 109.96, baseline_loss = 30.164, entropy_loss = -6.7746, learner_queue_size = 18, _tick = 42814, _time = 1.654e+09, train_seconds = 1.9643e+04)
[2022-05-31 19:37:48,978][root][INFO] - Step 129510400 @ 6650.7 SPS. Inference batcher size: 108. Learner queue size: 29. Other stats: (step = 129510400, mean_episode_return = 260.56, mean_episode_step = 728.86, total_loss = 381.4, pg_loss = 292.9, baseline_loss = 95.27, entropy_loss = -6.7715, learner_queue_size = 19, _tick = 42825, _time = 1.654e+09, train_seconds = 1.9648e+04)
[2022-05-31 19:37:53,982][root][INFO] - Step 129541120 @ 6139.1 SPS. Inference batcher size: 55. Learner queue size: 19. Other stats: (step = 129541120, mean_episode_return = None, mean_episode_step = 700.81, total_loss = -37.567, pg_loss = -69.581, baseline_loss = 38.159, entropy_loss = -6.1445, learner_queue_size = 23, _tick = 42836, _time = 1.654e+09, train_seconds = 1.9653e+04)
[2022-05-31 19:37:58,986][root][INFO] - Step 129574400 @ 6650.5 SPS. Inference batcher size: 130. Learner queue size: 23. Other stats: (step = 129574400, mean_episode_return = 328.84, mean_episode_step = 794.47, total_loss = 195.13, pg_loss = 132.62, baseline_loss = 68.868, entropy_loss = -6.3562, learner_queue_size = 22, _tick = 42847, _time = 1.654e+09, train_seconds = 1.9658e+04)
[2022-05-31 19:38:03,990][root][INFO] - Step 129610240 @ 7162.4 SPS. Inference batcher size: 123. Learner queue size: 21. Other stats: (step = 129610240, mean_episode_return = 120.68, mean_episode_step = 824.21, total_loss = -1.6485, pg_loss = -65.662, baseline_loss = 70.401, entropy_loss = -6.388, learner_queue_size = 17, _tick = 42858, _time = 1.654e+09, train_seconds = 1.9663e+04)
[2022-05-31 19:38:08,996][root][INFO] - Step 129640960 @ 6136.5 SPS. Inference batcher size: 95. Learner queue size: 21. Other stats: (step = 129640960, mean_episode_return = 156.99, mean_episode_step = 761.58, total_loss = -19.635, pg_loss = -66.292, baseline_loss = 53.286, entropy_loss = -6.6284, learner_queue_size = 29, _tick = 42869, _time = 1.654e+09, train_seconds = 1.9668e+04)
[2022-05-31 19:38:14,002][root][INFO] - Step 129674240 @ 6647.8 SPS. Inference batcher size: 29. Learner queue size: 15. Other stats: (step = 129674240, mean_episode_return = 204.06, mean_episode_step = 779.19, total_loss = -74.952, pg_loss = -236.56, baseline_loss = 168.62, entropy_loss = -7.0113, learner_queue_size = 26, _tick = 42882, _time = 1.654e+09, train_seconds = 1.9673e+04)
[2022-05-31 19:38:19,008][root][INFO] - Step 129707520 @ 6648.0 SPS. Inference batcher size: 80. Learner queue size: 25. Other stats: (step = 129707520, mean_episode_return = 190.22, mean_episode_step = 805.33, total_loss = 84.834, pg_loss = -34.738, baseline_loss = 126.08, entropy_loss = -6.5071, learner_queue_size = 19, _tick = 42895, _time = 1.654e+09, train_seconds = 1.9678e+04)
[2022-05-31 19:38:24,014][root][INFO] - Step 129740800 @ 6648.1 SPS. Inference batcher size: 71. Learner queue size: 17. Other stats: (step = 129740800, mean_episode_return = 134.73, mean_episode_step = 722.37, total_loss = 39.42, pg_loss = 16.454, baseline_loss = 29.782, entropy_loss = -6.8156, learner_queue_size = 15, _tick = 42906, _time = 1.654e+09, train_seconds = 1.9683e+04)
[2022-05-31 19:38:29,018][root][INFO] - Step 129774080 @ 6650.9 SPS. Inference batcher size: 0. Learner queue size: 9. Other stats: (step = 129774080, mean_episode_return = 120.98, mean_episode_step = 832.72, total_loss = 209.84, pg_loss = 109.15, baseline_loss = 106.84, entropy_loss = -6.1509, learner_queue_size = 12, _tick = 42918, _time = 1.654e+09, train_seconds = 1.9688e+04)
[2022-05-31 19:38:34,022][root][INFO] - Step 129807360 @ 6650.4 SPS. Inference batcher size: 6. Learner queue size: 3. Other stats: (step = 129807360, mean_episode_return = None, mean_episode_step = 711.09, total_loss = -49.26, pg_loss = -100.97, baseline_loss = 57.787, entropy_loss = -6.078, learner_queue_size = 17, _tick = 42929, _time = 1.654e+09, train_seconds = 1.9693e+04)
[2022-05-31 19:38:39,030][root][INFO] - Step 129840640 @ 6645.8 SPS. Inference batcher size: 68. Learner queue size: 5. Other stats: (step = 129840640, mean_episode_return = 111.72, mean_episode_step = 732.34, total_loss = 138.92, pg_loss = 60.467, baseline_loss = 83.969, entropy_loss = -5.5202, learner_queue_size = 29, _tick = 42940, _time = 1.654e+09, train_seconds = 1.9698e+04)
[2022-05-31 19:38:44,036][root][INFO] - Step 129873920 @ 6647.9 SPS. Inference batcher size: 77. Learner queue size: 3. Other stats: (step = 129873920, mean_episode_return = 312.13, mean_episode_step = 815.54, total_loss = -88.34, pg_loss = -119.77, baseline_loss = 36.905, entropy_loss = -5.4779, learner_queue_size = 23, _tick = 42952, _time = 1.654e+09, train_seconds = 1.9703e+04)
[2022-05-31 19:38:49,042][root][INFO] - Step 129907200 @ 6648.1 SPS. Inference batcher size: 57. Learner queue size: 18. Other stats: (step = 129907200, mean_episode_return = 264.68, mean_episode_step = 677.16, total_loss = 851.81, pg_loss = 368.86, baseline_loss = 488.36, entropy_loss = -5.4101, learner_queue_size = 17, _tick = 42964, _time = 1.654e+09, train_seconds = 1.9708e+04)
[2022-05-31 19:38:54,046][root][INFO] - Step 129940480 @ 6650.7 SPS. Inference batcher size: 76. Learner queue size: 16. Other stats: (step = 129940480, mean_episode_return = 320.71, mean_episode_step = 660.02, total_loss = 111.92, pg_loss = -281.16, baseline_loss = 398.92, entropy_loss = -5.8339, learner_queue_size = 11, _tick = 42975, _time = 1.654e+09, train_seconds = 1.9713e+04)
[2022-05-31 19:38:59,050][root][INFO] - Step 129971200 @ 6139.0 SPS. Inference batcher size: 95. Learner queue size: 10. Other stats: (step = 129971200, mean_episode_return = 259.81, mean_episode_step = 720.05, total_loss = -295.55, pg_loss = -344.5, baseline_loss = 55.269, entropy_loss = -6.32, learner_queue_size = 17, _tick = 42985, _time = 1.654e+09, train_seconds = 1.9718e+04)
[2022-05-31 19:39:04,056][root][INFO] - Step 130004480 @ 6647.8 SPS. Inference batcher size: 33. Learner queue size: 8. Other stats: (step = 130004480, mean_episode_return = 500.28, mean_episode_step = 687.18, total_loss = -232.46, pg_loss = -275.11, baseline_loss = 48.275, entropy_loss = -5.6297, learner_queue_size = 16, _tick = 42996, _time = 1.654e+09, train_seconds = 1.9723e+04)
[2022-05-31 19:39:09,062][root][INFO] - Step 130037760 @ 6648.2 SPS. Inference batcher size: 31. Learner queue size: 8. Other stats: (step = 130037760, mean_episode_return = 253.61, mean_episode_step = 844.87, total_loss = 9.6982, pg_loss = -124.43, baseline_loss = 140.19, entropy_loss = -6.0631, learner_queue_size = 14, _tick = 43008, _time = 1.654e+09, train_seconds = 1.9728e+04)
[2022-05-31 19:39:14,066][root][INFO] - Step 130071040 @ 6650.7 SPS. Inference batcher size: 117. Learner queue size: 2. Other stats: (step = 130071040, mean_episode_return = 310.78, mean_episode_step = 838.11, total_loss = 45.284, pg_loss = 5.059, baseline_loss = 46.794, entropy_loss = -6.5689, learner_queue_size = 18, _tick = 43020, _time = 1.654e+09, train_seconds = 1.9733e+04)
[2022-05-31 19:39:19,070][root][INFO] - Step 130104320 @ 6650.7 SPS. Inference batcher size: 101. Learner queue size: 0. Other stats: (step = 130104320, mean_episode_return = 131.24, mean_episode_step = 786.09, total_loss = 282.42, pg_loss = 228.99, baseline_loss = 59.19, entropy_loss = -5.7516, learner_queue_size = 22, _tick = 43033, _time = 1.654e+09, train_seconds = 1.9738e+04)
[2022-05-31 19:39:24,074][root][INFO] - Step 130137600 @ 6650.8 SPS. Inference batcher size: 90. Learner queue size: 31. Other stats: (step = 130137600, mean_episode_return = 83.237, mean_episode_step = 589.73, total_loss = 26.365, pg_loss = -52.594, baseline_loss = 84.353, entropy_loss = -5.3938, learner_queue_size = 20, _tick = 43044, _time = 1.654e+09, train_seconds = 1.9743e+04)
[2022-05-31 19:39:29,080][root][INFO] - Step 130168320 @ 6136.3 SPS. Inference batcher size: 143. Learner queue size: 18. Other stats: (step = 130168320, mean_episode_return = 184.35, mean_episode_step = 578.53, total_loss = -91.019, pg_loss = -185.1, baseline_loss = 99.768, entropy_loss = -5.6849, learner_queue_size = 16, _tick = 43055, _time = 1.654e+09, train_seconds = 1.9748e+04)
[2022-05-31 19:39:34,086][root][INFO] - Step 130201600 @ 6648.3 SPS. Inference batcher size: 143. Learner queue size: 22. Other stats: (step = 130201600, mean_episode_return = 244.26, mean_episode_step = 721.92, total_loss = 419.9, pg_loss = 98.405, baseline_loss = 327.17, entropy_loss = -5.6811, learner_queue_size = 17, _tick = 43066, _time = 1.654e+09, train_seconds = 1.9753e+04)
[2022-05-31 19:39:39,092][root][INFO] - Step 130234880 @ 6648.0 SPS. Inference batcher size: 73. Learner queue size: 21. Other stats: (step = 130234880, mean_episode_return = None, mean_episode_step = 773.53, total_loss = -9.7955, pg_loss = -163.99, baseline_loss = 159.96, entropy_loss = -5.7632, learner_queue_size = 20, _tick = 43078, _time = 1.654e+09, train_seconds = 1.9758e+04)
[2022-05-31 19:39:44,098][root][INFO] - Step 130268160 @ 6648.0 SPS. Inference batcher size: 121. Learner queue size: 12. Other stats: (step = 130268160, mean_episode_return = 298.04, mean_episode_step = 655.58, total_loss = 334.1, pg_loss = 3.2574, baseline_loss = 336.54, entropy_loss = -5.6961, learner_queue_size = 21, _tick = 43090, _time = 1.654e+09, train_seconds = 1.9763e+04)
[2022-05-31 19:39:49,104][root][INFO] - Step 130301440 @ 6648.0 SPS. Inference batcher size: 0. Learner queue size: 19. Other stats: (step = 130301440, mean_episode_return = 156.45, mean_episode_step = 652.84, total_loss = -124.71, pg_loss = -208.92, baseline_loss = 90.071, entropy_loss = -5.8693, learner_queue_size = 18, _tick = 43101, _time = 1.654e+09, train_seconds = 1.9768e+04)
[2022-05-31 19:39:54,111][root][INFO] - Step 130334720 @ 6646.5 SPS. Inference batcher size: 115. Learner queue size: 19. Other stats: (step = 130334720, mean_episode_return = 243.2, mean_episode_step = 557.41, total_loss = -61.387, pg_loss = -154.84, baseline_loss = 98.881, entropy_loss = -5.4243, learner_queue_size = 18, _tick = 43113, _time = 1.654e+09, train_seconds = 1.9773e+04)
[2022-05-31 19:39:59,114][root][INFO] - Step 130368000 @ 6652.2 SPS. Inference batcher size: 85. Learner queue size: 15. Other stats: (step = 130368000, mean_episode_return = 284.41, mean_episode_step = 799.49, total_loss = -169.42, pg_loss = -235.46, baseline_loss = 72.301, entropy_loss = -6.265, learner_queue_size = 27, _tick = 43126, _time = 1.654e+09, train_seconds = 1.9778e+04)
[2022-05-31 19:40:04,120][root][INFO] - Step 130401280 @ 6648.0 SPS. Inference batcher size: 76. Learner queue size: 16. Other stats: (step = 130401280, mean_episode_return = 258.5, mean_episode_step = 601.35, total_loss = 146.75, pg_loss = 21.91, baseline_loss = 129.74, entropy_loss = -4.9054, learner_queue_size = 12, _tick = 43137, _time = 1.654e+09, train_seconds = 1.9783e+04)
[2022-05-31 19:40:09,126][root][INFO] - Step 130434560 @ 6648.0 SPS. Inference batcher size: 159. Learner queue size: 16. Other stats: (step = 130434560, mean_episode_return = 387.16, mean_episode_step = 499.5, total_loss = 282.87, pg_loss = 60.437, baseline_loss = 227.94, entropy_loss = -5.5062, learner_queue_size = 13, _tick = 43149, _time = 1.654e+09, train_seconds = 1.9788e+04)
[2022-05-31 19:40:14,132][root][INFO] - Step 130467840 @ 6647.9 SPS. Inference batcher size: 124. Learner queue size: 18. Other stats: (step = 130467840, mean_episode_return = 144.32, mean_episode_step = 593.41, total_loss = -68.196, pg_loss = -124.88, baseline_loss = 62.406, entropy_loss = -5.7199, learner_queue_size = 19, _tick = 43162, _time = 1.654e+09, train_seconds = 1.9793e+04)
[2022-05-31 19:40:19,138][root][INFO] - Step 130501120 @ 6648.0 SPS. Inference batcher size: 62. Learner queue size: 19. Other stats: (step = 130501120, mean_episode_return = 355.37, mean_episode_step = 705.19, total_loss = 205.47, pg_loss = 19.168, baseline_loss = 191.98, entropy_loss = -5.6837, learner_queue_size = 13, _tick = 43175, _time = 1.654e+09, train_seconds = 1.9798e+04)
[2022-05-31 19:40:24,143][root][INFO] - Step 130534400 @ 6649.4 SPS. Inference batcher size: 116. Learner queue size: 10. Other stats: (step = 130534400, mean_episode_return = 30.79, mean_episode_step = 587.02, total_loss = -14.104, pg_loss = -59.869, baseline_loss = 51.839, entropy_loss = -6.074, learner_queue_size = 13, _tick = 43186, _time = 1.654e+09, train_seconds = 1.9803e+04)
[2022-05-31 19:40:29,149][root][INFO] - Step 130567680 @ 6648.0 SPS. Inference batcher size: 120. Learner queue size: 11. Other stats: (step = 130567680, mean_episode_return = 112.53, mean_episode_step = 764.92, total_loss = -71.349, pg_loss = -121.2, baseline_loss = 56.579, entropy_loss = -6.7326, learner_queue_size = 13, _tick = 43197, _time = 1.654e+09, train_seconds = 1.9808e+04)
[2022-05-31 19:40:34,158][root][INFO] - Step 130600960 @ 6644.5 SPS. Inference batcher size: 174. Learner queue size: 1. Other stats: (step = 130600960, mean_episode_return = 297.11, mean_episode_step = 747.09, total_loss = -44.716, pg_loss = -115.62, baseline_loss = 76.456, entropy_loss = -5.5546, learner_queue_size = 18, _tick = 43210, _time = 1.654e+09, train_seconds = 1.9813e+04)
[2022-05-31 19:40:39,162][root][INFO] - Step 130634240 @ 6650.5 SPS. Inference batcher size: 116. Learner queue size: 1. Other stats: (step = 130634240, mean_episode_return = 246.85, mean_episode_step = 758.89, total_loss = 43.522, pg_loss = 7.5629, baseline_loss = 42.18, entropy_loss = -6.2203, learner_queue_size = 18, _tick = 43222, _time = 1.654e+09, train_seconds = 1.9818e+04)
[2022-05-31 19:40:44,166][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 19:40:44,236][root][INFO] - Step 130667520 @ 6650.6 SPS. Inference batcher size: 97. Learner queue size: 28. Other stats: (step = 130667520, mean_episode_return = 333.31, mean_episode_step = 660.19, total_loss = 699.2, pg_loss = 487.63, baseline_loss = 216.96, entropy_loss = -5.3894, learner_queue_size = 20, _tick = 43234, _time = 1.654e+09, train_seconds = 1.9823e+04)
[2022-05-31 19:40:49,238][root][INFO] - Step 130700800 @ 6561.6 SPS. Inference batcher size: 126. Learner queue size: 24. Other stats: (step = 130700800, mean_episode_return = 421.38, mean_episode_step = 790.44, total_loss = 258.52, pg_loss = 103.88, baseline_loss = 160.32, entropy_loss = -5.6813, learner_queue_size = 22, _tick = 43246, _time = 1.654e+09, train_seconds = 1.9828e+04)
[2022-05-31 19:40:54,242][root][INFO] - Step 130731520 @ 6139.0 SPS. Inference batcher size: 162. Learner queue size: 17. Other stats: (step = 130731520, mean_episode_return = None, mean_episode_step = 747.38, total_loss = -30.672, pg_loss = -80.565, baseline_loss = 55.903, entropy_loss = -6.0096, learner_queue_size = 21, _tick = 43256, _time = 1.654e+09, train_seconds = 1.9833e+04)
[2022-05-31 19:40:59,248][root][INFO] - Step 130764800 @ 6647.5 SPS. Inference batcher size: 123. Learner queue size: 23. Other stats: (step = 130764800, mean_episode_return = None, mean_episode_step = 787.53, total_loss = 291.72, pg_loss = 123.51, baseline_loss = 173.89, entropy_loss = -5.6768, learner_queue_size = 13, _tick = 43267, _time = 1.654e+09, train_seconds = 1.9838e+04)
[2022-05-31 19:41:04,254][root][INFO] - Step 130798080 @ 6648.0 SPS. Inference batcher size: 145. Learner queue size: 19. Other stats: (step = 130798080, mean_episode_return = 15.21, mean_episode_step = 720.65, total_loss = 35.263, pg_loss = -59.866, baseline_loss = 101.43, entropy_loss = -6.297, learner_queue_size = 11, _tick = 43279, _time = 1.654e+09, train_seconds = 1.9843e+04)
[2022-05-31 19:41:09,260][root][INFO] - Step 130831360 @ 6648.0 SPS. Inference batcher size: 160. Learner queue size: 15. Other stats: (step = 130831360, mean_episode_return = 148.81, mean_episode_step = 589.66, total_loss = 94.827, pg_loss = 5.9401, baseline_loss = 95.241, entropy_loss = -6.3541, learner_queue_size = 22, _tick = 43291, _time = 1.654e+09, train_seconds = 1.9848e+04)
[2022-05-31 19:41:14,266][root][INFO] - Step 130864640 @ 6648.0 SPS. Inference batcher size: 124. Learner queue size: 13. Other stats: (step = 130864640, mean_episode_return = 198.39, mean_episode_step = 821.72, total_loss = 325.75, pg_loss = 144.83, baseline_loss = 187.0, entropy_loss = -6.0811, learner_queue_size = 14, _tick = 43302, _time = 1.654e+09, train_seconds = 1.9853e+04)
[2022-05-31 19:41:19,270][root][INFO] - Step 130897920 @ 6651.4 SPS. Inference batcher size: 105. Learner queue size: 16. Other stats: (step = 130897920, mean_episode_return = 149.89, mean_episode_step = 568.63, total_loss = 234.21, pg_loss = 112.1, baseline_loss = 127.62, entropy_loss = -5.5194, learner_queue_size = 21, _tick = 43315, _time = 1.654e+09, train_seconds = 1.9858e+04)
[2022-05-31 19:41:24,274][root][INFO] - Step 130931200 @ 6650.7 SPS. Inference batcher size: 118. Learner queue size: 2. Other stats: (step = 130931200, mean_episode_return = 160.18, mean_episode_step = 711.23, total_loss = 323.94, pg_loss = 19.787, baseline_loss = 309.93, entropy_loss = -5.7825, learner_queue_size = 18, _tick = 43327, _time = 1.654e+09, train_seconds = 1.9863e+04)
[2022-05-31 19:41:29,278][root][INFO] - Step 130964480 @ 6650.7 SPS. Inference batcher size: 98. Learner queue size: 7. Other stats: (step = 130964480, mean_episode_return = None, mean_episode_step = 665.0, total_loss = -127.99, pg_loss = -167.88, baseline_loss = 45.794, entropy_loss = -5.9074, learner_queue_size = 24, _tick = 43339, _time = 1.654e+09, train_seconds = 1.9868e+04)
[2022-05-31 19:41:34,282][root][INFO] - Step 130997760 @ 6650.7 SPS. Inference batcher size: 99. Learner queue size: 7. Other stats: (step = 130997760, mean_episode_return = 174.81, mean_episode_step = 651.75, total_loss = 351.67, pg_loss = 211.4, baseline_loss = 146.2, entropy_loss = -5.925, learner_queue_size = 19, _tick = 43348, _time = 1.654e+09, train_seconds = 1.9873e+04)
[2022-05-31 19:41:39,286][root][INFO] - Step 131031040 @ 6650.7 SPS. Inference batcher size: 0. Learner queue size: 6. Other stats: (step = 131031040, mean_episode_return = 129.56, mean_episode_step = 659.87, total_loss = 146.82, pg_loss = 37.493, baseline_loss = 114.84, entropy_loss = -5.5135, learner_queue_size = 14, _tick = 43357, _time = 1.654e+09, train_seconds = 1.9878e+04)
[2022-05-31 19:41:44,294][root][INFO] - Step 131064320 @ 6645.4 SPS. Inference batcher size: 3. Learner queue size: 2. Other stats: (step = 131064320, mean_episode_return = 330.54, mean_episode_step = 527.89, total_loss = 250.43, pg_loss = 174.05, baseline_loss = 81.806, entropy_loss = -5.4284, learner_queue_size = 20, _tick = 43370, _time = 1.654e+09, train_seconds = 1.9883e+04)
[2022-05-31 19:41:49,298][root][INFO] - Step 131097600 @ 6650.6 SPS. Inference batcher size: 103. Learner queue size: 19. Other stats: (step = 131097600, mean_episode_return = 120.76, mean_episode_step = 755.13, total_loss = 12.35, pg_loss = -79.805, baseline_loss = 97.7, entropy_loss = -5.5449, learner_queue_size = 9, _tick = 43383, _time = 1.654e+09, train_seconds = 1.9888e+04)
[2022-05-31 19:41:54,302][root][INFO] - Step 131130880 @ 6650.7 SPS. Inference batcher size: 162. Learner queue size: 21. Other stats: (step = 131130880, mean_episode_return = 518.43, mean_episode_step = 593.08, total_loss = -55.466, pg_loss = -124.25, baseline_loss = 74.477, entropy_loss = -5.6978, learner_queue_size = 15, _tick = 43394, _time = 1.654e+09, train_seconds = 1.9893e+04)
[2022-05-31 19:41:59,307][root][INFO] - Step 131161600 @ 6137.3 SPS. Inference batcher size: 181. Learner queue size: 28. Other stats: (step = 131161600, mean_episode_return = 384.84, mean_episode_step = 606.0, total_loss = 402.5, pg_loss = 134.32, baseline_loss = 273.83, entropy_loss = -5.6532, learner_queue_size = 20, _tick = 43406, _time = 1.654e+09, train_seconds = 1.9898e+04)
[2022-05-31 19:42:04,310][root][INFO] - Step 131197440 @ 7164.4 SPS. Inference batcher size: 130. Learner queue size: 11. Other stats: (step = 131197440, mean_episode_return = 263.63, mean_episode_step = 558.87, total_loss = 468.2, pg_loss = 226.4, baseline_loss = 246.48, entropy_loss = -4.6786, learner_queue_size = 11, _tick = 43419, _time = 1.654e+09, train_seconds = 1.9903e+04)
[2022-05-31 19:42:09,314][root][INFO] - Step 131228160 @ 6139.1 SPS. Inference batcher size: 128. Learner queue size: 16. Other stats: (step = 131228160, mean_episode_return = 269.54, mean_episode_step = 601.43, total_loss = -171.22, pg_loss = -276.85, baseline_loss = 111.44, entropy_loss = -5.8077, learner_queue_size = 24, _tick = 43430, _time = 1.654e+09, train_seconds = 1.9908e+04)
[2022-05-31 19:42:14,318][root][INFO] - Step 131261440 @ 6650.6 SPS. Inference batcher size: 109. Learner queue size: 15. Other stats: (step = 131261440, mean_episode_return = 153.52, mean_episode_step = 586.99, total_loss = 673.67, pg_loss = 349.61, baseline_loss = 329.98, entropy_loss = -5.9178, learner_queue_size = 14, _tick = 43441, _time = 1.654e+09, train_seconds = 1.9913e+04)
[2022-05-31 19:42:19,324][root][INFO] - Step 131294720 @ 6648.0 SPS. Inference batcher size: 61. Learner queue size: 14. Other stats: (step = 131294720, mean_episode_return = 526.26, mean_episode_step = 722.06, total_loss = -20.376, pg_loss = -96.844, baseline_loss = 82.8, entropy_loss = -6.332, learner_queue_size = 13, _tick = 43452, _time = 1.654e+09, train_seconds = 1.9918e+04)
[2022-05-31 19:42:24,330][root][INFO] - Step 131328000 @ 6648.2 SPS. Inference batcher size: 143. Learner queue size: 19. Other stats: (step = 131328000, mean_episode_return = 452.63, mean_episode_step = 649.56, total_loss = -157.5, pg_loss = -182.27, baseline_loss = 31.498, entropy_loss = -6.7252, learner_queue_size = 29, _tick = 43465, _time = 1.654e+09, train_seconds = 1.9923e+04)
[2022-05-31 19:42:29,334][root][INFO] - Step 131361280 @ 6650.6 SPS. Inference batcher size: 127. Learner queue size: 16. Other stats: (step = 131361280, mean_episode_return = 303.69, mean_episode_step = 654.57, total_loss = 123.09, pg_loss = 86.942, baseline_loss = 42.202, entropy_loss = -6.054, learner_queue_size = 19, _tick = 43476, _time = 1.654e+09, train_seconds = 1.9928e+04)
[2022-05-31 19:42:34,340][root][INFO] - Step 131394560 @ 6647.9 SPS. Inference batcher size: 93. Learner queue size: 8. Other stats: (step = 131394560, mean_episode_return = 18.85, mean_episode_step = 746.49, total_loss = 60.805, pg_loss = -1.339, baseline_loss = 67.953, entropy_loss = -5.8085, learner_queue_size = 19, _tick = 43487, _time = 1.654e+09, train_seconds = 1.9933e+04)
[2022-05-31 19:42:39,346][root][INFO] - Step 131427840 @ 6647.7 SPS. Inference batcher size: 97. Learner queue size: 10. Other stats: (step = 131427840, mean_episode_return = 379.84, mean_episode_step = 604.34, total_loss = 76.99, pg_loss = 44.458, baseline_loss = 38.317, entropy_loss = -5.7854, learner_queue_size = 25, _tick = 43499, _time = 1.654e+09, train_seconds = 1.9938e+04)
[2022-05-31 19:42:44,351][root][INFO] - Step 131461120 @ 6650.3 SPS. Inference batcher size: 86. Learner queue size: 5. Other stats: (step = 131461120, mean_episode_return = 871.52, mean_episode_step = 677.58, total_loss = -66.491, pg_loss = -81.987, baseline_loss = 21.708, entropy_loss = -6.2115, learner_queue_size = 14, _tick = 43511, _time = 1.654e+09, train_seconds = 1.9943e+04)
[2022-05-31 19:42:49,354][root][INFO] - Step 131494400 @ 6651.4 SPS. Inference batcher size: 131. Learner queue size: 8. Other stats: (step = 131494400, mean_episode_return = 192.83, mean_episode_step = 557.38, total_loss = 88.038, pg_loss = 8.1134, baseline_loss = 85.851, entropy_loss = -5.9264, learner_queue_size = 28, _tick = 43523, _time = 1.654e+09, train_seconds = 1.9948e+04)
[2022-05-31 19:42:54,358][root][INFO] - Step 131527680 @ 6650.5 SPS. Inference batcher size: 126. Learner queue size: 19. Other stats: (step = 131527680, mean_episode_return = 316.57, mean_episode_step = 657.61, total_loss = 191.5, pg_loss = 134.95, baseline_loss = 62.546, entropy_loss = -6.0015, learner_queue_size = 18, _tick = 43534, _time = 1.654e+09, train_seconds = 1.9953e+04)
[2022-05-31 19:42:59,362][root][INFO] - Step 131558400 @ 6139.2 SPS. Inference batcher size: 92. Learner queue size: 19. Other stats: (step = 131558400, mean_episode_return = 250.91, mean_episode_step = 553.51, total_loss = -25.262, pg_loss = -73.691, baseline_loss = 54.236, entropy_loss = -5.8075, learner_queue_size = 20, _tick = 43545, _time = 1.654e+09, train_seconds = 1.9958e+04)
[2022-05-31 19:43:04,368][root][INFO] - Step 131591680 @ 6647.9 SPS. Inference batcher size: 88. Learner queue size: 16. Other stats: (step = 131591680, mean_episode_return = 146.11, mean_episode_step = 638.91, total_loss = 151.39, pg_loss = 98.194, baseline_loss = 59.248, entropy_loss = -6.056, learner_queue_size = 18, _tick = 43558, _time = 1.654e+09, train_seconds = 1.9963e+04)
[2022-05-31 19:43:09,374][root][INFO] - Step 131624960 @ 6648.6 SPS. Inference batcher size: 66. Learner queue size: 17. Other stats: (step = 131624960, mean_episode_return = 286.29, mean_episode_step = 616.32, total_loss = 365.28, pg_loss = 218.3, baseline_loss = 152.61, entropy_loss = -5.6328, learner_queue_size = 13, _tick = 43571, _time = 1.654e+09, train_seconds = 1.9968e+04)
[2022-05-31 19:43:14,378][root][INFO] - Step 131658240 @ 6650.1 SPS. Inference batcher size: 123. Learner queue size: 23. Other stats: (step = 131658240, mean_episode_return = 347.76, mean_episode_step = 689.81, total_loss = 171.65, pg_loss = 93.881, baseline_loss = 84.158, entropy_loss = -6.3865, learner_queue_size = 25, _tick = 43582, _time = 1.654e+09, train_seconds = 1.9973e+04)
[2022-05-31 19:43:19,384][root][INFO] - Step 131691520 @ 6647.8 SPS. Inference batcher size: 123. Learner queue size: 10. Other stats: (step = 131691520, mean_episode_return = 234.9, mean_episode_step = 746.53, total_loss = 70.065, pg_loss = 35.288, baseline_loss = 40.94, entropy_loss = -6.1621, learner_queue_size = 20, _tick = 43594, _time = 1.654e+09, train_seconds = 1.9978e+04)
[2022-05-31 19:43:24,390][root][INFO] - Step 131724800 @ 6648.3 SPS. Inference batcher size: 176. Learner queue size: 25. Other stats: (step = 131724800, mean_episode_return = 373.75, mean_episode_step = 678.02, total_loss = 38.521, pg_loss = -2.6604, baseline_loss = 47.163, entropy_loss = -5.9814, learner_queue_size = 12, _tick = 43606, _time = 1.654e+09, train_seconds = 1.9983e+04)
[2022-05-31 19:43:29,394][root][INFO] - Step 131758080 @ 6650.7 SPS. Inference batcher size: 115. Learner queue size: 18. Other stats: (step = 131758080, mean_episode_return = 194.04, mean_episode_step = 793.27, total_loss = -217.65, pg_loss = -407.0, baseline_loss = 195.36, entropy_loss = -6.0065, learner_queue_size = 28, _tick = 43618, _time = 1.654e+09, train_seconds = 1.9988e+04)
[2022-05-31 19:43:34,398][root][INFO] - Step 131791360 @ 6650.7 SPS. Inference batcher size: 96. Learner queue size: 6. Other stats: (step = 131791360, mean_episode_return = 306.28, mean_episode_step = 672.51, total_loss = 244.33, pg_loss = 157.76, baseline_loss = 91.979, entropy_loss = -5.4107, learner_queue_size = 15, _tick = 43630, _time = 1.654e+09, train_seconds = 1.9993e+04)
[2022-05-31 19:43:39,402][root][INFO] - Step 131824640 @ 6650.6 SPS. Inference batcher size: 50. Learner queue size: 1. Other stats: (step = 131824640, mean_episode_return = 309.07, mean_episode_step = 596.52, total_loss = 201.05, pg_loss = 53.892, baseline_loss = 152.71, entropy_loss = -5.5528, learner_queue_size = 31, _tick = 43643, _time = 1.654e+09, train_seconds = 1.9998e+04)
[2022-05-31 19:43:44,406][root][INFO] - Step 131857920 @ 6650.8 SPS. Inference batcher size: 82. Learner queue size: 22. Other stats: (step = 131857920, mean_episode_return = 480.07, mean_episode_step = 688.71, total_loss = -75.323, pg_loss = -182.57, baseline_loss = 112.81, entropy_loss = -5.5608, learner_queue_size = 18, _tick = 43656, _time = 1.654e+09, train_seconds = 2.0003e+04)
[2022-05-31 19:43:49,410][root][INFO] - Step 131891200 @ 6650.7 SPS. Inference batcher size: 81. Learner queue size: 24. Other stats: (step = 131891200, mean_episode_return = 205.23, mean_episode_step = 531.59, total_loss = 83.67, pg_loss = 12.758, baseline_loss = 76.759, entropy_loss = -5.8476, learner_queue_size = 20, _tick = 43669, _time = 1.654e+09, train_seconds = 2.0008e+04)
[2022-05-31 19:43:54,414][root][INFO] - Step 131924480 @ 6650.6 SPS. Inference batcher size: 129. Learner queue size: 29. Other stats: (step = 131924480, mean_episode_return = 288.95, mean_episode_step = 518.07, total_loss = -131.08, pg_loss = -204.87, baseline_loss = 79.956, entropy_loss = -6.1735, learner_queue_size = 16, _tick = 43682, _time = 1.654e+09, train_seconds = 2.0013e+04)
[2022-05-31 19:43:59,418][root][INFO] - Step 131957760 @ 6650.6 SPS. Inference batcher size: 103. Learner queue size: 24. Other stats: (step = 131957760, mean_episode_return = 231.68, mean_episode_step = 568.89, total_loss = 317.15, pg_loss = 204.9, baseline_loss = 118.62, entropy_loss = -6.3764, learner_queue_size = 7, _tick = 43693, _time = 1.654e+09, train_seconds = 2.0018e+04)
[2022-05-31 19:44:04,422][root][INFO] - Step 131991040 @ 6650.6 SPS. Inference batcher size: 91. Learner queue size: 3. Other stats: (step = 131991040, mean_episode_return = 326.55, mean_episode_step = 668.4, total_loss = -118.61, pg_loss = -147.07, baseline_loss = 35.037, entropy_loss = -6.576, learner_queue_size = 13, _tick = 43706, _time = 1.654e+09, train_seconds = 2.0023e+04)
[2022-05-31 19:44:09,426][root][INFO] - Step 132024320 @ 6650.8 SPS. Inference batcher size: 154. Learner queue size: 29. Other stats: (step = 132024320, mean_episode_return = 84.961, mean_episode_step = 733.51, total_loss = 85.168, pg_loss = 37.803, baseline_loss = 53.684, entropy_loss = -6.3185, learner_queue_size = 26, _tick = 43716, _time = 1.654e+09, train_seconds = 2.0028e+04)
[2022-05-31 19:44:14,430][root][INFO] - Step 132057600 @ 6650.7 SPS. Inference batcher size: 79. Learner queue size: 23. Other stats: (step = 132057600, mean_episode_return = 184.01, mean_episode_step = 625.72, total_loss = 646.08, pg_loss = 432.24, baseline_loss = 219.98, entropy_loss = -6.1429, learner_queue_size = 20, _tick = 43728, _time = 1.654e+09, train_seconds = 2.0033e+04)
[2022-05-31 19:44:19,434][root][INFO] - Step 132090880 @ 6650.7 SPS. Inference batcher size: 106. Learner queue size: 27. Other stats: (step = 132090880, mean_episode_return = 124.65, mean_episode_step = 608.97, total_loss = 126.97, pg_loss = 25.257, baseline_loss = 107.78, entropy_loss = -6.0612, learner_queue_size = 23, _tick = 43739, _time = 1.654e+09, train_seconds = 2.0038e+04)
[2022-05-31 19:44:24,438][root][INFO] - Step 132124160 @ 6650.8 SPS. Inference batcher size: 118. Learner queue size: 13. Other stats: (step = 132124160, mean_episode_return = 459.92, mean_episode_step = 788.75, total_loss = 68.396, pg_loss = 19.675, baseline_loss = 55.729, entropy_loss = -7.0081, learner_queue_size = 13, _tick = 43752, _time = 1.654e+09, train_seconds = 2.0043e+04)
[2022-05-31 19:44:29,442][root][INFO] - Step 132154880 @ 6138.8 SPS. Inference batcher size: 21. Learner queue size: 11. Other stats: (step = 132154880, mean_episode_return = 368.87, mean_episode_step = 638.71, total_loss = 129.29, pg_loss = 90.583, baseline_loss = 45.81, entropy_loss = -7.0983, learner_queue_size = 17, _tick = 43763, _time = 1.654e+09, train_seconds = 2.0048e+04)
[2022-05-31 19:44:34,446][root][INFO] - Step 132188160 @ 6650.8 SPS. Inference batcher size: 150. Learner queue size: 17. Other stats: (step = 132188160, mean_episode_return = None, mean_episode_step = 607.78, total_loss = 100.16, pg_loss = 48.864, baseline_loss = 57.339, entropy_loss = -6.0431, learner_queue_size = 25, _tick = 43774, _time = 1.654e+09, train_seconds = 2.0053e+04)
[2022-05-31 19:44:39,450][root][INFO] - Step 132221440 @ 6650.7 SPS. Inference batcher size: 41. Learner queue size: 6. Other stats: (step = 132221440, mean_episode_return = 214.87, mean_episode_step = 645.5, total_loss = 67.451, pg_loss = -18.787, baseline_loss = 92.229, entropy_loss = -5.9913, learner_queue_size = 16, _tick = 43786, _time = 1.654e+09, train_seconds = 2.0058e+04)
[2022-05-31 19:44:44,454][root][INFO] - Step 132254720 @ 6650.8 SPS. Inference batcher size: 92. Learner queue size: 31. Other stats: (step = 132254720, mean_episode_return = 292.97, mean_episode_step = 793.12, total_loss = 71.524, pg_loss = -5.2497, baseline_loss = 82.54, entropy_loss = -5.7661, learner_queue_size = 21, _tick = 43797, _time = 1.654e+09, train_seconds = 2.0063e+04)
[2022-05-31 19:44:49,458][root][INFO] - Step 132288000 @ 6650.7 SPS. Inference batcher size: 129. Learner queue size: 31. Other stats: (step = 132288000, mean_episode_return = 330.07, mean_episode_step = 601.69, total_loss = -320.79, pg_loss = -337.18, baseline_loss = 22.66, entropy_loss = -6.2777, learner_queue_size = 23, _tick = 43809, _time = 1.654e+09, train_seconds = 2.0068e+04)
[2022-05-31 19:44:54,462][root][INFO] - Step 132321280 @ 6650.6 SPS. Inference batcher size: 57. Learner queue size: 28. Other stats: (step = 132321280, mean_episode_return = 169.73, mean_episode_step = 733.39, total_loss = -153.26, pg_loss = -174.31, baseline_loss = 27.541, entropy_loss = -6.4909, learner_queue_size = 21, _tick = 43821, _time = 1.654e+09, train_seconds = 2.0073e+04)
[2022-05-31 19:44:59,466][root][INFO] - Step 132354560 @ 6650.2 SPS. Inference batcher size: 142. Learner queue size: 22. Other stats: (step = 132354560, mean_episode_return = 476.72, mean_episode_step = 729.93, total_loss = 149.41, pg_loss = 68.915, baseline_loss = 86.306, entropy_loss = -5.8141, learner_queue_size = 17, _tick = 43832, _time = 1.654e+09, train_seconds = 2.0078e+04)
[2022-05-31 19:45:04,473][root][INFO] - Step 132385280 @ 6136.3 SPS. Inference batcher size: 99. Learner queue size: 10. Other stats: (step = 132385280, mean_episode_return = 284.38, mean_episode_step = 684.51, total_loss = -1.6619, pg_loss = -179.22, baseline_loss = 183.27, entropy_loss = -5.7174, learner_queue_size = 20, _tick = 43844, _time = 1.654e+09, train_seconds = 2.0083e+04)
[2022-05-31 19:45:09,478][root][INFO] - Step 132418560 @ 6648.9 SPS. Inference batcher size: 164. Learner queue size: 10. Other stats: (step = 132418560, mean_episode_return = 305.04, mean_episode_step = 493.93, total_loss = 165.46, pg_loss = -2.6646, baseline_loss = 173.12, entropy_loss = -4.9915, learner_queue_size = 7, _tick = 43857, _time = 1.654e+09, train_seconds = 2.0088e+04)
[2022-05-31 19:45:14,484][root][INFO] - Step 132451840 @ 6647.9 SPS. Inference batcher size: 122. Learner queue size: 6. Other stats: (step = 132451840, mean_episode_return = 231.8, mean_episode_step = 623.65, total_loss = -29.817, pg_loss = -97.112, baseline_loss = 72.826, entropy_loss = -5.5317, learner_queue_size = 27, _tick = 43869, _time = 1.654e+09, train_seconds = 2.0093e+04)
[2022-05-31 19:45:19,490][root][INFO] - Step 132485120 @ 6648.0 SPS. Inference batcher size: 136. Learner queue size: 7. Other stats: (step = 132485120, mean_episode_return = 257.06, mean_episode_step = 564.91, total_loss = -43.961, pg_loss = -126.26, baseline_loss = 87.919, entropy_loss = -5.6192, learner_queue_size = 24, _tick = 43882, _time = 1.654e+09, train_seconds = 2.0098e+04)
[2022-05-31 19:45:24,496][root][INFO] - Step 132518400 @ 6648.0 SPS. Inference batcher size: 72. Learner queue size: 1. Other stats: (step = 132518400, mean_episode_return = 315.4, mean_episode_step = 516.92, total_loss = -157.29, pg_loss = -214.36, baseline_loss = 62.537, entropy_loss = -5.4648, learner_queue_size = 20, _tick = 43895, _time = 1.654e+09, train_seconds = 2.0103e+04)
[2022-05-31 19:45:29,503][root][INFO] - Step 132551680 @ 6647.1 SPS. Inference batcher size: 113. Learner queue size: 1. Other stats: (step = 132551680, mean_episode_return = None, mean_episode_step = 892.62, total_loss = -91.568, pg_loss = -95.52, baseline_loss = 10.604, entropy_loss = -6.6519, learner_queue_size = 12, _tick = 43903, _time = 1.654e+09, train_seconds = 2.0108e+04)
[2022-05-31 19:45:34,506][root][INFO] - Step 132584960 @ 6651.8 SPS. Inference batcher size: 146. Learner queue size: 6. Other stats: (step = 132584960, mean_episode_return = 57.88, mean_episode_step = 619.4, total_loss = -9.8628, pg_loss = -68.732, baseline_loss = 64.743, entropy_loss = -5.8743, learner_queue_size = 19, _tick = 43915, _time = 1.654e+09, train_seconds = 2.0113e+04)
[2022-05-31 19:45:39,510][root][INFO] - Step 132618240 @ 6650.7 SPS. Inference batcher size: 142. Learner queue size: 26. Other stats: (step = 132618240, mean_episode_return = 599.2, mean_episode_step = 749.81, total_loss = -0.51197, pg_loss = -72.245, baseline_loss = 77.108, entropy_loss = -5.3745, learner_queue_size = 18, _tick = 43927, _time = 1.654e+09, train_seconds = 2.0118e+04)
[2022-05-31 19:45:44,514][root][INFO] - Step 132651520 @ 6650.2 SPS. Inference batcher size: 43. Learner queue size: 25. Other stats: (step = 132651520, mean_episode_return = 288.69, mean_episode_step = 742.36, total_loss = 15.604, pg_loss = -69.1, baseline_loss = 90.183, entropy_loss = -5.4781, learner_queue_size = 21, _tick = 43940, _time = 1.654e+09, train_seconds = 2.0123e+04)
[2022-05-31 19:45:49,521][root][INFO] - Step 132682240 @ 6135.6 SPS. Inference batcher size: 75. Learner queue size: 16. Other stats: (step = 132682240, mean_episode_return = 250.12, mean_episode_step = 610.9, total_loss = 261.72, pg_loss = 181.24, baseline_loss = 85.975, entropy_loss = -5.4995, learner_queue_size = 25, _tick = 43952, _time = 1.654e+09, train_seconds = 2.0128e+04)
[2022-05-31 19:45:54,526][root][INFO] - Step 132715520 @ 6649.7 SPS. Inference batcher size: 24. Learner queue size: 7. Other stats: (step = 132715520, mean_episode_return = 223.73, mean_episode_step = 705.12, total_loss = 196.88, pg_loss = 49.888, baseline_loss = 152.58, entropy_loss = -5.5887, learner_queue_size = 18, _tick = 43965, _time = 1.654e+09, train_seconds = 2.0133e+04)
[2022-05-31 19:45:59,532][root][INFO] - Step 132748800 @ 6647.4 SPS. Inference batcher size: 58. Learner queue size: 6. Other stats: (step = 132748800, mean_episode_return = None, mean_episode_step = 528.44, total_loss = 265.56, pg_loss = 149.93, baseline_loss = 120.48, entropy_loss = -4.8552, learner_queue_size = 18, _tick = 43977, _time = 1.654e+09, train_seconds = 2.0138e+04)
[2022-05-31 19:46:04,538][root][INFO] - Step 132779520 @ 6137.0 SPS. Inference batcher size: 9. Learner queue size: 20. Other stats: (step = 132779520, mean_episode_return = 329.1, mean_episode_step = 620.39, total_loss = 247.32, pg_loss = -62.9, baseline_loss = 315.66, entropy_loss = -5.438, learner_queue_size = 14, _tick = 43987, _time = 1.654e+09, train_seconds = 2.0143e+04)
[2022-05-31 19:46:09,542][root][INFO] - Step 132815360 @ 7162.4 SPS. Inference batcher size: 88. Learner queue size: 3. Other stats: (step = 132815360, mean_episode_return = 315.65, mean_episode_step = 656.9, total_loss = 476.88, pg_loss = 143.42, baseline_loss = 338.75, entropy_loss = -5.2923, learner_queue_size = 26, _tick = 44000, _time = 1.654e+09, train_seconds = 2.0148e+04)
[2022-05-31 19:46:14,546][root][INFO] - Step 132848640 @ 6650.7 SPS. Inference batcher size: 146. Learner queue size: 24. Other stats: (step = 132848640, mean_episode_return = 196.89, mean_episode_step = 807.25, total_loss = -41.088, pg_loss = -139.05, baseline_loss = 103.22, entropy_loss = -5.2572, learner_queue_size = 17, _tick = 44012, _time = 1.654e+09, train_seconds = 2.0153e+04)
[2022-05-31 19:46:19,550][root][INFO] - Step 132881920 @ 6650.6 SPS. Inference batcher size: 143. Learner queue size: 13. Other stats: (step = 132881920, mean_episode_return = 321.01, mean_episode_step = 558.29, total_loss = 436.62, pg_loss = 212.74, baseline_loss = 228.68, entropy_loss = -4.7961, learner_queue_size = 6, _tick = 44023, _time = 1.654e+09, train_seconds = 2.0158e+04)
[2022-05-31 19:46:24,552][root][INFO] - Step 132912640 @ 6141.9 SPS. Inference batcher size: 126. Learner queue size: 16. Other stats: (step = 132912640, mean_episode_return = 261.52, mean_episode_step = 605.77, total_loss = -98.27, pg_loss = -198.47, baseline_loss = 105.79, entropy_loss = -5.5857, learner_queue_size = 23, _tick = 44034, _time = 1.654e+09, train_seconds = 2.0163e+04)
[2022-05-31 19:46:29,554][root][INFO] - Step 132945920 @ 6652.6 SPS. Inference batcher size: 28. Learner queue size: 5. Other stats: (step = 132945920, mean_episode_return = 358.26, mean_episode_step = 694.13, total_loss = 247.2, pg_loss = 164.15, baseline_loss = 88.825, entropy_loss = -5.78, learner_queue_size = 16, _tick = 44044, _time = 1.654e+09, train_seconds = 2.0168e+04)
[2022-05-31 19:46:34,561][root][INFO] - Step 132979200 @ 6647.4 SPS. Inference batcher size: 124. Learner queue size: 3. Other stats: (step = 132979200, mean_episode_return = 485.87, mean_episode_step = 635.7, total_loss = -5.2504, pg_loss = -46.958, baseline_loss = 47.646, entropy_loss = -5.9379, learner_queue_size = 20, _tick = 44056, _time = 1.654e+09, train_seconds = 2.0173e+04)
[2022-05-31 19:46:39,566][root][INFO] - Step 133012480 @ 6648.9 SPS. Inference batcher size: 116. Learner queue size: 29. Other stats: (step = 133012480, mean_episode_return = 247.14, mean_episode_step = 499.1, total_loss = 169.73, pg_loss = -12.93, baseline_loss = 188.19, entropy_loss = -5.5316, learner_queue_size = 20, _tick = 44069, _time = 1.654e+09, train_seconds = 2.0178e+04)
[2022-05-31 19:46:44,572][root][INFO] - Step 133045760 @ 6647.9 SPS. Inference batcher size: 102. Learner queue size: 1. Other stats: (step = 133045760, mean_episode_return = None, mean_episode_step = 654.59, total_loss = 308.73, pg_loss = 219.07, baseline_loss = 95.806, entropy_loss = -6.1492, learner_queue_size = 29, _tick = 44080, _time = 1.654e+09, train_seconds = 2.0183e+04)
[2022-05-31 19:46:49,574][root][INFO] - Step 133079040 @ 6653.5 SPS. Inference batcher size: 73. Learner queue size: 3. Other stats: (step = 133079040, mean_episode_return = 219.34, mean_episode_step = 569.36, total_loss = -4.9094, pg_loss = -28.098, baseline_loss = 29.391, entropy_loss = -6.2027, learner_queue_size = 23, _tick = 44093, _time = 1.654e+09, train_seconds = 2.0188e+04)
[2022-05-31 19:46:54,578][root][INFO] - Step 133112320 @ 6650.8 SPS. Inference batcher size: 140. Learner queue size: 0. Other stats: (step = 133112320, mean_episode_return = 375.62, mean_episode_step = 674.74, total_loss = -26.458, pg_loss = -60.112, baseline_loss = 39.816, entropy_loss = -6.1619, learner_queue_size = 22, _tick = 44105, _time = 1.654e+09, train_seconds = 2.0193e+04)
[2022-05-31 19:46:59,582][root][INFO] - Step 133145600 @ 6650.7 SPS. Inference batcher size: 77. Learner queue size: 18. Other stats: (step = 133145600, mean_episode_return = None, mean_episode_step = 636.69, total_loss = 100.62, pg_loss = 73.404, baseline_loss = 33.346, entropy_loss = -6.1331, learner_queue_size = 14, _tick = 44114, _time = 1.654e+09, train_seconds = 2.0198e+04)
[2022-05-31 19:47:04,588][root][INFO] - Step 133176320 @ 6136.3 SPS. Inference batcher size: 178. Learner queue size: 22. Other stats: (step = 133176320, mean_episode_return = 186.87, mean_episode_step = 694.3, total_loss = 248.43, pg_loss = 67.616, baseline_loss = 186.8, entropy_loss = -5.9837, learner_queue_size = 21, _tick = 44123, _time = 1.654e+09, train_seconds = 2.0203e+04)
[2022-05-31 19:47:09,594][root][INFO] - Step 133209600 @ 6648.3 SPS. Inference batcher size: 114. Learner queue size: 17. Other stats: (step = 133209600, mean_episode_return = 218.98, mean_episode_step = 661.79, total_loss = -69.253, pg_loss = -174.15, baseline_loss = 110.57, entropy_loss = -5.6747, learner_queue_size = 21, _tick = 44135, _time = 1.654e+09, train_seconds = 2.0208e+04)
[2022-05-31 19:47:14,598][root][INFO] - Step 133242880 @ 6650.8 SPS. Inference batcher size: 61. Learner queue size: 27. Other stats: (step = 133242880, mean_episode_return = 297.08, mean_episode_step = 803.56, total_loss = 40.762, pg_loss = -40.388, baseline_loss = 87.564, entropy_loss = -6.4147, learner_queue_size = 16, _tick = 44146, _time = 1.654e+09, train_seconds = 2.0213e+04)
[2022-05-31 19:47:19,602][root][INFO] - Step 133276160 @ 6650.5 SPS. Inference batcher size: 167. Learner queue size: 15. Other stats: (step = 133276160, mean_episode_return = 173.31, mean_episode_step = 726.22, total_loss = -42.037, pg_loss = -76.765, baseline_loss = 41.674, entropy_loss = -6.946, learner_queue_size = 28, _tick = 44157, _time = 1.654e+09, train_seconds = 2.0218e+04)
[2022-05-31 19:47:24,606][root][INFO] - Step 133309440 @ 6650.9 SPS. Inference batcher size: 65. Learner queue size: 11. Other stats: (step = 133309440, mean_episode_return = 275.46, mean_episode_step = 745.68, total_loss = 385.01, pg_loss = 248.53, baseline_loss = 143.18, entropy_loss = -6.6981, learner_queue_size = 22, _tick = 44170, _time = 1.654e+09, train_seconds = 2.0223e+04)
[2022-05-31 19:47:29,610][root][INFO] - Step 133342720 @ 6650.3 SPS. Inference batcher size: 87. Learner queue size: 6. Other stats: (step = 133342720, mean_episode_return = None, mean_episode_step = 548.34, total_loss = 662.71, pg_loss = 420.89, baseline_loss = 247.21, entropy_loss = -5.3881, learner_queue_size = 15, _tick = 44182, _time = 1.654e+09, train_seconds = 2.0228e+04)
[2022-05-31 19:47:34,614][root][INFO] - Step 133376000 @ 6651.0 SPS. Inference batcher size: 131. Learner queue size: 2. Other stats: (step = 133376000, mean_episode_return = 12.64, mean_episode_step = 648.26, total_loss = 52.331, pg_loss = -72.168, baseline_loss = 130.19, entropy_loss = -5.6878, learner_queue_size = 14, _tick = 44195, _time = 1.654e+09, train_seconds = 2.0233e+04)
[2022-05-31 19:47:39,618][root][INFO] - Step 133409280 @ 6650.6 SPS. Inference batcher size: 101. Learner queue size: 0. Other stats: (step = 133409280, mean_episode_return = 505.06, mean_episode_step = 641.72, total_loss = -177.37, pg_loss = -307.32, baseline_loss = 135.69, entropy_loss = -5.7421, learner_queue_size = 29, _tick = 44207, _time = 1.654e+09, train_seconds = 2.0238e+04)
[2022-05-31 19:47:44,622][root][INFO] - Step 133442560 @ 6650.8 SPS. Inference batcher size: 32. Learner queue size: 28. Other stats: (step = 133442560, mean_episode_return = 102.58, mean_episode_step = 549.53, total_loss = 138.35, pg_loss = -7.6071, baseline_loss = 151.7, entropy_loss = -5.7474, learner_queue_size = 22, _tick = 44219, _time = 1.654e+09, train_seconds = 2.0243e+04)
[2022-05-31 19:47:49,626][root][INFO] - Step 133475840 @ 6650.7 SPS. Inference batcher size: 173. Learner queue size: 22. Other stats: (step = 133475840, mean_episode_return = 329.96, mean_episode_step = 643.68, total_loss = 280.61, pg_loss = 74.635, baseline_loss = 211.55, entropy_loss = -5.5724, learner_queue_size = 19, _tick = 44231, _time = 1.654e+09, train_seconds = 2.0248e+04)
[2022-05-31 19:47:54,632][root][INFO] - Step 133506560 @ 6136.6 SPS. Inference batcher size: 94. Learner queue size: 17. Other stats: (step = 133506560, mean_episode_return = 184.91, mean_episode_step = 743.93, total_loss = -129.88, pg_loss = -238.45, baseline_loss = 115.21, entropy_loss = -6.6424, learner_queue_size = 22, _tick = 44241, _time = 1.654e+09, train_seconds = 2.0253e+04)
[2022-05-31 19:47:59,638][root][INFO] - Step 133539840 @ 6648.0 SPS. Inference batcher size: 84. Learner queue size: 20. Other stats: (step = 133539840, mean_episode_return = 458.93, mean_episode_step = 726.37, total_loss = 305.36, pg_loss = 208.18, baseline_loss = 103.32, entropy_loss = -6.1465, learner_queue_size = 19, _tick = 44251, _time = 1.654e+09, train_seconds = 2.0258e+04)
[2022-05-31 19:48:04,644][root][INFO] - Step 133573120 @ 6648.0 SPS. Inference batcher size: 153. Learner queue size: 19. Other stats: (step = 133573120, mean_episode_return = 129.51, mean_episode_step = 748.19, total_loss = 352.61, pg_loss = 221.76, baseline_loss = 136.77, entropy_loss = -5.917, learner_queue_size = 17, _tick = 44263, _time = 1.654e+09, train_seconds = 2.0263e+04)
[2022-05-31 19:48:09,650][root][INFO] - Step 133606400 @ 6648.1 SPS. Inference batcher size: 103. Learner queue size: 18. Other stats: (step = 133606400, mean_episode_return = 210.81, mean_episode_step = 639.98, total_loss = 116.2, pg_loss = -2.4126, baseline_loss = 124.32, entropy_loss = -5.7068, learner_queue_size = 17, _tick = 44276, _time = 1.654e+09, train_seconds = 2.0268e+04)
[2022-05-31 19:48:14,654][root][INFO] - Step 133639680 @ 6650.6 SPS. Inference batcher size: 64. Learner queue size: 12. Other stats: (step = 133639680, mean_episode_return = 360.57, mean_episode_step = 618.46, total_loss = -13.883, pg_loss = -109.84, baseline_loss = 101.57, entropy_loss = -5.6118, learner_queue_size = 20, _tick = 44288, _time = 1.654e+09, train_seconds = 2.0273e+04)
[2022-05-31 19:48:19,658][root][INFO] - Step 133672960 @ 6650.6 SPS. Inference batcher size: 134. Learner queue size: 8. Other stats: (step = 133672960, mean_episode_return = 666.86, mean_episode_step = 722.01, total_loss = -33.138, pg_loss = -74.13, baseline_loss = 47.067, entropy_loss = -6.0745, learner_queue_size = 21, _tick = 44301, _time = 1.654e+09, train_seconds = 2.0278e+04)
[2022-05-31 19:48:24,662][root][INFO] - Step 133706240 @ 6650.7 SPS. Inference batcher size: 103. Learner queue size: 2. Other stats: (step = 133706240, mean_episode_return = 527.54, mean_episode_step = 797.28, total_loss = -11.597, pg_loss = -46.603, baseline_loss = 41.549, entropy_loss = -6.5434, learner_queue_size = 22, _tick = 44312, _time = 1.654e+09, train_seconds = 2.0283e+04)
[2022-05-31 19:48:29,666][root][INFO] - Step 133739520 @ 6650.7 SPS. Inference batcher size: 84. Learner queue size: 27. Other stats: (step = 133739520, mean_episode_return = 286.01, mean_episode_step = 635.9, total_loss = 160.29, pg_loss = 44.159, baseline_loss = 122.3, entropy_loss = -6.1679, learner_queue_size = 16, _tick = 44325, _time = 1.654e+09, train_seconds = 2.0288e+04)
[2022-05-31 19:48:34,670][root][INFO] - Step 133772800 @ 6650.5 SPS. Inference batcher size: 69. Learner queue size: 23. Other stats: (step = 133772800, mean_episode_return = 187.24, mean_episode_step = 712.78, total_loss = -44.808, pg_loss = -152.65, baseline_loss = 114.17, entropy_loss = -6.3232, learner_queue_size = 22, _tick = 44337, _time = 1.654e+09, train_seconds = 2.0293e+04)
[2022-05-31 19:48:39,676][root][INFO] - Step 133803520 @ 6136.5 SPS. Inference batcher size: 138. Learner queue size: 22. Other stats: (step = 133803520, mean_episode_return = 380.15, mean_episode_step = 720.21, total_loss = 422.92, pg_loss = 196.45, baseline_loss = 232.73, entropy_loss = -6.2543, learner_queue_size = 23, _tick = 44346, _time = 1.654e+09, train_seconds = 2.0298e+04)
[2022-05-31 19:48:44,682][root][INFO] - Step 133836800 @ 6648.0 SPS. Inference batcher size: 78. Learner queue size: 18. Other stats: (step = 133836800, mean_episode_return = 70.54, mean_episode_step = 812.09, total_loss = 582.25, pg_loss = 357.48, baseline_loss = 230.76, entropy_loss = -5.993, learner_queue_size = 19, _tick = 44358, _time = 1.654e+09, train_seconds = 2.0303e+04)
[2022-05-31 19:48:49,686][root][INFO] - Step 133870080 @ 6650.9 SPS. Inference batcher size: 84. Learner queue size: 2. Other stats: (step = 133870080, mean_episode_return = 415.18, mean_episode_step = 799.47, total_loss = 23.972, pg_loss = -60.825, baseline_loss = 91.251, entropy_loss = -6.4533, learner_queue_size = 19, _tick = 44371, _time = 1.654e+09, train_seconds = 2.0308e+04)
[2022-05-31 19:48:54,691][root][INFO] - Step 133903360 @ 6650.0 SPS. Inference batcher size: 25. Learner queue size: 2. Other stats: (step = 133903360, mean_episode_return = 184.7, mean_episode_step = 701.72, total_loss = 6.9854, pg_loss = -33.85, baseline_loss = 47.216, entropy_loss = -6.38, learner_queue_size = 18, _tick = 44382, _time = 1.654e+09, train_seconds = 2.0313e+04)
[2022-05-31 19:48:59,699][root][INFO] - Step 133936640 @ 6645.6 SPS. Inference batcher size: 120. Learner queue size: 2. Other stats: (step = 133936640, mean_episode_return = 121.66, mean_episode_step = 820.35, total_loss = -65.016, pg_loss = -99.464, baseline_loss = 40.431, entropy_loss = -5.9829, learner_queue_size = 28, _tick = 44394, _time = 1.654e+09, train_seconds = 2.0318e+04)
[2022-05-31 19:49:04,702][root][INFO] - Step 133969920 @ 6651.1 SPS. Inference batcher size: 133. Learner queue size: 24. Other stats: (step = 133969920, mean_episode_return = 220.47, mean_episode_step = 782.08, total_loss = 113.41, pg_loss = -7.9931, baseline_loss = 127.43, entropy_loss = -6.0347, learner_queue_size = 21, _tick = 44404, _time = 1.654e+09, train_seconds = 2.0323e+04)
[2022-05-31 19:49:09,705][root][INFO] - Step 134000640 @ 6140.1 SPS. Inference batcher size: 136. Learner queue size: 11. Other stats: (step = 134000640, mean_episode_return = 323.46, mean_episode_step = 826.7, total_loss = -127.2, pg_loss = -151.35, baseline_loss = 29.884, entropy_loss = -5.7349, learner_queue_size = 20, _tick = 44416, _time = 1.654e+09, train_seconds = 2.0328e+04)
[2022-05-31 19:49:14,714][root][INFO] - Step 134033920 @ 6644.8 SPS. Inference batcher size: 120. Learner queue size: 12. Other stats: (step = 134033920, mean_episode_return = 251.01, mean_episode_step = 790.89, total_loss = 30.284, pg_loss = -15.298, baseline_loss = 51.661, entropy_loss = -6.0781, learner_queue_size = 15, _tick = 44429, _time = 1.654e+09, train_seconds = 2.0333e+04)
[2022-05-31 19:49:19,718][root][INFO] - Step 134067200 @ 6650.3 SPS. Inference batcher size: 160. Learner queue size: 13. Other stats: (step = 134067200, mean_episode_return = 173.52, mean_episode_step = 829.41, total_loss = 308.0, pg_loss = 210.78, baseline_loss = 104.26, entropy_loss = -7.0369, learner_queue_size = 20, _tick = 44439, _time = 1.654e+09, train_seconds = 2.0338e+04)
[2022-05-31 19:49:24,722][root][INFO] - Step 134100480 @ 6650.6 SPS. Inference batcher size: 130. Learner queue size: 8. Other stats: (step = 134100480, mean_episode_return = 124.36, mean_episode_step = 654.44, total_loss = 72.129, pg_loss = 25.633, baseline_loss = 53.099, entropy_loss = -6.6029, learner_queue_size = 26, _tick = 44450, _time = 1.654e+09, train_seconds = 2.0343e+04)
[2022-05-31 19:49:29,726][root][INFO] - Step 134133760 @ 6650.3 SPS. Inference batcher size: 113. Learner queue size: 6. Other stats: (step = 134133760, mean_episode_return = 196.55, mean_episode_step = 813.84, total_loss = -226.97, pg_loss = -285.26, baseline_loss = 64.954, entropy_loss = -6.6722, learner_queue_size = 14, _tick = 44462, _time = 1.654e+09, train_seconds = 2.0348e+04)
[2022-05-31 19:49:34,732][root][INFO] - Step 134167040 @ 6648.0 SPS. Inference batcher size: 126. Learner queue size: 12. Other stats: (step = 134167040, mean_episode_return = 393.84, mean_episode_step = 761.42, total_loss = 5.9854, pg_loss = -85.44, baseline_loss = 97.17, entropy_loss = -5.7445, learner_queue_size = 15, _tick = 44474, _time = 1.654e+09, train_seconds = 2.0353e+04)
[2022-05-31 19:49:39,738][root][INFO] - Step 134200320 @ 6648.5 SPS. Inference batcher size: 121. Learner queue size: 31. Other stats: (step = 134200320, mean_episode_return = 284.12, mean_episode_step = 799.68, total_loss = -395.85, pg_loss = -703.54, baseline_loss = 313.72, entropy_loss = -6.0365, learner_queue_size = 23, _tick = 44486, _time = 1.654e+09, train_seconds = 2.0358e+04)
[2022-05-31 19:49:44,742][root][INFO] - Step 134233600 @ 6650.6 SPS. Inference batcher size: 0. Learner queue size: 31. Other stats: (step = 134233600, mean_episode_return = 121.11, mean_episode_step = 607.83, total_loss = 290.32, pg_loss = 36.914, baseline_loss = 258.65, entropy_loss = -5.2399, learner_queue_size = 17, _tick = 44499, _time = 1.654e+09, train_seconds = 2.0363e+04)
[2022-05-31 19:49:49,747][root][INFO] - Step 134264320 @ 6138.6 SPS. Inference batcher size: 167. Learner queue size: 25. Other stats: (step = 134264320, mean_episode_return = 236.95, mean_episode_step = 681.44, total_loss = -30.356, pg_loss = -80.497, baseline_loss = 55.734, entropy_loss = -5.5928, learner_queue_size = 25, _tick = 44511, _time = 1.654e+09, train_seconds = 2.0368e+04)
[2022-05-31 19:49:54,753][root][INFO] - Step 134297600 @ 6647.6 SPS. Inference batcher size: 185. Learner queue size: 24. Other stats: (step = 134297600, mean_episode_return = 473.1, mean_episode_step = 835.09, total_loss = 56.151, pg_loss = -93.737, baseline_loss = 155.83, entropy_loss = -5.9459, learner_queue_size = 17, _tick = 44522, _time = 1.654e+09, train_seconds = 2.0373e+04)
[2022-05-31 19:49:59,759][root][INFO] - Step 134330880 @ 6648.1 SPS. Inference batcher size: 124. Learner queue size: 16. Other stats: (step = 134330880, mean_episode_return = 144.89, mean_episode_step = 810.64, total_loss = -38.452, pg_loss = -72.367, baseline_loss = 39.436, entropy_loss = -5.5207, learner_queue_size = 18, _tick = 44534, _time = 1.654e+09, train_seconds = 2.0378e+04)
[2022-05-31 19:50:04,762][root][INFO] - Step 134364160 @ 6651.7 SPS. Inference batcher size: 63. Learner queue size: 8. Other stats: (step = 134364160, mean_episode_return = 115.26, mean_episode_step = 653.96, total_loss = -53.73, pg_loss = -129.62, baseline_loss = 81.176, entropy_loss = -5.2861, learner_queue_size = 15, _tick = 44545, _time = 1.654e+09, train_seconds = 2.0383e+04)
[2022-05-31 19:50:09,766][root][INFO] - Step 134397440 @ 6650.5 SPS. Inference batcher size: 108. Learner queue size: 9. Other stats: (step = 134397440, mean_episode_return = 630.73, mean_episode_step = 744.86, total_loss = 46.838, pg_loss = -36.363, baseline_loss = 89.142, entropy_loss = -5.9413, learner_queue_size = 17, _tick = 44558, _time = 1.654e+09, train_seconds = 2.0388e+04)
[2022-05-31 19:50:14,770][root][INFO] - Step 134430720 @ 6650.9 SPS. Inference batcher size: 71. Learner queue size: 10. Other stats: (step = 134430720, mean_episode_return = 139.19, mean_episode_step = 518.1, total_loss = 42.648, pg_loss = -60.862, baseline_loss = 108.57, entropy_loss = -5.0582, learner_queue_size = 26, _tick = 44571, _time = 1.654e+09, train_seconds = 2.0394e+04)
[2022-05-31 19:50:19,776][root][INFO] - Step 134464000 @ 6647.5 SPS. Inference batcher size: 67. Learner queue size: 4. Other stats: (step = 134464000, mean_episode_return = 421.71, mean_episode_step = 650.3, total_loss = 374.02, pg_loss = 290.93, baseline_loss = 89.355, entropy_loss = -6.2701, learner_queue_size = 22, _tick = 44583, _time = 1.654e+09, train_seconds = 2.0398e+04)
[2022-05-31 19:50:24,782][root][INFO] - Step 134497280 @ 6648.4 SPS. Inference batcher size: 102. Learner queue size: 2. Other stats: (step = 134497280, mean_episode_return = 254.56, mean_episode_step = 638.41, total_loss = -88.177, pg_loss = -116.89, baseline_loss = 35.593, entropy_loss = -6.8814, learner_queue_size = 16, _tick = 44595, _time = 1.654e+09, train_seconds = 2.0404e+04)
[2022-05-31 19:50:29,786][root][INFO] - Step 134530560 @ 6650.7 SPS. Inference batcher size: 40. Learner queue size: 23. Other stats: (step = 134530560, mean_episode_return = 374.05, mean_episode_step = 659.89, total_loss = -30.599, pg_loss = -45.383, baseline_loss = 21.427, entropy_loss = -6.6425, learner_queue_size = 20, _tick = 44606, _time = 1.654e+09, train_seconds = 2.0408e+04)
[2022-05-31 19:50:34,790][root][INFO] - Step 134563840 @ 6650.7 SPS. Inference batcher size: 109. Learner queue size: 27. Other stats: (step = 134563840, mean_episode_return = 359.81, mean_episode_step = 563.32, total_loss = 62.745, pg_loss = -36.234, baseline_loss = 104.74, entropy_loss = -5.7585, learner_queue_size = 16, _tick = 44617, _time = 1.654e+09, train_seconds = 2.0414e+04)
[2022-05-31 19:50:39,796][root][INFO] - Step 134594560 @ 6136.2 SPS. Inference batcher size: 145. Learner queue size: 25. Other stats: (step = 134594560, mean_episode_return = None, mean_episode_step = 753.59, total_loss = 223.11, pg_loss = 132.41, baseline_loss = 96.247, entropy_loss = -5.5442, learner_queue_size = 17, _tick = 44628, _time = 1.654e+09, train_seconds = 2.0418e+04)
[2022-05-31 19:50:44,802][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 19:50:44,966][root][INFO] - Step 134627840 @ 6648.0 SPS. Inference batcher size: 152. Learner queue size: 23. Other stats: (step = 134630400, mean_episode_return = 232.34, mean_episode_step = 660.63, total_loss = -75.432, pg_loss = -103.62, baseline_loss = 33.46, entropy_loss = -5.2734, learner_queue_size = 23, _tick = 44641, _time = 1.654e+09, train_seconds = 2.0424e+04)
[2022-05-31 19:50:49,970][root][INFO] - Step 134661120 @ 6440.0 SPS. Inference batcher size: 129. Learner queue size: 22. Other stats: (step = 134661120, mean_episode_return = 129.08, mean_episode_step = 628.03, total_loss = 20.497, pg_loss = -50.987, baseline_loss = 76.565, entropy_loss = -5.0808, learner_queue_size = 18, _tick = 44652, _time = 1.654e+09, train_seconds = 2.0429e+04)
[2022-05-31 19:50:54,974][root][INFO] - Step 134694400 @ 6650.7 SPS. Inference batcher size: 17. Learner queue size: 10. Other stats: (step = 134694400, mean_episode_return = 192.4, mean_episode_step = 561.46, total_loss = 160.98, pg_loss = 86.073, baseline_loss = 80.395, entropy_loss = -5.4917, learner_queue_size = 11, _tick = 44665, _time = 1.654e+09, train_seconds = 2.0434e+04)
[2022-05-31 19:50:59,978][root][INFO] - Step 134727680 @ 6650.7 SPS. Inference batcher size: 153. Learner queue size: 16. Other stats: (step = 134727680, mean_episode_return = 362.06, mean_episode_step = 624.5, total_loss = 142.54, pg_loss = 71.288, baseline_loss = 77.025, entropy_loss = -5.7733, learner_queue_size = 19, _tick = 44677, _time = 1.654e+09, train_seconds = 2.0439e+04)
[2022-05-31 19:51:04,982][root][INFO] - Step 134760960 @ 6650.7 SPS. Inference batcher size: 140. Learner queue size: 3. Other stats: (step = 134760960, mean_episode_return = 311.75, mean_episode_step = 665.96, total_loss = 379.14, pg_loss = 267.94, baseline_loss = 117.29, entropy_loss = -6.0837, learner_queue_size = 24, _tick = 44689, _time = 1.654e+09, train_seconds = 2.0444e+04)
[2022-05-31 19:51:09,987][root][INFO] - Step 134794240 @ 6648.6 SPS. Inference batcher size: 104. Learner queue size: 2. Other stats: (step = 134794240, mean_episode_return = 152.96, mean_episode_step = 622.3, total_loss = 317.84, pg_loss = 157.98, baseline_loss = 165.49, entropy_loss = -5.6208, learner_queue_size = 14, _tick = 44700, _time = 1.654e+09, train_seconds = 2.0449e+04)
[2022-05-31 19:51:14,990][root][INFO] - Step 134827520 @ 6652.7 SPS. Inference batcher size: 97. Learner queue size: 26. Other stats: (step = 134827520, mean_episode_return = 195.43, mean_episode_step = 611.75, total_loss = -19.82, pg_loss = -135.15, baseline_loss = 120.66, entropy_loss = -5.3305, learner_queue_size = 12, _tick = 44712, _time = 1.654e+09, train_seconds = 2.0454e+04)
[2022-05-31 19:51:19,996][root][INFO] - Step 134858240 @ 6136.1 SPS. Inference batcher size: 115. Learner queue size: 17. Other stats: (step = 134858240, mean_episode_return = 338.11, mean_episode_step = 551.94, total_loss = 275.63, pg_loss = 31.48, baseline_loss = 249.02, entropy_loss = -4.8687, learner_queue_size = 15, _tick = 44724, _time = 1.654e+09, train_seconds = 2.0459e+04)
[2022-05-31 19:51:25,002][root][INFO] - Step 134891520 @ 6648.6 SPS. Inference batcher size: 52. Learner queue size: 17. Other stats: (step = 134891520, mean_episode_return = 300.35, mean_episode_step = 466.77, total_loss = -136.92, pg_loss = -318.35, baseline_loss = 186.65, entropy_loss = -5.2191, learner_queue_size = 10, _tick = 44736, _time = 1.654e+09, train_seconds = 2.0464e+04)
[2022-05-31 19:51:30,009][root][INFO] - Step 134924800 @ 6647.2 SPS. Inference batcher size: 127. Learner queue size: 11. Other stats: (step = 134924800, mean_episode_return = 273.36, mean_episode_step = 865.08, total_loss = -18.673, pg_loss = -67.694, baseline_loss = 55.296, entropy_loss = -6.2751, learner_queue_size = 30, _tick = 44748, _time = 1.654e+09, train_seconds = 2.0469e+04)
[2022-05-31 19:51:35,015][root][INFO] - Step 134958080 @ 6647.9 SPS. Inference batcher size: 150. Learner queue size: 18. Other stats: (step = 134958080, mean_episode_return = 251.44, mean_episode_step = 474.63, total_loss = 450.84, pg_loss = 301.08, baseline_loss = 155.87, entropy_loss = -6.1091, learner_queue_size = 21, _tick = 44761, _time = 1.654e+09, train_seconds = 2.0474e+04)
[2022-05-31 19:51:40,018][root][INFO] - Step 134991360 @ 6651.5 SPS. Inference batcher size: 118. Learner queue size: 15. Other stats: (step = 134991360, mean_episode_return = 124.38, mean_episode_step = 654.93, total_loss = 37.326, pg_loss = -2.8135, baseline_loss = 46.478, entropy_loss = -6.3386, learner_queue_size = 25, _tick = 44773, _time = 1.654e+09, train_seconds = 2.0479e+04)
[2022-05-31 19:51:45,022][root][INFO] - Step 135024640 @ 6650.6 SPS. Inference batcher size: 16. Learner queue size: 4. Other stats: (step = 135024640, mean_episode_return = 156.78, mean_episode_step = 874.88, total_loss = 482.45, pg_loss = 338.2, baseline_loss = 149.97, entropy_loss = -5.7214, learner_queue_size = 20, _tick = 44784, _time = 1.654e+09, train_seconds = 2.0484e+04)
[2022-05-31 19:51:50,026][root][INFO] - Step 135057920 @ 6650.9 SPS. Inference batcher size: 80. Learner queue size: 4. Other stats: (step = 135057920, mean_episode_return = 305.17, mean_episode_step = 620.18, total_loss = -28.381, pg_loss = -108.25, baseline_loss = 85.535, entropy_loss = -5.6675, learner_queue_size = 17, _tick = 44797, _time = 1.654e+09, train_seconds = 2.0489e+04)
[2022-05-31 19:51:55,030][root][INFO] - Step 135091200 @ 6650.7 SPS. Inference batcher size: 96. Learner queue size: 2. Other stats: (step = 135091200, mean_episode_return = 324.8, mean_episode_step = 561.05, total_loss = 50.704, pg_loss = -53.774, baseline_loss = 110.37, entropy_loss = -5.8915, learner_queue_size = 10, _tick = 44808, _time = 1.654e+09, train_seconds = 2.0494e+04)
[2022-05-31 19:52:00,035][root][INFO] - Step 135121920 @ 6137.9 SPS. Inference batcher size: 116. Learner queue size: 11. Other stats: (step = 135121920, mean_episode_return = 236.28, mean_episode_step = 602.55, total_loss = 1007.1, pg_loss = 550.09, baseline_loss = 463.12, entropy_loss = -6.1057, learner_queue_size = 19, _tick = 44820, _time = 1.654e+09, train_seconds = 2.0499e+04)
[2022-05-31 19:52:05,042][root][INFO] - Step 135155200 @ 6647.2 SPS. Inference batcher size: 125. Learner queue size: 12. Other stats: (step = 135155200, mean_episode_return = None, mean_episode_step = 461.41, total_loss = 615.36, pg_loss = 240.41, baseline_loss = 380.26, entropy_loss = -5.3078, learner_queue_size = 18, _tick = 44831, _time = 1.654e+09, train_seconds = 2.0504e+04)
[2022-05-31 19:52:10,046][root][INFO] - Step 135188480 @ 6650.0 SPS. Inference batcher size: 146. Learner queue size: 16. Other stats: (step = 135188480, mean_episode_return = None, mean_episode_step = 913.16, total_loss = -57.403, pg_loss = -108.83, baseline_loss = 57.694, entropy_loss = -6.2633, learner_queue_size = 20, _tick = 44842, _time = 1.654e+09, train_seconds = 2.0509e+04)
[2022-05-31 19:52:15,050][root][INFO] - Step 135221760 @ 6650.6 SPS. Inference batcher size: 26. Learner queue size: 0. Other stats: (step = 135221760, mean_episode_return = 398.21, mean_episode_step = 631.65, total_loss = 94.584, pg_loss = -20.024, baseline_loss = 119.89, entropy_loss = -5.279, learner_queue_size = 25, _tick = 44855, _time = 1.654e+09, train_seconds = 2.0514e+04)
[2022-05-31 19:52:20,057][root][INFO] - Step 135255040 @ 6647.3 SPS. Inference batcher size: 73. Learner queue size: 1. Other stats: (step = 135255040, mean_episode_return = 168.35, mean_episode_step = 603.11, total_loss = 368.56, pg_loss = 266.02, baseline_loss = 108.16, entropy_loss = -5.6174, learner_queue_size = 15, _tick = 44868, _time = 1.654e+09, train_seconds = 2.0519e+04)
[2022-05-31 19:52:25,062][root][INFO] - Step 135288320 @ 6648.9 SPS. Inference batcher size: 138. Learner queue size: 31. Other stats: (step = 135288320, mean_episode_return = 112.13, mean_episode_step = 651.49, total_loss = 303.8, pg_loss = 143.02, baseline_loss = 166.14, entropy_loss = -5.3669, learner_queue_size = 16, _tick = 44879, _time = 1.654e+09, train_seconds = 2.0524e+04)
[2022-05-31 19:52:30,066][root][INFO] - Step 135321600 @ 6650.7 SPS. Inference batcher size: 145. Learner queue size: 30. Other stats: (step = 135321600, mean_episode_return = 550.7, mean_episode_step = 758.71, total_loss = 32.538, pg_loss = -285.57, baseline_loss = 323.65, entropy_loss = -5.5385, learner_queue_size = 17, _tick = 44892, _time = 1.654e+09, train_seconds = 2.0529e+04)
[2022-05-31 19:52:35,070][root][INFO] - Step 135354880 @ 6650.9 SPS. Inference batcher size: 114. Learner queue size: 25. Other stats: (step = 135354880, mean_episode_return = 164.18, mean_episode_step = 772.04, total_loss = 316.42, pg_loss = 140.29, baseline_loss = 182.16, entropy_loss = -6.0334, learner_queue_size = 17, _tick = 44905, _time = 1.654e+09, train_seconds = 2.0534e+04)
[2022-05-31 19:52:40,073][root][INFO] - Step 135385600 @ 6139.7 SPS. Inference batcher size: 93. Learner queue size: 13. Other stats: (step = 135385600, mean_episode_return = 322.61, mean_episode_step = 556.67, total_loss = -143.51, pg_loss = -380.22, baseline_loss = 242.48, entropy_loss = -5.7653, learner_queue_size = 23, _tick = 44916, _time = 1.654e+09, train_seconds = 2.0539e+04)
[2022-05-31 19:52:45,079][root][INFO] - Step 135418880 @ 6647.9 SPS. Inference batcher size: 59. Learner queue size: 4. Other stats: (step = 135418880, mean_episode_return = 236.29, mean_episode_step = 543.66, total_loss = 126.7, pg_loss = -38.494, baseline_loss = 171.49, entropy_loss = -6.294, learner_queue_size = 17, _tick = 44929, _time = 1.654e+09, train_seconds = 2.0544e+04)
[2022-05-31 19:52:50,086][root][INFO] - Step 135452160 @ 6647.9 SPS. Inference batcher size: 150. Learner queue size: 4. Other stats: (step = 135452160, mean_episode_return = 296.15, mean_episode_step = 597.66, total_loss = 108.53, pg_loss = -7.0386, baseline_loss = 121.79, entropy_loss = -6.2215, learner_queue_size = 20, _tick = 44941, _time = 1.654e+09, train_seconds = 2.0549e+04)
[2022-05-31 19:52:55,090][root][INFO] - Step 135485440 @ 6650.1 SPS. Inference batcher size: 34. Learner queue size: 29. Other stats: (step = 135485440, mean_episode_return = 225.51, mean_episode_step = 590.74, total_loss = 469.84, pg_loss = 250.51, baseline_loss = 225.53, entropy_loss = -6.1942, learner_queue_size = 17, _tick = 44954, _time = 1.654e+09, train_seconds = 2.0554e+04)
[2022-05-31 19:53:00,096][root][INFO] - Step 135516160 @ 6136.1 SPS. Inference batcher size: 124. Learner queue size: 16. Other stats: (step = 135516160, mean_episode_return = 497.28, mean_episode_step = 644.77, total_loss = 48.737, pg_loss = 34.576, baseline_loss = 20.563, entropy_loss = -6.4023, learner_queue_size = 13, _tick = 44965, _time = 1.654e+09, train_seconds = 2.0559e+04)
[2022-05-31 19:53:05,102][root][INFO] - Step 135549440 @ 6648.6 SPS. Inference batcher size: 159. Learner queue size: 19. Other stats: (step = 135549440, mean_episode_return = 407.2, mean_episode_step = 598.07, total_loss = -10.645, pg_loss = -37.416, baseline_loss = 32.431, entropy_loss = -5.6602, learner_queue_size = 9, _tick = 44976, _time = 1.654e+09, train_seconds = 2.0564e+04)
[2022-05-31 19:53:10,108][root][INFO] - Step 135582720 @ 6647.7 SPS. Inference batcher size: 90. Learner queue size: 12. Other stats: (step = 135582720, mean_episode_return = None, mean_episode_step = 558.12, total_loss = -204.93, pg_loss = -212.7, baseline_loss = 14.257, entropy_loss = -6.4878, learner_queue_size = 25, _tick = 44987, _time = 1.654e+09, train_seconds = 2.0569e+04)
[2022-05-31 19:53:15,114][root][INFO] - Step 135616000 @ 6648.3 SPS. Inference batcher size: 62. Learner queue size: 18. Other stats: (step = 135616000, mean_episode_return = 241.42, mean_episode_step = 698.44, total_loss = 258.99, pg_loss = 150.28, baseline_loss = 114.71, entropy_loss = -6.0091, learner_queue_size = 24, _tick = 44998, _time = 1.654e+09, train_seconds = 2.0574e+04)
[2022-05-31 19:53:20,120][root][INFO] - Step 135649280 @ 6647.9 SPS. Inference batcher size: 59. Learner queue size: 10. Other stats: (step = 135649280, mean_episode_return = 340.14, mean_episode_step = 569.03, total_loss = 354.97, pg_loss = 129.59, baseline_loss = 230.86, entropy_loss = -5.4842, learner_queue_size = 21, _tick = 45009, _time = 1.654e+09, train_seconds = 2.0579e+04)
[2022-05-31 19:53:25,126][root][INFO] - Step 135682560 @ 6648.1 SPS. Inference batcher size: 24. Learner queue size: 15. Other stats: (step = 135682560, mean_episode_return = 393.98, mean_episode_step = 711.45, total_loss = 43.764, pg_loss = -181.03, baseline_loss = 230.8, entropy_loss = -6.0087, learner_queue_size = 14, _tick = 45020, _time = 1.654e+09, train_seconds = 2.0584e+04)
[2022-05-31 19:53:30,130][root][INFO] - Step 135715840 @ 6650.6 SPS. Inference batcher size: 143. Learner queue size: 15. Other stats: (step = 135715840, mean_episode_return = 177.61, mean_episode_step = 618.0, total_loss = 19.872, pg_loss = -85.652, baseline_loss = 111.31, entropy_loss = -5.7887, learner_queue_size = 30, _tick = 45032, _time = 1.654e+09, train_seconds = 2.0589e+04)
[2022-05-31 19:53:35,136][root][INFO] - Step 135749120 @ 6648.0 SPS. Inference batcher size: 142. Learner queue size: 10. Other stats: (step = 135749120, mean_episode_return = 392.02, mean_episode_step = 612.67, total_loss = 146.88, pg_loss = 35.191, baseline_loss = 117.58, entropy_loss = -5.8876, learner_queue_size = 21, _tick = 45044, _time = 1.654e+09, train_seconds = 2.0594e+04)
[2022-05-31 19:53:40,142][root][INFO] - Step 135782400 @ 6648.1 SPS. Inference batcher size: 106. Learner queue size: 5. Other stats: (step = 135782400, mean_episode_return = 143.17, mean_episode_step = 729.17, total_loss = 34.375, pg_loss = -31.99, baseline_loss = 72.824, entropy_loss = -6.459, learner_queue_size = 16, _tick = 45056, _time = 1.654e+09, train_seconds = 2.0599e+04)
[2022-05-31 19:53:45,146][root][INFO] - Step 135815680 @ 6650.7 SPS. Inference batcher size: 117. Learner queue size: 27. Other stats: (step = 135815680, mean_episode_return = 213.28, mean_episode_step = 709.41, total_loss = 26.653, pg_loss = -66.702, baseline_loss = 99.113, entropy_loss = -5.758, learner_queue_size = 8, _tick = 45068, _time = 1.654e+09, train_seconds = 2.0604e+04)
[2022-05-31 19:53:50,151][root][INFO] - Step 135848960 @ 6649.1 SPS. Inference batcher size: 68. Learner queue size: 24. Other stats: (step = 135848960, mean_episode_return = 122.13, mean_episode_step = 713.19, total_loss = 38.785, pg_loss = -5.0768, baseline_loss = 50.271, entropy_loss = -6.4101, learner_queue_size = 16, _tick = 45080, _time = 1.654e+09, train_seconds = 2.0609e+04)
[2022-05-31 19:53:55,157][root][INFO] - Step 135882240 @ 6647.5 SPS. Inference batcher size: 80. Learner queue size: 2. Other stats: (step = 135882240, mean_episode_return = None, mean_episode_step = 668.94, total_loss = 192.6, pg_loss = 107.35, baseline_loss = 91.212, entropy_loss = -5.9555, learner_queue_size = 22, _tick = 45091, _time = 1.654e+09, train_seconds = 2.0614e+04)
[2022-05-31 19:54:00,162][root][INFO] - Step 135915520 @ 6650.0 SPS. Inference batcher size: 114. Learner queue size: 0. Other stats: (step = 135915520, mean_episode_return = None, mean_episode_step = 798.66, total_loss = 255.62, pg_loss = 157.59, baseline_loss = 104.28, entropy_loss = -6.2484, learner_queue_size = 17, _tick = 45098, _time = 1.654e+09, train_seconds = 2.0619e+04)
[2022-05-31 19:54:05,166][root][INFO] - Step 135948800 @ 6650.8 SPS. Inference batcher size: 68. Learner queue size: 24. Other stats: (step = 135948800, mean_episode_return = 251.08, mean_episode_step = 882.74, total_loss = 42.034, pg_loss = -87.939, baseline_loss = 137.12, entropy_loss = -7.1493, learner_queue_size = 20, _tick = 45107, _time = 1.654e+09, train_seconds = 2.0624e+04)
[2022-05-31 19:54:10,172][root][INFO] - Step 135979520 @ 6136.0 SPS. Inference batcher size: 150. Learner queue size: 26. Other stats: (step = 135979520, mean_episode_return = None, mean_episode_step = 812.19, total_loss = -92.649, pg_loss = -103.51, baseline_loss = 17.875, entropy_loss = -7.0093, learner_queue_size = 11, _tick = 45117, _time = 1.654e+09, train_seconds = 2.0629e+04)
[2022-05-31 19:54:15,178][root][INFO] - Step 136012800 @ 6648.7 SPS. Inference batcher size: 120. Learner queue size: 20. Other stats: (step = 136012800, mean_episode_return = 393.45, mean_episode_step = 919.73, total_loss = 113.21, pg_loss = 45.67, baseline_loss = 73.822, entropy_loss = -6.2862, learner_queue_size = 17, _tick = 45128, _time = 1.654e+09, train_seconds = 2.0634e+04)
[2022-05-31 19:54:20,182][root][INFO] - Step 136046080 @ 6650.7 SPS. Inference batcher size: 97. Learner queue size: 12. Other stats: (step = 136046080, mean_episode_return = 140.15, mean_episode_step = 630.34, total_loss = 332.67, pg_loss = 164.53, baseline_loss = 174.42, entropy_loss = -6.2798, learner_queue_size = 22, _tick = 45141, _time = 1.654e+09, train_seconds = 2.0639e+04)
[2022-05-31 19:54:25,188][root][INFO] - Step 136079360 @ 6648.1 SPS. Inference batcher size: 143. Learner queue size: 6. Other stats: (step = 136079360, mean_episode_return = 244.86, mean_episode_step = 561.45, total_loss = 494.73, pg_loss = 276.34, baseline_loss = 224.06, entropy_loss = -5.6688, learner_queue_size = 17, _tick = 45153, _time = 1.654e+09, train_seconds = 2.0644e+04)
[2022-05-31 19:54:30,194][root][INFO] - Step 136110080 @ 6136.6 SPS. Inference batcher size: 121. Learner queue size: 16. Other stats: (step = 136110080, mean_episode_return = 172.68, mean_episode_step = 560.45, total_loss = 165.59, pg_loss = 34.975, baseline_loss = 136.45, entropy_loss = -5.8349, learner_queue_size = 14, _tick = 45164, _time = 1.654e+09, train_seconds = 2.0649e+04)
[2022-05-31 19:54:35,198][root][INFO] - Step 136143360 @ 6650.6 SPS. Inference batcher size: 147. Learner queue size: 20. Other stats: (step = 136143360, mean_episode_return = 283.1, mean_episode_step = 831.88, total_loss = 258.86, pg_loss = 166.01, baseline_loss = 99.458, entropy_loss = -6.6033, learner_queue_size = 12, _tick = 45177, _time = 1.654e+09, train_seconds = 2.0654e+04)
[2022-05-31 19:54:40,204][root][INFO] - Step 136176640 @ 6647.9 SPS. Inference batcher size: 75. Learner queue size: 15. Other stats: (step = 136176640, mean_episode_return = None, mean_episode_step = 696.78, total_loss = 474.17, pg_loss = 256.96, baseline_loss = 223.2, entropy_loss = -5.988, learner_queue_size = 21, _tick = 45188, _time = 1.654e+09, train_seconds = 2.0659e+04)
[2022-05-31 19:54:45,210][root][INFO] - Step 136209920 @ 6647.9 SPS. Inference batcher size: 144. Learner queue size: 11. Other stats: (step = 136209920, mean_episode_return = 181.45, mean_episode_step = 771.27, total_loss = 254.72, pg_loss = 123.48, baseline_loss = 137.63, entropy_loss = -6.3869, learner_queue_size = 27, _tick = 45200, _time = 1.654e+09, train_seconds = 2.0664e+04)
[2022-05-31 19:54:50,214][root][INFO] - Step 136243200 @ 6650.9 SPS. Inference batcher size: 125. Learner queue size: 4. Other stats: (step = 136243200, mean_episode_return = 486.36, mean_episode_step = 835.44, total_loss = 233.85, pg_loss = 80.202, baseline_loss = 160.37, entropy_loss = -6.7246, learner_queue_size = 26, _tick = 45213, _time = 1.654e+09, train_seconds = 2.0669e+04)
[2022-05-31 19:54:55,222][root][INFO] - Step 136276480 @ 6645.4 SPS. Inference batcher size: 110. Learner queue size: 1. Other stats: (step = 136276480, mean_episode_return = 67.32, mean_episode_step = 673.47, total_loss = 120.85, pg_loss = 62.049, baseline_loss = 65.134, entropy_loss = -6.3345, learner_queue_size = 20, _tick = 45225, _time = 1.654e+09, train_seconds = 2.0674e+04)
[2022-05-31 19:55:00,226][root][INFO] - Step 136309760 @ 6650.6 SPS. Inference batcher size: 84. Learner queue size: 28. Other stats: (step = 136309760, mean_episode_return = 474.48, mean_episode_step = 659.32, total_loss = 18.378, pg_loss = -56.98, baseline_loss = 80.77, entropy_loss = -5.412, learner_queue_size = 27, _tick = 45238, _time = 1.654e+09, train_seconds = 2.0679e+04)
[2022-05-31 19:55:05,230][root][INFO] - Step 136340480 @ 6139.1 SPS. Inference batcher size: 106. Learner queue size: 20. Other stats: (step = 136340480, mean_episode_return = None, mean_episode_step = 584.5, total_loss = 180.28, pg_loss = 88.938, baseline_loss = 96.92, entropy_loss = -5.5754, learner_queue_size = 24, _tick = 45249, _time = 1.654e+09, train_seconds = 2.0684e+04)
[2022-05-31 19:55:10,234][root][INFO] - Step 136373760 @ 6650.7 SPS. Inference batcher size: 152. Learner queue size: 15. Other stats: (step = 136373760, mean_episode_return = 322.83, mean_episode_step = 647.92, total_loss = 72.951, pg_loss = -128.48, baseline_loss = 207.73, entropy_loss = -6.3058, learner_queue_size = 14, _tick = 45262, _time = 1.654e+09, train_seconds = 2.0689e+04)
[2022-05-31 19:55:15,238][root][INFO] - Step 136407040 @ 6650.7 SPS. Inference batcher size: 107. Learner queue size: 7. Other stats: (step = 136407040, mean_episode_return = 409.45, mean_episode_step = 561.07, total_loss = -171.91, pg_loss = -210.29, baseline_loss = 44.699, entropy_loss = -6.3151, learner_queue_size = 15, _tick = 45274, _time = 1.654e+09, train_seconds = 2.0694e+04)
[2022-05-31 19:55:20,244][root][INFO] - Step 136440320 @ 6647.7 SPS. Inference batcher size: 142. Learner queue size: 3. Other stats: (step = 136440320, mean_episode_return = 101.23, mean_episode_step = 610.68, total_loss = 102.19, pg_loss = 56.843, baseline_loss = 51.736, entropy_loss = -6.385, learner_queue_size = 19, _tick = 45286, _time = 1.654e+09, train_seconds = 2.0699e+04)
[2022-05-31 19:55:25,250][root][INFO] - Step 136473600 @ 6648.3 SPS. Inference batcher size: 97. Learner queue size: 22. Other stats: (step = 136473600, mean_episode_return = 313.84, mean_episode_step = 731.09, total_loss = 98.166, pg_loss = 62.326, baseline_loss = 41.968, entropy_loss = -6.1285, learner_queue_size = 13, _tick = 45299, _time = 1.654e+09, train_seconds = 2.0704e+04)
[2022-05-31 19:55:30,256][root][INFO] - Step 136504320 @ 6136.5 SPS. Inference batcher size: 119. Learner queue size: 15. Other stats: (step = 136504320, mean_episode_return = 241.72, mean_episode_step = 713.39, total_loss = 142.82, pg_loss = 102.76, baseline_loss = 46.421, entropy_loss = -6.3596, learner_queue_size = 27, _tick = 45311, _time = 1.654e+09, train_seconds = 2.0709e+04)
[2022-05-31 19:55:35,262][root][INFO] - Step 136537600 @ 6648.2 SPS. Inference batcher size: 86. Learner queue size: 7. Other stats: (step = 136537600, mean_episode_return = 199.72, mean_episode_step = 701.17, total_loss = 197.79, pg_loss = 123.4, baseline_loss = 80.532, entropy_loss = -6.1473, learner_queue_size = 15, _tick = 45324, _time = 1.654e+09, train_seconds = 2.0714e+04)
[2022-05-31 19:55:40,266][root][INFO] - Step 136570880 @ 6650.6 SPS. Inference batcher size: 121. Learner queue size: 31. Other stats: (step = 136570880, mean_episode_return = 240.68, mean_episode_step = 598.47, total_loss = 25.682, pg_loss = -38.165, baseline_loss = 70.379, entropy_loss = -6.5317, learner_queue_size = 12, _tick = 45337, _time = 1.654e+09, train_seconds = 2.0719e+04)
[2022-05-31 19:55:45,270][root][INFO] - Step 136604160 @ 6650.8 SPS. Inference batcher size: 98. Learner queue size: 31. Other stats: (step = 136604160, mean_episode_return = None, mean_episode_step = 689.91, total_loss = 190.93, pg_loss = 101.64, baseline_loss = 95.686, entropy_loss = -6.3972, learner_queue_size = 16, _tick = 45349, _time = 1.654e+09, train_seconds = 2.0724e+04)
[2022-05-31 19:55:50,272][root][INFO] - Step 136634880 @ 6140.9 SPS. Inference batcher size: 85. Learner queue size: 14. Other stats: (step = 136634880, mean_episode_return = 118.81, mean_episode_step = 608.87, total_loss = 39.923, pg_loss = -34.313, baseline_loss = 80.903, entropy_loss = -6.6678, learner_queue_size = 17, _tick = 45360, _time = 1.654e+09, train_seconds = 2.0729e+04)
[2022-05-31 19:55:55,278][root][INFO] - Step 136668160 @ 6648.6 SPS. Inference batcher size: 149. Learner queue size: 22. Other stats: (step = 136668160, mean_episode_return = 377.46, mean_episode_step = 656.76, total_loss = 160.59, pg_loss = 81.398, baseline_loss = 85.289, entropy_loss = -6.0928, learner_queue_size = 27, _tick = 45370, _time = 1.654e+09, train_seconds = 2.0734e+04)
[2022-05-31 19:56:00,284][root][INFO] - Step 136701440 @ 6647.9 SPS. Inference batcher size: 119. Learner queue size: 14. Other stats: (step = 136701440, mean_episode_return = 308.16, mean_episode_step = 721.87, total_loss = 11.344, pg_loss = -35.644, baseline_loss = 53.338, entropy_loss = -6.3497, learner_queue_size = 19, _tick = 45382, _time = 1.654e+09, train_seconds = 2.0739e+04)
[2022-05-31 19:56:05,290][root][INFO] - Step 136734720 @ 6648.0 SPS. Inference batcher size: 19. Learner queue size: 11. Other stats: (step = 136734720, mean_episode_return = 199.03, mean_episode_step = 713.71, total_loss = 159.74, pg_loss = 53.977, baseline_loss = 111.69, entropy_loss = -5.9295, learner_queue_size = 29, _tick = 45395, _time = 1.654e+09, train_seconds = 2.0744e+04)
[2022-05-31 19:56:10,294][root][INFO] - Step 136768000 @ 6651.3 SPS. Inference batcher size: 114. Learner queue size: 19. Other stats: (step = 136768000, mean_episode_return = 178.77, mean_episode_step = 582.29, total_loss = 252.52, pg_loss = 133.23, baseline_loss = 125.08, entropy_loss = -5.7916, learner_queue_size = 27, _tick = 45404, _time = 1.654e+09, train_seconds = 2.0749e+04)
[2022-05-31 19:56:15,298][root][INFO] - Step 136801280 @ 6650.1 SPS. Inference batcher size: 136. Learner queue size: 20. Other stats: (step = 136801280, mean_episode_return = None, mean_episode_step = 498.44, total_loss = 58.437, pg_loss = 3.9064, baseline_loss = 60.549, entropy_loss = -6.0182, learner_queue_size = 21, _tick = 45415, _time = 1.654e+09, train_seconds = 2.0754e+04)
[2022-05-31 19:56:20,304][root][INFO] - Step 136834560 @ 6648.0 SPS. Inference batcher size: 59. Learner queue size: 9. Other stats: (step = 136834560, mean_episode_return = 261.48, mean_episode_step = 564.52, total_loss = -69.384, pg_loss = -163.07, baseline_loss = 99.532, entropy_loss = -5.8428, learner_queue_size = 17, _tick = 45428, _time = 1.654e+09, train_seconds = 2.0759e+04)
[2022-05-31 19:56:25,310][root][INFO] - Step 136867840 @ 6647.9 SPS. Inference batcher size: 108. Learner queue size: 0. Other stats: (step = 136867840, mean_episode_return = 189.7, mean_episode_step = 726.72, total_loss = 180.96, pg_loss = 118.24, baseline_loss = 69.584, entropy_loss = -6.8579, learner_queue_size = 25, _tick = 45440, _time = 1.654e+09, train_seconds = 2.0764e+04)
[2022-05-31 19:56:30,314][root][INFO] - Step 136901120 @ 6650.9 SPS. Inference batcher size: 95. Learner queue size: 24. Other stats: (step = 136901120, mean_episode_return = 193.09, mean_episode_step = 621.74, total_loss = 363.7, pg_loss = 290.0, baseline_loss = 80.237, entropy_loss = -6.5306, learner_queue_size = 13, _tick = 45453, _time = 1.654e+09, train_seconds = 2.0769e+04)
[2022-05-31 19:56:35,318][root][INFO] - Step 136934400 @ 6650.7 SPS. Inference batcher size: 41. Learner queue size: 1. Other stats: (step = 136934400, mean_episode_return = 41.7, mean_episode_step = 714.99, total_loss = 26.375, pg_loss = -15.144, baseline_loss = 47.974, entropy_loss = -6.4545, learner_queue_size = 26, _tick = 45464, _time = 1.654e+09, train_seconds = 2.0774e+04)
[2022-05-31 19:56:40,322][root][INFO] - Step 136967680 @ 6650.5 SPS. Inference batcher size: 140. Learner queue size: 24. Other stats: (step = 136967680, mean_episode_return = 351.62, mean_episode_step = 659.91, total_loss = 719.77, pg_loss = 540.87, baseline_loss = 185.45, entropy_loss = -6.5515, learner_queue_size = 20, _tick = 45475, _time = 1.654e+09, train_seconds = 2.0779e+04)
[2022-05-31 19:56:45,326][root][INFO] - Step 137000960 @ 6650.8 SPS. Inference batcher size: 112. Learner queue size: 18. Other stats: (step = 137000960, mean_episode_return = 333.09, mean_episode_step = 731.91, total_loss = 24.781, pg_loss = -47.0, baseline_loss = 78.132, entropy_loss = -6.3507, learner_queue_size = 17, _tick = 45488, _time = 1.654e+09, train_seconds = 2.0784e+04)
[2022-05-31 19:56:50,332][root][INFO] - Step 137031680 @ 6136.6 SPS. Inference batcher size: 80. Learner queue size: 22. Other stats: (step = 137031680, mean_episode_return = 258.23, mean_episode_step = 617.42, total_loss = -39.405, pg_loss = -109.09, baseline_loss = 75.924, entropy_loss = -6.2372, learner_queue_size = 15, _tick = 45499, _time = 1.654e+09, train_seconds = 2.0789e+04)
[2022-05-31 19:56:55,338][root][INFO] - Step 137064960 @ 6648.0 SPS. Inference batcher size: 144. Learner queue size: 9. Other stats: (step = 137064960, mean_episode_return = 138.21, mean_episode_step = 552.41, total_loss = -179.13, pg_loss = -232.91, baseline_loss = 60.121, entropy_loss = -6.3442, learner_queue_size = 19, _tick = 45510, _time = 1.654e+09, train_seconds = 2.0794e+04)
[2022-05-31 19:57:00,344][root][INFO] - Step 137098240 @ 6648.0 SPS. Inference batcher size: 134. Learner queue size: 20. Other stats: (step = 137098240, mean_episode_return = None, mean_episode_step = 674.09, total_loss = -69.167, pg_loss = -84.636, baseline_loss = 22.461, entropy_loss = -6.9928, learner_queue_size = 20, _tick = 45520, _time = 1.654e+09, train_seconds = 2.0799e+04)
[2022-05-31 19:57:05,346][root][INFO] - Step 137131520 @ 6653.2 SPS. Inference batcher size: 117. Learner queue size: 17. Other stats: (step = 137131520, mean_episode_return = 159.97, mean_episode_step = 701.86, total_loss = 211.44, pg_loss = 149.3, baseline_loss = 68.371, entropy_loss = -6.2263, learner_queue_size = 29, _tick = 45529, _time = 1.654e+09, train_seconds = 2.0804e+04)
[2022-05-31 19:57:10,350][root][INFO] - Step 137164800 @ 6650.7 SPS. Inference batcher size: 144. Learner queue size: 18. Other stats: (step = 137164800, mean_episode_return = 170.97, mean_episode_step = 642.53, total_loss = -37.008, pg_loss = -125.07, baseline_loss = 94.464, entropy_loss = -6.4056, learner_queue_size = 14, _tick = 45539, _time = 1.654e+09, train_seconds = 2.0809e+04)
[2022-05-31 19:57:15,356][root][INFO] - Step 137198080 @ 6648.0 SPS. Inference batcher size: 126. Learner queue size: 14. Other stats: (step = 137198080, mean_episode_return = 252.17, mean_episode_step = 724.99, total_loss = 41.387, pg_loss = -40.704, baseline_loss = 89.104, entropy_loss = -7.0131, learner_queue_size = 23, _tick = 45552, _time = 1.654e+09, train_seconds = 2.0814e+04)
[2022-05-31 19:57:20,362][root][INFO] - Step 137231360 @ 6648.0 SPS. Inference batcher size: 73. Learner queue size: 9. Other stats: (step = 137231360, mean_episode_return = 175.95, mean_episode_step = 589.77, total_loss = 240.68, pg_loss = 182.83, baseline_loss = 63.751, entropy_loss = -5.8949, learner_queue_size = 21, _tick = 45565, _time = 1.654e+09, train_seconds = 2.0819e+04)
[2022-05-31 19:57:25,368][root][INFO] - Step 137264640 @ 6647.9 SPS. Inference batcher size: 99. Learner queue size: 7. Other stats: (step = 137264640, mean_episode_return = 157.13, mean_episode_step = 873.53, total_loss = -66.394, pg_loss = -86.317, baseline_loss = 26.808, entropy_loss = -6.8858, learner_queue_size = 12, _tick = 45577, _time = 1.654e+09, train_seconds = 2.0824e+04)
[2022-05-31 19:57:30,374][root][INFO] - Step 137297920 @ 6647.9 SPS. Inference batcher size: 133. Learner queue size: 2. Other stats: (step = 137297920, mean_episode_return = 191.95, mean_episode_step = 795.98, total_loss = -34.508, pg_loss = -40.409, baseline_loss = 13.094, entropy_loss = -7.1937, learner_queue_size = 20, _tick = 45588, _time = 1.654e+09, train_seconds = 2.0829e+04)
[2022-05-31 19:57:35,378][root][INFO] - Step 137331200 @ 6650.7 SPS. Inference batcher size: 116. Learner queue size: 3. Other stats: (step = 137331200, mean_episode_return = 188.08, mean_episode_step = 825.25, total_loss = 32.118, pg_loss = 5.5579, baseline_loss = 33.057, entropy_loss = -6.4968, learner_queue_size = 19, _tick = 45598, _time = 1.654e+09, train_seconds = 2.0834e+04)
[2022-05-31 19:57:40,382][root][INFO] - Step 137364480 @ 6650.9 SPS. Inference batcher size: 119. Learner queue size: 31. Other stats: (step = 137364480, mean_episode_return = 103.14, mean_episode_step = 740.76, total_loss = 152.48, pg_loss = 80.345, baseline_loss = 78.059, entropy_loss = -5.9261, learner_queue_size = 23, _tick = 45611, _time = 1.654e+09, train_seconds = 2.0839e+04)
[2022-05-31 19:57:45,386][root][INFO] - Step 137395200 @ 6139.1 SPS. Inference batcher size: 120. Learner queue size: 21. Other stats: (step = 137395200, mean_episode_return = 67.843, mean_episode_step = 643.01, total_loss = -109.82, pg_loss = -154.37, baseline_loss = 50.392, entropy_loss = -5.8493, learner_queue_size = 17, _tick = 45623, _time = 1.654e+09, train_seconds = 2.0844e+04)
[2022-05-31 19:57:50,391][root][INFO] - Step 137428480 @ 6649.6 SPS. Inference batcher size: 66. Learner queue size: 13. Other stats: (step = 137428480, mean_episode_return = 570.78, mean_episode_step = 675.09, total_loss = 44.51, pg_loss = -184.14, baseline_loss = 234.91, entropy_loss = -6.268, learner_queue_size = 19, _tick = 45636, _time = 1.654e+09, train_seconds = 2.0849e+04)
[2022-05-31 19:57:55,394][root][INFO] - Step 137461760 @ 6651.7 SPS. Inference batcher size: 36. Learner queue size: 14. Other stats: (step = 137461760, mean_episode_return = 215.68, mean_episode_step = 777.5, total_loss = 213.13, pg_loss = 86.947, baseline_loss = 132.35, entropy_loss = -6.1677, learner_queue_size = 16, _tick = 45645, _time = 1.654e+09, train_seconds = 2.0854e+04)
[2022-05-31 19:58:00,398][root][INFO] - Step 137495040 @ 6650.8 SPS. Inference batcher size: 59. Learner queue size: 7. Other stats: (step = 137495040, mean_episode_return = 206.08, mean_episode_step = 665.57, total_loss = 14.202, pg_loss = -328.1, baseline_loss = 348.63, entropy_loss = -6.3298, learner_queue_size = 24, _tick = 45656, _time = 1.654e+09, train_seconds = 2.0859e+04)
[2022-05-31 19:58:05,402][root][INFO] - Step 137528320 @ 6650.6 SPS. Inference batcher size: 74. Learner queue size: 1. Other stats: (step = 137528320, mean_episode_return = 343.85, mean_episode_step = 768.07, total_loss = 58.144, pg_loss = -115.8, baseline_loss = 179.65, entropy_loss = -5.7028, learner_queue_size = 24, _tick = 45668, _time = 1.654e+09, train_seconds = 2.0864e+04)
[2022-05-31 19:58:10,406][root][INFO] - Step 137559040 @ 6139.1 SPS. Inference batcher size: 139. Learner queue size: 25. Other stats: (step = 137559040, mean_episode_return = 239.46, mean_episode_step = 646.98, total_loss = 264.64, pg_loss = -14.133, baseline_loss = 284.41, entropy_loss = -5.6299, learner_queue_size = 9, _tick = 45677, _time = 1.654e+09, train_seconds = 2.0869e+04)
[2022-05-31 19:58:15,410][root][INFO] - Step 137592320 @ 6650.5 SPS. Inference batcher size: 25. Learner queue size: 21. Other stats: (step = 137592320, mean_episode_return = 122.21, mean_episode_step = 547.58, total_loss = 245.79, pg_loss = -463.98, baseline_loss = 715.07, entropy_loss = -5.3033, learner_queue_size = 13, _tick = 45690, _time = 1.654e+09, train_seconds = 2.0874e+04)
[2022-05-31 19:58:20,414][root][INFO] - Step 137625600 @ 6650.8 SPS. Inference batcher size: 101. Learner queue size: 15. Other stats: (step = 137625600, mean_episode_return = -3.7904, mean_episode_step = 669.45, total_loss = -138.36, pg_loss = -207.79, baseline_loss = 75.66, entropy_loss = -6.2295, learner_queue_size = 32, _tick = 45703, _time = 1.654e+09, train_seconds = 2.0879e+04)
[2022-05-31 19:58:25,420][root][INFO] - Step 137658880 @ 6647.6 SPS. Inference batcher size: 121. Learner queue size: 12. Other stats: (step = 137658880, mean_episode_return = 267.96, mean_episode_step = 735.53, total_loss = 100.36, pg_loss = -45.784, baseline_loss = 152.45, entropy_loss = -6.3069, learner_queue_size = 15, _tick = 45716, _time = 1.654e+09, train_seconds = 2.0884e+04)
[2022-05-31 19:58:30,426][root][INFO] - Step 137692160 @ 6648.3 SPS. Inference batcher size: 130. Learner queue size: 17. Other stats: (step = 137692160, mean_episode_return = 166.15, mean_episode_step = 597.88, total_loss = 108.94, pg_loss = 10.199, baseline_loss = 104.24, entropy_loss = -5.4914, learner_queue_size = 17, _tick = 45728, _time = 1.654e+09, train_seconds = 2.0889e+04)
[2022-05-31 19:58:35,430][root][INFO] - Step 137725440 @ 6650.7 SPS. Inference batcher size: 189. Learner queue size: 2. Other stats: (step = 137725440, mean_episode_return = 92.24, mean_episode_step = 687.66, total_loss = 124.02, pg_loss = 19.013, baseline_loss = 110.67, entropy_loss = -5.6645, learner_queue_size = 13, _tick = 45741, _time = 1.654e+09, train_seconds = 2.0894e+04)
[2022-05-31 19:58:40,436][root][INFO] - Step 137758720 @ 6648.2 SPS. Inference batcher size: 45. Learner queue size: 4. Other stats: (step = 137758720, mean_episode_return = 418.65, mean_episode_step = 701.98, total_loss = 400.66, pg_loss = 272.52, baseline_loss = 133.81, entropy_loss = -5.6687, learner_queue_size = 25, _tick = 45753, _time = 1.654e+09, train_seconds = 2.0899e+04)
[2022-05-31 19:58:45,438][root][INFO] - Step 137789440 @ 6141.4 SPS. Inference batcher size: 80. Learner queue size: 18. Other stats: (step = 137789440, mean_episode_return = 251.31, mean_episode_step = 647.21, total_loss = 877.26, pg_loss = 298.26, baseline_loss = 584.8, entropy_loss = -5.7919, learner_queue_size = 14, _tick = 45764, _time = 1.654e+09, train_seconds = 2.0904e+04)
[2022-05-31 19:58:50,442][root][INFO] - Step 137822720 @ 6650.8 SPS. Inference batcher size: 0. Learner queue size: 13. Other stats: (step = 137822720, mean_episode_return = 235.31, mean_episode_step = 614.82, total_loss = 426.95, pg_loss = 240.61, baseline_loss = 191.97, entropy_loss = -5.642, learner_queue_size = 21, _tick = 45777, _time = 1.654e+09, train_seconds = 2.0909e+04)
[2022-05-31 19:58:55,446][root][INFO] - Step 137856000 @ 6650.7 SPS. Inference batcher size: 201. Learner queue size: 7. Other stats: (step = 137856000, mean_episode_return = 288.29, mean_episode_step = 769.8, total_loss = 30.977, pg_loss = -77.858, baseline_loss = 114.71, entropy_loss = -5.8706, learner_queue_size = 19, _tick = 45787, _time = 1.654e+09, train_seconds = 2.0914e+04)
[2022-05-31 19:59:00,450][root][INFO] - Step 137889280 @ 6650.6 SPS. Inference batcher size: 145. Learner queue size: 3. Other stats: (step = 137889280, mean_episode_return = 327.05, mean_episode_step = 648.85, total_loss = -177.07, pg_loss = -225.7, baseline_loss = 54.955, entropy_loss = -6.3265, learner_queue_size = 17, _tick = 45799, _time = 1.654e+09, train_seconds = 2.0919e+04)
[2022-05-31 19:59:05,456][root][INFO] - Step 137922560 @ 6647.5 SPS. Inference batcher size: 22. Learner queue size: 1. Other stats: (step = 137922560, mean_episode_return = 373.83, mean_episode_step = 656.66, total_loss = 24.528, pg_loss = -0.0045347, baseline_loss = 31.009, entropy_loss = -6.4764, learner_queue_size = 17, _tick = 45810, _time = 1.654e+09, train_seconds = 2.0924e+04)
[2022-05-31 19:59:10,464][root][INFO] - Step 137953280 @ 6134.8 SPS. Inference batcher size: 191. Learner queue size: 28. Other stats: (step = 137953280, mean_episode_return = 252.97, mean_episode_step = 673.67, total_loss = 158.67, pg_loss = 66.454, baseline_loss = 98.515, entropy_loss = -6.3004, learner_queue_size = 17, _tick = 45822, _time = 1.654e+09, train_seconds = 2.0929e+04)
[2022-05-31 19:59:15,470][root][INFO] - Step 137989120 @ 7159.3 SPS. Inference batcher size: 107. Learner queue size: 23. Other stats: (step = 137989120, mean_episode_return = 23.03, mean_episode_step = 648.99, total_loss = 138.28, pg_loss = 52.044, baseline_loss = 92.494, entropy_loss = -6.2578, learner_queue_size = 16, _tick = 45835, _time = 1.654e+09, train_seconds = 2.0934e+04)
[2022-05-31 19:59:20,476][root][INFO] - Step 138019840 @ 6136.6 SPS. Inference batcher size: 135. Learner queue size: 21. Other stats: (step = 138019840, mean_episode_return = 382.86, mean_episode_step = 673.11, total_loss = -3.6827, pg_loss = -17.955, baseline_loss = 20.635, entropy_loss = -6.3626, learner_queue_size = 17, _tick = 45846, _time = 1.654e+09, train_seconds = 2.0939e+04)
[2022-05-31 19:59:25,482][root][INFO] - Step 138053120 @ 6647.9 SPS. Inference batcher size: 119. Learner queue size: 16. Other stats: (step = 138053120, mean_episode_return = 96.382, mean_episode_step = 745.23, total_loss = 165.21, pg_loss = 131.95, baseline_loss = 39.302, entropy_loss = -6.0364, learner_queue_size = 13, _tick = 45858, _time = 1.654e+09, train_seconds = 2.0944e+04)
[2022-05-31 19:59:30,488][root][INFO] - Step 138086400 @ 6648.0 SPS. Inference batcher size: 140. Learner queue size: 13. Other stats: (step = 138086400, mean_episode_return = 222.18, mean_episode_step = 637.08, total_loss = 4.5689, pg_loss = -40.878, baseline_loss = 51.585, entropy_loss = -6.1381, learner_queue_size = 27, _tick = 45870, _time = 1.654e+09, train_seconds = 2.0949e+04)
[2022-05-31 19:59:35,494][root][INFO] - Step 138119680 @ 6648.1 SPS. Inference batcher size: 143. Learner queue size: 10. Other stats: (step = 138119680, mean_episode_return = 79.635, mean_episode_step = 766.11, total_loss = 279.6, pg_loss = 233.73, baseline_loss = 51.946, entropy_loss = -6.071, learner_queue_size = 18, _tick = 45883, _time = 1.654e+09, train_seconds = 2.0954e+04)
[2022-05-31 19:59:40,498][root][INFO] - Step 138152960 @ 6650.7 SPS. Inference batcher size: 38. Learner queue size: 12. Other stats: (step = 138152960, mean_episode_return = 104.86, mean_episode_step = 686.63, total_loss = -164.74, pg_loss = -208.01, baseline_loss = 49.2, entropy_loss = -5.9276, learner_queue_size = 21, _tick = 45893, _time = 1.654e+09, train_seconds = 2.0959e+04)
[2022-05-31 19:59:45,504][root][INFO] - Step 138186240 @ 6647.7 SPS. Inference batcher size: 170. Learner queue size: 5. Other stats: (step = 138186240, mean_episode_return = 390.0, mean_episode_step = 735.95, total_loss = -18.994, pg_loss = -130.35, baseline_loss = 117.27, entropy_loss = -5.9173, learner_queue_size = 24, _tick = 45905, _time = 1.654e+09, train_seconds = 2.0964e+04)
[2022-05-31 19:59:50,510][root][INFO] - Step 138219520 @ 6648.4 SPS. Inference batcher size: 145. Learner queue size: 1. Other stats: (step = 138219520, mean_episode_return = 183.67, mean_episode_step = 720.92, total_loss = 102.59, pg_loss = -4.9633, baseline_loss = 113.32, entropy_loss = -5.7672, learner_queue_size = 20, _tick = 45918, _time = 1.654e+09, train_seconds = 2.0969e+04)
[2022-05-31 19:59:55,514][root][INFO] - Step 138252800 @ 6650.2 SPS. Inference batcher size: 22. Learner queue size: 26. Other stats: (step = 138252800, mean_episode_return = 197.82, mean_episode_step = 707.3, total_loss = 328.01, pg_loss = 193.01, baseline_loss = 139.99, entropy_loss = -4.9941, learner_queue_size = 16, _tick = 45931, _time = 1.654e+09, train_seconds = 2.0974e+04)
[2022-05-31 20:00:00,518][root][INFO] - Step 138286080 @ 6651.0 SPS. Inference batcher size: 97. Learner queue size: 21. Other stats: (step = 138286080, mean_episode_return = 227.31, mean_episode_step = 765.28, total_loss = 69.273, pg_loss = -44.795, baseline_loss = 119.41, entropy_loss = -5.3425, learner_queue_size = 20, _tick = 45944, _time = 1.654e+09, train_seconds = 2.0979e+04)
[2022-05-31 20:00:05,524][root][INFO] - Step 138316800 @ 6136.7 SPS. Inference batcher size: 94. Learner queue size: 22. Other stats: (step = 138316800, mean_episode_return = 242.32, mean_episode_step = 444.05, total_loss = 49.699, pg_loss = -117.73, baseline_loss = 172.33, entropy_loss = -4.9004, learner_queue_size = 17, _tick = 45956, _time = 1.654e+09, train_seconds = 2.0984e+04)
[2022-05-31 20:00:10,526][root][INFO] - Step 138350080 @ 6653.4 SPS. Inference batcher size: 100. Learner queue size: 23. Other stats: (step = 138350080, mean_episode_return = 304.08, mean_episode_step = 580.45, total_loss = 333.81, pg_loss = 67.84, baseline_loss = 271.35, entropy_loss = -5.3749, learner_queue_size = 23, _tick = 45968, _time = 1.654e+09, train_seconds = 2.0989e+04)
[2022-05-31 20:00:15,532][root][INFO] - Step 138383360 @ 6648.0 SPS. Inference batcher size: 86. Learner queue size: 14. Other stats: (step = 138383360, mean_episode_return = 238.44, mean_episode_step = 587.87, total_loss = 610.26, pg_loss = 257.66, baseline_loss = 358.32, entropy_loss = -5.7105, learner_queue_size = 19, _tick = 45978, _time = 1.654e+09, train_seconds = 2.0994e+04)
[2022-05-31 20:00:20,538][root][INFO] - Step 138416640 @ 6648.0 SPS. Inference batcher size: 136. Learner queue size: 14. Other stats: (step = 138416640, mean_episode_return = 176.96, mean_episode_step = 592.97, total_loss = 397.28, pg_loss = 171.52, baseline_loss = 231.56, entropy_loss = -5.7995, learner_queue_size = 15, _tick = 45990, _time = 1.654e+09, train_seconds = 2.0999e+04)
[2022-05-31 20:00:25,542][root][INFO] - Step 138449920 @ 6650.8 SPS. Inference batcher size: 19. Learner queue size: 17. Other stats: (step = 138449920, mean_episode_return = None, mean_episode_step = 762.69, total_loss = 9.6516, pg_loss = -66.533, baseline_loss = 82.348, entropy_loss = -6.1635, learner_queue_size = 11, _tick = 46000, _time = 1.654e+09, train_seconds = 2.1004e+04)
[2022-05-31 20:00:30,546][root][INFO] - Step 138483200 @ 6650.6 SPS. Inference batcher size: 125. Learner queue size: 13. Other stats: (step = 138483200, mean_episode_return = 110.79, mean_episode_step = 736.04, total_loss = 400.05, pg_loss = 169.99, baseline_loss = 236.15, entropy_loss = -6.0872, learner_queue_size = 24, _tick = 46013, _time = 1.654e+09, train_seconds = 2.1009e+04)
[2022-05-31 20:00:35,552][root][INFO] - Step 138516480 @ 6647.9 SPS. Inference batcher size: 143. Learner queue size: 3. Other stats: (step = 138516480, mean_episode_return = 178.15, mean_episode_step = 596.2, total_loss = -9.2529, pg_loss = -93.317, baseline_loss = 89.776, entropy_loss = -5.7123, learner_queue_size = 16, _tick = 46026, _time = 1.654e+09, train_seconds = 2.1014e+04)
[2022-05-31 20:00:40,558][root][INFO] - Step 138549760 @ 6648.2 SPS. Inference batcher size: 101. Learner queue size: 26. Other stats: (step = 138549760, mean_episode_return = None, mean_episode_step = 757.97, total_loss = -19.365, pg_loss = -55.095, baseline_loss = 42.087, entropy_loss = -6.3572, learner_queue_size = 20, _tick = 46038, _time = 1.654e+09, train_seconds = 2.1019e+04)
[2022-05-31 20:00:45,564][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 20:00:45,669][root][INFO] - Step 138580480 @ 6136.9 SPS. Inference batcher size: 119. Learner queue size: 27. Other stats: (step = 138583040, mean_episode_return = None, mean_episode_step = 713.69, total_loss = 68.003, pg_loss = 17.3, baseline_loss = 56.959, entropy_loss = -6.2558, learner_queue_size = 25, _tick = 46049, _time = 1.654e+09, train_seconds = 2.1024e+04)
[2022-05-31 20:00:50,675][root][INFO] - Step 138613760 @ 6511.6 SPS. Inference batcher size: 107. Learner queue size: 19. Other stats: (step = 138613760, mean_episode_return = 509.97, mean_episode_step = 692.18, total_loss = -96.536, pg_loss = -145.76, baseline_loss = 55.293, entropy_loss = -6.0691, learner_queue_size = 15, _tick = 46061, _time = 1.654e+09, train_seconds = 2.1029e+04)
[2022-05-31 20:00:55,678][root][INFO] - Step 138647040 @ 6651.5 SPS. Inference batcher size: 122. Learner queue size: 18. Other stats: (step = 138647040, mean_episode_return = 306.53, mean_episode_step = 659.95, total_loss = 137.16, pg_loss = 59.311, baseline_loss = 83.648, entropy_loss = -5.8004, learner_queue_size = 21, _tick = 46074, _time = 1.654e+09, train_seconds = 2.1034e+04)
[2022-05-31 20:01:00,684][root][INFO] - Step 138680320 @ 6647.9 SPS. Inference batcher size: 126. Learner queue size: 19. Other stats: (step = 138680320, mean_episode_return = None, mean_episode_step = 643.62, total_loss = 341.9, pg_loss = 180.84, baseline_loss = 167.32, entropy_loss = -6.261, learner_queue_size = 18, _tick = 46084, _time = 1.654e+09, train_seconds = 2.1039e+04)
[2022-05-31 20:01:05,690][root][INFO] - Step 138713600 @ 6648.3 SPS. Inference batcher size: 103. Learner queue size: 19. Other stats: (step = 138713600, mean_episode_return = 392.77, mean_episode_step = 570.95, total_loss = 175.43, pg_loss = 46.652, baseline_loss = 134.33, entropy_loss = -5.5472, learner_queue_size = 25, _tick = 46097, _time = 1.654e+09, train_seconds = 2.1044e+04)
[2022-05-31 20:01:10,694][root][INFO] - Step 138746880 @ 6650.7 SPS. Inference batcher size: 113. Learner queue size: 9. Other stats: (step = 138746880, mean_episode_return = 258.92, mean_episode_step = 586.84, total_loss = 30.262, pg_loss = -109.8, baseline_loss = 145.76, entropy_loss = -5.7012, learner_queue_size = 15, _tick = 46110, _time = 1.654e+09, train_seconds = 2.1049e+04)
[2022-05-31 20:01:15,701][root][INFO] - Step 138780160 @ 6647.0 SPS. Inference batcher size: 18. Learner queue size: 8. Other stats: (step = 138780160, mean_episode_return = 281.56, mean_episode_step = 653.6, total_loss = -71.97, pg_loss = -245.39, baseline_loss = 180.06, entropy_loss = -6.634, learner_queue_size = 22, _tick = 46123, _time = 1.654e+09, train_seconds = 2.1054e+04)
[2022-05-31 20:01:20,706][root][INFO] - Step 138813440 @ 6649.0 SPS. Inference batcher size: 143. Learner queue size: 30. Other stats: (step = 138813440, mean_episode_return = 318.02, mean_episode_step = 644.75, total_loss = 64.147, pg_loss = -135.86, baseline_loss = 206.19, entropy_loss = -6.1814, learner_queue_size = 23, _tick = 46135, _time = 1.654e+09, train_seconds = 2.1059e+04)
[2022-05-31 20:01:25,712][root][INFO] - Step 138844160 @ 6136.6 SPS. Inference batcher size: 135. Learner queue size: 19. Other stats: (step = 138844160, mean_episode_return = 149.51, mean_episode_step = 653.03, total_loss = 249.09, pg_loss = 94.904, baseline_loss = 160.14, entropy_loss = -5.9573, learner_queue_size = 20, _tick = 46146, _time = 1.654e+09, train_seconds = 2.1064e+04)
[2022-05-31 20:01:30,719][root][INFO] - Step 138877440 @ 6647.3 SPS. Inference batcher size: 27. Learner queue size: 14. Other stats: (step = 138877440, mean_episode_return = 359.83, mean_episode_step = 724.09, total_loss = -7.5969, pg_loss = -236.41, baseline_loss = 235.31, entropy_loss = -6.4941, learner_queue_size = 13, _tick = 46157, _time = 1.654e+09, train_seconds = 2.1069e+04)
[2022-05-31 20:01:35,725][root][INFO] - Step 138910720 @ 6647.5 SPS. Inference batcher size: 78. Learner queue size: 8. Other stats: (step = 138910720, mean_episode_return = 365.81, mean_episode_step = 633.55, total_loss = 269.64, pg_loss = 171.18, baseline_loss = 104.76, entropy_loss = -6.2994, learner_queue_size = 19, _tick = 46169, _time = 1.654e+09, train_seconds = 2.1074e+04)
[2022-05-31 20:01:40,730][root][INFO] - Step 138944000 @ 6649.5 SPS. Inference batcher size: 142. Learner queue size: 14. Other stats: (step = 138944000, mean_episode_return = 233.64, mean_episode_step = 588.33, total_loss = 297.67, pg_loss = 48.79, baseline_loss = 254.24, entropy_loss = -5.3588, learner_queue_size = 24, _tick = 46179, _time = 1.654e+09, train_seconds = 2.1079e+04)
[2022-05-31 20:01:45,734][root][INFO] - Step 138977280 @ 6650.5 SPS. Inference batcher size: 51. Learner queue size: 5. Other stats: (step = 138977280, mean_episode_return = None, mean_episode_step = 749.03, total_loss = 367.73, pg_loss = 167.94, baseline_loss = 205.62, entropy_loss = -5.8313, learner_queue_size = 32, _tick = 46189, _time = 1.654e+09, train_seconds = 2.1084e+04)
[2022-05-31 20:01:50,738][root][INFO] - Step 139010560 @ 6650.8 SPS. Inference batcher size: 172. Learner queue size: 3. Other stats: (step = 139010560, mean_episode_return = 522.27, mean_episode_step = 703.5, total_loss = -196.56, pg_loss = -276.04, baseline_loss = 85.191, entropy_loss = -5.7141, learner_queue_size = 18, _tick = 46200, _time = 1.654e+09, train_seconds = 2.1089e+04)
[2022-05-31 20:01:55,742][root][INFO] - Step 139043840 @ 6650.7 SPS. Inference batcher size: 73. Learner queue size: 23. Other stats: (step = 139043840, mean_episode_return = 279.6, mean_episode_step = 647.21, total_loss = 159.69, pg_loss = 27.237, baseline_loss = 137.89, entropy_loss = -5.4415, learner_queue_size = 18, _tick = 46213, _time = 1.654e+09, train_seconds = 2.1094e+04)
[2022-05-31 20:02:00,746][root][INFO] - Step 139077120 @ 6650.7 SPS. Inference batcher size: 124. Learner queue size: 24. Other stats: (step = 139077120, mean_episode_return = 394.98, mean_episode_step = 716.52, total_loss = -23.522, pg_loss = -134.39, baseline_loss = 117.05, entropy_loss = -6.1834, learner_queue_size = 24, _tick = 46225, _time = 1.654e+09, train_seconds = 2.1099e+04)
[2022-05-31 20:02:05,750][root][INFO] - Step 139110400 @ 6650.6 SPS. Inference batcher size: 110. Learner queue size: 26. Other stats: (step = 139110400, mean_episode_return = 194.22, mean_episode_step = 797.88, total_loss = 4.5284, pg_loss = -54.727, baseline_loss = 65.731, entropy_loss = -6.4758, learner_queue_size = 19, _tick = 46237, _time = 1.654e+09, train_seconds = 2.1104e+04)
[2022-05-31 20:02:10,756][root][INFO] - Step 139141120 @ 6136.7 SPS. Inference batcher size: 123. Learner queue size: 15. Other stats: (step = 139141120, mean_episode_return = 12.17, mean_episode_step = 628.19, total_loss = -118.2, pg_loss = -163.35, baseline_loss = 51.118, entropy_loss = -5.9642, learner_queue_size = 23, _tick = 46248, _time = 1.654e+09, train_seconds = 2.1109e+04)
[2022-05-31 20:02:15,758][root][INFO] - Step 139174400 @ 6653.3 SPS. Inference batcher size: 132. Learner queue size: 15. Other stats: (step = 139174400, mean_episode_return = 376.78, mean_episode_step = 607.13, total_loss = 165.04, pg_loss = -281.76, baseline_loss = 452.12, entropy_loss = -5.3208, learner_queue_size = 13, _tick = 46259, _time = 1.654e+09, train_seconds = 2.1114e+04)
[2022-05-31 20:02:20,763][root][INFO] - Step 139207680 @ 6649.2 SPS. Inference batcher size: 89. Learner queue size: 11. Other stats: (step = 139207680, mean_episode_return = 100.82, mean_episode_step = 567.38, total_loss = 416.37, pg_loss = 224.52, baseline_loss = 197.43, entropy_loss = -5.5751, learner_queue_size = 24, _tick = 46272, _time = 1.654e+09, train_seconds = 2.1119e+04)
[2022-05-31 20:02:25,770][root][INFO] - Step 139240960 @ 6646.9 SPS. Inference batcher size: 111. Learner queue size: 5. Other stats: (step = 139240960, mean_episode_return = 431.34, mean_episode_step = 635.3, total_loss = -91.967, pg_loss = -192.0, baseline_loss = 106.03, entropy_loss = -6.0005, learner_queue_size = 17, _tick = 46282, _time = 1.654e+09, train_seconds = 2.1124e+04)
[2022-05-31 20:02:30,774][root][INFO] - Step 139274240 @ 6650.6 SPS. Inference batcher size: 159. Learner queue size: 8. Other stats: (step = 139274240, mean_episode_return = 228.53, mean_episode_step = 725.0, total_loss = -23.057, pg_loss = -70.161, baseline_loss = 53.299, entropy_loss = -6.1959, learner_queue_size = 19, _tick = 46293, _time = 1.654e+09, train_seconds = 2.113e+04)
[2022-05-31 20:02:35,778][root][INFO] - Step 139307520 @ 6650.7 SPS. Inference batcher size: 78. Learner queue size: 30. Other stats: (step = 139307520, mean_episode_return = 304.04, mean_episode_step = 583.32, total_loss = 42.725, pg_loss = -23.622, baseline_loss = 72.277, entropy_loss = -5.9292, learner_queue_size = 30, _tick = 46305, _time = 1.654e+09, train_seconds = 2.1134e+04)
[2022-05-31 20:02:40,782][root][INFO] - Step 139338240 @ 6139.1 SPS. Inference batcher size: 14. Learner queue size: 21. Other stats: (step = 139338240, mean_episode_return = 212.46, mean_episode_step = 730.39, total_loss = 218.79, pg_loss = 143.3, baseline_loss = 81.527, entropy_loss = -6.0359, learner_queue_size = 19, _tick = 46316, _time = 1.654e+09, train_seconds = 2.114e+04)
[2022-05-31 20:02:45,789][root][INFO] - Step 139371520 @ 6647.3 SPS. Inference batcher size: 151. Learner queue size: 24. Other stats: (step = 139371520, mean_episode_return = None, mean_episode_step = 591.06, total_loss = -180.54, pg_loss = -242.73, baseline_loss = 68.316, entropy_loss = -6.1262, learner_queue_size = 24, _tick = 46328, _time = 1.654e+09, train_seconds = 2.1144e+04)
[2022-05-31 20:02:50,795][root][INFO] - Step 139404800 @ 6648.0 SPS. Inference batcher size: 130. Learner queue size: 8. Other stats: (step = 139404800, mean_episode_return = 302.71, mean_episode_step = 645.02, total_loss = 89.339, pg_loss = 5.5412, baseline_loss = 90.23, entropy_loss = -6.4326, learner_queue_size = 18, _tick = 46340, _time = 1.654e+09, train_seconds = 2.115e+04)
[2022-05-31 20:02:55,798][root][INFO] - Step 139438080 @ 6651.4 SPS. Inference batcher size: 103. Learner queue size: 15. Other stats: (step = 139438080, mean_episode_return = 260.18, mean_episode_step = 690.18, total_loss = -22.041, pg_loss = -77.916, baseline_loss = 61.819, entropy_loss = -5.9432, learner_queue_size = 18, _tick = 46351, _time = 1.654e+09, train_seconds = 2.1154e+04)
[2022-05-31 20:03:00,802][root][INFO] - Step 139471360 @ 6650.8 SPS. Inference batcher size: 165. Learner queue size: 14. Other stats: (step = 139471360, mean_episode_return = 86.42, mean_episode_step = 642.92, total_loss = -126.48, pg_loss = -157.62, baseline_loss = 37.803, entropy_loss = -6.6558, learner_queue_size = 14, _tick = 46363, _time = 1.654e+09, train_seconds = 2.116e+04)
[2022-05-31 20:03:05,806][root][INFO] - Step 139504640 @ 6650.6 SPS. Inference batcher size: 76. Learner queue size: 5. Other stats: (step = 139504640, mean_episode_return = 188.32, mean_episode_step = 659.34, total_loss = 28.629, pg_loss = 6.8259, baseline_loss = 28.422, entropy_loss = -6.619, learner_queue_size = 21, _tick = 46376, _time = 1.654e+09, train_seconds = 2.1164e+04)
[2022-05-31 20:03:10,810][root][INFO] - Step 139537920 @ 6650.7 SPS. Inference batcher size: 165. Learner queue size: 18. Other stats: (step = 139537920, mean_episode_return = 211.93, mean_episode_step = 734.99, total_loss = 726.12, pg_loss = 496.4, baseline_loss = 235.86, entropy_loss = -6.1464, learner_queue_size = 16, _tick = 46387, _time = 1.654e+09, train_seconds = 2.117e+04)
[2022-05-31 20:03:15,814][root][INFO] - Step 139571200 @ 6650.7 SPS. Inference batcher size: 64. Learner queue size: 0. Other stats: (step = 139571200, mean_episode_return = 318.15, mean_episode_step = 674.54, total_loss = 277.24, pg_loss = 150.63, baseline_loss = 132.76, entropy_loss = -6.1467, learner_queue_size = 22, _tick = 46399, _time = 1.654e+09, train_seconds = 2.1174e+04)
[2022-05-31 20:03:20,818][root][INFO] - Step 139604480 @ 6650.5 SPS. Inference batcher size: 16. Learner queue size: 5. Other stats: (step = 139604480, mean_episode_return = 217.23, mean_episode_step = 765.45, total_loss = -179.52, pg_loss = -247.51, baseline_loss = 74.267, entropy_loss = -6.2826, learner_queue_size = 14, _tick = 46411, _time = 1.654e+09, train_seconds = 2.118e+04)
[2022-05-31 20:03:25,822][root][INFO] - Step 139637760 @ 6650.8 SPS. Inference batcher size: 145. Learner queue size: 2. Other stats: (step = 139637760, mean_episode_return = 631.44, mean_episode_step = 715.32, total_loss = 97.39, pg_loss = -8.7182, baseline_loss = 112.16, entropy_loss = -6.0476, learner_queue_size = 26, _tick = 46423, _time = 1.654e+09, train_seconds = 2.1184e+04)
[2022-05-31 20:03:30,826][root][INFO] - Step 139671040 @ 6650.8 SPS. Inference batcher size: 95. Learner queue size: 22. Other stats: (step = 139671040, mean_episode_return = 244.73, mean_episode_step = 599.53, total_loss = 126.66, pg_loss = -15.901, baseline_loss = 148.29, entropy_loss = -5.7273, learner_queue_size = 11, _tick = 46435, _time = 1.654e+09, train_seconds = 2.119e+04)
[2022-05-31 20:03:35,830][root][INFO] - Step 139704320 @ 6650.6 SPS. Inference batcher size: 105. Learner queue size: 30. Other stats: (step = 139704320, mean_episode_return = 306.81, mean_episode_step = 611.76, total_loss = 273.13, pg_loss = -85.5, baseline_loss = 364.28, entropy_loss = -5.6463, learner_queue_size = 20, _tick = 46448, _time = 1.654e+09, train_seconds = 2.1194e+04)
[2022-05-31 20:03:40,836][root][INFO] - Step 139735040 @ 6136.1 SPS. Inference batcher size: 154. Learner queue size: 14. Other stats: (step = 139735040, mean_episode_return = 190.12, mean_episode_step = 672.69, total_loss = 165.93, pg_loss = 73.174, baseline_loss = 98.615, entropy_loss = -5.8549, learner_queue_size = 13, _tick = 46459, _time = 1.654e+09, train_seconds = 2.12e+04)
[2022-05-31 20:03:45,842][root][INFO] - Step 139770880 @ 7160.0 SPS. Inference batcher size: 143. Learner queue size: 30. Other stats: (step = 139770880, mean_episode_return = 102.77, mean_episode_step = 729.93, total_loss = -124.5, pg_loss = -572.2, baseline_loss = 453.47, entropy_loss = -5.7615, learner_queue_size = 27, _tick = 46472, _time = 1.654e+09, train_seconds = 2.1204e+04)
[2022-05-31 20:03:50,846][root][INFO] - Step 139804160 @ 6650.8 SPS. Inference batcher size: 136. Learner queue size: 19. Other stats: (step = 139804160, mean_episode_return = 193.82, mean_episode_step = 699.65, total_loss = 115.66, pg_loss = -100.29, baseline_loss = 221.53, entropy_loss = -5.5721, learner_queue_size = 19, _tick = 46483, _time = 1.654e+09, train_seconds = 2.121e+04)
[2022-05-31 20:03:55,852][root][INFO] - Step 139834880 @ 6136.4 SPS. Inference batcher size: 97. Learner queue size: 11. Other stats: (step = 139834880, mean_episode_return = 127.7, mean_episode_step = 768.48, total_loss = -161.27, pg_loss = -196.67, baseline_loss = 41.647, entropy_loss = -6.2446, learner_queue_size = 19, _tick = 46494, _time = 1.654e+09, train_seconds = 2.1214e+04)
[2022-05-31 20:04:00,858][root][INFO] - Step 139868160 @ 6648.1 SPS. Inference batcher size: 122. Learner queue size: 16. Other stats: (step = 139868160, mean_episode_return = 240.34, mean_episode_step = 762.72, total_loss = 245.53, pg_loss = 178.78, baseline_loss = 73.163, entropy_loss = -6.4182, learner_queue_size = 25, _tick = 46506, _time = 1.654e+09, train_seconds = 2.122e+04)
[2022-05-31 20:04:05,862][root][INFO] - Step 139901440 @ 6650.8 SPS. Inference batcher size: 94. Learner queue size: 2. Other stats: (step = 139901440, mean_episode_return = 127.76, mean_episode_step = 609.32, total_loss = 210.67, pg_loss = -63.001, baseline_loss = 279.16, entropy_loss = -5.4882, learner_queue_size = 27, _tick = 46517, _time = 1.654e+09, train_seconds = 2.1224e+04)
[2022-05-31 20:04:10,866][root][INFO] - Step 139934720 @ 6650.8 SPS. Inference batcher size: 132. Learner queue size: 7. Other stats: (step = 139934720, mean_episode_return = 176.32, mean_episode_step = 670.58, total_loss = -151.58, pg_loss = -348.25, baseline_loss = 202.57, entropy_loss = -5.8983, learner_queue_size = 18, _tick = 46530, _time = 1.654e+09, train_seconds = 2.123e+04)
[2022-05-31 20:04:15,870][root][INFO] - Step 139968000 @ 6650.6 SPS. Inference batcher size: 101. Learner queue size: 5. Other stats: (step = 139968000, mean_episode_return = None, mean_episode_step = 667.16, total_loss = -12.231, pg_loss = -46.689, baseline_loss = 41.226, entropy_loss = -6.7687, learner_queue_size = 21, _tick = 46541, _time = 1.654e+09, train_seconds = 2.1235e+04)
[2022-05-31 20:04:20,875][root][INFO] - Step 140001280 @ 6650.1 SPS. Inference batcher size: 20. Learner queue size: 20. Other stats: (step = 140001280, mean_episode_return = 192.42, mean_episode_step = 660.04, total_loss = 247.65, pg_loss = 210.85, baseline_loss = 43.578, entropy_loss = -6.7788, learner_queue_size = 16, _tick = 46554, _time = 1.654e+09, train_seconds = 2.124e+04)
[2022-05-31 20:04:25,878][root][INFO] - Step 140034560 @ 6651.3 SPS. Inference batcher size: 1. Learner queue size: 29. Other stats: (step = 140034560, mean_episode_return = 233.13, mean_episode_step = 607.29, total_loss = -96.522, pg_loss = -117.01, baseline_loss = 26.245, entropy_loss = -5.7622, learner_queue_size = 28, _tick = 46564, _time = 1.654e+09, train_seconds = 2.1245e+04)
[2022-05-31 20:04:30,884][root][INFO] - Step 140065280 @ 6136.1 SPS. Inference batcher size: 113. Learner queue size: 20. Other stats: (step = 140065280, mean_episode_return = 244.07, mean_episode_step = 636.49, total_loss = -44.729, pg_loss = -49.139, baseline_loss = 10.808, entropy_loss = -6.3977, learner_queue_size = 24, _tick = 46576, _time = 1.654e+09, train_seconds = 2.125e+04)
[2022-05-31 20:04:35,890][root][INFO] - Step 140098560 @ 6648.0 SPS. Inference batcher size: 107. Learner queue size: 15. Other stats: (step = 140098560, mean_episode_return = 221.24, mean_episode_step = 746.31, total_loss = 141.54, pg_loss = 99.757, baseline_loss = 48.244, entropy_loss = -6.4565, learner_queue_size = 14, _tick = 46585, _time = 1.654e+09, train_seconds = 2.1255e+04)
[2022-05-31 20:04:40,894][root][INFO] - Step 140131840 @ 6651.2 SPS. Inference batcher size: 106. Learner queue size: 11. Other stats: (step = 140131840, mean_episode_return = 220.86, mean_episode_step = 623.57, total_loss = -100.21, pg_loss = -139.98, baseline_loss = 46.098, entropy_loss = -6.3233, learner_queue_size = 16, _tick = 46594, _time = 1.654e+09, train_seconds = 2.126e+04)
[2022-05-31 20:04:45,900][root][INFO] - Step 140165120 @ 6648.0 SPS. Inference batcher size: 110. Learner queue size: 1. Other stats: (step = 140165120, mean_episode_return = 81.565, mean_episode_step = 597.99, total_loss = 253.89, pg_loss = 36.032, baseline_loss = 223.54, entropy_loss = -5.6785, learner_queue_size = 20, _tick = 46606, _time = 1.654e+09, train_seconds = 2.1265e+04)
[2022-05-31 20:04:50,902][root][INFO] - Step 140198400 @ 6653.4 SPS. Inference batcher size: 163. Learner queue size: 1. Other stats: (step = 140198400, mean_episode_return = 193.53, mean_episode_step = 665.43, total_loss = -76.504, pg_loss = -140.2, baseline_loss = 69.892, entropy_loss = -6.1922, learner_queue_size = 26, _tick = 46618, _time = 1.654e+09, train_seconds = 2.127e+04)
[2022-05-31 20:04:55,906][root][INFO] - Step 140229120 @ 6139.0 SPS. Inference batcher size: 89. Learner queue size: 24. Other stats: (step = 140229120, mean_episode_return = 89.012, mean_episode_step = 704.74, total_loss = -26.244, pg_loss = -69.115, baseline_loss = 49.1, entropy_loss = -6.2296, learner_queue_size = 18, _tick = 46629, _time = 1.654e+09, train_seconds = 2.1275e+04)
[2022-05-31 20:05:00,910][root][INFO] - Step 140264960 @ 7162.4 SPS. Inference batcher size: 147. Learner queue size: 24. Other stats: (step = 140264960, mean_episode_return = 452.66, mean_episode_step = 668.29, total_loss = 97.798, pg_loss = 81.922, baseline_loss = 22.472, entropy_loss = -6.5954, learner_queue_size = 16, _tick = 46642, _time = 1.654e+09, train_seconds = 2.128e+04)
[2022-05-31 20:05:05,914][root][INFO] - Step 140298240 @ 6650.4 SPS. Inference batcher size: 93. Learner queue size: 26. Other stats: (step = 140298240, mean_episode_return = 245.56, mean_episode_step = 629.14, total_loss = 51.114, pg_loss = 28.236, baseline_loss = 28.567, entropy_loss = -5.6886, learner_queue_size = 16, _tick = 46655, _time = 1.654e+09, train_seconds = 2.1285e+04)
[2022-05-31 20:05:10,920][root][INFO] - Step 140328960 @ 6136.6 SPS. Inference batcher size: 123. Learner queue size: 17. Other stats: (step = 140328960, mean_episode_return = 221.54, mean_episode_step = 742.67, total_loss = 194.74, pg_loss = -44.437, baseline_loss = 244.99, entropy_loss = -5.8161, learner_queue_size = 18, _tick = 46665, _time = 1.654e+09, train_seconds = 2.129e+04)
[2022-05-31 20:05:15,926][root][INFO] - Step 140362240 @ 6647.9 SPS. Inference batcher size: 94. Learner queue size: 10. Other stats: (step = 140362240, mean_episode_return = 158.58, mean_episode_step = 676.7, total_loss = 83.367, pg_loss = -74.946, baseline_loss = 164.17, entropy_loss = -5.8602, learner_queue_size = 21, _tick = 46676, _time = 1.654e+09, train_seconds = 2.1295e+04)
[2022-05-31 20:05:20,932][root][INFO] - Step 140395520 @ 6648.3 SPS. Inference batcher size: 140. Learner queue size: 20. Other stats: (step = 140395520, mean_episode_return = 390.12, mean_episode_step = 742.71, total_loss = 35.964, pg_loss = -43.394, baseline_loss = 85.625, entropy_loss = -6.2671, learner_queue_size = 20, _tick = 46688, _time = 1.654e+09, train_seconds = 2.13e+04)
[2022-05-31 20:05:25,938][root][INFO] - Step 140428800 @ 6648.2 SPS. Inference batcher size: 80. Learner queue size: 14. Other stats: (step = 140428800, mean_episode_return = 167.1, mean_episode_step = 724.33, total_loss = 670.01, pg_loss = 447.86, baseline_loss = 228.03, entropy_loss = -5.8697, learner_queue_size = 21, _tick = 46700, _time = 1.654e+09, train_seconds = 2.1305e+04)
[2022-05-31 20:05:30,944][root][INFO] - Step 140462080 @ 6648.2 SPS. Inference batcher size: 139. Learner queue size: 7. Other stats: (step = 140462080, mean_episode_return = 214.71, mean_episode_step = 689.88, total_loss = 24.799, pg_loss = -115.65, baseline_loss = 145.93, entropy_loss = -5.4854, learner_queue_size = 10, _tick = 46713, _time = 1.654e+09, train_seconds = 2.131e+04)
[2022-05-31 20:05:35,950][root][INFO] - Step 140495360 @ 6648.2 SPS. Inference batcher size: 49. Learner queue size: 2. Other stats: (step = 140495360, mean_episode_return = 81.301, mean_episode_step = 702.6, total_loss = -41.965, pg_loss = -86.466, baseline_loss = 50.48, entropy_loss = -5.9794, learner_queue_size = 12, _tick = 46724, _time = 1.654e+09, train_seconds = 2.1315e+04)
[2022-05-31 20:05:40,955][root][INFO] - Step 140528640 @ 6648.5 SPS. Inference batcher size: 46. Learner queue size: 11. Other stats: (step = 140528640, mean_episode_return = 352.28, mean_episode_step = 833.41, total_loss = 97.39, pg_loss = 31.582, baseline_loss = 72.471, entropy_loss = -6.6634, learner_queue_size = 20, _tick = 46735, _time = 1.654e+09, train_seconds = 2.132e+04)
[2022-05-31 20:05:45,958][root][INFO] - Step 140561920 @ 6652.4 SPS. Inference batcher size: 34. Learner queue size: 11. Other stats: (step = 140561920, mean_episode_return = 67.325, mean_episode_step = 771.85, total_loss = 409.52, pg_loss = 224.38, baseline_loss = 191.7, entropy_loss = -6.5626, learner_queue_size = 24, _tick = 46746, _time = 1.654e+09, train_seconds = 2.1325e+04)
[2022-05-31 20:05:50,962][root][INFO] - Step 140595200 @ 6650.7 SPS. Inference batcher size: 132. Learner queue size: 2. Other stats: (step = 140595200, mean_episode_return = 638.21, mean_episode_step = 631.26, total_loss = 240.3, pg_loss = 173.58, baseline_loss = 73.119, entropy_loss = -6.4013, learner_queue_size = 11, _tick = 46758, _time = 1.654e+09, train_seconds = 2.133e+04)
[2022-05-31 20:05:55,966][root][INFO] - Step 140628480 @ 6650.7 SPS. Inference batcher size: 125. Learner queue size: 1. Other stats: (step = 140628480, mean_episode_return = 49.601, mean_episode_step = 790.77, total_loss = -29.07, pg_loss = -33.902, baseline_loss = 12.518, entropy_loss = -7.6864, learner_queue_size = 28, _tick = 46769, _time = 1.654e+09, train_seconds = 2.1335e+04)
[2022-05-31 20:06:00,972][root][INFO] - Step 140661760 @ 6648.0 SPS. Inference batcher size: 158. Learner queue size: 3. Other stats: (step = 140661760, mean_episode_return = 348.51, mean_episode_step = 695.38, total_loss = 131.1, pg_loss = 119.18, baseline_loss = 19.647, entropy_loss = -7.7301, learner_queue_size = 22, _tick = 46782, _time = 1.654e+09, train_seconds = 2.134e+04)
[2022-05-31 20:06:05,978][root][INFO] - Step 140695040 @ 6648.0 SPS. Inference batcher size: 146. Learner queue size: 5. Other stats: (step = 140695040, mean_episode_return = None, mean_episode_step = 756.94, total_loss = -20.882, pg_loss = -23.187, baseline_loss = 9.6755, entropy_loss = -7.3699, learner_queue_size = 11, _tick = 46792, _time = 1.654e+09, train_seconds = 2.1345e+04)
[2022-05-31 20:06:10,982][root][INFO] - Step 140728320 @ 6650.8 SPS. Inference batcher size: 114. Learner queue size: 30. Other stats: (step = 140728320, mean_episode_return = 444.49, mean_episode_step = 887.98, total_loss = 75.217, pg_loss = 60.618, baseline_loss = 21.824, entropy_loss = -7.2243, learner_queue_size = 16, _tick = 46803, _time = 1.654e+09, train_seconds = 2.135e+04)
[2022-05-31 20:06:15,986][root][INFO] - Step 140761600 @ 6650.6 SPS. Inference batcher size: 104. Learner queue size: 24. Other stats: (step = 140761600, mean_episode_return = 286.11, mean_episode_step = 721.05, total_loss = 318.9, pg_loss = 232.23, baseline_loss = 92.75, entropy_loss = -6.0849, learner_queue_size = 16, _tick = 46813, _time = 1.654e+09, train_seconds = 2.1355e+04)
[2022-05-31 20:06:20,990][root][INFO] - Step 140794880 @ 6650.7 SPS. Inference batcher size: 105. Learner queue size: 1. Other stats: (step = 140794880, mean_episode_return = None, mean_episode_step = 851.53, total_loss = -45.142, pg_loss = -82.481, baseline_loss = 43.445, entropy_loss = -6.1059, learner_queue_size = 30, _tick = 46823, _time = 1.654e+09, train_seconds = 2.136e+04)
[2022-05-31 20:06:25,996][root][INFO] - Step 140825600 @ 6136.9 SPS. Inference batcher size: 129. Learner queue size: 22. Other stats: (step = 140825600, mean_episode_return = 104.06, mean_episode_step = 844.58, total_loss = -73.842, pg_loss = -154.7, baseline_loss = 87.161, entropy_loss = -6.3076, learner_queue_size = 17, _tick = 46834, _time = 1.654e+09, train_seconds = 2.1365e+04)
[2022-05-31 20:06:30,998][root][INFO] - Step 140861440 @ 7164.9 SPS. Inference batcher size: 80. Learner queue size: 18. Other stats: (step = 140861440, mean_episode_return = None, mean_episode_step = 928.91, total_loss = 71.65, pg_loss = 13.827, baseline_loss = 64.13, entropy_loss = -6.3062, learner_queue_size = 18, _tick = 46844, _time = 1.654e+09, train_seconds = 2.137e+04)
[2022-05-31 20:06:36,004][root][INFO] - Step 140892160 @ 6136.7 SPS. Inference batcher size: 55. Learner queue size: 21. Other stats: (step = 140892160, mean_episode_return = None, mean_episode_step = 902.97, total_loss = 407.94, pg_loss = 269.35, baseline_loss = 144.97, entropy_loss = -6.3802, learner_queue_size = 20, _tick = 46854, _time = 1.654e+09, train_seconds = 2.1375e+04)
[2022-05-31 20:06:41,010][root][INFO] - Step 140925440 @ 6648.1 SPS. Inference batcher size: 101. Learner queue size: 19. Other stats: (step = 140925440, mean_episode_return = 307.11, mean_episode_step = 809.88, total_loss = -28.302, pg_loss = -62.706, baseline_loss = 40.607, entropy_loss = -6.2028, learner_queue_size = 21, _tick = 46867, _time = 1.654e+09, train_seconds = 2.138e+04)
[2022-05-31 20:06:46,014][root][INFO] - Step 140958720 @ 6650.6 SPS. Inference batcher size: 170. Learner queue size: 18. Other stats: (step = 140958720, mean_episode_return = 170.16, mean_episode_step = 730.03, total_loss = 119.81, pg_loss = 28.928, baseline_loss = 96.967, entropy_loss = -6.0862, learner_queue_size = 20, _tick = 46880, _time = 1.654e+09, train_seconds = 2.1385e+04)
[2022-05-31 20:06:51,018][root][INFO] - Step 140992000 @ 6650.7 SPS. Inference batcher size: 174. Learner queue size: 7. Other stats: (step = 140992000, mean_episode_return = 189.56, mean_episode_step = 794.76, total_loss = 602.4, pg_loss = 433.5, baseline_loss = 175.38, entropy_loss = -6.4787, learner_queue_size = 23, _tick = 46891, _time = 1.654e+09, train_seconds = 2.139e+04)
[2022-05-31 20:06:56,022][root][INFO] - Step 141025280 @ 6650.5 SPS. Inference batcher size: 117. Learner queue size: 14. Other stats: (step = 141025280, mean_episode_return = None, mean_episode_step = 865.81, total_loss = -72.033, pg_loss = -87.735, baseline_loss = 23.071, entropy_loss = -7.3688, learner_queue_size = 13, _tick = 46902, _time = 1.654e+09, train_seconds = 2.1395e+04)
[2022-05-31 20:07:01,026][root][INFO] - Step 141058560 @ 6650.8 SPS. Inference batcher size: 138. Learner queue size: 5. Other stats: (step = 141058560, mean_episode_return = 230.15, mean_episode_step = 916.33, total_loss = -75.75, pg_loss = -88.132, baseline_loss = 19.961, entropy_loss = -7.5784, learner_queue_size = 22, _tick = 46915, _time = 1.654e+09, train_seconds = 2.14e+04)
[2022-05-31 20:07:06,030][root][INFO] - Step 141091840 @ 6650.6 SPS. Inference batcher size: 28. Learner queue size: 3. Other stats: (step = 141091840, mean_episode_return = 361.63, mean_episode_step = 733.44, total_loss = 315.37, pg_loss = 273.25, baseline_loss = 49.452, entropy_loss = -7.3325, learner_queue_size = 20, _tick = 46925, _time = 1.654e+09, train_seconds = 2.1405e+04)
[2022-05-31 20:07:11,034][root][INFO] - Step 141122560 @ 6139.1 SPS. Inference batcher size: 110. Learner queue size: 20. Other stats: (step = 141122560, mean_episode_return = 89.696, mean_episode_step = 707.86, total_loss = 73.385, pg_loss = 47.491, baseline_loss = 32.705, entropy_loss = -6.8109, learner_queue_size = 20, _tick = 46936, _time = 1.654e+09, train_seconds = 2.141e+04)
[2022-05-31 20:07:16,040][root][INFO] - Step 141155840 @ 6648.0 SPS. Inference batcher size: 121. Learner queue size: 10. Other stats: (step = 141155840, mean_episode_return = None, mean_episode_step = 906.19, total_loss = 97.928, pg_loss = 41.895, baseline_loss = 62.646, entropy_loss = -6.6132, learner_queue_size = 24, _tick = 46946, _time = 1.654e+09, train_seconds = 2.1415e+04)
[2022-05-31 20:07:21,046][root][INFO] - Step 141189120 @ 6648.0 SPS. Inference batcher size: 171. Learner queue size: 9. Other stats: (step = 141189120, mean_episode_return = 224.17, mean_episode_step = 848.26, total_loss = -177.42, pg_loss = -228.0, baseline_loss = 57.114, entropy_loss = -6.5302, learner_queue_size = 23, _tick = 46957, _time = 1.654e+09, train_seconds = 2.142e+04)
[2022-05-31 20:07:26,050][root][INFO] - Step 141222400 @ 6650.9 SPS. Inference batcher size: 167. Learner queue size: 2. Other stats: (step = 141222400, mean_episode_return = 392.74, mean_episode_step = 596.84, total_loss = 38.235, pg_loss = -146.63, baseline_loss = 190.26, entropy_loss = -5.3965, learner_queue_size = 15, _tick = 46970, _time = 1.654e+09, train_seconds = 2.1425e+04)
[2022-05-31 20:07:31,054][root][INFO] - Step 141255680 @ 6650.6 SPS. Inference batcher size: 145. Learner queue size: 28. Other stats: (step = 141255680, mean_episode_return = 265.32, mean_episode_step = 988.41, total_loss = -216.93, pg_loss = -323.23, baseline_loss = 112.51, entropy_loss = -6.2097, learner_queue_size = 17, _tick = 46982, _time = 1.654e+09, train_seconds = 2.143e+04)
[2022-05-31 20:07:36,058][root][INFO] - Step 141288960 @ 6650.8 SPS. Inference batcher size: 160. Learner queue size: 29. Other stats: (step = 141288960, mean_episode_return = 186.56, mean_episode_step = 478.0, total_loss = 195.18, pg_loss = 60.342, baseline_loss = 140.61, entropy_loss = -5.7665, learner_queue_size = 20, _tick = 46995, _time = 1.654e+09, train_seconds = 2.1435e+04)
[2022-05-31 20:07:41,064][root][INFO] - Step 141319680 @ 6136.5 SPS. Inference batcher size: 9. Learner queue size: 22. Other stats: (step = 141319680, mean_episode_return = 278.72, mean_episode_step = 683.74, total_loss = 1043.6, pg_loss = 643.8, baseline_loss = 406.07, entropy_loss = -6.2311, learner_queue_size = 21, _tick = 47007, _time = 1.654e+09, train_seconds = 2.144e+04)
[2022-05-31 20:07:46,070][root][INFO] - Step 141352960 @ 6647.5 SPS. Inference batcher size: 96. Learner queue size: 17. Other stats: (step = 141352960, mean_episode_return = 212.95, mean_episode_step = 807.77, total_loss = 219.6, pg_loss = 120.84, baseline_loss = 105.16, entropy_loss = -6.4062, learner_queue_size = 17, _tick = 47018, _time = 1.654e+09, train_seconds = 2.1445e+04)
[2022-05-31 20:07:51,076][root][INFO] - Step 141386240 @ 6648.0 SPS. Inference batcher size: 107. Learner queue size: 17. Other stats: (step = 141386240, mean_episode_return = 385.05, mean_episode_step = 707.01, total_loss = 272.41, pg_loss = 133.73, baseline_loss = 145.3, entropy_loss = -6.6151, learner_queue_size = 25, _tick = 47031, _time = 1.654e+09, train_seconds = 2.145e+04)
[2022-05-31 20:07:56,083][root][INFO] - Step 141419520 @ 6648.0 SPS. Inference batcher size: 127. Learner queue size: 5. Other stats: (step = 141419520, mean_episode_return = 8.7697, mean_episode_step = 1001.2, total_loss = -28.615, pg_loss = -130.17, baseline_loss = 107.81, entropy_loss = -6.2585, learner_queue_size = 12, _tick = 47043, _time = 1.654e+09, train_seconds = 2.1455e+04)
[2022-05-31 20:08:01,090][root][INFO] - Step 141452800 @ 6646.4 SPS. Inference batcher size: 91. Learner queue size: 7. Other stats: (step = 141452800, mean_episode_return = 253.16, mean_episode_step = 807.15, total_loss = 97.546, pg_loss = 16.164, baseline_loss = 87.641, entropy_loss = -6.2595, learner_queue_size = 21, _tick = 47055, _time = 1.654e+09, train_seconds = 2.146e+04)
[2022-05-31 20:08:06,094][root][INFO] - Step 141486080 @ 6650.4 SPS. Inference batcher size: 113. Learner queue size: 3. Other stats: (step = 141486080, mean_episode_return = 220.16, mean_episode_step = 690.02, total_loss = 610.84, pg_loss = 346.77, baseline_loss = 269.64, entropy_loss = -5.5774, learner_queue_size = 18, _tick = 47067, _time = 1.654e+09, train_seconds = 2.1465e+04)
[2022-05-31 20:08:11,098][root][INFO] - Step 141519360 @ 6650.7 SPS. Inference batcher size: 83. Learner queue size: 29. Other stats: (step = 141519360, mean_episode_return = 170.61, mean_episode_step = 646.33, total_loss = -291.58, pg_loss = -426.85, baseline_loss = 141.26, entropy_loss = -5.9875, learner_queue_size = 17, _tick = 47079, _time = 1.654e+09, train_seconds = 2.147e+04)
[2022-05-31 20:08:16,102][root][INFO] - Step 141552640 @ 6650.5 SPS. Inference batcher size: 7. Learner queue size: 26. Other stats: (step = 141552640, mean_episode_return = 273.58, mean_episode_step = 581.96, total_loss = 175.31, pg_loss = -42.154, baseline_loss = 223.94, entropy_loss = -6.4731, learner_queue_size = 26, _tick = 47092, _time = 1.654e+09, train_seconds = 2.1475e+04)
[2022-05-31 20:08:21,108][root][INFO] - Step 141583360 @ 6136.7 SPS. Inference batcher size: 53. Learner queue size: 15. Other stats: (step = 141583360, mean_episode_return = None, mean_episode_step = 584.81, total_loss = -59.707, pg_loss = -129.49, baseline_loss = 76.157, entropy_loss = -6.3692, learner_queue_size = 26, _tick = 47103, _time = 1.654e+09, train_seconds = 2.148e+04)
[2022-05-31 20:08:26,114][root][INFO] - Step 141616640 @ 6648.4 SPS. Inference batcher size: 136. Learner queue size: 24. Other stats: (step = 141616640, mean_episode_return = 107.03, mean_episode_step = 647.52, total_loss = 593.86, pg_loss = 496.21, baseline_loss = 103.66, entropy_loss = -6.0042, learner_queue_size = 23, _tick = 47114, _time = 1.654e+09, train_seconds = 2.1485e+04)
[2022-05-31 20:08:31,118][root][INFO] - Step 141649920 @ 6649.8 SPS. Inference batcher size: 1. Learner queue size: 18. Other stats: (step = 141649920, mean_episode_return = 295.9, mean_episode_step = 617.73, total_loss = 280.39, pg_loss = 68.129, baseline_loss = 218.41, entropy_loss = -6.1455, learner_queue_size = 13, _tick = 47125, _time = 1.654e+09, train_seconds = 2.149e+04)
[2022-05-31 20:08:36,122][root][INFO] - Step 141683200 @ 6651.3 SPS. Inference batcher size: 108. Learner queue size: 11. Other stats: (step = 141683200, mean_episode_return = 122.86, mean_episode_step = 784.43, total_loss = 64.096, pg_loss = 23.681, baseline_loss = 47.069, entropy_loss = -6.6537, learner_queue_size = 20, _tick = 47137, _time = 1.654e+09, train_seconds = 2.1495e+04)
[2022-05-31 20:08:41,128][root][INFO] - Step 141716480 @ 6648.1 SPS. Inference batcher size: 75. Learner queue size: 5. Other stats: (step = 141716480, mean_episode_return = 87.462, mean_episode_step = 583.14, total_loss = 126.36, pg_loss = 59.201, baseline_loss = 73.348, entropy_loss = -6.1862, learner_queue_size = 20, _tick = 47149, _time = 1.654e+09, train_seconds = 2.15e+04)
[2022-05-31 20:08:46,134][root][INFO] - Step 141749760 @ 6648.4 SPS. Inference batcher size: 108. Learner queue size: 0. Other stats: (step = 141749760, mean_episode_return = 111.61, mean_episode_step = 530.51, total_loss = 340.54, pg_loss = 203.62, baseline_loss = 142.83, entropy_loss = -5.9092, learner_queue_size = 16, _tick = 47162, _time = 1.654e+09, train_seconds = 2.1505e+04)
[2022-05-31 20:08:51,139][root][INFO] - Step 141783040 @ 6648.2 SPS. Inference batcher size: 143. Learner queue size: 6. Other stats: (step = 141783040, mean_episode_return = 218.72, mean_episode_step = 723.61, total_loss = -72.733, pg_loss = -174.08, baseline_loss = 108.0, entropy_loss = -6.644, learner_queue_size = 18, _tick = 47175, _time = 1.654e+09, train_seconds = 2.151e+04)
[2022-05-31 20:08:56,142][root][INFO] - Step 141816320 @ 6652.7 SPS. Inference batcher size: 141. Learner queue size: 31. Other stats: (step = 141816320, mean_episode_return = 261.92, mean_episode_step = 596.82, total_loss = 66.07, pg_loss = -19.305, baseline_loss = 91.462, entropy_loss = -6.0866, learner_queue_size = 20, _tick = 47188, _time = 1.654e+09, train_seconds = 2.1515e+04)
[2022-05-31 20:09:01,146][root][INFO] - Step 141849600 @ 6650.6 SPS. Inference batcher size: 59. Learner queue size: 27. Other stats: (step = 141849600, mean_episode_return = 288.94, mean_episode_step = 647.18, total_loss = 153.83, pg_loss = -14.576, baseline_loss = 174.67, entropy_loss = -6.2612, learner_queue_size = 16, _tick = 47200, _time = 1.654e+09, train_seconds = 2.152e+04)
[2022-05-31 20:09:06,150][root][INFO] - Step 141882880 @ 6650.7 SPS. Inference batcher size: 87. Learner queue size: 31. Other stats: (step = 141882880, mean_episode_return = None, mean_episode_step = 764.34, total_loss = -128.93, pg_loss = -140.99, baseline_loss = 18.674, entropy_loss = -6.62, learner_queue_size = 25, _tick = 47209, _time = 1.654e+09, train_seconds = 2.1525e+04)
[2022-05-31 20:09:11,154][root][INFO] - Step 141916160 @ 6650.7 SPS. Inference batcher size: 102. Learner queue size: 28. Other stats: (step = 141916160, mean_episode_return = 54.811, mean_episode_step = 620.34, total_loss = 49.064, pg_loss = -9.7419, baseline_loss = 64.781, entropy_loss = -5.9744, learner_queue_size = 18, _tick = 47222, _time = 1.654e+09, train_seconds = 2.153e+04)
[2022-05-31 20:09:16,158][root][INFO] - Step 141949440 @ 6650.7 SPS. Inference batcher size: 127. Learner queue size: 31. Other stats: (step = 141949440, mean_episode_return = 360.5, mean_episode_step = 566.7, total_loss = -26.813, pg_loss = -66.099, baseline_loss = 45.647, entropy_loss = -6.3605, learner_queue_size = 9, _tick = 47232, _time = 1.654e+09, train_seconds = 2.1535e+04)
[2022-05-31 20:09:21,163][root][INFO] - Step 141982720 @ 6648.5 SPS. Inference batcher size: 101. Learner queue size: 4. Other stats: (step = 141982720, mean_episode_return = 176.26, mean_episode_step = 609.91, total_loss = 333.96, pg_loss = 201.52, baseline_loss = 138.29, entropy_loss = -5.856, learner_queue_size = 18, _tick = 47242, _time = 1.654e+09, train_seconds = 2.154e+04)
[2022-05-31 20:09:26,166][root][INFO] - Step 142016000 @ 6652.8 SPS. Inference batcher size: 133. Learner queue size: 30. Other stats: (step = 142016000, mean_episode_return = 240.74, mean_episode_step = 681.88, total_loss = 323.32, pg_loss = 164.72, baseline_loss = 164.54, entropy_loss = -5.9356, learner_queue_size = 28, _tick = 47254, _time = 1.654e+09, train_seconds = 2.1545e+04)
[2022-05-31 20:09:31,170][root][INFO] - Step 142049280 @ 6650.7 SPS. Inference batcher size: 90. Learner queue size: 24. Other stats: (step = 142049280, mean_episode_return = 216.87, mean_episode_step = 705.7, total_loss = 8.7228, pg_loss = -237.05, baseline_loss = 251.5, entropy_loss = -5.7341, learner_queue_size = 20, _tick = 47266, _time = 1.654e+09, train_seconds = 2.155e+04)
[2022-05-31 20:09:36,174][root][INFO] - Step 142080000 @ 6139.0 SPS. Inference batcher size: 91. Learner queue size: 18. Other stats: (step = 142080000, mean_episode_return = 183.85, mean_episode_step = 697.53, total_loss = -17.285, pg_loss = -175.07, baseline_loss = 164.18, entropy_loss = -6.3889, learner_queue_size = 18, _tick = 47277, _time = 1.654e+09, train_seconds = 2.1555e+04)
[2022-05-31 20:09:41,178][root][INFO] - Step 142113280 @ 6650.8 SPS. Inference batcher size: 75. Learner queue size: 18. Other stats: (step = 142113280, mean_episode_return = 354.78, mean_episode_step = 518.46, total_loss = 203.47, pg_loss = 79.541, baseline_loss = 130.26, entropy_loss = -6.3296, learner_queue_size = 18, _tick = 47289, _time = 1.654e+09, train_seconds = 2.156e+04)
[2022-05-31 20:09:46,182][root][INFO] - Step 142146560 @ 6650.7 SPS. Inference batcher size: 169. Learner queue size: 8. Other stats: (step = 142146560, mean_episode_return = 234.85, mean_episode_step = 706.12, total_loss = 650.93, pg_loss = 486.93, baseline_loss = 170.37, entropy_loss = -6.3673, learner_queue_size = 23, _tick = 47300, _time = 1.654e+09, train_seconds = 2.1565e+04)
[2022-05-31 20:09:51,186][root][INFO] - Step 142179840 @ 6650.7 SPS. Inference batcher size: 90. Learner queue size: 21. Other stats: (step = 142179840, mean_episode_return = None, mean_episode_step = 709.28, total_loss = 132.37, pg_loss = -1.9943, baseline_loss = 140.88, entropy_loss = -6.5177, learner_queue_size = 11, _tick = 47310, _time = 1.654e+09, train_seconds = 2.157e+04)
[2022-05-31 20:09:56,190][root][INFO] - Step 142213120 @ 6650.6 SPS. Inference batcher size: 126. Learner queue size: 26. Other stats: (step = 142213120, mean_episode_return = 274.56, mean_episode_step = 740.15, total_loss = 573.14, pg_loss = 310.69, baseline_loss = 268.64, entropy_loss = -6.1868, learner_queue_size = 17, _tick = 47321, _time = 1.654e+09, train_seconds = 2.1575e+04)
[2022-05-31 20:10:01,194][root][INFO] - Step 142246400 @ 6650.7 SPS. Inference batcher size: 113. Learner queue size: 29. Other stats: (step = 142246400, mean_episode_return = 562.06, mean_episode_step = 850.3, total_loss = 9.1703, pg_loss = -186.67, baseline_loss = 201.71, entropy_loss = -5.8737, learner_queue_size = 19, _tick = 47334, _time = 1.654e+09, train_seconds = 2.158e+04)
[2022-05-31 20:10:06,200][root][INFO] - Step 142279680 @ 6648.0 SPS. Inference batcher size: 104. Learner queue size: 5. Other stats: (step = 142279680, mean_episode_return = 195.25, mean_episode_step = 674.31, total_loss = 176.46, pg_loss = 21.234, baseline_loss = 160.88, entropy_loss = -5.6525, learner_queue_size = 29, _tick = 47344, _time = 1.654e+09, train_seconds = 2.1585e+04)
[2022-05-31 20:10:11,202][root][INFO] - Step 142312960 @ 6653.5 SPS. Inference batcher size: 99. Learner queue size: 31. Other stats: (step = 142312960, mean_episode_return = 226.85, mean_episode_step = 765.99, total_loss = 268.62, pg_loss = 18.664, baseline_loss = 256.08, entropy_loss = -6.1251, learner_queue_size = 14, _tick = 47354, _time = 1.654e+09, train_seconds = 2.159e+04)
[2022-05-31 20:10:16,208][root][INFO] - Step 142346240 @ 6647.9 SPS. Inference batcher size: 32. Learner queue size: 4. Other stats: (step = 142346240, mean_episode_return = 182.84, mean_episode_step = 879.24, total_loss = 177.74, pg_loss = 70.478, baseline_loss = 113.58, entropy_loss = -6.3178, learner_queue_size = 19, _tick = 47365, _time = 1.654e+09, train_seconds = 2.1595e+04)
[2022-05-31 20:10:21,210][root][INFO] - Step 142376960 @ 6141.6 SPS. Inference batcher size: 114. Learner queue size: 20. Other stats: (step = 142376960, mean_episode_return = 371.39, mean_episode_step = 563.22, total_loss = 434.86, pg_loss = 265.11, baseline_loss = 176.09, entropy_loss = -6.3327, learner_queue_size = 13, _tick = 47377, _time = 1.654e+09, train_seconds = 2.16e+04)
[2022-05-31 20:10:26,214][root][INFO] - Step 142410240 @ 6650.7 SPS. Inference batcher size: 121. Learner queue size: 15. Other stats: (step = 142410240, mean_episode_return = 294.53, mean_episode_step = 698.07, total_loss = 327.11, pg_loss = 90.757, baseline_loss = 242.72, entropy_loss = -6.3669, learner_queue_size = 21, _tick = 47389, _time = 1.654e+09, train_seconds = 2.1605e+04)
[2022-05-31 20:10:31,220][root][INFO] - Step 142443520 @ 6648.0 SPS. Inference batcher size: 131. Learner queue size: 20. Other stats: (step = 142443520, mean_episode_return = 135.01, mean_episode_step = 909.56, total_loss = -110.67, pg_loss = -125.68, baseline_loss = 22.275, entropy_loss = -7.2609, learner_queue_size = 15, _tick = 47401, _time = 1.654e+09, train_seconds = 2.161e+04)
[2022-05-31 20:10:36,226][root][INFO] - Step 142476800 @ 6647.9 SPS. Inference batcher size: 153. Learner queue size: 16. Other stats: (step = 142476800, mean_episode_return = 172.73, mean_episode_step = 695.16, total_loss = -178.41, pg_loss = -197.54, baseline_loss = 25.579, entropy_loss = -6.4535, learner_queue_size = 17, _tick = 47414, _time = 1.654e+09, train_seconds = 2.1615e+04)
[2022-05-31 20:10:41,230][root][INFO] - Step 142510080 @ 6650.6 SPS. Inference batcher size: 125. Learner queue size: 14. Other stats: (step = 142510080, mean_episode_return = 230.21, mean_episode_step = 881.93, total_loss = 243.72, pg_loss = 157.74, baseline_loss = 92.031, entropy_loss = -6.0459, learner_queue_size = 12, _tick = 47427, _time = 1.654e+09, train_seconds = 2.162e+04)
[2022-05-31 20:10:46,237][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 20:10:46,402][root][INFO] - Step 142543360 @ 6647.0 SPS. Inference batcher size: 106. Learner queue size: 20. Other stats: (step = 142545920, mean_episode_return = 352.97, mean_episode_step = 832.42, total_loss = 56.372, pg_loss = 9.2283, baseline_loss = 53.898, entropy_loss = -6.7544, learner_queue_size = 16, _tick = 47440, _time = 1.654e+09, train_seconds = 2.1625e+04)
[2022-05-31 20:10:51,406][root][INFO] - Step 142579200 @ 6933.5 SPS. Inference batcher size: 37. Learner queue size: 29. Other stats: (step = 142579200, mean_episode_return = 41.219, mean_episode_step = 682.98, total_loss = 256.85, pg_loss = 147.15, baseline_loss = 116.07, entropy_loss = -6.3789, learner_queue_size = 20, _tick = 47451, _time = 1.654e+09, train_seconds = 2.163e+04)
[2022-05-31 20:10:56,410][root][INFO] - Step 142612480 @ 6650.7 SPS. Inference batcher size: 173. Learner queue size: 20. Other stats: (step = 142612480, mean_episode_return = None, mean_episode_step = 1001.6, total_loss = 154.62, pg_loss = 83.951, baseline_loss = 77.444, entropy_loss = -6.7712, learner_queue_size = 16, _tick = 47461, _time = 1.654e+09, train_seconds = 2.1635e+04)
[2022-05-31 20:11:01,416][root][INFO] - Step 142643200 @ 6136.6 SPS. Inference batcher size: 131. Learner queue size: 15. Other stats: (step = 142643200, mean_episode_return = None, mean_episode_step = 795.56, total_loss = 33.024, pg_loss = -25.309, baseline_loss = 65.579, entropy_loss = -7.2458, learner_queue_size = 15, _tick = 47469, _time = 1.654e+09, train_seconds = 2.164e+04)
[2022-05-31 20:11:06,418][root][INFO] - Step 142676480 @ 6653.4 SPS. Inference batcher size: 114. Learner queue size: 16. Other stats: (step = 142676480, mean_episode_return = 277.53, mean_episode_step = 782.16, total_loss = 305.91, pg_loss = 145.56, baseline_loss = 167.36, entropy_loss = -7.0087, learner_queue_size = 16, _tick = 47480, _time = 1.654e+09, train_seconds = 2.1645e+04)
[2022-05-31 20:11:11,422][root][INFO] - Step 142709760 @ 6650.6 SPS. Inference batcher size: 31. Learner queue size: 16. Other stats: (step = 142709760, mean_episode_return = 152.64, mean_episode_step = 828.83, total_loss = 898.24, pg_loss = 611.96, baseline_loss = 293.44, entropy_loss = -7.1603, learner_queue_size = 23, _tick = 47492, _time = 1.654e+09, train_seconds = 2.165e+04)
[2022-05-31 20:11:16,426][root][INFO] - Step 142743040 @ 6650.7 SPS. Inference batcher size: 140. Learner queue size: 15. Other stats: (step = 142743040, mean_episode_return = 166.23, mean_episode_step = 651.69, total_loss = -75.25, pg_loss = -268.55, baseline_loss = 199.8, entropy_loss = -6.4964, learner_queue_size = 17, _tick = 47504, _time = 1.654e+09, train_seconds = 2.1655e+04)
[2022-05-31 20:11:21,432][root][INFO] - Step 142776320 @ 6648.0 SPS. Inference batcher size: 110. Learner queue size: 16. Other stats: (step = 142776320, mean_episode_return = None, mean_episode_step = 1035.9, total_loss = 135.3, pg_loss = 111.07, baseline_loss = 31.458, entropy_loss = -7.2315, learner_queue_size = 22, _tick = 47513, _time = 1.654e+09, train_seconds = 2.166e+04)
[2022-05-31 20:11:26,438][root][INFO] - Step 142809600 @ 6648.2 SPS. Inference batcher size: 170. Learner queue size: 8. Other stats: (step = 142809600, mean_episode_return = 795.56, mean_episode_step = 834.35, total_loss = -87.849, pg_loss = -112.91, baseline_loss = 32.13, entropy_loss = -7.0661, learner_queue_size = 13, _tick = 47526, _time = 1.654e+09, train_seconds = 2.1665e+04)
[2022-05-31 20:11:31,442][root][INFO] - Step 142842880 @ 6650.6 SPS. Inference batcher size: 70. Learner queue size: 4. Other stats: (step = 142842880, mean_episode_return = 140.03, mean_episode_step = 798.68, total_loss = 273.57, pg_loss = 211.9, baseline_loss = 68.457, entropy_loss = -6.7866, learner_queue_size = 19, _tick = 47539, _time = 1.654e+09, train_seconds = 2.167e+04)
[2022-05-31 20:11:36,446][root][INFO] - Step 142876160 @ 6650.6 SPS. Inference batcher size: 101. Learner queue size: 0. Other stats: (step = 142876160, mean_episode_return = 239.52, mean_episode_step = 694.67, total_loss = 18.464, pg_loss = -19.217, baseline_loss = 44.31, entropy_loss = -6.629, learner_queue_size = 20, _tick = 47552, _time = 1.654e+09, train_seconds = 2.1675e+04)
[2022-05-31 20:11:41,450][root][INFO] - Step 142906880 @ 6139.3 SPS. Inference batcher size: 91. Learner queue size: 18. Other stats: (step = 142906880, mean_episode_return = 228.87, mean_episode_step = 729.95, total_loss = 132.43, pg_loss = 88.354, baseline_loss = 50.352, entropy_loss = -6.2801, learner_queue_size = 30, _tick = 47562, _time = 1.654e+09, train_seconds = 2.168e+04)
[2022-05-31 20:11:46,454][root][INFO] - Step 142942720 @ 7162.3 SPS. Inference batcher size: 97. Learner queue size: 25. Other stats: (step = 142942720, mean_episode_return = 156.5, mean_episode_step = 918.41, total_loss = 103.23, pg_loss = 77.073, baseline_loss = 33.194, entropy_loss = -7.0425, learner_queue_size = 14, _tick = 47575, _time = 1.654e+09, train_seconds = 2.1685e+04)
[2022-05-31 20:11:51,460][root][INFO] - Step 142973440 @ 6136.4 SPS. Inference batcher size: 144. Learner queue size: 24. Other stats: (step = 142973440, mean_episode_return = 256.06, mean_episode_step = 732.09, total_loss = 296.34, pg_loss = 171.02, baseline_loss = 131.02, entropy_loss = -5.7005, learner_queue_size = 16, _tick = 47587, _time = 1.654e+09, train_seconds = 2.169e+04)
[2022-05-31 20:11:56,462][root][INFO] - Step 143006720 @ 6653.4 SPS. Inference batcher size: 156. Learner queue size: 12. Other stats: (step = 143006720, mean_episode_return = 287.99, mean_episode_step = 694.88, total_loss = -99.682, pg_loss = -241.69, baseline_loss = 148.36, entropy_loss = -6.3527, learner_queue_size = 14, _tick = 47600, _time = 1.654e+09, train_seconds = 2.1695e+04)
[2022-05-31 20:12:01,466][root][INFO] - Step 143040000 @ 6650.5 SPS. Inference batcher size: 29. Learner queue size: 8. Other stats: (step = 143040000, mean_episode_return = 303.25, mean_episode_step = 856.25, total_loss = 461.47, pg_loss = 297.41, baseline_loss = 170.47, entropy_loss = -6.4097, learner_queue_size = 22, _tick = 47612, _time = 1.654e+09, train_seconds = 2.17e+04)
[2022-05-31 20:12:06,470][root][INFO] - Step 143070720 @ 6139.2 SPS. Inference batcher size: 191. Learner queue size: 21. Other stats: (step = 143070720, mean_episode_return = 77.121, mean_episode_step = 818.09, total_loss = 141.73, pg_loss = 69.611, baseline_loss = 78.756, entropy_loss = -6.6358, learner_queue_size = 20, _tick = 47623, _time = 1.654e+09, train_seconds = 2.1705e+04)
[2022-05-31 20:12:11,474][root][INFO] - Step 143104000 @ 6650.8 SPS. Inference batcher size: 112. Learner queue size: 23. Other stats: (step = 143104000, mean_episode_return = 151.95, mean_episode_step = 527.36, total_loss = 309.77, pg_loss = 165.9, baseline_loss = 149.27, entropy_loss = -5.3999, learner_queue_size = 25, _tick = 47636, _time = 1.654e+09, train_seconds = 2.171e+04)
[2022-05-31 20:12:16,478][root][INFO] - Step 143137280 @ 6650.7 SPS. Inference batcher size: 162. Learner queue size: 14. Other stats: (step = 143137280, mean_episode_return = 568.77, mean_episode_step = 749.11, total_loss = 121.34, pg_loss = 67.888, baseline_loss = 59.681, entropy_loss = -6.2289, learner_queue_size = 22, _tick = 47648, _time = 1.654e+09, train_seconds = 2.1715e+04)
[2022-05-31 20:12:21,482][root][INFO] - Step 143170560 @ 6650.8 SPS. Inference batcher size: 87. Learner queue size: 14. Other stats: (step = 143170560, mean_episode_return = 134.88, mean_episode_step = 699.72, total_loss = -83.89, pg_loss = -117.8, baseline_loss = 40.28, entropy_loss = -6.3653, learner_queue_size = 12, _tick = 47659, _time = 1.654e+09, train_seconds = 2.172e+04)
[2022-05-31 20:12:26,486][root][INFO] - Step 143203840 @ 6650.7 SPS. Inference batcher size: 114. Learner queue size: 16. Other stats: (step = 143203840, mean_episode_return = 450.47, mean_episode_step = 625.64, total_loss = 12.012, pg_loss = -34.958, baseline_loss = 53.036, entropy_loss = -6.0658, learner_queue_size = 19, _tick = 47672, _time = 1.654e+09, train_seconds = 2.1725e+04)
[2022-05-31 20:12:31,492][root][INFO] - Step 143237120 @ 6648.4 SPS. Inference batcher size: 102. Learner queue size: 1. Other stats: (step = 143237120, mean_episode_return = 116.82, mean_episode_step = 521.48, total_loss = -24.097, pg_loss = -106.06, baseline_loss = 87.642, entropy_loss = -5.6777, learner_queue_size = 14, _tick = 47685, _time = 1.654e+09, train_seconds = 2.173e+04)
[2022-05-31 20:12:36,495][root][INFO] - Step 143270400 @ 6651.5 SPS. Inference batcher size: 56. Learner queue size: 9. Other stats: (step = 143270400, mean_episode_return = 465.71, mean_episode_step = 584.28, total_loss = 136.18, pg_loss = 9.85, baseline_loss = 132.15, entropy_loss = -5.8196, learner_queue_size = 10, _tick = 47697, _time = 1.654e+09, train_seconds = 2.1735e+04)
[2022-05-31 20:12:41,502][root][INFO] - Step 143303680 @ 6646.8 SPS. Inference batcher size: 145. Learner queue size: 6. Other stats: (step = 143303680, mean_episode_return = 144.67, mean_episode_step = 694.72, total_loss = 46.291, pg_loss = -18.713, baseline_loss = 71.337, entropy_loss = -6.3328, learner_queue_size = 15, _tick = 47709, _time = 1.654e+09, train_seconds = 2.174e+04)
[2022-05-31 20:12:46,506][root][INFO] - Step 143336960 @ 6650.7 SPS. Inference batcher size: 168. Learner queue size: 2. Other stats: (step = 143336960, mean_episode_return = 530.35, mean_episode_step = 590.33, total_loss = 190.42, pg_loss = 53.272, baseline_loss = 142.8, entropy_loss = -5.6549, learner_queue_size = 11, _tick = 47721, _time = 1.654e+09, train_seconds = 2.1745e+04)
[2022-05-31 20:12:51,512][root][INFO] - Step 143370240 @ 6648.2 SPS. Inference batcher size: 110. Learner queue size: 0. Other stats: (step = 143370240, mean_episode_return = 77.45, mean_episode_step = 723.32, total_loss = 431.67, pg_loss = 323.15, baseline_loss = 114.7, entropy_loss = -6.1727, learner_queue_size = 21, _tick = 47732, _time = 1.654e+09, train_seconds = 2.175e+04)
[2022-05-31 20:12:56,514][root][INFO] - Step 143403520 @ 6652.9 SPS. Inference batcher size: 130. Learner queue size: 25. Other stats: (step = 143403520, mean_episode_return = 367.24, mean_episode_step = 567.79, total_loss = 38.051, pg_loss = -94.825, baseline_loss = 138.63, entropy_loss = -5.7551, learner_queue_size = 21, _tick = 47744, _time = 1.654e+09, train_seconds = 2.1755e+04)
[2022-05-31 20:13:01,518][root][INFO] - Step 143436800 @ 6650.7 SPS. Inference batcher size: 162. Learner queue size: 1. Other stats: (step = 143436800, mean_episode_return = 345.46, mean_episode_step = 827.82, total_loss = -51.358, pg_loss = -162.84, baseline_loss = 118.15, entropy_loss = -6.6638, learner_queue_size = 28, _tick = 47757, _time = 1.654e+09, train_seconds = 2.176e+04)
[2022-05-31 20:13:06,524][root][INFO] - Step 143467520 @ 6136.4 SPS. Inference batcher size: 161. Learner queue size: 15. Other stats: (step = 143467520, mean_episode_return = 465.92, mean_episode_step = 550.77, total_loss = 362.22, pg_loss = 175.94, baseline_loss = 192.29, entropy_loss = -6.0095, learner_queue_size = 17, _tick = 47768, _time = 1.654e+09, train_seconds = 2.1765e+04)
[2022-05-31 20:13:11,530][root][INFO] - Step 143500800 @ 6648.4 SPS. Inference batcher size: 93. Learner queue size: 6. Other stats: (step = 143500800, mean_episode_return = 296.03, mean_episode_step = 633.26, total_loss = 190.51, pg_loss = 128.57, baseline_loss = 68.66, entropy_loss = -6.7283, learner_queue_size = 18, _tick = 47779, _time = 1.654e+09, train_seconds = 2.177e+04)
[2022-05-31 20:13:16,534][root][INFO] - Step 143534080 @ 6650.8 SPS. Inference batcher size: 102. Learner queue size: 7. Other stats: (step = 143534080, mean_episode_return = 117.18, mean_episode_step = 648.57, total_loss = 39.069, pg_loss = -22.491, baseline_loss = 67.873, entropy_loss = -6.313, learner_queue_size = 19, _tick = 47792, _time = 1.654e+09, train_seconds = 2.1775e+04)
[2022-05-31 20:13:21,540][root][INFO] - Step 143567360 @ 6647.9 SPS. Inference batcher size: 100. Learner queue size: 7. Other stats: (step = 143567360, mean_episode_return = 293.22, mean_episode_step = 644.75, total_loss = 112.34, pg_loss = 51.473, baseline_loss = 66.52, entropy_loss = -5.6574, learner_queue_size = 18, _tick = 47805, _time = 1.654e+09, train_seconds = 2.178e+04)
[2022-05-31 20:13:26,546][root][INFO] - Step 143600640 @ 6648.2 SPS. Inference batcher size: 146. Learner queue size: 7. Other stats: (step = 143600640, mean_episode_return = 200.01, mean_episode_step = 703.84, total_loss = 107.83, pg_loss = 5.4457, baseline_loss = 108.25, entropy_loss = -5.8687, learner_queue_size = 22, _tick = 47817, _time = 1.654e+09, train_seconds = 2.1785e+04)
[2022-05-31 20:13:31,550][root][INFO] - Step 143633920 @ 6650.7 SPS. Inference batcher size: 56. Learner queue size: 26. Other stats: (step = 143633920, mean_episode_return = 332.06, mean_episode_step = 777.02, total_loss = 272.88, pg_loss = 194.04, baseline_loss = 85.565, entropy_loss = -6.7244, learner_queue_size = 13, _tick = 47828, _time = 1.654e+09, train_seconds = 2.179e+04)
[2022-05-31 20:13:36,554][root][INFO] - Step 143667200 @ 6650.6 SPS. Inference batcher size: 102. Learner queue size: 27. Other stats: (step = 143667200, mean_episode_return = 197.42, mean_episode_step = 705.06, total_loss = 84.322, pg_loss = 42.146, baseline_loss = 48.132, entropy_loss = -5.9562, learner_queue_size = 15, _tick = 47840, _time = 1.654e+09, train_seconds = 2.1795e+04)
[2022-05-31 20:13:41,558][root][INFO] - Step 143700480 @ 6650.8 SPS. Inference batcher size: 138. Learner queue size: 2. Other stats: (step = 143700480, mean_episode_return = 581.21, mean_episode_step = 476.1, total_loss = 87.674, pg_loss = -11.855, baseline_loss = 105.48, entropy_loss = -5.9559, learner_queue_size = 22, _tick = 47852, _time = 1.654e+09, train_seconds = 2.18e+04)
[2022-05-31 20:13:46,562][root][INFO] - Step 143731200 @ 6139.0 SPS. Inference batcher size: 136. Learner queue size: 22. Other stats: (step = 143731200, mean_episode_return = 59.471, mean_episode_step = 557.47, total_loss = 270.37, pg_loss = 211.05, baseline_loss = 65.297, entropy_loss = -5.9855, learner_queue_size = 15, _tick = 47862, _time = 1.654e+09, train_seconds = 2.1805e+04)
[2022-05-31 20:13:51,568][root][INFO] - Step 143764480 @ 6648.0 SPS. Inference batcher size: 160. Learner queue size: 12. Other stats: (step = 143764480, mean_episode_return = 258.23, mean_episode_step = 696.33, total_loss = -66.902, pg_loss = -103.25, baseline_loss = 42.577, entropy_loss = -6.2274, learner_queue_size = 26, _tick = 47875, _time = 1.654e+09, train_seconds = 2.181e+04)
[2022-05-31 20:13:56,574][root][INFO] - Step 143797760 @ 6648.1 SPS. Inference batcher size: 39. Learner queue size: 10. Other stats: (step = 143797760, mean_episode_return = 113.32, mean_episode_step = 560.94, total_loss = -139.35, pg_loss = -213.4, baseline_loss = 79.96, entropy_loss = -5.9057, learner_queue_size = 20, _tick = 47888, _time = 1.654e+09, train_seconds = 2.1815e+04)
[2022-05-31 20:14:01,578][root][INFO] - Step 143831040 @ 6650.6 SPS. Inference batcher size: 39. Learner queue size: 10. Other stats: (step = 143831040, mean_episode_return = 317.7, mean_episode_step = 622.08, total_loss = 516.89, pg_loss = 290.99, baseline_loss = 231.31, entropy_loss = -5.4051, learner_queue_size = 19, _tick = 47899, _time = 1.654e+09, train_seconds = 2.182e+04)
[2022-05-31 20:14:06,582][root][INFO] - Step 143864320 @ 6650.8 SPS. Inference batcher size: 98. Learner queue size: 18. Other stats: (step = 143864320, mean_episode_return = 244.92, mean_episode_step = 579.94, total_loss = -6.1985, pg_loss = -273.45, baseline_loss = 272.47, entropy_loss = -5.2115, learner_queue_size = 22, _tick = 47912, _time = 1.654e+09, train_seconds = 2.1825e+04)
[2022-05-31 20:14:11,586][root][INFO] - Step 143897600 @ 6650.7 SPS. Inference batcher size: 129. Learner queue size: 3. Other stats: (step = 143897600, mean_episode_return = 342.01, mean_episode_step = 663.08, total_loss = 106.93, pg_loss = 27.168, baseline_loss = 86.045, entropy_loss = -6.2843, learner_queue_size = 24, _tick = 47925, _time = 1.654e+09, train_seconds = 2.183e+04)
[2022-05-31 20:14:16,590][root][INFO] - Step 143930880 @ 6650.4 SPS. Inference batcher size: 72. Learner queue size: 5. Other stats: (step = 143930880, mean_episode_return = 328.44, mean_episode_step = 625.2, total_loss = 282.74, pg_loss = 95.417, baseline_loss = 193.21, entropy_loss = -5.8919, learner_queue_size = 15, _tick = 47938, _time = 1.654e+09, train_seconds = 2.1835e+04)
[2022-05-31 20:14:21,594][root][INFO] - Step 143964160 @ 6650.8 SPS. Inference batcher size: 61. Learner queue size: 26. Other stats: (step = 143964160, mean_episode_return = 106.62, mean_episode_step = 538.66, total_loss = 469.31, pg_loss = 263.34, baseline_loss = 211.77, entropy_loss = -5.7955, learner_queue_size = 14, _tick = 47949, _time = 1.654e+09, train_seconds = 2.184e+04)
[2022-05-31 20:14:26,598][root][INFO] - Step 143997440 @ 6650.9 SPS. Inference batcher size: 93. Learner queue size: 17. Other stats: (step = 143997440, mean_episode_return = 374.72, mean_episode_step = 541.73, total_loss = 294.69, pg_loss = 170.46, baseline_loss = 129.66, entropy_loss = -5.4203, learner_queue_size = 13, _tick = 47961, _time = 1.654e+09, train_seconds = 2.1845e+04)
[2022-05-31 20:14:31,602][root][INFO] - Step 144030720 @ 6650.7 SPS. Inference batcher size: 139. Learner queue size: 24. Other stats: (step = 144030720, mean_episode_return = 362.91, mean_episode_step = 555.84, total_loss = 0.74129, pg_loss = -85.629, baseline_loss = 91.913, entropy_loss = -5.543, learner_queue_size = 20, _tick = 47973, _time = 1.654e+09, train_seconds = 2.185e+04)
[2022-05-31 20:14:36,606][root][INFO] - Step 144061440 @ 6139.0 SPS. Inference batcher size: 146. Learner queue size: 26. Other stats: (step = 144061440, mean_episode_return = 183.3, mean_episode_step = 677.71, total_loss = 179.28, pg_loss = 73.715, baseline_loss = 111.16, entropy_loss = -5.5917, learner_queue_size = 13, _tick = 47984, _time = 1.654e+09, train_seconds = 2.1855e+04)
[2022-05-31 20:14:41,610][root][INFO] - Step 144097280 @ 7162.3 SPS. Inference batcher size: 108. Learner queue size: 16. Other stats: (step = 144097280, mean_episode_return = 89.18, mean_episode_step = 601.13, total_loss = -50.28, pg_loss = -98.251, baseline_loss = 55.06, entropy_loss = -7.089, learner_queue_size = 15, _tick = 47994, _time = 1.654e+09, train_seconds = 2.186e+04)
[2022-05-31 20:14:46,614][root][INFO] - Step 144128000 @ 6139.1 SPS. Inference batcher size: 169. Learner queue size: 22. Other stats: (step = 144128000, mean_episode_return = 154.04, mean_episode_step = 802.18, total_loss = 93.058, pg_loss = 57.866, baseline_loss = 42.452, entropy_loss = -7.2602, learner_queue_size = 18, _tick = 48003, _time = 1.654e+09, train_seconds = 2.1865e+04)
[2022-05-31 20:14:51,618][root][INFO] - Step 144161280 @ 6650.7 SPS. Inference batcher size: 154. Learner queue size: 20. Other stats: (step = 144161280, mean_episode_return = 272.33, mean_episode_step = 751.45, total_loss = 714.53, pg_loss = 544.74, baseline_loss = 176.0, entropy_loss = -6.2106, learner_queue_size = 22, _tick = 48014, _time = 1.654e+09, train_seconds = 2.187e+04)
[2022-05-31 20:14:56,624][root][INFO] - Step 144194560 @ 6647.9 SPS. Inference batcher size: 86. Learner queue size: 17. Other stats: (step = 144194560, mean_episode_return = 302.11, mean_episode_step = 702.86, total_loss = 842.26, pg_loss = 423.31, baseline_loss = 424.25, entropy_loss = -5.2982, learner_queue_size = 18, _tick = 48026, _time = 1.654e+09, train_seconds = 2.1875e+04)
[2022-05-31 20:15:01,630][root][INFO] - Step 144227840 @ 6648.1 SPS. Inference batcher size: 107. Learner queue size: 18. Other stats: (step = 144227840, mean_episode_return = 59.239, mean_episode_step = 702.82, total_loss = 81.998, pg_loss = 24.3, baseline_loss = 63.478, entropy_loss = -5.7807, learner_queue_size = 25, _tick = 48038, _time = 1.654e+09, train_seconds = 2.188e+04)
[2022-05-31 20:15:06,634][root][INFO] - Step 144261120 @ 6650.8 SPS. Inference batcher size: 62. Learner queue size: 1. Other stats: (step = 144261120, mean_episode_return = 290.77, mean_episode_step = 693.4, total_loss = 427.1, pg_loss = 232.67, baseline_loss = 200.1, entropy_loss = -5.6714, learner_queue_size = 13, _tick = 48051, _time = 1.654e+09, train_seconds = 2.1885e+04)
[2022-05-31 20:15:11,638][root][INFO] - Step 144294400 @ 6650.0 SPS. Inference batcher size: 15. Learner queue size: 21. Other stats: (step = 144294400, mean_episode_return = 248.87, mean_episode_step = 667.39, total_loss = 84.859, pg_loss = -59.009, baseline_loss = 149.76, entropy_loss = -5.897, learner_queue_size = 21, _tick = 48064, _time = 1.654e+09, train_seconds = 2.189e+04)
[2022-05-31 20:15:16,642][root][INFO] - Step 144327680 @ 6651.3 SPS. Inference batcher size: 126. Learner queue size: 19. Other stats: (step = 144327680, mean_episode_return = 198.71, mean_episode_step = 755.17, total_loss = -135.03, pg_loss = -157.89, baseline_loss = 29.335, entropy_loss = -6.4707, learner_queue_size = 25, _tick = 48076, _time = 1.654e+09, train_seconds = 2.1895e+04)
[2022-05-31 20:15:21,646][root][INFO] - Step 144360960 @ 6650.7 SPS. Inference batcher size: 157. Learner queue size: 10. Other stats: (step = 144360960, mean_episode_return = 61.997, mean_episode_step = 901.32, total_loss = 221.38, pg_loss = 77.361, baseline_loss = 150.79, entropy_loss = -6.7756, learner_queue_size = 12, _tick = 48086, _time = 1.654e+09, train_seconds = 2.19e+04)
[2022-05-31 20:15:26,652][root][INFO] - Step 144394240 @ 6648.0 SPS. Inference batcher size: 21. Learner queue size: 2. Other stats: (step = 144394240, mean_episode_return = 220.88, mean_episode_step = 922.48, total_loss = -7.641, pg_loss = -44.555, baseline_loss = 43.673, entropy_loss = -6.7586, learner_queue_size = 19, _tick = 48096, _time = 1.654e+09, train_seconds = 2.1905e+04)
[2022-05-31 20:15:31,658][root][INFO] - Step 144427520 @ 6648.0 SPS. Inference batcher size: 40. Learner queue size: 2. Other stats: (step = 144427520, mean_episode_return = 171.63, mean_episode_step = 835.32, total_loss = 180.29, pg_loss = 36.662, baseline_loss = 150.16, entropy_loss = -6.5306, learner_queue_size = 10, _tick = 48109, _time = 1.654e+09, train_seconds = 2.191e+04)
[2022-05-31 20:15:36,662][root][INFO] - Step 144460800 @ 6650.7 SPS. Inference batcher size: 137. Learner queue size: 4. Other stats: (step = 144460800, mean_episode_return = 469.22, mean_episode_step = 759.83, total_loss = -73.225, pg_loss = -193.02, baseline_loss = 125.73, entropy_loss = -5.9261, learner_queue_size = 24, _tick = 48121, _time = 1.654e+09, train_seconds = 2.1915e+04)
[2022-05-31 20:15:41,666][root][INFO] - Step 144494080 @ 6650.7 SPS. Inference batcher size: 123. Learner queue size: 0. Other stats: (step = 144494080, mean_episode_return = 242.39, mean_episode_step = 674.94, total_loss = 479.67, pg_loss = 318.41, baseline_loss = 167.22, entropy_loss = -5.9584, learner_queue_size = 20, _tick = 48132, _time = 1.654e+09, train_seconds = 2.192e+04)
[2022-05-31 20:15:46,670][root][INFO] - Step 144527360 @ 6650.2 SPS. Inference batcher size: 97. Learner queue size: 30. Other stats: (step = 144527360, mean_episode_return = 329.5, mean_episode_step = 808.04, total_loss = 139.09, pg_loss = 58.412, baseline_loss = 87.177, entropy_loss = -6.5031, learner_queue_size = 18, _tick = 48142, _time = 1.654e+09, train_seconds = 2.1925e+04)
[2022-05-31 20:15:51,674][root][INFO] - Step 144560640 @ 6651.2 SPS. Inference batcher size: 77. Learner queue size: 15. Other stats: (step = 144560640, mean_episode_return = 127.89, mean_episode_step = 759.9, total_loss = -90.036, pg_loss = -214.75, baseline_loss = 130.6, entropy_loss = -5.8863, learner_queue_size = 15, _tick = 48155, _time = 1.654e+09, train_seconds = 2.193e+04)
[2022-05-31 20:15:56,678][root][INFO] - Step 144591360 @ 6139.1 SPS. Inference batcher size: 169. Learner queue size: 10. Other stats: (step = 144591360, mean_episode_return = 210.67, mean_episode_step = 943.46, total_loss = 140.12, pg_loss = 76.801, baseline_loss = 70.352, entropy_loss = -7.0371, learner_queue_size = 19, _tick = 48166, _time = 1.654e+09, train_seconds = 2.1935e+04)
[2022-05-31 20:16:01,682][root][INFO] - Step 144624640 @ 6650.6 SPS. Inference batcher size: 5. Learner queue size: 6. Other stats: (step = 144624640, mean_episode_return = 294.17, mean_episode_step = 775.04, total_loss = 88.014, pg_loss = 18.73, baseline_loss = 75.419, entropy_loss = -6.1346, learner_queue_size = 19, _tick = 48179, _time = 1.654e+09, train_seconds = 2.194e+04)
[2022-05-31 20:16:06,686][root][INFO] - Step 144657920 @ 6650.8 SPS. Inference batcher size: 86. Learner queue size: 1. Other stats: (step = 144657920, mean_episode_return = 148.45, mean_episode_step = 717.95, total_loss = -25.532, pg_loss = -70.583, baseline_loss = 51.478, entropy_loss = -6.4265, learner_queue_size = 32, _tick = 48191, _time = 1.654e+09, train_seconds = 2.1945e+04)
[2022-05-31 20:16:11,690][root][INFO] - Step 144691200 @ 6650.6 SPS. Inference batcher size: 103. Learner queue size: 4. Other stats: (step = 144691200, mean_episode_return = 232.26, mean_episode_step = 706.81, total_loss = 229.15, pg_loss = 146.69, baseline_loss = 88.79, entropy_loss = -6.3277, learner_queue_size = 21, _tick = 48204, _time = 1.654e+09, train_seconds = 2.195e+04)
[2022-05-31 20:16:16,694][root][INFO] - Step 144724480 @ 6650.8 SPS. Inference batcher size: 108. Learner queue size: 26. Other stats: (step = 144724480, mean_episode_return = 235.19, mean_episode_step = 738.89, total_loss = 42.041, pg_loss = -71.147, baseline_loss = 119.6, entropy_loss = -6.4082, learner_queue_size = 10, _tick = 48216, _time = 1.654e+09, train_seconds = 2.1955e+04)
[2022-05-31 20:16:21,700][root][INFO] - Step 144757760 @ 6648.0 SPS. Inference batcher size: 123. Learner queue size: 13. Other stats: (step = 144757760, mean_episode_return = 415.67, mean_episode_step = 536.87, total_loss = 421.4, pg_loss = 195.3, baseline_loss = 231.35, entropy_loss = -5.2482, learner_queue_size = 13, _tick = 48228, _time = 1.654e+09, train_seconds = 2.196e+04)
[2022-05-31 20:16:26,706][root][INFO] - Step 144791040 @ 6647.9 SPS. Inference batcher size: 99. Learner queue size: 27. Other stats: (step = 144791040, mean_episode_return = 221.87, mean_episode_step = 686.78, total_loss = 184.15, pg_loss = 51.893, baseline_loss = 138.73, entropy_loss = -6.4658, learner_queue_size = 22, _tick = 48241, _time = 1.654e+09, train_seconds = 2.1965e+04)
[2022-05-31 20:16:31,710][root][INFO] - Step 144824320 @ 6650.9 SPS. Inference batcher size: 84. Learner queue size: 29. Other stats: (step = 144824320, mean_episode_return = 115.88, mean_episode_step = 808.23, total_loss = 109.42, pg_loss = 22.78, baseline_loss = 92.87, entropy_loss = -6.2306, learner_queue_size = 25, _tick = 48250, _time = 1.654e+09, train_seconds = 2.197e+04)
[2022-05-31 20:16:36,716][root][INFO] - Step 144855040 @ 6136.6 SPS. Inference batcher size: 127. Learner queue size: 14. Other stats: (step = 144855040, mean_episode_return = 155.6, mean_episode_step = 722.98, total_loss = 431.7, pg_loss = 118.56, baseline_loss = 319.13, entropy_loss = -5.9869, learner_queue_size = 15, _tick = 48262, _time = 1.654e+09, train_seconds = 2.1975e+04)
[2022-05-31 20:16:41,722][root][INFO] - Step 144888320 @ 6648.0 SPS. Inference batcher size: 106. Learner queue size: 15. Other stats: (step = 144888320, mean_episode_return = 676.42, mean_episode_step = 747.92, total_loss = 590.49, pg_loss = 328.13, baseline_loss = 267.86, entropy_loss = -5.4926, learner_queue_size = 17, _tick = 48274, _time = 1.654e+09, train_seconds = 2.198e+04)
[2022-05-31 20:16:46,728][root][INFO] - Step 144921600 @ 6648.0 SPS. Inference batcher size: 113. Learner queue size: 17. Other stats: (step = 144921600, mean_episode_return = 465.67, mean_episode_step = 544.81, total_loss = 251.63, pg_loss = -63.732, baseline_loss = 320.8, entropy_loss = -5.4412, learner_queue_size = 10, _tick = 48285, _time = 1.654e+09, train_seconds = 2.1985e+04)
[2022-05-31 20:16:51,730][root][INFO] - Step 144954880 @ 6653.3 SPS. Inference batcher size: 131. Learner queue size: 22. Other stats: (step = 144954880, mean_episode_return = 290.43, mean_episode_step = 686.61, total_loss = -42.819, pg_loss = -221.75, baseline_loss = 185.13, entropy_loss = -6.1967, learner_queue_size = 20, _tick = 48298, _time = 1.654e+09, train_seconds = 2.199e+04)
[2022-05-31 20:16:56,735][root][INFO] - Step 144988160 @ 6649.8 SPS. Inference batcher size: 143. Learner queue size: 8. Other stats: (step = 144988160, mean_episode_return = 242.02, mean_episode_step = 654.59, total_loss = 56.876, pg_loss = -128.14, baseline_loss = 191.55, entropy_loss = -6.5323, learner_queue_size = 24, _tick = 48310, _time = 1.654e+09, train_seconds = 2.1995e+04)
[2022-05-31 20:17:01,738][root][INFO] - Step 145021440 @ 6651.5 SPS. Inference batcher size: 97. Learner queue size: 7. Other stats: (step = 145021440, mean_episode_return = 143.9, mean_episode_step = 793.77, total_loss = 273.36, pg_loss = 122.8, baseline_loss = 157.17, entropy_loss = -6.6111, learner_queue_size = 14, _tick = 48322, _time = 1.654e+09, train_seconds = 2.2e+04)
[2022-05-31 20:17:06,744][root][INFO] - Step 145054720 @ 6648.2 SPS. Inference batcher size: 106. Learner queue size: 4. Other stats: (step = 145054720, mean_episode_return = 296.49, mean_episode_step = 796.5, total_loss = 19.139, pg_loss = -22.169, baseline_loss = 48.25, entropy_loss = -6.9426, learner_queue_size = 17, _tick = 48333, _time = 1.654e+09, train_seconds = 2.2005e+04)
[2022-05-31 20:17:11,746][root][INFO] - Step 145088000 @ 6653.0 SPS. Inference batcher size: 51. Learner queue size: 3. Other stats: (step = 145088000, mean_episode_return = -2.5904, mean_episode_step = 712.24, total_loss = 65.678, pg_loss = 19.777, baseline_loss = 53.058, entropy_loss = -7.1559, learner_queue_size = 28, _tick = 48343, _time = 1.654e+09, train_seconds = 2.201e+04)
[2022-05-31 20:17:16,750][root][INFO] - Step 145121280 @ 6650.9 SPS. Inference batcher size: 14. Learner queue size: 3. Other stats: (step = 145121280, mean_episode_return = 447.53, mean_episode_step = 555.59, total_loss = 14.034, pg_loss = -13.072, baseline_loss = 34.324, entropy_loss = -7.2179, learner_queue_size = 17, _tick = 48356, _time = 1.654e+09, train_seconds = 2.2015e+04)
[2022-05-31 20:17:21,754][root][INFO] - Step 145154560 @ 6650.7 SPS. Inference batcher size: 94. Learner queue size: 29. Other stats: (step = 145154560, mean_episode_return = 148.9, mean_episode_step = 721.51, total_loss = -62.023, pg_loss = -66.538, baseline_loss = 11.768, entropy_loss = -7.2537, learner_queue_size = 26, _tick = 48369, _time = 1.654e+09, train_seconds = 2.202e+04)
[2022-05-31 20:17:26,758][root][INFO] - Step 145187840 @ 6650.7 SPS. Inference batcher size: 72. Learner queue size: 30. Other stats: (step = 145187840, mean_episode_return = 45.195, mean_episode_step = 642.21, total_loss = 93.614, pg_loss = 33.762, baseline_loss = 66.246, entropy_loss = -6.3936, learner_queue_size = 16, _tick = 48380, _time = 1.654e+09, train_seconds = 2.2025e+04)
[2022-05-31 20:17:31,762][root][INFO] - Step 145221120 @ 6650.6 SPS. Inference batcher size: 142. Learner queue size: 19. Other stats: (step = 145221120, mean_episode_return = 135.56, mean_episode_step = 802.64, total_loss = 110.73, pg_loss = 41.883, baseline_loss = 75.171, entropy_loss = -6.3285, learner_queue_size = 17, _tick = 48392, _time = 1.654e+09, train_seconds = 2.203e+04)
[2022-05-31 20:17:36,768][root][INFO] - Step 145251840 @ 6136.5 SPS. Inference batcher size: 186. Learner queue size: 22. Other stats: (step = 145251840, mean_episode_return = 193.02, mean_episode_step = 726.61, total_loss = 30.152, pg_loss = -54.518, baseline_loss = 90.726, entropy_loss = -6.0563, learner_queue_size = 11, _tick = 48404, _time = 1.654e+09, train_seconds = 2.2036e+04)
[2022-05-31 20:17:41,774][root][INFO] - Step 145285120 @ 6648.0 SPS. Inference batcher size: 110. Learner queue size: 16. Other stats: (step = 145285120, mean_episode_return = 526.95, mean_episode_step = 597.05, total_loss = -65.733, pg_loss = -115.18, baseline_loss = 55.761, entropy_loss = -6.3183, learner_queue_size = 25, _tick = 48416, _time = 1.654e+09, train_seconds = 2.204e+04)
[2022-05-31 20:17:46,777][root][INFO] - Step 145318400 @ 6651.8 SPS. Inference batcher size: 167. Learner queue size: 13. Other stats: (step = 145318400, mean_episode_return = 230.37, mean_episode_step = 640.44, total_loss = 82.963, pg_loss = 7.3559, baseline_loss = 82.369, entropy_loss = -6.7613, learner_queue_size = 18, _tick = 48428, _time = 1.654e+09, train_seconds = 2.2046e+04)
[2022-05-31 20:17:51,782][root][INFO] - Step 145351680 @ 6649.7 SPS. Inference batcher size: 146. Learner queue size: 6. Other stats: (step = 145351680, mean_episode_return = 251.26, mean_episode_step = 725.29, total_loss = -85.576, pg_loss = -228.3, baseline_loss = 149.45, entropy_loss = -6.7244, learner_queue_size = 18, _tick = 48440, _time = 1.654e+09, train_seconds = 2.205e+04)
[2022-05-31 20:17:56,786][root][INFO] - Step 145384960 @ 6650.6 SPS. Inference batcher size: 115. Learner queue size: 7. Other stats: (step = 145384960, mean_episode_return = 237.64, mean_episode_step = 540.95, total_loss = 30.066, pg_loss = -101.81, baseline_loss = 138.0, entropy_loss = -6.1264, learner_queue_size = 24, _tick = 48452, _time = 1.654e+09, train_seconds = 2.2056e+04)
[2022-05-31 20:18:01,792][root][INFO] - Step 145418240 @ 6648.0 SPS. Inference batcher size: 197. Learner queue size: 4. Other stats: (step = 145418240, mean_episode_return = None, mean_episode_step = 616.28, total_loss = 151.28, pg_loss = 83.421, baseline_loss = 74.48, entropy_loss = -6.6228, learner_queue_size = 24, _tick = 48464, _time = 1.654e+09, train_seconds = 2.206e+04)
[2022-05-31 20:18:06,798][root][INFO] - Step 145451520 @ 6648.2 SPS. Inference batcher size: 70. Learner queue size: 29. Other stats: (step = 145451520, mean_episode_return = 266.61, mean_episode_step = 666.16, total_loss = 19.868, pg_loss = -28.878, baseline_loss = 55.711, entropy_loss = -6.9639, learner_queue_size = 21, _tick = 48474, _time = 1.654e+09, train_seconds = 2.2066e+04)
[2022-05-31 20:18:11,802][root][INFO] - Step 145484800 @ 6650.6 SPS. Inference batcher size: 127. Learner queue size: 15. Other stats: (step = 145484800, mean_episode_return = 371.96, mean_episode_step = 726.78, total_loss = 127.03, pg_loss = 38.863, baseline_loss = 94.574, entropy_loss = -6.4025, learner_queue_size = 12, _tick = 48484, _time = 1.654e+09, train_seconds = 2.207e+04)
[2022-05-31 20:18:16,808][root][INFO] - Step 145515520 @ 6136.4 SPS. Inference batcher size: 84. Learner queue size: 26. Other stats: (step = 145515520, mean_episode_return = 204.2, mean_episode_step = 540.46, total_loss = 178.3, pg_loss = 75.559, baseline_loss = 108.34, entropy_loss = -5.5994, learner_queue_size = 15, _tick = 48495, _time = 1.654e+09, train_seconds = 2.2076e+04)
[2022-05-31 20:18:21,811][root][INFO] - Step 145548800 @ 6652.2 SPS. Inference batcher size: 79. Learner queue size: 20. Other stats: (step = 145548800, mean_episode_return = None, mean_episode_step = 826.59, total_loss = -47.246, pg_loss = -127.44, baseline_loss = 86.62, entropy_loss = -6.4301, learner_queue_size = 24, _tick = 48507, _time = 1.654e+09, train_seconds = 2.208e+04)
[2022-05-31 20:18:26,814][root][INFO] - Step 145582080 @ 6652.1 SPS. Inference batcher size: 93. Learner queue size: 23. Other stats: (step = 145582080, mean_episode_return = 99.263, mean_episode_step = 625.53, total_loss = -278.28, pg_loss = -329.13, baseline_loss = 56.743, entropy_loss = -5.8956, learner_queue_size = 20, _tick = 48520, _time = 1.654e+09, train_seconds = 2.2086e+04)
[2022-05-31 20:18:31,818][root][INFO] - Step 145615360 @ 6650.7 SPS. Inference batcher size: 123. Learner queue size: 8. Other stats: (step = 145615360, mean_episode_return = 149.74, mean_episode_step = 677.36, total_loss = 138.06, pg_loss = 55.634, baseline_loss = 88.596, entropy_loss = -6.1702, learner_queue_size = 21, _tick = 48533, _time = 1.654e+09, train_seconds = 2.209e+04)
[2022-05-31 20:18:36,823][root][INFO] - Step 145648640 @ 6649.4 SPS. Inference batcher size: 116. Learner queue size: 8. Other stats: (step = 145648640, mean_episode_return = 127.77, mean_episode_step = 854.4, total_loss = 64.161, pg_loss = -6.4944, baseline_loss = 76.997, entropy_loss = -6.341, learner_queue_size = 17, _tick = 48545, _time = 1.654e+09, train_seconds = 2.2096e+04)
[2022-05-31 20:18:41,826][root][INFO] - Step 145681920 @ 6651.9 SPS. Inference batcher size: 104. Learner queue size: 3. Other stats: (step = 145681920, mean_episode_return = 274.58, mean_episode_step = 690.08, total_loss = -23.174, pg_loss = -70.363, baseline_loss = 53.737, entropy_loss = -6.5484, learner_queue_size = 23, _tick = 48558, _time = 1.654e+09, train_seconds = 2.21e+04)
[2022-05-31 20:18:46,830][root][INFO] - Step 145715200 @ 6650.7 SPS. Inference batcher size: 120. Learner queue size: 3. Other stats: (step = 145715200, mean_episode_return = 423.33, mean_episode_step = 620.94, total_loss = 76.689, pg_loss = 18.738, baseline_loss = 64.186, entropy_loss = -6.2355, learner_queue_size = 18, _tick = 48570, _time = 1.654e+09, train_seconds = 2.2106e+04)
[2022-05-31 20:18:51,834][root][INFO] - Step 145748480 @ 6650.6 SPS. Inference batcher size: 23. Learner queue size: 19. Other stats: (step = 145748480, mean_episode_return = 208.0, mean_episode_step = 633.67, total_loss = 44.282, pg_loss = -14.619, baseline_loss = 64.929, entropy_loss = -6.0283, learner_queue_size = 17, _tick = 48582, _time = 1.654e+09, train_seconds = 2.211e+04)
[2022-05-31 20:18:56,840][root][INFO] - Step 145779200 @ 6136.6 SPS. Inference batcher size: 146. Learner queue size: 11. Other stats: (step = 145779200, mean_episode_return = 259.41, mean_episode_step = 788.69, total_loss = 230.17, pg_loss = 3.7217, baseline_loss = 232.23, entropy_loss = -5.7865, learner_queue_size = 14, _tick = 48593, _time = 1.654e+09, train_seconds = 2.2116e+04)
[2022-05-31 20:19:01,846][root][INFO] - Step 145812480 @ 6648.1 SPS. Inference batcher size: 161. Learner queue size: 1. Other stats: (step = 145812480, mean_episode_return = 241.43, mean_episode_step = 498.71, total_loss = 34.019, pg_loss = -18.517, baseline_loss = 58.394, entropy_loss = -5.8584, learner_queue_size = 17, _tick = 48605, _time = 1.654e+09, train_seconds = 2.212e+04)
[2022-05-31 20:19:06,850][root][INFO] - Step 145845760 @ 6650.5 SPS. Inference batcher size: 129. Learner queue size: 7. Other stats: (step = 145845760, mean_episode_return = 326.24, mean_episode_step = 452.45, total_loss = 172.98, pg_loss = 80.471, baseline_loss = 98.121, entropy_loss = -5.6172, learner_queue_size = 16, _tick = 48618, _time = 1.654e+09, train_seconds = 2.2126e+04)
[2022-05-31 20:19:11,854][root][INFO] - Step 145879040 @ 6650.7 SPS. Inference batcher size: 135. Learner queue size: 15. Other stats: (step = 145879040, mean_episode_return = 236.61, mean_episode_step = 846.31, total_loss = 119.44, pg_loss = -8.02, baseline_loss = 134.02, entropy_loss = -6.5549, learner_queue_size = 21, _tick = 48629, _time = 1.654e+09, train_seconds = 2.213e+04)
[2022-05-31 20:19:16,860][root][INFO] - Step 145912320 @ 6647.9 SPS. Inference batcher size: 105. Learner queue size: 2. Other stats: (step = 145912320, mean_episode_return = 299.53, mean_episode_step = 644.9, total_loss = -340.56, pg_loss = -455.99, baseline_loss = 121.71, entropy_loss = -6.2824, learner_queue_size = 20, _tick = 48642, _time = 1.654e+09, train_seconds = 2.2136e+04)
[2022-05-31 20:19:21,866][root][INFO] - Step 145945600 @ 6648.1 SPS. Inference batcher size: 106. Learner queue size: 29. Other stats: (step = 145945600, mean_episode_return = 295.15, mean_episode_step = 617.31, total_loss = 15.915, pg_loss = -87.827, baseline_loss = 110.57, entropy_loss = -6.8324, learner_queue_size = 17, _tick = 48654, _time = 1.654e+09, train_seconds = 2.2141e+04)
[2022-05-31 20:19:26,872][root][INFO] - Step 145976320 @ 6136.5 SPS. Inference batcher size: 158. Learner queue size: 16. Other stats: (step = 145976320, mean_episode_return = 194.81, mean_episode_step = 534.63, total_loss = -193.82, pg_loss = -243.79, baseline_loss = 56.231, entropy_loss = -6.2596, learner_queue_size = 23, _tick = 48665, _time = 1.654e+09, train_seconds = 2.2146e+04)
[2022-05-31 20:19:31,876][root][INFO] - Step 146009600 @ 6650.6 SPS. Inference batcher size: 133. Learner queue size: 23. Other stats: (step = 146009600, mean_episode_return = 192.66, mean_episode_step = 700.15, total_loss = 141.37, pg_loss = 51.956, baseline_loss = 95.746, entropy_loss = -6.3365, learner_queue_size = 16, _tick = 48678, _time = 1.654e+09, train_seconds = 2.2151e+04)
[2022-05-31 20:19:36,882][root][INFO] - Step 146042880 @ 6648.0 SPS. Inference batcher size: 115. Learner queue size: 16. Other stats: (step = 146042880, mean_episode_return = 670.38, mean_episode_step = 765.09, total_loss = 210.62, pg_loss = 100.02, baseline_loss = 116.34, entropy_loss = -5.7475, learner_queue_size = 21, _tick = 48690, _time = 1.654e+09, train_seconds = 2.2156e+04)
[2022-05-31 20:19:41,886][root][INFO] - Step 146076160 @ 6651.0 SPS. Inference batcher size: 123. Learner queue size: 12. Other stats: (step = 146076160, mean_episode_return = 387.46, mean_episode_step = 489.92, total_loss = -51.295, pg_loss = -196.93, baseline_loss = 151.01, entropy_loss = -5.3768, learner_queue_size = 21, _tick = 48703, _time = 1.654e+09, train_seconds = 2.2161e+04)
[2022-05-31 20:19:46,892][root][INFO] - Step 146109440 @ 6648.0 SPS. Inference batcher size: 12. Learner queue size: 9. Other stats: (step = 146109440, mean_episode_return = 161.84, mean_episode_step = 576.22, total_loss = -26.892, pg_loss = -116.71, baseline_loss = 95.525, entropy_loss = -5.7101, learner_queue_size = 19, _tick = 48716, _time = 1.654e+09, train_seconds = 2.2166e+04)
[2022-05-31 20:19:51,894][root][INFO] - Step 146142720 @ 6653.4 SPS. Inference batcher size: 41. Learner queue size: 5. Other stats: (step = 146142720, mean_episode_return = 351.15, mean_episode_step = 702.12, total_loss = 95.406, pg_loss = 64.889, baseline_loss = 36.562, entropy_loss = -6.0445, learner_queue_size = 14, _tick = 48729, _time = 1.654e+09, train_seconds = 2.2171e+04)
[2022-05-31 20:19:56,898][root][INFO] - Step 146176000 @ 6650.4 SPS. Inference batcher size: 8. Learner queue size: 20. Other stats: (step = 146176000, mean_episode_return = 120.26, mean_episode_step = 622.34, total_loss = -193.18, pg_loss = -223.85, baseline_loss = 36.741, entropy_loss = -6.073, learner_queue_size = 18, _tick = 48742, _time = 1.654e+09, train_seconds = 2.2176e+04)
[2022-05-31 20:20:01,902][root][INFO] - Step 146209280 @ 6650.8 SPS. Inference batcher size: 170. Learner queue size: 24. Other stats: (step = 146209280, mean_episode_return = 489.34, mean_episode_step = 627.34, total_loss = 193.19, pg_loss = 151.36, baseline_loss = 48.406, entropy_loss = -6.5737, learner_queue_size = 15, _tick = 48755, _time = 1.654e+09, train_seconds = 2.2181e+04)
[2022-05-31 20:20:06,908][root][INFO] - Step 146240000 @ 6136.6 SPS. Inference batcher size: 111. Learner queue size: 20. Other stats: (step = 146240000, mean_episode_return = 230.4, mean_episode_step = 557.38, total_loss = 209.0, pg_loss = 135.46, baseline_loss = 79.493, entropy_loss = -5.9595, learner_queue_size = 20, _tick = 48766, _time = 1.654e+09, train_seconds = 2.2186e+04)
[2022-05-31 20:20:11,914][root][INFO] - Step 146273280 @ 6648.1 SPS. Inference batcher size: 118. Learner queue size: 16. Other stats: (step = 146273280, mean_episode_return = 139.41, mean_episode_step = 708.17, total_loss = 304.05, pg_loss = 246.28, baseline_loss = 63.759, entropy_loss = -5.9862, learner_queue_size = 21, _tick = 48778, _time = 1.654e+09, train_seconds = 2.2191e+04)
[2022-05-31 20:20:16,918][root][INFO] - Step 146306560 @ 6650.7 SPS. Inference batcher size: 124. Learner queue size: 16. Other stats: (step = 146306560, mean_episode_return = 204.06, mean_episode_step = 484.65, total_loss = 332.5, pg_loss = 236.01, baseline_loss = 102.34, entropy_loss = -5.8429, learner_queue_size = 11, _tick = 48790, _time = 1.654e+09, train_seconds = 2.2196e+04)
[2022-05-31 20:20:21,924][root][INFO] - Step 146339840 @ 6647.9 SPS. Inference batcher size: 85. Learner queue size: 8. Other stats: (step = 146339840, mean_episode_return = 239.23, mean_episode_step = 761.3, total_loss = 115.61, pg_loss = 46.865, baseline_loss = 75.226, entropy_loss = -6.4824, learner_queue_size = 20, _tick = 48802, _time = 1.654e+09, train_seconds = 2.2201e+04)
[2022-05-31 20:20:26,930][root][INFO] - Step 146373120 @ 6648.1 SPS. Inference batcher size: 74. Learner queue size: 7. Other stats: (step = 146373120, mean_episode_return = 554.36, mean_episode_step = 636.69, total_loss = 388.62, pg_loss = 61.463, baseline_loss = 333.29, entropy_loss = -6.1368, learner_queue_size = 24, _tick = 48814, _time = 1.654e+09, train_seconds = 2.2206e+04)
[2022-05-31 20:20:31,938][root][INFO] - Step 146406400 @ 6645.3 SPS. Inference batcher size: 86. Learner queue size: 1. Other stats: (step = 146406400, mean_episode_return = 248.4, mean_episode_step = 599.16, total_loss = 26.195, pg_loss = -44.525, baseline_loss = 76.763, entropy_loss = -6.0434, learner_queue_size = 24, _tick = 48826, _time = 1.654e+09, train_seconds = 2.2211e+04)
[2022-05-31 20:20:36,942][root][INFO] - Step 146439680 @ 6650.7 SPS. Inference batcher size: 57. Learner queue size: 22. Other stats: (step = 146439680, mean_episode_return = 413.98, mean_episode_step = 500.68, total_loss = 512.96, pg_loss = 332.47, baseline_loss = 186.18, entropy_loss = -5.6875, learner_queue_size = 20, _tick = 48838, _time = 1.654e+09, train_seconds = 2.2216e+04)
[2022-05-31 20:20:41,946][root][INFO] - Step 146472960 @ 6650.8 SPS. Inference batcher size: 112. Learner queue size: 15. Other stats: (step = 146472960, mean_episode_return = 255.24, mean_episode_step = 813.84, total_loss = 92.586, pg_loss = 2.9556, baseline_loss = 96.234, entropy_loss = -6.6034, learner_queue_size = 8, _tick = 48848, _time = 1.654e+09, train_seconds = 2.2221e+04)
[2022-05-31 20:20:46,950][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 20:20:47,127][root][INFO] - Step 146503680 @ 6139.0 SPS. Inference batcher size: 92. Learner queue size: 26. Other stats: (step = 146506240, mean_episode_return = 101.62, mean_episode_step = 747.74, total_loss = 112.33, pg_loss = 51.902, baseline_loss = 67.027, entropy_loss = -6.5961, learner_queue_size = 22, _tick = 48859, _time = 1.654e+09, train_seconds = 2.2226e+04)
[2022-05-31 20:20:52,133][root][INFO] - Step 146536960 @ 6421.4 SPS. Inference batcher size: 69. Learner queue size: 13. Other stats: (step = 146536960, mean_episode_return = 475.34, mean_episode_step = 684.52, total_loss = 189.09, pg_loss = 49.329, baseline_loss = 146.13, entropy_loss = -6.3699, learner_queue_size = 19, _tick = 48870, _time = 1.654e+09, train_seconds = 2.2231e+04)
[2022-05-31 20:20:57,138][root][INFO] - Step 146570240 @ 6648.3 SPS. Inference batcher size: 171. Learner queue size: 15. Other stats: (step = 146570240, mean_episode_return = 37.37, mean_episode_step = 594.07, total_loss = 164.94, pg_loss = 106.16, baseline_loss = 65.265, entropy_loss = -6.4782, learner_queue_size = 23, _tick = 48883, _time = 1.654e+09, train_seconds = 2.2236e+04)
[2022-05-31 20:21:02,144][root][INFO] - Step 146603520 @ 6648.5 SPS. Inference batcher size: 130. Learner queue size: 10. Other stats: (step = 146603520, mean_episode_return = 250.82, mean_episode_step = 827.16, total_loss = 33.145, pg_loss = -30.327, baseline_loss = 70.623, entropy_loss = -7.1516, learner_queue_size = 20, _tick = 48893, _time = 1.654e+09, train_seconds = 2.2241e+04)
[2022-05-31 20:21:07,146][root][INFO] - Step 146636800 @ 6653.5 SPS. Inference batcher size: 117. Learner queue size: 22. Other stats: (step = 146636800, mean_episode_return = 95.997, mean_episode_step = 760.12, total_loss = 482.74, pg_loss = 206.02, baseline_loss = 283.55, entropy_loss = -6.8289, learner_queue_size = 20, _tick = 48904, _time = 1.654e+09, train_seconds = 2.2246e+04)
[2022-05-31 20:21:12,150][root][INFO] - Step 146670080 @ 6650.8 SPS. Inference batcher size: 97. Learner queue size: 13. Other stats: (step = 146670080, mean_episode_return = None, mean_episode_step = 848.28, total_loss = -56.976, pg_loss = -98.07, baseline_loss = 47.877, entropy_loss = -6.7831, learner_queue_size = 21, _tick = 48916, _time = 1.654e+09, train_seconds = 2.2251e+04)
[2022-05-31 20:21:17,154][root][INFO] - Step 146703360 @ 6650.7 SPS. Inference batcher size: 151. Learner queue size: 9. Other stats: (step = 146703360, mean_episode_return = 246.33, mean_episode_step = 752.2, total_loss = 216.1, pg_loss = 83.802, baseline_loss = 139.31, entropy_loss = -7.0063, learner_queue_size = 16, _tick = 48929, _time = 1.654e+09, train_seconds = 2.2256e+04)
[2022-05-31 20:21:22,158][root][INFO] - Step 146736640 @ 6650.5 SPS. Inference batcher size: 180. Learner queue size: 6. Other stats: (step = 146736640, mean_episode_return = 255.25, mean_episode_step = 768.94, total_loss = 44.211, pg_loss = 33.172, baseline_loss = 18.632, entropy_loss = -7.5927, learner_queue_size = 19, _tick = 48941, _time = 1.654e+09, train_seconds = 2.2261e+04)
[2022-05-31 20:21:27,162][root][INFO] - Step 146769920 @ 6650.8 SPS. Inference batcher size: 120. Learner queue size: 11. Other stats: (step = 146769920, mean_episode_return = 685.29, mean_episode_step = 708.78, total_loss = 47.183, pg_loss = 18.879, baseline_loss = 35.624, entropy_loss = -7.32, learner_queue_size = 15, _tick = 48953, _time = 1.654e+09, train_seconds = 2.2266e+04)
[2022-05-31 20:21:32,166][root][INFO] - Step 146803200 @ 6650.6 SPS. Inference batcher size: 51. Learner queue size: 3. Other stats: (step = 146803200, mean_episode_return = 86.039, mean_episode_step = 850.94, total_loss = 361.72, pg_loss = 264.59, baseline_loss = 103.76, entropy_loss = -6.6282, learner_queue_size = 17, _tick = 48963, _time = 1.654e+09, train_seconds = 2.2271e+04)
[2022-05-31 20:21:37,170][root][INFO] - Step 146836480 @ 6650.7 SPS. Inference batcher size: 96. Learner queue size: 4. Other stats: (step = 146836480, mean_episode_return = 286.03, mean_episode_step = 601.04, total_loss = 201.81, pg_loss = -91.759, baseline_loss = 299.28, entropy_loss = -5.7134, learner_queue_size = 22, _tick = 48975, _time = 1.654e+09, train_seconds = 2.2276e+04)
[2022-05-31 20:21:42,174][root][INFO] - Step 146869760 @ 6650.7 SPS. Inference batcher size: 114. Learner queue size: 4. Other stats: (step = 146869760, mean_episode_return = 295.05, mean_episode_step = 732.15, total_loss = -58.463, pg_loss = -199.95, baseline_loss = 148.02, entropy_loss = -6.5352, learner_queue_size = 21, _tick = 48985, _time = 1.654e+09, train_seconds = 2.2281e+04)
[2022-05-31 20:21:47,178][root][INFO] - Step 146903040 @ 6650.3 SPS. Inference batcher size: 16. Learner queue size: 30. Other stats: (step = 146903040, mean_episode_return = 108.32, mean_episode_step = 713.93, total_loss = 254.21, pg_loss = 152.35, baseline_loss = 108.03, entropy_loss = -6.1699, learner_queue_size = 27, _tick = 48996, _time = 1.654e+09, train_seconds = 2.2286e+04)
[2022-05-31 20:21:52,182][root][INFO] - Step 146936320 @ 6651.1 SPS. Inference batcher size: 124. Learner queue size: 31. Other stats: (step = 146936320, mean_episode_return = 230.83, mean_episode_step = 650.78, total_loss = -166.07, pg_loss = -230.52, baseline_loss = 70.559, entropy_loss = -6.1102, learner_queue_size = 18, _tick = 49009, _time = 1.654e+09, train_seconds = 2.2291e+04)
[2022-05-31 20:21:57,186][root][INFO] - Step 146969600 @ 6650.1 SPS. Inference batcher size: 125. Learner queue size: 31. Other stats: (step = 146969600, mean_episode_return = 282.52, mean_episode_step = 807.78, total_loss = 212.74, pg_loss = 145.47, baseline_loss = 74.19, entropy_loss = -6.9217, learner_queue_size = 20, _tick = 49020, _time = 1.654e+09, train_seconds = 2.2296e+04)
[2022-05-31 20:22:02,193][root][INFO] - Step 147000320 @ 6136.1 SPS. Inference batcher size: 156. Learner queue size: 14. Other stats: (step = 147000320, mean_episode_return = 218.34, mean_episode_step = 711.15, total_loss = -142.0, pg_loss = -209.21, baseline_loss = 73.806, entropy_loss = -6.6002, learner_queue_size = 18, _tick = 49031, _time = 1.654e+09, train_seconds = 2.2301e+04)
[2022-05-31 20:22:07,199][root][INFO] - Step 147033600 @ 6648.1 SPS. Inference batcher size: 175. Learner queue size: 12. Other stats: (step = 147033600, mean_episode_return = 203.57, mean_episode_step = 864.72, total_loss = 238.47, pg_loss = 55.839, baseline_loss = 189.17, entropy_loss = -6.5429, learner_queue_size = 19, _tick = 49043, _time = 1.654e+09, train_seconds = 2.2306e+04)
[2022-05-31 20:22:12,202][root][INFO] - Step 147066880 @ 6651.8 SPS. Inference batcher size: 129. Learner queue size: 9. Other stats: (step = 147066880, mean_episode_return = 205.83, mean_episode_step = 732.88, total_loss = -43.044, pg_loss = -134.13, baseline_loss = 97.827, entropy_loss = -6.7439, learner_queue_size = 22, _tick = 49055, _time = 1.654e+09, train_seconds = 2.2311e+04)
[2022-05-31 20:22:17,206][root][INFO] - Step 147100160 @ 6650.6 SPS. Inference batcher size: 154. Learner queue size: 9. Other stats: (step = 147100160, mean_episode_return = 80.76, mean_episode_step = 913.35, total_loss = 210.18, pg_loss = 189.27, baseline_loss = 28.341, entropy_loss = -7.4369, learner_queue_size = 24, _tick = 49068, _time = 1.654e+09, train_seconds = 2.2316e+04)
[2022-05-31 20:22:22,210][root][INFO] - Step 147133440 @ 6650.7 SPS. Inference batcher size: 119. Learner queue size: 2. Other stats: (step = 147133440, mean_episode_return = 396.28, mean_episode_step = 704.49, total_loss = -4.1092, pg_loss = -62.384, baseline_loss = 65.166, entropy_loss = -6.8913, learner_queue_size = 29, _tick = 49081, _time = 1.654e+09, train_seconds = 2.2321e+04)
[2022-05-31 20:22:27,216][root][INFO] - Step 147166720 @ 6648.0 SPS. Inference batcher size: 133. Learner queue size: 2. Other stats: (step = 147166720, mean_episode_return = 135.35, mean_episode_step = 666.62, total_loss = 101.54, pg_loss = 53.707, baseline_loss = 54.856, entropy_loss = -7.0218, learner_queue_size = 22, _tick = 49092, _time = 1.654e+09, train_seconds = 2.2326e+04)
[2022-05-31 20:22:32,222][root][INFO] - Step 147200000 @ 6648.0 SPS. Inference batcher size: 121. Learner queue size: 2. Other stats: (step = 147200000, mean_episode_return = 230.17, mean_episode_step = 868.38, total_loss = 353.9, pg_loss = 282.13, baseline_loss = 78.668, entropy_loss = -6.9053, learner_queue_size = 16, _tick = 49104, _time = 1.654e+09, train_seconds = 2.2331e+04)
[2022-05-31 20:22:37,226][root][INFO] - Step 147230720 @ 6139.2 SPS. Inference batcher size: 101. Learner queue size: 20. Other stats: (step = 147230720, mean_episode_return = 123.23, mean_episode_step = 574.92, total_loss = 116.42, pg_loss = 22.038, baseline_loss = 100.88, entropy_loss = -6.4902, learner_queue_size = 17, _tick = 49114, _time = 1.654e+09, train_seconds = 2.2336e+04)
[2022-05-31 20:22:42,232][root][INFO] - Step 147264000 @ 6647.9 SPS. Inference batcher size: 166. Learner queue size: 18. Other stats: (step = 147264000, mean_episode_return = 279.57, mean_episode_step = 708.53, total_loss = -21.37, pg_loss = -47.637, baseline_loss = 33.175, entropy_loss = -6.9087, learner_queue_size = 9, _tick = 49127, _time = 1.654e+09, train_seconds = 2.2341e+04)
[2022-05-31 20:22:47,238][root][INFO] - Step 147297280 @ 6648.1 SPS. Inference batcher size: 48. Learner queue size: 17. Other stats: (step = 147297280, mean_episode_return = 201.62, mean_episode_step = 694.29, total_loss = 174.41, pg_loss = 73.787, baseline_loss = 107.0, entropy_loss = -6.3766, learner_queue_size = 21, _tick = 49140, _time = 1.654e+09, train_seconds = 2.2346e+04)
[2022-05-31 20:22:52,242][root][INFO] - Step 147330560 @ 6650.8 SPS. Inference batcher size: 135. Learner queue size: 14. Other stats: (step = 147330560, mean_episode_return = 144.4, mean_episode_step = 564.5, total_loss = 23.75, pg_loss = -24.312, baseline_loss = 54.194, entropy_loss = -6.1321, learner_queue_size = 21, _tick = 49152, _time = 1.654e+09, train_seconds = 2.2351e+04)
[2022-05-31 20:22:57,248][root][INFO] - Step 147363840 @ 6648.0 SPS. Inference batcher size: 126. Learner queue size: 15. Other stats: (step = 147363840, mean_episode_return = 159.84, mean_episode_step = 653.11, total_loss = 258.67, pg_loss = 34.117, baseline_loss = 230.89, entropy_loss = -6.3426, learner_queue_size = 22, _tick = 49164, _time = 1.654e+09, train_seconds = 2.2356e+04)
[2022-05-31 20:23:02,254][root][INFO] - Step 147397120 @ 6648.1 SPS. Inference batcher size: 155. Learner queue size: 15. Other stats: (step = 147397120, mean_episode_return = 239.96, mean_episode_step = 686.32, total_loss = -91.336, pg_loss = -115.48, baseline_loss = 30.985, entropy_loss = -6.8387, learner_queue_size = 26, _tick = 49175, _time = 1.654e+09, train_seconds = 2.2361e+04)
[2022-05-31 20:23:07,260][root][INFO] - Step 147430400 @ 6648.0 SPS. Inference batcher size: 127. Learner queue size: 2. Other stats: (step = 147430400, mean_episode_return = 82.99, mean_episode_step = 613.97, total_loss = -82.836, pg_loss = -131.16, baseline_loss = 54.535, entropy_loss = -6.2156, learner_queue_size = 10, _tick = 49186, _time = 1.654e+09, train_seconds = 2.2366e+04)
[2022-05-31 20:23:12,262][root][INFO] - Step 147463680 @ 6653.3 SPS. Inference batcher size: 111. Learner queue size: 30. Other stats: (step = 147463680, mean_episode_return = 122.96, mean_episode_step = 639.13, total_loss = 23.789, pg_loss = -75.955, baseline_loss = 105.57, entropy_loss = -5.825, learner_queue_size = 25, _tick = 49198, _time = 1.654e+09, train_seconds = 2.2371e+04)
[2022-05-31 20:23:17,266][root][INFO] - Step 147496960 @ 6650.7 SPS. Inference batcher size: 87. Learner queue size: 30. Other stats: (step = 147496960, mean_episode_return = 339.63, mean_episode_step = 759.46, total_loss = 153.93, pg_loss = 31.844, baseline_loss = 128.12, entropy_loss = -6.0344, learner_queue_size = 23, _tick = 49210, _time = 1.654e+09, train_seconds = 2.2376e+04)
[2022-05-31 20:23:22,270][root][INFO] - Step 147530240 @ 6650.7 SPS. Inference batcher size: 34. Learner queue size: 23. Other stats: (step = 147530240, mean_episode_return = 449.14, mean_episode_step = 705.97, total_loss = -259.61, pg_loss = -289.88, baseline_loss = 36.321, entropy_loss = -6.0529, learner_queue_size = 20, _tick = 49220, _time = 1.654e+09, train_seconds = 2.2381e+04)
[2022-05-31 20:23:27,274][root][INFO] - Step 147563520 @ 6650.7 SPS. Inference batcher size: 125. Learner queue size: 12. Other stats: (step = 147563520, mean_episode_return = 297.25, mean_episode_step = 790.38, total_loss = 119.72, pg_loss = 20.309, baseline_loss = 105.43, entropy_loss = -6.0223, learner_queue_size = 12, _tick = 49233, _time = 1.654e+09, train_seconds = 2.2386e+04)
[2022-05-31 20:23:32,278][root][INFO] - Step 147594240 @ 6139.0 SPS. Inference batcher size: 81. Learner queue size: 17. Other stats: (step = 147594240, mean_episode_return = 1019.7, mean_episode_step = 704.36, total_loss = -144.89, pg_loss = -178.4, baseline_loss = 40.695, entropy_loss = -7.182, learner_queue_size = 18, _tick = 49242, _time = 1.654e+09, train_seconds = 2.2391e+04)
[2022-05-31 20:23:37,282][root][INFO] - Step 147627520 @ 6650.3 SPS. Inference batcher size: 124. Learner queue size: 7. Other stats: (step = 147627520, mean_episode_return = 190.1, mean_episode_step = 680.92, total_loss = -13.787, pg_loss = -156.05, baseline_loss = 149.28, entropy_loss = -7.0161, learner_queue_size = 25, _tick = 49255, _time = 1.654e+09, train_seconds = 2.2396e+04)
[2022-05-31 20:23:42,288][root][INFO] - Step 147660800 @ 6648.0 SPS. Inference batcher size: 178. Learner queue size: 2. Other stats: (step = 147660800, mean_episode_return = 414.29, mean_episode_step = 705.83, total_loss = 243.34, pg_loss = 165.26, baseline_loss = 84.826, entropy_loss = -6.7516, learner_queue_size = 21, _tick = 49265, _time = 1.654e+09, train_seconds = 2.2401e+04)
[2022-05-31 20:23:47,290][root][INFO] - Step 147694080 @ 6653.7 SPS. Inference batcher size: 114. Learner queue size: 6. Other stats: (step = 147694080, mean_episode_return = 138.21, mean_episode_step = 731.64, total_loss = 83.625, pg_loss = 49.313, baseline_loss = 40.419, entropy_loss = -6.107, learner_queue_size = 24, _tick = 49277, _time = 1.654e+09, train_seconds = 2.2406e+04)
[2022-05-31 20:23:52,294][root][INFO] - Step 147727360 @ 6650.8 SPS. Inference batcher size: 146. Learner queue size: 31. Other stats: (step = 147727360, mean_episode_return = 219.2, mean_episode_step = 723.56, total_loss = -360.02, pg_loss = -444.55, baseline_loss = 90.581, entropy_loss = -6.0539, learner_queue_size = 18, _tick = 49289, _time = 1.654e+09, train_seconds = 2.2411e+04)
[2022-05-31 20:23:57,300][root][INFO] - Step 147758080 @ 6136.6 SPS. Inference batcher size: 116. Learner queue size: 20. Other stats: (step = 147758080, mean_episode_return = 107.16, mean_episode_step = 640.8, total_loss = 56.644, pg_loss = 12.078, baseline_loss = 50.744, entropy_loss = -6.1774, learner_queue_size = 15, _tick = 49299, _time = 1.654e+09, train_seconds = 2.2416e+04)
[2022-05-31 20:24:02,306][root][INFO] - Step 147793920 @ 7159.5 SPS. Inference batcher size: 1. Learner queue size: 19. Other stats: (step = 147793920, mean_episode_return = 294.02, mean_episode_step = 654.82, total_loss = -72.848, pg_loss = -234.85, baseline_loss = 167.71, entropy_loss = -5.7125, learner_queue_size = 11, _tick = 49310, _time = 1.654e+09, train_seconds = 2.2421e+04)
[2022-05-31 20:24:07,313][root][INFO] - Step 147824640 @ 6135.5 SPS. Inference batcher size: 180. Learner queue size: 12. Other stats: (step = 147824640, mean_episode_return = 365.7, mean_episode_step = 822.13, total_loss = 39.982, pg_loss = -173.8, baseline_loss = 219.8, entropy_loss = -6.014, learner_queue_size = 25, _tick = 49321, _time = 1.654e+09, train_seconds = 2.2426e+04)
[2022-05-31 20:24:12,319][root][INFO] - Step 147857920 @ 6648.1 SPS. Inference batcher size: 132. Learner queue size: 14. Other stats: (step = 147857920, mean_episode_return = 254.01, mean_episode_step = 838.64, total_loss = 136.21, pg_loss = -67.716, baseline_loss = 209.7, entropy_loss = -5.7789, learner_queue_size = 25, _tick = 49334, _time = 1.654e+09, train_seconds = 2.2431e+04)
[2022-05-31 20:24:17,325][root][INFO] - Step 147891200 @ 6648.1 SPS. Inference batcher size: 153. Learner queue size: 18. Other stats: (step = 147891200, mean_episode_return = 361.08, mean_episode_step = 791.59, total_loss = 422.57, pg_loss = 91.322, baseline_loss = 337.35, entropy_loss = -6.1081, learner_queue_size = 25, _tick = 49344, _time = 1.654e+09, train_seconds = 2.2436e+04)
[2022-05-31 20:24:22,330][root][INFO] - Step 147924480 @ 6649.1 SPS. Inference batcher size: 47. Learner queue size: 1. Other stats: (step = 147924480, mean_episode_return = 290.75, mean_episode_step = 760.11, total_loss = -92.339, pg_loss = -185.41, baseline_loss = 99.238, entropy_loss = -6.1644, learner_queue_size = 18, _tick = 49355, _time = 1.654e+09, train_seconds = 2.2441e+04)
[2022-05-31 20:24:27,334][root][INFO] - Step 147957760 @ 6650.7 SPS. Inference batcher size: 121. Learner queue size: 8. Other stats: (step = 147957760, mean_episode_return = 733.6, mean_episode_step = 740.93, total_loss = 462.43, pg_loss = 219.87, baseline_loss = 248.61, entropy_loss = -6.0519, learner_queue_size = 20, _tick = 49367, _time = 1.654e+09, train_seconds = 2.2446e+04)
[2022-05-31 20:24:32,338][root][INFO] - Step 147991040 @ 6650.7 SPS. Inference batcher size: 38. Learner queue size: 22. Other stats: (step = 147991040, mean_episode_return = None, mean_episode_step = 809.56, total_loss = -20.075, pg_loss = -86.96, baseline_loss = 73.409, entropy_loss = -6.5243, learner_queue_size = 17, _tick = 49377, _time = 1.654e+09, train_seconds = 2.2451e+04)
[2022-05-31 20:24:37,344][root][INFO] - Step 148021760 @ 6136.2 SPS. Inference batcher size: 116. Learner queue size: 16. Other stats: (step = 148021760, mean_episode_return = None, mean_episode_step = 746.28, total_loss = 181.03, pg_loss = 79.328, baseline_loss = 108.21, entropy_loss = -6.509, learner_queue_size = 23, _tick = 49386, _time = 1.654e+09, train_seconds = 2.2456e+04)
[2022-05-31 20:24:42,350][root][INFO] - Step 148055040 @ 6648.1 SPS. Inference batcher size: 69. Learner queue size: 14. Other stats: (step = 148055040, mean_episode_return = 304.31, mean_episode_step = 691.15, total_loss = 392.06, pg_loss = 174.69, baseline_loss = 223.72, entropy_loss = -6.3537, learner_queue_size = 14, _tick = 49398, _time = 1.654e+09, train_seconds = 2.2461e+04)
[2022-05-31 20:24:47,356][root][INFO] - Step 148088320 @ 6648.1 SPS. Inference batcher size: 183. Learner queue size: 10. Other stats: (step = 148088320, mean_episode_return = 466.87, mean_episode_step = 686.58, total_loss = 259.51, pg_loss = 130.64, baseline_loss = 134.51, entropy_loss = -5.6349, learner_queue_size = 12, _tick = 49410, _time = 1.654e+09, train_seconds = 2.2466e+04)
[2022-05-31 20:24:52,362][root][INFO] - Step 148121600 @ 6648.3 SPS. Inference batcher size: 122. Learner queue size: 21. Other stats: (step = 148121600, mean_episode_return = 196.44, mean_episode_step = 772.23, total_loss = 15.279, pg_loss = -222.8, baseline_loss = 244.22, entropy_loss = -6.1358, learner_queue_size = 17, _tick = 49421, _time = 1.654e+09, train_seconds = 2.2471e+04)
[2022-05-31 20:24:57,366][root][INFO] - Step 148154880 @ 6650.7 SPS. Inference batcher size: 74. Learner queue size: 2. Other stats: (step = 148154880, mean_episode_return = 315.45, mean_episode_step = 617.71, total_loss = 77.525, pg_loss = -53.723, baseline_loss = 137.28, entropy_loss = -6.0288, learner_queue_size = 28, _tick = 49432, _time = 1.654e+09, train_seconds = 2.2476e+04)
[2022-05-31 20:25:02,370][root][INFO] - Step 148188160 @ 6650.7 SPS. Inference batcher size: 53. Learner queue size: 1. Other stats: (step = 148188160, mean_episode_return = 214.92, mean_episode_step = 764.6, total_loss = 87.509, pg_loss = 59.984, baseline_loss = 33.842, entropy_loss = -6.3173, learner_queue_size = 24, _tick = 49444, _time = 1.654e+09, train_seconds = 2.2481e+04)
[2022-05-31 20:25:07,374][root][INFO] - Step 148221440 @ 6650.7 SPS. Inference batcher size: 66. Learner queue size: 3. Other stats: (step = 148221440, mean_episode_return = 326.41, mean_episode_step = 721.28, total_loss = 60.63, pg_loss = 42.302, baseline_loss = 24.532, entropy_loss = -6.2039, learner_queue_size = 27, _tick = 49455, _time = 1.654e+09, train_seconds = 2.2486e+04)
[2022-05-31 20:25:12,380][root][INFO] - Step 148252160 @ 6137.0 SPS. Inference batcher size: 70. Learner queue size: 18. Other stats: (step = 148252160, mean_episode_return = 98.766, mean_episode_step = 493.1, total_loss = 490.54, pg_loss = 348.55, baseline_loss = 147.49, entropy_loss = -5.499, learner_queue_size = 16, _tick = 49464, _time = 1.654e+09, train_seconds = 2.2491e+04)
[2022-05-31 20:25:17,382][root][INFO] - Step 148285440 @ 6652.9 SPS. Inference batcher size: 73. Learner queue size: 7. Other stats: (step = 148285440, mean_episode_return = 752.44, mean_episode_step = 651.61, total_loss = 79.611, pg_loss = 36.227, baseline_loss = 49.683, entropy_loss = -6.2992, learner_queue_size = 22, _tick = 49475, _time = 1.654e+09, train_seconds = 2.2496e+04)
[2022-05-31 20:25:22,386][root][INFO] - Step 148318720 @ 6650.7 SPS. Inference batcher size: 54. Learner queue size: 30. Other stats: (step = 148318720, mean_episode_return = 302.42, mean_episode_step = 645.48, total_loss = -111.4, pg_loss = -218.38, baseline_loss = 112.69, entropy_loss = -5.7166, learner_queue_size = 22, _tick = 49487, _time = 1.654e+09, train_seconds = 2.2501e+04)
[2022-05-31 20:25:27,390][root][INFO] - Step 148352000 @ 6650.1 SPS. Inference batcher size: 26. Learner queue size: 17. Other stats: (step = 148352000, mean_episode_return = 130.89, mean_episode_step = 805.39, total_loss = 67.894, pg_loss = 30.774, baseline_loss = 43.195, entropy_loss = -6.0738, learner_queue_size = 17, _tick = 49499, _time = 1.654e+09, train_seconds = 2.2506e+04)
[2022-05-31 20:25:32,394][root][INFO] - Step 148385280 @ 6651.2 SPS. Inference batcher size: 78. Learner queue size: 2. Other stats: (step = 148385280, mean_episode_return = None, mean_episode_step = 700.72, total_loss = 39.964, pg_loss = -9.3467, baseline_loss = 55.687, entropy_loss = -6.3759, learner_queue_size = 26, _tick = 49510, _time = 1.654e+09, train_seconds = 2.2511e+04)
[2022-05-31 20:25:37,398][root][INFO] - Step 148418560 @ 6650.7 SPS. Inference batcher size: 143. Learner queue size: 0. Other stats: (step = 148418560, mean_episode_return = 179.28, mean_episode_step = 576.55, total_loss = 27.285, pg_loss = 15.148, baseline_loss = 18.987, entropy_loss = -6.849, learner_queue_size = 27, _tick = 49523, _time = 1.654e+09, train_seconds = 2.2516e+04)
[2022-05-31 20:25:42,404][root][INFO] - Step 148451840 @ 6647.7 SPS. Inference batcher size: 129. Learner queue size: 0. Other stats: (step = 148451840, mean_episode_return = 141.69, mean_episode_step = 721.04, total_loss = 252.52, pg_loss = 172.41, baseline_loss = 86.245, entropy_loss = -6.1321, learner_queue_size = 19, _tick = 49535, _time = 1.654e+09, train_seconds = 2.2521e+04)
[2022-05-31 20:25:47,410][root][INFO] - Step 148482560 @ 6137.0 SPS. Inference batcher size: 93. Learner queue size: 28. Other stats: (step = 148482560, mean_episode_return = 217.67, mean_episode_step = 561.86, total_loss = 246.0, pg_loss = 87.586, baseline_loss = 163.92, entropy_loss = -5.5024, learner_queue_size = 26, _tick = 49547, _time = 1.654e+09, train_seconds = 2.2526e+04)
[2022-05-31 20:25:52,416][root][INFO] - Step 148515840 @ 6648.0 SPS. Inference batcher size: 123. Learner queue size: 15. Other stats: (step = 148515840, mean_episode_return = 151.23, mean_episode_step = 911.29, total_loss = -354.0, pg_loss = -425.65, baseline_loss = 77.221, entropy_loss = -5.5771, learner_queue_size = 8, _tick = 49559, _time = 1.654e+09, train_seconds = 2.2531e+04)
[2022-05-31 20:25:57,422][root][INFO] - Step 148549120 @ 6648.0 SPS. Inference batcher size: 142. Learner queue size: 21. Other stats: (step = 148549120, mean_episode_return = 233.32, mean_episode_step = 666.76, total_loss = -154.02, pg_loss = -200.7, baseline_loss = 52.615, entropy_loss = -5.9397, learner_queue_size = 22, _tick = 49570, _time = 1.654e+09, train_seconds = 2.2536e+04)
[2022-05-31 20:26:02,423][root][INFO] - Step 148582400 @ 6654.7 SPS. Inference batcher size: 185. Learner queue size: 16. Other stats: (step = 148582400, mean_episode_return = 210.11, mean_episode_step = 660.25, total_loss = 93.158, pg_loss = -101.92, baseline_loss = 201.07, entropy_loss = -5.993, learner_queue_size = 26, _tick = 49582, _time = 1.654e+09, train_seconds = 2.2541e+04)
[2022-05-31 20:26:07,426][root][INFO] - Step 148615680 @ 6651.1 SPS. Inference batcher size: 13. Learner queue size: 7. Other stats: (step = 148615680, mean_episode_return = 384.18, mean_episode_step = 584.41, total_loss = 108.54, pg_loss = 24.549, baseline_loss = 89.992, entropy_loss = -5.9959, learner_queue_size = 19, _tick = 49594, _time = 1.654e+09, train_seconds = 2.2546e+04)
[2022-05-31 20:26:12,430][root][INFO] - Step 148648960 @ 6651.4 SPS. Inference batcher size: 81. Learner queue size: 4. Other stats: (step = 148648960, mean_episode_return = 540.21, mean_episode_step = 673.44, total_loss = 70.856, pg_loss = -52.376, baseline_loss = 129.73, entropy_loss = -6.4947, learner_queue_size = 12, _tick = 49606, _time = 1.654e+09, train_seconds = 2.2551e+04)
[2022-05-31 20:26:17,434][root][INFO] - Step 148682240 @ 6650.8 SPS. Inference batcher size: 101. Learner queue size: 30. Other stats: (step = 148682240, mean_episode_return = 237.56, mean_episode_step = 538.36, total_loss = 258.92, pg_loss = 115.05, baseline_loss = 150.05, entropy_loss = -6.1828, learner_queue_size = 15, _tick = 49617, _time = 1.654e+09, train_seconds = 2.2556e+04)
[2022-05-31 20:26:22,438][root][INFO] - Step 148715520 @ 6650.6 SPS. Inference batcher size: 76. Learner queue size: 4. Other stats: (step = 148715520, mean_episode_return = 191.21, mean_episode_step = 717.3, total_loss = -7.1587, pg_loss = -47.541, baseline_loss = 47.153, entropy_loss = -6.7703, learner_queue_size = 23, _tick = 49630, _time = 1.654e+09, train_seconds = 2.2561e+04)
[2022-05-31 20:26:27,442][root][INFO] - Step 148748800 @ 6650.8 SPS. Inference batcher size: 103. Learner queue size: 26. Other stats: (step = 148748800, mean_episode_return = 402.47, mean_episode_step = 572.81, total_loss = 551.43, pg_loss = 238.65, baseline_loss = 319.08, entropy_loss = -6.2956, learner_queue_size = 22, _tick = 49641, _time = 1.654e+09, train_seconds = 2.2566e+04)
[2022-05-31 20:26:32,446][root][INFO] - Step 148782080 @ 6650.7 SPS. Inference batcher size: 85. Learner queue size: 24. Other stats: (step = 148782080, mean_episode_return = 156.97, mean_episode_step = 697.01, total_loss = 206.11, pg_loss = 88.187, baseline_loss = 124.09, entropy_loss = -6.1655, learner_queue_size = 21, _tick = 49654, _time = 1.654e+09, train_seconds = 2.2571e+04)
[2022-05-31 20:26:37,452][root][INFO] - Step 148812800 @ 6136.8 SPS. Inference batcher size: 155. Learner queue size: 27. Other stats: (step = 148812800, mean_episode_return = 212.43, mean_episode_step = 555.54, total_loss = 1110.5, pg_loss = 656.57, baseline_loss = 460.37, entropy_loss = -6.3931, learner_queue_size = 17, _tick = 49665, _time = 1.654e+09, train_seconds = 2.2576e+04)
[2022-05-31 20:26:42,454][root][INFO] - Step 148846080 @ 6653.2 SPS. Inference batcher size: 106. Learner queue size: 24. Other stats: (step = 148846080, mean_episode_return = 164.84, mean_episode_step = 685.76, total_loss = 67.943, pg_loss = 16.857, baseline_loss = 58.117, entropy_loss = -7.0314, learner_queue_size = 23, _tick = 49676, _time = 1.654e+09, train_seconds = 2.2581e+04)
[2022-05-31 20:26:47,458][root][INFO] - Step 148879360 @ 6650.7 SPS. Inference batcher size: 145. Learner queue size: 15. Other stats: (step = 148879360, mean_episode_return = 94.109, mean_episode_step = 955.34, total_loss = -31.624, pg_loss = -40.599, baseline_loss = 16.528, entropy_loss = -7.5527, learner_queue_size = 24, _tick = 49687, _time = 1.654e+09, train_seconds = 2.2586e+04)
[2022-05-31 20:26:52,462][root][INFO] - Step 148912640 @ 6650.6 SPS. Inference batcher size: 148. Learner queue size: 14. Other stats: (step = 148912640, mean_episode_return = 358.04, mean_episode_step = 767.01, total_loss = 924.91, pg_loss = 456.92, baseline_loss = 474.17, entropy_loss = -6.1711, learner_queue_size = 13, _tick = 49699, _time = 1.654e+09, train_seconds = 2.2591e+04)
[2022-05-31 20:26:57,466][root][INFO] - Step 148945920 @ 6650.8 SPS. Inference batcher size: 45. Learner queue size: 12. Other stats: (step = 148945920, mean_episode_return = 270.32, mean_episode_step = 745.52, total_loss = 35.134, pg_loss = -42.056, baseline_loss = 82.986, entropy_loss = -5.7956, learner_queue_size = 14, _tick = 49711, _time = 1.654e+09, train_seconds = 2.2596e+04)
[2022-05-31 20:27:02,470][root][INFO] - Step 148979200 @ 6650.7 SPS. Inference batcher size: 106. Learner queue size: 21. Other stats: (step = 148979200, mean_episode_return = 383.74, mean_episode_step = 899.33, total_loss = 208.07, pg_loss = 96.409, baseline_loss = 117.56, entropy_loss = -5.9043, learner_queue_size = 24, _tick = 49724, _time = 1.654e+09, train_seconds = 2.2601e+04)
[2022-05-31 20:27:07,477][root][INFO] - Step 149012480 @ 6647.3 SPS. Inference batcher size: 117. Learner queue size: 5. Other stats: (step = 149012480, mean_episode_return = 232.67, mean_episode_step = 538.95, total_loss = 387.14, pg_loss = 121.28, baseline_loss = 270.98, entropy_loss = -5.1273, learner_queue_size = 16, _tick = 49736, _time = 1.654e+09, train_seconds = 2.2606e+04)
[2022-05-31 20:27:12,482][root][INFO] - Step 149045760 @ 6648.8 SPS. Inference batcher size: 140. Learner queue size: 0. Other stats: (step = 149045760, mean_episode_return = 109.96, mean_episode_step = 558.47, total_loss = 82.564, pg_loss = -121.94, baseline_loss = 210.41, entropy_loss = -5.8978, learner_queue_size = 12, _tick = 49747, _time = 1.654e+09, train_seconds = 2.2611e+04)
[2022-05-31 20:27:17,486][root][INFO] - Step 149079040 @ 6650.7 SPS. Inference batcher size: 25. Learner queue size: 30. Other stats: (step = 149079040, mean_episode_return = 191.57, mean_episode_step = 952.92, total_loss = -165.85, pg_loss = -292.78, baseline_loss = 133.38, entropy_loss = -6.4571, learner_queue_size = 13, _tick = 49756, _time = 1.654e+09, train_seconds = 2.2616e+04)
[2022-05-31 20:27:22,490][root][INFO] - Step 149112320 @ 6650.6 SPS. Inference batcher size: 147. Learner queue size: 30. Other stats: (step = 149112320, mean_episode_return = 103.32, mean_episode_step = 696.74, total_loss = 185.07, pg_loss = 159.63, baseline_loss = 33.146, entropy_loss = -7.7128, learner_queue_size = 16, _tick = 49766, _time = 1.654e+09, train_seconds = 2.2621e+04)
[2022-05-31 20:27:27,494][root][INFO] - Step 149145600 @ 6650.7 SPS. Inference batcher size: 56. Learner queue size: 3. Other stats: (step = 149145600, mean_episode_return = 406.82, mean_episode_step = 783.72, total_loss = 289.57, pg_loss = 117.98, baseline_loss = 178.7, entropy_loss = -7.1106, learner_queue_size = 28, _tick = 49777, _time = 1.654e+09, train_seconds = 2.2626e+04)
[2022-05-31 20:27:32,498][root][INFO] - Step 149178880 @ 6650.6 SPS. Inference batcher size: 156. Learner queue size: 17. Other stats: (step = 149178880, mean_episode_return = 285.66, mean_episode_step = 910.14, total_loss = -7.8932, pg_loss = -54.07, baseline_loss = 52.725, entropy_loss = -6.5483, learner_queue_size = 17, _tick = 49789, _time = 1.654e+09, train_seconds = 2.2631e+04)
[2022-05-31 20:27:37,502][root][INFO] - Step 149212160 @ 6650.7 SPS. Inference batcher size: 125. Learner queue size: 18. Other stats: (step = 149212160, mean_episode_return = 260.6, mean_episode_step = 542.4, total_loss = 382.3, pg_loss = 210.3, baseline_loss = 178.2, entropy_loss = -6.1986, learner_queue_size = 13, _tick = 49800, _time = 1.654e+09, train_seconds = 2.2636e+04)
[2022-05-31 20:27:42,508][root][INFO] - Step 149242880 @ 6136.2 SPS. Inference batcher size: 99. Learner queue size: 15. Other stats: (step = 149242880, mean_episode_return = 156.56, mean_episode_step = 694.12, total_loss = -210.33, pg_loss = -231.67, baseline_loss = 28.559, entropy_loss = -7.2182, learner_queue_size = 15, _tick = 49811, _time = 1.654e+09, train_seconds = 2.2641e+04)
[2022-05-31 20:27:47,514][root][INFO] - Step 149276160 @ 6648.0 SPS. Inference batcher size: 97. Learner queue size: 26. Other stats: (step = 149276160, mean_episode_return = 264.38, mean_episode_step = 856.68, total_loss = 130.04, pg_loss = -53.241, baseline_loss = 190.0, entropy_loss = -6.715, learner_queue_size = 20, _tick = 49823, _time = 1.654e+09, train_seconds = 2.2646e+04)
[2022-05-31 20:27:52,519][root][INFO] - Step 149309440 @ 6650.1 SPS. Inference batcher size: 88. Learner queue size: 15. Other stats: (step = 149309440, mean_episode_return = 227.77, mean_episode_step = 844.34, total_loss = 221.49, pg_loss = 103.94, baseline_loss = 124.03, entropy_loss = -6.4787, learner_queue_size = 31, _tick = 49836, _time = 1.654e+09, train_seconds = 2.2651e+04)
[2022-05-31 20:27:57,522][root][INFO] - Step 149342720 @ 6651.5 SPS. Inference batcher size: 73. Learner queue size: 6. Other stats: (step = 149342720, mean_episode_return = 143.61, mean_episode_step = 814.22, total_loss = 259.82, pg_loss = 97.323, baseline_loss = 169.24, entropy_loss = -6.7462, learner_queue_size = 23, _tick = 49848, _time = 1.654e+09, train_seconds = 2.2656e+04)
[2022-05-31 20:28:02,526][root][INFO] - Step 149376000 @ 6650.7 SPS. Inference batcher size: 184. Learner queue size: 7. Other stats: (step = 149376000, mean_episode_return = 289.1, mean_episode_step = 586.26, total_loss = 104.44, pg_loss = 28.51, baseline_loss = 82.065, entropy_loss = -6.1368, learner_queue_size = 15, _tick = 49860, _time = 1.654e+09, train_seconds = 2.2661e+04)
[2022-05-31 20:28:07,530][root][INFO] - Step 149409280 @ 6650.8 SPS. Inference batcher size: 119. Learner queue size: 0. Other stats: (step = 149409280, mean_episode_return = 35.79, mean_episode_step = 614.38, total_loss = 113.25, pg_loss = 10.277, baseline_loss = 108.99, entropy_loss = -6.0128, learner_queue_size = 17, _tick = 49871, _time = 1.654e+09, train_seconds = 2.2666e+04)
[2022-05-31 20:28:12,534][root][INFO] - Step 149442560 @ 6650.4 SPS. Inference batcher size: 128. Learner queue size: 4. Other stats: (step = 149442560, mean_episode_return = None, mean_episode_step = 950.09, total_loss = 277.05, pg_loss = 135.02, baseline_loss = 148.01, entropy_loss = -5.9771, learner_queue_size = 25, _tick = 49883, _time = 1.654e+09, train_seconds = 2.2671e+04)
[2022-05-31 20:28:17,538][root][INFO] - Step 149473280 @ 6139.3 SPS. Inference batcher size: 130. Learner queue size: 25. Other stats: (step = 149473280, mean_episode_return = 490.32, mean_episode_step = 730.93, total_loss = 37.28, pg_loss = 4.5748, baseline_loss = 39.858, entropy_loss = -7.1522, learner_queue_size = 23, _tick = 49894, _time = 1.654e+09, train_seconds = 2.2676e+04)
[2022-05-31 20:28:22,544][root][INFO] - Step 149506560 @ 6647.9 SPS. Inference batcher size: 134. Learner queue size: 23. Other stats: (step = 149506560, mean_episode_return = 313.6, mean_episode_step = 981.07, total_loss = 164.56, pg_loss = 13.457, baseline_loss = 157.25, entropy_loss = -6.1485, learner_queue_size = 14, _tick = 49904, _time = 1.654e+09, train_seconds = 2.2681e+04)
[2022-05-31 20:28:27,550][root][INFO] - Step 149539840 @ 6648.2 SPS. Inference batcher size: 112. Learner queue size: 17. Other stats: (step = 149539840, mean_episode_return = None, mean_episode_step = 808.84, total_loss = 354.27, pg_loss = 124.29, baseline_loss = 236.36, entropy_loss = -6.3878, learner_queue_size = 24, _tick = 49914, _time = 1.654e+09, train_seconds = 2.2686e+04)
[2022-05-31 20:28:32,554][root][INFO] - Step 149573120 @ 6650.7 SPS. Inference batcher size: 121. Learner queue size: 15. Other stats: (step = 149573120, mean_episode_return = 191.24, mean_episode_step = 718.55, total_loss = 303.33, pg_loss = 170.58, baseline_loss = 138.82, entropy_loss = -6.0697, learner_queue_size = 13, _tick = 49926, _time = 1.654e+09, train_seconds = 2.2691e+04)
[2022-05-31 20:28:37,560][root][INFO] - Step 149606400 @ 6647.9 SPS. Inference batcher size: 159. Learner queue size: 16. Other stats: (step = 149606400, mean_episode_return = 513.87, mean_episode_step = 742.91, total_loss = 144.29, pg_loss = -21.619, baseline_loss = 171.64, entropy_loss = -5.7352, learner_queue_size = 21, _tick = 49939, _time = 1.654e+09, train_seconds = 2.2696e+04)
[2022-05-31 20:28:42,566][root][INFO] - Step 149639680 @ 6648.0 SPS. Inference batcher size: 68. Learner queue size: 20. Other stats: (step = 149639680, mean_episode_return = 347.83, mean_episode_step = 746.48, total_loss = 199.19, pg_loss = 46.402, baseline_loss = 158.95, entropy_loss = -6.1656, learner_queue_size = 18, _tick = 49950, _time = 1.654e+09, train_seconds = 2.2701e+04)
[2022-05-31 20:28:47,570][root][INFO] - Step 149672960 @ 6650.8 SPS. Inference batcher size: 68. Learner queue size: 6. Other stats: (step = 149672960, mean_episode_return = 290.83, mean_episode_step = 790.55, total_loss = 115.78, pg_loss = 52.119, baseline_loss = 70.151, entropy_loss = -6.4928, learner_queue_size = 14, _tick = 49961, _time = 1.654e+09, train_seconds = 2.2706e+04)
[2022-05-31 20:28:52,574][root][INFO] - Step 149706240 @ 6650.6 SPS. Inference batcher size: 151. Learner queue size: 19. Other stats: (step = 149706240, mean_episode_return = 69.149, mean_episode_step = 838.68, total_loss = -62.144, pg_loss = -114.28, baseline_loss = 58.758, entropy_loss = -6.6212, learner_queue_size = 24, _tick = 49972, _time = 1.654e+09, train_seconds = 2.2711e+04)
[2022-05-31 20:28:57,578][root][INFO] - Step 149739520 @ 6650.6 SPS. Inference batcher size: 106. Learner queue size: 9. Other stats: (step = 149739520, mean_episode_return = 240.68, mean_episode_step = 713.49, total_loss = 54.916, pg_loss = 6.4388, baseline_loss = 55.21, entropy_loss = -6.7333, learner_queue_size = 20, _tick = 49983, _time = 1.654e+09, train_seconds = 2.2716e+04)
[2022-05-31 20:29:02,582][root][INFO] - Step 149772800 @ 6650.7 SPS. Inference batcher size: 91. Learner queue size: 12. Other stats: (step = 149772800, mean_episode_return = 225.54, mean_episode_step = 861.83, total_loss = -140.08, pg_loss = -165.68, baseline_loss = 32.688, entropy_loss = -7.0885, learner_queue_size = 21, _tick = 49995, _time = 1.654e+09, train_seconds = 2.2721e+04)
[2022-05-31 20:29:07,588][root][INFO] - Step 149806080 @ 6647.6 SPS. Inference batcher size: 123. Learner queue size: 2. Other stats: (step = 149806080, mean_episode_return = 292.76, mean_episode_step = 780.35, total_loss = -64.03, pg_loss = -111.71, baseline_loss = 54.516, entropy_loss = -6.8387, learner_queue_size = 20, _tick = 50008, _time = 1.654e+09, train_seconds = 2.2726e+04)
[2022-05-31 20:29:12,594][root][INFO] - Step 149839360 @ 6648.6 SPS. Inference batcher size: 47. Learner queue size: 29. Other stats: (step = 149839360, mean_episode_return = 365.37, mean_episode_step = 751.0, total_loss = -106.04, pg_loss = -131.56, baseline_loss = 32.385, entropy_loss = -6.8621, learner_queue_size = 10, _tick = 50018, _time = 1.654e+09, train_seconds = 2.2731e+04)
[2022-05-31 20:29:17,598][root][INFO] - Step 149872640 @ 6650.6 SPS. Inference batcher size: 97. Learner queue size: 24. Other stats: (step = 149872640, mean_episode_return = 200.72, mean_episode_step = 1014.7, total_loss = 184.59, pg_loss = 156.32, baseline_loss = 35.752, entropy_loss = -7.4823, learner_queue_size = 24, _tick = 50030, _time = 1.654e+09, train_seconds = 2.2736e+04)
[2022-05-31 20:29:22,602][root][INFO] - Step 149903360 @ 6138.6 SPS. Inference batcher size: 9. Learner queue size: 29. Other stats: (step = 149903360, mean_episode_return = None, mean_episode_step = 900.44, total_loss = 226.13, pg_loss = 154.52, baseline_loss = 78.248, entropy_loss = -6.6373, learner_queue_size = 16, _tick = 50041, _time = 1.654e+09, train_seconds = 2.2741e+04)
[2022-05-31 20:29:27,611][root][INFO] - Step 149939200 @ 7156.2 SPS. Inference batcher size: 153. Learner queue size: 30. Other stats: (step = 149939200, mean_episode_return = 315.45, mean_episode_step = 810.77, total_loss = 352.71, pg_loss = 189.47, baseline_loss = 169.3, entropy_loss = -6.0548, learner_queue_size = 15, _tick = 50050, _time = 1.654e+09, train_seconds = 2.2746e+04)
[2022-05-31 20:29:32,614][root][INFO] - Step 149972480 @ 6651.5 SPS. Inference batcher size: 142. Learner queue size: 29. Other stats: (step = 149972480, mean_episode_return = None, mean_episode_step = 1081.7, total_loss = 380.72, pg_loss = 268.33, baseline_loss = 118.87, entropy_loss = -6.4841, learner_queue_size = 23, _tick = 50060, _time = 1.654e+09, train_seconds = 2.2751e+04)
[2022-05-31 20:29:37,618][root][INFO] - Step 150005760 @ 6650.6 SPS. Inference batcher size: 44. Learner queue size: 25. Other stats: (step = 150005760, mean_episode_return = 319.32, mean_episode_step = 827.3, total_loss = 256.37, pg_loss = 67.417, baseline_loss = 194.48, entropy_loss = -5.5238, learner_queue_size = 21, _tick = 50072, _time = 1.654e+09, train_seconds = 2.2756e+04)
[2022-05-31 20:29:42,622][root][INFO] - Step 150039040 @ 6650.7 SPS. Inference batcher size: 159. Learner queue size: 3. Other stats: (step = 150039040, mean_episode_return = 408.85, mean_episode_step = 687.23, total_loss = 166.09, pg_loss = 5.8942, baseline_loss = 166.36, entropy_loss = -6.1617, learner_queue_size = 20, _tick = 50082, _time = 1.654e+09, train_seconds = 2.2761e+04)
[2022-05-31 20:29:47,626][root][INFO] - Step 150072320 @ 6650.8 SPS. Inference batcher size: 85. Learner queue size: 7. Other stats: (step = 150072320, mean_episode_return = 423.34, mean_episode_step = 1110.9, total_loss = 180.17, pg_loss = -34.696, baseline_loss = 221.62, entropy_loss = -6.7548, learner_queue_size = 22, _tick = 50092, _time = 1.654e+09, train_seconds = 2.2766e+04)
[2022-05-31 20:29:52,630][root][INFO] - Step 150105600 @ 6650.5 SPS. Inference batcher size: 119. Learner queue size: 23. Other stats: (step = 150105600, mean_episode_return = None, mean_episode_step = 989.47, total_loss = 204.76, pg_loss = 148.96, baseline_loss = 62.857, entropy_loss = -7.0542, learner_queue_size = 13, _tick = 50102, _time = 1.654e+09, train_seconds = 2.2771e+04)
[2022-05-31 20:29:57,634][root][INFO] - Step 150138880 @ 6650.6 SPS. Inference batcher size: 127. Learner queue size: 23. Other stats: (step = 150138880, mean_episode_return = None, mean_episode_step = 769.12, total_loss = 575.07, pg_loss = 435.02, baseline_loss = 146.37, entropy_loss = -6.3095, learner_queue_size = 19, _tick = 50114, _time = 1.654e+09, train_seconds = 2.2776e+04)
[2022-05-31 20:30:02,641][root][INFO] - Step 150169600 @ 6136.1 SPS. Inference batcher size: 133. Learner queue size: 18. Other stats: (step = 150169600, mean_episode_return = 300.07, mean_episode_step = 875.31, total_loss = 47.8, pg_loss = -24.334, baseline_loss = 78.806, entropy_loss = -6.6731, learner_queue_size = 17, _tick = 50125, _time = 1.654e+09, train_seconds = 2.2781e+04)
[2022-05-31 20:30:07,646][root][INFO] - Step 150202880 @ 6648.7 SPS. Inference batcher size: 103. Learner queue size: 23. Other stats: (step = 150202880, mean_episode_return = 348.31, mean_episode_step = 858.99, total_loss = -74.728, pg_loss = -133.78, baseline_loss = 66.214, entropy_loss = -7.1651, learner_queue_size = 21, _tick = 50137, _time = 1.654e+09, train_seconds = 2.2786e+04)
[2022-05-31 20:30:12,650][root][INFO] - Step 150236160 @ 6650.5 SPS. Inference batcher size: 133. Learner queue size: 14. Other stats: (step = 150236160, mean_episode_return = None, mean_episode_step = 903.84, total_loss = 80.061, pg_loss = 14.127, baseline_loss = 72.086, entropy_loss = -6.1526, learner_queue_size = 12, _tick = 50148, _time = 1.654e+09, train_seconds = 2.2791e+04)
[2022-05-31 20:30:17,654][root][INFO] - Step 150269440 @ 6650.9 SPS. Inference batcher size: 81. Learner queue size: 1. Other stats: (step = 150269440, mean_episode_return = 492.87, mean_episode_step = 753.2, total_loss = 194.0, pg_loss = -2.1769, baseline_loss = 202.2, entropy_loss = -6.0222, learner_queue_size = 11, _tick = 50159, _time = 1.654e+09, train_seconds = 2.2796e+04)
[2022-05-31 20:30:22,658][root][INFO] - Step 150302720 @ 6650.8 SPS. Inference batcher size: 42. Learner queue size: 22. Other stats: (step = 150302720, mean_episode_return = 326.72, mean_episode_step = 606.57, total_loss = -202.52, pg_loss = -618.41, baseline_loss = 421.72, entropy_loss = -5.8211, learner_queue_size = 15, _tick = 50171, _time = 1.654e+09, train_seconds = 2.2801e+04)
[2022-05-31 20:30:27,662][root][INFO] - Step 150333440 @ 6139.1 SPS. Inference batcher size: 157. Learner queue size: 27. Other stats: (step = 150333440, mean_episode_return = 219.82, mean_episode_step = 672.56, total_loss = -126.94, pg_loss = -202.66, baseline_loss = 82.375, entropy_loss = -6.6607, learner_queue_size = 18, _tick = 50183, _time = 1.654e+09, train_seconds = 2.2806e+04)
[2022-05-31 20:30:32,666][root][INFO] - Step 150366720 @ 6650.7 SPS. Inference batcher size: 150. Learner queue size: 14. Other stats: (step = 150366720, mean_episode_return = 340.65, mean_episode_step = 679.95, total_loss = -222.99, pg_loss = -274.2, baseline_loss = 57.381, entropy_loss = -6.1732, learner_queue_size = 25, _tick = 50194, _time = 1.654e+09, train_seconds = 2.2811e+04)
[2022-05-31 20:30:37,672][root][INFO] - Step 150400000 @ 6648.1 SPS. Inference batcher size: 140. Learner queue size: 17. Other stats: (step = 150400000, mean_episode_return = 144.79, mean_episode_step = 604.57, total_loss = 191.01, pg_loss = 88.314, baseline_loss = 108.98, entropy_loss = -6.287, learner_queue_size = 24, _tick = 50207, _time = 1.654e+09, train_seconds = 2.2816e+04)
[2022-05-31 20:30:42,674][root][INFO] - Step 150433280 @ 6653.2 SPS. Inference batcher size: 115. Learner queue size: 12. Other stats: (step = 150433280, mean_episode_return = 232.86, mean_episode_step = 785.99, total_loss = 86.35, pg_loss = -30.22, baseline_loss = 123.46, entropy_loss = -6.8932, learner_queue_size = 22, _tick = 50219, _time = 1.654e+09, train_seconds = 2.2821e+04)
[2022-05-31 20:30:47,680][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 20:30:47,774][root][INFO] - Step 150466560 @ 6648.0 SPS. Inference batcher size: 151. Learner queue size: 15. Other stats: (step = 150466560, mean_episode_return = 90.74, mean_episode_step = 687.99, total_loss = 94.166, pg_loss = 7.426, baseline_loss = 93.142, entropy_loss = -6.4022, learner_queue_size = 10, _tick = 50231, _time = 1.654e+09, train_seconds = 2.2826e+04)
[2022-05-31 20:30:52,778][root][INFO] - Step 150499840 @ 6528.2 SPS. Inference batcher size: 69. Learner queue size: 8. Other stats: (step = 150499840, mean_episode_return = 161.32, mean_episode_step = 888.87, total_loss = 243.69, pg_loss = -135.07, baseline_loss = 385.74, entropy_loss = -6.9845, learner_queue_size = 26, _tick = 50242, _time = 1.654e+09, train_seconds = 2.2832e+04)
[2022-05-31 20:30:57,784][root][INFO] - Step 150533120 @ 6647.9 SPS. Inference batcher size: 134. Learner queue size: 10. Other stats: (step = 150533120, mean_episode_return = 253.79, mean_episode_step = 734.54, total_loss = 142.74, pg_loss = 78.447, baseline_loss = 71.365, entropy_loss = -7.0754, learner_queue_size = 14, _tick = 50252, _time = 1.654e+09, train_seconds = 2.2836e+04)
[2022-05-31 20:31:02,786][root][INFO] - Step 150566400 @ 6653.2 SPS. Inference batcher size: 47. Learner queue size: 11. Other stats: (step = 150566400, mean_episode_return = 303.12, mean_episode_step = 794.97, total_loss = 300.7, pg_loss = 212.05, baseline_loss = 95.333, entropy_loss = -6.677, learner_queue_size = 19, _tick = 50262, _time = 1.654e+09, train_seconds = 2.2842e+04)
[2022-05-31 20:31:07,793][root][INFO] - Step 150599680 @ 6647.5 SPS. Inference batcher size: 146. Learner queue size: 14. Other stats: (step = 150599680, mean_episode_return = 63.06, mean_episode_step = 882.52, total_loss = 284.34, pg_loss = 161.56, baseline_loss = 128.7, entropy_loss = -5.9197, learner_queue_size = 12, _tick = 50273, _time = 1.654e+09, train_seconds = 2.2846e+04)
[2022-05-31 20:31:12,798][root][INFO] - Step 150632960 @ 6648.0 SPS. Inference batcher size: 165. Learner queue size: 22. Other stats: (step = 150632960, mean_episode_return = None, mean_episode_step = 726.0, total_loss = -49.552, pg_loss = -83.464, baseline_loss = 40.309, entropy_loss = -6.3974, learner_queue_size = 12, _tick = 50284, _time = 1.654e+09, train_seconds = 2.2852e+04)
[2022-05-31 20:31:17,802][root][INFO] - Step 150666240 @ 6651.4 SPS. Inference batcher size: 38. Learner queue size: 19. Other stats: (step = 150666240, mean_episode_return = 315.11, mean_episode_step = 1015.3, total_loss = 74.023, pg_loss = 38.216, baseline_loss = 42.592, entropy_loss = -6.7839, learner_queue_size = 19, _tick = 50296, _time = 1.654e+09, train_seconds = 2.2856e+04)
[2022-05-31 20:31:22,808][root][INFO] - Step 150699520 @ 6648.0 SPS. Inference batcher size: 33. Learner queue size: 18. Other stats: (step = 150699520, mean_episode_return = 134.14, mean_episode_step = 595.5, total_loss = 283.6, pg_loss = 151.93, baseline_loss = 137.73, entropy_loss = -6.0614, learner_queue_size = 24, _tick = 50308, _time = 1.654e+09, train_seconds = 2.2862e+04)
[2022-05-31 20:31:27,810][root][INFO] - Step 150732800 @ 6653.1 SPS. Inference batcher size: 31. Learner queue size: 8. Other stats: (step = 150732800, mean_episode_return = 325.9, mean_episode_step = 797.78, total_loss = -32.825, pg_loss = -98.184, baseline_loss = 71.878, entropy_loss = -6.5192, learner_queue_size = 14, _tick = 50321, _time = 1.654e+09, train_seconds = 2.2866e+04)
[2022-05-31 20:31:32,817][root][INFO] - Step 150766080 @ 6646.6 SPS. Inference batcher size: 82. Learner queue size: 5. Other stats: (step = 150766080, mean_episode_return = 278.11, mean_episode_step = 920.9, total_loss = 155.16, pg_loss = 50.627, baseline_loss = 110.81, entropy_loss = -6.2753, learner_queue_size = 21, _tick = 50331, _time = 1.654e+09, train_seconds = 2.2872e+04)
[2022-05-31 20:31:37,824][root][INFO] - Step 150799360 @ 6647.5 SPS. Inference batcher size: 46. Learner queue size: 10. Other stats: (step = 150799360, mean_episode_return = 271.02, mean_episode_step = 927.73, total_loss = -182.17, pg_loss = -223.21, baseline_loss = 47.568, entropy_loss = -6.5247, learner_queue_size = 18, _tick = 50342, _time = 1.654e+09, train_seconds = 2.2876e+04)
[2022-05-31 20:31:42,830][root][INFO] - Step 150832640 @ 6647.6 SPS. Inference batcher size: 182. Learner queue size: 5. Other stats: (step = 150832640, mean_episode_return = 290.24, mean_episode_step = 589.1, total_loss = 517.49, pg_loss = 206.21, baseline_loss = 316.99, entropy_loss = -5.7032, learner_queue_size = 15, _tick = 50354, _time = 1.654e+09, train_seconds = 2.2882e+04)
[2022-05-31 20:31:47,834][root][INFO] - Step 150865920 @ 6650.6 SPS. Inference batcher size: 120. Learner queue size: 3. Other stats: (step = 150865920, mean_episode_return = None, mean_episode_step = 896.31, total_loss = 678.32, pg_loss = 499.98, baseline_loss = 185.08, entropy_loss = -6.7435, learner_queue_size = 17, _tick = 50363, _time = 1.654e+09, train_seconds = 2.2886e+04)
[2022-05-31 20:31:52,838][root][INFO] - Step 150899200 @ 6650.6 SPS. Inference batcher size: 59. Learner queue size: 4. Other stats: (step = 150899200, mean_episode_return = 229.85, mean_episode_step = 701.3, total_loss = 493.97, pg_loss = 242.11, baseline_loss = 258.32, entropy_loss = -6.4648, learner_queue_size = 21, _tick = 50374, _time = 1.654e+09, train_seconds = 2.2892e+04)
[2022-05-31 20:31:57,842][root][INFO] - Step 150932480 @ 6650.6 SPS. Inference batcher size: 115. Learner queue size: 23. Other stats: (step = 150932480, mean_episode_return = None, mean_episode_step = 757.84, total_loss = 350.91, pg_loss = 227.84, baseline_loss = 130.18, entropy_loss = -7.097, learner_queue_size = 16, _tick = 50385, _time = 1.654e+09, train_seconds = 2.2896e+04)
[2022-05-31 20:32:02,850][root][INFO] - Step 150963200 @ 6134.1 SPS. Inference batcher size: 126. Learner queue size: 22. Other stats: (step = 150963200, mean_episode_return = 561.13, mean_episode_step = 658.21, total_loss = 323.4, pg_loss = 203.98, baseline_loss = 126.04, entropy_loss = -6.6267, learner_queue_size = 23, _tick = 50394, _time = 1.654e+09, train_seconds = 2.2902e+04)
[2022-05-31 20:32:07,854][root][INFO] - Step 150996480 @ 6650.8 SPS. Inference batcher size: 110. Learner queue size: 14. Other stats: (step = 150996480, mean_episode_return = 278.1, mean_episode_step = 724.51, total_loss = 118.28, pg_loss = 2.1818, baseline_loss = 122.69, entropy_loss = -6.5891, learner_queue_size = 26, _tick = 50406, _time = 1.654e+09, train_seconds = 2.2906e+04)
[2022-05-31 20:32:12,858][root][INFO] - Step 151032320 @ 7162.2 SPS. Inference batcher size: 96. Learner queue size: 19. Other stats: (step = 151032320, mean_episode_return = 294.6, mean_episode_step = 763.07, total_loss = 616.32, pg_loss = 336.38, baseline_loss = 285.8, entropy_loss = -5.8614, learner_queue_size = 19, _tick = 50419, _time = 1.654e+09, train_seconds = 2.2912e+04)
[2022-05-31 20:32:17,864][root][INFO] - Step 151063040 @ 6136.6 SPS. Inference batcher size: 60. Learner queue size: 16. Other stats: (step = 151063040, mean_episode_return = 145.53, mean_episode_step = 668.02, total_loss = 54.146, pg_loss = 3.6425, baseline_loss = 57.242, entropy_loss = -6.7381, learner_queue_size = 15, _tick = 50431, _time = 1.654e+09, train_seconds = 2.2916e+04)
[2022-05-31 20:32:22,870][root][INFO] - Step 151096320 @ 6648.0 SPS. Inference batcher size: 148. Learner queue size: 19. Other stats: (step = 151096320, mean_episode_return = 396.59, mean_episode_step = 650.14, total_loss = 249.44, pg_loss = 141.51, baseline_loss = 114.49, entropy_loss = -6.5632, learner_queue_size = 16, _tick = 50442, _time = 1.654e+09, train_seconds = 2.2922e+04)
[2022-05-31 20:32:27,874][root][INFO] - Step 151129600 @ 6650.8 SPS. Inference batcher size: 130. Learner queue size: 21. Other stats: (step = 151129600, mean_episode_return = 171.21, mean_episode_step = 769.38, total_loss = -111.93, pg_loss = -144.91, baseline_loss = 39.52, entropy_loss = -6.5471, learner_queue_size = 11, _tick = 50452, _time = 1.654e+09, train_seconds = 2.2927e+04)
[2022-05-31 20:32:32,880][root][INFO] - Step 151162880 @ 6648.0 SPS. Inference batcher size: 159. Learner queue size: 13. Other stats: (step = 151162880, mean_episode_return = 289.48, mean_episode_step = 861.63, total_loss = 130.48, pg_loss = 68.615, baseline_loss = 68.247, entropy_loss = -6.3841, learner_queue_size = 20, _tick = 50465, _time = 1.654e+09, train_seconds = 2.2932e+04)
[2022-05-31 20:32:37,886][root][INFO] - Step 151196160 @ 6648.1 SPS. Inference batcher size: 94. Learner queue size: 14. Other stats: (step = 151196160, mean_episode_return = 830.2, mean_episode_step = 897.11, total_loss = 219.86, pg_loss = 157.21, baseline_loss = 68.807, entropy_loss = -6.1597, learner_queue_size = 18, _tick = 50477, _time = 1.654e+09, train_seconds = 2.2937e+04)
[2022-05-31 20:32:42,890][root][INFO] - Step 151229440 @ 6650.8 SPS. Inference batcher size: 133. Learner queue size: 10. Other stats: (step = 151229440, mean_episode_return = 260.72, mean_episode_step = 636.4, total_loss = -39.175, pg_loss = -74.955, baseline_loss = 41.972, entropy_loss = -6.1928, learner_queue_size = 26, _tick = 50490, _time = 1.654e+09, train_seconds = 2.2942e+04)
[2022-05-31 20:32:47,894][root][INFO] - Step 151262720 @ 6650.6 SPS. Inference batcher size: 146. Learner queue size: 12. Other stats: (step = 151262720, mean_episode_return = 189.49, mean_episode_step = 600.86, total_loss = 60.117, pg_loss = 3.3407, baseline_loss = 62.973, entropy_loss = -6.197, learner_queue_size = 20, _tick = 50501, _time = 1.654e+09, train_seconds = 2.2947e+04)
[2022-05-31 20:32:52,898][root][INFO] - Step 151296000 @ 6650.7 SPS. Inference batcher size: 90. Learner queue size: 8. Other stats: (step = 151296000, mean_episode_return = 213.2, mean_episode_step = 634.16, total_loss = -80.314, pg_loss = -154.87, baseline_loss = 80.863, entropy_loss = -6.3108, learner_queue_size = 22, _tick = 50512, _time = 1.654e+09, train_seconds = 2.2952e+04)
[2022-05-31 20:32:57,902][root][INFO] - Step 151329280 @ 6650.7 SPS. Inference batcher size: 25. Learner queue size: 14. Other stats: (step = 151329280, mean_episode_return = 432.27, mean_episode_step = 843.76, total_loss = -33.911, pg_loss = -118.27, baseline_loss = 90.946, entropy_loss = -6.5841, learner_queue_size = 15, _tick = 50524, _time = 1.654e+09, train_seconds = 2.2957e+04)
[2022-05-31 20:33:02,908][root][INFO] - Step 151362560 @ 6647.4 SPS. Inference batcher size: 116. Learner queue size: 4. Other stats: (step = 151362560, mean_episode_return = 179.95, mean_episode_step = 624.04, total_loss = -54.135, pg_loss = -163.53, baseline_loss = 115.93, entropy_loss = -6.5425, learner_queue_size = 16, _tick = 50537, _time = 1.654e+09, train_seconds = 2.2962e+04)
[2022-05-31 20:33:07,914][root][INFO] - Step 151395840 @ 6648.0 SPS. Inference batcher size: 59. Learner queue size: 6. Other stats: (step = 151395840, mean_episode_return = 318.04, mean_episode_step = 765.27, total_loss = -4.7106, pg_loss = -73.642, baseline_loss = 75.677, entropy_loss = -6.7455, learner_queue_size = 20, _tick = 50548, _time = 1.654e+09, train_seconds = 2.2967e+04)
[2022-05-31 20:33:12,919][root][INFO] - Step 151429120 @ 6650.7 SPS. Inference batcher size: 8. Learner queue size: 29. Other stats: (step = 151429120, mean_episode_return = 113.33, mean_episode_step = 632.2, total_loss = 416.95, pg_loss = 285.04, baseline_loss = 137.72, entropy_loss = -5.8097, learner_queue_size = 21, _tick = 50560, _time = 1.654e+09, train_seconds = 2.2972e+04)
[2022-05-31 20:33:17,922][root][INFO] - Step 151462400 @ 6651.3 SPS. Inference batcher size: 136. Learner queue size: 0. Other stats: (step = 151462400, mean_episode_return = 228.95, mean_episode_step = 557.23, total_loss = 279.39, pg_loss = 123.45, baseline_loss = 161.71, entropy_loss = -5.7709, learner_queue_size = 15, _tick = 50572, _time = 1.654e+09, train_seconds = 2.2977e+04)
[2022-05-31 20:33:22,928][root][INFO] - Step 151495680 @ 6647.9 SPS. Inference batcher size: 121. Learner queue size: 7. Other stats: (step = 151495680, mean_episode_return = 304.34, mean_episode_step = 834.69, total_loss = 120.51, pg_loss = 54.321, baseline_loss = 72.78, entropy_loss = -6.594, learner_queue_size = 17, _tick = 50585, _time = 1.654e+09, train_seconds = 2.2982e+04)
[2022-05-31 20:33:27,934][root][INFO] - Step 151528960 @ 6648.1 SPS. Inference batcher size: 123. Learner queue size: 0. Other stats: (step = 151528960, mean_episode_return = None, mean_episode_step = 828.66, total_loss = -28.537, pg_loss = -85.202, baseline_loss = 63.22, entropy_loss = -6.5547, learner_queue_size = 17, _tick = 50597, _time = 1.654e+09, train_seconds = 2.2987e+04)
[2022-05-31 20:33:32,940][root][INFO] - Step 151559680 @ 6136.5 SPS. Inference batcher size: 0. Learner queue size: 23. Other stats: (step = 151559680, mean_episode_return = 231.27, mean_episode_step = 651.16, total_loss = 161.64, pg_loss = 124.61, baseline_loss = 43.39, entropy_loss = -6.3605, learner_queue_size = 10, _tick = 50608, _time = 1.654e+09, train_seconds = 2.2992e+04)
[2022-05-31 20:33:37,946][root][INFO] - Step 151592960 @ 6647.7 SPS. Inference batcher size: 75. Learner queue size: 16. Other stats: (step = 151592960, mean_episode_return = None, mean_episode_step = 654.19, total_loss = -206.08, pg_loss = -225.07, baseline_loss = 25.915, entropy_loss = -6.9226, learner_queue_size = 19, _tick = 50620, _time = 1.654e+09, train_seconds = 2.2997e+04)
[2022-05-31 20:33:42,950][root][INFO] - Step 151626240 @ 6651.0 SPS. Inference batcher size: 24. Learner queue size: 10. Other stats: (step = 151626240, mean_episode_return = 286.05, mean_episode_step = 557.85, total_loss = 67.871, pg_loss = 24.004, baseline_loss = 49.975, entropy_loss = -6.1082, learner_queue_size = 9, _tick = 50633, _time = 1.654e+09, train_seconds = 2.3002e+04)
[2022-05-31 20:33:47,954][root][INFO] - Step 151659520 @ 6650.7 SPS. Inference batcher size: 116. Learner queue size: 17. Other stats: (step = 151659520, mean_episode_return = None, mean_episode_step = 814.34, total_loss = -143.87, pg_loss = -213.48, baseline_loss = 74.794, entropy_loss = -5.1772, learner_queue_size = 23, _tick = 50643, _time = 1.654e+09, train_seconds = 2.3007e+04)
[2022-05-31 20:33:52,958][root][INFO] - Step 151692800 @ 6650.6 SPS. Inference batcher size: 91. Learner queue size: 15. Other stats: (step = 151692800, mean_episode_return = 188.24, mean_episode_step = 813.27, total_loss = 112.33, pg_loss = 43.958, baseline_loss = 75.1, entropy_loss = -6.724, learner_queue_size = 26, _tick = 50655, _time = 1.654e+09, train_seconds = 2.3012e+04)
[2022-05-31 20:33:57,962][root][INFO] - Step 151726080 @ 6650.4 SPS. Inference batcher size: 9. Learner queue size: 1. Other stats: (step = 151726080, mean_episode_return = None, mean_episode_step = 773.38, total_loss = 95.525, pg_loss = 7.4083, baseline_loss = 94.705, entropy_loss = -6.5885, learner_queue_size = 21, _tick = 50666, _time = 1.654e+09, train_seconds = 2.3017e+04)
[2022-05-31 20:34:02,966][root][INFO] - Step 151759360 @ 6651.1 SPS. Inference batcher size: 156. Learner queue size: 0. Other stats: (step = 151759360, mean_episode_return = 369.67, mean_episode_step = 723.73, total_loss = 24.509, pg_loss = -89.131, baseline_loss = 120.15, entropy_loss = -6.5124, learner_queue_size = 17, _tick = 50679, _time = 1.654e+09, train_seconds = 2.3022e+04)
[2022-05-31 20:34:07,970][root][INFO] - Step 151790080 @ 6139.1 SPS. Inference batcher size: 55. Learner queue size: 19. Other stats: (step = 151790080, mean_episode_return = 215.55, mean_episode_step = 779.56, total_loss = 169.4, pg_loss = 105.6, baseline_loss = 70.753, entropy_loss = -6.9562, learner_queue_size = 17, _tick = 50689, _time = 1.654e+09, train_seconds = 2.3027e+04)
[2022-05-31 20:34:12,974][root][INFO] - Step 151825920 @ 7162.3 SPS. Inference batcher size: 46. Learner queue size: 21. Other stats: (step = 151825920, mean_episode_return = None, mean_episode_step = 742.38, total_loss = 342.54, pg_loss = 256.94, baseline_loss = 92.301, entropy_loss = -6.704, learner_queue_size = 17, _tick = 50701, _time = 1.654e+09, train_seconds = 2.3032e+04)
[2022-05-31 20:34:17,978][root][INFO] - Step 151856640 @ 6139.3 SPS. Inference batcher size: 94. Learner queue size: 19. Other stats: (step = 151856640, mean_episode_return = 333.35, mean_episode_step = 727.79, total_loss = 356.99, pg_loss = 148.72, baseline_loss = 214.6, entropy_loss = -6.3282, learner_queue_size = 19, _tick = 50711, _time = 1.654e+09, train_seconds = 2.3037e+04)
[2022-05-31 20:34:22,982][root][INFO] - Step 151892480 @ 7161.9 SPS. Inference batcher size: 14. Learner queue size: 13. Other stats: (step = 151892480, mean_episode_return = 459.71, mean_episode_step = 658.11, total_loss = -118.34, pg_loss = -263.3, baseline_loss = 151.05, entropy_loss = -6.0888, learner_queue_size = 15, _tick = 50723, _time = 1.654e+09, train_seconds = 2.3042e+04)
[2022-05-31 20:34:27,986][root][INFO] - Step 151923200 @ 6139.0 SPS. Inference batcher size: 93. Learner queue size: 12. Other stats: (step = 151923200, mean_episode_return = 191.04, mean_episode_step = 1061.4, total_loss = 255.45, pg_loss = 179.35, baseline_loss = 82.664, entropy_loss = -6.5664, learner_queue_size = 16, _tick = 50734, _time = 1.654e+09, train_seconds = 2.3047e+04)
[2022-05-31 20:34:32,990][root][INFO] - Step 151956480 @ 6650.6 SPS. Inference batcher size: 87. Learner queue size: 16. Other stats: (step = 151956480, mean_episode_return = 375.48, mean_episode_step = 1006.5, total_loss = -99.599, pg_loss = -125.64, baseline_loss = 33.381, entropy_loss = -7.3443, learner_queue_size = 7, _tick = 50746, _time = 1.654e+09, train_seconds = 2.3052e+04)
[2022-05-31 20:34:37,994][root][INFO] - Step 151989760 @ 6650.8 SPS. Inference batcher size: 76. Learner queue size: 7. Other stats: (step = 151989760, mean_episode_return = 148.5, mean_episode_step = 777.86, total_loss = 203.18, pg_loss = 131.36, baseline_loss = 78.881, entropy_loss = -7.0584, learner_queue_size = 14, _tick = 50759, _time = 1.654e+09, train_seconds = 2.3057e+04)
[2022-05-31 20:34:42,998][root][INFO] - Step 152023040 @ 6650.7 SPS. Inference batcher size: 69. Learner queue size: 1. Other stats: (step = 152023040, mean_episode_return = 150.19, mean_episode_step = 610.68, total_loss = 585.21, pg_loss = 235.2, baseline_loss = 356.47, entropy_loss = -6.4578, learner_queue_size = 23, _tick = 50771, _time = 1.654e+09, train_seconds = 2.3062e+04)
[2022-05-31 20:34:48,004][root][INFO] - Step 152053760 @ 6136.7 SPS. Inference batcher size: 106. Learner queue size: 16. Other stats: (step = 152053760, mean_episode_return = 220.29, mean_episode_step = 638.93, total_loss = 252.21, pg_loss = 170.37, baseline_loss = 88.577, entropy_loss = -6.7361, learner_queue_size = 10, _tick = 50783, _time = 1.654e+09, train_seconds = 2.3067e+04)
[2022-05-31 20:34:53,010][root][INFO] - Step 152087040 @ 6647.8 SPS. Inference batcher size: 62. Learner queue size: 16. Other stats: (step = 152087040, mean_episode_return = 373.7, mean_episode_step = 1158.7, total_loss = -59.58, pg_loss = -120.67, baseline_loss = 68.41, entropy_loss = -7.3179, learner_queue_size = 26, _tick = 50796, _time = 1.654e+09, train_seconds = 2.3072e+04)
[2022-05-31 20:34:58,014][root][INFO] - Step 152120320 @ 6650.7 SPS. Inference batcher size: 116. Learner queue size: 29. Other stats: (step = 152120320, mean_episode_return = 90.166, mean_episode_step = 771.71, total_loss = 66.717, pg_loss = -23.815, baseline_loss = 96.607, entropy_loss = -6.0743, learner_queue_size = 23, _tick = 50809, _time = 1.654e+09, train_seconds = 2.3077e+04)
[2022-05-31 20:35:03,020][root][INFO] - Step 152153600 @ 6647.9 SPS. Inference batcher size: 148. Learner queue size: 14. Other stats: (step = 152153600, mean_episode_return = 241.11, mean_episode_step = 649.7, total_loss = 151.21, pg_loss = 86.064, baseline_loss = 70.866, entropy_loss = -5.7239, learner_queue_size = 15, _tick = 50821, _time = 1.654e+09, train_seconds = 2.3082e+04)
[2022-05-31 20:35:08,026][root][INFO] - Step 152186880 @ 6648.0 SPS. Inference batcher size: 53. Learner queue size: 22. Other stats: (step = 152186880, mean_episode_return = 217.32, mean_episode_step = 724.02, total_loss = -266.3, pg_loss = -302.24, baseline_loss = 42.445, entropy_loss = -6.5072, learner_queue_size = 21, _tick = 50834, _time = 1.654e+09, train_seconds = 2.3087e+04)
[2022-05-31 20:35:13,030][root][INFO] - Step 152220160 @ 6650.8 SPS. Inference batcher size: 82. Learner queue size: 9. Other stats: (step = 152220160, mean_episode_return = 224.89, mean_episode_step = 585.56, total_loss = 38.868, pg_loss = -56.361, baseline_loss = 101.49, entropy_loss = -6.2647, learner_queue_size = 20, _tick = 50847, _time = 1.654e+09, train_seconds = 2.3092e+04)
[2022-05-31 20:35:18,034][root][INFO] - Step 152253440 @ 6650.6 SPS. Inference batcher size: 160. Learner queue size: 3. Other stats: (step = 152253440, mean_episode_return = 236.08, mean_episode_step = 558.18, total_loss = 253.83, pg_loss = 100.2, baseline_loss = 159.59, entropy_loss = -5.964, learner_queue_size = 18, _tick = 50860, _time = 1.654e+09, train_seconds = 2.3097e+04)
[2022-05-31 20:35:23,038][root][INFO] - Step 152286720 @ 6650.7 SPS. Inference batcher size: 111. Learner queue size: 9. Other stats: (step = 152286720, mean_episode_return = 220.26, mean_episode_step = 674.63, total_loss = 503.17, pg_loss = 231.07, baseline_loss = 278.12, entropy_loss = -6.0235, learner_queue_size = 17, _tick = 50871, _time = 1.654e+09, train_seconds = 2.3102e+04)
[2022-05-31 20:35:28,042][root][INFO] - Step 152320000 @ 6650.7 SPS. Inference batcher size: 106. Learner queue size: 5. Other stats: (step = 152320000, mean_episode_return = 416.6, mean_episode_step = 788.28, total_loss = 209.87, pg_loss = -29.061, baseline_loss = 245.66, entropy_loss = -6.7354, learner_queue_size = 12, _tick = 50883, _time = 1.654e+09, train_seconds = 2.3107e+04)
[2022-05-31 20:35:33,046][root][INFO] - Step 152353280 @ 6650.6 SPS. Inference batcher size: 103. Learner queue size: 7. Other stats: (step = 152353280, mean_episode_return = 65.56, mean_episode_step = 929.33, total_loss = -13.028, pg_loss = -118.82, baseline_loss = 112.24, entropy_loss = -6.4433, learner_queue_size = 27, _tick = 50895, _time = 1.654e+09, train_seconds = 2.3112e+04)
[2022-05-31 20:35:38,050][root][INFO] - Step 152386560 @ 6650.8 SPS. Inference batcher size: 108. Learner queue size: 4. Other stats: (step = 152386560, mean_episode_return = 80.46, mean_episode_step = 716.02, total_loss = 689.66, pg_loss = 395.33, baseline_loss = 300.86, entropy_loss = -6.5294, learner_queue_size = 16, _tick = 50908, _time = 1.654e+09, train_seconds = 2.3117e+04)
[2022-05-31 20:35:43,054][root][INFO] - Step 152419840 @ 6650.7 SPS. Inference batcher size: 103. Learner queue size: 2. Other stats: (step = 152419840, mean_episode_return = 289.71, mean_episode_step = 730.78, total_loss = 19.713, pg_loss = -38.188, baseline_loss = 64.425, entropy_loss = -6.5246, learner_queue_size = 14, _tick = 50919, _time = 1.654e+09, train_seconds = 2.3122e+04)
[2022-05-31 20:35:48,058][root][INFO] - Step 152453120 @ 6650.7 SPS. Inference batcher size: 105. Learner queue size: 20. Other stats: (step = 152453120, mean_episode_return = 475.77, mean_episode_step = 518.12, total_loss = 127.22, pg_loss = 57.925, baseline_loss = 75.181, entropy_loss = -5.886, learner_queue_size = 18, _tick = 50929, _time = 1.654e+09, train_seconds = 2.3127e+04)
[2022-05-31 20:35:53,060][root][INFO] - Step 152483840 @ 6141.5 SPS. Inference batcher size: 150. Learner queue size: 12. Other stats: (step = 152483840, mean_episode_return = 311.04, mean_episode_step = 645.71, total_loss = 126.38, pg_loss = 74.078, baseline_loss = 58.733, entropy_loss = -6.4337, learner_queue_size = 15, _tick = 50941, _time = 1.654e+09, train_seconds = 2.3132e+04)
[2022-05-31 20:35:58,062][root][INFO] - Step 152517120 @ 6653.4 SPS. Inference batcher size: 113. Learner queue size: 19. Other stats: (step = 152517120, mean_episode_return = 151.37, mean_episode_step = 784.53, total_loss = 136.53, pg_loss = 96.134, baseline_loss = 47.036, entropy_loss = -6.6378, learner_queue_size = 16, _tick = 50951, _time = 1.654e+09, train_seconds = 2.3137e+04)
[2022-05-31 20:36:03,066][root][INFO] - Step 152550400 @ 6650.7 SPS. Inference batcher size: 92. Learner queue size: 5. Other stats: (step = 152550400, mean_episode_return = 247.1, mean_episode_step = 792.32, total_loss = -180.56, pg_loss = -234.03, baseline_loss = 59.711, entropy_loss = -6.2413, learner_queue_size = 25, _tick = 50963, _time = 1.654e+09, train_seconds = 2.3142e+04)
[2022-05-31 20:36:08,070][root][INFO] - Step 152583680 @ 6650.7 SPS. Inference batcher size: 86. Learner queue size: 4. Other stats: (step = 152583680, mean_episode_return = 274.09, mean_episode_step = 567.11, total_loss = 13.552, pg_loss = -118.18, baseline_loss = 137.36, entropy_loss = -5.629, learner_queue_size = 20, _tick = 50974, _time = 1.654e+09, train_seconds = 2.3147e+04)
[2022-05-31 20:36:13,074][root][INFO] - Step 152616960 @ 6650.7 SPS. Inference batcher size: 108. Learner queue size: 3. Other stats: (step = 152616960, mean_episode_return = 204.8, mean_episode_step = 584.24, total_loss = -27.96, pg_loss = -64.363, baseline_loss = 42.609, entropy_loss = -6.2059, learner_queue_size = 29, _tick = 50987, _time = 1.654e+09, train_seconds = 2.3152e+04)
[2022-05-31 20:36:18,078][root][INFO] - Step 152650240 @ 6650.5 SPS. Inference batcher size: 102. Learner queue size: 0. Other stats: (step = 152650240, mean_episode_return = 305.51, mean_episode_step = 737.72, total_loss = 76.894, pg_loss = 25.033, baseline_loss = 58.962, entropy_loss = -7.1, learner_queue_size = 13, _tick = 50998, _time = 1.654e+09, train_seconds = 2.3157e+04)
[2022-05-31 20:36:23,084][root][INFO] - Step 152683520 @ 6647.9 SPS. Inference batcher size: 94. Learner queue size: 2. Other stats: (step = 152683520, mean_episode_return = 278.73, mean_episode_step = 792.44, total_loss = 85.09, pg_loss = 34.99, baseline_loss = 57.153, entropy_loss = -7.053, learner_queue_size = 12, _tick = 51008, _time = 1.654e+09, train_seconds = 2.3162e+04)
[2022-05-31 20:36:28,090][root][INFO] - Step 152716800 @ 6648.2 SPS. Inference batcher size: 205. Learner queue size: 7. Other stats: (step = 152716800, mean_episode_return = None, mean_episode_step = 644.5, total_loss = 109.79, pg_loss = 54.761, baseline_loss = 60.985, entropy_loss = -5.9593, learner_queue_size = 21, _tick = 51020, _time = 1.654e+09, train_seconds = 2.3167e+04)
[2022-05-31 20:36:33,094][root][INFO] - Step 152750080 @ 6650.8 SPS. Inference batcher size: 81. Learner queue size: 28. Other stats: (step = 152750080, mean_episode_return = 273.72, mean_episode_step = 606.79, total_loss = -167.18, pg_loss = -188.11, baseline_loss = 27.316, entropy_loss = -6.3908, learner_queue_size = 21, _tick = 51032, _time = 1.654e+09, train_seconds = 2.3172e+04)
[2022-05-31 20:36:38,098][root][INFO] - Step 152783360 @ 6650.7 SPS. Inference batcher size: 67. Learner queue size: 0. Other stats: (step = 152783360, mean_episode_return = 741.5, mean_episode_step = 579.29, total_loss = 166.7, pg_loss = 69.573, baseline_loss = 103.07, entropy_loss = -5.945, learner_queue_size = 24, _tick = 51043, _time = 1.654e+09, train_seconds = 2.3177e+04)
[2022-05-31 20:36:43,102][root][INFO] - Step 152814080 @ 6139.1 SPS. Inference batcher size: 134. Learner queue size: 23. Other stats: (step = 152814080, mean_episode_return = 278.14, mean_episode_step = 751.6, total_loss = 42.003, pg_loss = -121.47, baseline_loss = 169.76, entropy_loss = -6.2827, learner_queue_size = 18, _tick = 51054, _time = 1.654e+09, train_seconds = 2.3182e+04)
[2022-05-31 20:36:48,108][root][INFO] - Step 152847360 @ 6648.0 SPS. Inference batcher size: 143. Learner queue size: 11. Other stats: (step = 152847360, mean_episode_return = 60.02, mean_episode_step = 664.17, total_loss = -139.15, pg_loss = -181.65, baseline_loss = 48.33, entropy_loss = -5.8317, learner_queue_size = 20, _tick = 51066, _time = 1.654e+09, train_seconds = 2.3187e+04)
[2022-05-31 20:36:53,114][root][INFO] - Step 152880640 @ 6648.0 SPS. Inference batcher size: 74. Learner queue size: 7. Other stats: (step = 152880640, mean_episode_return = 156.05, mean_episode_step = 655.42, total_loss = 511.07, pg_loss = 355.33, baseline_loss = 161.25, entropy_loss = -5.5033, learner_queue_size = 16, _tick = 51077, _time = 1.654e+09, train_seconds = 2.3192e+04)
[2022-05-31 20:36:58,118][root][INFO] - Step 152913920 @ 6650.7 SPS. Inference batcher size: 152. Learner queue size: 1. Other stats: (step = 152913920, mean_episode_return = 153.35, mean_episode_step = 827.76, total_loss = -105.29, pg_loss = -162.8, baseline_loss = 63.955, entropy_loss = -6.4408, learner_queue_size = 14, _tick = 51089, _time = 1.654e+09, train_seconds = 2.3197e+04)
[2022-05-31 20:37:03,122][root][INFO] - Step 152947200 @ 6650.6 SPS. Inference batcher size: 88. Learner queue size: 4. Other stats: (step = 152947200, mean_episode_return = 147.86, mean_episode_step = 725.16, total_loss = -109.59, pg_loss = -139.7, baseline_loss = 36.528, entropy_loss = -6.4207, learner_queue_size = 20, _tick = 51102, _time = 1.654e+09, train_seconds = 2.3202e+04)
[2022-05-31 20:37:08,128][root][INFO] - Step 152977920 @ 6136.8 SPS. Inference batcher size: 150. Learner queue size: 20. Other stats: (step = 152977920, mean_episode_return = 296.54, mean_episode_step = 657.48, total_loss = 274.93, pg_loss = 132.53, baseline_loss = 148.1, entropy_loss = -5.7002, learner_queue_size = 15, _tick = 51113, _time = 1.654e+09, train_seconds = 2.3207e+04)
[2022-05-31 20:37:13,130][root][INFO] - Step 153011200 @ 6653.2 SPS. Inference batcher size: 113. Learner queue size: 16. Other stats: (step = 153011200, mean_episode_return = 202.12, mean_episode_step = 787.76, total_loss = 140.92, pg_loss = 58.041, baseline_loss = 89.02, entropy_loss = -6.1397, learner_queue_size = 19, _tick = 51125, _time = 1.654e+09, train_seconds = 2.3212e+04)
[2022-05-31 20:37:18,134][root][INFO] - Step 153044480 @ 6650.8 SPS. Inference batcher size: 122. Learner queue size: 5. Other stats: (step = 153044480, mean_episode_return = 309.98, mean_episode_step = 674.64, total_loss = -108.58, pg_loss = -290.27, baseline_loss = 187.77, entropy_loss = -6.0835, learner_queue_size = 26, _tick = 51138, _time = 1.654e+09, train_seconds = 2.3217e+04)
[2022-05-31 20:37:23,138][root][INFO] - Step 153077760 @ 6650.7 SPS. Inference batcher size: 187. Learner queue size: 28. Other stats: (step = 153077760, mean_episode_return = 326.48, mean_episode_step = 573.45, total_loss = 195.82, pg_loss = -114.23, baseline_loss = 315.71, entropy_loss = -5.6544, learner_queue_size = 12, _tick = 51149, _time = 1.654e+09, train_seconds = 2.3222e+04)
[2022-05-31 20:37:28,142][root][INFO] - Step 153108480 @ 6139.1 SPS. Inference batcher size: 141. Learner queue size: 28. Other stats: (step = 153108480, mean_episode_return = 41.41, mean_episode_step = 799.16, total_loss = -86.409, pg_loss = -180.88, baseline_loss = 100.71, entropy_loss = -6.2367, learner_queue_size = 19, _tick = 51159, _time = 1.654e+09, train_seconds = 2.3227e+04)
[2022-05-31 20:37:33,146][root][INFO] - Step 153141760 @ 6650.6 SPS. Inference batcher size: 144. Learner queue size: 26. Other stats: (step = 153141760, mean_episode_return = 219.43, mean_episode_step = 712.66, total_loss = -42.661, pg_loss = -142.69, baseline_loss = 106.84, entropy_loss = -6.8134, learner_queue_size = 7, _tick = 51171, _time = 1.654e+09, train_seconds = 2.3232e+04)
[2022-05-31 20:37:38,152][root][INFO] - Step 153175040 @ 6647.9 SPS. Inference batcher size: 169. Learner queue size: 14. Other stats: (step = 153175040, mean_episode_return = 75.89, mean_episode_step = 853.45, total_loss = 83.919, pg_loss = 45.567, baseline_loss = 45.113, entropy_loss = -6.7603, learner_queue_size = 11, _tick = 51183, _time = 1.654e+09, train_seconds = 2.3237e+04)
[2022-05-31 20:37:43,158][root][INFO] - Step 153208320 @ 6648.3 SPS. Inference batcher size: 160. Learner queue size: 13. Other stats: (step = 153208320, mean_episode_return = 123.96, mean_episode_step = 707.12, total_loss = 153.41, pg_loss = 94.551, baseline_loss = 65.013, entropy_loss = -6.1561, learner_queue_size = 14, _tick = 51195, _time = 1.654e+09, train_seconds = 2.3242e+04)
[2022-05-31 20:37:48,162][root][INFO] - Step 153241600 @ 6650.6 SPS. Inference batcher size: 30. Learner queue size: 6. Other stats: (step = 153241600, mean_episode_return = 237.65, mean_episode_step = 569.94, total_loss = 345.03, pg_loss = 195.86, baseline_loss = 155.15, entropy_loss = -5.9812, learner_queue_size = 23, _tick = 51207, _time = 1.654e+09, train_seconds = 2.3247e+04)
[2022-05-31 20:37:53,168][root][INFO] - Step 153274880 @ 6647.8 SPS. Inference batcher size: 47. Learner queue size: 1. Other stats: (step = 153274880, mean_episode_return = 621.95, mean_episode_step = 604.1, total_loss = -64.06, pg_loss = -163.02, baseline_loss = 104.4, entropy_loss = -5.4456, learner_queue_size = 27, _tick = 51220, _time = 1.654e+09, train_seconds = 2.3252e+04)
[2022-05-31 20:37:58,174][root][INFO] - Step 153305600 @ 6136.4 SPS. Inference batcher size: 109. Learner queue size: 26. Other stats: (step = 153305600, mean_episode_return = 338.91, mean_episode_step = 528.13, total_loss = 292.62, pg_loss = 103.58, baseline_loss = 194.18, entropy_loss = -5.1428, learner_queue_size = 10, _tick = 51231, _time = 1.654e+09, train_seconds = 2.3257e+04)
[2022-05-31 20:38:03,178][root][INFO] - Step 153341440 @ 7162.8 SPS. Inference batcher size: 114. Learner queue size: 30. Other stats: (step = 153341440, mean_episode_return = 103.29, mean_episode_step = 668.51, total_loss = -236.6, pg_loss = -263.0, baseline_loss = 32.372, entropy_loss = -5.9764, learner_queue_size = 16, _tick = 51244, _time = 1.654e+09, train_seconds = 2.3262e+04)
[2022-05-31 20:38:08,183][root][INFO] - Step 153374720 @ 6648.8 SPS. Inference batcher size: 116. Learner queue size: 18. Other stats: (step = 153374720, mean_episode_return = 511.02, mean_episode_step = 690.46, total_loss = 407.32, pg_loss = 270.8, baseline_loss = 141.67, entropy_loss = -5.1502, learner_queue_size = 18, _tick = 51257, _time = 1.654e+09, train_seconds = 2.3267e+04)
[2022-05-31 20:38:13,189][root][INFO] - Step 153405440 @ 6136.8 SPS. Inference batcher size: 128. Learner queue size: 18. Other stats: (step = 153405440, mean_episode_return = 585.67, mean_episode_step = 648.75, total_loss = 126.78, pg_loss = 1.6439, baseline_loss = 130.85, entropy_loss = -5.7138, learner_queue_size = 19, _tick = 51268, _time = 1.654e+09, train_seconds = 2.3272e+04)
[2022-05-31 20:38:18,194][root][INFO] - Step 153438720 @ 6649.8 SPS. Inference batcher size: 119. Learner queue size: 19. Other stats: (step = 153438720, mean_episode_return = 526.08, mean_episode_step = 628.35, total_loss = 434.71, pg_loss = 227.13, baseline_loss = 213.06, entropy_loss = -5.4764, learner_queue_size = 16, _tick = 51281, _time = 1.654e+09, train_seconds = 2.3277e+04)
[2022-05-31 20:38:23,198][root][INFO] - Step 153472000 @ 6650.7 SPS. Inference batcher size: 127. Learner queue size: 12. Other stats: (step = 153472000, mean_episode_return = 207.31, mean_episode_step = 727.38, total_loss = 340.04, pg_loss = 236.84, baseline_loss = 109.39, entropy_loss = -6.186, learner_queue_size = 15, _tick = 51294, _time = 1.654e+09, train_seconds = 2.3282e+04)
[2022-05-31 20:38:28,201][root][INFO] - Step 153505280 @ 6651.8 SPS. Inference batcher size: 140. Learner queue size: 9. Other stats: (step = 153505280, mean_episode_return = None, mean_episode_step = 705.22, total_loss = 122.01, pg_loss = 74.187, baseline_loss = 54.209, entropy_loss = -6.3829, learner_queue_size = 14, _tick = 51305, _time = 1.654e+09, train_seconds = 2.3287e+04)
[2022-05-31 20:38:33,207][root][INFO] - Step 153538560 @ 6647.9 SPS. Inference batcher size: 62. Learner queue size: 8. Other stats: (step = 153538560, mean_episode_return = 266.71, mean_episode_step = 594.69, total_loss = 37.488, pg_loss = -54.262, baseline_loss = 97.674, entropy_loss = -5.9232, learner_queue_size = 18, _tick = 51317, _time = 1.654e+09, train_seconds = 2.3292e+04)
[2022-05-31 20:38:38,210][root][INFO] - Step 153571840 @ 6652.4 SPS. Inference batcher size: 138. Learner queue size: 28. Other stats: (step = 153571840, mean_episode_return = None, mean_episode_step = 740.16, total_loss = 24.926, pg_loss = -1.3923, baseline_loss = 31.479, entropy_loss = -5.1616, learner_queue_size = 15, _tick = 51328, _time = 1.654e+09, train_seconds = 2.3297e+04)
[2022-05-31 20:38:43,214][root][INFO] - Step 153605120 @ 6650.6 SPS. Inference batcher size: 125. Learner queue size: 31. Other stats: (step = 153605120, mean_episode_return = 501.52, mean_episode_step = 553.87, total_loss = 118.61, pg_loss = 19.643, baseline_loss = 104.45, entropy_loss = -5.4801, learner_queue_size = 15, _tick = 51341, _time = 1.654e+09, train_seconds = 2.3302e+04)
[2022-05-31 20:38:48,220][root][INFO] - Step 153638400 @ 6647.9 SPS. Inference batcher size: 108. Learner queue size: 25. Other stats: (step = 153638400, mean_episode_return = 404.71, mean_episode_step = 731.37, total_loss = 152.41, pg_loss = 24.144, baseline_loss = 133.56, entropy_loss = -5.29, learner_queue_size = 15, _tick = 51353, _time = 1.654e+09, train_seconds = 2.3307e+04)
[2022-05-31 20:38:53,226][root][INFO] - Step 153671680 @ 6648.1 SPS. Inference batcher size: 81. Learner queue size: 23. Other stats: (step = 153671680, mean_episode_return = 305.63, mean_episode_step = 700.3, total_loss = -26.218, pg_loss = -83.36, baseline_loss = 63.222, entropy_loss = -6.0805, learner_queue_size = 17, _tick = 51364, _time = 1.654e+09, train_seconds = 2.3312e+04)
[2022-05-31 20:38:58,232][root][INFO] - Step 153702400 @ 6136.6 SPS. Inference batcher size: 187. Learner queue size: 22. Other stats: (step = 153702400, mean_episode_return = 130.83, mean_episode_step = 692.15, total_loss = -19.526, pg_loss = -149.68, baseline_loss = 136.47, entropy_loss = -6.3121, learner_queue_size = 18, _tick = 51375, _time = 1.654e+09, train_seconds = 2.3317e+04)
[2022-05-31 20:39:03,238][root][INFO] - Step 153735680 @ 6648.1 SPS. Inference batcher size: 68. Learner queue size: 16. Other stats: (step = 153735680, mean_episode_return = 420.13, mean_episode_step = 732.97, total_loss = 260.19, pg_loss = 164.39, baseline_loss = 102.2, entropy_loss = -6.4033, learner_queue_size = 21, _tick = 51388, _time = 1.654e+09, train_seconds = 2.3322e+04)
[2022-05-31 20:39:08,244][root][INFO] - Step 153768960 @ 6647.9 SPS. Inference batcher size: 150. Learner queue size: 23. Other stats: (step = 153768960, mean_episode_return = 872.23, mean_episode_step = 696.51, total_loss = 430.56, pg_loss = 277.77, baseline_loss = 158.52, entropy_loss = -5.74, learner_queue_size = 19, _tick = 51401, _time = 1.654e+09, train_seconds = 2.3327e+04)
[2022-05-31 20:39:13,250][root][INFO] - Step 153802240 @ 6648.0 SPS. Inference batcher size: 158. Learner queue size: 20. Other stats: (step = 153802240, mean_episode_return = 317.23, mean_episode_step = 615.88, total_loss = 38.345, pg_loss = -47.193, baseline_loss = 91.951, entropy_loss = -6.4123, learner_queue_size = 18, _tick = 51412, _time = 1.654e+09, train_seconds = 2.3332e+04)
[2022-05-31 20:39:18,255][root][INFO] - Step 153835520 @ 6649.8 SPS. Inference batcher size: 51. Learner queue size: 17. Other stats: (step = 153835520, mean_episode_return = 262.25, mean_episode_step = 785.66, total_loss = -12.066, pg_loss = -27.761, baseline_loss = 22.78, entropy_loss = -7.0846, learner_queue_size = 13, _tick = 51422, _time = 1.654e+09, train_seconds = 2.3337e+04)
[2022-05-31 20:39:23,261][root][INFO] - Step 153868800 @ 6648.3 SPS. Inference batcher size: 19. Learner queue size: 7. Other stats: (step = 153868800, mean_episode_return = 144.28, mean_episode_step = 603.19, total_loss = 107.76, pg_loss = 56.563, baseline_loss = 58.355, entropy_loss = -7.1567, learner_queue_size = 12, _tick = 51434, _time = 1.654e+09, train_seconds = 2.3342e+04)
[2022-05-31 20:39:28,266][root][INFO] - Step 153902080 @ 6648.9 SPS. Inference batcher size: 160. Learner queue size: 7. Other stats: (step = 153902080, mean_episode_return = 295.03, mean_episode_step = 589.42, total_loss = -90.67, pg_loss = -158.31, baseline_loss = 74.235, entropy_loss = -6.5953, learner_queue_size = 14, _tick = 51445, _time = 1.654e+09, train_seconds = 2.3347e+04)
[2022-05-31 20:39:33,270][root][INFO] - Step 153935360 @ 6650.7 SPS. Inference batcher size: 67. Learner queue size: 10. Other stats: (step = 153935360, mean_episode_return = 503.02, mean_episode_step = 697.13, total_loss = 143.38, pg_loss = 97.739, baseline_loss = 52.366, entropy_loss = -6.7217, learner_queue_size = 18, _tick = 51457, _time = 1.654e+09, train_seconds = 2.3352e+04)
[2022-05-31 20:39:38,274][root][INFO] - Step 153968640 @ 6650.6 SPS. Inference batcher size: 101. Learner queue size: 2. Other stats: (step = 153968640, mean_episode_return = 265.02, mean_episode_step = 651.84, total_loss = 33.824, pg_loss = -56.916, baseline_loss = 97.275, entropy_loss = -6.5347, learner_queue_size = 10, _tick = 51469, _time = 1.654e+09, train_seconds = 2.3357e+04)
[2022-05-31 20:39:43,278][root][INFO] - Step 154001920 @ 6650.7 SPS. Inference batcher size: 119. Learner queue size: 20. Other stats: (step = 154001920, mean_episode_return = 370.77, mean_episode_step = 982.88, total_loss = 359.15, pg_loss = 210.07, baseline_loss = 155.54, entropy_loss = -6.4495, learner_queue_size = 14, _tick = 51482, _time = 1.654e+09, train_seconds = 2.3362e+04)
[2022-05-31 20:39:48,282][root][INFO] - Step 154032640 @ 6139.2 SPS. Inference batcher size: 95. Learner queue size: 23. Other stats: (step = 154032640, mean_episode_return = 216.15, mean_episode_step = 687.11, total_loss = 113.68, pg_loss = -28.942, baseline_loss = 148.26, entropy_loss = -5.6368, learner_queue_size = 16, _tick = 51494, _time = 1.654e+09, train_seconds = 2.3367e+04)
[2022-05-31 20:39:53,286][root][INFO] - Step 154065920 @ 6650.6 SPS. Inference batcher size: 80. Learner queue size: 16. Other stats: (step = 154065920, mean_episode_return = 389.6, mean_episode_step = 826.61, total_loss = -105.03, pg_loss = -164.07, baseline_loss = 65.441, entropy_loss = -6.3954, learner_queue_size = 16, _tick = 51506, _time = 1.654e+09, train_seconds = 2.3372e+04)
[2022-05-31 20:39:58,292][root][INFO] - Step 154099200 @ 6647.9 SPS. Inference batcher size: 111. Learner queue size: 12. Other stats: (step = 154099200, mean_episode_return = 216.45, mean_episode_step = 826.75, total_loss = 72.047, pg_loss = 6.032, baseline_loss = 72.41, entropy_loss = -6.3953, learner_queue_size = 17, _tick = 51517, _time = 1.654e+09, train_seconds = 2.3377e+04)
[2022-05-31 20:40:03,298][root][INFO] - Step 154132480 @ 6648.1 SPS. Inference batcher size: 127. Learner queue size: 9. Other stats: (step = 154132480, mean_episode_return = 243.94, mean_episode_step = 833.27, total_loss = 23.614, pg_loss = -7.7038, baseline_loss = 38.433, entropy_loss = -7.1147, learner_queue_size = 14, _tick = 51529, _time = 1.654e+09, train_seconds = 2.3382e+04)
[2022-05-31 20:40:08,302][root][INFO] - Step 154165760 @ 6650.7 SPS. Inference batcher size: 114. Learner queue size: 15. Other stats: (step = 154165760, mean_episode_return = 301.89, mean_episode_step = 689.5, total_loss = 156.23, pg_loss = 84.151, baseline_loss = 78.605, entropy_loss = -6.5212, learner_queue_size = 15, _tick = 51541, _time = 1.654e+09, train_seconds = 2.3387e+04)
[2022-05-31 20:40:13,306][root][INFO] - Step 154199040 @ 6650.7 SPS. Inference batcher size: 51. Learner queue size: 6. Other stats: (step = 154199040, mean_episode_return = 176.3, mean_episode_step = 736.01, total_loss = 66.497, pg_loss = -43.717, baseline_loss = 116.74, entropy_loss = -6.5294, learner_queue_size = 32, _tick = 51553, _time = 1.654e+09, train_seconds = 2.3392e+04)
[2022-05-31 20:40:18,312][root][INFO] - Step 154232320 @ 6647.8 SPS. Inference batcher size: 107. Learner queue size: 5. Other stats: (step = 154232320, mean_episode_return = 237.09, mean_episode_step = 704.6, total_loss = -205.26, pg_loss = -328.27, baseline_loss = 129.27, entropy_loss = -6.2695, learner_queue_size = 14, _tick = 51566, _time = 1.654e+09, train_seconds = 2.3397e+04)
[2022-05-31 20:40:23,318][root][INFO] - Step 154265600 @ 6648.1 SPS. Inference batcher size: 108. Learner queue size: 5. Other stats: (step = 154265600, mean_episode_return = 319.42, mean_episode_step = 675.88, total_loss = 315.85, pg_loss = 183.5, baseline_loss = 138.9, entropy_loss = -6.5524, learner_queue_size = 19, _tick = 51578, _time = 1.654e+09, train_seconds = 2.3402e+04)
[2022-05-31 20:40:28,322][root][INFO] - Step 154298880 @ 6650.8 SPS. Inference batcher size: 134. Learner queue size: 21. Other stats: (step = 154298880, mean_episode_return = 270.4, mean_episode_step = 641.53, total_loss = 36.122, pg_loss = -30.555, baseline_loss = 72.396, entropy_loss = -5.7192, learner_queue_size = 16, _tick = 51589, _time = 1.654e+09, train_seconds = 2.3407e+04)
[2022-05-31 20:40:33,326][root][INFO] - Step 154332160 @ 6650.7 SPS. Inference batcher size: 88. Learner queue size: 20. Other stats: (step = 154332160, mean_episode_return = 265.7, mean_episode_step = 862.39, total_loss = 141.75, pg_loss = 40.584, baseline_loss = 107.29, entropy_loss = -6.116, learner_queue_size = 11, _tick = 51602, _time = 1.654e+09, train_seconds = 2.3412e+04)
[2022-05-31 20:40:38,332][root][INFO] - Step 154365440 @ 6648.0 SPS. Inference batcher size: 34. Learner queue size: 18. Other stats: (step = 154365440, mean_episode_return = 529.5, mean_episode_step = 533.27, total_loss = 161.6, pg_loss = -101.62, baseline_loss = 268.77, entropy_loss = -5.5464, learner_queue_size = 18, _tick = 51615, _time = 1.654e+09, train_seconds = 2.3417e+04)
[2022-05-31 20:40:43,339][root][INFO] - Step 154396160 @ 6135.7 SPS. Inference batcher size: 133. Learner queue size: 18. Other stats: (step = 154396160, mean_episode_return = 474.9, mean_episode_step = 600.66, total_loss = -81.182, pg_loss = -224.74, baseline_loss = 149.09, entropy_loss = -5.526, learner_queue_size = 21, _tick = 51627, _time = 1.654e+09, train_seconds = 2.3422e+04)
[2022-05-31 20:40:48,345][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge/nethack_baselines/torchbeast/outputs/2022-05-31/14-10-16/checkpoint.tar
[2022-05-31 20:40:48,500][root][INFO] - Step 154429440 @ 6647.9 SPS. Inference batcher size: 176. Learner queue size: 21. Other stats: (step = 154432000, mean_episode_return = 682.72, mean_episode_step = 828.39, total_loss = 50.125, pg_loss = -73.767, baseline_loss = 130.03, entropy_loss = -6.1345, learner_queue_size = 17, _tick = 51640, _time = 1.654e+09, train_seconds = 2.3427e+04)
[2022-05-31 20:40:53,506][root][INFO] - Step 154462720 @ 6448.1 SPS. Inference batcher size: 112. Learner queue size: 18. Other stats: (step = 154462720, mean_episode_return = 160.09, mean_episode_step = 711.77, total_loss = 419.82, pg_loss = 300.16, baseline_loss = 125.11, entropy_loss = -5.4511, learner_queue_size = 25, _tick = 51651, _time = 1.654e+09, train_seconds = 2.3432e+04)
[2022-05-31 20:40:58,510][root][INFO] - Step 154496000 @ 6650.7 SPS. Inference batcher size: 86. Learner queue size: 11. Other stats: (step = 154496000, mean_episode_return = 655.84, mean_episode_step = 466.8, total_loss = 349.26, pg_loss = 172.76, baseline_loss = 181.68, entropy_loss = -5.1856, learner_queue_size = 11, _tick = 51663, _time = 1.654e+09, train_seconds = 2.3437e+04)
[2022-05-31 20:41:03,516][root][INFO] - Step 154529280 @ 6648.0 SPS. Inference batcher size: 48. Learner queue size: 19. Other stats: (step = 154529280, mean_episode_return = 175.49, mean_episode_step = 927.41, total_loss = 321.27, pg_loss = 163.32, baseline_loss = 164.14, entropy_loss = -6.1916, learner_queue_size = 28, _tick = 51675, _time = 1.654e+09, train_seconds = 2.3442e+04)
[2022-05-31 20:41:08,522][root][INFO] - Step 154562560 @ 6648.0 SPS. Inference batcher size: 101. Learner queue size: 9. Other stats: (step = 154562560, mean_episode_return = 366.09, mean_episode_step = 593.2, total_loss = -159.23, pg_loss = -240.59, baseline_loss = 87.393, entropy_loss = -6.0292, learner_queue_size = 21, _tick = 51687, _time = 1.654e+09, train_seconds = 2.3447e+04)
[2022-05-31 20:41:13,528][root][INFO] - Step 154595840 @ 6647.8 SPS. Inference batcher size: 122. Learner queue size: 15. Other stats: (step = 154595840, mean_episode_return = 236.55, mean_episode_step = 914.6, total_loss = 372.85, pg_loss = 274.24, baseline_loss = 105.9, entropy_loss = -7.2902, learner_queue_size = 19, _tick = 51699, _time = 1.654e+09, train_seconds = 2.3452e+04)
[2022-05-31 20:41:18,535][root][INFO] - Step 154629120 @ 6647.1 SPS. Inference batcher size: 141. Learner queue size: 10. Other stats: (step = 154629120, mean_episode_return = 316.64, mean_episode_step = 632.92, total_loss = 14.835, pg_loss = -47.013, baseline_loss = 68.08, entropy_loss = -6.2321, learner_queue_size = 19, _tick = 51712, _time = 1.654e+09, train_seconds = 2.3457e+04)
[2022-05-31 20:41:23,538][root][INFO] - Step 154662400 @ 6651.9 SPS. Inference batcher size: 120. Learner queue size: 2. Other stats: (step = 154662400, mean_episode_return = 179.55, mean_episode_step = 654.33, total_loss = 385.45, pg_loss = 208.52, baseline_loss = 183.45, entropy_loss = -6.5198, learner_queue_size = 21, _tick = 51723, _time = 1.654e+09, train_seconds = 2.3462e+04)
[2022-05-31 20:41:28,544][root][INFO] - Step 154695680 @ 6648.0 SPS. Inference batcher size: 115. Learner queue size: 5. Other stats: (step = 154695680, mean_episode_return = 224.53, mean_episode_step = 723.86, total_loss = 249.61, pg_loss = 40.347, baseline_loss = 215.88, entropy_loss = -6.6117, learner_queue_size = 19, _tick = 51735, _time = 1.654e+09, train_seconds = 2.3467e+04)
[2022-05-31 20:41:33,550][root][INFO] - Step 154728960 @ 6647.9 SPS. Inference batcher size: 98. Learner queue size: 26. Other stats: (step = 154728960, mean_episode_return = 282.88, mean_episode_step = 769.47, total_loss = -292.07, pg_loss = -355.54, baseline_loss = 70.405, entropy_loss = -6.929, learner_queue_size = 20, _tick = 51745, _time = 1.654e+09, train_seconds = 2.3472e+04)
[2022-05-31 20:41:38,556][root][INFO] - Step 154759680 @ 6136.6 SPS. Inference batcher size: 98. Learner queue size: 19. Other stats: (step = 154759680, mean_episode_return = 407.84, mean_episode_step = 663.98, total_loss = 113.67, pg_loss = -29.754, baseline_loss = 149.89, entropy_loss = -6.4674, learner_queue_size = 16, _tick = 51757, _time = 1.654e+09, train_seconds = 2.3477e+04)
[2022-05-31 20:41:43,562][root][INFO] - Step 154792960 @ 6648.0 SPS. Inference batcher size: 117. Learner queue size: 17. Other stats: (step = 154792960, mean_episode_return = 142.69, mean_episode_step = 650.57, total_loss = -199.78, pg_loss = -301.05, baseline_loss = 107.8, entropy_loss = -6.535, learner_queue_size = 12, _tick = 51769, _time = 1.654e+09, train_seconds = 2.3482e+04)
[2022-05-31 20:41:48,566][root][INFO] - Step 154826240 @ 6650.8 SPS. Inference batcher size: 117. Learner queue size: 17. Other stats: (step = 154826240, mean_episode_return = 523.77, mean_episode_step = 591.61, total_loss = 122.15, pg_loss = -0.64679, baseline_loss = 128.25, entropy_loss = -5.4518, learner_queue_size = 18, _tick = 51778, _time = 1.654e+09, train_seconds = 2.3487e+04)
[2022-05-31 20:41:53,570][root][INFO] - Step 154859520 @ 6650.2 SPS. Inference batcher size: 34. Learner queue size: 9. Other stats: (step = 154859520, mean_episode_return = 359.42, mean_episode_step = 760.55, total_loss = 268.84, pg_loss = 107.96, baseline_loss = 167.87, entropy_loss = -6.9972, learner_queue_size = 25, _tick = 51791, _time = 1.654e+09, train_seconds = 2.3492e+04)
[2022-05-31 20:41:58,574][root][INFO] - Step 154892800 @ 6651.1 SPS. Inference batcher size: 161. Learner queue size: 8. Other stats: (step = 154892800, mean_episode_return = 364.35, mean_episode_step = 561.59, total_loss = 34.257, pg_loss = -11.637, baseline_loss = 52.243, entropy_loss = -6.348, learner_queue_size = 21, _tick = 51804, _time = 1.654e+09, train_seconds = 2.3497e+04)
[2022-05-31 20:42:03,578][root][INFO] - Step 154926080 @ 6650.8 SPS. Inference batcher size: 144. Learner queue size: 6. Other stats: (step = 154926080, mean_episode_return = 512.11, mean_episode_step = 696.71, total_loss = 214.19, pg_loss = 154.0, baseline_loss = 66.519, entropy_loss = -6.3324, learner_queue_size = 16, _tick = 51815, _time = 1.654e+09, train_seconds = 2.3502e+04)
[2022-05-31 20:42:08,582][root][INFO] - Step 154959360 @ 6650.7 SPS. Inference batcher size: 91. Learner queue size: 11. Other stats: (step = 154959360, mean_episode_return = 146.25, mean_episode_step = 819.55, total_loss = 77.412, pg_loss = -50.089, baseline_loss = 133.74, entropy_loss = -6.24, learner_queue_size = 27, _tick = 51827, _time = 1.654e+09, train_seconds = 2.3507e+04)
[2022-05-31 20:42:13,586][root][INFO] - Step 154992640 @ 6650.7 SPS. Inference batcher size: 103. Learner queue size: 3. Other stats: (step = 154992640, mean_episode_return = None, mean_episode_step = 699.47, total_loss = 228.94, pg_loss = 171.46, baseline_loss = 64.71, entropy_loss = -7.2319, learner_queue_size = 20, _tick = 51838, _time = 1.654e+09, train_seconds = 2.3512e+04)
[2022-05-31 20:42:18,590][root][INFO] - Step 155025920 @ 6650.8 SPS. Inference batcher size: 134. Learner queue size: 3. Other stats: (step = 155025920, mean_episode_return = 123.61, mean_episode_step = 583.18, total_loss = 241.92, pg_loss = 162.45, baseline_loss = 85.876, entropy_loss = -6.407, learner_queue_size = 7, _tick = 51848, _time = 1.654e+09, train_seconds = 2.3517e+04)
[2022-05-31 20:42:23,594][root][INFO] - Step 155059200 @ 6650.6 SPS. Inference batcher size: 127. Learner queue size: 5. Other stats: (step = 155059200, mean_episode_return = 241.06, mean_episode_step = 739.71, total_loss = 216.93, pg_loss = 146.75, baseline_loss = 76.983, entropy_loss = -6.8026, learner_queue_size = 18, _tick = 51859, _time = 1.654e+09, train_seconds = 2.3522e+04)
[2022-05-31 20:42:28,598][root][INFO] - Step 155092480 @ 6650.7 SPS. Inference batcher size: 149. Learner queue size: 1. Other stats: (step = 155092480, mean_episode_return = 294.71, mean_episode_step = 723.56, total_loss = 232.32, pg_loss = 143.72, baseline_loss = 94.894, entropy_loss = -6.2965, learner_queue_size = 11, _tick = 51871, _time = 1.654e+09, train_seconds = 2.3527e+04)
[2022-05-31 20:42:33,604][root][INFO] - Step 155125760 @ 6647.7 SPS. Inference batcher size: 22. Learner queue size: 25. Other stats: (step = 155125760, mean_episode_return = 228.97, mean_episode_step = 688.94, total_loss = 96.049, pg_loss = -105.78, baseline_loss = 207.44, entropy_loss = -5.6109, learner_queue_size = 24, _tick = 51884, _time = 1.654e+09, train_seconds = 2.3532e+04)
[2022-05-31 20:42:38,611][root][INFO] - Step 155156480 @ 6136.1 SPS. Inference batcher size: 121. Learner queue size: 17. Other stats: (step = 155156480, mean_episode_return = 193.62, mean_episode_step = 738.51, total_loss = 426.87, pg_loss = 67.125, baseline_loss = 365.66, entropy_loss = -5.9086, learner_queue_size = 20, _tick = 51896, _time = 1.654e+09, train_seconds = 2.3537e+04)
[2022-05-31 20:42:43,617][root][INFO] - Step 155189760 @ 6648.0 SPS. Inference batcher size: 105. Learner queue size: 14. Other stats: (step = 155189760, mean_episode_return = 266.78, mean_episode_step = 741.76, total_loss = 148.21, pg_loss = 80.423, baseline_loss = 74.517, entropy_loss = -6.7328, learner_queue_size = 18, _tick = 51909, _time = 1.654e+09, train_seconds = 2.3542e+04)
[2022-05-31 20:42:48,623][root][INFO] - Step 155223040 @ 6648.1 SPS. Inference batcher size: 106. Learner queue size: 17. Other stats: (step = 155223040, mean_episode_return = 125.06, mean_episode_step = 616.95, total_loss = 419.43, pg_loss = 233.29, baseline_loss = 192.86, entropy_loss = -6.7192, learner_queue_size = 19, _tick = 51921, _time = 1.654e+09, train_seconds = 2.3547e+04)
[2022-05-31 20:42:53,626][root][INFO] - Step 155256320 @ 6651.4 SPS. Inference batcher size: 116. Learner queue size: 10. Other stats: (step = 155256320, mean_episode_return = 383.94, mean_episode_step = 877.14, total_loss = 169.86, pg_loss = 88.792, baseline_loss = 87.625, entropy_loss = -6.5613, learner_queue_size = 17, _tick = 51933, _time = 1.654e+09, train_seconds = 2.3552e+04)
[2022-05-31 20:42:58,632][root][INFO] - Step 155289600 @ 6647.9 SPS. Inference batcher size: 111. Learner queue size: 17. Other stats: (step = 155289600, mean_episode_return = 173.57, mean_episode_step = 505.95, total_loss = 470.0, pg_loss = 291.53, baseline_loss = 184.45, entropy_loss = -5.973, learner_queue_size = 23, _tick = 51946, _time = 1.654e+09, train_seconds = 2.3557e+04)
[2022-05-31 20:43:03,638][root][INFO] - Step 155322880 @ 6648.0 SPS. Inference batcher size: 133. Learner queue size: 18. Other stats: (step = 155322880, mean_episode_return = 423.01, mean_episode_step = 586.84, total_loss = -231.36, pg_loss = -272.34, baseline_loss = 47.244, entropy_loss = -6.2624, learner_queue_size = 22, _tick = 51959, _time = 1.654e+09, train_seconds = 2.3562e+04)
[2022-05-31 20:43:08,642][root][INFO] - Step 155356160 @ 6650.9 SPS. Inference batcher size: 24. Learner queue size: 2. Other stats: (step = 155356160, mean_episode_return = 72.448, mean_episode_step = 661.9, total_loss = 141.26, pg_loss = 61.583, baseline_loss = 85.642, entropy_loss = -5.9609, learner_queue_size = 20, _tick = 51971, _time = 1.654e+09, train_seconds = 2.3567e+04)
[2022-05-31 20:43:13,648][root][INFO] - Step 155389440 @ 6648.0 SPS. Inference batcher size: 98. Learner queue size: 4. Other stats: (step = 155389440, mean_episode_return = 45.021, mean_episode_step = 671.09, total_loss = 171.56, pg_loss = 107.93, baseline_loss = 69.782, entropy_loss = -6.1459, learner_queue_size = 28, _tick = 51981, _time = 1.654e+09, train_seconds = 2.3572e+04)
[2022-05-31 20:43:18,654][root][INFO] - Step 155422720 @ 6648.1 SPS. Inference batcher size: 39. Learner queue size: 31. Other stats: (step = 155422720, mean_episode_return = 442.75, mean_episode_step = 679.03, total_loss = -0.1941, pg_loss = -37.679, baseline_loss = 44.126, entropy_loss = -6.6411, learner_queue_size = 18, _tick = 51992, _time = 1.654e+09, train_seconds = 2.3577e+04)
[2022-05-31 20:43:23,658][root][INFO] - Step 155456000 @ 6650.5 SPS. Inference batcher size: 113. Learner queue size: 1. Other stats: (step = 155456000, mean_episode_return = 151.33, mean_episode_step = 631.03, total_loss = 522.15, pg_loss = 398.37, baseline_loss = 129.74, entropy_loss = -5.9685, learner_queue_size = 18, _tick = 52005, _time = 1.654e+09, train_seconds = 2.3582e+04)
[2022-05-31 20:43:28,662][root][INFO] - Step 155489280 @ 6650.8 SPS. Inference batcher size: 88. Learner queue size: 27. Other stats: (step = 155489280, mean_episode_return = 292.57, mean_episode_step = 656.79, total_loss = 150.25, pg_loss = 97.849, baseline_loss = 58.177, entropy_loss = -5.7751, learner_queue_size = 23, _tick = 52017, _time = 1.654e+09, train_seconds = 2.3587e+04)
[2022-05-31 20:43:33,666][root][INFO] - Step 155522560 @ 6650.6 SPS. Inference batcher size: 108. Learner queue size: 22. Other stats: (step = 155522560, mean_episode_return = 190.57, mean_episode_step = 661.79, total_loss = 174.06, pg_loss = 59.493, baseline_loss = 120.77, entropy_loss = -6.2098, learner_queue_size = 19, _tick = 52028, _time = 1.654e+09, train_seconds = 2.3592e+04)
[2022-05-31 20:43:38,672][root][INFO] - Step 155553280 @ 6136.5 SPS. Inference batcher size: 142. Learner queue size: 8. Other stats: (step = 155553280, mean_episode_return = 81.429, mean_episode_step = 731.66, total_loss = 443.16, pg_loss = 198.5, baseline_loss = 250.5, entropy_loss = -5.8341, learner_queue_size = 16, _tick = 52038, _time = 1.654e+09, train_seconds = 2.3597e+04)
[2022-05-31 20:43:43,678][root][INFO] - Step 155586560 @ 6648.1 SPS. Inference batcher size: 143. Learner queue size: 16. Other stats: (step = 155586560, mean_episode_return = 397.77, mean_episode_step = 593.71, total_loss = 83.697, pg_loss = -206.5, baseline_loss = 296.02, entropy_loss = -5.8231, learner_queue_size = 17, _tick = 52051, _time = 1.654e+09, train_seconds = 2.3602e+04)
[2022-05-31 20:43:48,684][root][INFO] - Step 155619840 @ 6647.9 SPS. Inference batcher size: 106. Learner queue size: 17. Other stats: (step = 155619840, mean_episode_return = 306.36, mean_episode_step = 816.47, total_loss = 108.16, pg_loss = -123.02, baseline_loss = 237.27, entropy_loss = -6.0959, learner_queue_size = 22, _tick = 52062, _time = 1.654e+09, train_seconds = 2.3607e+04)
[2022-05-31 20:43:53,690][root][INFO] - Step 155653120 @ 6648.1 SPS. Inference batcher size: 91. Learner queue size: 19. Other stats: (step = 155653120, mean_episode_return = None, mean_episode_step = 656.78, total_loss = 192.44, pg_loss = 2.4475, baseline_loss = 195.4, entropy_loss = -5.4089, learner_queue_size = 13, _tick = 52072, _time = 1.654e+09, train_seconds = 2.3612e+04)
[2022-05-31 20:43:58,694][root][INFO] - Step 155686400 @ 6650.6 SPS. Inference batcher size: 16. Learner queue size: 1. Other stats: (step = 155686400, mean_episode_return = None, mean_episode_step = 683.03, total_loss = 67.253, pg_loss = 13.877, baseline_loss = 59.551, entropy_loss = -6.1744, learner_queue_size = 25, _tick = 52083, _time = 1.654e+09, train_seconds = 2.3617e+04)
[2022-05-31 20:44:03,698][root][INFO] - Step 155719680 @ 6650.8 SPS. Inference batcher size: 88. Learner queue size: 17. Other stats: (step = 155719680, mean_episode_return = 410.96, mean_episode_step = 854.21, total_loss = 163.04, pg_loss = 73.718, baseline_loss = 95.961, entropy_loss = -6.6368, learner_queue_size = 12, _tick = 52094, _time = 1.654e+09, train_seconds = 2.3622e+04)
[2022-05-31 20:44:08,704][root][INFO] - Step 155750400 @ 6136.6 SPS. Inference batcher size: 163. Learner queue size: 24. Other stats: (step = 155750400, mean_episode_return = 375.78, mean_episode_step = 701.64, total_loss = -19.103, pg_loss = -78.369, baseline_loss = 65.537, entropy_loss = -6.2716, learner_queue_size = 31, _tick = 52105, _time = 1.654e+09, train_seconds = 2.3627e+04)
[2022-05-31 20:44:13,710][root][INFO] - Step 155786240 @ 7159.6 SPS. Inference batcher size: 11. Learner queue size: 21. Other stats: (step = 155786240, mean_episode_return = 267.83, mean_episode_step = 550.32, total_loss = 236.08, pg_loss = 167.52, baseline_loss = 75.066, entropy_loss = -6.5097, learner_queue_size = 11, _tick = 52116, _time = 1.654e+09, train_seconds = 2.3632e+04)
[2022-05-31 20:44:18,714][root][INFO] - Step 155819520 @ 6650.7 SPS. Inference batcher size: 158. Learner queue size: 25. Other stats: (step = 155819520, mean_episode_return = 472.23, mean_episode_step = 795.59, total_loss = -61.705, pg_loss = -108.77, baseline_loss = 53.791, entropy_loss = -6.7213, learner_queue_size = 20, _tick = 52128, _time = 1.654e+09, train_seconds = 2.3637e+04)
[2022-05-31 20:44:23,718][root][INFO] - Step 155850240 @ 6139.0 SPS. Inference batcher size: 124. Learner queue size: 24. Other stats: (step = 155850240, mean_episode_return = 222.28, mean_episode_step = 677.61, total_loss = 174.05, pg_loss = -135.46, baseline_loss = 315.62, entropy_loss = -6.1075, learner_queue_size = 22, _tick = 52138, _time = 1.654e+09, train_seconds = 2.3642e+04)
[2022-05-31 20:44:28,723][root][INFO] - Step 155883520 @ 6649.0 SPS. Inference batcher size: 116. Learner queue size: 20. Other stats: (step = 155883520, mean_episode_return = 277.66, mean_episode_step = 819.84, total_loss = 80.439, pg_loss = -7.776, baseline_loss = 94.393, entropy_loss = -6.1785, learner_queue_size = 18, _tick = 52150, _time = 1.654e+09, train_seconds = 2.3647e+04)
[2022-05-31 20:44:33,729][root][INFO] - Step 155916800 @ 6648.0 SPS. Inference batcher size: 136. Learner queue size: 15. Other stats: (step = 155916800, mean_episode_return = 169.63, mean_episode_step = 673.36, total_loss = -18.46, pg_loss = -33.088, baseline_loss = 21.343, entropy_loss = -6.7149, learner_queue_size = 26, _tick = 52163, _time = 1.654e+09, train_seconds = 2.3652e+04)
[2022-05-31 20:44:38,734][root][INFO] - Step 155950080 @ 6649.7 SPS. Inference batcher size: 129. Learner queue size: 17. Other stats: (step = 155950080, mean_episode_return = None, mean_episode_step = 640.28, total_loss = -52.414, pg_loss = -118.2, baseline_loss = 72.483, entropy_loss = -6.6992, learner_queue_size = 24, _tick = 52174, _time = 1.654e+09, train_seconds = 2.3657e+04)
[2022-05-31 20:44:43,738][root][INFO] - Step 155983360 @ 6650.7 SPS. Inference batcher size: 53. Learner queue size: 19. Other stats: (step = 155983360, mean_episode_return = 69.839, mean_episode_step = 754.76, total_loss = -27.449, pg_loss = -57.181, baseline_loss = 36.226, entropy_loss = -6.4933, learner_queue_size = 21, _tick = 52187, _time = 1.654e+09, train_seconds = 2.3662e+04)
[2022-05-31 20:44:48,742][root][INFO] - Step 156016640 @ 6650.6 SPS. Inference batcher size: 120. Learner queue size: 15. Other stats: (step = 156016640, mean_episode_return = 192.82, mean_episode_step = 643.73, total_loss = 301.05, pg_loss = 178.59, baseline_loss = 128.45, entropy_loss = -5.9913, learner_queue_size = 18, _tick = 52199, _time = 1.654e+09, train_seconds = 2.3667e+04)
[2022-05-31 20:44:53,746][root][INFO] - Step 156049920 @ 6650.8 SPS. Inference batcher size: 125. Learner queue size: 11. Other stats: (step = 156049920, mean_episode_return = 320.65, mean_episode_step = 600.82, total_loss = 293.93, pg_loss = 192.64, baseline_loss = 108.07, entropy_loss = -6.7905, learner_queue_size = 12, _