[2022-06-09 20:07:51,820][root][INFO] - name: null
wandb: false
project: nethack_challenge
entity: user1
group: group1
mock: false
single_ttyrec: true
num_seeds: 0
write_profiler_trace: false
fn_penalty_step: constant
penalty_time: 0.0
penalty_step: -0.01
reward_lose: 0
reward_win: 100
state_counter: none
character: mon-hum-neu-mal
mode: train
env: challenge
num_actors: 256
total_steps: 1000000000.0
batch_size: 32
unroll_length: 80
num_learner_threads: 1
num_inference_threads: 1
disable_cuda: false
learner_device: cuda:2
actor_device: cuda:3
learning_rate: 0.0002
grad_norm_clipping: 40
alpha: 0.99
momentum: 0
epsilon: 1.0e-06
entropy_cost: 0.001
baseline_cost: 0.5
discounting: 0.999
normalize_reward: true
model: baseline
use_lstm: true
hidden_dim: 256
embedding_dim: 64
layers: 5
crop_dim: 9
use_index_select: true
restrict_action_space: true
msg:
  hidden_dim: 64
  embedding_dim: 32
load_dir: null

[2022-06-09 20:07:51,833][root][INFO] - Symlinked log directory: /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/latest
[2022-06-09 20:07:51,836][root][INFO] - Creating archive directory: /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/archives
[2022-06-09 20:07:51,837][root][INFO] - Logging results to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51
[2022-06-09 20:07:51,915][palaas/out][INFO] - Found log directory: /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51
[2022-06-09 20:07:51,916][palaas/out][INFO] - Saving arguments to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/meta.json
[2022-06-09 20:07:51,917][palaas/out][INFO] - Saving messages to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/out.log
[2022-06-09 20:07:51,918][palaas/out][INFO] - Saving logs data to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/logs.csv
[2022-06-09 20:07:51,918][palaas/out][INFO] - Saving logs' fields to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/fields.csv
[2022-06-09 20:07:51,956][root][INFO] - Using CUDA.
[2022-06-09 20:07:51,991][root][INFO] - Using model baseline
[2022-06-09 20:07:51,992][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:07:56,140][root][INFO] - Number of model parameters: 7069810
[2022-06-09 20:07:56,140][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,200][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,201][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,200][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,203][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,203][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,203][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,203][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,203][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,204][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,204][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,204][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,204][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,204][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,204][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,204][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,204][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,205][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,205][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,205][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,205][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,205][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,205][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,205][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,205][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,211][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,212][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,212][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,212][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,213][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,215][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,215][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,215][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,216][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,216][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,216][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,216][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,217][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,219][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,218][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,225][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,226][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,225][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,226][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,226][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,226][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,226][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,226][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,226][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,227][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,227][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,227][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,228][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,227][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,229][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,230][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,232][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,232][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,233][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,233][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,233][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,234][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,238][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,243][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,243][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,244][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,251][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,259][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,260][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,260][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,260][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,260][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,261][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,260][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,261][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,261][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,261][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,261][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,262][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,263][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,263][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,263][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,263][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,263][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,263][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,264][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,265][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,265][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,268][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,268][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,269][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,268][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,269][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,269][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,269][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,269][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,270][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,270][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,270][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,268][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,295][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,312][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,312][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,312][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,320][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,313][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,313][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,320][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,320][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,320][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,321][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,321][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,321][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,321][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,320][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,320][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,313][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,313][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,321][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,322][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,322][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,321][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,313][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,321][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,322][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,322][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,317][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,313][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,326][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,323][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,326][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,322][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,329][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,323][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,323][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,324][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,313][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,330][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,330][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,316][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,330][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,315][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,315][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,315][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,314][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,316][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,316][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,323][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,315][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,331][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,331][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,324][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,323][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,324][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,324][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,324][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,316][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,316][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,316][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,316][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,316][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,335][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,325][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,316][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,316][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,313][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,316][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,325][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,317][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,317][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,317][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,325][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,317][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,317][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,317][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,318][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,325][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,325][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,313][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,326][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,326][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,344][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,326][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,326][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,327][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,318][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,327][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,318][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,318][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,318][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,318][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,318][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,319][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,321][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,318][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,327][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,319][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,327][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,319][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,319][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,319][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,319][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,327][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,327][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,319][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,319][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,319][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,320][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,319][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,319][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,320][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,327][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,319][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,319][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,319][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,320][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,315][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,319][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,322][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,327][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,348][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,327][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,313][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,317][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,314][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,314][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,314][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,328][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,314][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,328][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,328][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,328][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,328][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,328][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,328][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,328][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,328][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,321][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,329][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,329][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,329][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,329][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,325][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,315][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,329][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,329][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,314][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,312][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,329][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,329][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,315][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,315][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,316][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,316][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,344][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,318][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:00,367][nle.env.base][INFO] - Not saving any NLE data.
[2022-06-09 20:08:05,145][palaas/out][INFO] - Updated log fields: ['_tick', '_time', 'step', 'mean_episode_return', 'mean_episode_step', 'total_loss', 'pg_loss', 'baseline_loss', 'entropy_loss', 'learner_queue_size']
[2022-06-09 20:08:05,196][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint_0.tar
[2022-06-09 20:08:05,382][root][INFO] - Step 7680 @ 1535.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 7680, mean_episode_return = -0.055, mean_episode_step = 40.143, total_loss = -5.6171, pg_loss = -0.90506, baseline_loss = 5.3318, entropy_loss = -10.044, learner_queue_size = 32, _tick = 0, _time = 1.6548e+09, train_seconds = 5.0)
[2022-06-09 20:08:06,426][palaas/out][INFO] - Updated log fields: ['_tick', '_time', 'step', 'mean_episode_return', 'mean_episode_step', 'total_loss', 'pg_loss', 'baseline_loss', 'entropy_loss', 'learner_queue_size', 'train_seconds']
[2022-06-09 20:08:10,386][root][INFO] - Step 25600 @ 3452.6 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 25600, mean_episode_return = None, mean_episode_step = 88.0, total_loss = -29.627, pg_loss = -22.274, baseline_loss = 2.0249, entropy_loss = -9.3777, learner_queue_size = 32, _tick = 3, _time = 1.6548e+09, train_seconds = 10.2)
[2022-06-09 20:08:15,390][root][INFO] - Step 43520 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 43520, mean_episode_return = None, mean_episode_step = 162.34, total_loss = -32.827, pg_loss = -25.141, baseline_loss = 1.6746, entropy_loss = -9.3611, learner_queue_size = 32, _tick = 5, _time = 1.6548e+09, train_seconds = 15.2)
[2022-06-09 20:08:20,394][root][INFO] - Step 61440 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 61440, mean_episode_return = None, mean_episode_step = 245.5, total_loss = 2.7233, pg_loss = 11.985, baseline_loss = 1.0844, entropy_loss = -10.346, learner_queue_size = 32, _tick = 5, _time = 1.6548e+09, train_seconds = 20.2)
[2022-06-09 20:08:25,398][root][INFO] - Step 81920 @ 4092.8 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 81920, mean_episode_return = None, mean_episode_step = 332.59, total_loss = -26.213, pg_loss = -16.736, baseline_loss = 0.84123, entropy_loss = -10.318, learner_queue_size = 32, _tick = 5, _time = 1.6548e+09, train_seconds = 25.2)
[2022-06-09 20:08:30,402][root][INFO] - Step 99840 @ 3581.1 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 99840, mean_episode_return = None, mean_episode_step = 380.53, total_loss = -16.799, pg_loss = -6.9262, baseline_loss = 0.74671, entropy_loss = -10.619, learner_queue_size = 32, _tick = 5, _time = 1.6548e+09, train_seconds = 30.2)
[2022-06-09 20:08:35,406][root][INFO] - Step 117760 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 117760, mean_episode_return = None, mean_episode_step = 469.94, total_loss = 32.201, pg_loss = 37.048, baseline_loss = 5.938, entropy_loss = -10.785, learner_queue_size = 32, _tick = 5, _time = 1.6548e+09, train_seconds = 35.2)
[2022-06-09 20:08:40,410][root][INFO] - Step 135680 @ 3581.1 SPS. Inference batcher size: 94. Learner queue size: 32. Other stats: (step = 135680, mean_episode_return = None, mean_episode_step = 535.5, total_loss = 1.4626, pg_loss = 11.664, baseline_loss = 0.58832, entropy_loss = -10.789, learner_queue_size = 32, _tick = 5, _time = 1.6548e+09, train_seconds = 40.2)
[2022-06-09 20:08:45,414][root][INFO] - Step 156160 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 156160, mean_episode_return = None, mean_episode_step = 568.0, total_loss = -14.862, pg_loss = -4.5174, baseline_loss = 0.47385, entropy_loss = -10.819, learner_queue_size = 32, _tick = 6, _time = 1.6548e+09, train_seconds = 45.2)
[2022-06-09 20:08:50,418][root][INFO] - Step 174080 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 174080, mean_episode_return = None, mean_episode_step = 675.31, total_loss = 192.9, pg_loss = 189.19, baseline_loss = 14.548, entropy_loss = -10.829, learner_queue_size = 32, _tick = 6, _time = 1.6548e+09, train_seconds = 50.2)
[2022-06-09 20:08:55,422][root][INFO] - Step 194560 @ 4092.8 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 194560, mean_episode_return = None, mean_episode_step = 766.12, total_loss = -15.699, pg_loss = -5.3449, baseline_loss = 0.47499, entropy_loss = -10.829, learner_queue_size = 32, _tick = 6, _time = 1.6548e+09, train_seconds = 55.2)
[2022-06-09 20:09:00,426][root][INFO] - Step 212480 @ 3581.1 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 212480, mean_episode_return = None, mean_episode_step = 821.94, total_loss = -13.399, pg_loss = -3.0749, baseline_loss = 0.46215, entropy_loss = -10.787, learner_queue_size = 32, _tick = 6, _time = 1.6548e+09, train_seconds = 60.2)
[2022-06-09 20:09:05,430][root][INFO] - Step 232960 @ 4092.7 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 232960, mean_episode_return = None, mean_episode_step = 932.09, total_loss = 7.3199, pg_loss = 17.513, baseline_loss = 0.56393, entropy_loss = -10.757, learner_queue_size = 32, _tick = 6, _time = 1.6548e+09, train_seconds = 65.2)
[2022-06-09 20:09:10,434][root][INFO] - Step 250880 @ 3581.2 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 250880, mean_episode_return = None, mean_episode_step = 982.59, total_loss = -28.035, pg_loss = -17.512, baseline_loss = 0.36159, entropy_loss = -10.884, learner_queue_size = 32, _tick = 6, _time = 1.6548e+09, train_seconds = 70.2)
[2022-06-09 20:09:15,438][root][INFO] - Step 268800 @ 3581.1 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 268800, mean_episode_return = None, mean_episode_step = 983.75, total_loss = -20.47, pg_loss = -10.012, baseline_loss = 0.43707, entropy_loss = -10.895, learner_queue_size = 32, _tick = 6, _time = 1.6548e+09, train_seconds = 75.2)
[2022-06-09 20:09:20,446][root][INFO] - Step 289280 @ 4089.3 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 289280, mean_episode_return = None, mean_episode_step = 1142.8, total_loss = -0.19188, pg_loss = 6.2124, baseline_loss = 4.5779, entropy_loss = -10.982, learner_queue_size = 32, _tick = 6, _time = 1.6548e+09, train_seconds = 80.3)
[2022-06-09 20:09:25,450][root][INFO] - Step 307200 @ 3581.3 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 307200, mean_episode_return = None, mean_episode_step = 1191.0, total_loss = 83.147, pg_loss = 88.081, baseline_loss = 5.8716, entropy_loss = -10.805, learner_queue_size = 32, _tick = 7, _time = 1.6548e+09, train_seconds = 85.3)
[2022-06-09 20:09:30,454][root][INFO] - Step 325120 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 325120, mean_episode_return = None, mean_episode_step = 1231.5, total_loss = 17.866, pg_loss = 26.136, baseline_loss = 2.0199, entropy_loss = -10.289, learner_queue_size = 32, _tick = 7, _time = 1.6548e+09, train_seconds = 90.3)
[2022-06-09 20:09:35,458][root][INFO] - Step 345600 @ 4092.6 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 345600, mean_episode_return = None, mean_episode_step = 1390.2, total_loss = 9.0997, pg_loss = -1.6144, baseline_loss = 20.349, entropy_loss = -9.6344, learner_queue_size = 32, _tick = 10, _time = 1.6548e+09, train_seconds = 95.3)
[2022-06-09 20:09:40,463][root][INFO] - Step 363520 @ 3580.9 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 363520, mean_episode_return = -12.85, mean_episode_step = 1349.5, total_loss = 131.11, pg_loss = 116.98, baseline_loss = 22.853, entropy_loss = -8.7207, learner_queue_size = 32, _tick = 12, _time = 1.6548e+09, train_seconds = 100.3)
[2022-06-09 20:09:45,466][root][INFO] - Step 381440 @ 3581.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 381440, mean_episode_return = None, mean_episode_step = 1435.8, total_loss = 5.4708, pg_loss = 9.1123, baseline_loss = 5.3151, entropy_loss = -8.9567, learner_queue_size = 32, _tick = 13, _time = 1.6548e+09, train_seconds = 105.3)
[2022-06-09 20:09:50,472][root][INFO] - Step 399360 @ 3579.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 399360, mean_episode_return = None, mean_episode_step = 1487.9, total_loss = -59.99, pg_loss = -55.75, baseline_loss = 4.3159, entropy_loss = -8.5562, learner_queue_size = 32, _tick = 15, _time = 1.6548e+09, train_seconds = 110.3)
[2022-06-09 20:09:55,478][root][INFO] - Step 419840 @ 4091.2 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 419840, mean_episode_return = None, mean_episode_step = 1561.5, total_loss = -68.436, pg_loss = -61.5, baseline_loss = 1.8109, entropy_loss = -8.7467, learner_queue_size = 32, _tick = 18, _time = 1.6548e+09, train_seconds = 115.3)
[2022-06-09 20:10:00,482][root][INFO] - Step 437760 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 437760, mean_episode_return = None, mean_episode_step = 1656.7, total_loss = 950.21, pg_loss = 582.71, baseline_loss = 376.42, entropy_loss = -8.9286, learner_queue_size = 32, _tick = 21, _time = 1.6548e+09, train_seconds = 120.3)
[2022-06-09 20:10:05,486][root][INFO] - Step 455680 @ 3581.2 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 455680, mean_episode_return = None, mean_episode_step = 1687.9, total_loss = -16.515, pg_loss = -24.27, baseline_loss = 16.031, entropy_loss = -8.2755, learner_queue_size = 32, _tick = 21, _time = 1.6548e+09, train_seconds = 125.3)
[2022-06-09 20:10:10,490][root][INFO] - Step 476160 @ 4092.7 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 476160, mean_episode_return = 13.01, mean_episode_step = 1560.3, total_loss = 77.115, pg_loss = 43.635, baseline_loss = 40.329, entropy_loss = -6.8484, learner_queue_size = 32, _tick = 23, _time = 1.6548e+09, train_seconds = 130.3)
[2022-06-09 20:10:15,494][root][INFO] - Step 494080 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 494080, mean_episode_return = -12.7, mean_episode_step = 1842.8, total_loss = -30.941, pg_loss = -28.764, baseline_loss = 5.5507, entropy_loss = -7.728, learner_queue_size = 32, _tick = 25, _time = 1.6548e+09, train_seconds = 135.3)
[2022-06-09 20:10:20,498][root][INFO] - Step 512000 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 512000, mean_episode_return = -22.375, mean_episode_step = 1888.1, total_loss = -13.032, pg_loss = -8.7865, baseline_loss = 3.7892, entropy_loss = -8.0348, learner_queue_size = 32, _tick = 27, _time = 1.6548e+09, train_seconds = 140.3)
[2022-06-09 20:10:25,502][root][INFO] - Step 532480 @ 4092.7 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 532480, mean_episode_return = None, mean_episode_step = 1911.9, total_loss = 183.59, pg_loss = 121.54, baseline_loss = 69.896, entropy_loss = -7.8434, learner_queue_size = 32, _tick = 31, _time = 1.6548e+09, train_seconds = 145.3)
[2022-06-09 20:10:30,506][root][INFO] - Step 550400 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 550400, mean_episode_return = -14.97, mean_episode_step = 2015.8, total_loss = 768.09, pg_loss = 376.94, baseline_loss = 399.12, entropy_loss = -7.9642, learner_queue_size = 32, _tick = 33, _time = 1.6548e+09, train_seconds = 150.3)
[2022-06-09 20:10:35,510][root][INFO] - Step 570880 @ 4092.7 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 570880, mean_episode_return = -21.2, mean_episode_step = 2103.1, total_loss = -40.703, pg_loss = -38.817, baseline_loss = 5.3064, entropy_loss = -7.1919, learner_queue_size = 32, _tick = 36, _time = 1.6548e+09, train_seconds = 155.3)
[2022-06-09 20:10:40,514][root][INFO] - Step 588800 @ 3581.0 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 588800, mean_episode_return = None, mean_episode_step = 2172.2, total_loss = 218.41, pg_loss = 129.18, baseline_loss = 96.95, entropy_loss = -7.7126, learner_queue_size = 32, _tick = 38, _time = 1.6548e+09, train_seconds = 160.3)
[2022-06-09 20:10:45,518][root][INFO] - Step 606720 @ 3581.3 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 606720, mean_episode_return = -20.76, mean_episode_step = 2097.9, total_loss = 627.48, pg_loss = 300.54, baseline_loss = 334.56, entropy_loss = -7.6173, learner_queue_size = 32, _tick = 40, _time = 1.6548e+09, train_seconds = 165.3)
[2022-06-09 20:10:50,522][root][INFO] - Step 627200 @ 4092.8 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 627200, mean_episode_return = 2.7699, mean_episode_step = 1928.8, total_loss = -35.411, pg_loss = -35.266, baseline_loss = 7.1639, entropy_loss = -7.3084, learner_queue_size = 32, _tick = 44, _time = 1.6548e+09, train_seconds = 170.3)
[2022-06-09 20:10:55,526][root][INFO] - Step 640000 @ 2557.9 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 640000, mean_episode_return = None, mean_episode_step = 2204.5, total_loss = 155.88, pg_loss = 97.321, baseline_loss = 65.906, entropy_loss = -7.3425, learner_queue_size = 32, _tick = 45, _time = 1.6548e+09, train_seconds = 175.3)
[2022-06-09 20:11:00,530][root][INFO] - Step 660480 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 660480, mean_episode_return = None, mean_episode_step = 2076.4, total_loss = 112.85, pg_loss = 60.973, baseline_loss = 59.646, entropy_loss = -7.7721, learner_queue_size = 32, _tick = 47, _time = 1.6548e+09, train_seconds = 180.3)
[2022-06-09 20:11:05,534][root][INFO] - Step 678400 @ 3581.2 SPS. Inference batcher size: 85. Learner queue size: 32. Other stats: (step = 678400, mean_episode_return = None, mean_episode_step = 2314.9, total_loss = -54.536, pg_loss = -59.056, baseline_loss = 12.255, entropy_loss = -7.7349, learner_queue_size = 32, _tick = 50, _time = 1.6548e+09, train_seconds = 185.3)
[2022-06-09 20:11:10,538][root][INFO] - Step 696320 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 696320, mean_episode_return = -18.83, mean_episode_step = 2197.3, total_loss = -52.832, pg_loss = -48.212, baseline_loss = 3.5659, entropy_loss = -8.1863, learner_queue_size = 32, _tick = 54, _time = 1.6548e+09, train_seconds = 190.3)
[2022-06-09 20:11:15,545][root][INFO] - Step 716800 @ 4090.1 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 716800, mean_episode_return = -23.62, mean_episode_step = 2639.3, total_loss = -57.653, pg_loss = -54.202, baseline_loss = 4.5312, entropy_loss = -7.9826, learner_queue_size = 32, _tick = 57, _time = 1.6548e+09, train_seconds = 195.4)
[2022-06-09 20:11:20,550][root][INFO] - Step 734720 @ 3580.6 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 734720, mean_episode_return = None, mean_episode_step = 2605.9, total_loss = 253.55, pg_loss = 174.82, baseline_loss = 86.729, entropy_loss = -7.9969, learner_queue_size = 32, _tick = 62, _time = 1.6548e+09, train_seconds = 200.4)
[2022-06-09 20:11:25,554][root][INFO] - Step 752640 @ 3581.1 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (step = 752640, mean_episode_return = -20.23, mean_episode_step = 2314.3, total_loss = -13.023, pg_loss = -6.4522, baseline_loss = 1.465, entropy_loss = -8.0362, learner_queue_size = 32, _tick = 65, _time = 1.6548e+09, train_seconds = 205.4)
[2022-06-09 20:11:30,558][root][INFO] - Step 773120 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 773120, mean_episode_return = None, mean_episode_step = 2357.8, total_loss = 574.72, pg_loss = 384.74, baseline_loss = 198.77, entropy_loss = -8.7816, learner_queue_size = 32, _tick = 66, _time = 1.6548e+09, train_seconds = 210.4)
[2022-06-09 20:11:35,562][root][INFO] - Step 791040 @ 3581.2 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (step = 791040, mean_episode_return = -22.751, mean_episode_step = 2362.4, total_loss = 380.96, pg_loss = 285.96, baseline_loss = 103.42, entropy_loss = -8.4132, learner_queue_size = 32, _tick = 67, _time = 1.6548e+09, train_seconds = 215.4)
[2022-06-09 20:11:40,566][root][INFO] - Step 811520 @ 4092.4 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 811520, mean_episode_return = None, mean_episode_step = 2786.9, total_loss = -70.553, pg_loss = -63.499, baseline_loss = 0.82, entropy_loss = -7.874, learner_queue_size = 32, _tick = 69, _time = 1.6548e+09, train_seconds = 220.4)
[2022-06-09 20:11:45,571][root][INFO] - Step 829440 @ 3580.6 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 829440, mean_episode_return = None, mean_episode_step = 2644.3, total_loss = 24.956, pg_loss = 28.993, baseline_loss = 5.1868, entropy_loss = -9.2229, learner_queue_size = 32, _tick = 69, _time = 1.6548e+09, train_seconds = 225.4)
[2022-06-09 20:11:50,579][root][INFO] - Step 849920 @ 4089.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (step = 849920, mean_episode_return = None, mean_episode_step = 2815.2, total_loss = -28.122, pg_loss = -21.824, baseline_loss = 3.0573, entropy_loss = -9.3553, learner_queue_size = 32, _tick = 69, _time = 1.6548e+09, train_seconds = 230.4)
[2022-06-09 20:11:55,583][root][INFO] - Step 867840 @ 3581.5 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 867840, mean_episode_return = None, mean_episode_step = 2938.4, total_loss = -31.435, pg_loss = -23.494, baseline_loss = 1.3535, entropy_loss = -9.2952, learner_queue_size = 32, _tick = 69, _time = 1.6548e+09, train_seconds = 235.4)
[2022-06-09 20:12:00,586][root][INFO] - Step 885760 @ 3581.6 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (step = 885760, mean_episode_return = None, mean_episode_step = 2815.8, total_loss = -36.067, pg_loss = -27.393, baseline_loss = 0.79406, entropy_loss = -9.4676, learner_queue_size = 32, _tick = 71, _time = 1.6548e+09, train_seconds = 240.4)
[2022-06-09 20:12:05,594][root][INFO] - Step 903680 @ 3578.3 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 903680, mean_episode_return = None, mean_episode_step = 2681.5, total_loss = 12.419, pg_loss = 17.376, baseline_loss = 4.348, entropy_loss = -9.3053, learner_queue_size = 32, _tick = 73, _time = 1.6548e+09, train_seconds = 245.4)
[2022-06-09 20:12:10,598][root][INFO] - Step 921600 @ 3581.0 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 921600, mean_episode_return = None, mean_episode_step = 3007.8, total_loss = 3.4792, pg_loss = 7.8236, baseline_loss = 4.7985, entropy_loss = -9.1429, learner_queue_size = 32, _tick = 74, _time = 1.6548e+09, train_seconds = 250.4)
[2022-06-09 20:12:15,602][root][INFO] - Step 939520 @ 3581.2 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 939520, mean_episode_return = None, mean_episode_step = 3122.0, total_loss = 1146.5, pg_loss = 516.96, baseline_loss = 638.15, entropy_loss = -8.6405, learner_queue_size = 32, _tick = 78, _time = 1.6548e+09, train_seconds = 255.4)
[2022-06-09 20:12:20,606][root][INFO] - Step 960000 @ 4092.7 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 960000, mean_episode_return = None, mean_episode_step = 2746.4, total_loss = -97.58, pg_loss = -90.488, baseline_loss = 1.4446, entropy_loss = -8.5364, learner_queue_size = 32, _tick = 80, _time = 1.6548e+09, train_seconds = 260.4)
[2022-06-09 20:12:25,610][root][INFO] - Step 977920 @ 3581.1 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 977920, mean_episode_return = None, mean_episode_step = 2914.2, total_loss = -129.03, pg_loss = -121.04, baseline_loss = 0.90656, entropy_loss = -8.897, learner_queue_size = 32, _tick = 82, _time = 1.6548e+09, train_seconds = 265.4)
[2022-06-09 20:12:30,614][root][INFO] - Step 995840 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 995840, mean_episode_return = -20.431, mean_episode_step = 3079.7, total_loss = 35.91, pg_loss = 33.318, baseline_loss = 11.225, entropy_loss = -8.633, learner_queue_size = 32, _tick = 83, _time = 1.6548e+09, train_seconds = 270.4)
[2022-06-09 20:12:35,618][root][INFO] - Step 1013760 @ 3581.2 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 1013760, mean_episode_return = None, mean_episode_step = 3338.7, total_loss = 252.03, pg_loss = 168.83, baseline_loss = 91.342, entropy_loss = -8.1507, learner_queue_size = 32, _tick = 84, _time = 1.6548e+09, train_seconds = 275.4)
[2022-06-09 20:12:40,622][root][INFO] - Step 1031680 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 1031680, mean_episode_return = None, mean_episode_step = 3327.9, total_loss = 74.242, pg_loss = 51.797, baseline_loss = 30.632, entropy_loss = -8.186, learner_queue_size = 32, _tick = 86, _time = 1.6548e+09, train_seconds = 280.4)
[2022-06-09 20:12:45,627][root][INFO] - Step 1052160 @ 4092.3 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 1052160, mean_episode_return = None, mean_episode_step = 3406.1, total_loss = -8.6494, pg_loss = -6.7855, baseline_loss = 6.0809, entropy_loss = -7.9448, learner_queue_size = 32, _tick = 86, _time = 1.6548e+09, train_seconds = 285.4)
[2022-06-09 20:12:50,630][root][INFO] - Step 1070080 @ 3581.5 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 1070080, mean_episode_return = 5.7799, mean_episode_step = 3431.2, total_loss = 270.77, pg_loss = 185.95, baseline_loss = 92.83, entropy_loss = -8.0094, learner_queue_size = 32, _tick = 90, _time = 1.6548e+09, train_seconds = 290.4)
[2022-06-09 20:12:55,634][root][INFO] - Step 1088000 @ 3581.0 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 1088000, mean_episode_return = None, mean_episode_step = 3491.1, total_loss = 29.624, pg_loss = 17.091, baseline_loss = 20.667, entropy_loss = -8.135, learner_queue_size = 32, _tick = 92, _time = 1.6548e+09, train_seconds = 295.4)
[2022-06-09 20:13:00,638][root][INFO] - Step 1108480 @ 4092.9 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 1108480, mean_episode_return = None, mean_episode_step = 3450.3, total_loss = 1079.2, pg_loss = 519.33, baseline_loss = 567.78, entropy_loss = -7.9583, learner_queue_size = 32, _tick = 95, _time = 1.6548e+09, train_seconds = 300.4)
[2022-06-09 20:13:05,642][root][INFO] - Step 1126400 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 1126400, mean_episode_return = None, mean_episode_step = 3404.0, total_loss = -30.301, pg_loss = -26.174, baseline_loss = 3.0329, entropy_loss = -7.1598, learner_queue_size = 32, _tick = 98, _time = 1.6548e+09, train_seconds = 305.4)
[2022-06-09 20:13:10,646][root][INFO] - Step 1144320 @ 3581.0 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 1144320, mean_episode_return = None, mean_episode_step = 3625.0, total_loss = -70.53, pg_loss = -63.533, baseline_loss = 1.1332, entropy_loss = -8.1303, learner_queue_size = 32, _tick = 99, _time = 1.6548e+09, train_seconds = 310.5)
[2022-06-09 20:13:15,650][root][INFO] - Step 1164800 @ 4092.8 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 1164800, mean_episode_return = None, mean_episode_step = 3871.0, total_loss = -36.827, pg_loss = -35.64, baseline_loss = 6.8495, entropy_loss = -8.036, learner_queue_size = 32, _tick = 100, _time = 1.6548e+09, train_seconds = 315.5)
[2022-06-09 20:13:20,654][root][INFO] - Step 1182720 @ 3581.1 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 1182720, mean_episode_return = -6.1802, mean_episode_step = 3091.9, total_loss = 127.07, pg_loss = 70.716, baseline_loss = 64.396, entropy_loss = -8.0434, learner_queue_size = 32, _tick = 102, _time = 1.6548e+09, train_seconds = 320.5)
[2022-06-09 20:13:25,658][root][INFO] - Step 1200640 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 1200640, mean_episode_return = None, mean_episode_step = 3690.2, total_loss = 17.516, pg_loss = 16.647, baseline_loss = 8.9844, entropy_loss = -8.1158, learner_queue_size = 32, _tick = 102, _time = 1.6548e+09, train_seconds = 325.5)
[2022-06-09 20:13:30,662][root][INFO] - Step 1221120 @ 4092.7 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 1221120, mean_episode_return = -23.241, mean_episode_step = 3764.3, total_loss = 313.55, pg_loss = 209.91, baseline_loss = 111.94, entropy_loss = -8.2984, learner_queue_size = 32, _tick = 107, _time = 1.6548e+09, train_seconds = 330.5)
[2022-06-09 20:13:35,667][root][INFO] - Step 1239040 @ 3580.5 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 1239040, mean_episode_return = None, mean_episode_step = 3778.8, total_loss = -55.561, pg_loss = -53.431, baseline_loss = 6.2495, entropy_loss = -8.3788, learner_queue_size = 32, _tick = 109, _time = 1.6548e+09, train_seconds = 335.5)
[2022-06-09 20:13:40,670][root][INFO] - Step 1256960 @ 3581.8 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 1256960, mean_episode_return = -21.941, mean_episode_step = 3552.8, total_loss = -46.899, pg_loss = -41.619, baseline_loss = 2.9824, entropy_loss = -8.2627, learner_queue_size = 32, _tick = 111, _time = 1.6548e+09, train_seconds = 340.5)
[2022-06-09 20:13:45,674][root][INFO] - Step 1277440 @ 4092.7 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 1277440, mean_episode_return = None, mean_episode_step = 3833.9, total_loss = 68.258, pg_loss = 39.56, baseline_loss = 37.068, entropy_loss = -8.3691, learner_queue_size = 32, _tick = 114, _time = 1.6548e+09, train_seconds = 345.5)
[2022-06-09 20:13:50,682][root][INFO] - Step 1295360 @ 3578.3 SPS. Inference batcher size: 76. Learner queue size: 32. Other stats: (step = 1295360, mean_episode_return = -24.711, mean_episode_step = 3584.2, total_loss = 262.8, pg_loss = 211.52, baseline_loss = 59.359, entropy_loss = -8.0796, learner_queue_size = 32, _tick = 118, _time = 1.6548e+09, train_seconds = 350.5)
[2022-06-09 20:13:55,686][root][INFO] - Step 1313280 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 1313280, mean_episode_return = 16.916, mean_episode_step = 3681.8, total_loss = 1077.2, pg_loss = 843.08, baseline_loss = 242.41, entropy_loss = -8.2866, learner_queue_size = 32, _tick = 122, _time = 1.6548e+09, train_seconds = 355.5)
[2022-06-09 20:14:00,690][root][INFO] - Step 1333760 @ 4092.7 SPS. Inference batcher size: 81. Learner queue size: 32. Other stats: (step = 1333760, mean_episode_return = -21.597, mean_episode_step = 3261.4, total_loss = 723.75, pg_loss = 565.96, baseline_loss = 166.34, entropy_loss = -8.5552, learner_queue_size = 32, _tick = 128, _time = 1.6548e+09, train_seconds = 360.5)
[2022-06-09 20:14:05,696][root][INFO] - Step 1351680 @ 3579.9 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 1351680, mean_episode_return = None, mean_episode_step = 3400.8, total_loss = 32.782, pg_loss = 23.651, baseline_loss = 17.277, entropy_loss = -8.1461, learner_queue_size = 32, _tick = 131, _time = 1.6548e+09, train_seconds = 365.5)
[2022-06-09 20:14:10,702][root][INFO] - Step 1369600 @ 3579.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 1369600, mean_episode_return = None, mean_episode_step = 4061.2, total_loss = -51.514, pg_loss = -46.722, baseline_loss = 3.0034, entropy_loss = -7.7961, learner_queue_size = 32, _tick = 133, _time = 1.6548e+09, train_seconds = 370.5)
[2022-06-09 20:14:15,706][root][INFO] - Step 1390080 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 1390080, mean_episode_return = None, mean_episode_step = 3364.7, total_loss = 24.411, pg_loss = 25.558, baseline_loss = 6.4249, entropy_loss = -7.572, learner_queue_size = 32, _tick = 138, _time = 1.6548e+09, train_seconds = 375.5)
[2022-06-09 20:14:20,710][root][INFO] - Step 1408000 @ 3581.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 1408000, mean_episode_return = -22.331, mean_episode_step = 4376.8, total_loss = 227.68, pg_loss = 156.23, baseline_loss = 79.176, entropy_loss = -7.7347, learner_queue_size = 32, _tick = 143, _time = 1.6548e+09, train_seconds = 380.5)
[2022-06-09 20:14:25,714][root][INFO] - Step 1428480 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 1428480, mean_episode_return = None, mean_episode_step = 3763.9, total_loss = 162.81, pg_loss = 93.807, baseline_loss = 76.386, entropy_loss = -7.3843, learner_queue_size = 32, _tick = 150, _time = 1.6548e+09, train_seconds = 385.5)
[2022-06-09 20:14:30,718][root][INFO] - Step 1446400 @ 3581.2 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 1446400, mean_episode_return = None, mean_episode_step = 3640.1, total_loss = -53.344, pg_loss = -61.598, baseline_loss = 15.544, entropy_loss = -7.2898, learner_queue_size = 32, _tick = 152, _time = 1.6548e+09, train_seconds = 390.5)
[2022-06-09 20:14:35,722][root][INFO] - Step 1464320 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 1464320, mean_episode_return = -1.47, mean_episode_step = 2703.4, total_loss = -17.123, pg_loss = -23.603, baseline_loss = 14.032, entropy_loss = -7.5522, learner_queue_size = 32, _tick = 159, _time = 1.6548e+09, train_seconds = 395.5)
[2022-06-09 20:14:40,726][root][INFO] - Step 1482240 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 1482240, mean_episode_return = -9.1263, mean_episode_step = 2622.2, total_loss = -40.206, pg_loss = -37.463, baseline_loss = 4.5828, entropy_loss = -7.3255, learner_queue_size = 32, _tick = 164, _time = 1.6548e+09, train_seconds = 400.5)
[2022-06-09 20:14:45,730][root][INFO] - Step 1502720 @ 4092.7 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 1502720, mean_episode_return = -20.249, mean_episode_step = 2736.5, total_loss = 41.312, pg_loss = 26.95, baseline_loss = 21.24, entropy_loss = -6.8774, learner_queue_size = 32, _tick = 171, _time = 1.6548e+09, train_seconds = 405.5)
[2022-06-09 20:14:50,734][root][INFO] - Step 1520640 @ 3580.9 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 1520640, mean_episode_return = -33.88, mean_episode_step = 2413.7, total_loss = 256.65, pg_loss = 163.23, baseline_loss = 100.9, entropy_loss = -7.4806, learner_queue_size = 32, _tick = 175, _time = 1.6548e+09, train_seconds = 410.5)
[2022-06-09 20:14:55,738][root][INFO] - Step 1538560 @ 3581.3 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 1538560, mean_episode_return = None, mean_episode_step = 2614.3, total_loss = 230.82, pg_loss = 148.78, baseline_loss = 89.317, entropy_loss = -7.2715, learner_queue_size = 32, _tick = 178, _time = 1.6548e+09, train_seconds = 415.5)
[2022-06-09 20:15:00,742][root][INFO] - Step 1559040 @ 4092.7 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 1559040, mean_episode_return = None, mean_episode_step = 2787.2, total_loss = -18.671, pg_loss = -20.356, baseline_loss = 8.835, entropy_loss = -7.1498, learner_queue_size = 32, _tick = 184, _time = 1.6548e+09, train_seconds = 420.5)
[2022-06-09 20:15:05,746][root][INFO] - Step 1576960 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 1576960, mean_episode_return = None, mean_episode_step = 3192.7, total_loss = -113.57, pg_loss = -107.2, baseline_loss = 0.93773, entropy_loss = -7.311, learner_queue_size = 32, _tick = 188, _time = 1.6548e+09, train_seconds = 425.6)
[2022-06-09 20:15:10,750][root][INFO] - Step 1594880 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 1594880, mean_episode_return = -22.48, mean_episode_step = 2895.4, total_loss = 307.39, pg_loss = 231.72, baseline_loss = 83.003, entropy_loss = -7.3379, learner_queue_size = 32, _tick = 192, _time = 1.6548e+09, train_seconds = 430.6)
[2022-06-09 20:15:15,754][root][INFO] - Step 1615360 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 1615360, mean_episode_return = -23.818, mean_episode_step = 2441.8, total_loss = -73.093, pg_loss = -73.982, baseline_loss = 8.3634, entropy_loss = -7.4752, learner_queue_size = 32, _tick = 197, _time = 1.6548e+09, train_seconds = 435.6)
[2022-06-09 20:15:20,758][root][INFO] - Step 1633280 @ 3581.2 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 1633280, mean_episode_return = None, mean_episode_step = 2696.4, total_loss = 2795.2, pg_loss = 953.71, baseline_loss = 1848.5, entropy_loss = -7.0725, learner_queue_size = 32, _tick = 202, _time = 1.6548e+09, train_seconds = 440.6)
[2022-06-09 20:15:25,762][root][INFO] - Step 1651200 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 1651200, mean_episode_return = -19.951, mean_episode_step = 1687.9, total_loss = 417.44, pg_loss = 154.37, baseline_loss = 269.93, entropy_loss = -6.8657, learner_queue_size = 32, _tick = 208, _time = 1.6548e+09, train_seconds = 445.6)
[2022-06-09 20:15:30,766][root][INFO] - Step 1671680 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 1671680, mean_episode_return = -12.394, mean_episode_step = 1616.5, total_loss = -162.72, pg_loss = -163.39, baseline_loss = 7.7803, entropy_loss = -7.114, learner_queue_size = 32, _tick = 214, _time = 1.6548e+09, train_seconds = 450.6)
[2022-06-09 20:15:35,770][root][INFO] - Step 1689600 @ 3581.0 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 1689600, mean_episode_return = 121.04, mean_episode_step = 2029.1, total_loss = -58.404, pg_loss = -70.321, baseline_loss = 18.969, entropy_loss = -7.0526, learner_queue_size = 32, _tick = 220, _time = 1.6548e+09, train_seconds = 455.6)
[2022-06-09 20:15:40,774][root][INFO] - Step 1707520 @ 3581.2 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (step = 1707520, mean_episode_return = 63.91, mean_episode_step = 2192.7, total_loss = -17.607, pg_loss = -24.565, baseline_loss = 13.245, entropy_loss = -6.2877, learner_queue_size = 32, _tick = 225, _time = 1.6548e+09, train_seconds = 460.6)
[2022-06-09 20:15:45,778][root][INFO] - Step 1725440 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 1725440, mean_episode_return = -15.71, mean_episode_step = 1687.4, total_loss = 79.455, pg_loss = 57.05, baseline_loss = 29.913, entropy_loss = -7.508, learner_queue_size = 32, _tick = 230, _time = 1.6548e+09, train_seconds = 465.6)
[2022-06-09 20:15:50,782][root][INFO] - Step 1745920 @ 4092.8 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 1745920, mean_episode_return = None, mean_episode_step = 1870.3, total_loss = 396.41, pg_loss = 294.84, baseline_loss = 108.36, entropy_loss = -6.7908, learner_queue_size = 32, _tick = 233, _time = 1.6548e+09, train_seconds = 470.6)
[2022-06-09 20:15:55,786][root][INFO] - Step 1763840 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 1763840, mean_episode_return = None, mean_episode_step = 1802.1, total_loss = -16.14, pg_loss = -15.21, baseline_loss = 5.7817, entropy_loss = -6.7117, learner_queue_size = 32, _tick = 235, _time = 1.6548e+09, train_seconds = 475.6)
[2022-06-09 20:16:00,790][root][INFO] - Step 1781760 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 1781760, mean_episode_return = -3.92, mean_episode_step = 2200.6, total_loss = -21.87, pg_loss = -24.334, baseline_loss = 9.4112, entropy_loss = -6.9479, learner_queue_size = 32, _tick = 238, _time = 1.6548e+09, train_seconds = 480.6)
[2022-06-09 20:16:05,794][root][INFO] - Step 1799680 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 1799680, mean_episode_return = 11.74, mean_episode_step = 2229.9, total_loss = 102.87, pg_loss = 86.217, baseline_loss = 23.747, entropy_loss = -7.0989, learner_queue_size = 32, _tick = 242, _time = 1.6548e+09, train_seconds = 485.6)
[2022-06-09 20:16:10,798][root][INFO] - Step 1820160 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 1820160, mean_episode_return = None, mean_episode_step = 2115.1, total_loss = 78.478, pg_loss = 54.431, baseline_loss = 31.716, entropy_loss = -7.6696, learner_queue_size = 32, _tick = 246, _time = 1.6548e+09, train_seconds = 490.6)
[2022-06-09 20:16:15,802][root][INFO] - Step 1838080 @ 3581.0 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 1838080, mean_episode_return = None, mean_episode_step = 2407.6, total_loss = 28.828, pg_loss = 23.581, baseline_loss = 12.984, entropy_loss = -7.7366, learner_queue_size = 32, _tick = 251, _time = 1.6548e+09, train_seconds = 495.6)
[2022-06-09 20:16:20,806][root][INFO] - Step 1858560 @ 4093.0 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 1858560, mean_episode_return = None, mean_episode_step = 1473.6, total_loss = -95.858, pg_loss = -92.339, baseline_loss = 4.1484, entropy_loss = -7.6671, learner_queue_size = 32, _tick = 257, _time = 1.6548e+09, train_seconds = 500.6)
[2022-06-09 20:16:25,810][root][INFO] - Step 1876480 @ 3581.0 SPS. Inference batcher size: 91. Learner queue size: 32. Other stats: (step = 1876480, mean_episode_return = None, mean_episode_step = 2383.5, total_loss = 89.11, pg_loss = 55.646, baseline_loss = 41.023, entropy_loss = -7.56, learner_queue_size = 32, _tick = 262, _time = 1.6548e+09, train_seconds = 505.6)
[2022-06-09 20:16:30,814][root][INFO] - Step 1896960 @ 4092.8 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 1896960, mean_episode_return = None, mean_episode_step = 1758.2, total_loss = 538.59, pg_loss = 403.39, baseline_loss = 142.89, entropy_loss = -7.6913, learner_queue_size = 32, _tick = 268, _time = 1.6548e+09, train_seconds = 510.6)
[2022-06-09 20:16:35,818][root][INFO] - Step 1914880 @ 3581.2 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 1914880, mean_episode_return = 17.13, mean_episode_step = 1513.2, total_loss = 354.63, pg_loss = 266.87, baseline_loss = 95.47, entropy_loss = -7.7052, learner_queue_size = 32, _tick = 274, _time = 1.6548e+09, train_seconds = 515.6)
[2022-06-09 20:16:40,822][root][INFO] - Step 1932800 @ 3581.1 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 1932800, mean_episode_return = -2.3802, mean_episode_step = 1431.7, total_loss = 69.057, pg_loss = 12.692, baseline_loss = 63.83, entropy_loss = -7.4655, learner_queue_size = 32, _tick = 278, _time = 1.6548e+09, train_seconds = 520.6)
[2022-06-09 20:16:45,826][root][INFO] - Step 1953280 @ 4092.7 SPS. Inference batcher size: 77. Learner queue size: 32. Other stats: (step = 1953280, mean_episode_return = None, mean_episode_step = 1532.7, total_loss = 44.285, pg_loss = 37.877, baseline_loss = 13.868, entropy_loss = -7.4589, learner_queue_size = 32, _tick = 283, _time = 1.6548e+09, train_seconds = 525.6)
[2022-06-09 20:16:50,830][root][INFO] - Step 1971200 @ 3581.2 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 1971200, mean_episode_return = 7.5254, mean_episode_step = 1811.5, total_loss = -67.872, pg_loss = -70.542, baseline_loss = 9.8091, entropy_loss = -7.1383, learner_queue_size = 32, _tick = 287, _time = 1.6548e+09, train_seconds = 530.6)
[2022-06-09 20:16:55,834][root][INFO] - Step 1989120 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 1989120, mean_episode_return = 2.5897, mean_episode_step = 2274.1, total_loss = -38.998, pg_loss = -33.389, baseline_loss = 2.2623, entropy_loss = -7.8704, learner_queue_size = 32, _tick = 289, _time = 1.6548e+09, train_seconds = 535.6)
[2022-06-09 20:17:00,838][root][INFO] - Step 2009600 @ 4092.6 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 2009600, mean_episode_return = 59.171, mean_episode_step = 1872.6, total_loss = 22.131, pg_loss = -7.8413, baseline_loss = 37.81, entropy_loss = -7.8375, learner_queue_size = 32, _tick = 295, _time = 1.6548e+09, train_seconds = 540.6)
[2022-06-09 20:17:05,842][root][INFO] - Step 2027520 @ 3581.2 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 2027520, mean_episode_return = -36.249, mean_episode_step = 2475.8, total_loss = 190.32, pg_loss = 99.599, baseline_loss = 98.448, entropy_loss = -7.7221, learner_queue_size = 32, _tick = 301, _time = 1.6548e+09, train_seconds = 545.6)
[2022-06-09 20:17:10,846][root][INFO] - Step 2045440 @ 3581.0 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 2045440, mean_episode_return = None, mean_episode_step = 1742.5, total_loss = 488.31, pg_loss = 335.07, baseline_loss = 161.03, entropy_loss = -7.7806, learner_queue_size = 32, _tick = 304, _time = 1.6548e+09, train_seconds = 550.7)
[2022-06-09 20:17:15,850][root][INFO] - Step 2065920 @ 4092.9 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 2065920, mean_episode_return = None, mean_episode_step = 1866.2, total_loss = -101.52, pg_loss = -99.452, baseline_loss = 5.4707, entropy_loss = -7.5406, learner_queue_size = 32, _tick = 308, _time = 1.6548e+09, train_seconds = 555.7)
[2022-06-09 20:17:20,854][root][INFO] - Step 2083840 @ 3581.1 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 2083840, mean_episode_return = 25.99, mean_episode_step = 2064.9, total_loss = 604.88, pg_loss = 448.97, baseline_loss = 163.62, entropy_loss = -7.7082, learner_queue_size = 32, _tick = 311, _time = 1.6548e+09, train_seconds = 560.7)
[2022-06-09 20:17:25,860][root][INFO] - Step 2101760 @ 3579.4 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 2101760, mean_episode_return = None, mean_episode_step = 1856.9, total_loss = 81.955, pg_loss = 51.048, baseline_loss = 38.536, entropy_loss = -7.6298, learner_queue_size = 32, _tick = 314, _time = 1.6548e+09, train_seconds = 565.7)
[2022-06-09 20:17:30,866][root][INFO] - Step 2122240 @ 4091.4 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 2122240, mean_episode_return = None, mean_episode_step = 1798.6, total_loss = 622.2, pg_loss = 424.12, baseline_loss = 205.84, entropy_loss = -7.7635, learner_queue_size = 32, _tick = 317, _time = 1.6548e+09, train_seconds = 570.7)
[2022-06-09 20:17:35,870][root][INFO] - Step 2140160 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 2140160, mean_episode_return = None, mean_episode_step = 2193.2, total_loss = 248.16, pg_loss = 160.15, baseline_loss = 95.404, entropy_loss = -7.3951, learner_queue_size = 32, _tick = 319, _time = 1.6548e+09, train_seconds = 575.7)
[2022-06-09 20:17:40,875][root][INFO] - Step 2158080 @ 3580.4 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 2158080, mean_episode_return = None, mean_episode_step = 1989.0, total_loss = 421.49, pg_loss = 270.45, baseline_loss = 157.84, entropy_loss = -6.8007, learner_queue_size = 32, _tick = 323, _time = 1.6548e+09, train_seconds = 580.7)
[2022-06-09 20:17:45,878][root][INFO] - Step 2178560 @ 4093.6 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 2178560, mean_episode_return = 7.8195, mean_episode_step = 2001.4, total_loss = 74.354, pg_loss = 42.594, baseline_loss = 35.304, entropy_loss = -3.5444, learner_queue_size = 32, _tick = 328, _time = 1.6548e+09, train_seconds = 585.7)
[2022-06-09 20:17:50,882][root][INFO] - Step 2196480 @ 3581.1 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 2196480, mean_episode_return = None, mean_episode_step = 1554.6, total_loss = 5.7563, pg_loss = 11.873, baseline_loss = 1.5289, entropy_loss = -7.6457, learner_queue_size = 32, _tick = 328, _time = 1.6548e+09, train_seconds = 590.7)
[2022-06-09 20:17:55,886][root][INFO] - Step 2216960 @ 4092.7 SPS. Inference batcher size: 82. Learner queue size: 32. Other stats: (step = 2216960, mean_episode_return = None, mean_episode_step = 1957.5, total_loss = -60.936, pg_loss = -52.322, baseline_loss = 1.7703, entropy_loss = -10.384, learner_queue_size = 32, _tick = 329, _time = 1.6548e+09, train_seconds = 595.7)
[2022-06-09 20:18:00,890][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-09 20:18:00,975][root][INFO] - Step 2234880 @ 3581.2 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (step = 2234880, mean_episode_return = 0.30985, mean_episode_step = 2055.8, total_loss = -5.4112, pg_loss = 1.8645, baseline_loss = 3.4123, entropy_loss = -10.688, learner_queue_size = 32, _tick = 330, _time = 1.6548e+09, train_seconds = 600.7)
[2022-06-09 20:18:05,978][root][INFO] - Step 2255360 @ 4025.0 SPS. Inference batcher size: 78. Learner queue size: 32. Other stats: (step = 2255360, mean_episode_return = 23.006, mean_episode_step = 2142.8, total_loss = 72.558, pg_loss = 75.058, baseline_loss = 5.7022, entropy_loss = -8.2019, learner_queue_size = 32, _tick = 334, _time = 1.6548e+09, train_seconds = 605.8)
[2022-06-09 20:18:10,982][root][INFO] - Step 2273280 @ 3581.3 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 2273280, mean_episode_return = -0.88033, mean_episode_step = 2305.8, total_loss = -9.0611, pg_loss = -5.8018, baseline_loss = 4.5747, entropy_loss = -7.834, learner_queue_size = 32, _tick = 338, _time = 1.6548e+09, train_seconds = 610.8)
[2022-06-09 20:18:15,986][root][INFO] - Step 2291200 @ 3581.1 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 2291200, mean_episode_return = None, mean_episode_step = 2303.1, total_loss = 128.37, pg_loss = 94.562, baseline_loss = 41.65, entropy_loss = -7.8369, learner_queue_size = 32, _tick = 343, _time = 1.6548e+09, train_seconds = 615.8)
[2022-06-09 20:18:20,990][root][INFO] - Step 2309120 @ 3581.1 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 2309120, mean_episode_return = 8.2596, mean_episode_step = 1983.7, total_loss = -3.1266, pg_loss = -4.4938, baseline_loss = 8.6719, entropy_loss = -7.3047, learner_queue_size = 32, _tick = 349, _time = 1.6548e+09, train_seconds = 620.8)
[2022-06-09 20:18:25,994][root][INFO] - Step 2329600 @ 4092.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 2329600, mean_episode_return = None, mean_episode_step = 2009.3, total_loss = 44.548, pg_loss = 24.856, baseline_loss = 25.983, entropy_loss = -6.2908, learner_queue_size = 32, _tick = 351, _time = 1.6548e+09, train_seconds = 625.8)
[2022-06-09 20:18:30,998][root][INFO] - Step 2347520 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 2347520, mean_episode_return = 44.03, mean_episode_step = 2257.9, total_loss = -32.62, pg_loss = -43.47, baseline_loss = 17.312, entropy_loss = -6.4614, learner_queue_size = 32, _tick = 357, _time = 1.6548e+09, train_seconds = 630.8)
[2022-06-09 20:18:36,002][root][INFO] - Step 2365440 @ 3581.1 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 2365440, mean_episode_return = None, mean_episode_step = 2292.7, total_loss = 1.4887, pg_loss = -18.353, baseline_loss = 25.958, entropy_loss = -6.1163, learner_queue_size = 32, _tick = 359, _time = 1.6548e+09, train_seconds = 635.8)
[2022-06-09 20:18:41,007][root][INFO] - Step 2385920 @ 4092.2 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 2385920, mean_episode_return = None, mean_episode_step = 2342.1, total_loss = 467.35, pg_loss = 265.93, baseline_loss = 207.83, entropy_loss = -6.4084, learner_queue_size = 32, _tick = 362, _time = 1.6548e+09, train_seconds = 640.8)
[2022-06-09 20:18:46,010][root][INFO] - Step 2403840 @ 3581.6 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 2403840, mean_episode_return = None, mean_episode_step = 2744.8, total_loss = 492.24, pg_loss = 324.35, baseline_loss = 173.65, entropy_loss = -5.7585, learner_queue_size = 32, _tick = 364, _time = 1.6548e+09, train_seconds = 645.8)
[2022-06-09 20:18:51,016][root][INFO] - Step 2421760 @ 3579.4 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 2421760, mean_episode_return = None, mean_episode_step = 2479.6, total_loss = 179.46, pg_loss = 71.016, baseline_loss = 112.97, entropy_loss = -4.5191, learner_queue_size = 32, _tick = 366, _time = 1.6548e+09, train_seconds = 650.8)
[2022-06-09 20:18:56,022][root][INFO] - Step 2442240 @ 4091.4 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 2442240, mean_episode_return = None, mean_episode_step = 2614.6, total_loss = -25.49, pg_loss = -23.267, baseline_loss = 3.9262, entropy_loss = -6.1491, learner_queue_size = 32, _tick = 368, _time = 1.6548e+09, train_seconds = 655.8)
[2022-06-09 20:19:01,026][root][INFO] - Step 2460160 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 2460160, mean_episode_return = None, mean_episode_step = 2773.6, total_loss = -24.532, pg_loss = -16.756, baseline_loss = 1.92, entropy_loss = -9.6965, learner_queue_size = 32, _tick = 370, _time = 1.6548e+09, train_seconds = 660.8)
[2022-06-09 20:19:06,030][root][INFO] - Step 2480640 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 2480640, mean_episode_return = None, mean_episode_step = 2343.2, total_loss = -19.915, pg_loss = -12.406, baseline_loss = 2.9389, entropy_loss = -10.447, learner_queue_size = 32, _tick = 371, _time = 1.6548e+09, train_seconds = 665.8)
[2022-06-09 20:19:11,034][root][INFO] - Step 2498560 @ 3581.2 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 2498560, mean_episode_return = None, mean_episode_step = 1988.8, total_loss = -4.4723, pg_loss = 3.2522, baseline_loss = 2.435, entropy_loss = -10.16, learner_queue_size = 32, _tick = 371, _time = 1.6548e+09, train_seconds = 670.8)
[2022-06-09 20:19:16,038][root][INFO] - Step 2519040 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 2519040, mean_episode_return = None, mean_episode_step = 2744.8, total_loss = 3.4322, pg_loss = 12.044, baseline_loss = 1.7576, entropy_loss = -10.37, learner_queue_size = 32, _tick = 371, _time = 1.6548e+09, train_seconds = 675.8)
[2022-06-09 20:19:21,042][root][INFO] - Step 2536960 @ 3581.2 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 2536960, mean_episode_return = None, mean_episode_step = 2305.8, total_loss = -20.427, pg_loss = -11.14, baseline_loss = 1.3309, entropy_loss = -10.617, learner_queue_size = 32, _tick = 371, _time = 1.6548e+09, train_seconds = 680.8)
[2022-06-09 20:19:26,046][root][INFO] - Step 2554880 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 2554880, mean_episode_return = None, mean_episode_step = 2770.5, total_loss = -35.766, pg_loss = -26.258, baseline_loss = 1.2064, entropy_loss = -10.715, learner_queue_size = 32, _tick = 372, _time = 1.6548e+09, train_seconds = 685.9)
[2022-06-09 20:19:31,050][root][INFO] - Step 2575360 @ 4092.6 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 2575360, mean_episode_return = None, mean_episode_step = 2644.6, total_loss = -36.448, pg_loss = -26.624, baseline_loss = 1.0786, entropy_loss = -10.902, learner_queue_size = 32, _tick = 372, _time = 1.6548e+09, train_seconds = 690.9)
[2022-06-09 20:19:36,054][root][INFO] - Step 2593280 @ 3581.2 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 2593280, mean_episode_return = None, mean_episode_step = 2472.6, total_loss = -19.467, pg_loss = -9.5808, baseline_loss = 1.0051, entropy_loss = -10.891, learner_queue_size = 32, _tick = 372, _time = 1.6548e+09, train_seconds = 695.9)
[2022-06-09 20:19:41,059][root][INFO] - Step 2613760 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 2613760, mean_episode_return = None, mean_episode_step = 2764.8, total_loss = -4.6355, pg_loss = 5.477, baseline_loss = 0.81929, entropy_loss = -10.932, learner_queue_size = 32, _tick = 372, _time = 1.6548e+09, train_seconds = 700.9)
[2022-06-09 20:19:46,062][root][INFO] - Step 2631680 @ 3581.1 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 2631680, mean_episode_return = None, mean_episode_step = 3075.9, total_loss = -12.035, pg_loss = -1.8699, baseline_loss = 0.76241, entropy_loss = -10.927, learner_queue_size = 32, _tick = 372, _time = 1.6548e+09, train_seconds = 705.9)
[2022-06-09 20:19:51,066][root][INFO] - Step 2652160 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 2652160, mean_episode_return = None, mean_episode_step = 2735.7, total_loss = 954.26, pg_loss = 651.02, baseline_loss = 314.2, entropy_loss = -10.961, learner_queue_size = 32, _tick = 373, _time = 1.6548e+09, train_seconds = 710.9)
[2022-06-09 20:19:56,070][root][INFO] - Step 2670080 @ 3581.1 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 2670080, mean_episode_return = None, mean_episode_step = 3020.7, total_loss = -28.576, pg_loss = -18.21, baseline_loss = 0.56849, entropy_loss = -10.934, learner_queue_size = 32, _tick = 373, _time = 1.6548e+09, train_seconds = 715.9)
[2022-06-09 20:20:01,074][root][INFO] - Step 2688000 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 2688000, mean_episode_return = None, mean_episode_step = 2748.5, total_loss = -9.6782, pg_loss = 0.59437, baseline_loss = 0.66015, entropy_loss = -10.933, learner_queue_size = 32, _tick = 373, _time = 1.6548e+09, train_seconds = 720.9)
[2022-06-09 20:20:06,078][root][INFO] - Step 2708480 @ 4092.7 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 2708480, mean_episode_return = None, mean_episode_step = 3071.9, total_loss = 5.6888, pg_loss = 16.048, baseline_loss = 0.6725, entropy_loss = -11.031, learner_queue_size = 32, _tick = 374, _time = 1.6548e+09, train_seconds = 725.9)
[2022-06-09 20:20:11,082][root][INFO] - Step 2726400 @ 3581.2 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 2726400, mean_episode_return = None, mean_episode_step = 3483.9, total_loss = -2.7261, pg_loss = 7.7653, baseline_loss = 0.54093, entropy_loss = -11.032, learner_queue_size = 32, _tick = 374, _time = 1.6548e+09, train_seconds = 730.9)
[2022-06-09 20:20:16,086][root][INFO] - Step 2746880 @ 4092.7 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 2746880, mean_episode_return = None, mean_episode_step = 3106.1, total_loss = -18.072, pg_loss = -7.5189, baseline_loss = 0.45717, entropy_loss = -11.01, learner_queue_size = 32, _tick = 375, _time = 1.6548e+09, train_seconds = 735.9)
[2022-06-09 20:20:21,090][root][INFO] - Step 2767360 @ 4092.7 SPS. Inference batcher size: 79. Learner queue size: 32. Other stats: (step = 2767360, mean_episode_return = None, mean_episode_step = 3122.4, total_loss = -19.225, pg_loss = -8.7185, baseline_loss = 0.45902, entropy_loss = -10.965, learner_queue_size = 32, _tick = 375, _time = 1.6548e+09, train_seconds = 740.9)
[2022-06-09 20:20:26,094][root][INFO] - Step 2785280 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 2785280, mean_episode_return = None, mean_episode_step = 3746.2, total_loss = -16.011, pg_loss = -5.3551, baseline_loss = 0.4676, entropy_loss = -11.123, learner_queue_size = 32, _tick = 375, _time = 1.6548e+09, train_seconds = 745.9)
[2022-06-09 20:20:31,098][root][INFO] - Step 2805760 @ 4092.7 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 2805760, mean_episode_return = None, mean_episode_step = 3557.2, total_loss = -21.995, pg_loss = -11.265, baseline_loss = 0.42744, entropy_loss = -11.157, learner_queue_size = 32, _tick = 375, _time = 1.6548e+09, train_seconds = 750.9)
[2022-06-09 20:20:36,102][root][INFO] - Step 2823680 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 2823680, mean_episode_return = None, mean_episode_step = 4297.6, total_loss = -27.076, pg_loss = -18.023, baseline_loss = 2.0715, entropy_loss = -11.125, learner_queue_size = 32, _tick = 375, _time = 1.6548e+09, train_seconds = 755.9)
[2022-06-09 20:20:41,108][root][INFO] - Step 2841600 @ 3580.0 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 2841600, mean_episode_return = None, mean_episode_step = 3696.8, total_loss = -45.581, pg_loss = -36.759, baseline_loss = 1.921, entropy_loss = -10.743, learner_queue_size = 32, _tick = 375, _time = 1.6548e+09, train_seconds = 760.9)
[2022-06-09 20:20:46,110][root][INFO] - Step 2862080 @ 4094.0 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 2862080, mean_episode_return = None, mean_episode_step = 3085.9, total_loss = -30.279, pg_loss = -19.689, baseline_loss = 0.4404, entropy_loss = -11.031, learner_queue_size = 32, _tick = 376, _time = 1.6548e+09, train_seconds = 765.9)
[2022-06-09 20:20:51,114][root][INFO] - Step 2880000 @ 3581.2 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 2880000, mean_episode_return = None, mean_episode_step = 3821.5, total_loss = -26.975, pg_loss = -16.28, baseline_loss = 0.43464, entropy_loss = -11.129, learner_queue_size = 32, _tick = 376, _time = 1.6548e+09, train_seconds = 770.9)
[2022-06-09 20:20:56,118][root][INFO] - Step 2897920 @ 3581.1 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (step = 2897920, mean_episode_return = None, mean_episode_step = 3769.7, total_loss = -24.098, pg_loss = -13.405, baseline_loss = 0.41618, entropy_loss = -11.109, learner_queue_size = 32, _tick = 376, _time = 1.6548e+09, train_seconds = 775.9)
[2022-06-09 20:21:01,122][root][INFO] - Step 2915840 @ 3581.1 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 2915840, mean_episode_return = None, mean_episode_step = 3929.2, total_loss = -45.001, pg_loss = -34.313, baseline_loss = 0.37991, entropy_loss = -11.068, learner_queue_size = 32, _tick = 378, _time = 1.6548e+09, train_seconds = 780.9)
[2022-06-09 20:21:06,126][root][INFO] - Step 2933760 @ 3581.2 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 2933760, mean_episode_return = None, mean_episode_step = 4039.4, total_loss = -9.8411, pg_loss = 0.88271, baseline_loss = 0.39132, entropy_loss = -11.115, learner_queue_size = 32, _tick = 378, _time = 1.6548e+09, train_seconds = 785.9)
[2022-06-09 20:21:11,130][root][INFO] - Step 2951680 @ 3581.0 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 2951680, mean_episode_return = None, mean_episode_step = 4096.2, total_loss = -13.137, pg_loss = -2.3568, baseline_loss = 0.33916, entropy_loss = -11.119, learner_queue_size = 32, _tick = 378, _time = 1.6548e+09, train_seconds = 790.9)
[2022-06-09 20:21:16,134][root][INFO] - Step 2972160 @ 4092.9 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 2972160, mean_episode_return = None, mean_episode_step = 4069.2, total_loss = -19.299, pg_loss = -8.4901, baseline_loss = 0.32684, entropy_loss = -11.136, learner_queue_size = 32, _tick = 378, _time = 1.6548e+09, train_seconds = 795.9)
[2022-06-09 20:21:21,138][root][INFO] - Step 2990080 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 2990080, mean_episode_return = None, mean_episode_step = 4385.8, total_loss = -18.538, pg_loss = -7.7994, baseline_loss = 0.34015, entropy_loss = -11.078, learner_queue_size = 32, _tick = 379, _time = 1.6548e+09, train_seconds = 800.9)
[2022-06-09 20:21:26,142][root][INFO] - Step 3010560 @ 4092.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 3010560, mean_episode_return = None, mean_episode_step = 4648.9, total_loss = -22.559, pg_loss = -11.76, baseline_loss = 0.30007, entropy_loss = -11.1, learner_queue_size = 32, _tick = 379, _time = 1.6548e+09, train_seconds = 805.9)
[2022-06-09 20:21:31,146][root][INFO] - Step 3028480 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 3028480, mean_episode_return = None, mean_episode_step = 4238.4, total_loss = -15.399, pg_loss = -4.5446, baseline_loss = 0.30081, entropy_loss = -11.155, learner_queue_size = 32, _tick = 379, _time = 1.6548e+09, train_seconds = 811.0)
[2022-06-09 20:21:36,153][root][INFO] - Step 3048960 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 3048960, mean_episode_return = None, mean_episode_step = 4212.7, total_loss = 322.17, pg_loss = 325.72, baseline_loss = 6.5696, entropy_loss = -10.12, learner_queue_size = 32, _tick = 379, _time = 1.6548e+09, train_seconds = 816.0)
[2022-06-09 20:21:41,158][root][INFO] - Step 3066880 @ 3578.3 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 3066880, mean_episode_return = None, mean_episode_step = 4525.6, total_loss = 1074.1, pg_loss = 663.4, baseline_loss = 421.83, entropy_loss = -11.133, learner_queue_size = 32, _tick = 379, _time = 1.6548e+09, train_seconds = 821.0)
[2022-06-09 20:21:46,162][root][INFO] - Step 3087360 @ 4092.7 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 3087360, mean_episode_return = None, mean_episode_step = 4625.3, total_loss = -12.924, pg_loss = -2.1543, baseline_loss = 0.3614, entropy_loss = -11.131, learner_queue_size = 32, _tick = 379, _time = 1.6548e+09, train_seconds = 826.0)
[2022-06-09 20:21:51,167][root][INFO] - Step 3105280 @ 3580.3 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 3105280, mean_episode_return = None, mean_episode_step = 4730.9, total_loss = -11.368, pg_loss = -0.59314, baseline_loss = 0.32038, entropy_loss = -11.095, learner_queue_size = 32, _tick = 379, _time = 1.6548e+09, train_seconds = 831.0)
[2022-06-09 20:21:56,174][root][INFO] - Step 3125760 @ 4090.3 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (step = 3125760, mean_episode_return = None, mean_episode_step = 4558.0, total_loss = -1.9868, pg_loss = 8.8423, baseline_loss = 0.33722, entropy_loss = -11.166, learner_queue_size = 32, _tick = 379, _time = 1.6548e+09, train_seconds = 836.0)
[2022-06-09 20:22:01,178][root][INFO] - Step 3143680 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 3143680, mean_episode_return = None, mean_episode_step = 4638.9, total_loss = -6.3739, pg_loss = 4.4135, baseline_loss = 0.34099, entropy_loss = -11.128, learner_queue_size = 32, _tick = 380, _time = 1.6548e+09, train_seconds = 841.0)
[2022-06-09 20:22:06,182][root][INFO] - Step 3161600 @ 3581.2 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 3161600, mean_episode_return = None, mean_episode_step = 5108.8, total_loss = 1601.4, pg_loss = 1561.1, baseline_loss = 50.313, entropy_loss = -9.9992, learner_queue_size = 32, _tick = 380, _time = 1.6548e+09, train_seconds = 846.0)
[2022-06-09 20:22:11,186][root][INFO] - Step 3182080 @ 4092.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 3182080, mean_episode_return = None, mean_episode_step = 5364.8, total_loss = 0.036261, pg_loss = -0.7486, baseline_loss = 5.3195, entropy_loss = -4.5346, learner_queue_size = 32, _tick = 380, _time = 1.6548e+09, train_seconds = 851.0)
[2022-06-09 20:22:16,190][root][INFO] - Step 3200000 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 3200000, mean_episode_return = None, mean_episode_step = 5366.1, total_loss = -53.891, pg_loss = -49.685, baseline_loss = 4.6877, entropy_loss = -8.8943, learner_queue_size = 32, _tick = 381, _time = 1.6548e+09, train_seconds = 856.0)
[2022-06-09 20:22:21,194][root][INFO] - Step 3217920 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 3217920, mean_episode_return = None, mean_episode_step = 4797.2, total_loss = 32.753, pg_loss = 14.45, baseline_loss = 26.148, entropy_loss = -7.8439, learner_queue_size = 32, _tick = 383, _time = 1.6548e+09, train_seconds = 861.0)
[2022-06-09 20:22:26,198][root][INFO] - Step 3238400 @ 4092.8 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 3238400, mean_episode_return = None, mean_episode_step = 5073.2, total_loss = 12.039, pg_loss = -0.33997, baseline_loss = 21.329, entropy_loss = -8.9501, learner_queue_size = 32, _tick = 385, _time = 1.6548e+09, train_seconds = 866.0)
[2022-06-09 20:22:31,202][root][INFO] - Step 3256320 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 3256320, mean_episode_return = None, mean_episode_step = 5326.0, total_loss = -82.188, pg_loss = -77.997, baseline_loss = 3.926, entropy_loss = -8.1166, learner_queue_size = 32, _tick = 388, _time = 1.6548e+09, train_seconds = 871.0)
[2022-06-09 20:22:36,206][root][INFO] - Step 3274240 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 3274240, mean_episode_return = -55.967, mean_episode_step = 5266.9, total_loss = -37.433, pg_loss = -33.892, baseline_loss = 3.9386, entropy_loss = -7.4802, learner_queue_size = 32, _tick = 391, _time = 1.6548e+09, train_seconds = 876.0)
[2022-06-09 20:22:41,210][root][INFO] - Step 3292160 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 3292160, mean_episode_return = -29.121, mean_episode_step = 4789.4, total_loss = 59.634, pg_loss = 45.587, baseline_loss = 20.336, entropy_loss = -6.2895, learner_queue_size = 32, _tick = 395, _time = 1.6548e+09, train_seconds = 881.0)
[2022-06-09 20:22:46,214][root][INFO] - Step 3312640 @ 4092.8 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 3312640, mean_episode_return = None, mean_episode_step = 5123.6, total_loss = 66.872, pg_loss = 18.894, baseline_loss = 54.242, entropy_loss = -6.2632, learner_queue_size = 32, _tick = 397, _time = 1.6548e+09, train_seconds = 886.0)
[2022-06-09 20:22:51,218][root][INFO] - Step 3330560 @ 3581.1 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 3330560, mean_episode_return = -92.721, mean_episode_step = 3783.0, total_loss = -2.6381, pg_loss = -5.9623, baseline_loss = 8.4928, entropy_loss = -5.1687, learner_queue_size = 32, _tick = 400, _time = 1.6548e+09, train_seconds = 891.0)
[2022-06-09 20:22:56,222][root][INFO] - Step 3348480 @ 3581.1 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 3348480, mean_episode_return = None, mean_episode_step = 4588.4, total_loss = 196.29, pg_loss = 116.96, baseline_loss = 83.941, entropy_loss = -4.6132, learner_queue_size = 32, _tick = 403, _time = 1.6548e+09, train_seconds = 896.0)
[2022-06-09 20:23:01,226][root][INFO] - Step 3366400 @ 3581.0 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 3366400, mean_episode_return = None, mean_episode_step = 4485.4, total_loss = 150.05, pg_loss = 85.794, baseline_loss = 67.914, entropy_loss = -3.6583, learner_queue_size = 32, _tick = 405, _time = 1.6548e+09, train_seconds = 901.0)
[2022-06-09 20:23:06,230][root][INFO] - Step 3386880 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 3386880, mean_episode_return = 44.919, mean_episode_step = 4845.0, total_loss = 495.07, pg_loss = 167.75, baseline_loss = 332.39, entropy_loss = -5.0678, learner_queue_size = 32, _tick = 407, _time = 1.6548e+09, train_seconds = 906.0)
[2022-06-09 20:23:11,234][root][INFO] - Step 3404800 @ 3581.3 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 3404800, mean_episode_return = None, mean_episode_step = 4907.9, total_loss = 169.75, pg_loss = 109.83, baseline_loss = 65.115, entropy_loss = -5.193, learner_queue_size = 32, _tick = 409, _time = 1.6548e+09, train_seconds = 911.0)
[2022-06-09 20:23:16,238][root][INFO] - Step 3422720 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 3422720, mean_episode_return = 27.279, mean_episode_step = 4129.7, total_loss = 123.14, pg_loss = -7.9035, baseline_loss = 136.58, entropy_loss = -5.5427, learner_queue_size = 32, _tick = 413, _time = 1.6548e+09, train_seconds = 916.0)
[2022-06-09 20:23:21,242][root][INFO] - Step 3440640 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 3440640, mean_episode_return = 20.62, mean_episode_step = 4690.6, total_loss = 0.61374, pg_loss = -54.786, baseline_loss = 60.684, entropy_loss = -5.2844, learner_queue_size = 32, _tick = 418, _time = 1.6548e+09, train_seconds = 921.0)
[2022-06-09 20:23:26,246][root][INFO] - Step 3461120 @ 4092.8 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 3461120, mean_episode_return = -14.836, mean_episode_step = 3872.8, total_loss = -12.484, pg_loss = -57.658, baseline_loss = 50.123, entropy_loss = -4.9492, learner_queue_size = 32, _tick = 423, _time = 1.6548e+09, train_seconds = 926.1)
[2022-06-09 20:23:31,250][root][INFO] - Step 3479040 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 3479040, mean_episode_return = None, mean_episode_step = 4419.4, total_loss = 336.87, pg_loss = 143.6, baseline_loss = 198.49, entropy_loss = -5.2183, learner_queue_size = 32, _tick = 426, _time = 1.6548e+09, train_seconds = 931.1)
[2022-06-09 20:23:36,254][root][INFO] - Step 3499520 @ 4092.7 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 3499520, mean_episode_return = -64.196, mean_episode_step = 3633.3, total_loss = -1.1322, pg_loss = -30.314, baseline_loss = 33.289, entropy_loss = -4.1076, learner_queue_size = 32, _tick = 430, _time = 1.6548e+09, train_seconds = 936.1)
[2022-06-09 20:23:41,258][root][INFO] - Step 3517440 @ 3581.2 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 3517440, mean_episode_return = None, mean_episode_step = 4792.8, total_loss = -180.1, pg_loss = -179.59, baseline_loss = 4.0156, entropy_loss = -4.5323, learner_queue_size = 32, _tick = 432, _time = 1.6548e+09, train_seconds = 941.1)
[2022-06-09 20:23:46,262][root][INFO] - Step 3535360 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 3535360, mean_episode_return = 10.679, mean_episode_step = 4103.8, total_loss = -51.706, pg_loss = -82.291, baseline_loss = 34.934, entropy_loss = -4.3488, learner_queue_size = 32, _tick = 435, _time = 1.6548e+09, train_seconds = 946.1)
[2022-06-09 20:23:51,266][root][INFO] - Step 3555840 @ 4092.8 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 3555840, mean_episode_return = 104.68, mean_episode_step = 2821.8, total_loss = -89.558, pg_loss = -103.44, baseline_loss = 16.581, entropy_loss = -2.6944, learner_queue_size = 32, _tick = 439, _time = 1.6548e+09, train_seconds = 951.1)
[2022-06-09 20:23:56,270][root][INFO] - Step 3573760 @ 3581.2 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 3573760, mean_episode_return = None, mean_episode_step = 4664.0, total_loss = 0.27098, pg_loss = -2.1171, baseline_loss = 4.7218, entropy_loss = -2.3338, learner_queue_size = 32, _tick = 440, _time = 1.6548e+09, train_seconds = 956.1)
[2022-06-09 20:24:01,274][root][INFO] - Step 3594240 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 3594240, mean_episode_return = None, mean_episode_step = 4703.9, total_loss = -12.655, pg_loss = -2.1201, baseline_loss = 0.52787, entropy_loss = -11.063, learner_queue_size = 32, _tick = 441, _time = 1.6548e+09, train_seconds = 961.1)
[2022-06-09 20:24:06,278][root][INFO] - Step 3612160 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 3612160, mean_episode_return = None, mean_episode_step = 4293.1, total_loss = -12.223, pg_loss = -2.3881, baseline_loss = 1.2757, entropy_loss = -11.111, learner_queue_size = 32, _tick = 441, _time = 1.6548e+09, train_seconds = 966.1)
[2022-06-09 20:24:11,282][root][INFO] - Step 3632640 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 3632640, mean_episode_return = None, mean_episode_step = 4821.6, total_loss = -18.097, pg_loss = -9.8631, baseline_loss = 2.5743, entropy_loss = -10.808, learner_queue_size = 32, _tick = 442, _time = 1.6548e+09, train_seconds = 971.1)
[2022-06-09 20:24:16,286][root][INFO] - Step 3650560 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 3650560, mean_episode_return = None, mean_episode_step = 5239.0, total_loss = -75.763, pg_loss = -69.371, baseline_loss = 4.3698, entropy_loss = -10.762, learner_queue_size = 32, _tick = 442, _time = 1.6548e+09, train_seconds = 976.1)
[2022-06-09 20:24:21,290][root][INFO] - Step 3668480 @ 3581.2 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 3668480, mean_episode_return = None, mean_episode_step = 4410.6, total_loss = -9.5119, pg_loss = 0.27626, baseline_loss = 1.108, entropy_loss = -10.896, learner_queue_size = 32, _tick = 443, _time = 1.6548e+09, train_seconds = 981.1)
[2022-06-09 20:24:26,294][root][INFO] - Step 3688960 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 3688960, mean_episode_return = None, mean_episode_step = 4703.8, total_loss = -31.388, pg_loss = -21.266, baseline_loss = 0.8781, entropy_loss = -11.0, learner_queue_size = 32, _tick = 443, _time = 1.6548e+09, train_seconds = 986.1)
[2022-06-09 20:24:31,298][root][INFO] - Step 3706880 @ 3581.0 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 3706880, mean_episode_return = None, mean_episode_step = 5116.3, total_loss = 8.1958, pg_loss = 18.307, baseline_loss = 0.93202, entropy_loss = -11.043, learner_queue_size = 32, _tick = 443, _time = 1.6548e+09, train_seconds = 991.1)
[2022-06-09 20:24:36,302][root][INFO] - Step 3724800 @ 3581.2 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 3724800, mean_episode_return = None, mean_episode_step = 4084.5, total_loss = -31.019, pg_loss = -20.717, baseline_loss = 0.73066, entropy_loss = -11.032, learner_queue_size = 32, _tick = 443, _time = 1.6548e+09, train_seconds = 996.1)
[2022-06-09 20:24:41,306][root][INFO] - Step 3742720 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 3742720, mean_episode_return = 4.1068, mean_episode_step = 4210.0, total_loss = 116.47, pg_loss = 113.33, baseline_loss = 13.992, entropy_loss = -10.85, learner_queue_size = 32, _tick = 446, _time = 1.6548e+09, train_seconds = 1001.1)
[2022-06-09 20:24:46,310][root][INFO] - Step 3763200 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 3763200, mean_episode_return = 2.4404, mean_episode_step = 5126.5, total_loss = 32.597, pg_loss = 41.092, baseline_loss = 2.583, entropy_loss = -11.078, learner_queue_size = 32, _tick = 447, _time = 1.6548e+09, train_seconds = 1006.1)
[2022-06-09 20:24:51,314][root][INFO] - Step 3781120 @ 3581.1 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 3781120, mean_episode_return = None, mean_episode_step = 5896.5, total_loss = -26.294, pg_loss = -15.852, baseline_loss = 0.57109, entropy_loss = -11.013, learner_queue_size = 32, _tick = 449, _time = 1.6548e+09, train_seconds = 1011.1)
[2022-06-09 20:24:56,318][root][INFO] - Step 3801600 @ 4092.7 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 3801600, mean_episode_return = None, mean_episode_step = 4558.8, total_loss = -8.6425, pg_loss = 1.815, baseline_loss = 0.59175, entropy_loss = -11.049, learner_queue_size = 32, _tick = 449, _time = 1.6548e+09, train_seconds = 1016.1)
[2022-06-09 20:25:01,327][root][INFO] - Step 3819520 @ 3577.8 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 3819520, mean_episode_return = None, mean_episode_step = 5234.2, total_loss = -7.7069, pg_loss = 2.7127, baseline_loss = 0.60753, entropy_loss = -11.027, learner_queue_size = 32, _tick = 450, _time = 1.6548e+09, train_seconds = 1021.1)
[2022-06-09 20:25:06,330][root][INFO] - Step 3837440 @ 3581.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 3837440, mean_episode_return = None, mean_episode_step = 4791.7, total_loss = -14.336, pg_loss = -4.1795, baseline_loss = 0.8647, entropy_loss = -11.021, learner_queue_size = 32, _tick = 450, _time = 1.6548e+09, train_seconds = 1026.1)
[2022-06-09 20:25:11,334][root][INFO] - Step 3857920 @ 4092.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 3857920, mean_episode_return = None, mean_episode_step = 4890.3, total_loss = -11.557, pg_loss = -0.84023, baseline_loss = 0.46328, entropy_loss = -11.18, learner_queue_size = 32, _tick = 450, _time = 1.6548e+09, train_seconds = 1031.1)
[2022-06-09 20:25:16,338][root][INFO] - Step 3875840 @ 3581.2 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 3875840, mean_episode_return = None, mean_episode_step = 4607.9, total_loss = -9.2257, pg_loss = 1.5636, baseline_loss = 0.38692, entropy_loss = -11.176, learner_queue_size = 32, _tick = 451, _time = 1.6548e+09, train_seconds = 1036.1)
[2022-06-09 20:25:21,356][root][INFO] - Step 3896320 @ 4080.8 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 3896320, mean_episode_return = None, mean_episode_step = 5408.1, total_loss = -10.659, pg_loss = 0.19191, baseline_loss = 0.36415, entropy_loss = -11.215, learner_queue_size = 32, _tick = 451, _time = 1.6548e+09, train_seconds = 1041.2)
[2022-06-09 20:25:26,362][root][INFO] - Step 3914240 @ 3580.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 3914240, mean_episode_return = None, mean_episode_step = 5560.9, total_loss = -5.415, pg_loss = 5.4137, baseline_loss = 0.38023, entropy_loss = -11.209, learner_queue_size = 32, _tick = 451, _time = 1.6548e+09, train_seconds = 1046.2)
[2022-06-09 20:25:31,366][root][INFO] - Step 3934720 @ 4092.7 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 3934720, mean_episode_return = None, mean_episode_step = 5048.8, total_loss = -12.367, pg_loss = -1.4949, baseline_loss = 0.32614, entropy_loss = -11.198, learner_queue_size = 32, _tick = 452, _time = 1.6548e+09, train_seconds = 1051.2)
[2022-06-09 20:25:36,370][root][INFO] - Step 3952640 @ 3581.0 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 3952640, mean_episode_return = None, mean_episode_step = 5361.2, total_loss = -5.5426, pg_loss = 5.3402, baseline_loss = 0.34238, entropy_loss = -11.225, learner_queue_size = 32, _tick = 452, _time = 1.6548e+09, train_seconds = 1056.2)
[2022-06-09 20:25:41,374][root][INFO] - Step 3970560 @ 3581.3 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 3970560, mean_episode_return = None, mean_episode_step = 6572.0, total_loss = -14.206, pg_loss = -3.314, baseline_loss = 0.29947, entropy_loss = -11.191, learner_queue_size = 32, _tick = 453, _time = 1.6548e+09, train_seconds = 1061.2)
[2022-06-09 20:25:46,380][root][INFO] - Step 3991040 @ 4091.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 3991040, mean_episode_return = None, mean_episode_step = 4633.4, total_loss = -12.977, pg_loss = -2.0118, baseline_loss = 0.29705, entropy_loss = -11.263, learner_queue_size = 32, _tick = 453, _time = 1.6548e+09, train_seconds = 1066.2)
[2022-06-09 20:25:51,382][root][INFO] - Step 4008960 @ 3582.5 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 4008960, mean_episode_return = None, mean_episode_step = 6117.2, total_loss = -23.357, pg_loss = -12.414, baseline_loss = 0.30534, entropy_loss = -11.249, learner_queue_size = 32, _tick = 453, _time = 1.6548e+09, train_seconds = 1071.2)
[2022-06-09 20:25:56,386][root][INFO] - Step 4029440 @ 4092.4 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 4029440, mean_episode_return = None, mean_episode_step = 4973.7, total_loss = 394.72, pg_loss = 390.4, baseline_loss = 11.635, entropy_loss = -7.3226, learner_queue_size = 32, _tick = 454, _time = 1.6548e+09, train_seconds = 1076.2)
[2022-06-09 20:26:01,390][root][INFO] - Step 4047360 @ 3581.4 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 4047360, mean_episode_return = None, mean_episode_step = 5446.8, total_loss = -14.802, pg_loss = -4.0574, baseline_loss = 0.45994, entropy_loss = -11.205, learner_queue_size = 32, _tick = 454, _time = 1.6548e+09, train_seconds = 1081.2)
[2022-06-09 20:26:06,394][root][INFO] - Step 4067840 @ 4092.6 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 4067840, mean_episode_return = None, mean_episode_step = 6631.9, total_loss = 11.843, pg_loss = 21.353, baseline_loss = 1.6565, entropy_loss = -11.167, learner_queue_size = 32, _tick = 454, _time = 1.6548e+09, train_seconds = 1086.2)
[2022-06-09 20:26:11,398][root][INFO] - Step 4085760 @ 3581.2 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 4085760, mean_episode_return = None, mean_episode_step = 6592.8, total_loss = -44.695, pg_loss = -33.909, baseline_loss = 0.37909, entropy_loss = -11.166, learner_queue_size = 32, _tick = 454, _time = 1.6548e+09, train_seconds = 1091.2)
[2022-06-09 20:26:16,402][root][INFO] - Step 4103680 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 4103680, mean_episode_return = None, mean_episode_step = 6917.3, total_loss = -15.237, pg_loss = -4.2748, baseline_loss = 0.27041, entropy_loss = -11.232, learner_queue_size = 32, _tick = 455, _time = 1.6548e+09, train_seconds = 1096.2)
[2022-06-09 20:26:21,406][root][INFO] - Step 4121600 @ 3581.2 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 4121600, mean_episode_return = None, mean_episode_step = 6177.4, total_loss = 904.1, pg_loss = 890.81, baseline_loss = 21.941, entropy_loss = -8.6536, learner_queue_size = 32, _tick = 455, _time = 1.6548e+09, train_seconds = 1101.2)
[2022-06-09 20:26:26,410][root][INFO] - Step 4142080 @ 4092.7 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 4142080, mean_episode_return = None, mean_episode_step = 5952.9, total_loss = 255.61, pg_loss = 242.2, baseline_loss = 22.095, entropy_loss = -8.6836, learner_queue_size = 32, _tick = 455, _time = 1.6548e+09, train_seconds = 1106.2)
[2022-06-09 20:26:31,414][root][INFO] - Step 4160000 @ 3581.2 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 4160000, mean_episode_return = None, mean_episode_step = 5761.7, total_loss = -47.395, pg_loss = -49.135, baseline_loss = 6.3263, entropy_loss = -4.5857, learner_queue_size = 32, _tick = 456, _time = 1.6548e+09, train_seconds = 1111.2)
[2022-06-09 20:26:36,418][root][INFO] - Step 4180480 @ 4092.7 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 4180480, mean_episode_return = None, mean_episode_step = 6579.6, total_loss = 32.242, pg_loss = 34.316, baseline_loss = 8.4112, entropy_loss = -10.485, learner_queue_size = 32, _tick = 458, _time = 1.6548e+09, train_seconds = 1116.2)
[2022-06-09 20:26:41,422][root][INFO] - Step 4198400 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 4198400, mean_episode_return = None, mean_episode_step = 6024.8, total_loss = 2.0584, pg_loss = 7.6575, baseline_loss = 3.9106, entropy_loss = -9.5097, learner_queue_size = 32, _tick = 460, _time = 1.6548e+09, train_seconds = 1121.2)
[2022-06-09 20:26:46,426][root][INFO] - Step 4218880 @ 4092.5 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 4218880, mean_episode_return = 37.761, mean_episode_step = 5877.8, total_loss = 78.738, pg_loss = 78.701, baseline_loss = 7.4482, entropy_loss = -7.4114, learner_queue_size = 32, _tick = 462, _time = 1.6548e+09, train_seconds = 1126.2)
[2022-06-09 20:26:51,430][root][INFO] - Step 4236800 @ 3581.3 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 4236800, mean_episode_return = None, mean_episode_step = 6604.1, total_loss = 101.66, pg_loss = 65.492, baseline_loss = 43.615, entropy_loss = -7.4444, learner_queue_size = 32, _tick = 466, _time = 1.6548e+09, train_seconds = 1131.2)
[2022-06-09 20:26:56,434][root][INFO] - Step 4257280 @ 4092.7 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 4257280, mean_episode_return = -44.679, mean_episode_step = 6573.2, total_loss = 209.78, pg_loss = 177.74, baseline_loss = 38.064, entropy_loss = -6.022, learner_queue_size = 32, _tick = 472, _time = 1.6548e+09, train_seconds = 1136.2)
[2022-06-09 20:27:01,438][root][INFO] - Step 4275200 @ 3581.1 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (step = 4275200, mean_episode_return = -22.341, mean_episode_step = 7108.6, total_loss = 86.772, pg_loss = 49.443, baseline_loss = 41.537, entropy_loss = -4.2075, learner_queue_size = 32, _tick = 478, _time = 1.6548e+09, train_seconds = 1141.2)
[2022-06-09 20:27:06,442][root][INFO] - Step 4295680 @ 4092.8 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 4295680, mean_episode_return = None, mean_episode_step = 4847.8, total_loss = 37.856, pg_loss = 13.344, baseline_loss = 29.582, entropy_loss = -5.0693, learner_queue_size = 32, _tick = 482, _time = 1.6548e+09, train_seconds = 1146.2)
[2022-06-09 20:27:11,446][root][INFO] - Step 4313600 @ 3581.1 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 4313600, mean_episode_return = None, mean_episode_step = 4375.2, total_loss = 110.29, pg_loss = 80.79, baseline_loss = 33.858, entropy_loss = -4.3573, learner_queue_size = 32, _tick = 482, _time = 1.6548e+09, train_seconds = 1151.3)
[2022-06-09 20:27:16,450][root][INFO] - Step 4331520 @ 3581.2 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 4331520, mean_episode_return = None, mean_episode_step = 5105.8, total_loss = -75.713, pg_loss = -73.971, baseline_loss = 3.9146, entropy_loss = -5.6561, learner_queue_size = 32, _tick = 483, _time = 1.6548e+09, train_seconds = 1156.3)
[2022-06-09 20:27:21,454][root][INFO] - Step 4352000 @ 4092.6 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 4352000, mean_episode_return = None, mean_episode_step = 6399.0, total_loss = 26.655, pg_loss = 16.801, baseline_loss = 14.983, entropy_loss = -5.1281, learner_queue_size = 32, _tick = 486, _time = 1.6548e+09, train_seconds = 1161.3)
[2022-06-09 20:27:26,458][root][INFO] - Step 4369920 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 4369920, mean_episode_return = None, mean_episode_step = 4564.6, total_loss = 142.95, pg_loss = 84.702, baseline_loss = 63.076, entropy_loss = -4.8269, learner_queue_size = 32, _tick = 488, _time = 1.6548e+09, train_seconds = 1166.3)
[2022-06-09 20:27:31,462][root][INFO] - Step 4387840 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 4387840, mean_episode_return = 12.12, mean_episode_step = 5289.6, total_loss = 76.2, pg_loss = 23.14, baseline_loss = 56.607, entropy_loss = -3.5472, learner_queue_size = 32, _tick = 491, _time = 1.6548e+09, train_seconds = 1171.3)
[2022-06-09 20:27:36,466][root][INFO] - Step 4405760 @ 3581.1 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 4405760, mean_episode_return = None, mean_episode_step = 4925.4, total_loss = 239.85, pg_loss = 138.89, baseline_loss = 106.29, entropy_loss = -5.3251, learner_queue_size = 32, _tick = 495, _time = 1.6548e+09, train_seconds = 1176.3)
[2022-06-09 20:27:41,471][root][INFO] - Step 4426240 @ 4092.3 SPS. Inference batcher size: 73. Learner queue size: 32. Other stats: (step = 4426240, mean_episode_return = 2.9765, mean_episode_step = 5848.6, total_loss = -25.056, pg_loss = -47.982, baseline_loss = 28.078, entropy_loss = -5.1521, learner_queue_size = 32, _tick = 498, _time = 1.6548e+09, train_seconds = 1181.3)
[2022-06-09 20:27:46,474][root][INFO] - Step 4444160 @ 3581.5 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 4444160, mean_episode_return = None, mean_episode_step = 5016.6, total_loss = 88.819, pg_loss = 41.193, baseline_loss = 52.606, entropy_loss = -4.9805, learner_queue_size = 32, _tick = 501, _time = 1.6548e+09, train_seconds = 1186.3)
[2022-06-09 20:27:51,478][root][INFO] - Step 4462080 @ 3581.2 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 4462080, mean_episode_return = None, mean_episode_step = 4878.4, total_loss = -35.369, pg_loss = -32.113, baseline_loss = 1.6448, entropy_loss = -4.9005, learner_queue_size = 32, _tick = 504, _time = 1.6548e+09, train_seconds = 1191.3)
[2022-06-09 20:27:56,484][root][INFO] - Step 4480000 @ 3579.9 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 4480000, mean_episode_return = 41.608, mean_episode_step = 5896.2, total_loss = -0.09358, pg_loss = -15.086, baseline_loss = 19.868, entropy_loss = -4.8761, learner_queue_size = 32, _tick = 508, _time = 1.6548e+09, train_seconds = 1196.3)
[2022-06-09 20:28:01,486][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-09 20:28:01,650][root][INFO] - Step 4500480 @ 4094.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 4500480, mean_episode_return = -31.29, mean_episode_step = 4788.9, total_loss = 30.189, pg_loss = -28.841, baseline_loss = 63.415, entropy_loss = -4.3859, learner_queue_size = 32, _tick = 511, _time = 1.6548e+09, train_seconds = 1201.3)
[2022-06-09 20:28:06,654][root][INFO] - Step 4518400 @ 3467.5 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 4518400, mean_episode_return = -41.068, mean_episode_step = 5040.6, total_loss = 25.246, pg_loss = -11.561, baseline_loss = 41.374, entropy_loss = -4.5663, learner_queue_size = 32, _tick = 515, _time = 1.6548e+09, train_seconds = 1206.5)
[2022-06-09 20:28:11,658][root][INFO] - Step 4538880 @ 4092.8 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 4538880, mean_episode_return = None, mean_episode_step = 5991.9, total_loss = 441.8, pg_loss = 264.98, baseline_loss = 181.45, entropy_loss = -4.6258, learner_queue_size = 32, _tick = 519, _time = 1.6548e+09, train_seconds = 1211.5)
[2022-06-09 20:28:16,662][root][INFO] - Step 4556800 @ 3580.8 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 4556800, mean_episode_return = None, mean_episode_step = 4959.2, total_loss = 63.18, pg_loss = 11.033, baseline_loss = 56.822, entropy_loss = -4.6751, learner_queue_size = 32, _tick = 520, _time = 1.6548e+09, train_seconds = 1216.5)
[2022-06-09 20:28:21,666][root][INFO] - Step 4574720 @ 3581.5 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 4574720, mean_episode_return = None, mean_episode_step = 5536.5, total_loss = 132.63, pg_loss = 60.724, baseline_loss = 76.512, entropy_loss = -4.6006, learner_queue_size = 32, _tick = 522, _time = 1.6548e+09, train_seconds = 1221.5)
[2022-06-09 20:28:26,670][root][INFO] - Step 4595200 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 4595200, mean_episode_return = 9.9885, mean_episode_step = 3865.3, total_loss = 88.491, pg_loss = 55.972, baseline_loss = 37.446, entropy_loss = -4.9277, learner_queue_size = 32, _tick = 524, _time = 1.6548e+09, train_seconds = 1226.5)
[2022-06-09 20:28:31,674][root][INFO] - Step 4613120 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 4613120, mean_episode_return = None, mean_episode_step = 5105.8, total_loss = -26.257, pg_loss = -28.614, baseline_loss = 7.1687, entropy_loss = -4.8117, learner_queue_size = 32, _tick = 526, _time = 1.6548e+09, train_seconds = 1231.5)
[2022-06-09 20:28:36,678][root][INFO] - Step 4631040 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 4631040, mean_episode_return = None, mean_episode_step = 5677.5, total_loss = 225.78, pg_loss = 97.781, baseline_loss = 133.09, entropy_loss = -5.0884, learner_queue_size = 32, _tick = 530, _time = 1.6548e+09, train_seconds = 1236.5)
[2022-06-09 20:28:41,682][root][INFO] - Step 4651520 @ 4092.7 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 4651520, mean_episode_return = None, mean_episode_step = 5009.6, total_loss = 36.939, pg_loss = 20.443, baseline_loss = 21.077, entropy_loss = -4.5809, learner_queue_size = 32, _tick = 534, _time = 1.6548e+09, train_seconds = 1241.5)
[2022-06-09 20:28:46,686][root][INFO] - Step 4669440 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 4669440, mean_episode_return = None, mean_episode_step = 4233.5, total_loss = 277.44, pg_loss = 144.92, baseline_loss = 137.23, entropy_loss = -4.7147, learner_queue_size = 32, _tick = 537, _time = 1.6548e+09, train_seconds = 1246.5)
[2022-06-09 20:28:51,690][root][INFO] - Step 4689920 @ 4092.7 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 4689920, mean_episode_return = 43.588, mean_episode_step = 4503.5, total_loss = 202.15, pg_loss = 90.849, baseline_loss = 116.43, entropy_loss = -5.1253, learner_queue_size = 32, _tick = 543, _time = 1.6548e+09, train_seconds = 1251.5)
[2022-06-09 20:28:56,694][root][INFO] - Step 4707840 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 4707840, mean_episode_return = 15.646, mean_episode_step = 3606.7, total_loss = 0.37889, pg_loss = -62.666, baseline_loss = 68.895, entropy_loss = -5.8498, learner_queue_size = 32, _tick = 546, _time = 1.6548e+09, train_seconds = 1256.5)
[2022-06-09 20:29:01,698][root][INFO] - Step 4725760 @ 3580.9 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 4725760, mean_episode_return = 12.194, mean_episode_step = 4788.7, total_loss = 39.239, pg_loss = -44.948, baseline_loss = 89.539, entropy_loss = -5.3522, learner_queue_size = 32, _tick = 550, _time = 1.6548e+09, train_seconds = 1261.5)
[2022-06-09 20:29:06,702][root][INFO] - Step 4746240 @ 4093.0 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 4746240, mean_episode_return = None, mean_episode_step = 5928.6, total_loss = 15.191, pg_loss = 0.91145, baseline_loss = 18.697, entropy_loss = -4.4172, learner_queue_size = 32, _tick = 555, _time = 1.6548e+09, train_seconds = 1266.5)
[2022-06-09 20:29:11,706][root][INFO] - Step 4764160 @ 3581.2 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 4764160, mean_episode_return = None, mean_episode_step = 4091.1, total_loss = -67.315, pg_loss = -65.601, baseline_loss = 3.6565, entropy_loss = -5.371, learner_queue_size = 32, _tick = 557, _time = 1.6548e+09, train_seconds = 1271.5)
[2022-06-09 20:29:16,710][root][INFO] - Step 4782080 @ 3581.1 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 4782080, mean_episode_return = -63.005, mean_episode_step = 4437.4, total_loss = -157.68, pg_loss = -158.37, baseline_loss = 5.9483, entropy_loss = -5.26, learner_queue_size = 32, _tick = 563, _time = 1.6548e+09, train_seconds = 1276.5)
[2022-06-09 20:29:21,714][root][INFO] - Step 4802560 @ 4092.7 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 4802560, mean_episode_return = -12.055, mean_episode_step = 3976.6, total_loss = 42.554, pg_loss = -46.965, baseline_loss = 94.509, entropy_loss = -4.9904, learner_queue_size = 32, _tick = 565, _time = 1.6548e+09, train_seconds = 1281.5)
[2022-06-09 20:29:26,718][root][INFO] - Step 4820480 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 4820480, mean_episode_return = None, mean_episode_step = 5195.1, total_loss = -148.07, pg_loss = -144.65, baseline_loss = 1.5243, entropy_loss = -4.9403, learner_queue_size = 32, _tick = 566, _time = 1.6548e+09, train_seconds = 1286.5)
[2022-06-09 20:29:31,722][root][INFO] - Step 4840960 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 4840960, mean_episode_return = None, mean_episode_step = 4781.7, total_loss = 7.4958, pg_loss = -34.738, baseline_loss = 46.951, entropy_loss = -4.7173, learner_queue_size = 32, _tick = 568, _time = 1.6548e+09, train_seconds = 1291.5)
[2022-06-09 20:29:36,726][root][INFO] - Step 4858880 @ 3581.1 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 4858880, mean_episode_return = None, mean_episode_step = 4635.3, total_loss = -88.369, pg_loss = -101.62, baseline_loss = 17.765, entropy_loss = -4.5124, learner_queue_size = 32, _tick = 571, _time = 1.6548e+09, train_seconds = 1296.5)
[2022-06-09 20:29:41,730][root][INFO] - Step 4876800 @ 3581.2 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 4876800, mean_episode_return = 48.466, mean_episode_step = 4913.4, total_loss = 51.62, pg_loss = -0.99428, baseline_loss = 57.928, entropy_loss = -5.3135, learner_queue_size = 32, _tick = 574, _time = 1.6548e+09, train_seconds = 1301.5)
[2022-06-09 20:29:46,734][root][INFO] - Step 4894720 @ 3581.1 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 4894720, mean_episode_return = -16.455, mean_episode_step = 4474.9, total_loss = -91.973, pg_loss = -93.541, baseline_loss = 6.422, entropy_loss = -4.8544, learner_queue_size = 32, _tick = 578, _time = 1.6548e+09, train_seconds = 1306.5)
[2022-06-09 20:29:51,738][root][INFO] - Step 4915200 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 4915200, mean_episode_return = None, mean_episode_step = 4841.3, total_loss = 661.26, pg_loss = 432.62, baseline_loss = 233.71, entropy_loss = -5.0701, learner_queue_size = 32, _tick = 578, _time = 1.6548e+09, train_seconds = 1311.5)
[2022-06-09 20:29:56,743][root][INFO] - Step 4933120 @ 3580.6 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 4933120, mean_episode_return = 60.39, mean_episode_step = 5213.3, total_loss = -52.496, pg_loss = -51.681, baseline_loss = 4.2427, entropy_loss = -5.0579, learner_queue_size = 32, _tick = 581, _time = 1.6548e+09, train_seconds = 1316.6)
[2022-06-09 20:30:01,746][root][INFO] - Step 4951040 @ 3581.6 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 4951040, mean_episode_return = None, mean_episode_step = 5290.6, total_loss = 91.655, pg_loss = 20.175, baseline_loss = 76.326, entropy_loss = -4.8462, learner_queue_size = 32, _tick = 584, _time = 1.6548e+09, train_seconds = 1321.6)
[2022-06-09 20:30:06,750][root][INFO] - Step 4968960 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 4968960, mean_episode_return = None, mean_episode_step = 3930.3, total_loss = 122.51, pg_loss = 42.159, baseline_loss = 85.047, entropy_loss = -4.6922, learner_queue_size = 32, _tick = 585, _time = 1.6548e+09, train_seconds = 1326.6)
[2022-06-09 20:30:11,754][root][INFO] - Step 4989440 @ 4092.8 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 4989440, mean_episode_return = None, mean_episode_step = 4413.7, total_loss = 307.77, pg_loss = 194.84, baseline_loss = 117.35, entropy_loss = -4.4193, learner_queue_size = 32, _tick = 588, _time = 1.6548e+09, train_seconds = 1331.6)
[2022-06-09 20:30:16,758][root][INFO] - Step 5007360 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 5007360, mean_episode_return = None, mean_episode_step = 4716.6, total_loss = 222.49, pg_loss = 138.44, baseline_loss = 87.831, entropy_loss = -3.7775, learner_queue_size = 32, _tick = 590, _time = 1.6548e+09, train_seconds = 1336.6)
[2022-06-09 20:30:21,762][root][INFO] - Step 5027840 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 5027840, mean_episode_return = 29.341, mean_episode_step = 4757.0, total_loss = 3.6584, pg_loss = 9.788, baseline_loss = 3.6207, entropy_loss = -9.7503, learner_queue_size = 32, _tick = 595, _time = 1.6548e+09, train_seconds = 1341.6)
[2022-06-09 20:30:26,766][root][INFO] - Step 5045760 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 5045760, mean_episode_return = 92.891, mean_episode_step = 4519.1, total_loss = -18.438, pg_loss = -11.089, baseline_loss = 1.7373, entropy_loss = -9.0858, learner_queue_size = 32, _tick = 600, _time = 1.6548e+09, train_seconds = 1346.6)
[2022-06-09 20:30:31,770][root][INFO] - Step 5063680 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 5063680, mean_episode_return = None, mean_episode_step = 4062.2, total_loss = -53.264, pg_loss = -45.505, baseline_loss = 1.0515, entropy_loss = -8.8109, learner_queue_size = 32, _tick = 605, _time = 1.6548e+09, train_seconds = 1351.6)
[2022-06-09 20:30:36,775][root][INFO] - Step 5084160 @ 4091.9 SPS. Inference batcher size: 82. Learner queue size: 32. Other stats: (step = 5084160, mean_episode_return = -23.058, mean_episode_step = 3708.2, total_loss = 129.65, pg_loss = 104.77, baseline_loss = 34.109, entropy_loss = -9.2199, learner_queue_size = 32, _tick = 608, _time = 1.6548e+09, train_seconds = 1356.6)
[2022-06-09 20:30:41,778][root][INFO] - Step 5102080 @ 3581.9 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 5102080, mean_episode_return = None, mean_episode_step = 4405.6, total_loss = 5.7021, pg_loss = 3.0175, baseline_loss = 10.785, entropy_loss = -8.1008, learner_queue_size = 32, _tick = 612, _time = 1.6548e+09, train_seconds = 1361.6)
[2022-06-09 20:30:46,782][root][INFO] - Step 5120000 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 5120000, mean_episode_return = None, mean_episode_step = 4090.2, total_loss = 158.41, pg_loss = 118.4, baseline_loss = 46.881, entropy_loss = -6.872, learner_queue_size = 32, _tick = 617, _time = 1.6548e+09, train_seconds = 1366.6)
[2022-06-09 20:30:51,786][root][INFO] - Step 5140480 @ 4092.8 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 5140480, mean_episode_return = 42.771, mean_episode_step = 3421.4, total_loss = 214.57, pg_loss = 168.95, baseline_loss = 54.46, entropy_loss = -8.8324, learner_queue_size = 32, _tick = 623, _time = 1.6548e+09, train_seconds = 1371.6)
[2022-06-09 20:30:56,790][root][INFO] - Step 5158400 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 5158400, mean_episode_return = None, mean_episode_step = 4369.6, total_loss = 293.55, pg_loss = 210.62, baseline_loss = 90.878, entropy_loss = -7.9542, learner_queue_size = 32, _tick = 629, _time = 1.6548e+09, train_seconds = 1376.6)
[2022-06-09 20:31:01,802][root][INFO] - Step 5178880 @ 4086.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 5178880, mean_episode_return = None, mean_episode_step = 2694.3, total_loss = 28.597, pg_loss = 25.466, baseline_loss = 10.097, entropy_loss = -6.9664, learner_queue_size = 32, _tick = 636, _time = 1.6548e+09, train_seconds = 1381.6)
[2022-06-09 20:31:06,806][root][INFO] - Step 5196800 @ 3581.2 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 5196800, mean_episode_return = -74.589, mean_episode_step = 2897.5, total_loss = -18.639, pg_loss = -38.687, baseline_loss = 26.927, entropy_loss = -6.879, learner_queue_size = 32, _tick = 642, _time = 1.6548e+09, train_seconds = 1386.6)
[2022-06-09 20:31:11,810][root][INFO] - Step 5214720 @ 3581.2 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 5214720, mean_episode_return = 24.495, mean_episode_step = 2158.8, total_loss = 50.8, pg_loss = -3.6125, baseline_loss = 60.392, entropy_loss = -5.9799, learner_queue_size = 32, _tick = 646, _time = 1.6548e+09, train_seconds = 1391.6)
[2022-06-09 20:31:16,814][root][INFO] - Step 5235200 @ 4092.8 SPS. Inference batcher size: 79. Learner queue size: 32. Other stats: (step = 5235200, mean_episode_return = 29.26, mean_episode_step = 2558.2, total_loss = 808.86, pg_loss = 498.39, baseline_loss = 316.76, entropy_loss = -6.2907, learner_queue_size = 32, _tick = 651, _time = 1.6548e+09, train_seconds = 1396.6)
[2022-06-09 20:31:21,818][root][INFO] - Step 5253120 @ 3581.2 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 5253120, mean_episode_return = None, mean_episode_step = 3929.7, total_loss = 190.07, pg_loss = 120.33, baseline_loss = 75.75, entropy_loss = -6.0074, learner_queue_size = 32, _tick = 654, _time = 1.6548e+09, train_seconds = 1401.6)
[2022-06-09 20:31:26,822][root][INFO] - Step 5271040 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 5271040, mean_episode_return = 68.158, mean_episode_step = 2872.4, total_loss = 70.885, pg_loss = 39.744, baseline_loss = 36.102, entropy_loss = -4.9618, learner_queue_size = 32, _tick = 657, _time = 1.6548e+09, train_seconds = 1406.6)
[2022-06-09 20:31:31,826][root][INFO] - Step 5291520 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 5291520, mean_episode_return = -28.142, mean_episode_step = 2733.7, total_loss = 1.6495, pg_loss = -41.459, baseline_loss = 47.963, entropy_loss = -4.8551, learner_queue_size = 32, _tick = 662, _time = 1.6548e+09, train_seconds = 1411.6)
[2022-06-09 20:31:36,830][root][INFO] - Step 5309440 @ 3581.0 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 5309440, mean_episode_return = 20.03, mean_episode_step = 2992.6, total_loss = 108.88, pg_loss = 22.113, baseline_loss = 91.719, entropy_loss = -4.9507, learner_queue_size = 32, _tick = 665, _time = 1.6548e+09, train_seconds = 1416.6)
[2022-06-09 20:31:41,834][root][INFO] - Step 5327360 @ 3581.2 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 5327360, mean_episode_return = None, mean_episode_step = 2776.7, total_loss = 310.04, pg_loss = 152.01, baseline_loss = 162.64, entropy_loss = -4.6067, learner_queue_size = 32, _tick = 668, _time = 1.6548e+09, train_seconds = 1421.6)
[2022-06-09 20:31:46,838][root][INFO] - Step 5345280 @ 3581.1 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 5345280, mean_episode_return = None, mean_episode_step = 3176.8, total_loss = -157.98, pg_loss = -157.28, baseline_loss = 3.9479, entropy_loss = -4.6477, learner_queue_size = 32, _tick = 672, _time = 1.6548e+09, train_seconds = 1426.6)
[2022-06-09 20:31:51,846][root][INFO] - Step 5363200 @ 3578.3 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 5363200, mean_episode_return = None, mean_episode_step = 2846.7, total_loss = 10.032, pg_loss = -21.48, baseline_loss = 36.662, entropy_loss = -5.1509, learner_queue_size = 32, _tick = 675, _time = 1.6548e+09, train_seconds = 1431.7)
[2022-06-09 20:31:56,850][root][INFO] - Step 5383680 @ 4092.8 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 5383680, mean_episode_return = None, mean_episode_step = 2610.3, total_loss = 190.63, pg_loss = 126.06, baseline_loss = 69.656, entropy_loss = -5.0879, learner_queue_size = 32, _tick = 675, _time = 1.6548e+09, train_seconds = 1436.7)
[2022-06-09 20:32:01,854][root][INFO] - Step 5401600 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 5401600, mean_episode_return = 24.785, mean_episode_step = 3547.2, total_loss = -113.33, pg_loss = -129.9, baseline_loss = 21.608, entropy_loss = -5.031, learner_queue_size = 32, _tick = 679, _time = 1.6548e+09, train_seconds = 1441.7)
[2022-06-09 20:32:06,858][root][INFO] - Step 5422080 @ 4092.8 SPS. Inference batcher size: 79. Learner queue size: 32. Other stats: (step = 5422080, mean_episode_return = None, mean_episode_step = 2857.8, total_loss = 86.001, pg_loss = 44.271, baseline_loss = 46.648, entropy_loss = -4.9185, learner_queue_size = 32, _tick = 683, _time = 1.6548e+09, train_seconds = 1446.7)
[2022-06-09 20:32:11,862][root][INFO] - Step 5440000 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 5440000, mean_episode_return = None, mean_episode_step = 2450.6, total_loss = -6.3492, pg_loss = -2.7849, baseline_loss = 5.1718, entropy_loss = -8.7361, learner_queue_size = 32, _tick = 687, _time = 1.6548e+09, train_seconds = 1451.7)
[2022-06-09 20:32:16,866][root][INFO] - Step 5457920 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 5457920, mean_episode_return = 37.98, mean_episode_step = 2359.7, total_loss = 164.78, pg_loss = 94.274, baseline_loss = 78.045, entropy_loss = -7.54, learner_queue_size = 32, _tick = 694, _time = 1.6548e+09, train_seconds = 1456.7)
[2022-06-09 20:32:21,870][root][INFO] - Step 5478400 @ 4092.6 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 5478400, mean_episode_return = None, mean_episode_step = 3418.8, total_loss = 95.894, pg_loss = 52.463, baseline_loss = 49.251, entropy_loss = -5.8201, learner_queue_size = 32, _tick = 700, _time = 1.6548e+09, train_seconds = 1461.7)
[2022-06-09 20:32:26,874][root][INFO] - Step 5496320 @ 3581.2 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 5496320, mean_episode_return = None, mean_episode_step = 1865.8, total_loss = 149.9, pg_loss = 78.784, baseline_loss = 76.09, entropy_loss = -4.9727, learner_queue_size = 32, _tick = 703, _time = 1.6548e+09, train_seconds = 1466.7)
[2022-06-09 20:32:31,878][root][INFO] - Step 5514240 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 5514240, mean_episode_return = -44.727, mean_episode_step = 3083.3, total_loss = 60.878, pg_loss = -3.7918, baseline_loss = 69.275, entropy_loss = -4.6052, learner_queue_size = 32, _tick = 706, _time = 1.6548e+09, train_seconds = 1471.7)
[2022-06-09 20:32:36,882][root][INFO] - Step 5534720 @ 4092.8 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 5534720, mean_episode_return = None, mean_episode_step = 3002.5, total_loss = 135.71, pg_loss = 34.939, baseline_loss = 105.82, entropy_loss = -5.0493, learner_queue_size = 32, _tick = 708, _time = 1.6548e+09, train_seconds = 1476.7)
[2022-06-09 20:32:41,886][root][INFO] - Step 5552640 @ 3581.2 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 5552640, mean_episode_return = None, mean_episode_step = 3718.7, total_loss = 364.99, pg_loss = 207.92, baseline_loss = 162.24, entropy_loss = -5.1794, learner_queue_size = 32, _tick = 710, _time = 1.6548e+09, train_seconds = 1481.7)
[2022-06-09 20:32:46,890][root][INFO] - Step 5570560 @ 3581.0 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 5570560, mean_episode_return = None, mean_episode_step = 3127.2, total_loss = -68.796, pg_loss = -68.098, baseline_loss = 4.2202, entropy_loss = -4.9183, learner_queue_size = 32, _tick = 711, _time = 1.6548e+09, train_seconds = 1486.7)
[2022-06-09 20:32:51,894][root][INFO] - Step 5588480 @ 3581.1 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 5588480, mean_episode_return = None, mean_episode_step = 2820.1, total_loss = -46.199, pg_loss = -46.81, baseline_loss = 5.2492, entropy_loss = -4.6383, learner_queue_size = 32, _tick = 713, _time = 1.6548e+09, train_seconds = 1491.7)
[2022-06-09 20:32:56,898][root][INFO] - Step 5608960 @ 4092.8 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 5608960, mean_episode_return = None, mean_episode_step = 2665.8, total_loss = 391.27, pg_loss = 272.93, baseline_loss = 124.62, entropy_loss = -6.2793, learner_queue_size = 32, _tick = 716, _time = 1.6548e+09, train_seconds = 1496.7)
[2022-06-09 20:33:01,902][root][INFO] - Step 5626880 @ 3581.2 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 5626880, mean_episode_return = 57.072, mean_episode_step = 2936.5, total_loss = -9.515, pg_loss = -37.595, baseline_loss = 33.313, entropy_loss = -5.2331, learner_queue_size = 32, _tick = 720, _time = 1.6548e+09, train_seconds = 1501.7)
[2022-06-09 20:33:06,906][root][INFO] - Step 5644800 @ 3581.1 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 5644800, mean_episode_return = None, mean_episode_step = 2266.9, total_loss = -51.336, pg_loss = -61.347, baseline_loss = 14.769, entropy_loss = -4.7591, learner_queue_size = 32, _tick = 724, _time = 1.6548e+09, train_seconds = 1506.7)
[2022-06-09 20:33:11,910][root][INFO] - Step 5665280 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 5665280, mean_episode_return = None, mean_episode_step = 3510.8, total_loss = -1.4253, pg_loss = -20.866, baseline_loss = 24.189, entropy_loss = -4.7489, learner_queue_size = 32, _tick = 729, _time = 1.6548e+09, train_seconds = 1511.7)
[2022-06-09 20:33:16,914][root][INFO] - Step 5683200 @ 3581.2 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 5683200, mean_episode_return = None, mean_episode_step = 2415.8, total_loss = 142.56, pg_loss = 57.45, baseline_loss = 89.995, entropy_loss = -4.887, learner_queue_size = 32, _tick = 731, _time = 1.6548e+09, train_seconds = 1516.7)
[2022-06-09 20:33:21,918][root][INFO] - Step 5701120 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 5701120, mean_episode_return = None, mean_episode_step = 2608.2, total_loss = 37.801, pg_loss = -6.3428, baseline_loss = 49.197, entropy_loss = -5.0532, learner_queue_size = 32, _tick = 735, _time = 1.6548e+09, train_seconds = 1521.7)
[2022-06-09 20:33:26,922][root][INFO] - Step 5719040 @ 3581.1 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 5719040, mean_episode_return = 14.495, mean_episode_step = 3305.4, total_loss = -30.56, pg_loss = -36.765, baseline_loss = 12.771, entropy_loss = -6.5661, learner_queue_size = 32, _tick = 738, _time = 1.6548e+09, train_seconds = 1526.7)
[2022-06-09 20:33:31,926][root][INFO] - Step 5739520 @ 4092.8 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 5739520, mean_episode_return = None, mean_episode_step = 2606.9, total_loss = -71.592, pg_loss = -71.175, baseline_loss = 5.983, entropy_loss = -6.3991, learner_queue_size = 32, _tick = 742, _time = 1.6548e+09, train_seconds = 1531.7)
[2022-06-09 20:33:36,932][root][INFO] - Step 5757440 @ 3580.0 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 5757440, mean_episode_return = None, mean_episode_step = 2807.5, total_loss = -64.481, pg_loss = -59.768, baseline_loss = 1.5729, entropy_loss = -6.2863, learner_queue_size = 32, _tick = 746, _time = 1.6548e+09, train_seconds = 1536.7)
[2022-06-09 20:33:41,934][root][INFO] - Step 5777920 @ 4094.0 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 5777920, mean_episode_return = 128.94, mean_episode_step = 3021.6, total_loss = -8.3741, pg_loss = -15.901, baseline_loss = 14.623, entropy_loss = -7.0953, learner_queue_size = 32, _tick = 750, _time = 1.6548e+09, train_seconds = 1541.7)
[2022-06-09 20:33:46,940][root][INFO] - Step 5795840 @ 3579.5 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 5795840, mean_episode_return = None, mean_episode_step = 2495.8, total_loss = 17.252, pg_loss = 19.988, baseline_loss = 5.6906, entropy_loss = -8.4259, learner_queue_size = 32, _tick = 754, _time = 1.6548e+09, train_seconds = 1546.7)
[2022-06-09 20:33:51,946][root][INFO] - Step 5813760 @ 3579.9 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 5813760, mean_episode_return = None, mean_episode_step = 1540.2, total_loss = 130.31, pg_loss = 107.74, baseline_loss = 29.912, entropy_loss = -7.3432, learner_queue_size = 32, _tick = 758, _time = 1.6548e+09, train_seconds = 1551.8)
[2022-06-09 20:33:56,950][root][INFO] - Step 5834240 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 5834240, mean_episode_return = -5.6505, mean_episode_step = 2811.5, total_loss = -56.627, pg_loss = -55.813, baseline_loss = 5.8148, entropy_loss = -6.6291, learner_queue_size = 32, _tick = 761, _time = 1.6548e+09, train_seconds = 1556.8)
[2022-06-09 20:34:01,954][root][INFO] - Step 5852160 @ 3581.2 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 5852160, mean_episode_return = None, mean_episode_step = 2898.2, total_loss = 24.521, pg_loss = 1.6718, baseline_loss = 30.628, entropy_loss = -7.7794, learner_queue_size = 32, _tick = 764, _time = 1.6548e+09, train_seconds = 1561.8)
[2022-06-09 20:34:06,958][root][INFO] - Step 5870080 @ 3581.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 5870080, mean_episode_return = 122.74, mean_episode_step = 3213.4, total_loss = 131.27, pg_loss = 96.364, baseline_loss = 42.125, entropy_loss = -7.2156, learner_queue_size = 32, _tick = 768, _time = 1.6548e+09, train_seconds = 1566.8)
[2022-06-09 20:34:11,962][root][INFO] - Step 5888000 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 5888000, mean_episode_return = -35.828, mean_episode_step = 2638.0, total_loss = 99.987, pg_loss = 72.116, baseline_loss = 35.657, entropy_loss = -7.7864, learner_queue_size = 32, _tick = 771, _time = 1.6548e+09, train_seconds = 1571.8)
[2022-06-09 20:34:16,966][root][INFO] - Step 5908480 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 5908480, mean_episode_return = 46.49, mean_episode_step = 2562.4, total_loss = 92.436, pg_loss = 66.452, baseline_loss = 32.94, entropy_loss = -6.9558, learner_queue_size = 32, _tick = 776, _time = 1.6548e+09, train_seconds = 1576.8)
[2022-06-09 20:34:21,970][root][INFO] - Step 5926400 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 5926400, mean_episode_return = -5.9103, mean_episode_step = 2562.0, total_loss = 53.55, pg_loss = 25.663, baseline_loss = 32.493, entropy_loss = -4.6064, learner_queue_size = 32, _tick = 780, _time = 1.6548e+09, train_seconds = 1581.8)
[2022-06-09 20:34:26,974][root][INFO] - Step 5946880 @ 4092.6 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 5946880, mean_episode_return = None, mean_episode_step = 3229.2, total_loss = -145.39, pg_loss = -146.86, baseline_loss = 6.2994, entropy_loss = -4.8328, learner_queue_size = 32, _tick = 784, _time = 1.6548e+09, train_seconds = 1586.8)
[2022-06-09 20:34:31,978][root][INFO] - Step 5964800 @ 3581.2 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 5964800, mean_episode_return = None, mean_episode_step = 2582.9, total_loss = 410.44, pg_loss = 252.74, baseline_loss = 162.22, entropy_loss = -4.5253, learner_queue_size = 32, _tick = 787, _time = 1.6548e+09, train_seconds = 1591.8)
[2022-06-09 20:34:36,982][root][INFO] - Step 5982720 @ 3581.2 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 5982720, mean_episode_return = None, mean_episode_step = 2190.5, total_loss = -83.404, pg_loss = -87.058, baseline_loss = 8.0042, entropy_loss = -4.3509, learner_queue_size = 32, _tick = 791, _time = 1.6548e+09, train_seconds = 1596.8)
[2022-06-09 20:34:41,986][root][INFO] - Step 6003200 @ 4092.6 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 6003200, mean_episode_return = None, mean_episode_step = 2119.6, total_loss = 170.17, pg_loss = 97.657, baseline_loss = 76.843, entropy_loss = -4.3286, learner_queue_size = 32, _tick = 793, _time = 1.6548e+09, train_seconds = 1601.8)
[2022-06-09 20:34:46,990][root][INFO] - Step 6021120 @ 3581.2 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 6021120, mean_episode_return = None, mean_episode_step = 3671.4, total_loss = -17.254, pg_loss = -32.537, baseline_loss = 21.27, entropy_loss = -5.9876, learner_queue_size = 32, _tick = 794, _time = 1.6548e+09, train_seconds = 1606.8)
[2022-06-09 20:34:51,994][root][INFO] - Step 6039040 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 6039040, mean_episode_return = 35.94, mean_episode_step = 3580.4, total_loss = -19.047, pg_loss = -17.462, baseline_loss = 4.7852, entropy_loss = -6.3705, learner_queue_size = 32, _tick = 799, _time = 1.6548e+09, train_seconds = 1611.8)
[2022-06-09 20:34:56,998][root][INFO] - Step 6059520 @ 4092.7 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (step = 6059520, mean_episode_return = 14.663, mean_episode_step = 2637.7, total_loss = 61.48, pg_loss = 3.8932, baseline_loss = 63.81, entropy_loss = -6.2239, learner_queue_size = 32, _tick = 807, _time = 1.6548e+09, train_seconds = 1616.8)
[2022-06-09 20:35:02,002][root][INFO] - Step 6077440 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 6077440, mean_episode_return = 16.598, mean_episode_step = 2609.8, total_loss = 143.18, pg_loss = 76.671, baseline_loss = 72.616, entropy_loss = -6.1043, learner_queue_size = 32, _tick = 811, _time = 1.6548e+09, train_seconds = 1621.8)
[2022-06-09 20:35:07,006][root][INFO] - Step 6095360 @ 3581.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 6095360, mean_episode_return = None, mean_episode_step = 2353.8, total_loss = 75.254, pg_loss = 36.675, baseline_loss = 43.906, entropy_loss = -5.3276, learner_queue_size = 32, _tick = 815, _time = 1.6548e+09, train_seconds = 1626.8)
[2022-06-09 20:35:12,018][root][INFO] - Step 6115840 @ 4086.2 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 6115840, mean_episode_return = 64.152, mean_episode_step = 2630.2, total_loss = 24.623, pg_loss = -8.6941, baseline_loss = 37.721, entropy_loss = -4.404, learner_queue_size = 32, _tick = 822, _time = 1.6548e+09, train_seconds = 1631.8)
[2022-06-09 20:35:17,030][root][INFO] - Step 6133760 @ 3575.4 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 6133760, mean_episode_return = None, mean_episode_step = 2149.4, total_loss = 125.4, pg_loss = 91.008, baseline_loss = 38.243, entropy_loss = -3.8526, learner_queue_size = 32, _tick = 823, _time = 1.6548e+09, train_seconds = 1636.8)
[2022-06-09 20:35:22,034][root][INFO] - Step 6151680 @ 3581.2 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 6151680, mean_episode_return = None, mean_episode_step = 2496.3, total_loss = 86.717, pg_loss = 28.856, baseline_loss = 62.162, entropy_loss = -4.3018, learner_queue_size = 32, _tick = 826, _time = 1.6548e+09, train_seconds = 1641.8)
[2022-06-09 20:35:27,038][root][INFO] - Step 6172160 @ 4092.7 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 6172160, mean_episode_return = None, mean_episode_step = 3248.2, total_loss = -67.601, pg_loss = -77.736, baseline_loss = 14.755, entropy_loss = -4.6199, learner_queue_size = 32, _tick = 828, _time = 1.6548e+09, train_seconds = 1646.8)
[2022-06-09 20:35:32,042][root][INFO] - Step 6190080 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 6190080, mean_episode_return = 185.26, mean_episode_step = 2400.5, total_loss = 148.51, pg_loss = 77.23, baseline_loss = 76.477, entropy_loss = -5.193, learner_queue_size = 32, _tick = 834, _time = 1.6548e+09, train_seconds = 1651.8)
[2022-06-09 20:35:37,046][root][INFO] - Step 6208000 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 6208000, mean_episode_return = -7.957, mean_episode_step = 2539.0, total_loss = -63.885, pg_loss = -114.79, baseline_loss = 55.398, entropy_loss = -4.4977, learner_queue_size = 32, _tick = 840, _time = 1.6548e+09, train_seconds = 1656.9)
[2022-06-09 20:35:42,050][root][INFO] - Step 6228480 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 6228480, mean_episode_return = 64.332, mean_episode_step = 3112.7, total_loss = 18.195, pg_loss = -22.063, baseline_loss = 44.782, entropy_loss = -4.5238, learner_queue_size = 32, _tick = 846, _time = 1.6548e+09, train_seconds = 1661.9)
[2022-06-09 20:35:47,054][root][INFO] - Step 6246400 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 6246400, mean_episode_return = 34.51, mean_episode_step = 2087.7, total_loss = 182.02, pg_loss = 58.797, baseline_loss = 127.78, entropy_loss = -4.5561, learner_queue_size = 32, _tick = 850, _time = 1.6548e+09, train_seconds = 1666.9)
[2022-06-09 20:35:52,058][root][INFO] - Step 6264320 @ 3581.2 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 6264320, mean_episode_return = None, mean_episode_step = 3207.7, total_loss = 246.22, pg_loss = 131.47, baseline_loss = 119.31, entropy_loss = -4.568, learner_queue_size = 32, _tick = 852, _time = 1.6548e+09, train_seconds = 1671.9)
[2022-06-09 20:35:57,062][root][INFO] - Step 6284800 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 6284800, mean_episode_return = 19.54, mean_episode_step = 1929.5, total_loss = 549.99, pg_loss = 168.65, baseline_loss = 385.86, entropy_loss = -4.5207, learner_queue_size = 32, _tick = 856, _time = 1.6548e+09, train_seconds = 1676.9)
[2022-06-09 20:36:02,066][root][INFO] - Step 6302720 @ 3581.2 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 6302720, mean_episode_return = None, mean_episode_step = 2007.8, total_loss = -5.8682, pg_loss = -1.2036, baseline_loss = 3.0657, entropy_loss = -7.7303, learner_queue_size = 32, _tick = 860, _time = 1.6548e+09, train_seconds = 1681.9)
[2022-06-09 20:36:07,070][root][INFO] - Step 6320640 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 6320640, mean_episode_return = None, mean_episode_step = 2400.8, total_loss = -12.259, pg_loss = -14.866, baseline_loss = 9.5468, entropy_loss = -6.9402, learner_queue_size = 32, _tick = 866, _time = 1.6548e+09, train_seconds = 1686.9)
[2022-06-09 20:36:12,074][root][INFO] - Step 6341120 @ 4092.8 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 6341120, mean_episode_return = -22.22, mean_episode_step = 2383.9, total_loss = 133.0, pg_loss = 104.0, baseline_loss = 35.115, entropy_loss = -6.1169, learner_queue_size = 32, _tick = 874, _time = 1.6548e+09, train_seconds = 1691.9)
[2022-06-09 20:36:17,078][root][INFO] - Step 6359040 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 6359040, mean_episode_return = None, mean_episode_step = 2147.8, total_loss = 130.26, pg_loss = 90.143, baseline_loss = 45.043, entropy_loss = -4.9301, learner_queue_size = 32, _tick = 879, _time = 1.6548e+09, train_seconds = 1696.9)
[2022-06-09 20:36:22,082][root][INFO] - Step 6376960 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 6376960, mean_episode_return = None, mean_episode_step = 2344.6, total_loss = 21.962, pg_loss = 15.961, baseline_loss = 11.608, entropy_loss = -5.6072, learner_queue_size = 32, _tick = 881, _time = 1.6548e+09, train_seconds = 1701.9)
[2022-06-09 20:36:27,086][root][INFO] - Step 6397440 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 6397440, mean_episode_return = None, mean_episode_step = 1836.1, total_loss = 183.08, pg_loss = 102.54, baseline_loss = 86.024, entropy_loss = -5.4844, learner_queue_size = 32, _tick = 885, _time = 1.6548e+09, train_seconds = 1706.9)
[2022-06-09 20:36:32,090][root][INFO] - Step 6415360 @ 3581.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 6415360, mean_episode_return = 37.14, mean_episode_step = 1988.4, total_loss = 123.33, pg_loss = 74.834, baseline_loss = 54.324, entropy_loss = -5.8257, learner_queue_size = 32, _tick = 888, _time = 1.6548e+09, train_seconds = 1711.9)
[2022-06-09 20:36:37,094][root][INFO] - Step 6433280 @ 3581.1 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 6433280, mean_episode_return = None, mean_episode_step = 2847.8, total_loss = 133.26, pg_loss = 64.527, baseline_loss = 73.996, entropy_loss = -5.2648, learner_queue_size = 32, _tick = 891, _time = 1.6548e+09, train_seconds = 1716.9)
[2022-06-09 20:36:42,098][root][INFO] - Step 6451200 @ 3581.2 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 6451200, mean_episode_return = 24.911, mean_episode_step = 2435.3, total_loss = -8.9594, pg_loss = -55.746, baseline_loss = 51.846, entropy_loss = -5.0593, learner_queue_size = 32, _tick = 897, _time = 1.6548e+09, train_seconds = 1721.9)
[2022-06-09 20:36:47,102][root][INFO] - Step 6471680 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 6471680, mean_episode_return = None, mean_episode_step = 2487.5, total_loss = -51.109, pg_loss = -52.651, baseline_loss = 4.8476, entropy_loss = -3.3049, learner_queue_size = 32, _tick = 900, _time = 1.6548e+09, train_seconds = 1726.9)
[2022-06-09 20:36:52,106][root][INFO] - Step 6489600 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 6489600, mean_episode_return = -4.9202, mean_episode_step = 2303.2, total_loss = -57.205, pg_loss = -79.419, baseline_loss = 26.332, entropy_loss = -4.1183, learner_queue_size = 32, _tick = 902, _time = 1.6548e+09, train_seconds = 1731.9)
[2022-06-09 20:36:57,110][root][INFO] - Step 6507520 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 6507520, mean_episode_return = 81.28, mean_episode_step = 2028.0, total_loss = -111.46, pg_loss = -115.84, baseline_loss = 9.0152, entropy_loss = -4.628, learner_queue_size = 32, _tick = 906, _time = 1.6548e+09, train_seconds = 1736.9)
[2022-06-09 20:37:02,114][root][INFO] - Step 6528000 @ 4092.7 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 6528000, mean_episode_return = None, mean_episode_step = 2086.2, total_loss = -37.78, pg_loss = -49.565, baseline_loss = 16.015, entropy_loss = -4.2303, learner_queue_size = 32, _tick = 911, _time = 1.6548e+09, train_seconds = 1741.9)
[2022-06-09 20:37:07,118][root][INFO] - Step 6545920 @ 3581.0 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 6545920, mean_episode_return = None, mean_episode_step = 2843.6, total_loss = 4.3558, pg_loss = -10.494, baseline_loss = 19.858, entropy_loss = -5.0074, learner_queue_size = 32, _tick = 914, _time = 1.6548e+09, train_seconds = 1746.9)
[2022-06-09 20:37:12,122][root][INFO] - Step 6563840 @ 3581.2 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 6563840, mean_episode_return = None, mean_episode_step = 2444.2, total_loss = -15.32, pg_loss = -27.727, baseline_loss = 17.3, entropy_loss = -4.892, learner_queue_size = 32, _tick = 914, _time = 1.6548e+09, train_seconds = 1751.9)
[2022-06-09 20:37:17,126][root][INFO] - Step 6581760 @ 3581.1 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 6581760, mean_episode_return = 23.131, mean_episode_step = 2479.5, total_loss = -56.263, pg_loss = -74.741, baseline_loss = 23.179, entropy_loss = -4.7017, learner_queue_size = 32, _tick = 918, _time = 1.6548e+09, train_seconds = 1756.9)
[2022-06-09 20:37:22,130][root][INFO] - Step 6602240 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 6602240, mean_episode_return = None, mean_episode_step = 2478.1, total_loss = -62.014, pg_loss = -67.063, baseline_loss = 10.035, entropy_loss = -4.986, learner_queue_size = 32, _tick = 921, _time = 1.6548e+09, train_seconds = 1761.9)
[2022-06-09 20:37:27,134][root][INFO] - Step 6620160 @ 3581.1 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 6620160, mean_episode_return = None, mean_episode_step = 2959.8, total_loss = 196.6, pg_loss = 87.378, baseline_loss = 115.14, entropy_loss = -5.9175, learner_queue_size = 32, _tick = 923, _time = 1.6548e+09, train_seconds = 1766.9)
[2022-06-09 20:37:32,142][root][INFO] - Step 6638080 @ 3578.4 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 6638080, mean_episode_return = None, mean_episode_step = 2465.6, total_loss = 23.078, pg_loss = -1.1929, baseline_loss = 29.452, entropy_loss = -5.1812, learner_queue_size = 32, _tick = 924, _time = 1.6548e+09, train_seconds = 1771.9)
[2022-06-09 20:37:37,146][root][INFO] - Step 6656000 @ 3581.0 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 6656000, mean_episode_return = -13.24, mean_episode_step = 2264.7, total_loss = 48.211, pg_loss = -26.571, baseline_loss = 79.622, entropy_loss = -4.841, learner_queue_size = 32, _tick = 927, _time = 1.6548e+09, train_seconds = 1777.0)
[2022-06-09 20:37:42,150][root][INFO] - Step 6673920 @ 3581.2 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 6673920, mean_episode_return = None, mean_episode_step = 2292.4, total_loss = 141.24, pg_loss = 37.198, baseline_loss = 108.46, entropy_loss = -4.4124, learner_queue_size = 32, _tick = 933, _time = 1.6548e+09, train_seconds = 1782.0)
[2022-06-09 20:37:47,154][root][INFO] - Step 6694400 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 6694400, mean_episode_return = None, mean_episode_step = 2682.9, total_loss = 137.74, pg_loss = 85.607, baseline_loss = 57.474, entropy_loss = -5.3393, learner_queue_size = 32, _tick = 933, _time = 1.6548e+09, train_seconds = 1787.0)
[2022-06-09 20:37:52,158][root][INFO] - Step 6712320 @ 3581.0 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 6712320, mean_episode_return = None, mean_episode_step = 2368.2, total_loss = -6.7071, pg_loss = -23.783, baseline_loss = 21.442, entropy_loss = -4.3661, learner_queue_size = 32, _tick = 938, _time = 1.6548e+09, train_seconds = 1792.0)
[2022-06-09 20:37:57,162][root][INFO] - Step 6732800 @ 4092.9 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 6732800, mean_episode_return = None, mean_episode_step = 2162.5, total_loss = 164.03, pg_loss = 110.62, baseline_loss = 57.55, entropy_loss = -4.1417, learner_queue_size = 32, _tick = 938, _time = 1.6548e+09, train_seconds = 1797.0)
[2022-06-09 20:38:02,166][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-09 20:38:02,436][root][INFO] - Step 6750720 @ 3581.2 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (step = 6753280, mean_episode_return = None, mean_episode_step = 2345.4, total_loss = -3.3666, pg_loss = -6.1889, baseline_loss = 5.6455, entropy_loss = -2.8232, learner_queue_size = 32, _tick = 941, _time = 1.6548e+09, train_seconds = 1802.0)
[2022-06-09 20:38:07,438][root][INFO] - Step 6771200 @ 3884.7 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 6771200, mean_episode_return = 57.881, mean_episode_step = 2586.5, total_loss = 30.187, pg_loss = -5.4556, baseline_loss = 40.156, entropy_loss = -4.5136, learner_queue_size = 32, _tick = 943, _time = 1.6548e+09, train_seconds = 1807.2)
[2022-06-09 20:38:12,442][root][INFO] - Step 6789120 @ 3581.1 SPS. Inference batcher size: 81. Learner queue size: 32. Other stats: (step = 6789120, mean_episode_return = None, mean_episode_step = 2439.2, total_loss = -41.566, pg_loss = -36.377, baseline_loss = 2.2307, entropy_loss = -7.4201, learner_queue_size = 32, _tick = 946, _time = 1.6548e+09, train_seconds = 1812.2)
[2022-06-09 20:38:17,446][root][INFO] - Step 6809600 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 6809600, mean_episode_return = 110.03, mean_episode_step = 2931.7, total_loss = 55.226, pg_loss = 33.794, baseline_loss = 26.711, entropy_loss = -5.2796, learner_queue_size = 32, _tick = 953, _time = 1.6548e+09, train_seconds = 1817.3)
[2022-06-09 20:38:22,450][root][INFO] - Step 6827520 @ 3581.2 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 6827520, mean_episode_return = 68.772, mean_episode_step = 2369.4, total_loss = -5.1897, pg_loss = -8.7861, baseline_loss = 8.5071, entropy_loss = -4.9107, learner_queue_size = 32, _tick = 957, _time = 1.6548e+09, train_seconds = 1822.3)
[2022-06-09 20:38:27,454][root][INFO] - Step 6848000 @ 4092.7 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 6848000, mean_episode_return = 34.821, mean_episode_step = 2083.0, total_loss = 8.6799, pg_loss = 11.423, baseline_loss = 4.3779, entropy_loss = -7.1209, learner_queue_size = 32, _tick = 961, _time = 1.6548e+09, train_seconds = 1827.3)
[2022-06-09 20:38:32,458][root][INFO] - Step 6865920 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 6865920, mean_episode_return = 5.2395, mean_episode_step = 2273.9, total_loss = -12.246, pg_loss = -19.185, baseline_loss = 12.32, entropy_loss = -5.3804, learner_queue_size = 32, _tick = 965, _time = 1.6548e+09, train_seconds = 1832.3)
[2022-06-09 20:38:37,462][root][INFO] - Step 6883840 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 6883840, mean_episode_return = None, mean_episode_step = 2938.6, total_loss = -102.93, pg_loss = -99.263, baseline_loss = 3.1537, entropy_loss = -6.8196, learner_queue_size = 32, _tick = 968, _time = 1.6548e+09, train_seconds = 1837.3)
[2022-06-09 20:38:42,466][root][INFO] - Step 6904320 @ 4092.8 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 6904320, mean_episode_return = 30.24, mean_episode_step = 2167.1, total_loss = -45.288, pg_loss = -41.968, baseline_loss = 2.7031, entropy_loss = -6.0229, learner_queue_size = 32, _tick = 973, _time = 1.6548e+09, train_seconds = 1842.3)
[2022-06-09 20:38:47,471][root][INFO] - Step 6922240 @ 3580.3 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 6922240, mean_episode_return = 27.792, mean_episode_step = 2829.5, total_loss = 216.98, pg_loss = 142.23, baseline_loss = 80.317, entropy_loss = -5.5656, learner_queue_size = 32, _tick = 978, _time = 1.6548e+09, train_seconds = 1847.3)
[2022-06-09 20:38:52,474][root][INFO] - Step 6942720 @ 4093.6 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 6942720, mean_episode_return = None, mean_episode_step = 1795.6, total_loss = 325.22, pg_loss = 204.2, baseline_loss = 126.95, entropy_loss = -5.9351, learner_queue_size = 32, _tick = 980, _time = 1.6548e+09, train_seconds = 1852.3)
[2022-06-09 20:38:57,478][root][INFO] - Step 6960640 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 6960640, mean_episode_return = 112.11, mean_episode_step = 2313.7, total_loss = -15.56, pg_loss = -10.927, baseline_loss = 5.759, entropy_loss = -10.392, learner_queue_size = 32, _tick = 983, _time = 1.6548e+09, train_seconds = 1857.3)
[2022-06-09 20:39:02,482][root][INFO] - Step 6981120 @ 4092.7 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 6981120, mean_episode_return = 14.728, mean_episode_step = 2321.2, total_loss = 82.697, pg_loss = 59.112, baseline_loss = 33.084, entropy_loss = -9.499, learner_queue_size = 32, _tick = 989, _time = 1.6548e+09, train_seconds = 1862.3)
[2022-06-09 20:39:07,486][root][INFO] - Step 6999040 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 6999040, mean_episode_return = None, mean_episode_step = 2336.2, total_loss = 177.82, pg_loss = 141.67, baseline_loss = 44.307, entropy_loss = -8.1557, learner_queue_size = 32, _tick = 992, _time = 1.6548e+09, train_seconds = 1867.3)
[2022-06-09 20:39:12,490][root][INFO] - Step 7016960 @ 3581.2 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 7016960, mean_episode_return = None, mean_episode_step = 2205.0, total_loss = 100.1, pg_loss = 80.944, baseline_loss = 26.136, entropy_loss = -6.9845, learner_queue_size = 32, _tick = 993, _time = 1.6548e+09, train_seconds = 1872.3)
[2022-06-09 20:39:17,494][root][INFO] - Step 7037440 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 7037440, mean_episode_return = 45.21, mean_episode_step = 3454.4, total_loss = 285.27, pg_loss = 226.45, baseline_loss = 65.303, entropy_loss = -6.4858, learner_queue_size = 32, _tick = 999, _time = 1.6548e+09, train_seconds = 1877.3)
[2022-06-09 20:39:22,498][root][INFO] - Step 7055360 @ 3581.2 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 7055360, mean_episode_return = 103.26, mean_episode_step = 2341.7, total_loss = 180.77, pg_loss = 142.87, baseline_loss = 44.224, entropy_loss = -6.3158, learner_queue_size = 32, _tick = 1006, _time = 1.6548e+09, train_seconds = 1882.3)
[2022-06-09 20:39:27,502][root][INFO] - Step 7073280 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 7073280, mean_episode_return = 17.267, mean_episode_step = 1985.5, total_loss = 19.273, pg_loss = -9.87, baseline_loss = 33.777, entropy_loss = -4.6342, learner_queue_size = 32, _tick = 1011, _time = 1.6548e+09, train_seconds = 1887.3)
[2022-06-09 20:39:32,506][root][INFO] - Step 7093760 @ 4092.6 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 7093760, mean_episode_return = 39.639, mean_episode_step = 1950.1, total_loss = -23.002, pg_loss = -42.658, baseline_loss = 23.246, entropy_loss = -3.5908, learner_queue_size = 32, _tick = 1018, _time = 1.6548e+09, train_seconds = 1892.3)
[2022-06-09 20:39:37,510][root][INFO] - Step 7111680 @ 3581.2 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 7111680, mean_episode_return = 43.846, mean_episode_step = 1969.3, total_loss = 106.41, pg_loss = 31.921, baseline_loss = 77.415, entropy_loss = -2.9243, learner_queue_size = 32, _tick = 1021, _time = 1.6548e+09, train_seconds = 1897.3)
[2022-06-09 20:39:42,514][root][INFO] - Step 7129600 @ 3581.1 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 7129600, mean_episode_return = 75.07, mean_episode_step = 2454.4, total_loss = -40.443, pg_loss = -51.082, baseline_loss = 14.382, entropy_loss = -3.7432, learner_queue_size = 32, _tick = 1024, _time = 1.6548e+09, train_seconds = 1902.3)
[2022-06-09 20:39:47,520][root][INFO] - Step 7147520 @ 3579.4 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 7147520, mean_episode_return = 23.569, mean_episode_step = 2455.7, total_loss = 117.18, pg_loss = 67.964, baseline_loss = 53.973, entropy_loss = -4.7609, learner_queue_size = 32, _tick = 1026, _time = 1.6548e+09, train_seconds = 1907.3)
[2022-06-09 20:39:52,526][root][INFO] - Step 7168000 @ 4091.5 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 7168000, mean_episode_return = 91.611, mean_episode_step = 3315.3, total_loss = -36.364, pg_loss = -44.305, baseline_loss = 12.063, entropy_loss = -4.1215, learner_queue_size = 32, _tick = 1032, _time = 1.6548e+09, train_seconds = 1912.3)
[2022-06-09 20:39:57,530][root][INFO] - Step 7185920 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 7185920, mean_episode_return = None, mean_episode_step = 2426.5, total_loss = 223.48, pg_loss = 155.14, baseline_loss = 72.083, entropy_loss = -3.7459, learner_queue_size = 32, _tick = 1037, _time = 1.6548e+09, train_seconds = 1917.3)
[2022-06-09 20:40:02,534][root][INFO] - Step 7206400 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 7206400, mean_episode_return = None, mean_episode_step = 1754.2, total_loss = 149.26, pg_loss = 58.716, baseline_loss = 94.078, entropy_loss = -3.5294, learner_queue_size = 32, _tick = 1039, _time = 1.6548e+09, train_seconds = 1922.3)
[2022-06-09 20:40:07,538][root][INFO] - Step 7224320 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 7224320, mean_episode_return = None, mean_episode_step = 2437.6, total_loss = 201.49, pg_loss = 94.115, baseline_loss = 111.08, entropy_loss = -3.7051, learner_queue_size = 32, _tick = 1041, _time = 1.6548e+09, train_seconds = 1927.3)
[2022-06-09 20:40:12,542][root][INFO] - Step 7244800 @ 4092.4 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 7244800, mean_episode_return = None, mean_episode_step = 1850.4, total_loss = 63.182, pg_loss = 26.468, baseline_loss = 40.339, entropy_loss = -3.6248, learner_queue_size = 32, _tick = 1043, _time = 1.6548e+09, train_seconds = 1932.4)
[2022-06-09 20:40:17,546][root][INFO] - Step 7262720 @ 3581.4 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 7262720, mean_episode_return = 69.731, mean_episode_step = 3005.3, total_loss = -8.9917, pg_loss = -40.526, baseline_loss = 34.947, entropy_loss = -3.4125, learner_queue_size = 32, _tick = 1047, _time = 1.6548e+09, train_seconds = 1937.4)
[2022-06-09 20:40:22,550][root][INFO] - Step 7280640 @ 3581.1 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 7280640, mean_episode_return = None, mean_episode_step = 2758.6, total_loss = -24.572, pg_loss = -29.108, baseline_loss = 7.7839, entropy_loss = -3.2483, learner_queue_size = 32, _tick = 1050, _time = 1.6548e+09, train_seconds = 1942.4)
[2022-06-09 20:40:27,554][root][INFO] - Step 7298560 @ 3581.2 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 7298560, mean_episode_return = 50.09, mean_episode_step = 1984.8, total_loss = 127.73, pg_loss = 24.506, baseline_loss = 106.67, entropy_loss = -3.4484, learner_queue_size = 32, _tick = 1053, _time = 1.6548e+09, train_seconds = 1947.4)
[2022-06-09 20:40:32,558][root][INFO] - Step 7319040 @ 4092.7 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 7319040, mean_episode_return = None, mean_episode_step = 2418.2, total_loss = -37.275, pg_loss = -48.943, baseline_loss = 14.373, entropy_loss = -2.7061, learner_queue_size = 32, _tick = 1055, _time = 1.6548e+09, train_seconds = 1952.4)
[2022-06-09 20:40:37,562][root][INFO] - Step 7336960 @ 3580.8 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (step = 7336960, mean_episode_return = None, mean_episode_step = 2454.6, total_loss = -112.16, pg_loss = -112.71, baseline_loss = 3.0936, entropy_loss = -2.5431, learner_queue_size = 32, _tick = 1058, _time = 1.6548e+09, train_seconds = 1957.4)
[2022-06-09 20:40:42,566][root][INFO] - Step 7357440 @ 4093.2 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 7357440, mean_episode_return = None, mean_episode_step = 3227.9, total_loss = -21.657, pg_loss = -19.413, baseline_loss = 1.0059, entropy_loss = -3.2503, learner_queue_size = 32, _tick = 1059, _time = 1.6548e+09, train_seconds = 1962.4)
[2022-06-09 20:40:47,570][root][INFO] - Step 7375360 @ 3581.1 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 7375360, mean_episode_return = -7.4906, mean_episode_step = 2797.6, total_loss = 29.032, pg_loss = -2.2342, baseline_loss = 35.748, entropy_loss = -4.4814, learner_queue_size = 32, _tick = 1063, _time = 1.6548e+09, train_seconds = 1967.4)
[2022-06-09 20:40:52,575][root][INFO] - Step 7393280 @ 3580.7 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (step = 7393280, mean_episode_return = 39.07, mean_episode_step = 2445.9, total_loss = 234.62, pg_loss = 152.91, baseline_loss = 88.005, entropy_loss = -6.2908, learner_queue_size = 32, _tick = 1067, _time = 1.6548e+09, train_seconds = 1972.4)
[2022-06-09 20:40:57,578][root][INFO] - Step 7413760 @ 4093.3 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 7413760, mean_episode_return = 47.411, mean_episode_step = 2346.4, total_loss = -5.5675, pg_loss = -15.909, baseline_loss = 17.006, entropy_loss = -6.6644, learner_queue_size = 32, _tick = 1073, _time = 1.6548e+09, train_seconds = 1977.4)
[2022-06-09 20:41:02,582][root][INFO] - Step 7431680 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 7431680, mean_episode_return = 93.494, mean_episode_step = 2240.2, total_loss = -92.62, pg_loss = -88.697, baseline_loss = 2.4218, entropy_loss = -6.3451, learner_queue_size = 32, _tick = 1080, _time = 1.6548e+09, train_seconds = 1982.4)
[2022-06-09 20:41:07,587][root][INFO] - Step 7449600 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 7449600, mean_episode_return = 12.814, mean_episode_step = 1889.9, total_loss = 168.37, pg_loss = 103.32, baseline_loss = 70.907, entropy_loss = -5.8576, learner_queue_size = 32, _tick = 1085, _time = 1.6548e+09, train_seconds = 1987.4)
[2022-06-09 20:41:12,590][root][INFO] - Step 7470080 @ 4092.8 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 7470080, mean_episode_return = None, mean_episode_step = 2979.3, total_loss = -26.229, pg_loss = -39.377, baseline_loss = 18.55, entropy_loss = -5.4011, learner_queue_size = 32, _tick = 1089, _time = 1.6548e+09, train_seconds = 1992.4)
[2022-06-09 20:41:17,594][root][INFO] - Step 7488000 @ 3581.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 7488000, mean_episode_return = None, mean_episode_step = 2365.6, total_loss = 18.31, pg_loss = -8.239, baseline_loss = 32.147, entropy_loss = -5.598, learner_queue_size = 32, _tick = 1092, _time = 1.6548e+09, train_seconds = 1997.4)
[2022-06-09 20:41:22,598][root][INFO] - Step 7505920 @ 3581.2 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 7505920, mean_episode_return = 69.572, mean_episode_step = 1974.4, total_loss = 224.25, pg_loss = 131.41, baseline_loss = 98.552, entropy_loss = -5.7095, learner_queue_size = 32, _tick = 1097, _time = 1.6548e+09, train_seconds = 2002.4)
[2022-06-09 20:41:27,602][root][INFO] - Step 7526400 @ 4092.7 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 7526400, mean_episode_return = None, mean_episode_step = 2557.1, total_loss = 121.69, pg_loss = 86.122, baseline_loss = 40.642, entropy_loss = -5.0748, learner_queue_size = 32, _tick = 1100, _time = 1.6548e+09, train_seconds = 2007.4)
[2022-06-09 20:41:32,606][root][INFO] - Step 7544320 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 7544320, mean_episode_return = 50.312, mean_episode_step = 2140.8, total_loss = -42.19, pg_loss = -98.009, baseline_loss = 61.037, entropy_loss = -5.2173, learner_queue_size = 32, _tick = 1107, _time = 1.6548e+09, train_seconds = 2012.4)
[2022-06-09 20:41:37,610][root][INFO] - Step 7557120 @ 2558.0 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 7557120, mean_episode_return = None, mean_episode_step = 2348.2, total_loss = -64.105, pg_loss = -78.188, baseline_loss = 18.783, entropy_loss = -4.7, learner_queue_size = 32, _tick = 1109, _time = 1.6548e+09, train_seconds = 2017.4)
[2022-06-09 20:41:42,614][root][INFO] - Step 7572480 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 7572480, mean_episode_return = None, mean_episode_step = 2276.1, total_loss = 598.25, pg_loss = 326.86, baseline_loss = 276.36, entropy_loss = -4.9608, learner_queue_size = 32, _tick = 1111, _time = 1.6548e+09, train_seconds = 2022.4)
[2022-06-09 20:41:47,618][root][INFO] - Step 7592960 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 7592960, mean_episode_return = None, mean_episode_step = 1709.6, total_loss = -1.3707, pg_loss = -10.932, baseline_loss = 13.969, entropy_loss = -4.407, learner_queue_size = 32, _tick = 1113, _time = 1.6548e+09, train_seconds = 2027.4)
[2022-06-09 20:41:52,623][root][INFO] - Step 7610880 @ 3580.4 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 7610880, mean_episode_return = None, mean_episode_step = 1907.2, total_loss = 317.52, pg_loss = 209.26, baseline_loss = 113.03, entropy_loss = -4.7745, learner_queue_size = 32, _tick = 1114, _time = 1.6548e+09, train_seconds = 2032.4)
[2022-06-09 20:41:57,626][root][INFO] - Step 7628800 @ 3582.0 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 7628800, mean_episode_return = None, mean_episode_step = 2136.0, total_loss = 198.33, pg_loss = 120.8, baseline_loss = 82.175, entropy_loss = -4.6457, learner_queue_size = 32, _tick = 1114, _time = 1.6548e+09, train_seconds = 2037.4)
[2022-06-09 20:42:02,630][root][INFO] - Step 7649280 @ 4092.7 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 7649280, mean_episode_return = None, mean_episode_step = 1940.0, total_loss = -138.48, pg_loss = -137.71, baseline_loss = 3.922, entropy_loss = -4.6862, learner_queue_size = 32, _tick = 1115, _time = 1.6548e+09, train_seconds = 2042.4)
[2022-06-09 20:42:07,634][root][INFO] - Step 7667200 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 7667200, mean_episode_return = -21.521, mean_episode_step = 2221.1, total_loss = -21.913, pg_loss = -39.048, baseline_loss = 22.587, entropy_loss = -5.4525, learner_queue_size = 32, _tick = 1116, _time = 1.6548e+09, train_seconds = 2047.4)
[2022-06-09 20:42:12,638][root][INFO] - Step 7687680 @ 4092.8 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 7687680, mean_episode_return = -16.531, mean_episode_step = 2121.1, total_loss = 14.403, pg_loss = -17.462, baseline_loss = 36.758, entropy_loss = -4.8925, learner_queue_size = 32, _tick = 1122, _time = 1.6548e+09, train_seconds = 2052.4)
[2022-06-09 20:42:17,642][root][INFO] - Step 7705600 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 7705600, mean_episode_return = 17.946, mean_episode_step = 2270.1, total_loss = -17.45, pg_loss = -32.929, baseline_loss = 20.887, entropy_loss = -5.4084, learner_queue_size = 32, _tick = 1126, _time = 1.6548e+09, train_seconds = 2057.4)
[2022-06-09 20:42:22,646][root][INFO] - Step 7723520 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 7723520, mean_episode_return = 57.09, mean_episode_step = 2133.3, total_loss = 298.38, pg_loss = 205.47, baseline_loss = 97.74, entropy_loss = -4.8212, learner_queue_size = 32, _tick = 1132, _time = 1.6548e+09, train_seconds = 2062.5)
[2022-06-09 20:42:27,650][root][INFO] - Step 7744000 @ 4092.7 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 7744000, mean_episode_return = 20.43, mean_episode_step = 2075.8, total_loss = 79.361, pg_loss = 42.456, baseline_loss = 41.937, entropy_loss = -5.0316, learner_queue_size = 32, _tick = 1137, _time = 1.6548e+09, train_seconds = 2067.5)
[2022-06-09 20:42:32,654][root][INFO] - Step 7761920 @ 3581.0 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 7761920, mean_episode_return = None, mean_episode_step = 2084.4, total_loss = -22.189, pg_loss = -40.956, baseline_loss = 23.614, entropy_loss = -4.8475, learner_queue_size = 32, _tick = 1138, _time = 1.6548e+09, train_seconds = 2072.5)
[2022-06-09 20:42:37,658][root][INFO] - Step 7779840 @ 3581.2 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 7779840, mean_episode_return = 52.594, mean_episode_step = 1966.5, total_loss = 14.413, pg_loss = -17.767, baseline_loss = 36.545, entropy_loss = -4.365, learner_queue_size = 32, _tick = 1140, _time = 1.6548e+09, train_seconds = 2077.5)
[2022-06-09 20:42:42,662][root][INFO] - Step 7797760 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 7797760, mean_episode_return = None, mean_episode_step = 2865.7, total_loss = 133.1, pg_loss = 79.856, baseline_loss = 58.106, entropy_loss = -4.8645, learner_queue_size = 32, _tick = 1142, _time = 1.6548e+09, train_seconds = 2082.5)
[2022-06-09 20:42:47,666][root][INFO] - Step 7818240 @ 4092.7 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 7818240, mean_episode_return = None, mean_episode_step = 2606.6, total_loss = -70.855, pg_loss = -69.586, baseline_loss = 4.113, entropy_loss = -5.3817, learner_queue_size = 32, _tick = 1144, _time = 1.6548e+09, train_seconds = 2087.5)
[2022-06-09 20:42:52,671][root][INFO] - Step 7836160 @ 3580.8 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 7836160, mean_episode_return = None, mean_episode_step = 2355.9, total_loss = 153.11, pg_loss = 125.94, baseline_loss = 32.759, entropy_loss = -5.587, learner_queue_size = 32, _tick = 1149, _time = 1.6548e+09, train_seconds = 2092.5)
[2022-06-09 20:42:57,674][root][INFO] - Step 7854080 @ 3581.5 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (step = 7854080, mean_episode_return = 78.699, mean_episode_step = 2021.1, total_loss = 429.72, pg_loss = 316.78, baseline_loss = 118.43, entropy_loss = -5.49, learner_queue_size = 32, _tick = 1155, _time = 1.6548e+09, train_seconds = 2097.5)
[2022-06-09 20:43:02,678][root][INFO] - Step 7874560 @ 4092.6 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 7874560, mean_episode_return = 88.831, mean_episode_step = 1987.3, total_loss = 148.82, pg_loss = 67.686, baseline_loss = 86.257, entropy_loss = -5.1229, learner_queue_size = 32, _tick = 1162, _time = 1.6548e+09, train_seconds = 2102.5)
[2022-06-09 20:43:07,682][root][INFO] - Step 7892480 @ 3581.2 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 7892480, mean_episode_return = 42.14, mean_episode_step = 2486.1, total_loss = 441.23, pg_loss = 227.23, baseline_loss = 219.02, entropy_loss = -5.0252, learner_queue_size = 32, _tick = 1166, _time = 1.6548e+09, train_seconds = 2107.5)
[2022-06-09 20:43:12,686][root][INFO] - Step 7910400 @ 3581.2 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 7910400, mean_episode_return = -26.571, mean_episode_step = 2202.5, total_loss = -39.5, pg_loss = -55.069, baseline_loss = 20.329, entropy_loss = -4.7599, learner_queue_size = 32, _tick = 1169, _time = 1.6548e+09, train_seconds = 2112.5)
[2022-06-09 20:43:17,690][root][INFO] - Step 7930880 @ 4092.7 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (step = 7930880, mean_episode_return = 20.031, mean_episode_step = 1772.6, total_loss = -42.822, pg_loss = -73.034, baseline_loss = 35.317, entropy_loss = -5.1056, learner_queue_size = 32, _tick = 1175, _time = 1.6548e+09, train_seconds = 2117.5)
[2022-06-09 20:43:22,694][root][INFO] - Step 7948800 @ 3581.1 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (step = 7948800, mean_episode_return = 22.751, mean_episode_step = 2043.6, total_loss = 24.019, pg_loss = -56.67, baseline_loss = 85.429, entropy_loss = -4.7398, learner_queue_size = 32, _tick = 1178, _time = 1.6548e+09, train_seconds = 2122.5)
[2022-06-09 20:43:27,698][root][INFO] - Step 7969280 @ 4092.6 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 7969280, mean_episode_return = 34.322, mean_episode_step = 2734.2, total_loss = 50.878, pg_loss = 16.724, baseline_loss = 39.911, entropy_loss = -5.7564, learner_queue_size = 32, _tick = 1181, _time = 1.6548e+09, train_seconds = 2127.5)
[2022-06-09 20:43:32,702][root][INFO] - Step 7984640 @ 3069.6 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 7984640, mean_episode_return = None, mean_episode_step = 2482.2, total_loss = -91.691, pg_loss = -92.375, baseline_loss = 6.5698, entropy_loss = -5.8856, learner_queue_size = 32, _tick = 1182, _time = 1.6548e+09, train_seconds = 2132.5)
[2022-06-09 20:43:37,706][root][INFO] - Step 8002560 @ 3581.2 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 8002560, mean_episode_return = 57.054, mean_episode_step = 2415.7, total_loss = -120.88, pg_loss = -140.45, baseline_loss = 25.616, entropy_loss = -6.0484, learner_queue_size = 32, _tick = 1187, _time = 1.6548e+09, train_seconds = 2137.5)
[2022-06-09 20:43:42,710][root][INFO] - Step 8020480 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 8020480, mean_episode_return = 51.86, mean_episode_step = 1699.5, total_loss = -67.816, pg_loss = -75.241, baseline_loss = 13.456, entropy_loss = -6.0307, learner_queue_size = 32, _tick = 1191, _time = 1.6548e+09, train_seconds = 2142.5)
[2022-06-09 20:43:47,714][root][INFO] - Step 8040960 @ 4092.7 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 8040960, mean_episode_return = 38.471, mean_episode_step = 2381.2, total_loss = 142.27, pg_loss = 80.83, baseline_loss = 67.476, entropy_loss = -6.0382, learner_queue_size = 32, _tick = 1196, _time = 1.6548e+09, train_seconds = 2147.5)
[2022-06-09 20:43:52,718][root][INFO] - Step 8058880 @ 3581.1 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 8058880, mean_episode_return = 113.03, mean_episode_step = 2055.2, total_loss = 147.08, pg_loss = 84.373, baseline_loss = 68.345, entropy_loss = -5.6407, learner_queue_size = 32, _tick = 1201, _time = 1.6548e+09, train_seconds = 2152.5)
[2022-06-09 20:43:57,724][root][INFO] - Step 8076800 @ 3579.6 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (step = 8076800, mean_episode_return = -6.1904, mean_episode_step = 2228.0, total_loss = 162.88, pg_loss = 95.82, baseline_loss = 72.257, entropy_loss = -5.1996, learner_queue_size = 32, _tick = 1208, _time = 1.6548e+09, train_seconds = 2157.5)
[2022-06-09 20:44:02,726][root][INFO] - Step 8094720 @ 3582.7 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 8094720, mean_episode_return = None, mean_episode_step = 2560.2, total_loss = 63.295, pg_loss = 31.354, baseline_loss = 37.06, entropy_loss = -5.1183, learner_queue_size = 32, _tick = 1211, _time = 1.6548e+09, train_seconds = 2162.5)
[2022-06-09 20:44:07,730][root][INFO] - Step 8115200 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 8115200, mean_episode_return = None, mean_episode_step = 2062.2, total_loss = 46.2, pg_loss = 15.356, baseline_loss = 36.499, entropy_loss = -5.6546, learner_queue_size = 32, _tick = 1216, _time = 1.6548e+09, train_seconds = 2167.5)
[2022-06-09 20:44:12,734][root][INFO] - Step 8133120 @ 3581.2 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 8133120, mean_episode_return = None, mean_episode_step = 2304.2, total_loss = -82.063, pg_loss = -81.544, baseline_loss = 4.5019, entropy_loss = -5.0203, learner_queue_size = 32, _tick = 1218, _time = 1.6548e+09, train_seconds = 2172.5)
[2022-06-09 20:44:17,738][root][INFO] - Step 8151040 @ 3581.1 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (step = 8151040, mean_episode_return = -3.755, mean_episode_step = 2634.9, total_loss = -31.051, pg_loss = -45.611, baseline_loss = 20.585, entropy_loss = -6.0251, learner_queue_size = 32, _tick = 1225, _time = 1.6548e+09, train_seconds = 2177.5)
[2022-06-09 20:44:22,742][root][INFO] - Step 8171520 @ 4092.7 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 8171520, mean_episode_return = 91.162, mean_episode_step = 2035.3, total_loss = 122.88, pg_loss = 73.231, baseline_loss = 55.967, entropy_loss = -6.3176, learner_queue_size = 32, _tick = 1229, _time = 1.6548e+09, train_seconds = 2182.5)
[2022-06-09 20:44:27,746][root][INFO] - Step 8189440 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 8189440, mean_episode_return = None, mean_episode_step = 1878.9, total_loss = 56.584, pg_loss = 39.987, baseline_loss = 22.794, entropy_loss = -6.1972, learner_queue_size = 32, _tick = 1231, _time = 1.6548e+09, train_seconds = 2187.6)
[2022-06-09 20:44:32,750][root][INFO] - Step 8209920 @ 4092.7 SPS. Inference batcher size: 79. Learner queue size: 32. Other stats: (step = 8209920, mean_episode_return = 22.78, mean_episode_step = 2222.3, total_loss = 121.4, pg_loss = 85.328, baseline_loss = 41.791, entropy_loss = -5.7161, learner_queue_size = 32, _tick = 1237, _time = 1.6548e+09, train_seconds = 2192.6)
[2022-06-09 20:44:37,754][root][INFO] - Step 8227840 @ 3580.9 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 8227840, mean_episode_return = None, mean_episode_step = 1860.5, total_loss = -47.87, pg_loss = -51.377, baseline_loss = 9.1587, entropy_loss = -5.6518, learner_queue_size = 32, _tick = 1243, _time = 1.6548e+09, train_seconds = 2197.6)
[2022-06-09 20:44:42,758][root][INFO] - Step 8245760 @ 3581.4 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 8245760, mean_episode_return = 39.351, mean_episode_step = 2218.5, total_loss = -1.4591, pg_loss = -14.162, baseline_loss = 19.119, entropy_loss = -6.4169, learner_queue_size = 32, _tick = 1250, _time = 1.6548e+09, train_seconds = 2202.6)
[2022-06-09 20:44:47,762][root][INFO] - Step 8266240 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 8266240, mean_episode_return = 48.802, mean_episode_step = 1900.1, total_loss = 356.27, pg_loss = 259.07, baseline_loss = 102.99, entropy_loss = -5.7875, learner_queue_size = 32, _tick = 1256, _time = 1.6548e+09, train_seconds = 2207.6)
[2022-06-09 20:44:52,766][root][INFO] - Step 8284160 @ 3581.2 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 8284160, mean_episode_return = 22.181, mean_episode_step = 1983.9, total_loss = -109.95, pg_loss = -115.19, baseline_loss = 10.627, entropy_loss = -5.3914, learner_queue_size = 32, _tick = 1262, _time = 1.6548e+09, train_seconds = 2212.6)
[2022-06-09 20:44:57,770][root][INFO] - Step 8299520 @ 3069.6 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 8299520, mean_episode_return = None, mean_episode_step = 2044.7, total_loss = 471.93, pg_loss = 320.8, baseline_loss = 157.1, entropy_loss = -5.9734, learner_queue_size = 32, _tick = 1264, _time = 1.6548e+09, train_seconds = 2217.6)
[2022-06-09 20:45:02,778][root][INFO] - Step 8317440 @ 3578.2 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 8317440, mean_episode_return = 45.895, mean_episode_step = 1847.4, total_loss = 408.74, pg_loss = 274.93, baseline_loss = 139.57, entropy_loss = -5.7586, learner_queue_size = 32, _tick = 1269, _time = 1.6548e+09, train_seconds = 2222.6)
[2022-06-09 20:45:07,782][root][INFO] - Step 8335360 @ 3581.1 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 8335360, mean_episode_return = 3.3494, mean_episode_step = 1476.5, total_loss = 105.47, pg_loss = 40.382, baseline_loss = 70.281, entropy_loss = -5.191, learner_queue_size = 32, _tick = 1274, _time = 1.6548e+09, train_seconds = 2227.6)
[2022-06-09 20:45:12,786][root][INFO] - Step 8355840 @ 4092.7 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 8355840, mean_episode_return = None, mean_episode_step = 2025.7, total_loss = 24.81, pg_loss = -1.1276, baseline_loss = 31.218, entropy_loss = -5.28, learner_queue_size = 32, _tick = 1278, _time = 1.6548e+09, train_seconds = 2232.6)
[2022-06-09 20:45:17,790][root][INFO] - Step 8373760 @ 3581.0 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 8373760, mean_episode_return = 42.419, mean_episode_step = 1731.2, total_loss = -122.64, pg_loss = -129.09, baseline_loss = 12.341, entropy_loss = -5.8862, learner_queue_size = 32, _tick = 1282, _time = 1.6548e+09, train_seconds = 2237.6)
[2022-06-09 20:45:22,794][root][INFO] - Step 8391680 @ 3581.1 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 8391680, mean_episode_return = None, mean_episode_step = 1704.3, total_loss = 184.03, pg_loss = 115.92, baseline_loss = 73.969, entropy_loss = -5.862, learner_queue_size = 32, _tick = 1287, _time = 1.6548e+09, train_seconds = 2242.6)
[2022-06-09 20:45:27,802][root][INFO] - Step 8409600 @ 3578.4 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 8409600, mean_episode_return = None, mean_episode_step = 1875.2, total_loss = 48.754, pg_loss = 17.515, baseline_loss = 37.006, entropy_loss = -5.7657, learner_queue_size = 32, _tick = 1288, _time = 1.6548e+09, train_seconds = 2247.6)
[2022-06-09 20:45:32,806][root][INFO] - Step 8427520 @ 3581.2 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (step = 8427520, mean_episode_return = 70.71, mean_episode_step = 2334.7, total_loss = -97.297, pg_loss = -127.21, baseline_loss = 35.655, entropy_loss = -5.7385, learner_queue_size = 32, _tick = 1291, _time = 1.6548e+09, train_seconds = 2252.6)
[2022-06-09 20:45:37,810][root][INFO] - Step 8448000 @ 4092.7 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 8448000, mean_episode_return = None, mean_episode_step = 1949.7, total_loss = 110.48, pg_loss = 64.721, baseline_loss = 50.916, entropy_loss = -5.1605, learner_queue_size = 32, _tick = 1293, _time = 1.6548e+09, train_seconds = 2257.6)
[2022-06-09 20:45:42,814][root][INFO] - Step 8465920 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 8465920, mean_episode_return = None, mean_episode_step = 1548.5, total_loss = 134.8, pg_loss = 84.894, baseline_loss = 55.499, entropy_loss = -5.5919, learner_queue_size = 32, _tick = 1295, _time = 1.6548e+09, train_seconds = 2262.6)
[2022-06-09 20:45:47,818][root][INFO] - Step 8483840 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 8483840, mean_episode_return = None, mean_episode_step = 1687.4, total_loss = 278.72, pg_loss = 214.02, baseline_loss = 70.293, entropy_loss = -5.5987, learner_queue_size = 32, _tick = 1297, _time = 1.6548e+09, train_seconds = 2267.6)
[2022-06-09 20:45:52,822][root][INFO] - Step 8504320 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 8504320, mean_episode_return = -5.0503, mean_episode_step = 2297.0, total_loss = 67.989, pg_loss = -2.0617, baseline_loss = 75.434, entropy_loss = -5.3826, learner_queue_size = 32, _tick = 1301, _time = 1.6548e+09, train_seconds = 2272.6)
[2022-06-09 20:45:57,826][root][INFO] - Step 8522240 @ 3581.1 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 8522240, mean_episode_return = None, mean_episode_step = 2885.4, total_loss = -80.571, pg_loss = -91.625, baseline_loss = 16.351, entropy_loss = -5.2976, learner_queue_size = 32, _tick = 1303, _time = 1.6548e+09, train_seconds = 2277.6)
[2022-06-09 20:46:02,830][root][INFO] - Step 8540160 @ 3581.1 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (step = 8540160, mean_episode_return = -5.1904, mean_episode_step = 1831.5, total_loss = 497.25, pg_loss = 240.17, baseline_loss = 262.3, entropy_loss = -5.2191, learner_queue_size = 32, _tick = 1307, _time = 1.6548e+09, train_seconds = 2282.6)
[2022-06-09 20:46:07,834][root][INFO] - Step 8558080 @ 3581.3 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 8558080, mean_episode_return = None, mean_episode_step = 1906.9, total_loss = -2.7172, pg_loss = -28.662, baseline_loss = 31.498, entropy_loss = -5.5532, learner_queue_size = 32, _tick = 1310, _time = 1.6548e+09, train_seconds = 2287.6)
[2022-06-09 20:46:12,838][root][INFO] - Step 8578560 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 8578560, mean_episode_return = None, mean_episode_step = 2137.7, total_loss = 70.415, pg_loss = 14.557, baseline_loss = 61.415, entropy_loss = -5.5573, learner_queue_size = 32, _tick = 1313, _time = 1.6548e+09, train_seconds = 2292.6)
[2022-06-09 20:46:17,842][root][INFO] - Step 8596480 @ 3581.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 8596480, mean_episode_return = None, mean_episode_step = 2402.2, total_loss = 23.414, pg_loss = -0.38085, baseline_loss = 29.283, entropy_loss = -5.4883, learner_queue_size = 32, _tick = 1313, _time = 1.6548e+09, train_seconds = 2297.6)
[2022-06-09 20:46:22,846][root][INFO] - Step 8614400 @ 3581.1 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 8614400, mean_episode_return = None, mean_episode_step = 2479.5, total_loss = 471.75, pg_loss = 306.37, baseline_loss = 171.12, entropy_loss = -5.7426, learner_queue_size = 32, _tick = 1316, _time = 1.6548e+09, train_seconds = 2302.7)
[2022-06-09 20:46:27,850][root][INFO] - Step 8634880 @ 4092.3 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 8634880, mean_episode_return = 76.191, mean_episode_step = 2029.5, total_loss = -103.42, pg_loss = -100.5, baseline_loss = 2.9308, entropy_loss = -5.848, learner_queue_size = 32, _tick = 1320, _time = 1.6548e+09, train_seconds = 2307.7)
[2022-06-09 20:46:32,854][root][INFO] - Step 8652800 @ 3581.5 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (step = 8652800, mean_episode_return = 69.01, mean_episode_step = 2413.4, total_loss = -116.41, pg_loss = -134.73, baseline_loss = 24.061, entropy_loss = -5.746, learner_queue_size = 32, _tick = 1324, _time = 1.6548e+09, train_seconds = 2312.7)
[2022-06-09 20:46:37,858][root][INFO] - Step 8673280 @ 4092.7 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 8673280, mean_episode_return = 13.95, mean_episode_step = 2320.9, total_loss = 22.674, pg_loss = -0.56575, baseline_loss = 28.645, entropy_loss = -5.4053, learner_queue_size = 32, _tick = 1330, _time = 1.6548e+09, train_seconds = 2317.7)
[2022-06-09 20:46:42,862][root][INFO] - Step 8691200 @ 3581.1 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 8691200, mean_episode_return = None, mean_episode_step = 2504.7, total_loss = -132.75, pg_loss = -130.66, baseline_loss = 3.6117, entropy_loss = -5.6991, learner_queue_size = 32, _tick = 1334, _time = 1.6548e+09, train_seconds = 2322.7)
[2022-06-09 20:46:47,866][root][INFO] - Step 8704000 @ 2558.0 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 8704000, mean_episode_return = 44.312, mean_episode_step = 2227.8, total_loss = -180.48, pg_loss = -181.55, baseline_loss = 6.9704, entropy_loss = -5.9029, learner_queue_size = 32, _tick = 1338, _time = 1.6548e+09, train_seconds = 2327.7)
[2022-06-09 20:46:52,870][root][INFO] - Step 8724480 @ 4092.6 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 8724480, mean_episode_return = 133.19, mean_episode_step = 2303.9, total_loss = -303.52, pg_loss = -309.49, baseline_loss = 11.962, entropy_loss = -5.9902, learner_queue_size = 32, _tick = 1341, _time = 1.6548e+09, train_seconds = 2332.7)
[2022-06-09 20:46:57,874][root][INFO] - Step 8742400 @ 3581.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 8742400, mean_episode_return = 49.125, mean_episode_step = 2012.9, total_loss = -31.81, pg_loss = -46.865, baseline_loss = 20.309, entropy_loss = -5.2536, learner_queue_size = 32, _tick = 1346, _time = 1.6548e+09, train_seconds = 2337.7)
[2022-06-09 20:47:02,878][root][INFO] - Step 8760320 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 8760320, mean_episode_return = 107.8, mean_episode_step = 2163.4, total_loss = -62.875, pg_loss = -87.045, baseline_loss = 29.84, entropy_loss = -5.6695, learner_queue_size = 32, _tick = 1349, _time = 1.6548e+09, train_seconds = 2342.7)
[2022-06-09 20:47:07,882][root][INFO] - Step 8780800 @ 4092.8 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 8780800, mean_episode_return = None, mean_episode_step = 1579.1, total_loss = 270.46, pg_loss = 182.81, baseline_loss = 92.93, entropy_loss = -5.279, learner_queue_size = 32, _tick = 1352, _time = 1.6548e+09, train_seconds = 2347.7)
[2022-06-09 20:47:12,886][root][INFO] - Step 8798720 @ 3581.1 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 8798720, mean_episode_return = 6.9397, mean_episode_step = 1591.6, total_loss = 284.53, pg_loss = 146.49, baseline_loss = 142.9, entropy_loss = -4.8599, learner_queue_size = 32, _tick = 1357, _time = 1.6548e+09, train_seconds = 2352.7)
[2022-06-09 20:47:17,890][root][INFO] - Step 8816640 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 8816640, mean_episode_return = -0.78035, mean_episode_step = 2048.1, total_loss = -81.951, pg_loss = -90.583, baseline_loss = 13.981, entropy_loss = -5.3489, learner_queue_size = 32, _tick = 1360, _time = 1.6548e+09, train_seconds = 2357.7)
[2022-06-09 20:47:22,894][root][INFO] - Step 8837120 @ 4092.6 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 8837120, mean_episode_return = 18.42, mean_episode_step = 2177.8, total_loss = -28.455, pg_loss = -60.016, baseline_loss = 36.501, entropy_loss = -4.9411, learner_queue_size = 32, _tick = 1364, _time = 1.6548e+09, train_seconds = 2362.7)
[2022-06-09 20:47:27,902][root][INFO] - Step 8855040 @ 3581.2 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 8855040, mean_episode_return = None, mean_episode_step = 2032.1, total_loss = -6.5132, pg_loss = -27.064, baseline_loss = 25.577, entropy_loss = -5.0255, learner_queue_size = 32, _tick = 1367, _time = 1.6548e+09, train_seconds = 2367.7)
[2022-06-09 20:47:32,910][root][INFO] - Step 8872960 @ 3575.4 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 8872960, mean_episode_return = None, mean_episode_step = 2461.2, total_loss = 83.943, pg_loss = 48.116, baseline_loss = 40.433, entropy_loss = -4.6059, learner_queue_size = 32, _tick = 1369, _time = 1.6548e+09, train_seconds = 2372.7)
[2022-06-09 20:47:37,914][root][INFO] - Step 8893440 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 8893440, mean_episode_return = None, mean_episode_step = 2249.1, total_loss = -32.569, pg_loss = -37.076, baseline_loss = 9.5722, entropy_loss = -5.065, learner_queue_size = 32, _tick = 1371, _time = 1.6548e+09, train_seconds = 2377.7)
[2022-06-09 20:47:42,918][root][INFO] - Step 8911360 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 8911360, mean_episode_return = None, mean_episode_step = 2362.3, total_loss = -22.162, pg_loss = -28.513, baseline_loss = 10.889, entropy_loss = -4.5382, learner_queue_size = 32, _tick = 1374, _time = 1.6548e+09, train_seconds = 2382.7)
[2022-06-09 20:47:47,922][root][INFO] - Step 8929280 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 8929280, mean_episode_return = None, mean_episode_step = 2220.9, total_loss = -62.263, pg_loss = -58.882, baseline_loss = 2.3143, entropy_loss = -5.6957, learner_queue_size = 32, _tick = 1377, _time = 1.6548e+09, train_seconds = 2387.7)
[2022-06-09 20:47:52,926][root][INFO] - Step 8949760 @ 4092.7 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 8949760, mean_episode_return = 11.8, mean_episode_step = 2871.5, total_loss = 32.48, pg_loss = 26.061, baseline_loss = 10.868, entropy_loss = -4.449, learner_queue_size = 32, _tick = 1382, _time = 1.6548e+09, train_seconds = 2392.7)
[2022-06-09 20:47:57,930][root][INFO] - Step 8967680 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 8967680, mean_episode_return = None, mean_episode_step = 2485.8, total_loss = -70.947, pg_loss = -67.706, baseline_loss = 1.7416, entropy_loss = -4.9826, learner_queue_size = 32, _tick = 1382, _time = 1.6548e+09, train_seconds = 2397.7)
[2022-06-09 20:48:02,934][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-09 20:48:03,166][root][INFO] - Step 8985600 @ 3581.1 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 8988160, mean_episode_return = None, mean_episode_step = 2075.2, total_loss = 80.564, pg_loss = 43.884, baseline_loss = 42.019, entropy_loss = -5.3384, learner_queue_size = 32, _tick = 1384, _time = 1.6548e+09, train_seconds = 2402.7)
[2022-06-09 20:48:08,170][root][INFO] - Step 9006080 @ 3911.4 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 9006080, mean_episode_return = -3.9801, mean_episode_step = 1923.2, total_loss = -85.975, pg_loss = -84.986, baseline_loss = 3.179, entropy_loss = -4.1675, learner_queue_size = 32, _tick = 1387, _time = 1.6548e+09, train_seconds = 2408.0)
[2022-06-09 20:48:13,174][root][INFO] - Step 9024000 @ 3581.2 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 9024000, mean_episode_return = None, mean_episode_step = 2514.3, total_loss = -20.989, pg_loss = -33.108, baseline_loss = 16.175, entropy_loss = -4.0557, learner_queue_size = 32, _tick = 1389, _time = 1.6548e+09, train_seconds = 2413.0)
[2022-06-09 20:48:18,178][root][INFO] - Step 9041920 @ 3581.1 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 9041920, mean_episode_return = -7.3601, mean_episode_step = 3084.6, total_loss = -21.907, pg_loss = -20.713, baseline_loss = 4.5011, entropy_loss = -5.6956, learner_queue_size = 32, _tick = 1391, _time = 1.6548e+09, train_seconds = 2418.0)
[2022-06-09 20:48:23,182][root][INFO] - Step 9062400 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 9062400, mean_episode_return = None, mean_episode_step = 2600.6, total_loss = 59.01, pg_loss = 42.099, baseline_loss = 22.728, entropy_loss = -5.8173, learner_queue_size = 32, _tick = 1396, _time = 1.6548e+09, train_seconds = 2423.0)
[2022-06-09 20:48:28,186][root][INFO] - Step 9080320 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 9080320, mean_episode_return = 51.942, mean_episode_step = 2732.2, total_loss = -83.541, pg_loss = -89.554, baseline_loss = 11.195, entropy_loss = -5.1818, learner_queue_size = 32, _tick = 1402, _time = 1.6548e+09, train_seconds = 2428.0)
[2022-06-09 20:48:33,190][root][INFO] - Step 9098240 @ 3581.2 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 9098240, mean_episode_return = 64.497, mean_episode_step = 2321.5, total_loss = -55.85, pg_loss = -52.446, baseline_loss = 1.6728, entropy_loss = -5.0764, learner_queue_size = 32, _tick = 1408, _time = 1.6548e+09, train_seconds = 2433.0)
[2022-06-09 20:48:38,194][root][INFO] - Step 9116160 @ 3581.1 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (step = 9116160, mean_episode_return = None, mean_episode_step = 2612.2, total_loss = -36.054, pg_loss = -37.965, baseline_loss = 7.0987, entropy_loss = -5.1882, learner_queue_size = 32, _tick = 1410, _time = 1.6548e+09, train_seconds = 2438.0)
[2022-06-09 20:48:43,198][root][INFO] - Step 9136640 @ 4092.8 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 9136640, mean_episode_return = None, mean_episode_step = 3078.8, total_loss = -96.812, pg_loss = -92.976, baseline_loss = 1.9349, entropy_loss = -5.7709, learner_queue_size = 32, _tick = 1412, _time = 1.6548e+09, train_seconds = 2443.0)
[2022-06-09 20:48:48,202][root][INFO] - Step 9154560 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 9154560, mean_episode_return = 18.46, mean_episode_step = 2044.9, total_loss = -1.434, pg_loss = -16.131, baseline_loss = 20.756, entropy_loss = -6.0589, learner_queue_size = 32, _tick = 1417, _time = 1.6548e+09, train_seconds = 2448.0)
[2022-06-09 20:48:53,206][root][INFO] - Step 9175040 @ 4092.7 SPS. Inference batcher size: 81. Learner queue size: 32. Other stats: (step = 9175040, mean_episode_return = None, mean_episode_step = 2629.0, total_loss = -25.18, pg_loss = -22.962, baseline_loss = 4.3571, entropy_loss = -6.5744, learner_queue_size = 32, _tick = 1422, _time = 1.6548e+09, train_seconds = 2453.0)
[2022-06-09 20:48:58,210][root][INFO] - Step 9192960 @ 3580.9 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 9192960, mean_episode_return = 45.777, mean_episode_step = 2497.9, total_loss = 213.31, pg_loss = 151.03, baseline_loss = 68.463, entropy_loss = -6.1833, learner_queue_size = 32, _tick = 1428, _time = 1.6548e+09, train_seconds = 2458.0)
[2022-06-09 20:49:03,214][root][INFO] - Step 9210880 @ 3581.4 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 9210880, mean_episode_return = None, mean_episode_step = 2646.3, total_loss = -62.181, pg_loss = -59.465, baseline_loss = 2.9036, entropy_loss = -5.619, learner_queue_size = 32, _tick = 1432, _time = 1.6548e+09, train_seconds = 2463.0)
[2022-06-09 20:49:08,218][root][INFO] - Step 9231360 @ 4092.8 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 9231360, mean_episode_return = None, mean_episode_step = 2325.2, total_loss = 259.37, pg_loss = 189.53, baseline_loss = 75.18, entropy_loss = -5.3426, learner_queue_size = 32, _tick = 1436, _time = 1.6548e+09, train_seconds = 2468.0)
[2022-06-09 20:49:13,222][root][INFO] - Step 9249280 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 9249280, mean_episode_return = 42.963, mean_episode_step = 2652.3, total_loss = -37.349, pg_loss = -50.521, baseline_loss = 18.516, entropy_loss = -5.3442, learner_queue_size = 32, _tick = 1440, _time = 1.6548e+09, train_seconds = 2473.0)
[2022-06-09 20:49:18,226][root][INFO] - Step 9269760 @ 4092.7 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 9269760, mean_episode_return = None, mean_episode_step = 2642.9, total_loss = -27.865, pg_loss = -33.682, baseline_loss = 10.958, entropy_loss = -5.1413, learner_queue_size = 32, _tick = 1444, _time = 1.6548e+09, train_seconds = 2478.0)
[2022-06-09 20:49:23,230][root][INFO] - Step 9287680 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 9287680, mean_episode_return = 4.8792, mean_episode_step = 2123.6, total_loss = 37.131, pg_loss = 10.092, baseline_loss = 31.782, entropy_loss = -4.7435, learner_queue_size = 32, _tick = 1449, _time = 1.6548e+09, train_seconds = 2483.0)
[2022-06-09 20:49:28,235][root][INFO] - Step 9305600 @ 3580.4 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 9305600, mean_episode_return = 9.7097, mean_episode_step = 2075.4, total_loss = 1.1007, pg_loss = -28.118, baseline_loss = 34.804, entropy_loss = -5.5847, learner_queue_size = 32, _tick = 1453, _time = 1.6548e+09, train_seconds = 2488.0)
[2022-06-09 20:49:33,238][root][INFO] - Step 9326080 @ 4093.6 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 9326080, mean_episode_return = 18.62, mean_episode_step = 2326.8, total_loss = 257.96, pg_loss = 188.68, baseline_loss = 74.706, entropy_loss = -5.4313, learner_queue_size = 32, _tick = 1457, _time = 1.6548e+09, train_seconds = 2493.0)
[2022-06-09 20:49:38,242][root][INFO] - Step 9344000 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 9344000, mean_episode_return = 92.717, mean_episode_step = 2370.1, total_loss = -72.082, pg_loss = -68.189, baseline_loss = 1.3765, entropy_loss = -5.2693, learner_queue_size = 32, _tick = 1463, _time = 1.6548e+09, train_seconds = 2498.0)
[2022-06-09 20:49:43,246][root][INFO] - Step 9364480 @ 4092.8 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 9364480, mean_episode_return = None, mean_episode_step = 2423.6, total_loss = 31.84, pg_loss = 8.1458, baseline_loss = 28.263, entropy_loss = -4.569, learner_queue_size = 32, _tick = 1468, _time = 1.6548e+09, train_seconds = 2503.1)
[2022-06-09 20:49:48,250][root][INFO] - Step 9382400 @ 3581.1 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 9382400, mean_episode_return = None, mean_episode_step = 2430.7, total_loss = 21.012, pg_loss = 10.02, baseline_loss = 15.625, entropy_loss = -4.6325, learner_queue_size = 32, _tick = 1470, _time = 1.6548e+09, train_seconds = 2508.1)
[2022-06-09 20:49:53,254][root][INFO] - Step 9400320 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 9400320, mean_episode_return = None, mean_episode_step = 1984.1, total_loss = 0.94325, pg_loss = -22.581, baseline_loss = 27.984, entropy_loss = -4.46, learner_queue_size = 32, _tick = 1473, _time = 1.6548e+09, train_seconds = 2513.1)
[2022-06-09 20:49:58,258][root][INFO] - Step 9420800 @ 4092.7 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 9420800, mean_episode_return = None, mean_episode_step = 1811.7, total_loss = 128.5, pg_loss = 48.462, baseline_loss = 84.062, entropy_loss = -4.0192, learner_queue_size = 32, _tick = 1474, _time = 1.6548e+09, train_seconds = 2518.1)
[2022-06-09 20:50:03,262][root][INFO] - Step 9438720 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 9438720, mean_episode_return = None, mean_episode_step = 2502.8, total_loss = -47.808, pg_loss = -55.027, baseline_loss = 11.773, entropy_loss = -4.5534, learner_queue_size = 32, _tick = 1476, _time = 1.6548e+09, train_seconds = 2523.1)
[2022-06-09 20:50:08,266][root][INFO] - Step 9456640 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 9456640, mean_episode_return = None, mean_episode_step = 2843.6, total_loss = 49.183, pg_loss = 28.948, baseline_loss = 24.725, entropy_loss = -4.4908, learner_queue_size = 32, _tick = 1478, _time = 1.6548e+09, train_seconds = 2528.1)
[2022-06-09 20:50:13,270][root][INFO] - Step 9477120 @ 4092.8 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 9477120, mean_episode_return = None, mean_episode_step = 1737.4, total_loss = 329.98, pg_loss = 205.31, baseline_loss = 129.03, entropy_loss = -4.3552, learner_queue_size = 32, _tick = 1482, _time = 1.6548e+09, train_seconds = 2533.1)
[2022-06-09 20:50:18,274][root][INFO] - Step 9495040 @ 3581.1 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 9495040, mean_episode_return = None, mean_episode_step = 2580.6, total_loss = -10.369, pg_loss = -29.711, baseline_loss = 23.295, entropy_loss = -3.9538, learner_queue_size = 32, _tick = 1483, _time = 1.6548e+09, train_seconds = 2538.1)
[2022-06-09 20:50:23,278][root][INFO] - Step 9515520 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 9515520, mean_episode_return = None, mean_episode_step = 2649.2, total_loss = 48.974, pg_loss = -5.3623, baseline_loss = 58.904, entropy_loss = -4.5683, learner_queue_size = 32, _tick = 1486, _time = 1.6548e+09, train_seconds = 2543.1)
[2022-06-09 20:50:28,282][root][INFO] - Step 9533440 @ 3581.1 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 9533440, mean_episode_return = -2.9605, mean_episode_step = 2210.2, total_loss = -19.975, pg_loss = -26.991, baseline_loss = 11.744, entropy_loss = -4.7286, learner_queue_size = 32, _tick = 1490, _time = 1.6548e+09, train_seconds = 2548.1)
[2022-06-09 20:50:33,288][root][INFO] - Step 9551360 @ 3580.0 SPS. Inference batcher size: 77. Learner queue size: 32. Other stats: (step = 9551360, mean_episode_return = None, mean_episode_step = 2348.9, total_loss = 104.42, pg_loss = 46.053, baseline_loss = 62.135, entropy_loss = -3.7658, learner_queue_size = 32, _tick = 1494, _time = 1.6548e+09, train_seconds = 2553.1)
[2022-06-09 20:50:38,294][root][INFO] - Step 9569280 @ 3579.5 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 9569280, mean_episode_return = None, mean_episode_step = 2376.1, total_loss = 140.96, pg_loss = 100.27, baseline_loss = 44.447, entropy_loss = -3.7555, learner_queue_size = 32, _tick = 1496, _time = 1.6548e+09, train_seconds = 2558.1)
[2022-06-09 20:50:43,298][root][INFO] - Step 9589760 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 9589760, mean_episode_return = None, mean_episode_step = 2400.2, total_loss = -80.023, pg_loss = -79.959, baseline_loss = 3.8009, entropy_loss = -3.865, learner_queue_size = 32, _tick = 1499, _time = 1.6548e+09, train_seconds = 2563.1)
[2022-06-09 20:50:48,302][root][INFO] - Step 9607680 @ 3581.2 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 9607680, mean_episode_return = 43.78, mean_episode_step = 2263.1, total_loss = -22.032, pg_loss = -42.925, baseline_loss = 25.067, entropy_loss = -4.1737, learner_queue_size = 32, _tick = 1502, _time = 1.6548e+09, train_seconds = 2568.1)
[2022-06-09 20:50:53,306][root][INFO] - Step 9625600 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 9625600, mean_episode_return = 22.859, mean_episode_step = 2222.8, total_loss = 20.701, pg_loss = -25.194, baseline_loss = 50.266, entropy_loss = -4.371, learner_queue_size = 32, _tick = 1508, _time = 1.6548e+09, train_seconds = 2573.1)
[2022-06-09 20:50:58,310][root][INFO] - Step 9646080 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 9646080, mean_episode_return = 36.564, mean_episode_step = 2283.9, total_loss = -126.38, pg_loss = -127.63, baseline_loss = 6.3529, entropy_loss = -5.1013, learner_queue_size = 32, _tick = 1511, _time = 1.6548e+09, train_seconds = 2578.1)
[2022-06-09 20:51:03,314][root][INFO] - Step 9664000 @ 3581.2 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (step = 9664000, mean_episode_return = 25.05, mean_episode_step = 2040.1, total_loss = -53.037, pg_loss = -51.135, baseline_loss = 3.8586, entropy_loss = -5.7611, learner_queue_size = 32, _tick = 1516, _time = 1.6548e+09, train_seconds = 2583.1)
[2022-06-09 20:51:08,318][root][INFO] - Step 9681920 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 9681920, mean_episode_return = None, mean_episode_step = 2721.7, total_loss = 321.47, pg_loss = 250.91, baseline_loss = 76.762, entropy_loss = -6.1944, learner_queue_size = 32, _tick = 1521, _time = 1.6548e+09, train_seconds = 2588.1)
[2022-06-09 20:51:13,322][root][INFO] - Step 9702400 @ 4092.8 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 9702400, mean_episode_return = -3.0303, mean_episode_step = 2812.8, total_loss = 315.75, pg_loss = 248.95, baseline_loss = 72.485, entropy_loss = -5.6798, learner_queue_size = 32, _tick = 1528, _time = 1.6548e+09, train_seconds = 2593.1)
[2022-06-09 20:51:18,326][root][INFO] - Step 9720320 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 9720320, mean_episode_return = None, mean_episode_step = 2589.3, total_loss = 321.32, pg_loss = 249.72, baseline_loss = 76.893, entropy_loss = -5.3007, learner_queue_size = 32, _tick = 1533, _time = 1.6548e+09, train_seconds = 2598.1)
[2022-06-09 20:51:23,330][root][INFO] - Step 9735680 @ 3069.5 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 9735680, mean_episode_return = 17.105, mean_episode_step = 2322.7, total_loss = 68.713, pg_loss = 26.773, baseline_loss = 46.852, entropy_loss = -4.9127, learner_queue_size = 32, _tick = 1536, _time = 1.6548e+09, train_seconds = 2603.1)
[2022-06-09 20:51:28,334][root][INFO] - Step 9753600 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 9753600, mean_episode_return = None, mean_episode_step = 1945.2, total_loss = 50.881, pg_loss = 28.259, baseline_loss = 26.953, entropy_loss = -4.3318, learner_queue_size = 32, _tick = 1541, _time = 1.6548e+09, train_seconds = 2608.1)
[2022-06-09 20:51:33,338][root][INFO] - Step 9774080 @ 4092.7 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 9774080, mean_episode_return = None, mean_episode_step = 2065.2, total_loss = 36.443, pg_loss = -3.8615, baseline_loss = 45.264, entropy_loss = -4.9597, learner_queue_size = 32, _tick = 1542, _time = 1.6548e+09, train_seconds = 2613.1)
[2022-06-09 20:51:38,342][root][INFO] - Step 9792000 @ 3581.2 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 9792000, mean_episode_return = None, mean_episode_step = 1824.7, total_loss = -109.42, pg_loss = -107.37, baseline_loss = 3.307, entropy_loss = -5.3525, learner_queue_size = 32, _tick = 1543, _time = 1.6548e+09, train_seconds = 2618.1)
[2022-06-09 20:51:43,346][root][INFO] - Step 9809920 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 9809920, mean_episode_return = 78.119, mean_episode_step = 1954.7, total_loss = -104.67, pg_loss = -127.88, baseline_loss = 28.555, entropy_loss = -5.3503, learner_queue_size = 32, _tick = 1548, _time = 1.6548e+09, train_seconds = 2623.2)
[2022-06-09 20:51:48,350][root][INFO] - Step 9830400 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 9830400, mean_episode_return = 38.479, mean_episode_step = 2452.2, total_loss = 117.6, pg_loss = 61.424, baseline_loss = 60.807, entropy_loss = -4.6268, learner_queue_size = 32, _tick = 1554, _time = 1.6548e+09, train_seconds = 2628.2)
[2022-06-09 20:51:53,354][root][INFO] - Step 9848320 @ 3581.1 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 9848320, mean_episode_return = None, mean_episode_step = 2208.6, total_loss = 72.051, pg_loss = 36.913, baseline_loss = 40.123, entropy_loss = -4.9852, learner_queue_size = 32, _tick = 1555, _time = 1.6548e+09, train_seconds = 2633.2)
[2022-06-09 20:51:58,358][root][INFO] - Step 9868800 @ 4092.8 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 9868800, mean_episode_return = 75.562, mean_episode_step = 2515.8, total_loss = 80.178, pg_loss = 42.864, baseline_loss = 42.081, entropy_loss = -4.7666, learner_queue_size = 32, _tick = 1561, _time = 1.6548e+09, train_seconds = 2638.2)
[2022-06-09 20:52:03,362][root][INFO] - Step 9886720 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 9886720, mean_episode_return = None, mean_episode_step = 2001.8, total_loss = 94.767, pg_loss = 59.589, baseline_loss = 40.26, entropy_loss = -5.0819, learner_queue_size = 32, _tick = 1564, _time = 1.6548e+09, train_seconds = 2643.2)
[2022-06-09 20:52:08,366][root][INFO] - Step 9907200 @ 4092.8 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 9907200, mean_episode_return = 78.407, mean_episode_step = 2864.4, total_loss = 195.0, pg_loss = 108.66, baseline_loss = 91.258, entropy_loss = -4.9213, learner_queue_size = 32, _tick = 1568, _time = 1.6548e+09, train_seconds = 2648.2)
[2022-06-09 20:52:13,370][root][INFO] - Step 9925120 @ 3581.2 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 9925120, mean_episode_return = None, mean_episode_step = 1799.0, total_loss = -125.94, pg_loss = -134.41, baseline_loss = 13.076, entropy_loss = -4.6108, learner_queue_size = 32, _tick = 1572, _time = 1.6548e+09, train_seconds = 2653.2)
[2022-06-09 20:52:18,374][root][INFO] - Step 9943040 @ 3581.0 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 9943040, mean_episode_return = None, mean_episode_step = 2259.4, total_loss = -12.624, pg_loss = -18.901, baseline_loss = 11.427, entropy_loss = -5.1498, learner_queue_size = 32, _tick = 1575, _time = 1.6548e+09, train_seconds = 2658.2)
[2022-06-09 20:52:23,378][root][INFO] - Step 9960960 @ 3581.2 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 9960960, mean_episode_return = 22.226, mean_episode_step = 1954.4, total_loss = 213.02, pg_loss = 122.19, baseline_loss = 95.536, entropy_loss = -4.7082, learner_queue_size = 32, _tick = 1580, _time = 1.6548e+09, train_seconds = 2663.2)
[2022-06-09 20:52:28,382][root][INFO] - Step 9981440 @ 4092.7 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 9981440, mean_episode_return = 33.711, mean_episode_step = 2026.4, total_loss = 194.19, pg_loss = 95.841, baseline_loss = 103.25, entropy_loss = -4.9023, learner_queue_size = 32, _tick = 1584, _time = 1.6548e+09, train_seconds = 2668.2)
[2022-06-09 20:52:33,386][root][INFO] - Step 9999360 @ 3581.2 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 9999360, mean_episode_return = 80.918, mean_episode_step = 2531.9, total_loss = -64.066, pg_loss = -70.442, baseline_loss = 11.181, entropy_loss = -4.8051, learner_queue_size = 32, _tick = 1589, _time = 1.6548e+09, train_seconds = 2673.2)
[2022-06-09 20:52:38,390][root][INFO] - Step 10017280 @ 3581.2 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 10017280, mean_episode_return = -0.81, mean_episode_step = 1967.6, total_loss = -101.55, pg_loss = -131.94, baseline_loss = 35.205, entropy_loss = -4.813, learner_queue_size = 32, _tick = 1595, _time = 1.6548e+09, train_seconds = 2678.2)
[2022-06-09 20:52:43,394][root][INFO] - Step 10037760 @ 4092.7 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 10037760, mean_episode_return = 12.356, mean_episode_step = 2197.5, total_loss = 42.851, pg_loss = 10.691, baseline_loss = 37.402, entropy_loss = -5.2427, learner_queue_size = 32, _tick = 1600, _time = 1.6548e+09, train_seconds = 2683.2)
[2022-06-09 20:52:48,398][root][INFO] - Step 10055680 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 10055680, mean_episode_return = None, mean_episode_step = 2189.7, total_loss = -19.302, pg_loss = -20.091, baseline_loss = 5.7413, entropy_loss = -4.9522, learner_queue_size = 32, _tick = 1604, _time = 1.6548e+09, train_seconds = 2688.2)
[2022-06-09 20:52:53,402][root][INFO] - Step 10076160 @ 4092.7 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 10076160, mean_episode_return = 111.91, mean_episode_step = 1857.0, total_loss = 88.657, pg_loss = 48.098, baseline_loss = 44.825, entropy_loss = -4.2664, learner_queue_size = 32, _tick = 1608, _time = 1.6548e+09, train_seconds = 2693.2)
[2022-06-09 20:52:58,406][root][INFO] - Step 10094080 @ 3581.1 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 10094080, mean_episode_return = None, mean_episode_step = 2236.0, total_loss = -52.585, pg_loss = -50.452, baseline_loss = 1.5856, entropy_loss = -3.7186, learner_queue_size = 32, _tick = 1612, _time = 1.6548e+09, train_seconds = 2698.2)
[2022-06-09 20:53:03,410][root][INFO] - Step 10112000 @ 3581.2 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 10112000, mean_episode_return = 32.15, mean_episode_step = 1817.4, total_loss = 207.99, pg_loss = 104.22, baseline_loss = 107.59, entropy_loss = -3.8227, learner_queue_size = 32, _tick = 1615, _time = 1.6548e+09, train_seconds = 2703.2)
[2022-06-09 20:53:08,414][root][INFO] - Step 10129920 @ 3581.1 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 10129920, mean_episode_return = None, mean_episode_step = 1968.2, total_loss = 5.0596, pg_loss = -3.5843, baseline_loss = 12.475, entropy_loss = -3.8313, learner_queue_size = 32, _tick = 1616, _time = 1.6548e+09, train_seconds = 2708.2)
[2022-06-09 20:53:13,418][root][INFO] - Step 10150400 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 10150400, mean_episode_return = 109.26, mean_episode_step = 2023.0, total_loss = -65.045, pg_loss = -64.864, baseline_loss = 4.2813, entropy_loss = -4.462, learner_queue_size = 32, _tick = 1619, _time = 1.6548e+09, train_seconds = 2713.2)
[2022-06-09 20:53:18,422][root][INFO] - Step 10168320 @ 3581.1 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (step = 10168320, mean_episode_return = None, mean_episode_step = 2486.0, total_loss = 64.663, pg_loss = 33.427, baseline_loss = 35.514, entropy_loss = -4.2778, learner_queue_size = 32, _tick = 1622, _time = 1.6548e+09, train_seconds = 2718.2)
[2022-06-09 20:53:23,426][root][INFO] - Step 10186240 @ 3581.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 10186240, mean_episode_return = None, mean_episode_step = 2335.0, total_loss = -20.698, pg_loss = -28.808, baseline_loss = 11.596, entropy_loss = -3.4862, learner_queue_size = 32, _tick = 1625, _time = 1.6548e+09, train_seconds = 2723.2)
[2022-06-09 20:53:28,430][root][INFO] - Step 10206720 @ 4092.7 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 10206720, mean_episode_return = None, mean_episode_step = 2191.3, total_loss = -15.14, pg_loss = -13.018, baseline_loss = 1.2815, entropy_loss = -3.4034, learner_queue_size = 32, _tick = 1626, _time = 1.6548e+09, train_seconds = 2728.2)
[2022-06-09 20:53:33,434][root][INFO] - Step 10224640 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 10224640, mean_episode_return = 89.467, mean_episode_step = 2367.5, total_loss = 175.05, pg_loss = 68.755, baseline_loss = 109.58, entropy_loss = -3.2852, learner_queue_size = 32, _tick = 1629, _time = 1.6548e+09, train_seconds = 2733.2)
[2022-06-09 20:53:38,438][root][INFO] - Step 10245120 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 10245120, mean_episode_return = 69.003, mean_episode_step = 1856.6, total_loss = 26.761, pg_loss = 0.85379, baseline_loss = 30.343, entropy_loss = -4.4349, learner_queue_size = 32, _tick = 1632, _time = 1.6548e+09, train_seconds = 2738.2)
[2022-06-09 20:53:43,442][root][INFO] - Step 10263040 @ 3581.1 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 10263040, mean_episode_return = None, mean_episode_step = 2440.6, total_loss = -47.279, pg_loss = -41.116, baseline_loss = 0.31117, entropy_loss = -6.474, learner_queue_size = 32, _tick = 1634, _time = 1.6548e+09, train_seconds = 2743.2)
[2022-06-09 20:53:48,446][root][INFO] - Step 10283520 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 10283520, mean_episode_return = 41.784, mean_episode_step = 2036.8, total_loss = 173.25, pg_loss = 152.29, baseline_loss = 28.993, entropy_loss = -8.0329, learner_queue_size = 32, _tick = 1639, _time = 1.6548e+09, train_seconds = 2748.3)
[2022-06-09 20:53:53,450][root][INFO] - Step 10301440 @ 3581.2 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 10301440, mean_episode_return = 57.623, mean_episode_step = 1855.6, total_loss = -41.66, pg_loss = -38.545, baseline_loss = 4.1584, entropy_loss = -7.2729, learner_queue_size = 32, _tick = 1645, _time = 1.6548e+09, train_seconds = 2753.3)
[2022-06-09 20:53:58,454][root][INFO] - Step 10319360 @ 3581.2 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 10319360, mean_episode_return = 65.545, mean_episode_step = 2263.0, total_loss = 227.89, pg_loss = 182.91, baseline_loss = 52.112, entropy_loss = -7.1399, learner_queue_size = 32, _tick = 1651, _time = 1.6548e+09, train_seconds = 2758.3)
[2022-06-09 20:54:03,458][root][INFO] - Step 10339840 @ 4092.7 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 10339840, mean_episode_return = None, mean_episode_step = 2253.0, total_loss = 124.65, pg_loss = 88.734, baseline_loss = 43.002, entropy_loss = -7.0862, learner_queue_size = 32, _tick = 1657, _time = 1.6548e+09, train_seconds = 2763.3)
[2022-06-09 20:54:08,462][root][INFO] - Step 10357760 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 10357760, mean_episode_return = 27.31, mean_episode_step = 2083.8, total_loss = 4.8235, pg_loss = 2.1977, baseline_loss = 8.56, entropy_loss = -5.9342, learner_queue_size = 32, _tick = 1664, _time = 1.6548e+09, train_seconds = 2768.3)
[2022-06-09 20:54:13,466][root][INFO] - Step 10375680 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 10375680, mean_episode_return = 64.89, mean_episode_step = 1790.1, total_loss = 166.42, pg_loss = 111.86, baseline_loss = 59.195, entropy_loss = -4.6349, learner_queue_size = 32, _tick = 1669, _time = 1.6548e+09, train_seconds = 2773.3)
[2022-06-09 20:54:18,470][root][INFO] - Step 10393600 @ 3581.1 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 10393600, mean_episode_return = None, mean_episode_step = 2028.9, total_loss = 68.628, pg_loss = 38.84, baseline_loss = 34.172, entropy_loss = -4.3831, learner_queue_size = 32, _tick = 1673, _time = 1.6548e+09, train_seconds = 2778.3)
[2022-06-09 20:54:23,474][root][INFO] - Step 10414080 @ 4092.6 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 10414080, mean_episode_return = None, mean_episode_step = 1411.1, total_loss = 145.88, pg_loss = 69.457, baseline_loss = 80.539, entropy_loss = -4.1135, learner_queue_size = 32, _tick = 1674, _time = 1.6548e+09, train_seconds = 2783.3)
[2022-06-09 20:54:28,478][root][INFO] - Step 10432000 @ 3581.3 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 10432000, mean_episode_return = 46.801, mean_episode_step = 2487.0, total_loss = 36.811, pg_loss = -13.965, baseline_loss = 54.609, entropy_loss = -3.8325, learner_queue_size = 32, _tick = 1676, _time = 1.6548e+09, train_seconds = 2788.3)
[2022-06-09 20:54:33,482][root][INFO] - Step 10452480 @ 4092.8 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 10452480, mean_episode_return = None, mean_episode_step = 2415.4, total_loss = -42.571, pg_loss = -56.87, baseline_loss = 18.264, entropy_loss = -3.9658, learner_queue_size = 32, _tick = 1679, _time = 1.6548e+09, train_seconds = 2793.3)
[2022-06-09 20:54:38,486][root][INFO] - Step 10470400 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 10470400, mean_episode_return = None, mean_episode_step = 1813.7, total_loss = 48.495, pg_loss = 27.804, baseline_loss = 24.988, entropy_loss = -4.2966, learner_queue_size = 32, _tick = 1680, _time = 1.6548e+09, train_seconds = 2798.3)
[2022-06-09 20:54:43,490][root][INFO] - Step 10488320 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 10488320, mean_episode_return = 27.04, mean_episode_step = 2687.1, total_loss = -27.719, pg_loss = -34.916, baseline_loss = 10.208, entropy_loss = -3.0107, learner_queue_size = 32, _tick = 1681, _time = 1.6548e+09, train_seconds = 2803.3)
[2022-06-09 20:54:48,494][root][INFO] - Step 10508800 @ 4092.7 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 10508800, mean_episode_return = None, mean_episode_step = 1597.3, total_loss = 74.474, pg_loss = 47.566, baseline_loss = 30.905, entropy_loss = -3.997, learner_queue_size = 32, _tick = 1684, _time = 1.6548e+09, train_seconds = 2808.3)
[2022-06-09 20:54:53,498][root][INFO] - Step 10526720 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 10526720, mean_episode_return = None, mean_episode_step = 1947.8, total_loss = -7.007, pg_loss = -9.2458, baseline_loss = 6.6272, entropy_loss = -4.3884, learner_queue_size = 32, _tick = 1685, _time = 1.6548e+09, train_seconds = 2813.3)
[2022-06-09 20:54:58,502][root][INFO] - Step 10544640 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 10544640, mean_episode_return = None, mean_episode_step = 2379.3, total_loss = -21.879, pg_loss = -21.625, baseline_loss = 4.2605, entropy_loss = -4.5137, learner_queue_size = 32, _tick = 1687, _time = 1.6548e+09, train_seconds = 2818.3)
[2022-06-09 20:55:03,506][root][INFO] - Step 10562560 @ 3581.1 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 10562560, mean_episode_return = None, mean_episode_step = 2410.3, total_loss = -2.1799, pg_loss = -16.785, baseline_loss = 18.875, entropy_loss = -4.2701, learner_queue_size = 32, _tick = 1690, _time = 1.6548e+09, train_seconds = 2823.3)
[2022-06-09 20:55:08,510][root][INFO] - Step 10583040 @ 4092.8 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 10583040, mean_episode_return = None, mean_episode_step = 2572.4, total_loss = -10.332, pg_loss = -14.015, baseline_loss = 8.2444, entropy_loss = -4.5616, learner_queue_size = 32, _tick = 1696, _time = 1.6548e+09, train_seconds = 2828.3)
[2022-06-09 20:55:13,514][root][INFO] - Step 10600960 @ 3581.1 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 10600960, mean_episode_return = 12.269, mean_episode_step = 1719.3, total_loss = 105.01, pg_loss = 55.108, baseline_loss = 54.569, entropy_loss = -4.6675, learner_queue_size = 32, _tick = 1698, _time = 1.6548e+09, train_seconds = 2833.3)
[2022-06-09 20:55:18,518][root][INFO] - Step 10618880 @ 3581.1 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (step = 10618880, mean_episode_return = 20.3, mean_episode_step = 2566.3, total_loss = -114.61, pg_loss = -118.79, baseline_loss = 8.9079, entropy_loss = -4.7334, learner_queue_size = 32, _tick = 1700, _time = 1.6548e+09, train_seconds = 2838.3)
[2022-06-09 20:55:23,522][root][INFO] - Step 10639360 @ 4092.7 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 10639360, mean_episode_return = 36.452, mean_episode_step = 2156.7, total_loss = 2375.2, pg_loss = 663.44, baseline_loss = 1716.5, entropy_loss = -4.8092, learner_queue_size = 32, _tick = 1704, _time = 1.6548e+09, train_seconds = 2843.3)
[2022-06-09 20:55:28,526][root][INFO] - Step 10657280 @ 3581.2 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 10657280, mean_episode_return = 25.06, mean_episode_step = 2573.7, total_loss = 18.212, pg_loss = -10.905, baseline_loss = 33.809, entropy_loss = -4.6907, learner_queue_size = 32, _tick = 1708, _time = 1.6548e+09, train_seconds = 2848.3)
[2022-06-09 20:55:33,530][root][INFO] - Step 10675200 @ 3581.2 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 10675200, mean_episode_return = 34.64, mean_episode_step = 2622.3, total_loss = -9.1504, pg_loss = -31.805, baseline_loss = 27.424, entropy_loss = -4.7693, learner_queue_size = 32, _tick = 1711, _time = 1.6548e+09, train_seconds = 2853.3)
[2022-06-09 20:55:38,534][root][INFO] - Step 10693120 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 10693120, mean_episode_return = 45.061, mean_episode_step = 2412.9, total_loss = -50.213, pg_loss = -58.971, baseline_loss = 13.479, entropy_loss = -4.7213, learner_queue_size = 32, _tick = 1717, _time = 1.6548e+09, train_seconds = 2858.3)
[2022-06-09 20:55:43,538][root][INFO] - Step 10713600 @ 4092.4 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 10713600, mean_episode_return = 57.701, mean_episode_step = 2739.9, total_loss = 124.32, pg_loss = 47.167, baseline_loss = 81.88, entropy_loss = -4.7298, learner_queue_size = 32, _tick = 1720, _time = 1.6548e+09, train_seconds = 2863.3)
[2022-06-09 20:55:48,542][root][INFO] - Step 10731520 @ 3581.4 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 10731520, mean_episode_return = None, mean_episode_step = 2230.2, total_loss = 30.647, pg_loss = 1.1647, baseline_loss = 33.926, entropy_loss = -4.4441, learner_queue_size = 32, _tick = 1724, _time = 1.6548e+09, train_seconds = 2868.3)
[2022-06-09 20:55:53,546][root][INFO] - Step 10752000 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 10752000, mean_episode_return = None, mean_episode_step = 2607.5, total_loss = 126.94, pg_loss = 73.279, baseline_loss = 58.207, entropy_loss = -4.5493, learner_queue_size = 32, _tick = 1726, _time = 1.6548e+09, train_seconds = 2873.4)
[2022-06-09 20:55:58,550][root][INFO] - Step 10769920 @ 3581.1 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 10769920, mean_episode_return = None, mean_episode_step = 2125.8, total_loss = 229.91, pg_loss = 142.32, baseline_loss = 91.878, entropy_loss = -4.2921, learner_queue_size = 32, _tick = 1728, _time = 1.6548e+09, train_seconds = 2878.4)
[2022-06-09 20:56:03,554][root][INFO] - Step 10790400 @ 4092.8 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 10790400, mean_episode_return = None, mean_episode_step = 2034.0, total_loss = 106.26, pg_loss = 59.465, baseline_loss = 51.14, entropy_loss = -4.3414, learner_queue_size = 32, _tick = 1729, _time = 1.6548e+09, train_seconds = 2883.4)
[2022-06-09 20:56:08,558][root][INFO] - Step 10808320 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 10808320, mean_episode_return = None, mean_episode_step = 2318.1, total_loss = 67.039, pg_loss = 15.637, baseline_loss = 55.898, entropy_loss = -4.4954, learner_queue_size = 32, _tick = 1731, _time = 1.6548e+09, train_seconds = 2888.4)
[2022-06-09 20:56:13,562][root][INFO] - Step 10828800 @ 4092.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 10828800, mean_episode_return = 54.43, mean_episode_step = 2263.2, total_loss = 41.334, pg_loss = 16.647, baseline_loss = 29.905, entropy_loss = -5.2173, learner_queue_size = 32, _tick = 1734, _time = 1.6548e+09, train_seconds = 2893.4)
[2022-06-09 20:56:18,566][root][INFO] - Step 10846720 @ 3581.2 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 10846720, mean_episode_return = 84.639, mean_episode_step = 2698.6, total_loss = -14.971, pg_loss = -22.594, baseline_loss = 12.885, entropy_loss = -5.2616, learner_queue_size = 32, _tick = 1740, _time = 1.6548e+09, train_seconds = 2898.4)
[2022-06-09 20:56:23,574][root][INFO] - Step 10867200 @ 4092.7 SPS. Inference batcher size: 73. Learner queue size: 32. Other stats: (step = 10867200, mean_episode_return = None, mean_episode_step = 2236.7, total_loss = 119.12, pg_loss = 83.847, baseline_loss = 40.181, entropy_loss = -4.9104, learner_queue_size = 32, _tick = 1745, _time = 1.6548e+09, train_seconds = 2903.4)
[2022-06-09 20:56:28,580][root][INFO] - Step 10885120 @ 3577.1 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 10885120, mean_episode_return = None, mean_episode_step = 2113.7, total_loss = 36.082, pg_loss = 17.363, baseline_loss = 24.35, entropy_loss = -5.6304, learner_queue_size = 32, _tick = 1750, _time = 1.6548e+09, train_seconds = 2908.4)
[2022-06-09 20:56:33,586][root][INFO] - Step 10903040 @ 3579.4 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 10903040, mean_episode_return = 43.193, mean_episode_step = 2217.0, total_loss = 218.34, pg_loss = 183.68, baseline_loss = 40.61, entropy_loss = -5.9436, learner_queue_size = 32, _tick = 1754, _time = 1.6548e+09, train_seconds = 2913.4)
[2022-06-09 20:56:38,590][root][INFO] - Step 10923520 @ 4092.8 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (step = 10923520, mean_episode_return = 80.823, mean_episode_step = 2725.6, total_loss = 59.168, pg_loss = -0.14795, baseline_loss = 64.948, entropy_loss = -5.6323, learner_queue_size = 32, _tick = 1759, _time = 1.6548e+09, train_seconds = 2918.4)
[2022-06-09 20:56:43,594][root][INFO] - Step 10941440 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 10941440, mean_episode_return = 33.12, mean_episode_step = 2712.4, total_loss = -50.337, pg_loss = -62.164, baseline_loss = 16.87, entropy_loss = -5.0427, learner_queue_size = 32, _tick = 1765, _time = 1.6548e+09, train_seconds = 2923.4)
[2022-06-09 20:56:48,598][root][INFO] - Step 10959360 @ 3581.2 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 10959360, mean_episode_return = 65.39, mean_episode_step = 2839.9, total_loss = 102.72, pg_loss = 38.44, baseline_loss = 69.402, entropy_loss = -5.1254, learner_queue_size = 32, _tick = 1768, _time = 1.6548e+09, train_seconds = 2928.4)
[2022-06-09 20:56:53,602][root][INFO] - Step 10979840 @ 4092.7 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (step = 10979840, mean_episode_return = None, mean_episode_step = 2203.4, total_loss = 88.802, pg_loss = 50.039, baseline_loss = 44.028, entropy_loss = -5.2645, learner_queue_size = 32, _tick = 1773, _time = 1.6548e+09, train_seconds = 2933.4)
[2022-06-09 20:56:58,606][root][INFO] - Step 10997760 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 10997760, mean_episode_return = None, mean_episode_step = 1914.9, total_loss = 117.0, pg_loss = 79.038, baseline_loss = 43.712, entropy_loss = -5.7477, learner_queue_size = 32, _tick = 1775, _time = 1.6548e+09, train_seconds = 2938.4)
[2022-06-09 20:57:03,610][root][INFO] - Step 11015680 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 11015680, mean_episode_return = None, mean_episode_step = 2615.3, total_loss = -69.856, pg_loss = -75.782, baseline_loss = 11.264, entropy_loss = -5.3378, learner_queue_size = 32, _tick = 1779, _time = 1.6548e+09, train_seconds = 2943.4)
[2022-06-09 20:57:08,614][root][INFO] - Step 11033600 @ 3581.1 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 11033600, mean_episode_return = None, mean_episode_step = 2473.7, total_loss = 65.737, pg_loss = 24.112, baseline_loss = 46.757, entropy_loss = -5.1319, learner_queue_size = 32, _tick = 1783, _time = 1.6548e+09, train_seconds = 2948.4)
[2022-06-09 20:57:13,618][root][INFO] - Step 11054080 @ 4092.8 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 11054080, mean_episode_return = None, mean_episode_step = 2423.8, total_loss = -107.17, pg_loss = -102.62, baseline_loss = 0.71486, entropy_loss = -5.2731, learner_queue_size = 32, _tick = 1787, _time = 1.6548e+09, train_seconds = 2953.4)
[2022-06-09 20:57:18,622][root][INFO] - Step 11072000 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 11072000, mean_episode_return = None, mean_episode_step = 1913.1, total_loss = 3.452, pg_loss = -19.559, baseline_loss = 28.321, entropy_loss = -5.31, learner_queue_size = 32, _tick = 1791, _time = 1.6548e+09, train_seconds = 2958.4)
[2022-06-09 20:57:23,626][root][INFO] - Step 11092480 @ 4092.8 SPS. Inference batcher size: 73. Learner queue size: 32. Other stats: (step = 11092480, mean_episode_return = -0.9303, mean_episode_step = 2323.4, total_loss = -10.024, pg_loss = -43.855, baseline_loss = 39.17, entropy_loss = -5.3399, learner_queue_size = 32, _tick = 1796, _time = 1.6548e+09, train_seconds = 2963.4)
[2022-06-09 20:57:28,630][root][INFO] - Step 11110400 @ 3581.0 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 11110400, mean_episode_return = 147.05, mean_episode_step = 2177.1, total_loss = -52.685, pg_loss = -78.221, baseline_loss = 30.376, entropy_loss = -4.8406, learner_queue_size = 32, _tick = 1802, _time = 1.6548e+09, train_seconds = 2968.4)
[2022-06-09 20:57:33,634][root][INFO] - Step 11128320 @ 3581.1 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 11128320, mean_episode_return = 52.203, mean_episode_step = 2148.3, total_loss = 93.392, pg_loss = 29.209, baseline_loss = 69.545, entropy_loss = -5.3618, learner_queue_size = 32, _tick = 1807, _time = 1.6548e+09, train_seconds = 2973.4)
[2022-06-09 20:57:38,638][root][INFO] - Step 11148800 @ 4092.8 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 11148800, mean_episode_return = None, mean_episode_step = 2587.7, total_loss = -106.0, pg_loss = -105.28, baseline_loss = 4.7251, entropy_loss = -5.4477, learner_queue_size = 32, _tick = 1809, _time = 1.6548e+09, train_seconds = 2978.4)
[2022-06-09 20:57:43,642][root][INFO] - Step 11166720 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 11166720, mean_episode_return = None, mean_episode_step = 2374.2, total_loss = 51.662, pg_loss = 34.25, baseline_loss = 23.114, entropy_loss = -5.7021, learner_queue_size = 32, _tick = 1811, _time = 1.6548e+09, train_seconds = 2983.4)
[2022-06-09 20:57:48,646][root][INFO] - Step 11184640 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 11184640, mean_episode_return = None, mean_episode_step = 2823.2, total_loss = 107.51, pg_loss = 68.017, baseline_loss = 44.656, entropy_loss = -5.1598, learner_queue_size = 32, _tick = 1814, _time = 1.6548e+09, train_seconds = 2988.5)
[2022-06-09 20:57:53,650][root][INFO] - Step 11205120 @ 4092.7 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 11205120, mean_episode_return = None, mean_episode_step = 2660.7, total_loss = 35.141, pg_loss = 16.009, baseline_loss = 24.797, entropy_loss = -5.6641, learner_queue_size = 32, _tick = 1819, _time = 1.6548e+09, train_seconds = 2993.5)
[2022-06-09 20:57:58,654][root][INFO] - Step 11223040 @ 3581.2 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 11223040, mean_episode_return = 15.975, mean_episode_step = 2101.9, total_loss = -177.21, pg_loss = -181.8, baseline_loss = 10.223, entropy_loss = -5.6334, learner_queue_size = 32, _tick = 1821, _time = 1.6548e+09, train_seconds = 2998.5)
[2022-06-09 20:58:03,659][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-09 20:58:03,796][root][INFO] - Step 11243520 @ 4092.4 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 11243520, mean_episode_return = None, mean_episode_step = 2409.8, total_loss = 80.472, pg_loss = 47.162, baseline_loss = 38.742, entropy_loss = -5.4328, learner_queue_size = 32, _tick = 1826, _time = 1.6548e+09, train_seconds = 3003.5)
[2022-06-09 20:58:08,802][root][INFO] - Step 11261440 @ 3484.0 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 11261440, mean_episode_return = None, mean_episode_step = 2803.2, total_loss = -49.452, pg_loss = -48.808, baseline_loss = 4.7137, entropy_loss = -5.3577, learner_queue_size = 32, _tick = 1830, _time = 1.6548e+09, train_seconds = 3008.6)
[2022-06-09 20:58:13,806][root][INFO] - Step 11279360 @ 3581.2 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 11279360, mean_episode_return = 41.92, mean_episode_step = 2460.1, total_loss = -81.478, pg_loss = -83.521, baseline_loss = 7.3286, entropy_loss = -5.2853, learner_queue_size = 32, _tick = 1833, _time = 1.6548e+09, train_seconds = 3013.6)
[2022-06-09 20:58:18,810][root][INFO] - Step 11299840 @ 4092.7 SPS. Inference batcher size: 77. Learner queue size: 32. Other stats: (step = 11299840, mean_episode_return = 44.92, mean_episode_step = 2747.5, total_loss = 116.09, pg_loss = 75.853, baseline_loss = 45.879, entropy_loss = -5.6394, learner_queue_size = 32, _tick = 1837, _time = 1.6548e+09, train_seconds = 3018.6)
[2022-06-09 20:58:23,814][root][INFO] - Step 11317760 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 11317760, mean_episode_return = None, mean_episode_step = 3017.0, total_loss = 0.54396, pg_loss = -1.4928, baseline_loss = 8.0339, entropy_loss = -5.9972, learner_queue_size = 32, _tick = 1841, _time = 1.6548e+09, train_seconds = 3023.6)
[2022-06-09 20:58:28,820][root][INFO] - Step 11338240 @ 4091.5 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 11338240, mean_episode_return = 87.467, mean_episode_step = 2689.7, total_loss = 53.683, pg_loss = 32.518, baseline_loss = 26.728, entropy_loss = -5.5626, learner_queue_size = 32, _tick = 1846, _time = 1.6548e+09, train_seconds = 3028.6)
[2022-06-09 20:58:33,822][root][INFO] - Step 11356160 @ 3582.2 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 11356160, mean_episode_return = 37.171, mean_episode_step = 2196.1, total_loss = 324.8, pg_loss = 255.94, baseline_loss = 74.705, entropy_loss = -5.8434, learner_queue_size = 32, _tick = 1852, _time = 1.6548e+09, train_seconds = 3033.6)
[2022-06-09 20:58:38,827][root][INFO] - Step 11374080 @ 3580.3 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 11374080, mean_episode_return = 19.307, mean_episode_step = 2621.6, total_loss = -24.078, pg_loss = -54.883, baseline_loss = 35.996, entropy_loss = -5.1912, learner_queue_size = 32, _tick = 1858, _time = 1.6548e+09, train_seconds = 3038.6)
[2022-06-09 20:58:43,830][root][INFO] - Step 11394560 @ 4093.8 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 11394560, mean_episode_return = 45.37, mean_episode_step = 1403.7, total_loss = 65.847, pg_loss = 34.955, baseline_loss = 35.606, entropy_loss = -4.7143, learner_queue_size = 32, _tick = 1866, _time = 1.6548e+09, train_seconds = 3043.6)
[2022-06-09 20:58:48,834][root][INFO] - Step 11412480 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 11412480, mean_episode_return = None, mean_episode_step = 1580.7, total_loss = -77.978, pg_loss = -96.984, baseline_loss = 23.808, entropy_loss = -4.8009, learner_queue_size = 32, _tick = 1871, _time = 1.6548e+09, train_seconds = 3048.6)
[2022-06-09 20:58:53,838][root][INFO] - Step 11430400 @ 3581.1 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 11430400, mean_episode_return = None, mean_episode_step = 2297.8, total_loss = -64.057, pg_loss = -76.457, baseline_loss = 17.309, entropy_loss = -4.9083, learner_queue_size = 32, _tick = 1871, _time = 1.6548e+09, train_seconds = 3053.6)
[2022-06-09 20:58:58,842][root][INFO] - Step 11450880 @ 4092.7 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 11450880, mean_episode_return = None, mean_episode_step = 2016.9, total_loss = -52.865, pg_loss = -63.29, baseline_loss = 15.421, entropy_loss = -4.9959, learner_queue_size = 32, _tick = 1872, _time = 1.6548e+09, train_seconds = 3058.6)
[2022-06-09 20:59:03,846][root][INFO] - Step 11468800 @ 3581.1 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 11468800, mean_episode_return = 247.36, mean_episode_step = 1791.5, total_loss = -146.38, pg_loss = -161.25, baseline_loss = 20.323, entropy_loss = -5.4491, learner_queue_size = 32, _tick = 1874, _time = 1.6548e+09, train_seconds = 3063.7)
[2022-06-09 20:59:08,850][root][INFO] - Step 11486720 @ 3581.2 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 11486720, mean_episode_return = None, mean_episode_step = 2360.3, total_loss = 193.49, pg_loss = 135.22, baseline_loss = 63.924, entropy_loss = -5.653, learner_queue_size = 32, _tick = 1876, _time = 1.6548e+09, train_seconds = 3068.7)
[2022-06-09 20:59:13,854][root][INFO] - Step 11504640 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 11504640, mean_episode_return = 119.49, mean_episode_step = 2366.8, total_loss = 38.629, pg_loss = -5.3609, baseline_loss = 49.266, entropy_loss = -5.2758, learner_queue_size = 32, _tick = 1882, _time = 1.6548e+09, train_seconds = 3073.7)
[2022-06-09 20:59:18,859][root][INFO] - Step 11525120 @ 4092.8 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (step = 11525120, mean_episode_return = 28.43, mean_episode_step = 2004.1, total_loss = -45.827, pg_loss = -72.544, baseline_loss = 31.998, entropy_loss = -5.2811, learner_queue_size = 32, _tick = 1887, _time = 1.6548e+09, train_seconds = 3078.7)
[2022-06-09 20:59:23,862][root][INFO] - Step 11543040 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 11543040, mean_episode_return = 95.58, mean_episode_step = 2995.1, total_loss = -65.355, pg_loss = -91.395, baseline_loss = 31.468, entropy_loss = -5.4278, learner_queue_size = 32, _tick = 1889, _time = 1.6548e+09, train_seconds = 3083.7)
[2022-06-09 20:59:28,866][root][INFO] - Step 11560960 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 11560960, mean_episode_return = 19.77, mean_episode_step = 1857.1, total_loss = 460.77, pg_loss = 323.29, baseline_loss = 142.62, entropy_loss = -5.1424, learner_queue_size = 32, _tick = 1892, _time = 1.6548e+09, train_seconds = 3088.7)
[2022-06-09 20:59:33,870][root][INFO] - Step 11581440 @ 4092.8 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 11581440, mean_episode_return = None, mean_episode_step = 1427.7, total_loss = 279.49, pg_loss = 182.82, baseline_loss = 102.25, entropy_loss = -5.5829, learner_queue_size = 32, _tick = 1896, _time = 1.6548e+09, train_seconds = 3093.7)
[2022-06-09 20:59:38,874][root][INFO] - Step 11599360 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 11599360, mean_episode_return = 6.8096, mean_episode_step = 1708.4, total_loss = -31.212, pg_loss = -58.079, baseline_loss = 32.373, entropy_loss = -5.5057, learner_queue_size = 32, _tick = 1900, _time = 1.6548e+09, train_seconds = 3098.7)
[2022-06-09 20:59:43,878][root][INFO] - Step 11619840 @ 4092.5 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 11619840, mean_episode_return = 58.721, mean_episode_step = 1814.9, total_loss = 99.901, pg_loss = 63.847, baseline_loss = 41.529, entropy_loss = -5.4744, learner_queue_size = 32, _tick = 1906, _time = 1.6548e+09, train_seconds = 3103.7)
[2022-06-09 20:59:48,882][root][INFO] - Step 11637760 @ 3581.3 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 11637760, mean_episode_return = None, mean_episode_step = 2019.1, total_loss = -19.746, pg_loss = -36.772, baseline_loss = 22.141, entropy_loss = -5.1156, learner_queue_size = 32, _tick = 1908, _time = 1.6548e+09, train_seconds = 3108.7)
[2022-06-09 20:59:53,886][root][INFO] - Step 11655680 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 11655680, mean_episode_return = -2.6003, mean_episode_step = 1979.3, total_loss = 51.319, pg_loss = 9.7727, baseline_loss = 47.075, entropy_loss = -5.5291, learner_queue_size = 32, _tick = 1913, _time = 1.6548e+09, train_seconds = 3113.7)
[2022-06-09 20:59:58,890][root][INFO] - Step 11676160 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 11676160, mean_episode_return = 38.981, mean_episode_step = 2394.4, total_loss = 212.47, pg_loss = 107.83, baseline_loss = 109.03, entropy_loss = -4.3982, learner_queue_size = 32, _tick = 1919, _time = 1.6548e+09, train_seconds = 3118.7)
[2022-06-09 21:00:03,894][root][INFO] - Step 11694080 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 11694080, mean_episode_return = -5.8703, mean_episode_step = 2361.0, total_loss = 4.1567, pg_loss = -28.786, baseline_loss = 37.542, entropy_loss = -4.5985, learner_queue_size = 32, _tick = 1923, _time = 1.6548e+09, train_seconds = 3123.7)
[2022-06-09 21:00:08,898][root][INFO] - Step 11714560 @ 4092.6 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 11714560, mean_episode_return = 3.0296, mean_episode_step = 1888.3, total_loss = 133.43, pg_loss = 64.073, baseline_loss = 73.621, entropy_loss = -4.2655, learner_queue_size = 32, _tick = 1928, _time = 1.6548e+09, train_seconds = 3128.7)
[2022-06-09 21:00:13,902][root][INFO] - Step 11732480 @ 3581.2 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 11732480, mean_episode_return = -8.7205, mean_episode_step = 2101.8, total_loss = 64.61, pg_loss = 32.67, baseline_loss = 36.609, entropy_loss = -4.669, learner_queue_size = 32, _tick = 1932, _time = 1.6548e+09, train_seconds = 3133.7)
[2022-06-09 21:00:18,906][root][INFO] - Step 11752960 @ 4092.7 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 11752960, mean_episode_return = 47.771, mean_episode_step = 2279.8, total_loss = 18.473, pg_loss = -4.0545, baseline_loss = 26.772, entropy_loss = -4.2448, learner_queue_size = 32, _tick = 1936, _time = 1.6548e+09, train_seconds = 3138.7)
[2022-06-09 21:00:23,910][root][INFO] - Step 11770880 @ 3580.8 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 11770880, mean_episode_return = None, mean_episode_step = 1675.7, total_loss = -16.642, pg_loss = -13.476, baseline_loss = 2.322, entropy_loss = -5.4879, learner_queue_size = 32, _tick = 1939, _time = 1.6548e+09, train_seconds = 3143.7)
[2022-06-09 21:00:28,914][root][INFO] - Step 11788800 @ 3581.5 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 11788800, mean_episode_return = 164.13, mean_episode_step = 2217.7, total_loss = -5.9465, pg_loss = -14.585, baseline_loss = 14.153, entropy_loss = -5.5147, learner_queue_size = 32, _tick = 1943, _time = 1.6548e+09, train_seconds = 3148.7)
[2022-06-09 21:00:33,918][root][INFO] - Step 11809280 @ 4092.7 SPS. Inference batcher size: 80. Learner queue size: 32. Other stats: (step = 11809280, mean_episode_return = 14.615, mean_episode_step = 2398.3, total_loss = -28.884, pg_loss = -43.424, baseline_loss = 19.981, entropy_loss = -5.4416, learner_queue_size = 32, _tick = 1948, _time = 1.6548e+09, train_seconds = 3153.7)
[2022-06-09 21:00:38,922][root][INFO] - Step 11827200 @ 3581.0 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 11827200, mean_episode_return = None, mean_episode_step = 1750.8, total_loss = 517.84, pg_loss = 388.1, baseline_loss = 134.83, entropy_loss = -5.0925, learner_queue_size = 32, _tick = 1950, _time = 1.6548e+09, train_seconds = 3158.7)
[2022-06-09 21:00:43,926][root][INFO] - Step 11847680 @ 4092.8 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 11847680, mean_episode_return = None, mean_episode_step = 1508.9, total_loss = -68.228, pg_loss = -69.847, baseline_loss = 6.3785, entropy_loss = -4.759, learner_queue_size = 32, _tick = 1952, _time = 1.6548e+09, train_seconds = 3163.7)
[2022-06-09 21:00:48,931][root][INFO] - Step 11865600 @ 3581.2 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 11865600, mean_episode_return = 48.7, mean_episode_step = 2634.7, total_loss = 24.671, pg_loss = -8.5265, baseline_loss = 38.462, entropy_loss = -5.2651, learner_queue_size = 32, _tick = 1955, _time = 1.6548e+09, train_seconds = 3168.7)
[2022-06-09 21:00:53,934][root][INFO] - Step 11886080 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 11886080, mean_episode_return = None, mean_episode_step = 2312.4, total_loss = -57.257, pg_loss = -57.901, baseline_loss = 5.3256, entropy_loss = -4.6811, learner_queue_size = 32, _tick = 1957, _time = 1.6548e+09, train_seconds = 3173.7)
[2022-06-09 21:00:58,938][root][INFO] - Step 11904000 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 11904000, mean_episode_return = None, mean_episode_step = 2264.2, total_loss = -23.458, pg_loss = -25.744, baseline_loss = 8.1909, entropy_loss = -5.9053, learner_queue_size = 32, _tick = 1960, _time = 1.6548e+09, train_seconds = 3178.7)
[2022-06-09 21:01:03,942][root][INFO] - Step 11921920 @ 3581.2 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 11921920, mean_episode_return = None, mean_episode_step = 1544.9, total_loss = 35.003, pg_loss = 22.576, baseline_loss = 17.084, entropy_loss = -4.6573, learner_queue_size = 32, _tick = 1966, _time = 1.6548e+09, train_seconds = 3183.7)
[2022-06-09 21:01:08,946][root][INFO] - Step 11942400 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 11942400, mean_episode_return = None, mean_episode_step = 1728.9, total_loss = 51.981, pg_loss = 24.043, baseline_loss = 32.566, entropy_loss = -4.6284, learner_queue_size = 32, _tick = 1970, _time = 1.6548e+09, train_seconds = 3188.8)
[2022-06-09 21:01:13,950][root][INFO] - Step 11960320 @ 3581.1 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 11960320, mean_episode_return = None, mean_episode_step = 1379.5, total_loss = 210.12, pg_loss = 102.2, baseline_loss = 112.35, entropy_loss = -4.4281, learner_queue_size = 32, _tick = 1973, _time = 1.6548e+09, train_seconds = 3193.8)
[2022-06-09 21:01:18,954][root][INFO] - Step 11980800 @ 4092.6 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (step = 11980800, mean_episode_return = None, mean_episode_step = 1885.1, total_loss = -2.8853, pg_loss = -28.382, baseline_loss = 29.662, entropy_loss = -4.1653, learner_queue_size = 32, _tick = 1975, _time = 1.6548e+09, train_seconds = 3198.8)
[2022-06-09 21:01:23,958][root][INFO] - Step 11998720 @ 3581.3 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 11998720, mean_episode_return = None, mean_episode_step = 1872.4, total_loss = -71.412, pg_loss = -79.152, baseline_loss = 11.777, entropy_loss = -4.037, learner_queue_size = 32, _tick = 1976, _time = 1.6548e+09, train_seconds = 3203.8)
[2022-06-09 21:01:28,962][root][INFO] - Step 12019200 @ 4092.7 SPS. Inference batcher size: 81. Learner queue size: 32. Other stats: (step = 12019200, mean_episode_return = 13.01, mean_episode_step = 2432.4, total_loss = -101.54, pg_loss = -100.09, baseline_loss = 3.1643, entropy_loss = -4.6089, learner_queue_size = 32, _tick = 1978, _time = 1.6548e+09, train_seconds = 3208.8)
[2022-06-09 21:01:33,966][root][INFO] - Step 12037120 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 12037120, mean_episode_return = 9.4097, mean_episode_step = 2650.7, total_loss = -118.12, pg_loss = -114.83, baseline_loss = 1.6497, entropy_loss = -4.9331, learner_queue_size = 32, _tick = 1979, _time = 1.6548e+09, train_seconds = 3213.8)
[2022-06-09 21:01:38,970][root][INFO] - Step 12057600 @ 4092.8 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 12057600, mean_episode_return = None, mean_episode_step = 2534.0, total_loss = 310.71, pg_loss = 167.42, baseline_loss = 148.39, entropy_loss = -5.1004, learner_queue_size = 32, _tick = 1981, _time = 1.6548e+09, train_seconds = 3218.8)
[2022-06-09 21:01:43,974][root][INFO] - Step 12075520 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 12075520, mean_episode_return = -24.56, mean_episode_step = 2292.4, total_loss = -23.718, pg_loss = -35.044, baseline_loss = 16.466, entropy_loss = -5.1396, learner_queue_size = 32, _tick = 1985, _time = 1.6548e+09, train_seconds = 3223.8)
[2022-06-09 21:01:48,978][root][INFO] - Step 12096000 @ 4092.7 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 12096000, mean_episode_return = 60.009, mean_episode_step = 2485.9, total_loss = -124.86, pg_loss = -128.44, baseline_loss = 8.369, entropy_loss = -4.7875, learner_queue_size = 32, _tick = 1988, _time = 1.6548e+09, train_seconds = 3228.8)
[2022-06-09 21:01:53,982][root][INFO] - Step 12113920 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 12113920, mean_episode_return = None, mean_episode_step = 2148.7, total_loss = 88.664, pg_loss = 45.692, baseline_loss = 47.757, entropy_loss = -4.7848, learner_queue_size = 32, _tick = 1994, _time = 1.6548e+09, train_seconds = 3233.8)
[2022-06-09 21:01:58,987][root][INFO] - Step 12131840 @ 3580.3 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 12131840, mean_episode_return = 96.127, mean_episode_step = 1906.4, total_loss = -0.13092, pg_loss = -21.532, baseline_loss = 26.494, entropy_loss = -5.0929, learner_queue_size = 32, _tick = 1999, _time = 1.6548e+09, train_seconds = 3238.8)
[2022-06-09 21:02:03,990][root][INFO] - Step 12152320 @ 4093.7 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 12152320, mean_episode_return = 17.685, mean_episode_step = 2169.6, total_loss = 5.5712, pg_loss = -20.73, baseline_loss = 31.806, entropy_loss = -5.5046, learner_queue_size = 32, _tick = 2006, _time = 1.6548e+09, train_seconds = 3243.8)
[2022-06-09 21:02:08,994][root][INFO] - Step 12170240 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 12170240, mean_episode_return = None, mean_episode_step = 2037.3, total_loss = 232.36, pg_loss = 177.42, baseline_loss = 60.862, entropy_loss = -5.9176, learner_queue_size = 32, _tick = 2009, _time = 1.6548e+09, train_seconds = 3248.8)
[2022-06-09 21:02:13,998][root][INFO] - Step 12188160 @ 3581.2 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 12188160, mean_episode_return = 88.439, mean_episode_step = 2383.7, total_loss = 159.74, pg_loss = 88.762, baseline_loss = 76.544, entropy_loss = -5.5654, learner_queue_size = 32, _tick = 2013, _time = 1.6548e+09, train_seconds = 3253.8)
[2022-06-09 21:02:19,002][root][INFO] - Step 12206080 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 12206080, mean_episode_return = 97.35, mean_episode_step = 2157.5, total_loss = 96.512, pg_loss = 49.594, baseline_loss = 51.934, entropy_loss = -5.0159, learner_queue_size = 32, _tick = 2018, _time = 1.6548e+09, train_seconds = 3258.8)
[2022-06-09 21:02:24,006][root][INFO] - Step 12224000 @ 3581.2 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 12224000, mean_episode_return = 51.13, mean_episode_step = 1787.3, total_loss = 253.67, pg_loss = 157.49, baseline_loss = 101.41, entropy_loss = -5.2264, learner_queue_size = 32, _tick = 2021, _time = 1.6548e+09, train_seconds = 3263.8)
[2022-06-09 21:02:29,010][root][INFO] - Step 12244480 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 12244480, mean_episode_return = None, mean_episode_step = 2315.1, total_loss = 24.244, pg_loss = 13.252, baseline_loss = 16.772, entropy_loss = -5.7797, learner_queue_size = 32, _tick = 2027, _time = 1.6548e+09, train_seconds = 3268.8)
[2022-06-09 21:02:34,014][root][INFO] - Step 12262400 @ 3581.2 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 12262400, mean_episode_return = 81.271, mean_episode_step = 1773.2, total_loss = 606.51, pg_loss = 370.71, baseline_loss = 241.4, entropy_loss = -5.6076, learner_queue_size = 32, _tick = 2034, _time = 1.6548e+09, train_seconds = 3273.8)
[2022-06-09 21:02:39,018][root][INFO] - Step 12282880 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 12282880, mean_episode_return = None, mean_episode_step = 1858.1, total_loss = 97.022, pg_loss = 80.903, baseline_loss = 21.061, entropy_loss = -4.9428, learner_queue_size = 32, _tick = 2037, _time = 1.6548e+09, train_seconds = 3278.8)
[2022-06-09 21:02:44,022][root][INFO] - Step 12300800 @ 3581.1 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (step = 12300800, mean_episode_return = None, mean_episode_step = 2070.1, total_loss = 92.725, pg_loss = 55.582, baseline_loss = 41.744, entropy_loss = -4.6012, learner_queue_size = 32, _tick = 2041, _time = 1.6548e+09, train_seconds = 3283.8)
[2022-06-09 21:02:49,026][root][INFO] - Step 12321280 @ 4092.8 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 12321280, mean_episode_return = None, mean_episode_step = 2313.9, total_loss = 25.06, pg_loss = -0.68954, baseline_loss = 31.117, entropy_loss = -5.3676, learner_queue_size = 32, _tick = 2046, _time = 1.6548e+09, train_seconds = 3288.8)
[2022-06-09 21:02:54,030][root][INFO] - Step 12339200 @ 3581.2 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 12339200, mean_episode_return = 109.97, mean_episode_step = 2217.8, total_loss = -85.036, pg_loss = -105.92, baseline_loss = 26.345, entropy_loss = -5.4647, learner_queue_size = 32, _tick = 2048, _time = 1.6548e+09, train_seconds = 3293.8)
[2022-06-09 21:02:59,034][root][INFO] - Step 12359680 @ 4092.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 12359680, mean_episode_return = 21.17, mean_episode_step = 2892.2, total_loss = -25.86, pg_loss = -44.217, baseline_loss = 23.914, entropy_loss = -5.5568, learner_queue_size = 32, _tick = 2052, _time = 1.6548e+09, train_seconds = 3298.8)
[2022-06-09 21:03:04,038][root][INFO] - Step 12377600 @ 3581.2 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 12377600, mean_episode_return = 39.756, mean_episode_step = 2024.9, total_loss = 47.433, pg_loss = 2.0142, baseline_loss = 50.703, entropy_loss = -5.2843, learner_queue_size = 32, _tick = 2056, _time = 1.6548e+09, train_seconds = 3303.8)
[2022-06-09 21:03:09,042][root][INFO] - Step 12395520 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 12395520, mean_episode_return = 60.881, mean_episode_step = 1615.4, total_loss = 42.484, pg_loss = 23.469, baseline_loss = 24.099, entropy_loss = -5.084, learner_queue_size = 32, _tick = 2058, _time = 1.6548e+09, train_seconds = 3308.8)
[2022-06-09 21:03:14,046][root][INFO] - Step 12416000 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 12416000, mean_episode_return = 111.8, mean_episode_step = 2503.6, total_loss = 271.67, pg_loss = 157.68, baseline_loss = 118.63, entropy_loss = -4.6312, learner_queue_size = 32, _tick = 2061, _time = 1.6548e+09, train_seconds = 3313.9)
[2022-06-09 21:03:19,050][root][INFO] - Step 12433920 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 12433920, mean_episode_return = None, mean_episode_step = 2680.4, total_loss = 88.747, pg_loss = 45.462, baseline_loss = 48.052, entropy_loss = -4.7672, learner_queue_size = 32, _tick = 2063, _time = 1.6548e+09, train_seconds = 3318.9)
[2022-06-09 21:03:24,055][root][INFO] - Step 12454400 @ 4091.6 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 12454400, mean_episode_return = None, mean_episode_step = 2212.8, total_loss = 49.49, pg_loss = 12.937, baseline_loss = 41.612, entropy_loss = -5.0595, learner_queue_size = 32, _tick = 2063, _time = 1.6548e+09, train_seconds = 3323.9)
[2022-06-09 21:03:29,058][root][INFO] - Step 12472320 @ 3582.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 12472320, mean_episode_return = None, mean_episode_step = 2176.1, total_loss = -88.943, pg_loss = -86.936, baseline_loss = 3.3477, entropy_loss = -5.3548, learner_queue_size = 32, _tick = 2066, _time = 1.6548e+09, train_seconds = 3328.9)
[2022-06-09 21:03:34,062][root][INFO] - Step 12490240 @ 3581.2 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 12490240, mean_episode_return = None, mean_episode_step = 2202.3, total_loss = 187.88, pg_loss = 125.17, baseline_loss = 67.89, entropy_loss = -5.1807, learner_queue_size = 32, _tick = 2068, _time = 1.6548e+09, train_seconds = 3333.9)
[2022-06-09 21:03:39,066][root][INFO] - Step 12508160 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 12508160, mean_episode_return = None, mean_episode_step = 1684.7, total_loss = -27.225, pg_loss = -26.99, baseline_loss = 5.3423, entropy_loss = -5.5766, learner_queue_size = 32, _tick = 2072, _time = 1.6548e+09, train_seconds = 3338.9)
[2022-06-09 21:03:44,070][root][INFO] - Step 12526080 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 12526080, mean_episode_return = 75.369, mean_episode_step = 2315.1, total_loss = -92.118, pg_loss = -104.5, baseline_loss = 17.572, entropy_loss = -5.1915, learner_queue_size = 32, _tick = 2077, _time = 1.6548e+09, train_seconds = 3343.9)
[2022-06-09 21:03:49,075][root][INFO] - Step 12546560 @ 4092.3 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 12546560, mean_episode_return = None, mean_episode_step = 2430.8, total_loss = -13.829, pg_loss = -37.409, baseline_loss = 28.439, entropy_loss = -4.8588, learner_queue_size = 32, _tick = 2080, _time = 1.6548e+09, train_seconds = 3348.9)
[2022-06-09 21:03:54,078][root][INFO] - Step 12564480 @ 3581.5 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 12564480, mean_episode_return = 34.29, mean_episode_step = 2203.7, total_loss = 992.07, pg_loss = 395.01, baseline_loss = 602.23, entropy_loss = -5.168, learner_queue_size = 32, _tick = 2082, _time = 1.6548e+09, train_seconds = 3353.9)
[2022-06-09 21:03:59,082][root][INFO] - Step 12584960 @ 4092.7 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 12584960, mean_episode_return = 40.804, mean_episode_step = 2237.9, total_loss = -6.8667, pg_loss = -27.639, baseline_loss = 26.023, entropy_loss = -5.2506, learner_queue_size = 32, _tick = 2085, _time = 1.6548e+09, train_seconds = 3358.9)
[2022-06-09 21:04:04,086][root][INFO] - Step 12602880 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 12602880, mean_episode_return = 90.549, mean_episode_step = 2118.2, total_loss = 177.4, pg_loss = 100.55, baseline_loss = 81.781, entropy_loss = -4.9367, learner_queue_size = 32, _tick = 2090, _time = 1.6548e+09, train_seconds = 3363.9)
[2022-06-09 21:04:09,090][root][INFO] - Step 12620800 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 12620800, mean_episode_return = 109.65, mean_episode_step = 2445.3, total_loss = 233.03, pg_loss = 124.76, baseline_loss = 113.02, entropy_loss = -4.7538, learner_queue_size = 32, _tick = 2096, _time = 1.6548e+09, train_seconds = 3368.9)
[2022-06-09 21:04:14,094][root][INFO] - Step 12638720 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 12638720, mean_episode_return = -13.68, mean_episode_step = 2294.5, total_loss = -36.873, pg_loss = -44.687, baseline_loss = 12.757, entropy_loss = -4.9437, learner_queue_size = 32, _tick = 2100, _time = 1.6548e+09, train_seconds = 3373.9)
[2022-06-09 21:04:19,098][root][INFO] - Step 12656640 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 12656640, mean_episode_return = None, mean_episode_step = 2296.4, total_loss = -82.983, pg_loss = -78.065, baseline_loss = 0.72217, entropy_loss = -5.6406, learner_queue_size = 32, _tick = 2105, _time = 1.6548e+09, train_seconds = 3378.9)
[2022-06-09 21:04:24,102][root][INFO] - Step 12677120 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 12677120, mean_episode_return = None, mean_episode_step = 1738.5, total_loss = 52.232, pg_loss = 24.545, baseline_loss = 33.119, entropy_loss = -5.4321, learner_queue_size = 32, _tick = 2110, _time = 1.6548e+09, train_seconds = 3383.9)
[2022-06-09 21:04:29,106][root][INFO] - Step 12695040 @ 3581.2 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 12695040, mean_episode_return = 26.41, mean_episode_step = 2389.3, total_loss = 372.37, pg_loss = 283.53, baseline_loss = 94.443, entropy_loss = -5.6049, learner_queue_size = 32, _tick = 2115, _time = 1.6548e+09, train_seconds = 3388.9)
[2022-06-09 21:04:34,110][root][INFO] - Step 12715520 @ 4092.8 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 12715520, mean_episode_return = None, mean_episode_step = 2330.8, total_loss = -45.729, pg_loss = -47.923, baseline_loss = 7.5558, entropy_loss = -5.3616, learner_queue_size = 32, _tick = 2121, _time = 1.6548e+09, train_seconds = 3393.9)
[2022-06-09 21:04:39,114][root][INFO] - Step 12733440 @ 3581.1 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (step = 12733440, mean_episode_return = None, mean_episode_step = 2120.0, total_loss = -19.857, pg_loss = -39.018, baseline_loss = 24.368, entropy_loss = -5.2057, learner_queue_size = 32, _tick = 2126, _time = 1.6548e+09, train_seconds = 3398.9)
[2022-06-09 21:04:44,118][root][INFO] - Step 12753920 @ 4092.7 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 12753920, mean_episode_return = 57.156, mean_episode_step = 2247.1, total_loss = -48.403, pg_loss = -98.976, baseline_loss = 55.788, entropy_loss = -5.2143, learner_queue_size = 32, _tick = 2132, _time = 1.6548e+09, train_seconds = 3403.9)
[2022-06-09 21:04:49,122][root][INFO] - Step 12771840 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 12771840, mean_episode_return = None, mean_episode_step = 1416.2, total_loss = -5.9253, pg_loss = -28.248, baseline_loss = 27.702, entropy_loss = -5.379, learner_queue_size = 32, _tick = 2135, _time = 1.6548e+09, train_seconds = 3408.9)
[2022-06-09 21:04:54,126][root][INFO] - Step 12792320 @ 4092.6 SPS. Inference batcher size: 76. Learner queue size: 32. Other stats: (step = 12792320, mean_episode_return = 82.646, mean_episode_step = 2289.9, total_loss = 0.96811, pg_loss = -41.943, baseline_loss = 48.68, entropy_loss = -5.7688, learner_queue_size = 32, _tick = 2141, _time = 1.6548e+09, train_seconds = 3413.9)
[2022-06-09 21:04:59,130][root][INFO] - Step 12810240 @ 3581.2 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 12810240, mean_episode_return = 42.591, mean_episode_step = 1704.2, total_loss = 479.22, pg_loss = 268.4, baseline_loss = 216.16, entropy_loss = -5.3366, learner_queue_size = 32, _tick = 2148, _time = 1.6548e+09, train_seconds = 3418.9)
[2022-06-09 21:05:04,134][root][INFO] - Step 12828160 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 12828160, mean_episode_return = 49.531, mean_episode_step = 1991.7, total_loss = 547.83, pg_loss = 345.48, baseline_loss = 207.57, entropy_loss = -5.2201, learner_queue_size = 32, _tick = 2153, _time = 1.6548e+09, train_seconds = 3423.9)
[2022-06-09 21:05:09,138][root][INFO] - Step 12846080 @ 3581.2 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 12846080, mean_episode_return = -8.3507, mean_episode_step = 1980.2, total_loss = -8.1207, pg_loss = -48.917, baseline_loss = 45.803, entropy_loss = -5.0072, learner_queue_size = 32, _tick = 2157, _time = 1.6548e+09, train_seconds = 3428.9)
[2022-06-09 21:05:14,142][root][INFO] - Step 12866560 @ 4092.7 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 12866560, mean_episode_return = None, mean_episode_step = 1601.3, total_loss = 366.18, pg_loss = 268.86, baseline_loss = 102.18, entropy_loss = -4.8741, learner_queue_size = 32, _tick = 2161, _time = 1.6548e+09, train_seconds = 3433.9)
[2022-06-09 21:05:19,146][root][INFO] - Step 12884480 @ 3581.2 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 12884480, mean_episode_return = 104.51, mean_episode_step = 1862.5, total_loss = -64.7, pg_loss = -74.425, baseline_loss = 14.871, entropy_loss = -5.1465, learner_queue_size = 32, _tick = 2164, _time = 1.6548e+09, train_seconds = 3439.0)
[2022-06-09 21:05:24,150][root][INFO] - Step 12904960 @ 4092.7 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 12904960, mean_episode_return = None, mean_episode_step = 1767.0, total_loss = -33.618, pg_loss = -34.956, baseline_loss = 7.0868, entropy_loss = -5.7481, learner_queue_size = 32, _tick = 2170, _time = 1.6548e+09, train_seconds = 3444.0)
[2022-06-09 21:05:29,158][root][INFO] - Step 12922880 @ 3578.0 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 12922880, mean_episode_return = None, mean_episode_step = 1895.5, total_loss = 135.05, pg_loss = 79.293, baseline_loss = 61.446, entropy_loss = -5.6852, learner_queue_size = 32, _tick = 2172, _time = 1.6548e+09, train_seconds = 3449.0)
[2022-06-09 21:05:34,166][root][INFO] - Step 12940800 @ 3578.5 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 12940800, mean_episode_return = None, mean_episode_step = 1659.0, total_loss = 89.192, pg_loss = 46.478, baseline_loss = 48.513, entropy_loss = -5.7991, learner_queue_size = 32, _tick = 2176, _time = 1.6548e+09, train_seconds = 3454.0)
[2022-06-09 21:05:39,171][root][INFO] - Step 12961280 @ 4091.7 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 12961280, mean_episode_return = 65.872, mean_episode_step = 1885.5, total_loss = -30.473, pg_loss = -53.007, baseline_loss = 28.078, entropy_loss = -5.5438, learner_queue_size = 32, _tick = 2183, _time = 1.6548e+09, train_seconds = 3459.0)
[2022-06-09 21:05:44,174][root][INFO] - Step 12979200 @ 3582.0 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 12979200, mean_episode_return = 40.254, mean_episode_step = 1787.9, total_loss = 323.45, pg_loss = 225.43, baseline_loss = 103.54, entropy_loss = -5.5202, learner_queue_size = 32, _tick = 2187, _time = 1.6548e+09, train_seconds = 3464.0)
[2022-06-09 21:05:49,178][root][INFO] - Step 12997120 @ 3581.1 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 12997120, mean_episode_return = None, mean_episode_step = 1865.5, total_loss = -51.784, pg_loss = -50.749, baseline_loss = 3.8552, entropy_loss = -4.89, learner_queue_size = 32, _tick = 2190, _time = 1.6548e+09, train_seconds = 3469.0)
[2022-06-09 21:05:54,182][root][INFO] - Step 13017600 @ 4092.8 SPS. Inference batcher size: 87. Learner queue size: 32. Other stats: (step = 13017600, mean_episode_return = None, mean_episode_step = 1916.0, total_loss = 124.45, pg_loss = 79.534, baseline_loss = 50.366, entropy_loss = -5.447, learner_queue_size = 32, _tick = 2194, _time = 1.6548e+09, train_seconds = 3474.0)
[2022-06-09 21:05:59,186][root][INFO] - Step 13035520 @ 3581.1 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 13035520, mean_episode_return = -3.8208, mean_episode_step = 1690.3, total_loss = 82.284, pg_loss = 42.161, baseline_loss = 45.585, entropy_loss = -5.4628, learner_queue_size = 32, _tick = 2197, _time = 1.6548e+09, train_seconds = 3479.0)
[2022-06-09 21:06:04,190][root][INFO] - Step 13053440 @ 3581.2 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 13053440, mean_episode_return = None, mean_episode_step = 2079.9, total_loss = -83.872, pg_loss = -85.269, baseline_loss = 7.093, entropy_loss = -5.6964, learner_queue_size = 32, _tick = 2198, _time = 1.6548e+09, train_seconds = 3484.0)
[2022-06-09 21:06:09,194][root][INFO] - Step 13071360 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 13071360, mean_episode_return = None, mean_episode_step = 2002.4, total_loss = 229.86, pg_loss = 148.99, baseline_loss = 85.945, entropy_loss = -5.0746, learner_queue_size = 32, _tick = 2201, _time = 1.6548e+09, train_seconds = 3489.0)
[2022-06-09 21:06:14,198][root][INFO] - Step 13091840 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 13091840, mean_episode_return = 15.92, mean_episode_step = 1602.3, total_loss = -82.398, pg_loss = -92.286, baseline_loss = 14.634, entropy_loss = -4.7462, learner_queue_size = 32, _tick = 2203, _time = 1.6548e+09, train_seconds = 3494.0)
[2022-06-09 21:06:19,202][root][INFO] - Step 13109760 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 13109760, mean_episode_return = 12.88, mean_episode_step = 2482.8, total_loss = -42.802, pg_loss = -56.832, baseline_loss = 19.4, entropy_loss = -5.3705, learner_queue_size = 32, _tick = 2207, _time = 1.6548e+09, train_seconds = 3499.0)
[2022-06-09 21:06:24,206][root][INFO] - Step 13127680 @ 3581.1 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 13127680, mean_episode_return = None, mean_episode_step = 2307.5, total_loss = 278.61, pg_loss = 200.46, baseline_loss = 83.676, entropy_loss = -5.5169, learner_queue_size = 32, _tick = 2212, _time = 1.6548e+09, train_seconds = 3504.0)
[2022-06-09 21:06:29,210][root][INFO] - Step 13148160 @ 4092.7 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 13148160, mean_episode_return = None, mean_episode_step = 2306.9, total_loss = 64.1, pg_loss = 32.673, baseline_loss = 36.946, entropy_loss = -5.5187, learner_queue_size = 32, _tick = 2216, _time = 1.6548e+09, train_seconds = 3509.0)
[2022-06-09 21:06:34,214][root][INFO] - Step 13166080 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 13166080, mean_episode_return = 36.935, mean_episode_step = 2003.0, total_loss = 10.007, pg_loss = -59.223, baseline_loss = 74.412, entropy_loss = -5.1824, learner_queue_size = 32, _tick = 2220, _time = 1.6548e+09, train_seconds = 3514.0)
[2022-06-09 21:06:39,218][root][INFO] - Step 13184000 @ 3581.1 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 13184000, mean_episode_return = None, mean_episode_step = 1777.5, total_loss = 77.522, pg_loss = 55.312, baseline_loss = 28.189, entropy_loss = -5.9795, learner_queue_size = 32, _tick = 2221, _time = 1.6548e+09, train_seconds = 3519.0)
[2022-06-09 21:06:44,226][root][INFO] - Step 13204480 @ 4089.5 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 13204480, mean_episode_return = 92.558, mean_episode_step = 2098.2, total_loss = -71.393, pg_loss = -74.276, baseline_loss = 8.4405, entropy_loss = -5.5572, learner_queue_size = 32, _tick = 2226, _time = 1.6548e+09, train_seconds = 3524.0)
[2022-06-09 21:06:49,230][root][INFO] - Step 13219840 @ 3069.5 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 13219840, mean_episode_return = None, mean_episode_step = 2162.7, total_loss = 107.38, pg_loss = 60.806, baseline_loss = 52.565, entropy_loss = -5.9917, learner_queue_size = 32, _tick = 2227, _time = 1.6548e+09, train_seconds = 3529.0)
[2022-06-09 21:06:54,234][root][INFO] - Step 13240320 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 13240320, mean_episode_return = None, mean_episode_step = 2688.8, total_loss = 159.84, pg_loss = 95.515, baseline_loss = 70.104, entropy_loss = -5.7754, learner_queue_size = 32, _tick = 2231, _time = 1.6548e+09, train_seconds = 3534.0)
[2022-06-09 21:06:59,238][root][INFO] - Step 13258240 @ 3581.1 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 13258240, mean_episode_return = 47.991, mean_episode_step = 2615.9, total_loss = -65.552, pg_loss = -68.768, baseline_loss = 8.5015, entropy_loss = -5.285, learner_queue_size = 32, _tick = 2236, _time = 1.6548e+09, train_seconds = 3539.0)
[2022-06-09 21:07:04,242][root][INFO] - Step 13276160 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 13276160, mean_episode_return = 27.027, mean_episode_step = 2602.3, total_loss = 80.964, pg_loss = 35.242, baseline_loss = 52.128, entropy_loss = -6.4056, learner_queue_size = 32, _tick = 2242, _time = 1.6548e+09, train_seconds = 3544.0)
[2022-06-09 21:07:09,246][root][INFO] - Step 13296640 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 13296640, mean_episode_return = None, mean_episode_step = 2673.7, total_loss = 13.308, pg_loss = -14.173, baseline_loss = 33.118, entropy_loss = -5.6368, learner_queue_size = 32, _tick = 2245, _time = 1.6548e+09, train_seconds = 3549.1)
[2022-06-09 21:07:14,250][root][INFO] - Step 13314560 @ 3581.1 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 13314560, mean_episode_return = None, mean_episode_step = 2344.2, total_loss = -7.1049, pg_loss = -16.463, baseline_loss = 15.08, entropy_loss = -5.722, learner_queue_size = 32, _tick = 2249, _time = 1.6548e+09, train_seconds = 3554.1)
[2022-06-09 21:07:19,254][root][INFO] - Step 13332480 @ 3581.2 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 13332480, mean_episode_return = None, mean_episode_step = 2187.7, total_loss = -5.9723, pg_loss = -22.259, baseline_loss = 21.681, entropy_loss = -5.3944, learner_queue_size = 32, _tick = 2254, _time = 1.6548e+09, train_seconds = 3559.1)
[2022-06-09 21:07:24,258][root][INFO] - Step 13352960 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 13352960, mean_episode_return = 99.248, mean_episode_step = 2372.5, total_loss = 425.11, pg_loss = 279.41, baseline_loss = 151.27, entropy_loss = -5.5608, learner_queue_size = 32, _tick = 2259, _time = 1.6548e+09, train_seconds = 3564.1)
[2022-06-09 21:07:29,262][root][INFO] - Step 13370880 @ 3581.0 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 13370880, mean_episode_return = 15.55, mean_episode_step = 1622.9, total_loss = 30.903, pg_loss = -27.167, baseline_loss = 63.307, entropy_loss = -5.2359, learner_queue_size = 32, _tick = 2265, _time = 1.6548e+09, train_seconds = 3569.1)
[2022-06-09 21:07:34,268][root][INFO] - Step 13388800 @ 3580.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 13388800, mean_episode_return = None, mean_episode_step = 2101.7, total_loss = 121.19, pg_loss = 63.84, baseline_loss = 63.076, entropy_loss = -5.7303, learner_queue_size = 32, _tick = 2268, _time = 1.6548e+09, train_seconds = 3574.1)
[2022-06-09 21:07:39,270][root][INFO] - Step 13409280 @ 4094.1 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 13409280, mean_episode_return = None, mean_episode_step = 2232.5, total_loss = 1.0091, pg_loss = -29.819, baseline_loss = 36.258, entropy_loss = -5.4293, learner_queue_size = 32, _tick = 2272, _time = 1.6548e+09, train_seconds = 3579.1)
[2022-06-09 21:07:44,274][root][INFO] - Step 13427200 @ 3581.1 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 13427200, mean_episode_return = 29.842, mean_episode_step = 1823.2, total_loss = 54.928, pg_loss = 20.873, baseline_loss = 39.53, entropy_loss = -5.4752, learner_queue_size = 32, _tick = 2279, _time = 1.6548e+09, train_seconds = 3584.1)
[2022-06-09 21:07:49,278][root][INFO] - Step 13447680 @ 4092.7 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 13447680, mean_episode_return = None, mean_episode_step = 1811.5, total_loss = 127.19, pg_loss = 60.037, baseline_loss = 72.431, entropy_loss = -5.2806, learner_queue_size = 32, _tick = 2284, _time = 1.6548e+09, train_seconds = 3589.1)
[2022-06-09 21:07:54,282][root][INFO] - Step 13465600 @ 3581.2 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 13465600, mean_episode_return = None, mean_episode_step = 2696.4, total_loss = 137.63, pg_loss = 102.74, baseline_loss = 40.273, entropy_loss = -5.3819, learner_queue_size = 32, _tick = 2285, _time = 1.6548e+09, train_seconds = 3594.1)
[2022-06-09 21:07:59,286][root][INFO] - Step 13483520 @ 3580.9 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 13483520, mean_episode_return = -0.14036, mean_episode_step = 2054.9, total_loss = 48.927, pg_loss = 39.501, baseline_loss = 14.636, entropy_loss = -5.2108, learner_queue_size = 32, _tick = 2289, _time = 1.6548e+09, train_seconds = 3599.1)
[2022-06-09 21:08:04,291][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-09 21:08:04,425][root][INFO] - Step 13501440 @ 3580.7 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 13501440, mean_episode_return = None, mean_episode_step = 2575.5, total_loss = -26.318, pg_loss = -39.915, baseline_loss = 19.219, entropy_loss = -5.6223, learner_queue_size = 32, _tick = 2294, _time = 1.6548e+09, train_seconds = 3604.1)
[2022-06-09 21:08:09,430][root][INFO] - Step 13521920 @ 3985.1 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 13521920, mean_episode_return = -6.3504, mean_episode_step = 1955.4, total_loss = 494.01, pg_loss = 270.87, baseline_loss = 229.18, entropy_loss = -6.044, learner_queue_size = 32, _tick = 2301, _time = 1.6548e+09, train_seconds = 3609.2)
[2022-06-09 21:08:14,434][root][INFO] - Step 13539840 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 13539840, mean_episode_return = None, mean_episode_step = 2342.6, total_loss = 250.96, pg_loss = 168.53, baseline_loss = 87.662, entropy_loss = -5.2376, learner_queue_size = 32, _tick = 2305, _time = 1.6548e+09, train_seconds = 3614.2)
[2022-06-09 21:08:19,438][root][INFO] - Step 13557760 @ 3581.0 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 13557760, mean_episode_return = None, mean_episode_step = 2238.4, total_loss = -24.34, pg_loss = -40.03, baseline_loss = 20.833, entropy_loss = -5.1432, learner_queue_size = 32, _tick = 2310, _time = 1.6548e+09, train_seconds = 3619.2)
[2022-06-09 21:08:24,442][root][INFO] - Step 13575680 @ 3581.4 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 13575680, mean_episode_return = 48.521, mean_episode_step = 1322.2, total_loss = 476.05, pg_loss = 155.44, baseline_loss = 325.73, entropy_loss = -5.1166, learner_queue_size = 32, _tick = 2315, _time = 1.6548e+09, train_seconds = 3624.2)
[2022-06-09 21:08:29,446][root][INFO] - Step 13596160 @ 4092.6 SPS. Inference batcher size: 79. Learner queue size: 32. Other stats: (step = 13596160, mean_episode_return = 55.712, mean_episode_step = 2011.9, total_loss = -88.716, pg_loss = -138.58, baseline_loss = 54.815, entropy_loss = -4.9515, learner_queue_size = 32, _tick = 2320, _time = 1.6548e+09, train_seconds = 3629.3)
[2022-06-09 21:08:34,450][root][INFO] - Step 13614080 @ 3581.3 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 13614080, mean_episode_return = 35.471, mean_episode_step = 2057.1, total_loss = 59.364, pg_loss = -44.177, baseline_loss = 108.84, entropy_loss = -5.3018, learner_queue_size = 32, _tick = 2325, _time = 1.6548e+09, train_seconds = 3634.3)
[2022-06-09 21:08:39,454][root][INFO] - Step 13632000 @ 3581.2 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 13632000, mean_episode_return = None, mean_episode_step = 2041.9, total_loss = 106.66, pg_loss = 78.703, baseline_loss = 33.815, entropy_loss = -5.8538, learner_queue_size = 32, _tick = 2330, _time = 1.6548e+09, train_seconds = 3639.3)
[2022-06-09 21:08:44,458][root][INFO] - Step 13652480 @ 4092.7 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 13652480, mean_episode_return = None, mean_episode_step = 2239.0, total_loss = -17.638, pg_loss = -23.756, baseline_loss = 11.547, entropy_loss = -5.4293, learner_queue_size = 32, _tick = 2334, _time = 1.6548e+09, train_seconds = 3644.3)
[2022-06-09 21:08:49,462][root][INFO] - Step 13670400 @ 3581.2 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 13670400, mean_episode_return = 57.561, mean_episode_step = 2086.4, total_loss = 203.34, pg_loss = 140.82, baseline_loss = 67.989, entropy_loss = -5.466, learner_queue_size = 32, _tick = 2337, _time = 1.6548e+09, train_seconds = 3649.3)
[2022-06-09 21:08:54,466][root][INFO] - Step 13688320 @ 3581.1 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 13688320, mean_episode_return = 40.312, mean_episode_step = 2157.1, total_loss = -97.86, pg_loss = -109.83, baseline_loss = 17.216, entropy_loss = -5.249, learner_queue_size = 32, _tick = 2344, _time = 1.6548e+09, train_seconds = 3654.3)
[2022-06-09 21:08:59,470][root][INFO] - Step 13708800 @ 4092.8 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 13708800, mean_episode_return = 86.038, mean_episode_step = 1901.9, total_loss = -85.332, pg_loss = -134.25, baseline_loss = 53.649, entropy_loss = -4.7282, learner_queue_size = 32, _tick = 2349, _time = 1.6548e+09, train_seconds = 3659.3)
[2022-06-09 21:09:04,474][root][INFO] - Step 13726720 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 13726720, mean_episode_return = None, mean_episode_step = 1557.9, total_loss = -39.57, pg_loss = -69.504, baseline_loss = 34.765, entropy_loss = -4.8307, learner_queue_size = 32, _tick = 2354, _time = 1.6548e+09, train_seconds = 3664.3)
[2022-06-09 21:09:09,478][root][INFO] - Step 13744640 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 13744640, mean_episode_return = 45.433, mean_episode_step = 1685.4, total_loss = 72.688, pg_loss = 16.75, baseline_loss = 60.746, entropy_loss = -4.8082, learner_queue_size = 32, _tick = 2360, _time = 1.6548e+09, train_seconds = 3669.3)
[2022-06-09 21:09:14,482][root][INFO] - Step 13765120 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 13765120, mean_episode_return = None, mean_episode_step = 2038.3, total_loss = -50.916, pg_loss = -61.597, baseline_loss = 15.896, entropy_loss = -5.2146, learner_queue_size = 32, _tick = 2365, _time = 1.6548e+09, train_seconds = 3674.3)
[2022-06-09 21:09:19,486][root][INFO] - Step 13783040 @ 3581.1 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 13783040, mean_episode_return = 85.727, mean_episode_step = 1958.9, total_loss = 91.367, pg_loss = 46.691, baseline_loss = 49.737, entropy_loss = -5.0617, learner_queue_size = 32, _tick = 2369, _time = 1.6548e+09, train_seconds = 3679.3)
[2022-06-09 21:09:24,490][root][INFO] - Step 13803520 @ 4092.4 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 13803520, mean_episode_return = None, mean_episode_step = 1631.0, total_loss = 187.39, pg_loss = 117.01, baseline_loss = 75.217, entropy_loss = -4.8362, learner_queue_size = 32, _tick = 2372, _time = 1.6548e+09, train_seconds = 3684.3)
[2022-06-09 21:09:29,494][root][INFO] - Step 13821440 @ 3581.4 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 13821440, mean_episode_return = None, mean_episode_step = 1554.7, total_loss = 36.979, pg_loss = 2.3416, baseline_loss = 39.41, entropy_loss = -4.7733, learner_queue_size = 32, _tick = 2374, _time = 1.6548e+09, train_seconds = 3689.3)
[2022-06-09 21:09:34,498][root][INFO] - Step 13839360 @ 3581.1 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 13839360, mean_episode_return = None, mean_episode_step = 2320.6, total_loss = -113.24, pg_loss = -114.2, baseline_loss = 6.1522, entropy_loss = -5.1887, learner_queue_size = 32, _tick = 2375, _time = 1.6548e+09, train_seconds = 3694.3)
[2022-06-09 21:09:39,504][root][INFO] - Step 13857280 @ 3579.6 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 13857280, mean_episode_return = 47.533, mean_episode_step = 1890.8, total_loss = 15.536, pg_loss = -7.9683, baseline_loss = 28.521, entropy_loss = -5.0173, learner_queue_size = 32, _tick = 2379, _time = 1.6548e+09, train_seconds = 3699.3)
[2022-06-09 21:09:44,510][root][INFO] - Step 13875200 @ 3579.9 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 13875200, mean_episode_return = None, mean_episode_step = 1571.5, total_loss = 38.685, pg_loss = -0.22003, baseline_loss = 43.769, entropy_loss = -4.8642, learner_queue_size = 32, _tick = 2384, _time = 1.6548e+09, train_seconds = 3704.3)
[2022-06-09 21:09:49,514][root][INFO] - Step 13895680 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 13895680, mean_episode_return = None, mean_episode_step = 2287.8, total_loss = 76.922, pg_loss = 39.787, baseline_loss = 41.859, entropy_loss = -4.7245, learner_queue_size = 32, _tick = 2388, _time = 1.6548e+09, train_seconds = 3709.3)
[2022-06-09 21:09:54,518][root][INFO] - Step 13913600 @ 3581.1 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 13913600, mean_episode_return = 20.75, mean_episode_step = 2192.5, total_loss = -63.65, pg_loss = -96.608, baseline_loss = 37.583, entropy_loss = -4.6257, learner_queue_size = 32, _tick = 2391, _time = 1.6548e+09, train_seconds = 3714.3)
[2022-06-09 21:09:59,522][root][INFO] - Step 13934080 @ 4092.7 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 13934080, mean_episode_return = None, mean_episode_step = 1979.8, total_loss = 56.769, pg_loss = 34.151, baseline_loss = 29.223, entropy_loss = -6.6056, learner_queue_size = 32, _tick = 2395, _time = 1.6548e+09, train_seconds = 3719.3)
[2022-06-09 21:10:04,529][root][INFO] - Step 13946880 @ 2556.3 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (step = 13946880, mean_episode_return = None, mean_episode_step = 2333.5, total_loss = -44.645, pg_loss = -45.437, baseline_loss = 5.537, entropy_loss = -4.7451, learner_queue_size = 32, _tick = 2397, _time = 1.6548e+09, train_seconds = 3724.3)
[2022-06-09 21:10:09,534][root][INFO] - Step 13964800 @ 3580.6 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 13964800, mean_episode_return = None, mean_episode_step = 1736.6, total_loss = -38.372, pg_loss = -51.603, baseline_loss = 17.744, entropy_loss = -4.5135, learner_queue_size = 32, _tick = 2401, _time = 1.6548e+09, train_seconds = 3729.3)
[2022-06-09 21:10:14,538][root][INFO] - Step 13985280 @ 4092.8 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 13985280, mean_episode_return = None, mean_episode_step = 2023.2, total_loss = -26.049, pg_loss = -41.072, baseline_loss = 20.068, entropy_loss = -5.0443, learner_queue_size = 32, _tick = 2405, _time = 1.6548e+09, train_seconds = 3734.3)
[2022-06-09 21:10:19,542][root][INFO] - Step 14003200 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 14003200, mean_episode_return = 15.099, mean_episode_step = 1873.8, total_loss = 45.27, pg_loss = 8.1815, baseline_loss = 41.729, entropy_loss = -4.6401, learner_queue_size = 32, _tick = 2407, _time = 1.6548e+09, train_seconds = 3739.3)
[2022-06-09 21:10:24,546][root][INFO] - Step 14023680 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 14023680, mean_episode_return = None, mean_episode_step = 2177.4, total_loss = -27.453, pg_loss = -21.997, baseline_loss = 1.3622, entropy_loss = -6.8183, learner_queue_size = 32, _tick = 2409, _time = 1.6548e+09, train_seconds = 3744.4)
[2022-06-09 21:10:29,550][root][INFO] - Step 14041600 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 14041600, mean_episode_return = 41.447, mean_episode_step = 2123.9, total_loss = 196.66, pg_loss = 148.39, baseline_loss = 54.457, entropy_loss = -6.1903, learner_queue_size = 32, _tick = 2415, _time = 1.6548e+09, train_seconds = 3749.4)
[2022-06-09 21:10:34,554][root][INFO] - Step 14059520 @ 3581.2 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 14059520, mean_episode_return = 87.319, mean_episode_step = 1703.9, total_loss = 185.47, pg_loss = 129.3, baseline_loss = 62.187, entropy_loss = -6.0247, learner_queue_size = 32, _tick = 2421, _time = 1.6548e+09, train_seconds = 3754.4)
[2022-06-09 21:10:39,560][root][INFO] - Step 14077440 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 14077440, mean_episode_return = 84.124, mean_episode_step = 1966.2, total_loss = 311.81, pg_loss = 230.7, baseline_loss = 86.517, entropy_loss = -5.4048, learner_queue_size = 32, _tick = 2426, _time = 1.6548e+09, train_seconds = 3759.4)
[2022-06-09 21:10:44,566][root][INFO] - Step 14097920 @ 4089.5 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 14097920, mean_episode_return = 32.383, mean_episode_step = 2111.7, total_loss = 92.579, pg_loss = 20.769, baseline_loss = 76.798, entropy_loss = -4.9876, learner_queue_size = 32, _tick = 2433, _time = 1.6548e+09, train_seconds = 3764.4)
[2022-06-09 21:10:49,570][root][INFO] - Step 14115840 @ 3581.1 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 14115840, mean_episode_return = 93.77, mean_episode_step = 1973.5, total_loss = 91.646, pg_loss = 18.709, baseline_loss = 78.046, entropy_loss = -5.1086, learner_queue_size = 32, _tick = 2438, _time = 1.6548e+09, train_seconds = 3769.4)
[2022-06-09 21:10:54,574][root][INFO] - Step 14133760 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 14133760, mean_episode_return = None, mean_episode_step = 1747.2, total_loss = 242.36, pg_loss = 182.78, baseline_loss = 65.064, entropy_loss = -5.4811, learner_queue_size = 32, _tick = 2441, _time = 1.6548e+09, train_seconds = 3774.4)
[2022-06-09 21:10:59,578][root][INFO] - Step 14154240 @ 4092.7 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 14154240, mean_episode_return = 19.231, mean_episode_step = 1828.5, total_loss = -107.22, pg_loss = -122.75, baseline_loss = 20.867, entropy_loss = -5.3341, learner_queue_size = 32, _tick = 2446, _time = 1.6548e+09, train_seconds = 3779.4)
[2022-06-09 21:11:04,582][root][INFO] - Step 14172160 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 14172160, mean_episode_return = 52.163, mean_episode_step = 1736.2, total_loss = 183.83, pg_loss = 129.92, baseline_loss = 59.491, entropy_loss = -5.5823, learner_queue_size = 32, _tick = 2452, _time = 1.6548e+09, train_seconds = 3784.4)
[2022-06-09 21:11:09,586][root][INFO] - Step 14190080 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 14190080, mean_episode_return = 71.707, mean_episode_step = 1639.1, total_loss = 374.6, pg_loss = 229.51, baseline_loss = 150.88, entropy_loss = -5.7965, learner_queue_size = 32, _tick = 2456, _time = 1.6548e+09, train_seconds = 3789.4)
[2022-06-09 21:11:14,590][root][INFO] - Step 14208000 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 14208000, mean_episode_return = 64.886, mean_episode_step = 2030.2, total_loss = 115.14, pg_loss = 21.342, baseline_loss = 99.274, entropy_loss = -5.4742, learner_queue_size = 32, _tick = 2460, _time = 1.6548e+09, train_seconds = 3794.4)
[2022-06-09 21:11:19,594][root][INFO] - Step 14228480 @ 4092.8 SPS. Inference batcher size: 79. Learner queue size: 32. Other stats: (step = 14228480, mean_episode_return = 29.04, mean_episode_step = 1677.3, total_loss = 100.39, pg_loss = 40.24, baseline_loss = 65.207, entropy_loss = -5.0557, learner_queue_size = 32, _tick = 2466, _time = 1.6548e+09, train_seconds = 3799.4)
[2022-06-09 21:11:24,598][root][INFO] - Step 14246400 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 14246400, mean_episode_return = None, mean_episode_step = 1487.5, total_loss = 79.568, pg_loss = 51.447, baseline_loss = 32.142, entropy_loss = -4.0203, learner_queue_size = 32, _tick = 2469, _time = 1.6548e+09, train_seconds = 3804.4)
[2022-06-09 21:11:29,602][root][INFO] - Step 14266880 @ 4092.7 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 14266880, mean_episode_return = None, mean_episode_step = 1814.0, total_loss = 50.064, pg_loss = 21.791, baseline_loss = 33.493, entropy_loss = -5.2198, learner_queue_size = 32, _tick = 2469, _time = 1.6548e+09, train_seconds = 3809.4)
[2022-06-09 21:11:34,606][root][INFO] - Step 14284800 @ 3581.0 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 14284800, mean_episode_return = None, mean_episode_step = 1851.6, total_loss = 5.563, pg_loss = -7.8134, baseline_loss = 18.059, entropy_loss = -4.6822, learner_queue_size = 32, _tick = 2470, _time = 1.6548e+09, train_seconds = 3814.4)
[2022-06-09 21:11:39,610][root][INFO] - Step 14302720 @ 3581.3 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 14302720, mean_episode_return = 59.591, mean_episode_step = 1730.6, total_loss = 103.05, pg_loss = 50.51, baseline_loss = 57.804, entropy_loss = -5.2668, learner_queue_size = 32, _tick = 2477, _time = 1.6548e+09, train_seconds = 3819.4)
[2022-06-09 21:11:44,614][root][INFO] - Step 14323200 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 14323200, mean_episode_return = -0.34536, mean_episode_step = 1452.7, total_loss = -130.9, pg_loss = -132.3, baseline_loss = 6.6519, entropy_loss = -5.2539, learner_queue_size = 32, _tick = 2481, _time = 1.6548e+09, train_seconds = 3824.4)
[2022-06-09 21:11:49,619][root][INFO] - Step 14341120 @ 3580.6 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (step = 14341120, mean_episode_return = 100.03, mean_episode_step = 1771.7, total_loss = 105.83, pg_loss = 49.973, baseline_loss = 61.025, entropy_loss = -5.164, learner_queue_size = 32, _tick = 2487, _time = 1.6548e+09, train_seconds = 3829.4)
[2022-06-09 21:11:54,622][root][INFO] - Step 14361600 @ 4093.3 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 14361600, mean_episode_return = 12.04, mean_episode_step = 1494.6, total_loss = -189.08, pg_loss = -194.21, baseline_loss = 10.088, entropy_loss = -4.9553, learner_queue_size = 32, _tick = 2492, _time = 1.6548e+09, train_seconds = 3834.4)
[2022-06-09 21:11:59,626][root][INFO] - Step 14379520 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 14379520, mean_episode_return = 118.44, mean_episode_step = 2033.3, total_loss = -53.984, pg_loss = -57.517, baseline_loss = 9.5991, entropy_loss = -6.0659, learner_queue_size = 32, _tick = 2496, _time = 1.6548e+09, train_seconds = 3839.4)
[2022-06-09 21:12:04,630][root][INFO] - Step 14400000 @ 4092.8 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 14400000, mean_episode_return = None, mean_episode_step = 1725.2, total_loss = -30.071, pg_loss = -36.437, baseline_loss = 10.643, entropy_loss = -4.2772, learner_queue_size = 32, _tick = 2500, _time = 1.6548e+09, train_seconds = 3844.4)
[2022-06-09 21:12:09,635][root][INFO] - Step 14417920 @ 3580.6 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 14417920, mean_episode_return = None, mean_episode_step = 1347.8, total_loss = -15.224, pg_loss = -14.946, baseline_loss = 5.6295, entropy_loss = -5.9075, learner_queue_size = 32, _tick = 2503, _time = 1.6548e+09, train_seconds = 3849.4)
[2022-06-09 21:12:14,638][root][INFO] - Step 14435840 @ 3581.6 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 14435840, mean_episode_return = 110.45, mean_episode_step = 1578.4, total_loss = 118.37, pg_loss = 86.723, baseline_loss = 38.717, entropy_loss = -7.0737, learner_queue_size = 32, _tick = 2505, _time = 1.6548e+09, train_seconds = 3854.4)
[2022-06-09 21:12:19,642][root][INFO] - Step 14456320 @ 4092.6 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (step = 14456320, mean_episode_return = 56.216, mean_episode_step = 1624.8, total_loss = 28.733, pg_loss = -7.8018, baseline_loss = 42.041, entropy_loss = -5.5057, learner_queue_size = 32, _tick = 2512, _time = 1.6548e+09, train_seconds = 3859.4)
[2022-06-09 21:12:24,646][root][INFO] - Step 14474240 @ 3581.3 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 14474240, mean_episode_return = -2.73, mean_episode_step = 1455.1, total_loss = 6.9883, pg_loss = -12.55, baseline_loss = 23.356, entropy_loss = -3.8176, learner_queue_size = 32, _tick = 2518, _time = 1.6548e+09, train_seconds = 3864.5)
[2022-06-09 21:12:29,650][root][INFO] - Step 14494720 @ 4092.3 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 14494720, mean_episode_return = None, mean_episode_step = 1583.5, total_loss = 235.1, pg_loss = 128.46, baseline_loss = 110.55, entropy_loss = -3.8986, learner_queue_size = 32, _tick = 2520, _time = 1.6548e+09, train_seconds = 3869.5)
[2022-06-09 21:12:34,654][root][INFO] - Step 14512640 @ 3581.4 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 14512640, mean_episode_return = None, mean_episode_step = 2051.2, total_loss = 59.303, pg_loss = 15.503, baseline_loss = 48.545, entropy_loss = -4.7445, learner_queue_size = 32, _tick = 2522, _time = 1.6548e+09, train_seconds = 3874.5)
[2022-06-09 21:12:39,658][root][INFO] - Step 14530560 @ 3581.2 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 14530560, mean_episode_return = None, mean_episode_step = 1903.9, total_loss = -49.744, pg_loss = -51.095, baseline_loss = 7.3732, entropy_loss = -6.0231, learner_queue_size = 32, _tick = 2523, _time = 1.6548e+09, train_seconds = 3879.5)
[2022-06-09 21:12:44,662][root][INFO] - Step 14548480 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 14548480, mean_episode_return = 10.41, mean_episode_step = 1408.7, total_loss = -13.625, pg_loss = -32.798, baseline_loss = 25.505, entropy_loss = -6.3319, learner_queue_size = 32, _tick = 2526, _time = 1.6548e+09, train_seconds = 3884.5)
[2022-06-09 21:12:49,666][root][INFO] - Step 14568960 @ 4092.6 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 14568960, mean_episode_return = 88.894, mean_episode_step = 1595.3, total_loss = -77.033, pg_loss = -99.75, baseline_loss = 29.016, entropy_loss = -6.2996, learner_queue_size = 32, _tick = 2531, _time = 1.6548e+09, train_seconds = 3889.5)
[2022-06-09 21:12:54,670][root][INFO] - Step 14586880 @ 3581.2 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 14586880, mean_episode_return = 77.012, mean_episode_step = 1783.1, total_loss = -79.308, pg_loss = -82.032, baseline_loss = 8.1286, entropy_loss = -5.4048, learner_queue_size = 32, _tick = 2536, _time = 1.6548e+09, train_seconds = 3894.5)
[2022-06-09 21:12:59,675][root][INFO] - Step 14607360 @ 4091.8 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 14607360, mean_episode_return = -7.6501, mean_episode_step = 1931.6, total_loss = 144.72, pg_loss = 77.528, baseline_loss = 71.707, entropy_loss = -4.5133, learner_queue_size = 32, _tick = 2541, _time = 1.6548e+09, train_seconds = 3899.5)
[2022-06-09 21:13:04,680][root][INFO] - Step 14625280 @ 3580.6 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 14625280, mean_episode_return = None, mean_episode_step = 1781.1, total_loss = 26.596, pg_loss = 3.1799, baseline_loss = 28.757, entropy_loss = -5.3406, learner_queue_size = 32, _tick = 2545, _time = 1.6548e+09, train_seconds = 3904.5)
[2022-06-09 21:13:09,682][root][INFO] - Step 14643200 @ 3582.5 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 14643200, mean_episode_return = None, mean_episode_step = 2291.6, total_loss = -2.1081, pg_loss = -15.275, baseline_loss = 19.049, entropy_loss = -5.8818, learner_queue_size = 32, _tick = 2550, _time = 1.6548e+09, train_seconds = 3909.5)
[2022-06-09 21:13:14,686][root][INFO] - Step 14663680 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 14663680, mean_episode_return = 90.56, mean_episode_step = 1731.1, total_loss = 80.535, pg_loss = 43.347, baseline_loss = 43.399, entropy_loss = -6.2118, learner_queue_size = 32, _tick = 2554, _time = 1.6548e+09, train_seconds = 3914.5)
[2022-06-09 21:13:19,690][root][INFO] - Step 14681600 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 14681600, mean_episode_return = 84.84, mean_episode_step = 1529.4, total_loss = -3.2197, pg_loss = -16.523, baseline_loss = 18.181, entropy_loss = -4.8777, learner_queue_size = 32, _tick = 2559, _time = 1.6548e+09, train_seconds = 3919.5)
[2022-06-09 21:13:24,695][root][INFO] - Step 14699520 @ 3580.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 14699520, mean_episode_return = None, mean_episode_step = 1797.2, total_loss = 48.623, pg_loss = 19.204, baseline_loss = 33.614, entropy_loss = -4.1942, learner_queue_size = 32, _tick = 2563, _time = 1.6548e+09, train_seconds = 3924.5)
[2022-06-09 21:13:29,698][root][INFO] - Step 14717440 @ 3582.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 14717440, mean_episode_return = 20.9, mean_episode_step = 1294.4, total_loss = 40.496, pg_loss = 14.549, baseline_loss = 29.233, entropy_loss = -3.2865, learner_queue_size = 32, _tick = 2564, _time = 1.6548e+09, train_seconds = 3929.5)
[2022-06-09 21:13:34,702][root][INFO] - Step 14737920 @ 4092.8 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 14737920, mean_episode_return = None, mean_episode_step = 1809.8, total_loss = -23.81, pg_loss = -19.3, baseline_loss = 0.91219, entropy_loss = -5.4224, learner_queue_size = 32, _tick = 2564, _time = 1.6548e+09, train_seconds = 3934.5)
[2022-06-09 21:13:39,706][root][INFO] - Step 14755840 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 14755840, mean_episode_return = None, mean_episode_step = 2101.7, total_loss = -76.046, pg_loss = -72.751, baseline_loss = 2.6807, entropy_loss = -5.9759, learner_queue_size = 32, _tick = 2566, _time = 1.6548e+09, train_seconds = 3939.5)
[2022-06-09 21:13:44,710][root][INFO] - Step 14773760 @ 3581.1 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 14773760, mean_episode_return = 71.449, mean_episode_step = 1700.0, total_loss = 231.08, pg_loss = 168.61, baseline_loss = 68.762, entropy_loss = -6.2887, learner_queue_size = 32, _tick = 2573, _time = 1.6548e+09, train_seconds = 3944.5)
[2022-06-09 21:13:49,714][root][INFO] - Step 14794240 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 14794240, mean_episode_return = None, mean_episode_step = 2015.7, total_loss = 176.63, pg_loss = 135.38, baseline_loss = 47.241, entropy_loss = -5.9849, learner_queue_size = 32, _tick = 2578, _time = 1.6548e+09, train_seconds = 3949.5)
[2022-06-09 21:13:54,718][root][INFO] - Step 14812160 @ 3581.0 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 14812160, mean_episode_return = None, mean_episode_step = 1530.3, total_loss = 83.847, pg_loss = 21.961, baseline_loss = 66.737, entropy_loss = -4.8516, learner_queue_size = 32, _tick = 2581, _time = 1.6548e+09, train_seconds = 3954.5)
[2022-06-09 21:13:59,722][root][INFO] - Step 14830080 @ 3581.2 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 14830080, mean_episode_return = None, mean_episode_step = 1997.0, total_loss = 45.696, pg_loss = 25.473, baseline_loss = 24.675, entropy_loss = -4.4527, learner_queue_size = 32, _tick = 2584, _time = 1.6548e+09, train_seconds = 3959.5)
[2022-06-09 21:14:04,726][root][INFO] - Step 14850560 @ 4092.7 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 14850560, mean_episode_return = 45.306, mean_episode_step = 1877.5, total_loss = 130.93, pg_loss = 68.111, baseline_loss = 67.536, entropy_loss = -4.7148, learner_queue_size = 32, _tick = 2589, _time = 1.6548e+09, train_seconds = 3964.5)
[2022-06-09 21:14:09,730][root][INFO] - Step 14868480 @ 3581.1 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 14868480, mean_episode_return = 76.474, mean_episode_step = 1931.5, total_loss = -76.263, pg_loss = -79.545, baseline_loss = 9.1385, entropy_loss = -5.857, learner_queue_size = 32, _tick = 2591, _time = 1.6548e+09, train_seconds = 3969.5)
[2022-06-09 21:14:14,734][root][INFO] - Step 14886400 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 14886400, mean_episode_return = None, mean_episode_step = 1840.2, total_loss = 9.0419, pg_loss = -0.99294, baseline_loss = 14.899, entropy_loss = -4.8638, learner_queue_size = 32, _tick = 2594, _time = 1.6548e+09, train_seconds = 3974.5)
[2022-06-09 21:14:19,738][root][INFO] - Step 14906880 @ 4092.8 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 14906880, mean_episode_return = None, mean_episode_step = 1916.6, total_loss = 134.99, pg_loss = 78.97, baseline_loss = 60.4, entropy_loss = -4.385, learner_queue_size = 32, _tick = 2598, _time = 1.6548e+09, train_seconds = 3979.5)
[2022-06-09 21:14:24,742][root][INFO] - Step 14924800 @ 3581.1 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 14924800, mean_episode_return = None, mean_episode_step = 1988.2, total_loss = -11.537, pg_loss = -19.553, baseline_loss = 13.171, entropy_loss = -5.154, learner_queue_size = 32, _tick = 2599, _time = 1.6548e+09, train_seconds = 3984.5)
[2022-06-09 21:14:29,746][root][INFO] - Step 14945280 @ 4092.7 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (step = 14945280, mean_episode_return = None, mean_episode_step = 1907.5, total_loss = 71.266, pg_loss = 37.816, baseline_loss = 38.501, entropy_loss = -5.051, learner_queue_size = 32, _tick = 2603, _time = 1.6548e+09, train_seconds = 3989.6)
[2022-06-09 21:14:34,750][root][INFO] - Step 14963200 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 14963200, mean_episode_return = 0.36965, mean_episode_step = 2034.9, total_loss = 11.737, pg_loss = 6.4955, baseline_loss = 8.8833, entropy_loss = -3.6417, learner_queue_size = 32, _tick = 2609, _time = 1.6548e+09, train_seconds = 3994.6)
[2022-06-09 21:14:39,754][root][INFO] - Step 14981120 @ 3581.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 14981120, mean_episode_return = None, mean_episode_step = 1782.0, total_loss = 39.218, pg_loss = 22.976, baseline_loss = 19.643, entropy_loss = -3.4004, learner_queue_size = 32, _tick = 2610, _time = 1.6548e+09, train_seconds = 3999.6)
[2022-06-09 21:14:44,758][root][INFO] - Step 14999040 @ 3581.2 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 14999040, mean_episode_return = 19.59, mean_episode_step = 1919.7, total_loss = -53.593, pg_loss = -88.316, baseline_loss = 39.401, entropy_loss = -4.6785, learner_queue_size = 32, _tick = 2613, _time = 1.6548e+09, train_seconds = 4004.6)
[2022-06-09 21:14:49,764][root][INFO] - Step 15019520 @ 4090.9 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 15019520, mean_episode_return = None, mean_episode_step = 2168.7, total_loss = 78.636, pg_loss = 41.851, baseline_loss = 41.742, entropy_loss = -4.9569, learner_queue_size = 32, _tick = 2615, _time = 1.6548e+09, train_seconds = 4009.6)
[2022-06-09 21:14:54,774][root][INFO] - Step 15037440 @ 3577.0 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 15037440, mean_episode_return = None, mean_episode_step = 1984.6, total_loss = 204.1, pg_loss = 100.56, baseline_loss = 108.48, entropy_loss = -4.941, learner_queue_size = 32, _tick = 2618, _time = 1.6548e+09, train_seconds = 4014.6)
[2022-06-09 21:14:59,778][root][INFO] - Step 15055360 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 15055360, mean_episode_return = -1.4592, mean_episode_step = 2487.4, total_loss = 324.47, pg_loss = 90.201, baseline_loss = 239.24, entropy_loss = -4.9669, learner_queue_size = 32, _tick = 2622, _time = 1.6548e+09, train_seconds = 4019.6)
[2022-06-09 21:15:04,782][root][INFO] - Step 15073280 @ 3581.1 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 15073280, mean_episode_return = 38.891, mean_episode_step = 1646.3, total_loss = -103.69, pg_loss = -132.23, baseline_loss = 33.622, entropy_loss = -5.0785, learner_queue_size = 32, _tick = 2627, _time = 1.6548e+09, train_seconds = 4024.6)
[2022-06-09 21:15:09,786][root][INFO] - Step 15091200 @ 3581.2 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 15091200, mean_episode_return = 241.27, mean_episode_step = 1977.6, total_loss = 110.91, pg_loss = 52.216, baseline_loss = 63.88, entropy_loss = -5.1824, learner_queue_size = 32, _tick = 2632, _time = 1.6548e+09, train_seconds = 4029.6)
[2022-06-09 21:15:14,790][root][INFO] - Step 15111680 @ 4092.6 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 15111680, mean_episode_return = 19.06, mean_episode_step = 1852.4, total_loss = 108.25, pg_loss = 53.728, baseline_loss = 59.535, entropy_loss = -5.0102, learner_queue_size = 32, _tick = 2635, _time = 1.6548e+09, train_seconds = 4034.6)
[2022-06-09 21:15:19,794][root][INFO] - Step 15129600 @ 3581.2 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 15129600, mean_episode_return = 69.417, mean_episode_step = 1771.8, total_loss = 254.25, pg_loss = 134.7, baseline_loss = 124.35, entropy_loss = -4.8014, learner_queue_size = 32, _tick = 2641, _time = 1.6548e+09, train_seconds = 4039.6)
[2022-06-09 21:15:24,798][root][INFO] - Step 15150080 @ 4092.5 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 15150080, mean_episode_return = None, mean_episode_step = 2007.2, total_loss = -4.7103, pg_loss = -29.823, baseline_loss = 30.176, entropy_loss = -5.0631, learner_queue_size = 32, _tick = 2643, _time = 1.6548e+09, train_seconds = 4044.6)
[2022-06-09 21:15:29,802][root][INFO] - Step 15168000 @ 3581.3 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 15168000, mean_episode_return = None, mean_episode_step = 2340.3, total_loss = 133.11, pg_loss = 72.884, baseline_loss = 65.691, entropy_loss = -5.4647, learner_queue_size = 32, _tick = 2644, _time = 1.6548e+09, train_seconds = 4049.6)
[2022-06-09 21:15:34,806][root][INFO] - Step 15185920 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 15185920, mean_episode_return = 35.38, mean_episode_step = 2050.9, total_loss = -141.06, pg_loss = -142.61, baseline_loss = 6.8596, entropy_loss = -5.3104, learner_queue_size = 32, _tick = 2649, _time = 1.6548e+09, train_seconds = 4054.6)
[2022-06-09 21:15:39,810][root][INFO] - Step 15206400 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 15206400, mean_episode_return = -33.73, mean_episode_step = 1988.3, total_loss = -137.24, pg_loss = -141.3, baseline_loss = 9.4046, entropy_loss = -5.3382, learner_queue_size = 32, _tick = 2655, _time = 1.6548e+09, train_seconds = 4059.6)
[2022-06-09 21:15:44,814][root][INFO] - Step 15224320 @ 3581.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 15224320, mean_episode_return = -4.9803, mean_episode_step = 2146.0, total_loss = 1.9813e+04, pg_loss = 3022.6, baseline_loss = 1.6795e+04, entropy_loss = -5.5359, learner_queue_size = 32, _tick = 2660, _time = 1.6548e+09, train_seconds = 4064.6)
[2022-06-09 21:15:49,818][root][INFO] - Step 15244800 @ 4092.6 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 15244800, mean_episode_return = 81.431, mean_episode_step = 2385.9, total_loss = 119.69, pg_loss = 65.091, baseline_loss = 60.637, entropy_loss = -6.0378, learner_queue_size = 32, _tick = 2667, _time = 1.6548e+09, train_seconds = 4069.6)
[2022-06-09 21:15:54,822][root][INFO] - Step 15262720 @ 3581.2 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 15262720, mean_episode_return = 69.336, mean_episode_step = 1986.7, total_loss = 137.36, pg_loss = 84.912, baseline_loss = 58.111, entropy_loss = -5.6664, learner_queue_size = 32, _tick = 2670, _time = 1.6548e+09, train_seconds = 4074.6)
[2022-06-09 21:15:59,826][root][INFO] - Step 15280640 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 15280640, mean_episode_return = 29.142, mean_episode_step = 1866.1, total_loss = -55.888, pg_loss = -69.884, baseline_loss = 19.726, entropy_loss = -5.7297, learner_queue_size = 32, _tick = 2676, _time = 1.6548e+09, train_seconds = 4079.6)
[2022-06-09 21:16:04,830][root][INFO] - Step 15301120 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 15301120, mean_episode_return = 79.721, mean_episode_step = 1708.8, total_loss = 5.4844, pg_loss = -8.6116, baseline_loss = 19.261, entropy_loss = -5.1647, learner_queue_size = 32, _tick = 2682, _time = 1.6548e+09, train_seconds = 4084.6)
[2022-06-09 21:16:09,834][root][INFO] - Step 15319040 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 15319040, mean_episode_return = 158.69, mean_episode_step = 1765.6, total_loss = 305.01, pg_loss = 219.87, baseline_loss = 90.745, entropy_loss = -5.6065, learner_queue_size = 32, _tick = 2688, _time = 1.6548e+09, train_seconds = 4089.6)
[2022-06-09 21:16:14,838][root][INFO] - Step 15339520 @ 4092.8 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 15339520, mean_episode_return = 63.255, mean_episode_step = 1652.1, total_loss = 136.17, pg_loss = 73.832, baseline_loss = 67.216, entropy_loss = -4.878, learner_queue_size = 32, _tick = 2694, _time = 1.6548e+09, train_seconds = 4094.6)
[2022-06-09 21:16:19,842][root][INFO] - Step 15357440 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 15357440, mean_episode_return = None, mean_episode_step = 1974.2, total_loss = 15.454, pg_loss = -3.0462, baseline_loss = 22.635, entropy_loss = -4.1349, learner_queue_size = 32, _tick = 2695, _time = 1.6548e+09, train_seconds = 4099.6)
[2022-06-09 21:16:24,846][root][INFO] - Step 15377920 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 15377920, mean_episode_return = 62.574, mean_episode_step = 2052.9, total_loss = 11.131, pg_loss = -12.892, baseline_loss = 29.281, entropy_loss = -5.2585, learner_queue_size = 32, _tick = 2698, _time = 1.6548e+09, train_seconds = 4104.7)
[2022-06-09 21:16:29,850][root][INFO] - Step 15395840 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 15395840, mean_episode_return = None, mean_episode_step = 2193.8, total_loss = -82.23, pg_loss = -86.539, baseline_loss = 9.4512, entropy_loss = -5.1418, learner_queue_size = 32, _tick = 2703, _time = 1.6548e+09, train_seconds = 4109.7)
[2022-06-09 21:16:34,856][root][INFO] - Step 15413760 @ 3579.6 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 15413760, mean_episode_return = None, mean_episode_step = 1886.3, total_loss = 229.46, pg_loss = 152.76, baseline_loss = 82.124, entropy_loss = -5.4158, learner_queue_size = 32, _tick = 2706, _time = 1.6548e+09, train_seconds = 4114.7)
[2022-06-09 21:16:39,858][root][INFO] - Step 15434240 @ 4094.4 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 15434240, mean_episode_return = 61.559, mean_episode_step = 1965.8, total_loss = 367.9, pg_loss = 266.35, baseline_loss = 106.66, entropy_loss = -5.1166, learner_queue_size = 32, _tick = 2710, _time = 1.6548e+09, train_seconds = 4119.7)
[2022-06-09 21:16:44,862][root][INFO] - Step 15452160 @ 3581.2 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 15452160, mean_episode_return = 22.98, mean_episode_step = 2107.3, total_loss = -50.968, pg_loss = -65.704, baseline_loss = 20.24, entropy_loss = -5.505, learner_queue_size = 32, _tick = 2711, _time = 1.6548e+09, train_seconds = 4124.7)
[2022-06-09 21:16:49,867][root][INFO] - Step 15472640 @ 4092.2 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 15472640, mean_episode_return = 13.99, mean_episode_step = 2108.5, total_loss = 165.2, pg_loss = 97.976, baseline_loss = 72.565, entropy_loss = -5.3445, learner_queue_size = 32, _tick = 2716, _time = 1.6548e+09, train_seconds = 4129.7)
[2022-06-09 21:16:54,870][root][INFO] - Step 15490560 @ 3581.6 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 15490560, mean_episode_return = 72.302, mean_episode_step = 1961.1, total_loss = 36.31, pg_loss = 6.6577, baseline_loss = 35.357, entropy_loss = -5.7046, learner_queue_size = 32, _tick = 2719, _time = 1.6548e+09, train_seconds = 4134.7)
[2022-06-09 21:16:59,874][root][INFO] - Step 15511040 @ 4092.7 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 15511040, mean_episode_return = 39.052, mean_episode_step = 2090.7, total_loss = 67.943, pg_loss = 17.792, baseline_loss = 55.39, entropy_loss = -5.2394, learner_queue_size = 32, _tick = 2726, _time = 1.6548e+09, train_seconds = 4139.7)
[2022-06-09 21:17:04,878][root][INFO] - Step 15528960 @ 3581.1 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (step = 15528960, mean_episode_return = 106.15, mean_episode_step = 2181.8, total_loss = 3.5425, pg_loss = -47.942, baseline_loss = 56.802, entropy_loss = -5.3179, learner_queue_size = 32, _tick = 2730, _time = 1.6548e+09, train_seconds = 4144.7)
[2022-06-09 21:17:09,882][root][INFO] - Step 15546880 @ 3581.2 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 15546880, mean_episode_return = 100.63, mean_episode_step = 1921.6, total_loss = -47.451, pg_loss = -56.166, baseline_loss = 13.82, entropy_loss = -5.1057, learner_queue_size = 32, _tick = 2736, _time = 1.6548e+09, train_seconds = 4149.7)
[2022-06-09 21:17:14,886][root][INFO] - Step 15564800 @ 3581.0 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 15564800, mean_episode_return = None, mean_episode_step = 1953.6, total_loss = 3.3503, pg_loss = -29.606, baseline_loss = 37.901, entropy_loss = -4.9448, learner_queue_size = 32, _tick = 2738, _time = 1.6548e+09, train_seconds = 4154.7)
[2022-06-09 21:17:19,890][root][INFO] - Step 15585280 @ 4092.8 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 15585280, mean_episode_return = 22.854, mean_episode_step = 2064.2, total_loss = -32.059, pg_loss = -38.316, baseline_loss = 11.931, entropy_loss = -5.6741, learner_queue_size = 32, _tick = 2743, _time = 1.6548e+09, train_seconds = 4159.7)
[2022-06-09 21:17:24,894][root][INFO] - Step 15603200 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 15603200, mean_episode_return = 26.165, mean_episode_step = 2272.4, total_loss = -114.74, pg_loss = -112.73, baseline_loss = 3.1859, entropy_loss = -5.201, learner_queue_size = 32, _tick = 2748, _time = 1.6548e+09, train_seconds = 4164.7)
[2022-06-09 21:17:29,898][root][INFO] - Step 15623680 @ 4092.6 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 15623680, mean_episode_return = -14.41, mean_episode_step = 2158.9, total_loss = 20.354, pg_loss = -15.751, baseline_loss = 41.497, entropy_loss = -5.392, learner_queue_size = 32, _tick = 2754, _time = 1.6548e+09, train_seconds = 4169.7)
[2022-06-09 21:17:34,902][root][INFO] - Step 15641600 @ 3581.3 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 15641600, mean_episode_return = None, mean_episode_step = 1897.6, total_loss = 358.71, pg_loss = 207.51, baseline_loss = 156.48, entropy_loss = -5.2753, learner_queue_size = 32, _tick = 2758, _time = 1.6548e+09, train_seconds = 4174.7)
[2022-06-09 21:17:39,906][root][INFO] - Step 15659520 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 15659520, mean_episode_return = 24.46, mean_episode_step = 1978.7, total_loss = -6.1176, pg_loss = -33.131, baseline_loss = 31.767, entropy_loss = -4.7541, learner_queue_size = 32, _tick = 2763, _time = 1.6548e+09, train_seconds = 4179.7)
[2022-06-09 21:17:44,910][root][INFO] - Step 15680000 @ 4092.6 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 15680000, mean_episode_return = None, mean_episode_step = 1963.6, total_loss = -49.038, pg_loss = -53.203, baseline_loss = 8.8446, entropy_loss = -4.6797, learner_queue_size = 32, _tick = 2767, _time = 1.6548e+09, train_seconds = 4184.7)
[2022-06-09 21:17:49,914][root][INFO] - Step 15697920 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 15697920, mean_episode_return = 40.715, mean_episode_step = 1261.8, total_loss = -12.217, pg_loss = -27.307, baseline_loss = 20.242, entropy_loss = -5.1522, learner_queue_size = 32, _tick = 2772, _time = 1.6548e+09, train_seconds = 4189.7)
[2022-06-09 21:17:54,918][root][INFO] - Step 15718400 @ 4092.7 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 15718400, mean_episode_return = 63.997, mean_episode_step = 1396.7, total_loss = 86.231, pg_loss = 25.298, baseline_loss = 66.766, entropy_loss = -5.8337, learner_queue_size = 32, _tick = 2778, _time = 1.6548e+09, train_seconds = 4194.7)
[2022-06-09 21:17:59,922][root][INFO] - Step 15736320 @ 3581.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 15736320, mean_episode_return = None, mean_episode_step = 2167.8, total_loss = -13.721, pg_loss = -20.328, baseline_loss = 11.777, entropy_loss = -5.169, learner_queue_size = 32, _tick = 2782, _time = 1.6548e+09, train_seconds = 4199.7)
[2022-06-09 21:18:04,926][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-09 21:18:05,091][root][INFO] - Step 15756800 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 15756800, mean_episode_return = 92.93, mean_episode_step = 1654.4, total_loss = 321.08, pg_loss = 223.86, baseline_loss = 102.01, entropy_loss = -4.7944, learner_queue_size = 32, _tick = 2786, _time = 1.6548e+09, train_seconds = 4204.7)
[2022-06-09 21:18:10,094][root][INFO] - Step 15774720 @ 3467.5 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 15774720, mean_episode_return = None, mean_episode_step = 1867.8, total_loss = 36.542, pg_loss = 11.838, baseline_loss = 29.734, entropy_loss = -5.03, learner_queue_size = 32, _tick = 2789, _time = 1.6548e+09, train_seconds = 4209.9)
[2022-06-09 21:18:15,098][root][INFO] - Step 15795200 @ 4092.7 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 15795200, mean_episode_return = 0.33966, mean_episode_step = 1532.5, total_loss = -66.212, pg_loss = -77.696, baseline_loss = 16.603, entropy_loss = -5.12, learner_queue_size = 32, _tick = 2790, _time = 1.6548e+09, train_seconds = 4214.9)
[2022-06-09 21:18:20,102][root][INFO] - Step 15813120 @ 3581.2 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 15813120, mean_episode_return = None, mean_episode_step = 2094.0, total_loss = -20.643, pg_loss = -26.422, baseline_loss = 10.262, entropy_loss = -4.4833, learner_queue_size = 32, _tick = 2794, _time = 1.6548e+09, train_seconds = 4219.9)
[2022-06-09 21:18:25,106][root][INFO] - Step 15831040 @ 3581.0 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 15831040, mean_episode_return = None, mean_episode_step = 1949.0, total_loss = 185.11, pg_loss = 112.08, baseline_loss = 77.567, entropy_loss = -4.5322, learner_queue_size = 32, _tick = 2798, _time = 1.6548e+09, train_seconds = 4224.9)
[2022-06-09 21:18:30,110][root][INFO] - Step 15848960 @ 3581.2 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 15848960, mean_episode_return = None, mean_episode_step = 1547.3, total_loss = 15.519, pg_loss = 5.9879, baseline_loss = 15.213, entropy_loss = -5.6812, learner_queue_size = 32, _tick = 2799, _time = 1.6548e+09, train_seconds = 4229.9)
[2022-06-09 21:18:35,114][root][INFO] - Step 15866880 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 15866880, mean_episode_return = 27.09, mean_episode_step = 1475.0, total_loss = 202.14, pg_loss = 136.32, baseline_loss = 71.13, entropy_loss = -5.3175, learner_queue_size = 32, _tick = 2804, _time = 1.6548e+09, train_seconds = 4234.9)
[2022-06-09 21:18:40,118][root][INFO] - Step 15887360 @ 4092.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 15887360, mean_episode_return = 1.1197, mean_episode_step = 1243.3, total_loss = 50.918, pg_loss = 14.279, baseline_loss = 41.863, entropy_loss = -5.2232, learner_queue_size = 32, _tick = 2809, _time = 1.6548e+09, train_seconds = 4239.9)
[2022-06-09 21:18:45,122][root][INFO] - Step 15905280 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 15905280, mean_episode_return = 70.412, mean_episode_step = 1470.6, total_loss = 24.82, pg_loss = -0.53934, baseline_loss = 30.409, entropy_loss = -5.0497, learner_queue_size = 32, _tick = 2815, _time = 1.6548e+09, train_seconds = 4244.9)
[2022-06-09 21:18:50,126][root][INFO] - Step 15923200 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 15923200, mean_episode_return = 104.97, mean_episode_step = 1700.5, total_loss = 375.83, pg_loss = 261.91, baseline_loss = 119.4, entropy_loss = -5.4781, learner_queue_size = 32, _tick = 2819, _time = 1.6548e+09, train_seconds = 4249.9)
[2022-06-09 21:18:55,130][root][INFO] - Step 15943680 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 15943680, mean_episode_return = None, mean_episode_step = 1791.1, total_loss = 64.239, pg_loss = 19.807, baseline_loss = 49.727, entropy_loss = -5.2939, learner_queue_size = 32, _tick = 2824, _time = 1.6548e+09, train_seconds = 4254.9)
[2022-06-09 21:19:00,134][root][INFO] - Step 15961600 @ 3581.2 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 15961600, mean_episode_return = 44.431, mean_episode_step = 1707.9, total_loss = 248.11, pg_loss = 162.21, baseline_loss = 90.92, entropy_loss = -5.0195, learner_queue_size = 32, _tick = 2829, _time = 1.6548e+09, train_seconds = 4259.9)
[2022-06-09 21:19:05,139][root][INFO] - Step 15979520 @ 3580.6 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 15979520, mean_episode_return = 128.77, mean_episode_step = 1695.5, total_loss = -101.84, pg_loss = -106.77, baseline_loss = 9.628, entropy_loss = -4.6969, learner_queue_size = 32, _tick = 2835, _time = 1.6548e+09, train_seconds = 4264.9)
[2022-06-09 21:19:10,142][root][INFO] - Step 16000000 @ 4093.3 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 16000000, mean_episode_return = 60.17, mean_episode_step = 1528.9, total_loss = 165.61, pg_loss = 105.01, baseline_loss = 66.883, entropy_loss = -6.2799, learner_queue_size = 32, _tick = 2840, _time = 1.6548e+09, train_seconds = 4269.9)
[2022-06-09 21:19:15,146][root][INFO] - Step 16017920 @ 3581.2 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 16017920, mean_episode_return = 35.07, mean_episode_step = 1455.8, total_loss = 120.67, pg_loss = 84.434, baseline_loss = 42.291, entropy_loss = -6.0508, learner_queue_size = 32, _tick = 2845, _time = 1.6548e+09, train_seconds = 4275.0)
[2022-06-09 21:19:20,150][root][INFO] - Step 16035840 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 16035840, mean_episode_return = 57.183, mean_episode_step = 1684.0, total_loss = -29.959, pg_loss = -43.319, baseline_loss = 18.324, entropy_loss = -4.9634, learner_queue_size = 32, _tick = 2851, _time = 1.6548e+09, train_seconds = 4280.0)
[2022-06-09 21:19:25,154][root][INFO] - Step 16056320 @ 4092.6 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 16056320, mean_episode_return = 57.744, mean_episode_step = 1313.4, total_loss = 131.62, pg_loss = 59.471, baseline_loss = 76.744, entropy_loss = -4.5917, learner_queue_size = 32, _tick = 2855, _time = 1.6548e+09, train_seconds = 4285.0)
[2022-06-09 21:19:30,158][root][INFO] - Step 16074240 @ 3581.2 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 16074240, mean_episode_return = 77.333, mean_episode_step = 1549.0, total_loss = 277.71, pg_loss = 175.71, baseline_loss = 106.58, entropy_loss = -4.5864, learner_queue_size = 32, _tick = 2858, _time = 1.6548e+09, train_seconds = 4290.0)
[2022-06-09 21:19:35,162][root][INFO] - Step 16092160 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 16092160, mean_episode_return = None, mean_episode_step = 1608.6, total_loss = 33.62, pg_loss = 13.784, baseline_loss = 25.317, entropy_loss = -5.4814, learner_queue_size = 32, _tick = 2863, _time = 1.6548e+09, train_seconds = 4295.0)
[2022-06-09 21:19:40,166][root][INFO] - Step 16112640 @ 4092.8 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 16112640, mean_episode_return = 74.54, mean_episode_step = 1761.8, total_loss = 96.852, pg_loss = 41.48, baseline_loss = 60.111, entropy_loss = -4.7387, learner_queue_size = 32, _tick = 2867, _time = 1.6548e+09, train_seconds = 4300.0)
[2022-06-09 21:19:45,170][root][INFO] - Step 16130560 @ 3581.2 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 16130560, mean_episode_return = None, mean_episode_step = 1656.9, total_loss = 154.76, pg_loss = 94.129, baseline_loss = 65.461, entropy_loss = -4.8287, learner_queue_size = 32, _tick = 2870, _time = 1.6548e+09, train_seconds = 4305.0)
[2022-06-09 21:19:50,174][root][INFO] - Step 16148480 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 16148480, mean_episode_return = 56.293, mean_episode_step = 1523.6, total_loss = -23.999, pg_loss = -61.539, baseline_loss = 42.291, entropy_loss = -4.7509, learner_queue_size = 32, _tick = 2875, _time = 1.6548e+09, train_seconds = 4310.0)
[2022-06-09 21:19:55,178][root][INFO] - Step 16168960 @ 4092.4 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 16168960, mean_episode_return = 1.6996, mean_episode_step = 1651.7, total_loss = 14.291, pg_loss = -46.996, baseline_loss = 65.983, entropy_loss = -4.6966, learner_queue_size = 32, _tick = 2879, _time = 1.6548e+09, train_seconds = 4315.0)
[2022-06-09 21:20:00,182][root][INFO] - Step 16186880 @ 3581.4 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 16186880, mean_episode_return = None, mean_episode_step = 1881.2, total_loss = 511.72, pg_loss = 375.62, baseline_loss = 140.8, entropy_loss = -4.7043, learner_queue_size = 32, _tick = 2881, _time = 1.6548e+09, train_seconds = 4320.0)
[2022-06-09 21:20:05,186][root][INFO] - Step 16204800 @ 3581.2 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 16204800, mean_episode_return = 15.99, mean_episode_step = 1873.1, total_loss = -99.112, pg_loss = -108.65, baseline_loss = 14.237, entropy_loss = -4.701, learner_queue_size = 32, _tick = 2885, _time = 1.6548e+09, train_seconds = 4325.0)
[2022-06-09 21:20:10,190][root][INFO] - Step 16225280 @ 4092.5 SPS. Inference batcher size: 79. Learner queue size: 32. Other stats: (step = 16225280, mean_episode_return = None, mean_episode_step = 1842.7, total_loss = 550.63, pg_loss = 411.32, baseline_loss = 144.03, entropy_loss = -4.7218, learner_queue_size = 32, _tick = 2889, _time = 1.6548e+09, train_seconds = 4330.0)
[2022-06-09 21:20:15,194][root][INFO] - Step 16243200 @ 3581.3 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 16243200, mean_episode_return = None, mean_episode_step = 1573.4, total_loss = 4.4692, pg_loss = -46.201, baseline_loss = 55.291, entropy_loss = -4.6213, learner_queue_size = 32, _tick = 2890, _time = 1.6548e+09, train_seconds = 4335.0)
[2022-06-09 21:20:20,198][root][INFO] - Step 16263680 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 16263680, mean_episode_return = None, mean_episode_step = 1766.2, total_loss = -100.47, pg_loss = -99.03, baseline_loss = 3.3732, entropy_loss = -4.8146, learner_queue_size = 32, _tick = 2893, _time = 1.6548e+09, train_seconds = 4340.0)
[2022-06-09 21:20:25,206][root][INFO] - Step 16281600 @ 3578.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 16281600, mean_episode_return = None, mean_episode_step = 1764.4, total_loss = 251.24, pg_loss = 147.77, baseline_loss = 108.61, entropy_loss = -5.1423, learner_queue_size = 32, _tick = 2897, _time = 1.6548e+09, train_seconds = 4345.0)
[2022-06-09 21:20:30,210][root][INFO] - Step 16299520 @ 3581.4 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (step = 16299520, mean_episode_return = None, mean_episode_step = 2199.1, total_loss = -7.58, pg_loss = -35.708, baseline_loss = 33.323, entropy_loss = -5.1946, learner_queue_size = 32, _tick = 2900, _time = 1.6548e+09, train_seconds = 4350.0)
[2022-06-09 21:20:35,214][root][INFO] - Step 16320000 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 16320000, mean_episode_return = None, mean_episode_step = 1962.9, total_loss = -7.0117, pg_loss = -9.2944, baseline_loss = 8.301, entropy_loss = -6.0183, learner_queue_size = 32, _tick = 2902, _time = 1.6548e+09, train_seconds = 4355.0)
[2022-06-09 21:20:40,222][root][INFO] - Step 16337920 @ 3578.3 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 16337920, mean_episode_return = 51.0, mean_episode_step = 1441.2, total_loss = 299.09, pg_loss = 120.05, baseline_loss = 184.75, entropy_loss = -5.7083, learner_queue_size = 32, _tick = 2908, _time = 1.6548e+09, train_seconds = 4360.0)
[2022-06-09 21:20:45,226][root][INFO] - Step 16355840 @ 3581.2 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 16355840, mean_episode_return = 151.53, mean_episode_step = 1608.8, total_loss = -195.6, pg_loss = -195.34, baseline_loss = 5.9284, entropy_loss = -6.1838, learner_queue_size = 32, _tick = 2915, _time = 1.6548e+09, train_seconds = 4365.0)
[2022-06-09 21:20:50,230][root][INFO] - Step 16376320 @ 4092.7 SPS. Inference batcher size: 87. Learner queue size: 32. Other stats: (step = 16376320, mean_episode_return = -3.8108, mean_episode_step = 1587.9, total_loss = 440.44, pg_loss = 294.27, baseline_loss = 151.62, entropy_loss = -5.4513, learner_queue_size = 32, _tick = 2921, _time = 1.6548e+09, train_seconds = 4370.0)
[2022-06-09 21:20:55,234][root][INFO] - Step 16394240 @ 3581.1 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 16394240, mean_episode_return = 79.878, mean_episode_step = 1446.7, total_loss = 55.567, pg_loss = 17.015, baseline_loss = 43.664, entropy_loss = -5.1122, learner_queue_size = 32, _tick = 2928, _time = 1.6548e+09, train_seconds = 4375.0)
[2022-06-09 21:21:00,238][root][INFO] - Step 16412160 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 16412160, mean_episode_return = 23.88, mean_episode_step = 1815.3, total_loss = 263.74, pg_loss = 104.75, baseline_loss = 164.03, entropy_loss = -5.0477, learner_queue_size = 32, _tick = 2933, _time = 1.6548e+09, train_seconds = 4380.0)
[2022-06-09 21:21:05,242][root][INFO] - Step 16430080 @ 3580.9 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 16430080, mean_episode_return = 38.34, mean_episode_step = 1524.4, total_loss = 237.62, pg_loss = 124.56, baseline_loss = 118.06, entropy_loss = -5.0082, learner_queue_size = 32, _tick = 2939, _time = 1.6548e+09, train_seconds = 4385.1)
[2022-06-09 21:21:10,246][root][INFO] - Step 16450560 @ 4093.1 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 16450560, mean_episode_return = None, mean_episode_step = 1322.3, total_loss = 33.452, pg_loss = -24.483, baseline_loss = 62.655, entropy_loss = -4.7204, learner_queue_size = 32, _tick = 2943, _time = 1.6548e+09, train_seconds = 4390.1)
[2022-06-09 21:21:15,250][root][INFO] - Step 16468480 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 16468480, mean_episode_return = 49.831, mean_episode_step = 1441.5, total_loss = 45.983, pg_loss = -40.229, baseline_loss = 90.957, entropy_loss = -4.7452, learner_queue_size = 32, _tick = 2948, _time = 1.6548e+09, train_seconds = 4395.1)
[2022-06-09 21:21:20,254][root][INFO] - Step 16486400 @ 3581.2 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 16486400, mean_episode_return = None, mean_episode_step = 1710.1, total_loss = 85.312, pg_loss = 34.12, baseline_loss = 56.12, entropy_loss = -4.9269, learner_queue_size = 32, _tick = 2948, _time = 1.6548e+09, train_seconds = 4400.1)
[2022-06-09 21:21:25,258][root][INFO] - Step 16506880 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 16506880, mean_episode_return = 32.907, mean_episode_step = 1685.2, total_loss = 177.31, pg_loss = 81.826, baseline_loss = 100.37, entropy_loss = -4.8871, learner_queue_size = 32, _tick = 2952, _time = 1.6548e+09, train_seconds = 4405.1)
[2022-06-09 21:21:30,262][root][INFO] - Step 16524800 @ 3581.1 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 16524800, mean_episode_return = 81.857, mean_episode_step = 1763.4, total_loss = 91.036, pg_loss = 37.158, baseline_loss = 58.681, entropy_loss = -4.8028, learner_queue_size = 32, _tick = 2957, _time = 1.6548e+09, train_seconds = 4410.1)
[2022-06-09 21:21:35,330][root][INFO] - Step 16545280 @ 4040.9 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 16545280, mean_episode_return = None, mean_episode_step = 1706.1, total_loss = 95.404, pg_loss = 57.183, baseline_loss = 43.158, entropy_loss = -4.9372, learner_queue_size = 32, _tick = 2960, _time = 1.6548e+09, train_seconds = 4415.1)
[2022-06-09 21:21:40,334][root][INFO] - Step 16563200 @ 3581.3 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 16563200, mean_episode_return = -0.53008, mean_episode_step = 1640.0, total_loss = 118.75, pg_loss = 76.169, baseline_loss = 47.564, entropy_loss = -4.9853, learner_queue_size = 32, _tick = 2962, _time = 1.6548e+09, train_seconds = 4420.1)
[2022-06-09 21:21:45,338][root][INFO] - Step 16581120 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 16581120, mean_episode_return = 5.7496, mean_episode_step = 1683.5, total_loss = -3.888, pg_loss = -23.078, baseline_loss = 24.417, entropy_loss = -5.2272, learner_queue_size = 32, _tick = 2966, _time = 1.6548e+09, train_seconds = 4425.1)
[2022-06-09 21:21:50,342][root][INFO] - Step 16601600 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 16601600, mean_episode_return = 32.793, mean_episode_step = 1473.0, total_loss = -85.045, pg_loss = -131.17, baseline_loss = 51.249, entropy_loss = -5.1248, learner_queue_size = 32, _tick = 2972, _time = 1.6548e+09, train_seconds = 4430.1)
[2022-06-09 21:21:55,346][root][INFO] - Step 16619520 @ 3581.2 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 16619520, mean_episode_return = None, mean_episode_step = 1906.9, total_loss = 255.86, pg_loss = 161.39, baseline_loss = 99.866, entropy_loss = -5.3952, learner_queue_size = 32, _tick = 2977, _time = 1.6548e+09, train_seconds = 4435.2)
[2022-06-09 21:22:00,351][root][INFO] - Step 16640000 @ 4092.0 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 16640000, mean_episode_return = 85.903, mean_episode_step = 1847.3, total_loss = 604.91, pg_loss = 308.18, baseline_loss = 301.58, entropy_loss = -4.8472, learner_queue_size = 32, _tick = 2983, _time = 1.6548e+09, train_seconds = 4440.2)
[2022-06-09 21:22:05,354][root][INFO] - Step 16657920 @ 3581.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 16657920, mean_episode_return = 14.15, mean_episode_step = 1449.5, total_loss = -50.772, pg_loss = -84.997, baseline_loss = 39.032, entropy_loss = -4.8069, learner_queue_size = 32, _tick = 2989, _time = 1.6548e+09, train_seconds = 4445.2)
[2022-06-09 21:22:10,358][root][INFO] - Step 16675840 @ 3581.1 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 16675840, mean_episode_return = 65.1, mean_episode_step = 1627.0, total_loss = -212.95, pg_loss = -234.85, baseline_loss = 26.733, entropy_loss = -4.8291, learner_queue_size = 32, _tick = 2993, _time = 1.6548e+09, train_seconds = 4450.2)
[2022-06-09 21:22:15,362][root][INFO] - Step 16693760 @ 3581.2 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 16693760, mean_episode_return = None, mean_episode_step = 1375.6, total_loss = -70.716, pg_loss = -86.077, baseline_loss = 20.144, entropy_loss = -4.7841, learner_queue_size = 32, _tick = 2997, _time = 1.6548e+09, train_seconds = 4455.2)
[2022-06-09 21:22:20,366][root][INFO] - Step 16714240 @ 4092.6 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 16714240, mean_episode_return = 57.944, mean_episode_step = 1709.0, total_loss = -115.69, pg_loss = -143.21, baseline_loss = 32.364, entropy_loss = -4.8405, learner_queue_size = 32, _tick = 3002, _time = 1.6548e+09, train_seconds = 4460.2)
[2022-06-09 21:22:25,370][root][INFO] - Step 16732160 @ 3581.2 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 16732160, mean_episode_return = 31.7, mean_episode_step = 1538.9, total_loss = -22.957, pg_loss = -101.35, baseline_loss = 83.244, entropy_loss = -4.8472, learner_queue_size = 32, _tick = 3008, _time = 1.6548e+09, train_seconds = 4465.2)
[2022-06-09 21:22:30,374][root][INFO] - Step 16750080 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 16750080, mean_episode_return = 192.88, mean_episode_step = 1742.9, total_loss = 359.84, pg_loss = 259.44, baseline_loss = 105.28, entropy_loss = -4.8802, learner_queue_size = 32, _tick = 3012, _time = 1.6548e+09, train_seconds = 4470.2)
[2022-06-09 21:22:35,379][root][INFO] - Step 16770560 @ 4092.1 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (step = 16770560, mean_episode_return = None, mean_episode_step = 1578.0, total_loss = 144.14, pg_loss = 76.426, baseline_loss = 72.436, entropy_loss = -4.7242, learner_queue_size = 32, _tick = 3017, _time = 1.6548e+09, train_seconds = 4475.2)
[2022-06-09 21:22:40,382][root][INFO] - Step 16785920 @ 3070.0 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 16785920, mean_episode_return = None, mean_episode_step = 1722.6, total_loss = 17.663, pg_loss = -5.4309, baseline_loss = 28.104, entropy_loss = -5.0099, learner_queue_size = 32, _tick = 3021, _time = 1.6548e+09, train_seconds = 4480.2)
[2022-06-09 21:22:45,386][root][INFO] - Step 16803840 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 16803840, mean_episode_return = 63.94, mean_episode_step = 1535.4, total_loss = 66.212, pg_loss = 32.019, baseline_loss = 38.999, entropy_loss = -4.8065, learner_queue_size = 32, _tick = 3025, _time = 1.6548e+09, train_seconds = 4485.2)
[2022-06-09 21:22:50,390][root][INFO] - Step 16824320 @ 4092.7 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 16824320, mean_episode_return = 21.38, mean_episode_step = 1323.6, total_loss = 442.43, pg_loss = 274.46, baseline_loss = 172.78, entropy_loss = -4.8093, learner_queue_size = 32, _tick = 3030, _time = 1.6548e+09, train_seconds = 4490.2)
[2022-06-09 21:22:55,394][root][INFO] - Step 16842240 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 16842240, mean_episode_return = None, mean_episode_step = 1652.0, total_loss = -90.009, pg_loss = -97.988, baseline_loss = 12.821, entropy_loss = -4.8414, learner_queue_size = 32, _tick = 3032, _time = 1.6548e+09, train_seconds = 4495.2)
[2022-06-09 21:23:00,398][root][INFO] - Step 16862720 @ 4092.7 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 16862720, mean_episode_return = None, mean_episode_step = 1536.8, total_loss = -45.481, pg_loss = -41.869, baseline_loss = 2.0041, entropy_loss = -5.6163, learner_queue_size = 32, _tick = 3036, _time = 1.6548e+09, train_seconds = 4500.2)
[2022-06-09 21:23:05,402][root][INFO] - Step 16880640 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 16880640, mean_episode_return = 29.376, mean_episode_step = 1734.4, total_loss = 220.98, pg_loss = 148.11, baseline_loss = 78.597, entropy_loss = -5.7236, learner_queue_size = 32, _tick = 3041, _time = 1.6548e+09, train_seconds = 4505.2)
[2022-06-09 21:23:10,406][root][INFO] - Step 16898560 @ 3581.0 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 16898560, mean_episode_return = None, mean_episode_step = 1699.9, total_loss = 25.487, pg_loss = 11.845, baseline_loss = 19.26, entropy_loss = -5.6182, learner_queue_size = 32, _tick = 3043, _time = 1.6548e+09, train_seconds = 4510.2)
[2022-06-09 21:23:15,410][root][INFO] - Step 16916480 @ 3581.3 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 16916480, mean_episode_return = 99.679, mean_episode_step = 1604.0, total_loss = 147.05, pg_loss = 68.726, baseline_loss = 83.904, entropy_loss = -5.5774, learner_queue_size = 32, _tick = 3050, _time = 1.6548e+09, train_seconds = 4515.2)
[2022-06-09 21:23:20,414][root][INFO] - Step 16936960 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 16936960, mean_episode_return = None, mean_episode_step = 1804.8, total_loss = 153.11, pg_loss = 120.53, baseline_loss = 38.346, entropy_loss = -5.7653, learner_queue_size = 32, _tick = 3053, _time = 1.6548e+09, train_seconds = 4520.2)
[2022-06-09 21:23:25,418][root][INFO] - Step 16954880 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 16954880, mean_episode_return = 39.061, mean_episode_step = 1875.0, total_loss = 41.383, pg_loss = 17.372, baseline_loss = 29.394, entropy_loss = -5.3832, learner_queue_size = 32, _tick = 3057, _time = 1.6548e+09, train_seconds = 4525.2)
[2022-06-09 21:23:30,422][root][INFO] - Step 16972800 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 16972800, mean_episode_return = 29.55, mean_episode_step = 1888.2, total_loss = 94.283, pg_loss = -26.266, baseline_loss = 126.02, entropy_loss = -5.4726, learner_queue_size = 32, _tick = 3063, _time = 1.6548e+09, train_seconds = 4530.2)
[2022-06-09 21:23:35,426][root][INFO] - Step 16993280 @ 4092.8 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 16993280, mean_episode_return = None, mean_episode_step = 1723.0, total_loss = 19.631, pg_loss = -3.8954, baseline_loss = 28.696, entropy_loss = -5.1701, learner_queue_size = 32, _tick = 3067, _time = 1.6548e+09, train_seconds = 4535.2)
[2022-06-09 21:23:40,430][root][INFO] - Step 17011200 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 17011200, mean_episode_return = None, mean_episode_step = 2220.6, total_loss = -49.445, pg_loss = -58.915, baseline_loss = 14.641, entropy_loss = -5.1713, learner_queue_size = 32, _tick = 3071, _time = 1.6548e+09, train_seconds = 4540.2)
[2022-06-09 21:23:45,434][root][INFO] - Step 17029120 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 17029120, mean_episode_return = None, mean_episode_step = 1606.0, total_loss = 347.46, pg_loss = 248.34, baseline_loss = 104.39, entropy_loss = -5.2703, learner_queue_size = 32, _tick = 3074, _time = 1.6548e+09, train_seconds = 4545.2)
[2022-06-09 21:23:50,438][root][INFO] - Step 17047040 @ 3581.0 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 17047040, mean_episode_return = None, mean_episode_step = 1552.8, total_loss = -63.394, pg_loss = -77.559, baseline_loss = 19.189, entropy_loss = -5.0245, learner_queue_size = 32, _tick = 3077, _time = 1.6548e+09, train_seconds = 4550.2)
[2022-06-09 21:23:55,442][root][INFO] - Step 17067520 @ 4092.9 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 17067520, mean_episode_return = None, mean_episode_step = 2111.3, total_loss = -37.3, pg_loss = -52.566, baseline_loss = 20.225, entropy_loss = -4.9586, learner_queue_size = 32, _tick = 3080, _time = 1.6548e+09, train_seconds = 4555.2)
[2022-06-09 21:24:00,446][root][INFO] - Step 17085440 @ 3580.9 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 17085440, mean_episode_return = None, mean_episode_step = 1990.9, total_loss = 84.101, pg_loss = 45.087, baseline_loss = 44.059, entropy_loss = -5.0447, learner_queue_size = 32, _tick = 3085, _time = 1.6548e+09, train_seconds = 4560.3)
[2022-06-09 21:24:05,451][root][INFO] - Step 17105920 @ 4093.0 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 17105920, mean_episode_return = 17.365, mean_episode_step = 1744.4, total_loss = -60.286, pg_loss = -89.3, baseline_loss = 33.823, entropy_loss = -4.8086, learner_queue_size = 32, _tick = 3089, _time = 1.6548e+09, train_seconds = 4565.3)
[2022-06-09 21:24:10,454][root][INFO] - Step 17123840 @ 3581.2 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 17123840, mean_episode_return = None, mean_episode_step = 1909.1, total_loss = 128.05, pg_loss = 83.556, baseline_loss = 49.659, entropy_loss = -5.1642, learner_queue_size = 32, _tick = 3090, _time = 1.6548e+09, train_seconds = 4570.3)
[2022-06-09 21:24:15,458][root][INFO] - Step 17144320 @ 4092.7 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 17144320, mean_episode_return = None, mean_episode_step = 2555.7, total_loss = -28.468, pg_loss = -54.809, baseline_loss = 32.073, entropy_loss = -5.7323, learner_queue_size = 32, _tick = 3094, _time = 1.6548e+09, train_seconds = 4575.3)
[2022-06-09 21:24:20,462][root][INFO] - Step 17162240 @ 3581.2 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 17162240, mean_episode_return = 32.726, mean_episode_step = 1609.9, total_loss = -107.63, pg_loss = -108.37, baseline_loss = 5.7954, entropy_loss = -5.0567, learner_queue_size = 32, _tick = 3096, _time = 1.6548e+09, train_seconds = 4580.3)
[2022-06-09 21:24:25,466][root][INFO] - Step 17180160 @ 3581.1 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 17180160, mean_episode_return = 8.97, mean_episode_step = 2400.9, total_loss = -182.78, pg_loss = -184.82, baseline_loss = 7.4665, entropy_loss = -5.4226, learner_queue_size = 32, _tick = 3100, _time = 1.6548e+09, train_seconds = 4585.3)
[2022-06-09 21:24:30,470][root][INFO] - Step 17200640 @ 4092.6 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 17200640, mean_episode_return = 40.033, mean_episode_step = 1912.6, total_loss = 378.13, pg_loss = 293.01, baseline_loss = 90.939, entropy_loss = -5.8198, learner_queue_size = 32, _tick = 3105, _time = 1.6548e+09, train_seconds = 4590.3)
[2022-06-09 21:24:35,474][root][INFO] - Step 17218560 @ 3581.2 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 17218560, mean_episode_return = 49.564, mean_episode_step = 1980.2, total_loss = 77.626, pg_loss = 21.731, baseline_loss = 61.654, entropy_loss = -5.7593, learner_queue_size = 32, _tick = 3112, _time = 1.6548e+09, train_seconds = 4595.3)
[2022-06-09 21:24:40,478][root][INFO] - Step 17239040 @ 4092.8 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 17239040, mean_episode_return = 66.35, mean_episode_step = 2292.8, total_loss = -115.35, pg_loss = -115.11, baseline_loss = 5.7035, entropy_loss = -5.9444, learner_queue_size = 32, _tick = 3118, _time = 1.6548e+09, train_seconds = 4600.3)
[2022-06-09 21:24:45,482][root][INFO] - Step 17256960 @ 3581.2 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 17256960, mean_episode_return = 58.033, mean_episode_step = 1998.2, total_loss = -91.092, pg_loss = -94.647, baseline_loss = 9.4878, entropy_loss = -5.9331, learner_queue_size = 32, _tick = 3121, _time = 1.6548e+09, train_seconds = 4605.3)
[2022-06-09 21:24:50,486][root][INFO] - Step 17274880 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 17274880, mean_episode_return = 25.766, mean_episode_step = 1538.0, total_loss = 353.27, pg_loss = 235.29, baseline_loss = 123.5, entropy_loss = -5.5135, learner_queue_size = 32, _tick = 3127, _time = 1.6548e+09, train_seconds = 4610.3)
[2022-06-09 21:24:55,490][root][INFO] - Step 17295360 @ 4092.7 SPS. Inference batcher size: 99. Learner queue size: 32. Other stats: (step = 17295360, mean_episode_return = 31.27, mean_episode_step = 1900.4, total_loss = 128.62, pg_loss = 83.49, baseline_loss = 49.758, entropy_loss = -4.6288, learner_queue_size = 32, _tick = 3132, _time = 1.6548e+09, train_seconds = 4615.3)
[2022-06-09 21:25:00,494][root][INFO] - Step 17313280 @ 3581.2 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 17313280, mean_episode_return = 42.97, mean_episode_step = 1762.9, total_loss = 26.616, pg_loss = -24.468, baseline_loss = 55.718, entropy_loss = -4.634, learner_queue_size = 32, _tick = 3137, _time = 1.6548e+09, train_seconds = 4620.3)
[2022-06-09 21:25:05,498][root][INFO] - Step 17331200 @ 3581.1 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 17331200, mean_episode_return = 39.06, mean_episode_step = 1968.2, total_loss = -23.854, pg_loss = -39.59, baseline_loss = 20.531, entropy_loss = -4.7951, learner_queue_size = 32, _tick = 3141, _time = 1.6548e+09, train_seconds = 4625.3)
[2022-06-09 21:25:10,502][root][INFO] - Step 17351680 @ 4092.7 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 17351680, mean_episode_return = 62.19, mean_episode_step = 1952.7, total_loss = 107.72, pg_loss = 63.994, baseline_loss = 49.69, entropy_loss = -5.962, learner_queue_size = 32, _tick = 3148, _time = 1.6548e+09, train_seconds = 4630.3)
[2022-06-09 21:25:15,506][root][INFO] - Step 17369600 @ 3581.2 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 17369600, mean_episode_return = 41.76, mean_episode_step = 1550.8, total_loss = -27.662, pg_loss = -45.39, baseline_loss = 23.61, entropy_loss = -5.8819, learner_queue_size = 32, _tick = 3153, _time = 1.6548e+09, train_seconds = 4635.3)
[2022-06-09 21:25:20,510][root][INFO] - Step 17387520 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 17387520, mean_episode_return = 32.256, mean_episode_step = 1702.6, total_loss = -128.27, pg_loss = -140.85, baseline_loss = 18.442, entropy_loss = -5.8628, learner_queue_size = 32, _tick = 3157, _time = 1.6548e+09, train_seconds = 4640.3)
[2022-06-09 21:25:25,514][root][INFO] - Step 17405440 @ 3581.2 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 17405440, mean_episode_return = 58.337, mean_episode_step = 1844.0, total_loss = -11.195, pg_loss = -23.084, baseline_loss = 17.926, entropy_loss = -6.0367, learner_queue_size = 32, _tick = 3162, _time = 1.6548e+09, train_seconds = 4645.3)
[2022-06-09 21:25:30,518][root][INFO] - Step 17425920 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 17425920, mean_episode_return = None, mean_episode_step = 1657.7, total_loss = 31.892, pg_loss = 19.408, baseline_loss = 18.318, entropy_loss = -5.833, learner_queue_size = 32, _tick = 3167, _time = 1.6548e+09, train_seconds = 4650.3)
[2022-06-09 21:25:35,522][root][INFO] - Step 17443840 @ 3581.2 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 17443840, mean_episode_return = None, mean_episode_step = 1883.3, total_loss = -73.909, pg_loss = -85.735, baseline_loss = 17.627, entropy_loss = -5.8015, learner_queue_size = 32, _tick = 3172, _time = 1.6548e+09, train_seconds = 4655.3)
[2022-06-09 21:25:40,526][root][INFO] - Step 17464320 @ 4092.7 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 17464320, mean_episode_return = 44.661, mean_episode_step = 1791.1, total_loss = 223.02, pg_loss = 136.29, baseline_loss = 91.86, entropy_loss = -5.133, learner_queue_size = 32, _tick = 3180, _time = 1.6548e+09, train_seconds = 4660.3)
[2022-06-09 21:25:45,530][root][INFO] - Step 17482240 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 17482240, mean_episode_return = 115.61, mean_episode_step = 1557.9, total_loss = 98.229, pg_loss = 44.814, baseline_loss = 58.84, entropy_loss = -5.4248, learner_queue_size = 32, _tick = 3185, _time = 1.6548e+09, train_seconds = 4665.3)
[2022-06-09 21:25:50,534][root][INFO] - Step 17500160 @ 3581.1 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 17500160, mean_episode_return = None, mean_episode_step = 1383.0, total_loss = -38.481, pg_loss = -39.454, baseline_loss = 5.9697, entropy_loss = -4.9969, learner_queue_size = 32, _tick = 3188, _time = 1.6548e+09, train_seconds = 4670.3)
[2022-06-09 21:25:55,538][root][INFO] - Step 17520640 @ 4092.7 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 17520640, mean_episode_return = None, mean_episode_step = 1639.3, total_loss = 257.06, pg_loss = 168.22, baseline_loss = 94.317, entropy_loss = -5.4737, learner_queue_size = 32, _tick = 3194, _time = 1.6548e+09, train_seconds = 4675.3)
[2022-06-09 21:26:00,542][root][INFO] - Step 17538560 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 17538560, mean_episode_return = None, mean_episode_step = 1490.8, total_loss = -5.4562, pg_loss = -42.692, baseline_loss = 42.632, entropy_loss = -5.3969, learner_queue_size = 32, _tick = 3198, _time = 1.6548e+09, train_seconds = 4680.3)
[2022-06-09 21:26:05,546][root][INFO] - Step 17556480 @ 3581.1 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 17556480, mean_episode_return = None, mean_episode_step = 1569.9, total_loss = 371.37, pg_loss = 267.02, baseline_loss = 109.64, entropy_loss = -5.2877, learner_queue_size = 32, _tick = 3201, _time = 1.6548e+09, train_seconds = 4685.4)
[2022-06-09 21:26:10,550][root][INFO] - Step 17574400 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 17574400, mean_episode_return = 76.16, mean_episode_step = 1721.4, total_loss = 196.72, pg_loss = 67.992, baseline_loss = 133.83, entropy_loss = -5.1012, learner_queue_size = 32, _tick = 3206, _time = 1.6548e+09, train_seconds = 4690.4)
[2022-06-09 21:26:15,554][root][INFO] - Step 17594880 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 17594880, mean_episode_return = 95.489, mean_episode_step = 1727.2, total_loss = 9.8914, pg_loss = -20.965, baseline_loss = 35.225, entropy_loss = -4.369, learner_queue_size = 32, _tick = 3212, _time = 1.6548e+09, train_seconds = 4695.4)
[2022-06-09 21:26:20,558][root][INFO] - Step 17612800 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 17612800, mean_episode_return = None, mean_episode_step = 2162.3, total_loss = 67.526, pg_loss = 18.503, baseline_loss = 53.565, entropy_loss = -4.542, learner_queue_size = 32, _tick = 3214, _time = 1.6548e+09, train_seconds = 4700.4)
[2022-06-09 21:26:25,562][root][INFO] - Step 17633280 @ 4092.8 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 17633280, mean_episode_return = 26.954, mean_episode_step = 1379.1, total_loss = 59.866, pg_loss = 2.5946, baseline_loss = 61.698, entropy_loss = -4.4264, learner_queue_size = 32, _tick = 3216, _time = 1.6548e+09, train_seconds = 4705.4)
[2022-06-09 21:26:30,566][root][INFO] - Step 17651200 @ 3581.1 SPS. Inference batcher size: 80. Learner queue size: 32. Other stats: (step = 17651200, mean_episode_return = None, mean_episode_step = 1793.2, total_loss = 55.401, pg_loss = 35.786, baseline_loss = 24.653, entropy_loss = -5.0377, learner_queue_size = 32, _tick = 3217, _time = 1.6548e+09, train_seconds = 4710.4)
[2022-06-09 21:26:35,570][root][INFO] - Step 17669120 @ 3581.1 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (step = 17669120, mean_episode_return = None, mean_episode_step = 2020.1, total_loss = 103.69, pg_loss = 34.337, baseline_loss = 74.475, entropy_loss = -5.1248, learner_queue_size = 32, _tick = 3219, _time = 1.6548e+09, train_seconds = 4715.4)
[2022-06-09 21:26:40,574][root][INFO] - Step 17687040 @ 3581.1 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 17687040, mean_episode_return = 47.111, mean_episode_step = 1886.8, total_loss = 159.78, pg_loss = 87.778, baseline_loss = 77.376, entropy_loss = -5.3717, learner_queue_size = 32, _tick = 3223, _time = 1.6548e+09, train_seconds = 4720.4)
[2022-06-09 21:26:45,578][root][INFO] - Step 17707520 @ 4092.3 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 17707520, mean_episode_return = 63.34, mean_episode_step = 1653.4, total_loss = 133.6, pg_loss = 69.308, baseline_loss = 69.615, entropy_loss = -5.3251, learner_queue_size = 32, _tick = 3227, _time = 1.6548e+09, train_seconds = 4725.4)
[2022-06-09 21:26:50,582][root][INFO] - Step 17725440 @ 3581.5 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 17725440, mean_episode_return = 47.551, mean_episode_step = 2310.0, total_loss = -60.548, pg_loss = -116.11, baseline_loss = 60.965, entropy_loss = -5.4015, learner_queue_size = 32, _tick = 3232, _time = 1.6548e+09, train_seconds = 4730.4)
[2022-06-09 21:26:55,588][root][INFO] - Step 17745920 @ 4091.3 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 17745920, mean_episode_return = -0.72541, mean_episode_step = 1709.0, total_loss = 35.001, pg_loss = 18.681, baseline_loss = 20.21, entropy_loss = -3.8904, learner_queue_size = 32, _tick = 3238, _time = 1.6548e+09, train_seconds = 4735.4)
[2022-06-09 21:27:00,594][root][INFO] - Step 17763840 @ 3579.5 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 17763840, mean_episode_return = 10.67, mean_episode_step = 2023.0, total_loss = -76.818, pg_loss = -85.095, baseline_loss = 13.311, entropy_loss = -5.0339, learner_queue_size = 32, _tick = 3245, _time = 1.6548e+09, train_seconds = 4740.4)
[2022-06-09 21:27:05,598][root][INFO] - Step 17781760 @ 3581.2 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 17781760, mean_episode_return = 138.64, mean_episode_step = 1898.1, total_loss = 192.73, pg_loss = 104.88, baseline_loss = 92.696, entropy_loss = -4.8421, learner_queue_size = 32, _tick = 3251, _time = 1.6548e+09, train_seconds = 4745.4)
[2022-06-09 21:27:10,602][root][INFO] - Step 17802240 @ 4092.7 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 17802240, mean_episode_return = 32.3, mean_episode_step = 1828.0, total_loss = -41.922, pg_loss = -63.167, baseline_loss = 26.281, entropy_loss = -5.0368, learner_queue_size = 32, _tick = 3257, _time = 1.6548e+09, train_seconds = 4750.4)
[2022-06-09 21:27:15,606][root][INFO] - Step 17820160 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 17820160, mean_episode_return = 18.55, mean_episode_step = 1586.7, total_loss = -64.698, pg_loss = -84.027, baseline_loss = 24.465, entropy_loss = -5.1358, learner_queue_size = 32, _tick = 3261, _time = 1.6548e+09, train_seconds = 4755.4)
[2022-06-09 21:27:20,610][root][INFO] - Step 17838080 @ 3581.1 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 17838080, mean_episode_return = None, mean_episode_step = 1396.6, total_loss = 222.92, pg_loss = 145.1, baseline_loss = 83.26, entropy_loss = -5.4332, learner_queue_size = 32, _tick = 3264, _time = 1.6548e+09, train_seconds = 4760.4)
[2022-06-09 21:27:25,614][root][INFO] - Step 17858560 @ 4092.8 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 17858560, mean_episode_return = 17.13, mean_episode_step = 2096.0, total_loss = 92.291, pg_loss = 50.663, baseline_loss = 46.824, entropy_loss = -5.1961, learner_queue_size = 32, _tick = 3271, _time = 1.6548e+09, train_seconds = 4765.4)
[2022-06-09 21:27:30,618][root][INFO] - Step 17876480 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 17876480, mean_episode_return = None, mean_episode_step = 1889.2, total_loss = -45.939, pg_loss = -52.098, baseline_loss = 11.009, entropy_loss = -4.8497, learner_queue_size = 32, _tick = 3276, _time = 1.6548e+09, train_seconds = 4770.4)
[2022-06-09 21:27:35,623][root][INFO] - Step 17894400 @ 3580.4 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 17894400, mean_episode_return = None, mean_episode_step = 1953.8, total_loss = -92.222, pg_loss = -88.508, baseline_loss = 2.0994, entropy_loss = -5.8135, learner_queue_size = 32, _tick = 3281, _time = 1.6548e+09, train_seconds = 4775.4)
[2022-06-09 21:27:40,629][root][INFO] - Step 17914880 @ 4090.8 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 17914880, mean_episode_return = None, mean_episode_step = 1581.7, total_loss = 263.75, pg_loss = 189.4, baseline_loss = 80.302, entropy_loss = -5.945, learner_queue_size = 32, _tick = 3287, _time = 1.6548e+09, train_seconds = 4780.4)
[2022-06-09 21:27:45,634][root][INFO] - Step 17932800 @ 3580.7 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 17932800, mean_episode_return = None, mean_episode_step = 1656.2, total_loss = 255.22, pg_loss = 161.27, baseline_loss = 100.02, entropy_loss = -6.0709, learner_queue_size = 32, _tick = 3290, _time = 1.6548e+09, train_seconds = 4785.4)
[2022-06-09 21:27:50,638][root][INFO] - Step 17953280 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 17953280, mean_episode_return = 28.04, mean_episode_step = 1655.2, total_loss = -43.279, pg_loss = -62.99, baseline_loss = 25.686, entropy_loss = -5.9744, learner_queue_size = 32, _tick = 3296, _time = 1.6548e+09, train_seconds = 4790.4)
[2022-06-09 21:27:55,642][root][INFO] - Step 17971200 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 17971200, mean_episode_return = 106.39, mean_episode_step = 1498.0, total_loss = 63.072, pg_loss = 11.059, baseline_loss = 57.744, entropy_loss = -5.7303, learner_queue_size = 32, _tick = 3303, _time = 1.6548e+09, train_seconds = 4795.4)
[2022-06-09 21:28:00,646][root][INFO] - Step 17989120 @ 3581.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 17989120, mean_episode_return = None, mean_episode_step = 1419.6, total_loss = 113.66, pg_loss = 85.948, baseline_loss = 33.17, entropy_loss = -5.4564, learner_queue_size = 32, _tick = 3305, _time = 1.6548e+09, train_seconds = 4800.5)
[2022-06-09 21:28:05,651][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-09 21:28:05,864][root][INFO] - Step 18007040 @ 3580.7 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 18009600, mean_episode_return = None, mean_episode_step = 1826.4, total_loss = 186.01, pg_loss = 136.91, baseline_loss = 54.516, entropy_loss = -5.4191, learner_queue_size = 32, _tick = 3309, _time = 1.6548e+09, train_seconds = 4805.5)
[2022-06-09 21:28:10,870][root][INFO] - Step 18027520 @ 3923.8 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 18027520, mean_episode_return = 52.197, mean_episode_step = 1489.4, total_loss = -93.595, pg_loss = -171.61, baseline_loss = 83.103, entropy_loss = -5.0882, learner_queue_size = 32, _tick = 3315, _time = 1.6548e+09, train_seconds = 4810.7)
[2022-06-09 21:28:15,874][root][INFO] - Step 18045440 @ 3581.1 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 18045440, mean_episode_return = None, mean_episode_step = 1951.7, total_loss = 32.389, pg_loss = 12.937, baseline_loss = 24.968, entropy_loss = -5.5159, learner_queue_size = 32, _tick = 3316, _time = 1.6548e+09, train_seconds = 4815.7)
[2022-06-09 21:28:20,878][root][INFO] - Step 18065920 @ 4092.7 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (step = 18065920, mean_episode_return = None, mean_episode_step = 1487.4, total_loss = 450.01, pg_loss = 329.11, baseline_loss = 126.26, entropy_loss = -5.3616, learner_queue_size = 32, _tick = 3319, _time = 1.6548e+09, train_seconds = 4820.7)
[2022-06-09 21:28:25,882][root][INFO] - Step 18083840 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 18083840, mean_episode_return = 79.39, mean_episode_step = 1941.1, total_loss = -46.729, pg_loss = -59.622, baseline_loss = 18.681, entropy_loss = -5.7876, learner_queue_size = 32, _tick = 3325, _time = 1.6548e+09, train_seconds = 4825.7)
[2022-06-09 21:28:30,886][root][INFO] - Step 18101760 @ 3581.1 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 18101760, mean_episode_return = None, mean_episode_step = 2159.6, total_loss = 113.68, pg_loss = 77.851, baseline_loss = 41.452, entropy_loss = -5.6274, learner_queue_size = 32, _tick = 3327, _time = 1.6548e+09, train_seconds = 4830.7)
[2022-06-09 21:28:35,890][root][INFO] - Step 18119680 @ 3581.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 18119680, mean_episode_return = -9.7845, mean_episode_step = 1790.1, total_loss = 186.24, pg_loss = 62.702, baseline_loss = 129.16, entropy_loss = -5.6213, learner_queue_size = 32, _tick = 3334, _time = 1.6548e+09, train_seconds = 4835.7)
[2022-06-09 21:28:40,894][root][INFO] - Step 18140160 @ 4092.8 SPS. Inference batcher size: 76. Learner queue size: 32. Other stats: (step = 18140160, mean_episode_return = None, mean_episode_step = 1669.8, total_loss = 77.265, pg_loss = 44.503, baseline_loss = 38.553, entropy_loss = -5.7917, learner_queue_size = 32, _tick = 3338, _time = 1.6548e+09, train_seconds = 4840.7)
[2022-06-09 21:28:45,898][root][INFO] - Step 18158080 @ 3581.1 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 18158080, mean_episode_return = 77.586, mean_episode_step = 1652.6, total_loss = -163.02, pg_loss = -181.94, baseline_loss = 24.65, entropy_loss = -5.7287, learner_queue_size = 32, _tick = 3344, _time = 1.6548e+09, train_seconds = 4845.7)
[2022-06-09 21:28:50,902][root][INFO] - Step 18176000 @ 3581.2 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 18176000, mean_episode_return = 77.549, mean_episode_step = 1585.3, total_loss = 0.54261, pg_loss = -31.854, baseline_loss = 38.161, entropy_loss = -5.7645, learner_queue_size = 32, _tick = 3349, _time = 1.6548e+09, train_seconds = 4850.7)
[2022-06-09 21:28:55,906][root][INFO] - Step 18196480 @ 4092.7 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 18196480, mean_episode_return = None, mean_episode_step = 1346.5, total_loss = 229.98, pg_loss = 164.24, baseline_loss = 71.533, entropy_loss = -5.7908, learner_queue_size = 32, _tick = 3354, _time = 1.6548e+09, train_seconds = 4855.7)
[2022-06-09 21:29:00,910][root][INFO] - Step 18214400 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 18214400, mean_episode_return = None, mean_episode_step = 1722.0, total_loss = 12.295, pg_loss = 0.23991, baseline_loss = 17.415, entropy_loss = -5.3601, learner_queue_size = 32, _tick = 3359, _time = 1.6548e+09, train_seconds = 4860.7)
[2022-06-09 21:29:05,914][root][INFO] - Step 18232320 @ 3581.1 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 18232320, mean_episode_return = None, mean_episode_step = 2018.7, total_loss = -110.03, pg_loss = -114.61, baseline_loss = 10.017, entropy_loss = -5.4449, learner_queue_size = 32, _tick = 3361, _time = 1.6548e+09, train_seconds = 4865.7)
[2022-06-09 21:29:10,918][root][INFO] - Step 18252800 @ 4092.7 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 18252800, mean_episode_return = None, mean_episode_step = 2210.0, total_loss = 96.024, pg_loss = 60.492, baseline_loss = 41.219, entropy_loss = -5.6863, learner_queue_size = 32, _tick = 3366, _time = 1.6548e+09, train_seconds = 4870.7)
[2022-06-09 21:29:15,922][root][INFO] - Step 18270720 @ 3581.2 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 18270720, mean_episode_return = 68.336, mean_episode_step = 1651.1, total_loss = -59.077, pg_loss = -118.83, baseline_loss = 65.314, entropy_loss = -5.5606, learner_queue_size = 32, _tick = 3371, _time = 1.6548e+09, train_seconds = 4875.7)
[2022-06-09 21:29:20,926][root][INFO] - Step 18288640 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 18288640, mean_episode_return = 37.522, mean_episode_step = 1754.9, total_loss = -200.09, pg_loss = -206.8, baseline_loss = 12.362, entropy_loss = -5.6518, learner_queue_size = 32, _tick = 3375, _time = 1.6548e+09, train_seconds = 4880.7)
[2022-06-09 21:29:25,930][root][INFO] - Step 18306560 @ 3581.2 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 18306560, mean_episode_return = None, mean_episode_step = 1665.6, total_loss = 135.54, pg_loss = 82.271, baseline_loss = 58.801, entropy_loss = -5.5288, learner_queue_size = 32, _tick = 3379, _time = 1.6548e+09, train_seconds = 4885.7)
[2022-06-09 21:29:30,934][root][INFO] - Step 18327040 @ 4092.7 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 18327040, mean_episode_return = 24.51, mean_episode_step = 1875.1, total_loss = 297.68, pg_loss = 183.28, baseline_loss = 120.03, entropy_loss = -5.6326, learner_queue_size = 32, _tick = 3387, _time = 1.6548e+09, train_seconds = 4890.7)
[2022-06-09 21:29:35,938][root][INFO] - Step 18344960 @ 3580.9 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 18344960, mean_episode_return = None, mean_episode_step = 1795.7, total_loss = 105.43, pg_loss = 64.798, baseline_loss = 46.397, entropy_loss = -5.7662, learner_queue_size = 32, _tick = 3391, _time = 1.6548e+09, train_seconds = 4895.7)
[2022-06-09 21:29:40,942][root][INFO] - Step 18362880 @ 3581.4 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 18362880, mean_episode_return = 4.6897, mean_episode_step = 1670.8, total_loss = 152.97, pg_loss = 111.51, baseline_loss = 47.329, entropy_loss = -5.8645, learner_queue_size = 32, _tick = 3397, _time = 1.6548e+09, train_seconds = 4900.7)
[2022-06-09 21:29:45,946][root][INFO] - Step 18383360 @ 4092.7 SPS. Inference batcher size: 73. Learner queue size: 32. Other stats: (step = 18383360, mean_episode_return = 19.88, mean_episode_step = 1389.9, total_loss = 4.5959, pg_loss = -30.372, baseline_loss = 40.669, entropy_loss = -5.7012, learner_queue_size = 32, _tick = 3402, _time = 1.6548e+09, train_seconds = 4905.8)
[2022-06-09 21:29:50,950][root][INFO] - Step 18401280 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 18401280, mean_episode_return = None, mean_episode_step = 1226.1, total_loss = 195.12, pg_loss = 134.14, baseline_loss = 66.395, entropy_loss = -5.4237, learner_queue_size = 32, _tick = 3406, _time = 1.6548e+09, train_seconds = 4910.8)
[2022-06-09 21:29:55,954][root][INFO] - Step 18419200 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 18419200, mean_episode_return = 18.09, mean_episode_step = 1801.2, total_loss = 36.398, pg_loss = -2.2734, baseline_loss = 44.252, entropy_loss = -5.5804, learner_queue_size = 32, _tick = 3412, _time = 1.6548e+09, train_seconds = 4915.8)
[2022-06-09 21:30:00,958][root][INFO] - Step 18437120 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 18437120, mean_episode_return = 145.7, mean_episode_step = 1536.2, total_loss = -119.76, pg_loss = -121.66, baseline_loss = 7.2047, entropy_loss = -5.3071, learner_queue_size = 32, _tick = 3416, _time = 1.6548e+09, train_seconds = 4920.8)
[2022-06-09 21:30:05,962][root][INFO] - Step 18455040 @ 3580.9 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 18455040, mean_episode_return = None, mean_episode_step = 1588.2, total_loss = 160.81, pg_loss = 89.467, baseline_loss = 76.809, entropy_loss = -5.4636, learner_queue_size = 32, _tick = 3419, _time = 1.6548e+09, train_seconds = 4925.8)
[2022-06-09 21:30:10,966][root][INFO] - Step 18475520 @ 4092.8 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 18475520, mean_episode_return = 38.781, mean_episode_step = 1575.1, total_loss = 351.74, pg_loss = 239.55, baseline_loss = 117.38, entropy_loss = -5.1935, learner_queue_size = 32, _tick = 3425, _time = 1.6548e+09, train_seconds = 4930.8)
[2022-06-09 21:30:15,970][root][INFO] - Step 18493440 @ 3581.1 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 18493440, mean_episode_return = 59.909, mean_episode_step = 1993.3, total_loss = -98.422, pg_loss = -126.22, baseline_loss = 32.88, entropy_loss = -5.0808, learner_queue_size = 32, _tick = 3429, _time = 1.6548e+09, train_seconds = 4935.8)
[2022-06-09 21:30:20,974][root][INFO] - Step 18511360 @ 3581.3 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 18511360, mean_episode_return = 19.935, mean_episode_step = 1389.0, total_loss = 4.4388, pg_loss = -64.251, baseline_loss = 73.85, entropy_loss = -5.1602, learner_queue_size = 32, _tick = 3432, _time = 1.6548e+09, train_seconds = 4940.8)
[2022-06-09 21:30:25,978][root][INFO] - Step 18531840 @ 4092.7 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 18531840, mean_episode_return = None, mean_episode_step = 1506.0, total_loss = 649.91, pg_loss = 309.17, baseline_loss = 345.91, entropy_loss = -5.1695, learner_queue_size = 32, _tick = 3435, _time = 1.6548e+09, train_seconds = 4945.8)
[2022-06-09 21:30:30,982][root][INFO] - Step 18549760 @ 3581.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 18549760, mean_episode_return = None, mean_episode_step = 1538.8, total_loss = 30.571, pg_loss = 10.63, baseline_loss = 25.432, entropy_loss = -5.4907, learner_queue_size = 32, _tick = 3438, _time = 1.6548e+09, train_seconds = 4950.8)
[2022-06-09 21:30:35,986][root][INFO] - Step 18567680 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 18567680, mean_episode_return = 57.412, mean_episode_step = 1581.1, total_loss = -2.689, pg_loss = -20.675, baseline_loss = 23.773, entropy_loss = -5.7862, learner_queue_size = 32, _tick = 3441, _time = 1.6548e+09, train_seconds = 4955.8)
[2022-06-09 21:30:40,990][root][INFO] - Step 18588160 @ 4092.7 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 18588160, mean_episode_return = None, mean_episode_step = 2095.2, total_loss = 0.76038, pg_loss = -29.227, baseline_loss = 35.37, entropy_loss = -5.3832, learner_queue_size = 32, _tick = 3447, _time = 1.6548e+09, train_seconds = 4960.8)
[2022-06-09 21:30:45,994][root][INFO] - Step 18606080 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 18606080, mean_episode_return = None, mean_episode_step = 1805.4, total_loss = 57.655, pg_loss = 36.893, baseline_loss = 26.113, entropy_loss = -5.3506, learner_queue_size = 32, _tick = 3452, _time = 1.6548e+09, train_seconds = 4965.8)
[2022-06-09 21:30:50,998][root][INFO] - Step 18624000 @ 3581.2 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (step = 18624000, mean_episode_return = 19.7, mean_episode_step = 1862.7, total_loss = -139.87, pg_loss = -140.68, baseline_loss = 6.5314, entropy_loss = -5.7167, learner_queue_size = 32, _tick = 3456, _time = 1.6548e+09, train_seconds = 4970.8)
[2022-06-09 21:30:56,002][root][INFO] - Step 18644480 @ 4092.6 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 18644480, mean_episode_return = None, mean_episode_step = 1862.1, total_loss = 21.772, pg_loss = 6.6723, baseline_loss = 21.205, entropy_loss = -6.1053, learner_queue_size = 32, _tick = 3460, _time = 1.6548e+09, train_seconds = 4975.8)
[2022-06-09 21:31:01,006][root][INFO] - Step 18662400 @ 3581.2 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 18662400, mean_episode_return = None, mean_episode_step = 2048.9, total_loss = 0.87185, pg_loss = -1.1527, baseline_loss = 7.5794, entropy_loss = -5.5549, learner_queue_size = 32, _tick = 3462, _time = 1.6548e+09, train_seconds = 4980.8)
[2022-06-09 21:31:06,010][root][INFO] - Step 18682880 @ 4092.7 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 18682880, mean_episode_return = None, mean_episode_step = 1944.9, total_loss = 208.22, pg_loss = 164.31, baseline_loss = 49.359, entropy_loss = -5.4502, learner_queue_size = 32, _tick = 3465, _time = 1.6548e+09, train_seconds = 4985.8)
[2022-06-09 21:31:11,014][root][INFO] - Step 18700800 @ 3581.0 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 18700800, mean_episode_return = 69.451, mean_episode_step = 1886.4, total_loss = 108.38, pg_loss = 61.532, baseline_loss = 51.924, entropy_loss = -5.0796, learner_queue_size = 32, _tick = 3471, _time = 1.6548e+09, train_seconds = 4990.8)
[2022-06-09 21:31:16,018][root][INFO] - Step 18718720 @ 3581.3 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 18718720, mean_episode_return = 9.2199, mean_episode_step = 1564.9, total_loss = -109.93, pg_loss = -114.09, baseline_loss = 9.5164, entropy_loss = -5.3577, learner_queue_size = 32, _tick = 3475, _time = 1.6548e+09, train_seconds = 4995.8)
[2022-06-09 21:31:21,022][root][INFO] - Step 18736640 @ 3581.1 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 18736640, mean_episode_return = 15.735, mean_episode_step = 1747.1, total_loss = 158.2, pg_loss = 103.19, baseline_loss = 60.439, entropy_loss = -5.4288, learner_queue_size = 32, _tick = 3482, _time = 1.6548e+09, train_seconds = 5000.8)
[2022-06-09 21:31:26,026][root][INFO] - Step 18757120 @ 4092.7 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (step = 18757120, mean_episode_return = 88.019, mean_episode_step = 1962.5, total_loss = -134.85, pg_loss = -133.47, baseline_loss = 4.2791, entropy_loss = -5.6497, learner_queue_size = 32, _tick = 3488, _time = 1.6548e+09, train_seconds = 5005.8)
[2022-06-09 21:31:31,032][root][INFO] - Step 18775040 @ 3579.4 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 18775040, mean_episode_return = 31.615, mean_episode_step = 1653.6, total_loss = 232.97, pg_loss = 171.14, baseline_loss = 67.229, entropy_loss = -5.3951, learner_queue_size = 32, _tick = 3495, _time = 1.6548e+09, train_seconds = 5010.8)
[2022-06-09 21:31:36,038][root][INFO] - Step 18795520 @ 4091.0 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 18795520, mean_episode_return = -9.2301, mean_episode_step = 1804.6, total_loss = 44.601, pg_loss = 15.568, baseline_loss = 33.779, entropy_loss = -4.7461, learner_queue_size = 32, _tick = 3501, _time = 1.6548e+09, train_seconds = 5015.8)
[2022-06-09 21:31:41,042][root][INFO] - Step 18813440 @ 3581.5 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 18813440, mean_episode_return = 66.28, mean_episode_step = 1850.0, total_loss = 77.454, pg_loss = 23.092, baseline_loss = 59.279, entropy_loss = -4.9168, learner_queue_size = 32, _tick = 3506, _time = 1.6548e+09, train_seconds = 5020.8)
[2022-06-09 21:31:46,046][root][INFO] - Step 18833920 @ 4092.2 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 18833920, mean_episode_return = 51.772, mean_episode_step = 2117.8, total_loss = -28.358, pg_loss = -31.893, baseline_loss = 9.2841, entropy_loss = -5.7495, learner_queue_size = 32, _tick = 3511, _time = 1.6548e+09, train_seconds = 5025.9)
[2022-06-09 21:31:51,050][root][INFO] - Step 18851840 @ 3581.5 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 18851840, mean_episode_return = 6.3796, mean_episode_step = 1267.0, total_loss = -0.98961, pg_loss = -24.426, baseline_loss = 29.051, entropy_loss = -5.6152, learner_queue_size = 32, _tick = 3514, _time = 1.6548e+09, train_seconds = 5030.9)
[2022-06-09 21:31:56,054][root][INFO] - Step 18869760 @ 3581.2 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 18869760, mean_episode_return = 86.487, mean_episode_step = 1814.3, total_loss = -33.518, pg_loss = -50.1, baseline_loss = 22.239, entropy_loss = -5.6559, learner_queue_size = 32, _tick = 3520, _time = 1.6548e+09, train_seconds = 5035.9)
[2022-06-09 21:32:01,058][root][INFO] - Step 18890240 @ 4092.7 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 18890240, mean_episode_return = None, mean_episode_step = 1828.2, total_loss = 149.64, pg_loss = 106.41, baseline_loss = 48.693, entropy_loss = -5.4701, learner_queue_size = 32, _tick = 3527, _time = 1.6548e+09, train_seconds = 5040.9)
[2022-06-09 21:32:06,062][root][INFO] - Step 18908160 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 18908160, mean_episode_return = 30.689, mean_episode_step = 1677.1, total_loss = 234.71, pg_loss = 141.12, baseline_loss = 98.884, entropy_loss = -5.3034, learner_queue_size = 32, _tick = 3531, _time = 1.6548e+09, train_seconds = 5045.9)
[2022-06-09 21:32:11,066][root][INFO] - Step 18928640 @ 4092.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 18928640, mean_episode_return = None, mean_episode_step = 2070.4, total_loss = 280.0, pg_loss = 189.3, baseline_loss = 95.329, entropy_loss = -4.6223, learner_queue_size = 32, _tick = 3535, _time = 1.6548e+09, train_seconds = 5050.9)
[2022-06-09 21:32:16,070][root][INFO] - Step 18946560 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 18946560, mean_episode_return = 65.26, mean_episode_step = 1518.4, total_loss = -111.49, pg_loss = -120.34, baseline_loss = 13.916, entropy_loss = -5.0589, learner_queue_size = 32, _tick = 3539, _time = 1.6548e+09, train_seconds = 5055.9)
[2022-06-09 21:32:21,074][root][INFO] - Step 18967040 @ 4092.7 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (step = 18967040, mean_episode_return = None, mean_episode_step = 1242.2, total_loss = 281.92, pg_loss = 182.77, baseline_loss = 103.93, entropy_loss = -4.7738, learner_queue_size = 32, _tick = 3544, _time = 1.6548e+09, train_seconds = 5060.9)
[2022-06-09 21:32:26,078][root][INFO] - Step 18984960 @ 3581.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 18984960, mean_episode_return = None, mean_episode_step = 1677.9, total_loss = -42.546, pg_loss = -61.875, baseline_loss = 24.066, entropy_loss = -4.7365, learner_queue_size = 32, _tick = 3547, _time = 1.6548e+09, train_seconds = 5065.9)
[2022-06-09 21:32:31,082][root][INFO] - Step 19002880 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 19002880, mean_episode_return = 95.644, mean_episode_step = 1499.9, total_loss = -172.33, pg_loss = -195.28, baseline_loss = 27.582, entropy_loss = -4.6365, learner_queue_size = 32, _tick = 3552, _time = 1.6548e+09, train_seconds = 5070.9)
[2022-06-09 21:32:36,086][root][INFO] - Step 19020800 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 19020800, mean_episode_return = None, mean_episode_step = 1821.5, total_loss = -29.402, pg_loss = -57.486, baseline_loss = 32.923, entropy_loss = -4.8384, learner_queue_size = 32, _tick = 3555, _time = 1.6548e+09, train_seconds = 5075.9)
[2022-06-09 21:32:41,090][root][INFO] - Step 19041280 @ 4092.8 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 19041280, mean_episode_return = None, mean_episode_step = 2076.7, total_loss = -125.7, pg_loss = -135.21, baseline_loss = 14.677, entropy_loss = -5.1657, learner_queue_size = 32, _tick = 3558, _time = 1.6548e+09, train_seconds = 5080.9)
[2022-06-09 21:32:46,094][root][INFO] - Step 19059200 @ 3581.1 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 19059200, mean_episode_return = 47.093, mean_episode_step = 1903.9, total_loss = 81.075, pg_loss = 12.129, baseline_loss = 74.549, entropy_loss = -5.6026, learner_queue_size = 32, _tick = 3563, _time = 1.6548e+09, train_seconds = 5085.9)
[2022-06-09 21:32:51,098][root][INFO] - Step 19077120 @ 3581.2 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 19077120, mean_episode_return = 101.09, mean_episode_step = 1327.5, total_loss = 92.49, pg_loss = 48.514, baseline_loss = 49.815, entropy_loss = -5.8387, learner_queue_size = 32, _tick = 3566, _time = 1.6548e+09, train_seconds = 5090.9)
[2022-06-09 21:32:56,102][root][INFO] - Step 19097600 @ 4092.5 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 19097600, mean_episode_return = 35.992, mean_episode_step = 1817.9, total_loss = 95.925, pg_loss = 55.056, baseline_loss = 46.623, entropy_loss = -5.7541, learner_queue_size = 32, _tick = 3571, _time = 1.6548e+09, train_seconds = 5095.9)
[2022-06-09 21:33:01,106][root][INFO] - Step 19115520 @ 3581.2 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 19115520, mean_episode_return = 18.59, mean_episode_step = 1406.3, total_loss = 222.81, pg_loss = 122.29, baseline_loss = 106.14, entropy_loss = -5.6097, learner_queue_size = 32, _tick = 3575, _time = 1.6548e+09, train_seconds = 5100.9)
[2022-06-09 21:33:06,110][root][INFO] - Step 19136000 @ 4092.8 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 19136000, mean_episode_return = None, mean_episode_step = 1490.1, total_loss = 367.03, pg_loss = 278.32, baseline_loss = 94.541, entropy_loss = -5.8228, learner_queue_size = 32, _tick = 3582, _time = 1.6548e+09, train_seconds = 5105.9)
[2022-06-09 21:33:11,114][root][INFO] - Step 19153920 @ 3581.2 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 19153920, mean_episode_return = 21.59, mean_episode_step = 1720.4, total_loss = 22.29, pg_loss = -11.76, baseline_loss = 39.705, entropy_loss = -5.655, learner_queue_size = 32, _tick = 3587, _time = 1.6548e+09, train_seconds = 5110.9)
[2022-06-09 21:33:16,118][root][INFO] - Step 19171840 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 19171840, mean_episode_return = 34.101, mean_episode_step = 1372.8, total_loss = 111.89, pg_loss = 52.231, baseline_loss = 65.052, entropy_loss = -5.394, learner_queue_size = 32, _tick = 3591, _time = 1.6548e+09, train_seconds = 5115.9)
[2022-06-09 21:33:21,122][root][INFO] - Step 19192320 @ 4092.6 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 19192320, mean_episode_return = -53.877, mean_episode_step = 1713.1, total_loss = -4.5792, pg_loss = -42.634, baseline_loss = 43.058, entropy_loss = -5.0033, learner_queue_size = 32, _tick = 3596, _time = 1.6548e+09, train_seconds = 5120.9)
[2022-06-09 21:33:26,126][root][INFO] - Step 19210240 @ 3581.2 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 19210240, mean_episode_return = None, mean_episode_step = 1911.6, total_loss = 194.51, pg_loss = 104.53, baseline_loss = 95.195, entropy_loss = -5.2107, learner_queue_size = 32, _tick = 3600, _time = 1.6548e+09, train_seconds = 5125.9)
[2022-06-09 21:33:31,130][root][INFO] - Step 19228160 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 19228160, mean_episode_return = 25.699, mean_episode_step = 1862.0, total_loss = 362.63, pg_loss = 240.44, baseline_loss = 127.66, entropy_loss = -5.4665, learner_queue_size = 32, _tick = 3603, _time = 1.6548e+09, train_seconds = 5130.9)
[2022-06-09 21:33:36,134][root][INFO] - Step 19248640 @ 4092.7 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 19248640, mean_episode_return = 20.3, mean_episode_step = 1837.0, total_loss = 273.23, pg_loss = 164.11, baseline_loss = 114.44, entropy_loss = -5.309, learner_queue_size = 32, _tick = 3604, _time = 1.6548e+09, train_seconds = 5135.9)
[2022-06-09 21:33:41,138][root][INFO] - Step 19266560 @ 3581.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 19266560, mean_episode_return = 38.21, mean_episode_step = 1633.2, total_loss = -113.13, pg_loss = -113.31, baseline_loss = 5.5813, entropy_loss = -5.4053, learner_queue_size = 32, _tick = 3610, _time = 1.6548e+09, train_seconds = 5140.9)
[2022-06-09 21:33:46,142][root][INFO] - Step 19284480 @ 3581.1 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 19284480, mean_episode_return = None, mean_episode_step = 2200.4, total_loss = 175.33, pg_loss = 124.23, baseline_loss = 56.848, entropy_loss = -5.7474, learner_queue_size = 32, _tick = 3614, _time = 1.6548e+09, train_seconds = 5145.9)
[2022-06-09 21:33:51,147][root][INFO] - Step 19304960 @ 4091.8 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 19304960, mean_episode_return = None, mean_episode_step = 2310.4, total_loss = 148.93, pg_loss = 106.99, baseline_loss = 47.399, entropy_loss = -5.4643, learner_queue_size = 32, _tick = 3619, _time = 1.6548e+09, train_seconds = 5151.0)
[2022-06-09 21:33:56,150][root][INFO] - Step 19322880 @ 3581.9 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (step = 19322880, mean_episode_return = None, mean_episode_step = 2295.0, total_loss = -45.481, pg_loss = -57.466, baseline_loss = 17.303, entropy_loss = -5.3183, learner_queue_size = 32, _tick = 3624, _time = 1.6548e+09, train_seconds = 5156.0)
[2022-06-09 21:34:01,154][root][INFO] - Step 19340800 @ 3581.2 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 19340800, mean_episode_return = 53.68, mean_episode_step = 1852.4, total_loss = 311.54, pg_loss = 204.98, baseline_loss = 111.7, entropy_loss = -5.1393, learner_queue_size = 32, _tick = 3628, _time = 1.6548e+09, train_seconds = 5161.0)
[2022-06-09 21:34:06,158][root][INFO] - Step 19361280 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 19361280, mean_episode_return = -3.7904, mean_episode_step = 2063.2, total_loss = 111.04, pg_loss = 54.305, baseline_loss = 61.896, entropy_loss = -5.1589, learner_queue_size = 32, _tick = 3632, _time = 1.6548e+09, train_seconds = 5166.0)
[2022-06-09 21:34:11,162][root][INFO] - Step 19379200 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 19379200, mean_episode_return = None, mean_episode_step = 1772.1, total_loss = -58.965, pg_loss = -55.546, baseline_loss = 2.2599, entropy_loss = -5.6793, learner_queue_size = 32, _tick = 3633, _time = 1.6548e+09, train_seconds = 5171.0)
[2022-06-09 21:34:16,167][root][INFO] - Step 19399680 @ 4091.7 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 19399680, mean_episode_return = 48.232, mean_episode_step = 2408.4, total_loss = -107.0, pg_loss = -104.59, baseline_loss = 3.0394, entropy_loss = -5.442, learner_queue_size = 32, _tick = 3637, _time = 1.6548e+09, train_seconds = 5176.0)
[2022-06-09 21:34:21,170][root][INFO] - Step 19417600 @ 3582.0 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 19417600, mean_episode_return = 26.156, mean_episode_step = 1919.1, total_loss = 341.89, pg_loss = 190.68, baseline_loss = 156.33, entropy_loss = -5.1151, learner_queue_size = 32, _tick = 3643, _time = 1.6548e+09, train_seconds = 5181.0)
[2022-06-09 21:34:26,174][root][INFO] - Step 19435520 @ 3581.1 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (step = 19435520, mean_episode_return = 10.46, mean_episode_step = 1659.6, total_loss = 14.723, pg_loss = 0.46704, baseline_loss = 19.925, entropy_loss = -5.6693, learner_queue_size = 32, _tick = 3647, _time = 1.6548e+09, train_seconds = 5186.0)
[2022-06-09 21:34:31,178][root][INFO] - Step 19456000 @ 4092.6 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 19456000, mean_episode_return = 21.54, mean_episode_step = 2039.8, total_loss = 102.86, pg_loss = 57.378, baseline_loss = 51.179, entropy_loss = -5.6952, learner_queue_size = 32, _tick = 3654, _time = 1.6548e+09, train_seconds = 5191.0)
[2022-06-09 21:34:36,182][root][INFO] - Step 19473920 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 19473920, mean_episode_return = 102.81, mean_episode_step = 2523.3, total_loss = 75.59, pg_loss = 28.598, baseline_loss = 52.013, entropy_loss = -5.0214, learner_queue_size = 32, _tick = 3657, _time = 1.6548e+09, train_seconds = 5196.0)
[2022-06-09 21:34:41,186][root][INFO] - Step 19491840 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 19491840, mean_episode_return = -2.4803, mean_episode_step = 2192.8, total_loss = -21.366, pg_loss = -61.307, baseline_loss = 44.662, entropy_loss = -4.7209, learner_queue_size = 32, _tick = 3660, _time = 1.6548e+09, train_seconds = 5201.0)
[2022-06-09 21:34:46,190][root][INFO] - Step 19512320 @ 4092.8 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 19512320, mean_episode_return = None, mean_episode_step = 1721.1, total_loss = 102.02, pg_loss = 59.129, baseline_loss = 47.879, entropy_loss = -4.9928, learner_queue_size = 32, _tick = 3663, _time = 1.6548e+09, train_seconds = 5206.0)
[2022-06-09 21:34:51,194][root][INFO] - Step 19530240 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 19530240, mean_episode_return = None, mean_episode_step = 2049.2, total_loss = 239.26, pg_loss = 182.55, baseline_loss = 61.642, entropy_loss = -4.9238, learner_queue_size = 32, _tick = 3664, _time = 1.6548e+09, train_seconds = 5211.0)
[2022-06-09 21:34:56,198][root][INFO] - Step 19550720 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 19550720, mean_episode_return = 33.769, mean_episode_step = 1942.3, total_loss = 0.8044, pg_loss = -34.049, baseline_loss = 40.15, entropy_loss = -5.2961, learner_queue_size = 32, _tick = 3667, _time = 1.6548e+09, train_seconds = 5216.0)
[2022-06-09 21:35:01,202][root][INFO] - Step 19568640 @ 3581.2 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 19568640, mean_episode_return = 58.274, mean_episode_step = 1697.5, total_loss = 127.96, pg_loss = 99.252, baseline_loss = 34.758, entropy_loss = -6.0494, learner_queue_size = 32, _tick = 3674, _time = 1.6548e+09, train_seconds = 5221.0)
[2022-06-09 21:35:06,206][root][INFO] - Step 19589120 @ 4092.7 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 19589120, mean_episode_return = None, mean_episode_step = 2155.8, total_loss = 13.933, pg_loss = -2.4968, baseline_loss = 21.033, entropy_loss = -4.6032, learner_queue_size = 32, _tick = 3680, _time = 1.6548e+09, train_seconds = 5226.0)
[2022-06-09 21:35:11,210][root][INFO] - Step 19607040 @ 3581.2 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 19607040, mean_episode_return = 32.053, mean_episode_step = 1807.7, total_loss = -69.796, pg_loss = -104.53, baseline_loss = 39.179, entropy_loss = -4.4401, learner_queue_size = 32, _tick = 3686, _time = 1.6548e+09, train_seconds = 5231.0)
[2022-06-09 21:35:16,214][root][INFO] - Step 19624960 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 19624960, mean_episode_return = None, mean_episode_step = 2034.3, total_loss = 62.778, pg_loss = 28.217, baseline_loss = 39.788, entropy_loss = -5.2267, learner_queue_size = 32, _tick = 3689, _time = 1.6548e+09, train_seconds = 5236.0)
[2022-06-09 21:35:21,219][root][INFO] - Step 19645440 @ 4091.8 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 19645440, mean_episode_return = 78.549, mean_episode_step = 2172.4, total_loss = -37.833, pg_loss = -45.216, baseline_loss = 12.201, entropy_loss = -4.8177, learner_queue_size = 32, _tick = 3693, _time = 1.6548e+09, train_seconds = 5241.0)
[2022-06-09 21:35:26,222][root][INFO] - Step 19663360 @ 3581.9 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 19663360, mean_episode_return = 32.58, mean_episode_step = 1807.8, total_loss = -168.7, pg_loss = -173.88, baseline_loss = 10.127, entropy_loss = -4.9413, learner_queue_size = 32, _tick = 3700, _time = 1.6548e+09, train_seconds = 5246.0)
[2022-06-09 21:35:31,226][root][INFO] - Step 19683840 @ 4092.8 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 19683840, mean_episode_return = 69.719, mean_episode_step = 1850.5, total_loss = -55.469, pg_loss = -61.66, baseline_loss = 11.615, entropy_loss = -5.4241, learner_queue_size = 32, _tick = 3705, _time = 1.6548e+09, train_seconds = 5251.0)
[2022-06-09 21:35:36,230][root][INFO] - Step 19701760 @ 3581.2 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 19701760, mean_episode_return = 73.103, mean_episode_step = 1743.9, total_loss = 159.78, pg_loss = 97.918, baseline_loss = 66.882, entropy_loss = -5.0227, learner_queue_size = 32, _tick = 3710, _time = 1.6548e+09, train_seconds = 5256.0)
[2022-06-09 21:35:41,234][root][INFO] - Step 19722240 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 19722240, mean_episode_return = 25.222, mean_episode_step = 1626.6, total_loss = -24.222, pg_loss = -33.994, baseline_loss = 14.181, entropy_loss = -4.4086, learner_queue_size = 32, _tick = 3714, _time = 1.6548e+09, train_seconds = 5261.0)
[2022-06-09 21:35:46,238][root][INFO] - Step 19740160 @ 3581.2 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 19740160, mean_episode_return = 87.919, mean_episode_step = 1793.0, total_loss = 34.014, pg_loss = 12.797, baseline_loss = 26.154, entropy_loss = -4.938, learner_queue_size = 32, _tick = 3717, _time = 1.6548e+09, train_seconds = 5266.0)
[2022-06-09 21:35:51,242][root][INFO] - Step 19760640 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 19760640, mean_episode_return = None, mean_episode_step = 1418.1, total_loss = 44.306, pg_loss = 11.513, baseline_loss = 36.951, entropy_loss = -4.1572, learner_queue_size = 32, _tick = 3723, _time = 1.6548e+09, train_seconds = 5271.0)
[2022-06-09 21:35:56,247][root][INFO] - Step 19778560 @ 3580.8 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 19778560, mean_episode_return = 19.109, mean_episode_step = 1330.9, total_loss = 192.37, pg_loss = 109.3, baseline_loss = 86.38, entropy_loss = -3.3014, learner_queue_size = 32, _tick = 3727, _time = 1.6548e+09, train_seconds = 5276.1)
[2022-06-09 21:36:01,250][root][INFO] - Step 19796480 @ 3581.4 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 19796480, mean_episode_return = 48.511, mean_episode_step = 1565.8, total_loss = -93.045, pg_loss = -97.68, baseline_loss = 9.1265, entropy_loss = -4.4915, learner_queue_size = 32, _tick = 3732, _time = 1.6548e+09, train_seconds = 5281.1)
[2022-06-09 21:36:06,254][root][INFO] - Step 19814400 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 19814400, mean_episode_return = -4.2204, mean_episode_step = 1832.1, total_loss = 54.234, pg_loss = 32.428, baseline_loss = 27.394, entropy_loss = -5.5881, learner_queue_size = 32, _tick = 3738, _time = 1.6548e+09, train_seconds = 5286.1)
[2022-06-09 21:36:11,258][root][INFO] - Step 19834880 @ 4092.8 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 19834880, mean_episode_return = None, mean_episode_step = 1875.8, total_loss = 15.273, pg_loss = 6.7338, baseline_loss = 13.264, entropy_loss = -4.7245, learner_queue_size = 32, _tick = 3741, _time = 1.6548e+09, train_seconds = 5291.1)
[2022-06-09 21:36:16,262][root][INFO] - Step 19852800 @ 3581.2 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 19852800, mean_episode_return = 59.632, mean_episode_step = 1446.3, total_loss = -129.71, pg_loss = -129.92, baseline_loss = 4.7408, entropy_loss = -4.5363, learner_queue_size = 32, _tick = 3747, _time = 1.6548e+09, train_seconds = 5296.1)
[2022-06-09 21:36:21,266][root][INFO] - Step 19870720 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 19870720, mean_episode_return = None, mean_episode_step = 1643.6, total_loss = 396.46, pg_loss = 277.64, baseline_loss = 123.23, entropy_loss = -4.4098, learner_queue_size = 32, _tick = 3750, _time = 1.6548e+09, train_seconds = 5301.1)
[2022-06-09 21:36:26,270][root][INFO] - Step 19891200 @ 4092.7 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 19891200, mean_episode_return = 83.3, mean_episode_step = 1416.8, total_loss = 52.362, pg_loss = -18.791, baseline_loss = 75.378, entropy_loss = -4.2254, learner_queue_size = 32, _tick = 3755, _time = 1.6548e+09, train_seconds = 5306.1)
[2022-06-09 21:36:31,277][root][INFO] - Step 19909120 @ 3578.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 19909120, mean_episode_return = 32.13, mean_episode_step = 1482.9, total_loss = -175.43, pg_loss = -194.09, baseline_loss = 22.73, entropy_loss = -4.0795, learner_queue_size = 32, _tick = 3758, _time = 1.6548e+09, train_seconds = 5311.1)
[2022-06-09 21:36:36,282][root][INFO] - Step 19929600 @ 4092.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 19929600, mean_episode_return = 48.022, mean_episode_step = 2126.5, total_loss = 39.041, pg_loss = 0.21287, baseline_loss = 43.492, entropy_loss = -4.6636, learner_queue_size = 32, _tick = 3764, _time = 1.6548e+09, train_seconds = 5316.1)
[2022-06-09 21:36:41,286][root][INFO] - Step 19947520 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 19947520, mean_episode_return = 65.439, mean_episode_step = 1602.8, total_loss = 29.957, pg_loss = 6.0401, baseline_loss = 28.58, entropy_loss = -4.6631, learner_queue_size = 32, _tick = 3768, _time = 1.6548e+09, train_seconds = 5321.1)
[2022-06-09 21:36:46,290][root][INFO] - Step 19965440 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 19965440, mean_episode_return = 60.905, mean_episode_step = 2131.8, total_loss = 162.79, pg_loss = 8.9994, baseline_loss = 158.21, entropy_loss = -4.4236, learner_queue_size = 32, _tick = 3774, _time = 1.6548e+09, train_seconds = 5326.1)
[2022-06-09 21:36:51,294][root][INFO] - Step 19985920 @ 4092.8 SPS. Inference batcher size: 90. Learner queue size: 32. Other stats: (step = 19985920, mean_episode_return = 51.191, mean_episode_step = 1495.5, total_loss = -45.021, pg_loss = -64.513, baseline_loss = 24.07, entropy_loss = -4.5789, learner_queue_size = 32, _tick = 3779, _time = 1.6548e+09, train_seconds = 5331.1)
[2022-06-09 21:36:56,300][root][INFO] - Step 20003840 @ 3579.8 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 20003840, mean_episode_return = 0.28968, mean_episode_step = 1575.7, total_loss = -126.77, pg_loss = -133.94, baseline_loss = 11.799, entropy_loss = -4.6307, learner_queue_size = 32, _tick = 3782, _time = 1.6548e+09, train_seconds = 5336.1)
[2022-06-09 21:37:01,302][root][INFO] - Step 20021760 @ 3582.4 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 20021760, mean_episode_return = None, mean_episode_step = 1461.1, total_loss = 117.79, pg_loss = 75.019, baseline_loss = 47.785, entropy_loss = -5.0155, learner_queue_size = 32, _tick = 3785, _time = 1.6548e+09, train_seconds = 5341.1)
[2022-06-09 21:37:06,306][root][INFO] - Step 20042240 @ 4092.7 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 20042240, mean_episode_return = 39.111, mean_episode_step = 1747.3, total_loss = 15.248, pg_loss = -43.533, baseline_loss = 63.71, entropy_loss = -4.9288, learner_queue_size = 32, _tick = 3792, _time = 1.6548e+09, train_seconds = 5346.1)
[2022-06-09 21:37:11,314][root][INFO] - Step 20060160 @ 3578.2 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 20060160, mean_episode_return = None, mean_episode_step = 1728.5, total_loss = 284.06, pg_loss = 191.39, baseline_loss = 97.838, entropy_loss = -5.1646, learner_queue_size = 32, _tick = 3795, _time = 1.6548e+09, train_seconds = 5351.1)
[2022-06-09 21:37:16,318][root][INFO] - Step 20078080 @ 3581.2 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 20078080, mean_episode_return = None, mean_episode_step = 1836.0, total_loss = -66.8, pg_loss = -72.441, baseline_loss = 10.562, entropy_loss = -4.9208, learner_queue_size = 32, _tick = 3800, _time = 1.6548e+09, train_seconds = 5356.1)
[2022-06-09 21:37:21,322][root][INFO] - Step 20096000 @ 3581.3 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (step = 20096000, mean_episode_return = 46.083, mean_episode_step = 1786.7, total_loss = 84.533, pg_loss = 32.476, baseline_loss = 57.154, entropy_loss = -5.0975, learner_queue_size = 32, _tick = 3805, _time = 1.6548e+09, train_seconds = 5361.1)
[2022-06-09 21:37:26,326][root][INFO] - Step 20116480 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 20116480, mean_episode_return = 100.56, mean_episode_step = 1909.6, total_loss = -47.063, pg_loss = -86.858, baseline_loss = 45.067, entropy_loss = -5.2718, learner_queue_size = 32, _tick = 3810, _time = 1.6548e+09, train_seconds = 5366.1)
[2022-06-09 21:37:31,330][root][INFO] - Step 20134400 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 20134400, mean_episode_return = 39.031, mean_episode_step = 1626.4, total_loss = 306.42, pg_loss = 231.15, baseline_loss = 80.815, entropy_loss = -5.5403, learner_queue_size = 32, _tick = 3814, _time = 1.6548e+09, train_seconds = 5371.1)
[2022-06-09 21:37:36,334][root][INFO] - Step 20152320 @ 3581.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 20152320, mean_episode_return = 148.43, mean_episode_step = 1701.4, total_loss = -123.75, pg_loss = -135.12, baseline_loss = 16.748, entropy_loss = -5.3825, learner_queue_size = 32, _tick = 3820, _time = 1.6548e+09, train_seconds = 5376.1)
[2022-06-09 21:37:41,338][root][INFO] - Step 20170240 @ 3581.1 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (step = 20170240, mean_episode_return = 35.722, mean_episode_step = 2221.1, total_loss = 59.477, pg_loss = 5.6421, baseline_loss = 59.253, entropy_loss = -5.4179, learner_queue_size = 32, _tick = 3823, _time = 1.6548e+09, train_seconds = 5381.1)
[2022-06-09 21:37:46,342][root][INFO] - Step 20190720 @ 4092.7 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 20190720, mean_episode_return = 76.387, mean_episode_step = 1588.3, total_loss = 166.78, pg_loss = 84.11, baseline_loss = 87.829, entropy_loss = -5.158, learner_queue_size = 32, _tick = 3829, _time = 1.6548e+09, train_seconds = 5386.1)
[2022-06-09 21:37:51,346][root][INFO] - Step 20208640 @ 3581.1 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (step = 20208640, mean_episode_return = None, mean_episode_step = 1758.2, total_loss = 424.2, pg_loss = 247.65, baseline_loss = 181.58, entropy_loss = -5.041, learner_queue_size = 32, _tick = 3832, _time = 1.6548e+09, train_seconds = 5391.2)
[2022-06-09 21:37:56,350][root][INFO] - Step 20226560 @ 3581.1 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 20226560, mean_episode_return = 67.337, mean_episode_step = 2126.7, total_loss = -213.69, pg_loss = -256.4, baseline_loss = 47.607, entropy_loss = -4.8968, learner_queue_size = 32, _tick = 3836, _time = 1.6548e+09, train_seconds = 5396.2)
[2022-06-09 21:38:01,354][root][INFO] - Step 20247040 @ 4092.6 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 20247040, mean_episode_return = -8.2701, mean_episode_step = 1693.6, total_loss = -43.659, pg_loss = -47.351, baseline_loss = 8.7862, entropy_loss = -5.0941, learner_queue_size = 32, _tick = 3843, _time = 1.6548e+09, train_seconds = 5401.2)
[2022-06-09 21:38:06,362][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-09 21:38:06,657][root][INFO] - Step 20264960 @ 3578.3 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 20267520, mean_episode_return = None, mean_episode_step = 1855.6, total_loss = 84.048, pg_loss = 48.568, baseline_loss = 40.726, entropy_loss = -5.246, learner_queue_size = 32, _tick = 3848, _time = 1.6548e+09, train_seconds = 5406.2)
[2022-06-09 21:38:11,662][root][INFO] - Step 20285440 @ 3864.2 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 20285440, mean_episode_return = None, mean_episode_step = 1913.1, total_loss = 403.52, pg_loss = 291.22, baseline_loss = 117.56, entropy_loss = -5.2558, learner_queue_size = 32, _tick = 3853, _time = 1.6548e+09, train_seconds = 5411.5)
[2022-06-09 21:38:16,666][root][INFO] - Step 20303360 @ 3581.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 20303360, mean_episode_return = 53.9, mean_episode_step = 2118.5, total_loss = -14.65, pg_loss = -47.696, baseline_loss = 37.841, entropy_loss = -4.7948, learner_queue_size = 32, _tick = 3859, _time = 1.6548e+09, train_seconds = 5416.5)
[2022-06-09 21:38:21,670][root][INFO] - Step 20323840 @ 4092.8 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 20323840, mean_episode_return = None, mean_episode_step = 1757.6, total_loss = 287.95, pg_loss = 197.74, baseline_loss = 95.346, entropy_loss = -5.1364, learner_queue_size = 32, _tick = 3863, _time = 1.6548e+09, train_seconds = 5421.5)
[2022-06-09 21:38:26,674][root][INFO] - Step 20341760 @ 3581.2 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 20341760, mean_episode_return = None, mean_episode_step = 1832.0, total_loss = 18.466, pg_loss = -7.1187, baseline_loss = 30.457, entropy_loss = -4.8724, learner_queue_size = 32, _tick = 3868, _time = 1.6548e+09, train_seconds = 5426.5)
[2022-06-09 21:38:31,678][root][INFO] - Step 20362240 @ 4092.7 SPS. Inference batcher size: 80. Learner queue size: 32. Other stats: (step = 20362240, mean_episode_return = 35.9, mean_episode_step = 1820.1, total_loss = -83.366, pg_loss = -87.492, baseline_loss = 9.4499, entropy_loss = -5.3238, learner_queue_size = 32, _tick = 3873, _time = 1.6548e+09, train_seconds = 5431.5)
[2022-06-09 21:38:36,682][root][INFO] - Step 20380160 @ 3581.1 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 20380160, mean_episode_return = None, mean_episode_step = 1891.4, total_loss = 19.443, pg_loss = 8.5624, baseline_loss = 16.155, entropy_loss = -5.2749, learner_queue_size = 32, _tick = 3876, _time = 1.6548e+09, train_seconds = 5436.5)
[2022-06-09 21:38:41,686][root][INFO] - Step 20398080 @ 3581.2 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 20398080, mean_episode_return = None, mean_episode_step = 1860.5, total_loss = -55.289, pg_loss = -57.228, baseline_loss = 6.989, entropy_loss = -5.0497, learner_queue_size = 32, _tick = 3880, _time = 1.6548e+09, train_seconds = 5441.5)
[2022-06-09 21:38:46,690][root][INFO] - Step 20416000 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 20416000, mean_episode_return = None, mean_episode_step = 1828.0, total_loss = 73.56, pg_loss = 40.36, baseline_loss = 38.505, entropy_loss = -5.3053, learner_queue_size = 32, _tick = 3885, _time = 1.6548e+09, train_seconds = 5446.5)
[2022-06-09 21:38:51,694][root][INFO] - Step 20436480 @ 4092.7 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 20436480, mean_episode_return = None, mean_episode_step = 1825.3, total_loss = -8.9547, pg_loss = -14.478, baseline_loss = 10.246, entropy_loss = -4.7225, learner_queue_size = 32, _tick = 3891, _time = 1.6548e+09, train_seconds = 5451.5)
[2022-06-09 21:38:56,698][root][INFO] - Step 20454400 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 20454400, mean_episode_return = None, mean_episode_step = 2111.7, total_loss = 41.944, pg_loss = 21.168, baseline_loss = 25.375, entropy_loss = -4.5984, learner_queue_size = 32, _tick = 3894, _time = 1.6548e+09, train_seconds = 5456.5)
[2022-06-09 21:39:01,702][root][INFO] - Step 20472320 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 20472320, mean_episode_return = 61.052, mean_episode_step = 2149.8, total_loss = 107.7, pg_loss = 64.163, baseline_loss = 48.847, entropy_loss = -5.3048, learner_queue_size = 32, _tick = 3898, _time = 1.6548e+09, train_seconds = 5461.5)
[2022-06-09 21:39:06,706][root][INFO] - Step 20492800 @ 4092.8 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 20492800, mean_episode_return = 70.119, mean_episode_step = 1566.7, total_loss = 3.9846, pg_loss = -33.217, baseline_loss = 41.934, entropy_loss = -4.7326, learner_queue_size = 32, _tick = 3903, _time = 1.6548e+09, train_seconds = 5466.5)
[2022-06-09 21:39:11,711][root][INFO] - Step 20510720 @ 3580.7 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 20510720, mean_episode_return = 33.96, mean_episode_step = 1856.0, total_loss = -74.748, pg_loss = -83.927, baseline_loss = 14.577, entropy_loss = -5.3979, learner_queue_size = 32, _tick = 3909, _time = 1.6548e+09, train_seconds = 5471.5)
[2022-06-09 21:39:16,714][root][INFO] - Step 20531200 @ 4093.2 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 20531200, mean_episode_return = 64.48, mean_episode_step = 1503.8, total_loss = -37.501, pg_loss = -46.561, baseline_loss = 12.181, entropy_loss = -3.1212, learner_queue_size = 32, _tick = 3914, _time = 1.6548e+09, train_seconds = 5476.5)
[2022-06-09 21:39:21,718][root][INFO] - Step 20549120 @ 3581.1 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 20549120, mean_episode_return = None, mean_episode_step = 1389.3, total_loss = 42.863, pg_loss = 12.974, baseline_loss = 33.979, entropy_loss = -4.0899, learner_queue_size = 32, _tick = 3917, _time = 1.6548e+09, train_seconds = 5481.5)
[2022-06-09 21:39:26,722][root][INFO] - Step 20569600 @ 4092.7 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (step = 20569600, mean_episode_return = 3.42, mean_episode_step = 1857.6, total_loss = -54.57, pg_loss = -84.587, baseline_loss = 34.578, entropy_loss = -4.561, learner_queue_size = 32, _tick = 3921, _time = 1.6548e+09, train_seconds = 5486.5)
[2022-06-09 21:39:31,726][root][INFO] - Step 20587520 @ 3581.1 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 20587520, mean_episode_return = None, mean_episode_step = 1515.1, total_loss = 73.318, pg_loss = 40.356, baseline_loss = 37.808, entropy_loss = -4.8467, learner_queue_size = 32, _tick = 3922, _time = 1.6548e+09, train_seconds = 5491.5)
[2022-06-09 21:39:36,730][root][INFO] - Step 20605440 @ 3581.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 20605440, mean_episode_return = 36.36, mean_episode_step = 1573.1, total_loss = 169.03, pg_loss = 105.51, baseline_loss = 68.51, entropy_loss = -4.9907, learner_queue_size = 32, _tick = 3928, _time = 1.6548e+09, train_seconds = 5496.5)
[2022-06-09 21:39:41,734][root][INFO] - Step 20625920 @ 4092.7 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (step = 20625920, mean_episode_return = None, mean_episode_step = 1762.0, total_loss = 298.17, pg_loss = 217.65, baseline_loss = 85.357, entropy_loss = -4.8432, learner_queue_size = 32, _tick = 3935, _time = 1.6548e+09, train_seconds = 5501.5)
[2022-06-09 21:39:46,738][root][INFO] - Step 20643840 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 20643840, mean_episode_return = None, mean_episode_step = 1650.7, total_loss = -78.17, pg_loss = -78.447, baseline_loss = 4.8123, entropy_loss = -4.5351, learner_queue_size = 32, _tick = 3938, _time = 1.6548e+09, train_seconds = 5506.5)
[2022-06-09 21:39:51,742][root][INFO] - Step 20664320 @ 4092.7 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 20664320, mean_episode_return = None, mean_episode_step = 1906.0, total_loss = 73.539, pg_loss = 39.102, baseline_loss = 39.042, entropy_loss = -4.605, learner_queue_size = 32, _tick = 3943, _time = 1.6548e+09, train_seconds = 5511.5)
[2022-06-09 21:39:56,746][root][INFO] - Step 20682240 @ 3581.1 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 20682240, mean_episode_return = None, mean_episode_step = 1707.1, total_loss = 17.513, pg_loss = -23.471, baseline_loss = 45.772, entropy_loss = -4.7878, learner_queue_size = 32, _tick = 3946, _time = 1.6548e+09, train_seconds = 5516.6)
[2022-06-09 21:40:01,750][root][INFO] - Step 20700160 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 20700160, mean_episode_return = None, mean_episode_step = 1871.8, total_loss = 50.189, pg_loss = 9.5602, baseline_loss = 45.62, entropy_loss = -4.9915, learner_queue_size = 32, _tick = 3948, _time = 1.6548e+09, train_seconds = 5521.6)
[2022-06-09 21:40:06,754][root][INFO] - Step 20720640 @ 4092.7 SPS. Inference batcher size: 73. Learner queue size: 32. Other stats: (step = 20720640, mean_episode_return = None, mean_episode_step = 1567.3, total_loss = 140.21, pg_loss = 115.14, baseline_loss = 30.347, entropy_loss = -5.2708, learner_queue_size = 32, _tick = 3952, _time = 1.6548e+09, train_seconds = 5526.6)
[2022-06-09 21:40:11,758][root][INFO] - Step 20738560 @ 3581.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 20738560, mean_episode_return = None, mean_episode_step = 1901.2, total_loss = 106.67, pg_loss = 69.88, baseline_loss = 42.111, entropy_loss = -5.3169, learner_queue_size = 32, _tick = 3957, _time = 1.6548e+09, train_seconds = 5531.6)
[2022-06-09 21:40:16,762][root][INFO] - Step 20756480 @ 3581.2 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 20756480, mean_episode_return = None, mean_episode_step = 1837.0, total_loss = 357.25, pg_loss = 283.89, baseline_loss = 78.481, entropy_loss = -5.1235, learner_queue_size = 32, _tick = 3963, _time = 1.6548e+09, train_seconds = 5536.6)
[2022-06-09 21:40:21,767][root][INFO] - Step 20776960 @ 4092.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 20776960, mean_episode_return = 42.858, mean_episode_step = 1706.3, total_loss = -51.465, pg_loss = -64.923, baseline_loss = 18.644, entropy_loss = -5.1861, learner_queue_size = 32, _tick = 3968, _time = 1.6548e+09, train_seconds = 5541.6)
[2022-06-09 21:40:26,770][root][INFO] - Step 20794880 @ 3581.6 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 20794880, mean_episode_return = 17.99, mean_episode_step = 1670.7, total_loss = -29.008, pg_loss = -37.008, baseline_loss = 12.508, entropy_loss = -4.5087, learner_queue_size = 32, _tick = 3975, _time = 1.6548e+09, train_seconds = 5546.6)
[2022-06-09 21:40:31,774][root][INFO] - Step 20812800 @ 3581.2 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 20812800, mean_episode_return = None, mean_episode_step = 1512.2, total_loss = 104.35, pg_loss = 60.542, baseline_loss = 47.805, entropy_loss = -4.0008, learner_queue_size = 32, _tick = 3977, _time = 1.6548e+09, train_seconds = 5551.6)
[2022-06-09 21:40:36,778][root][INFO] - Step 20830720 @ 3581.1 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 20830720, mean_episode_return = None, mean_episode_step = 1813.1, total_loss = 37.926, pg_loss = 1.3622, baseline_loss = 40.991, entropy_loss = -4.427, learner_queue_size = 32, _tick = 3980, _time = 1.6548e+09, train_seconds = 5556.6)
[2022-06-09 21:40:41,782][root][INFO] - Step 20851200 @ 4092.8 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 20851200, mean_episode_return = -2.7303, mean_episode_step = 1612.9, total_loss = 120.39, pg_loss = 91.857, baseline_loss = 33.63, entropy_loss = -5.092, learner_queue_size = 32, _tick = 3986, _time = 1.6548e+09, train_seconds = 5561.6)
[2022-06-09 21:40:46,786][root][INFO] - Step 20869120 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 20869120, mean_episode_return = 42.11, mean_episode_step = 1823.2, total_loss = 397.87, pg_loss = 283.48, baseline_loss = 119.18, entropy_loss = -4.7853, learner_queue_size = 32, _tick = 3990, _time = 1.6548e+09, train_seconds = 5566.6)
[2022-06-09 21:40:51,790][root][INFO] - Step 20889600 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 20889600, mean_episode_return = None, mean_episode_step = 1864.1, total_loss = -44.923, pg_loss = -52.14, baseline_loss = 11.748, entropy_loss = -4.5316, learner_queue_size = 32, _tick = 3992, _time = 1.6548e+09, train_seconds = 5571.6)
[2022-06-09 21:40:56,794][root][INFO] - Step 20907520 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 20907520, mean_episode_return = 94.35, mean_episode_step = 2017.4, total_loss = -51.38, pg_loss = -72.432, baseline_loss = 26.013, entropy_loss = -4.9613, learner_queue_size = 32, _tick = 3996, _time = 1.6548e+09, train_seconds = 5576.6)
[2022-06-09 21:41:01,798][root][INFO] - Step 20928000 @ 4092.6 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 20928000, mean_episode_return = 114.87, mean_episode_step = 1434.3, total_loss = 306.12, pg_loss = 212.42, baseline_loss = 98.333, entropy_loss = -4.6322, learner_queue_size = 32, _tick = 4003, _time = 1.6548e+09, train_seconds = 5581.6)
[2022-06-09 21:41:06,802][root][INFO] - Step 20945920 @ 3581.2 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 20945920, mean_episode_return = 19.74, mean_episode_step = 1593.9, total_loss = 22.268, pg_loss = -0.84642, baseline_loss = 27.321, entropy_loss = -4.2072, learner_queue_size = 32, _tick = 4005, _time = 1.6548e+09, train_seconds = 5586.6)
[2022-06-09 21:41:11,806][root][INFO] - Step 20963840 @ 3581.2 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 20963840, mean_episode_return = 30.661, mean_episode_step = 1428.9, total_loss = -47.106, pg_loss = -73.555, baseline_loss = 30.99, entropy_loss = -4.5415, learner_queue_size = 32, _tick = 4010, _time = 1.6548e+09, train_seconds = 5591.6)
[2022-06-09 21:41:16,810][root][INFO] - Step 20984320 @ 4092.7 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 20984320, mean_episode_return = 75.138, mean_episode_step = 2041.0, total_loss = 155.6, pg_loss = 91.0, baseline_loss = 69.234, entropy_loss = -4.6313, learner_queue_size = 32, _tick = 4016, _time = 1.6548e+09, train_seconds = 5596.6)
[2022-06-09 21:41:21,814][root][INFO] - Step 21002240 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 21002240, mean_episode_return = 66.556, mean_episode_step = 1680.6, total_loss = -8.2955, pg_loss = -78.323, baseline_loss = 73.837, entropy_loss = -3.8096, learner_queue_size = 32, _tick = 4021, _time = 1.6548e+09, train_seconds = 5601.6)
[2022-06-09 21:41:26,818][root][INFO] - Step 21020160 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 21020160, mean_episode_return = None, mean_episode_step = 1986.3, total_loss = 19.925, pg_loss = 5.9448, baseline_loss = 18.919, entropy_loss = -4.9383, learner_queue_size = 32, _tick = 4024, _time = 1.6548e+09, train_seconds = 5606.6)
[2022-06-09 21:41:31,822][root][INFO] - Step 21038080 @ 3581.1 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 21038080, mean_episode_return = None, mean_episode_step = 1519.5, total_loss = 44.719, pg_loss = 24.516, baseline_loss = 24.965, entropy_loss = -4.7616, learner_queue_size = 32, _tick = 4028, _time = 1.6548e+09, train_seconds = 5611.6)
[2022-06-09 21:41:36,826][root][INFO] - Step 21058560 @ 4092.7 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 21058560, mean_episode_return = 50.964, mean_episode_step = 2093.4, total_loss = -30.679, pg_loss = -62.08, baseline_loss = 36.089, entropy_loss = -4.6888, learner_queue_size = 32, _tick = 4034, _time = 1.6548e+09, train_seconds = 5616.6)
[2022-06-09 21:41:41,830][root][INFO] - Step 21076480 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 21076480, mean_episode_return = 72.13, mean_episode_step = 1338.1, total_loss = -15.275, pg_loss = -41.534, baseline_loss = 31.219, entropy_loss = -4.9608, learner_queue_size = 32, _tick = 4039, _time = 1.6548e+09, train_seconds = 5621.6)
[2022-06-09 21:41:46,836][root][INFO] - Step 21094400 @ 3579.8 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 21094400, mean_episode_return = 29.872, mean_episode_step = 1563.5, total_loss = 116.42, pg_loss = 91.031, baseline_loss = 29.932, entropy_loss = -4.5438, learner_queue_size = 32, _tick = 4045, _time = 1.6548e+09, train_seconds = 5626.6)
[2022-06-09 21:41:51,838][root][INFO] - Step 21112320 @ 3582.4 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 21112320, mean_episode_return = 106.82, mean_episode_step = 1639.7, total_loss = 164.56, pg_loss = 88.15, baseline_loss = 80.579, entropy_loss = -4.1669, learner_queue_size = 32, _tick = 4051, _time = 1.6548e+09, train_seconds = 5631.6)
[2022-06-09 21:41:56,842][root][INFO] - Step 21130240 @ 3581.2 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 21130240, mean_episode_return = -8.5704, mean_episode_step = 1339.6, total_loss = 26.2, pg_loss = 4.3241, baseline_loss = 24.971, entropy_loss = -3.0951, learner_queue_size = 32, _tick = 4057, _time = 1.6548e+09, train_seconds = 5636.6)
[2022-06-09 21:42:01,846][root][INFO] - Step 21150720 @ 4092.6 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 21150720, mean_episode_return = None, mean_episode_step = 1571.2, total_loss = 18.121, pg_loss = 15.084, baseline_loss = 8.0086, entropy_loss = -4.9713, learner_queue_size = 32, _tick = 4062, _time = 1.6548e+09, train_seconds = 5641.7)
[2022-06-09 21:42:06,850][root][INFO] - Step 21168640 @ 3581.3 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 21168640, mean_episode_return = None, mean_episode_step = 1354.7, total_loss = 90.756, pg_loss = 75.644, baseline_loss = 19.777, entropy_loss = -4.6653, learner_queue_size = 32, _tick = 4065, _time = 1.6548e+09, train_seconds = 5646.7)
[2022-06-09 21:42:11,854][root][INFO] - Step 21186560 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 21186560, mean_episode_return = None, mean_episode_step = 1627.8, total_loss = 6.5313, pg_loss = -8.8599, baseline_loss = 19.213, entropy_loss = -3.8218, learner_queue_size = 32, _tick = 4067, _time = 1.6548e+09, train_seconds = 5651.7)
[2022-06-09 21:42:16,858][root][INFO] - Step 21207040 @ 4092.8 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 21207040, mean_episode_return = None, mean_episode_step = 1856.1, total_loss = -41.409, pg_loss = -42.65, baseline_loss = 5.8763, entropy_loss = -4.6354, learner_queue_size = 32, _tick = 4070, _time = 1.6548e+09, train_seconds = 5656.7)
[2022-06-09 21:42:21,862][root][INFO] - Step 21224960 @ 3581.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 21224960, mean_episode_return = None, mean_episode_step = 1736.4, total_loss = 2.197, pg_loss = -6.4648, baseline_loss = 13.387, entropy_loss = -4.7256, learner_queue_size = 32, _tick = 4072, _time = 1.6548e+09, train_seconds = 5661.7)
[2022-06-09 21:42:26,866][root][INFO] - Step 21242880 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 21242880, mean_episode_return = 25.741, mean_episode_step = 1636.2, total_loss = -46.709, pg_loss = -73.397, baseline_loss = 30.821, entropy_loss = -4.1335, learner_queue_size = 32, _tick = 4078, _time = 1.6548e+09, train_seconds = 5666.7)
[2022-06-09 21:42:31,870][root][INFO] - Step 21263360 @ 4092.7 SPS. Inference batcher size: 75. Learner queue size: 32. Other stats: (step = 21263360, mean_episode_return = 70.304, mean_episode_step = 1564.6, total_loss = -156.71, pg_loss = -184.29, baseline_loss = 31.315, entropy_loss = -3.7352, learner_queue_size = 32, _tick = 4082, _time = 1.6548e+09, train_seconds = 5671.7)
[2022-06-09 21:42:36,874][root][INFO] - Step 21281280 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 21281280, mean_episode_return = None, mean_episode_step = 1717.8, total_loss = 3.7676, pg_loss = -25.608, baseline_loss = 33.384, entropy_loss = -4.008, learner_queue_size = 32, _tick = 4084, _time = 1.6548e+09, train_seconds = 5676.7)
[2022-06-09 21:42:41,878][root][INFO] - Step 21301760 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 21301760, mean_episode_return = None, mean_episode_step = 1636.2, total_loss = -25.816, pg_loss = -64.83, baseline_loss = 43.334, entropy_loss = -4.3194, learner_queue_size = 32, _tick = 4087, _time = 1.6548e+09, train_seconds = 5681.7)
[2022-06-09 21:42:46,882][root][INFO] - Step 21319680 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 21319680, mean_episode_return = None, mean_episode_step = 1509.2, total_loss = 375.28, pg_loss = 237.77, baseline_loss = 142.1, entropy_loss = -4.5946, learner_queue_size = 32, _tick = 4090, _time = 1.6548e+09, train_seconds = 5686.7)
[2022-06-09 21:42:51,886][root][INFO] - Step 21337600 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 21337600, mean_episode_return = 31.09, mean_episode_step = 1669.2, total_loss = 177.78, pg_loss = 132.28, baseline_loss = 50.448, entropy_loss = -4.9527, learner_queue_size = 32, _tick = 4095, _time = 1.6548e+09, train_seconds = 5691.7)
[2022-06-09 21:42:56,890][root][INFO] - Step 21355520 @ 3581.2 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (step = 21355520, mean_episode_return = None, mean_episode_step = 1662.8, total_loss = 10.676, pg_loss = -16.343, baseline_loss = 31.499, entropy_loss = -4.4791, learner_queue_size = 32, _tick = 4100, _time = 1.6548e+09, train_seconds = 5696.7)
[2022-06-09 21:43:01,894][root][INFO] - Step 21376000 @ 4092.7 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 21376000, mean_episode_return = 11.9, mean_episode_step = 1759.0, total_loss = -102.2, pg_loss = -106.67, baseline_loss = 9.0771, entropy_loss = -4.6161, learner_queue_size = 32, _tick = 4105, _time = 1.6548e+09, train_seconds = 5701.7)
[2022-06-09 21:43:06,898][root][INFO] - Step 21393920 @ 3581.1 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 21393920, mean_episode_return = None, mean_episode_step = 1614.5, total_loss = 85.181, pg_loss = 38.815, baseline_loss = 51.571, entropy_loss = -5.2049, learner_queue_size = 32, _tick = 4109, _time = 1.6548e+09, train_seconds = 5706.7)
[2022-06-09 21:43:11,902][root][INFO] - Step 21411840 @ 3581.1 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 21411840, mean_episode_return = None, mean_episode_step = 1830.8, total_loss = -78.403, pg_loss = -79.665, baseline_loss = 5.7906, entropy_loss = -4.5295, learner_queue_size = 32, _tick = 4113, _time = 1.6548e+09, train_seconds = 5711.7)
[2022-06-09 21:43:16,906][root][INFO] - Step 21432320 @ 4092.6 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 21432320, mean_episode_return = 99.215, mean_episode_step = 1565.3, total_loss = 135.22, pg_loss = 86.034, baseline_loss = 54.055, entropy_loss = -4.8691, learner_queue_size = 32, _tick = 4118, _time = 1.6548e+09, train_seconds = 5716.7)
[2022-06-09 21:43:21,910][root][INFO] - Step 21450240 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 21450240, mean_episode_return = 111.94, mean_episode_step = 1617.1, total_loss = 41.606, pg_loss = 22.687, baseline_loss = 24.673, entropy_loss = -5.7543, learner_queue_size = 32, _tick = 4124, _time = 1.6548e+09, train_seconds = 5721.7)
[2022-06-09 21:43:26,914][root][INFO] - Step 21470720 @ 4092.8 SPS. Inference batcher size: 75. Learner queue size: 32. Other stats: (step = 21470720, mean_episode_return = 93.218, mean_episode_step = 1591.2, total_loss = 317.46, pg_loss = 220.92, baseline_loss = 101.18, entropy_loss = -4.6345, learner_queue_size = 32, _tick = 4129, _time = 1.6548e+09, train_seconds = 5726.7)
[2022-06-09 21:43:31,918][root][INFO] - Step 21488640 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 21488640, mean_episode_return = None, mean_episode_step = 1369.3, total_loss = 40.407, pg_loss = 19.685, baseline_loss = 25.037, entropy_loss = -4.3145, learner_queue_size = 32, _tick = 4132, _time = 1.6548e+09, train_seconds = 5731.7)
[2022-06-09 21:43:36,922][root][INFO] - Step 21506560 @ 3581.1 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 21506560, mean_episode_return = None, mean_episode_step = 1901.9, total_loss = 0.25918, pg_loss = -42.616, baseline_loss = 47.311, entropy_loss = -4.436, learner_queue_size = 32, _tick = 4135, _time = 1.6548e+09, train_seconds = 5736.7)
[2022-06-09 21:43:41,926][root][INFO] - Step 21527040 @ 4092.7 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 21527040, mean_episode_return = 55.523, mean_episode_step = 1793.2, total_loss = -54.788, pg_loss = -95.647, baseline_loss = 45.348, entropy_loss = -4.4893, learner_queue_size = 32, _tick = 4139, _time = 1.6548e+09, train_seconds = 5741.7)
[2022-06-09 21:43:46,930][root][INFO] - Step 21542400 @ 3069.6 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 21542400, mean_episode_return = None, mean_episode_step = 1528.5, total_loss = -97.869, pg_loss = -98.405, baseline_loss = 5.1545, entropy_loss = -4.6181, learner_queue_size = 32, _tick = 4141, _time = 1.6548e+09, train_seconds = 5746.7)
[2022-06-09 21:43:51,934][root][INFO] - Step 21560320 @ 3581.2 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 21560320, mean_episode_return = None, mean_episode_step = 1878.1, total_loss = 400.52, pg_loss = 280.26, baseline_loss = 125.03, entropy_loss = -4.7686, learner_queue_size = 32, _tick = 4145, _time = 1.6548e+09, train_seconds = 5751.7)
[2022-06-09 21:43:56,939][root][INFO] - Step 21580800 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 21580800, mean_episode_return = 83.136, mean_episode_step = 1658.1, total_loss = -25.233, pg_loss = -94.752, baseline_loss = 74.409, entropy_loss = -4.8893, learner_queue_size = 32, _tick = 4149, _time = 1.6548e+09, train_seconds = 5756.7)
[2022-06-09 21:44:01,942][root][INFO] - Step 21598720 @ 3581.1 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 21598720, mean_episode_return = None, mean_episode_step = 1518.8, total_loss = 80.637, pg_loss = 39.809, baseline_loss = 45.512, entropy_loss = -4.6835, learner_queue_size = 32, _tick = 4150, _time = 1.6548e+09, train_seconds = 5761.7)
[2022-06-09 21:44:06,946][root][INFO] - Step 21616640 @ 3581.2 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 21616640, mean_episode_return = 33.522, mean_episode_step = 1907.8, total_loss = -164.17, pg_loss = -182.95, baseline_loss = 23.429, entropy_loss = -4.6498, learner_queue_size = 32, _tick = 4154, _time = 1.6548e+09, train_seconds = 5766.8)
[2022-06-09 21:44:11,950][root][INFO] - Step 21634560 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 21634560, mean_episode_return = None, mean_episode_step = 1563.5, total_loss = 68.779, pg_loss = 14.985, baseline_loss = 58.435, entropy_loss = -4.6404, learner_queue_size = 32, _tick = 4158, _time = 1.6548e+09, train_seconds = 5771.8)
[2022-06-09 21:44:16,954][root][INFO] - Step 21655040 @ 4092.7 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 21655040, mean_episode_return = None, mean_episode_step = 1589.6, total_loss = 66.289, pg_loss = 32.637, baseline_loss = 38.405, entropy_loss = -4.7526, learner_queue_size = 32, _tick = 4164, _time = 1.6548e+09, train_seconds = 5776.8)
[2022-06-09 21:44:21,958][root][INFO] - Step 21672960 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 21672960, mean_episode_return = 104.39, mean_episode_step = 1598.5, total_loss = 275.19, pg_loss = 165.46, baseline_loss = 114.5, entropy_loss = -4.767, learner_queue_size = 32, _tick = 4166, _time = 1.6548e+09, train_seconds = 5781.8)
[2022-06-09 21:44:26,962][root][INFO] - Step 21690880 @ 3581.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 21690880, mean_episode_return = None, mean_episode_step = 1953.5, total_loss = -7.1334, pg_loss = -19.558, baseline_loss = 17.584, entropy_loss = -5.1595, learner_queue_size = 32, _tick = 4167, _time = 1.6548e+09, train_seconds = 5786.8)
[2022-06-09 21:44:31,966][root][INFO] - Step 21708800 @ 3581.2 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 21708800, mean_episode_return = 43.261, mean_episode_step = 1788.3, total_loss = 328.15, pg_loss = 228.82, baseline_loss = 104.51, entropy_loss = -5.1795, learner_queue_size = 32, _tick = 4172, _time = 1.6548e+09, train_seconds = 5791.8)
[2022-06-09 21:44:36,970][root][INFO] - Step 21729280 @ 4092.6 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 21729280, mean_episode_return = 103.82, mean_episode_step = 1811.9, total_loss = 108.06, pg_loss = 43.326, baseline_loss = 69.835, entropy_loss = -5.0964, learner_queue_size = 32, _tick = 4179, _time = 1.6548e+09, train_seconds = 5796.8)
[2022-06-09 21:44:41,974][root][INFO] - Step 21747200 @ 3581.3 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 21747200, mean_episode_return = None, mean_episode_step = 1692.0, total_loss = 79.304, pg_loss = 52.214, baseline_loss = 32.365, entropy_loss = -5.2754, learner_queue_size = 32, _tick = 4183, _time = 1.6548e+09, train_seconds = 5801.8)
[2022-06-09 21:44:46,978][root][INFO] - Step 21765120 @ 3581.1 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 21765120, mean_episode_return = 7.96, mean_episode_step = 1718.7, total_loss = 128.63, pg_loss = 76.795, baseline_loss = 56.952, entropy_loss = -5.114, learner_queue_size = 32, _tick = 4189, _time = 1.6548e+09, train_seconds = 5806.8)
[2022-06-09 21:44:51,982][root][INFO] - Step 21785600 @ 4092.7 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 21785600, mean_episode_return = 52.039, mean_episode_step = 1650.5, total_loss = 75.459, pg_loss = -3.353, baseline_loss = 83.949, entropy_loss = -5.1363, learner_queue_size = 32, _tick = 4194, _time = 1.6548e+09, train_seconds = 5811.8)
[2022-06-09 21:44:56,986][root][INFO] - Step 21803520 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 21803520, mean_episode_return = 61.881, mean_episode_step = 1716.1, total_loss = -30.852, pg_loss = -53.945, baseline_loss = 28.447, entropy_loss = -5.3547, learner_queue_size = 32, _tick = 4198, _time = 1.6548e+09, train_seconds = 5816.8)
[2022-06-09 21:45:01,990][root][INFO] - Step 21821440 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 21821440, mean_episode_return = 27.671, mean_episode_step = 1511.5, total_loss = 21.273, pg_loss = -0.40161, baseline_loss = 26.678, entropy_loss = -5.0035, learner_queue_size = 32, _tick = 4203, _time = 1.6548e+09, train_seconds = 5821.8)
[2022-06-09 21:45:06,995][root][INFO] - Step 21841920 @ 4092.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 21841920, mean_episode_return = None, mean_episode_step = 1660.5, total_loss = 6.5223, pg_loss = -21.772, baseline_loss = 33.246, entropy_loss = -4.951, learner_queue_size = 32, _tick = 4207, _time = 1.6548e+09, train_seconds = 5826.8)
[2022-06-09 21:45:11,998][root][INFO] - Step 21859840 @ 3581.6 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 21859840, mean_episode_return = 23.83, mean_episode_step = 1652.7, total_loss = -22.586, pg_loss = -38.108, baseline_loss = 20.754, entropy_loss = -5.2315, learner_queue_size = 32, _tick = 4212, _time = 1.6548e+09, train_seconds = 5831.8)
[2022-06-09 21:45:17,002][root][INFO] - Step 21880320 @ 4092.7 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 21880320, mean_episode_return = None, mean_episode_step = 1541.1, total_loss = 257.62, pg_loss = 177.0, baseline_loss = 85.785, entropy_loss = -5.1617, learner_queue_size = 32, _tick = 4217, _time = 1.6548e+09, train_seconds = 5836.8)
[2022-06-09 21:45:22,006][root][INFO] - Step 21898240 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 21898240, mean_episode_return = None, mean_episode_step = 1346.1, total_loss = 158.28, pg_loss = 118.57, baseline_loss = 44.419, entropy_loss = -4.7093, learner_queue_size = 32, _tick = 4220, _time = 1.6548e+09, train_seconds = 5841.8)
[2022-06-09 21:45:27,010][root][INFO] - Step 21918720 @ 4092.8 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 21918720, mean_episode_return = 121.2, mean_episode_step = 1581.7, total_loss = -112.25, pg_loss = -121.43, baseline_loss = 13.461, entropy_loss = -4.2863, learner_queue_size = 32, _tick = 4225, _time = 1.6548e+09, train_seconds = 5846.8)
[2022-06-09 21:45:32,014][root][INFO] - Step 21936640 @ 3581.1 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 21936640, mean_episode_return = 23.603, mean_episode_step = 1948.2, total_loss = 37.764, pg_loss = 14.969, baseline_loss = 27.474, entropy_loss = -4.6797, learner_queue_size = 32, _tick = 4229, _time = 1.6548e+09, train_seconds = 5851.8)
[2022-06-09 21:45:37,018][root][INFO] - Step 21957120 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 21957120, mean_episode_return = None, mean_episode_step = 1721.1, total_loss = 208.42, pg_loss = 159.09, baseline_loss = 54.547, entropy_loss = -5.2208, learner_queue_size = 32, _tick = 4232, _time = 1.6548e+09, train_seconds = 5856.8)
[2022-06-09 21:45:42,022][root][INFO] - Step 21975040 @ 3581.2 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 21975040, mean_episode_return = 115.13, mean_episode_step = 1950.7, total_loss = -74.437, pg_loss = -73.191, baseline_loss = 4.3487, entropy_loss = -5.5947, learner_queue_size = 32, _tick = 4235, _time = 1.6548e+09, train_seconds = 5861.8)
[2022-06-09 21:45:47,029][root][INFO] - Step 21992960 @ 3579.1 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 21992960, mean_episode_return = 37.648, mean_episode_step = 2154.5, total_loss = -50.048, pg_loss = -82.211, baseline_loss = 37.24, entropy_loss = -5.0775, learner_queue_size = 32, _tick = 4240, _time = 1.6548e+09, train_seconds = 5866.8)
[2022-06-09 21:45:52,034][root][INFO] - Step 22010880 @ 3580.3 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 22010880, mean_episode_return = 31.28, mean_episode_step = 1389.9, total_loss = 250.25, pg_loss = 144.67, baseline_loss = 110.61, entropy_loss = -5.0338, learner_queue_size = 32, _tick = 4245, _time = 1.6548e+09, train_seconds = 5871.8)
[2022-06-09 21:45:57,038][root][INFO] - Step 22031360 @ 4092.7 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 22031360, mean_episode_return = 35.981, mean_episode_step = 2130.1, total_loss = -162.1, pg_loss = -163.21, baseline_loss = 6.0697, entropy_loss = -4.9613, learner_queue_size = 32, _tick = 4251, _time = 1.6548e+09, train_seconds = 5876.8)
[2022-06-09 21:46:02,042][root][INFO] - Step 22049280 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 22049280, mean_episode_return = 29.5, mean_episode_step = 1588.3, total_loss = 27.528, pg_loss = -13.351, baseline_loss = 45.755, entropy_loss = -4.8753, learner_queue_size = 32, _tick = 4256, _time = 1.6548e+09, train_seconds = 5881.8)
[2022-06-09 21:46:07,046][root][INFO] - Step 22067200 @ 3581.0 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (step = 22067200, mean_episode_return = 16.59, mean_episode_step = 1451.7, total_loss = -162.38, pg_loss = -171.97, baseline_loss = 14.216, entropy_loss = -4.6238, learner_queue_size = 32, _tick = 4258, _time = 1.6548e+09, train_seconds = 5886.9)
[2022-06-09 21:46:12,050][root][INFO] - Step 22087680 @ 4092.9 SPS. Inference batcher size: 73. Learner queue size: 32. Other stats: (step = 22087680, mean_episode_return = None, mean_episode_step = 1592.8, total_loss = 27.41, pg_loss = -13.311, baseline_loss = 45.453, entropy_loss = -4.731, learner_queue_size = 32, _tick = 4261, _time = 1.6548e+09, train_seconds = 5891.9)
[2022-06-09 21:46:17,054][root][INFO] - Step 22105600 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 22105600, mean_episode_return = 91.919, mean_episode_step = 1688.4, total_loss = -126.76, pg_loss = -129.81, baseline_loss = 7.7145, entropy_loss = -4.6629, learner_queue_size = 32, _tick = 4266, _time = 1.6548e+09, train_seconds = 5896.9)
[2022-06-09 21:46:22,058][root][INFO] - Step 22123520 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 22123520, mean_episode_return = None, mean_episode_step = 1842.1, total_loss = 347.86, pg_loss = 207.58, baseline_loss = 145.59, entropy_loss = -5.3082, learner_queue_size = 32, _tick = 4269, _time = 1.6548e+09, train_seconds = 5901.9)
[2022-06-09 21:46:27,062][root][INFO] - Step 22144000 @ 4092.7 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 22144000, mean_episode_return = 116.55, mean_episode_step = 1946.9, total_loss = 178.13, pg_loss = 127.09, baseline_loss = 55.544, entropy_loss = -4.5098, learner_queue_size = 32, _tick = 4275, _time = 1.6548e+09, train_seconds = 5906.9)
[2022-06-09 21:46:32,066][root][INFO] - Step 22161920 @ 3581.2 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 22161920, mean_episode_return = 49.271, mean_episode_step = 1425.2, total_loss = -53.074, pg_loss = -82.565, baseline_loss = 34.291, entropy_loss = -4.7997, learner_queue_size = 32, _tick = 4279, _time = 1.6548e+09, train_seconds = 5911.9)
[2022-06-09 21:46:37,070][root][INFO] - Step 22179840 @ 3581.1 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 22179840, mean_episode_return = 25.872, mean_episode_step = 1720.1, total_loss = 216.62, pg_loss = 132.5, baseline_loss = 88.68, entropy_loss = -4.5608, learner_queue_size = 32, _tick = 4284, _time = 1.6548e+09, train_seconds = 5916.9)
[2022-06-09 21:46:42,076][root][INFO] - Step 22200320 @ 4091.3 SPS. Inference batcher size: 85. Learner queue size: 32. Other stats: (step = 22200320, mean_episode_return = None, mean_episode_step = 1788.3, total_loss = 244.44, pg_loss = 143.7, baseline_loss = 105.22, entropy_loss = -4.4844, learner_queue_size = 32, _tick = 4289, _time = 1.6548e+09, train_seconds = 5921.9)
[2022-06-09 21:46:47,078][root][INFO] - Step 22218240 @ 3582.4 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 22218240, mean_episode_return = 26.29, mean_episode_step = 1661.5, total_loss = 221.16, pg_loss = 118.59, baseline_loss = 107.22, entropy_loss = -4.6561, learner_queue_size = 32, _tick = 4293, _time = 1.6548e+09, train_seconds = 5926.9)
[2022-06-09 21:46:52,082][root][INFO] - Step 22238720 @ 4092.8 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 22238720, mean_episode_return = None, mean_episode_step = 1817.5, total_loss = -23.349, pg_loss = -29.661, baseline_loss = 11.353, entropy_loss = -5.0411, learner_queue_size = 32, _tick = 4294, _time = 1.6548e+09, train_seconds = 5931.9)
[2022-06-09 21:46:57,086][root][INFO] - Step 22256640 @ 3581.1 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 22256640, mean_episode_return = 52.029, mean_episode_step = 1573.7, total_loss = -107.99, pg_loss = -126.02, baseline_loss = 23.298, entropy_loss = -5.2667, learner_queue_size = 32, _tick = 4298, _time = 1.6548e+09, train_seconds = 5936.9)
[2022-06-09 21:47:02,090][root][INFO] - Step 22277120 @ 4092.8 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 22277120, mean_episode_return = None, mean_episode_step = 1671.5, total_loss = 104.3, pg_loss = 58.703, baseline_loss = 50.763, entropy_loss = -5.1709, learner_queue_size = 32, _tick = 4305, _time = 1.6548e+09, train_seconds = 5941.9)
[2022-06-09 21:47:07,094][root][INFO] - Step 22295040 @ 3581.2 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 22295040, mean_episode_return = 73.239, mean_episode_step = 1790.7, total_loss = 222.93, pg_loss = 145.3, baseline_loss = 82.774, entropy_loss = -5.1424, learner_queue_size = 32, _tick = 4312, _time = 1.6548e+09, train_seconds = 5946.9)
[2022-06-09 21:47:12,098][root][INFO] - Step 22312960 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 22312960, mean_episode_return = 76.045, mean_episode_step = 2136.7, total_loss = 164.34, pg_loss = 71.328, baseline_loss = 98.126, entropy_loss = -5.119, learner_queue_size = 32, _tick = 4315, _time = 1.6548e+09, train_seconds = 5951.9)
[2022-06-09 21:47:17,102][root][INFO] - Step 22333440 @ 4092.7 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 22333440, mean_episode_return = None, mean_episode_step = 1748.1, total_loss = -29.434, pg_loss = -57.69, baseline_loss = 33.368, entropy_loss = -5.1125, learner_queue_size = 32, _tick = 4321, _time = 1.6548e+09, train_seconds = 5956.9)
[2022-06-09 21:47:22,106][root][INFO] - Step 22351360 @ 3581.1 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 22351360, mean_episode_return = 98.012, mean_episode_step = 2042.4, total_loss = 78.221, pg_loss = 6.418, baseline_loss = 76.512, entropy_loss = -4.7091, learner_queue_size = 32, _tick = 4325, _time = 1.6548e+09, train_seconds = 5961.9)
[2022-06-09 21:47:27,111][root][INFO] - Step 22369280 @ 3580.6 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 22369280, mean_episode_return = None, mean_episode_step = 1781.9, total_loss = 89.73, pg_loss = 52.726, baseline_loss = 41.699, entropy_loss = -4.6953, learner_queue_size = 32, _tick = 4328, _time = 1.6548e+09, train_seconds = 5966.9)
[2022-06-09 21:47:32,114][root][INFO] - Step 22389760 @ 4093.4 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (step = 22389760, mean_episode_return = 50.984, mean_episode_step = 1649.5, total_loss = 143.14, pg_loss = 70.714, baseline_loss = 77.249, entropy_loss = -4.8252, learner_queue_size = 32, _tick = 4331, _time = 1.6548e+09, train_seconds = 5971.9)
[2022-06-09 21:47:37,118][root][INFO] - Step 22407680 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 22407680, mean_episode_return = 28.106, mean_episode_step = 1411.3, total_loss = -156.62, pg_loss = -197.09, baseline_loss = 45.375, entropy_loss = -4.9057, learner_queue_size = 32, _tick = 4335, _time = 1.6548e+09, train_seconds = 5976.9)
[2022-06-09 21:47:42,122][root][INFO] - Step 22425600 @ 3581.0 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 22425600, mean_episode_return = 58.901, mean_episode_step = 2045.5, total_loss = 97.004, pg_loss = 17.635, baseline_loss = 84.39, entropy_loss = -5.0211, learner_queue_size = 32, _tick = 4339, _time = 1.6548e+09, train_seconds = 5981.9)
[2022-06-09 21:47:47,126][root][INFO] - Step 22443520 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 22443520, mean_episode_return = 18.23, mean_episode_step = 1727.9, total_loss = 212.98, pg_loss = 139.12, baseline_loss = 78.694, entropy_loss = -4.8359, learner_queue_size = 32, _tick = 4342, _time = 1.6548e+09, train_seconds = 5986.9)
[2022-06-09 21:47:52,130][root][INFO] - Step 22461440 @ 3581.2 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 22461440, mean_episode_return = 139.55, mean_episode_step = 1661.3, total_loss = -4.6601, pg_loss = -48.647, baseline_loss = 48.389, entropy_loss = -4.4019, learner_queue_size = 32, _tick = 4348, _time = 1.6548e+09, train_seconds = 5991.9)
[2022-06-09 21:47:57,136][root][INFO] - Step 22479360 @ 3580.0 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 22479360, mean_episode_return = 46.544, mean_episode_step = 1750.3, total_loss = 115.77, pg_loss = 45.908, baseline_loss = 74.336, entropy_loss = -4.4755, learner_queue_size = 32, _tick = 4352, _time = 1.6548e+09, train_seconds = 5996.9)
[2022-06-09 21:48:02,138][root][INFO] - Step 22499840 @ 4094.0 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 22499840, mean_episode_return = 31.94, mean_episode_step = 1474.2, total_loss = 55.86, pg_loss = -22.829, baseline_loss = 81.929, entropy_loss = -3.2398, learner_queue_size = 32, _tick = 4359, _time = 1.6548e+09, train_seconds = 6001.9)
[2022-06-09 21:48:07,143][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-09 21:48:07,259][root][INFO] - Step 22517760 @ 3580.4 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 22517760, mean_episode_return = 26.052, mean_episode_step = 1521.6, total_loss = -106.98, pg_loss = -118.92, baseline_loss = 16.755, entropy_loss = -4.8123, learner_queue_size = 32, _tick = 4363, _time = 1.6548e+09, train_seconds = 6007.0)
[2022-06-09 21:48:12,262][root][INFO] - Step 22538240 @ 4000.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 22538240, mean_episode_return = 44.582, mean_episode_step = 2158.1, total_loss = -83.227, pg_loss = -98.382, baseline_loss = 20.066, entropy_loss = -4.9104, learner_queue_size = 32, _tick = 4366, _time = 1.6548e+09, train_seconds = 6012.1)
[2022-06-09 21:48:17,266][root][INFO] - Step 22556160 @ 3581.2 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 22556160, mean_episode_return = -9.5104, mean_episode_step = 1313.2, total_loss = 0.16455, pg_loss = -47.187, baseline_loss = 52.003, entropy_loss = -4.6518, learner_queue_size = 32, _tick = 4372, _time = 1.6548e+09, train_seconds = 6017.1)
[2022-06-09 21:48:22,270][root][INFO] - Step 22574080 @ 3581.2 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 22574080, mean_episode_return = None, mean_episode_step = 1747.2, total_loss = -87.662, pg_loss = -86.437, baseline_loss = 3.4603, entropy_loss = -4.6849, learner_queue_size = 32, _tick = 4374, _time = 1.6548e+09, train_seconds = 6022.1)
[2022-06-09 21:48:27,274][root][INFO] - Step 22594560 @ 4092.6 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 22594560, mean_episode_return = None, mean_episode_step = 1878.5, total_loss = -89.441, pg_loss = -100.37, baseline_loss = 15.704, entropy_loss = -4.7733, learner_queue_size = 32, _tick = 4379, _time = 1.6548e+09, train_seconds = 6027.1)
[2022-06-09 21:48:32,278][root][INFO] - Step 22615040 @ 4092.8 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 22615040, mean_episode_return = None, mean_episode_step = 1771.4, total_loss = -47.118, pg_loss = -50.845, baseline_loss = 8.4849, entropy_loss = -4.7581, learner_queue_size = 32, _tick = 4384, _time = 1.6548e+09, train_seconds = 6032.1)
[2022-06-09 21:48:37,283][root][INFO] - Step 22632960 @ 3580.8 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (step = 22632960, mean_episode_return = 191.15, mean_episode_step = 1378.6, total_loss = 192.31, pg_loss = 124.29, baseline_loss = 72.953, entropy_loss = -4.9388, learner_queue_size = 32, _tick = 4389, _time = 1.6548e+09, train_seconds = 6037.1)
[2022-06-09 21:48:42,286][root][INFO] - Step 22653440 @ 4093.2 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 22653440, mean_episode_return = 20.039, mean_episode_step = 1814.0, total_loss = 153.0, pg_loss = 107.75, baseline_loss = 50.108, entropy_loss = -4.8518, learner_queue_size = 32, _tick = 4396, _time = 1.6548e+09, train_seconds = 6042.1)
[2022-06-09 21:48:47,290][root][INFO] - Step 22671360 @ 3581.2 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 22671360, mean_episode_return = 19.27, mean_episode_step = 1249.3, total_loss = 518.94, pg_loss = 385.5, baseline_loss = 138.11, entropy_loss = -4.6685, learner_queue_size = 32, _tick = 4403, _time = 1.6548e+09, train_seconds = 6047.1)
[2022-06-09 21:48:52,294][root][INFO] - Step 22689280 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 22689280, mean_episode_return = -1.5704, mean_episode_step = 1722.7, total_loss = 38.827, pg_loss = 13.406, baseline_loss = 29.818, entropy_loss = -4.3964, learner_queue_size = 32, _tick = 4409, _time = 1.6548e+09, train_seconds = 6052.1)
[2022-06-09 21:48:57,298][root][INFO] - Step 22707200 @ 3581.2 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 22707200, mean_episode_return = 97.362, mean_episode_step = 1590.0, total_loss = 144.97, pg_loss = 72.629, baseline_loss = 76.887, entropy_loss = -4.5452, learner_queue_size = 32, _tick = 4414, _time = 1.6548e+09, train_seconds = 6057.1)
[2022-06-09 21:49:02,302][root][INFO] - Step 22727680 @ 4092.3 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 22727680, mean_episode_return = 55.495, mean_episode_step = 1947.8, total_loss = 42.488, pg_loss = -38.372, baseline_loss = 85.523, entropy_loss = -4.6637, learner_queue_size = 32, _tick = 4422, _time = 1.6548e+09, train_seconds = 6062.1)
[2022-06-09 21:49:07,306][root][INFO] - Step 22745600 @ 3581.5 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 22745600, mean_episode_return = 110.87, mean_episode_step = 1371.7, total_loss = 45.66, pg_loss = 7.2642, baseline_loss = 42.668, entropy_loss = -4.272, learner_queue_size = 32, _tick = 4425, _time = 1.6548e+09, train_seconds = 6067.1)
[2022-06-09 21:49:12,310][root][INFO] - Step 22763520 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 22763520, mean_episode_return = None, mean_episode_step = 1755.6, total_loss = 62.257, pg_loss = 39.426, baseline_loss = 27.792, entropy_loss = -4.9609, learner_queue_size = 32, _tick = 4431, _time = 1.6548e+09, train_seconds = 6072.1)
[2022-06-09 21:49:17,314][root][INFO] - Step 22784000 @ 4092.7 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 22784000, mean_episode_return = 4.8596, mean_episode_step = 1712.8, total_loss = -99.78, pg_loss = -116.14, baseline_loss = 20.977, entropy_loss = -4.6175, learner_queue_size = 32, _tick = 4437, _time = 1.6548e+09, train_seconds = 6077.1)
[2022-06-09 21:49:22,319][root][INFO] - Step 22801920 @ 3580.3 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 22801920, mean_episode_return = 49.531, mean_episode_step = 1932.2, total_loss = 52.236, pg_loss = 14.771, baseline_loss = 41.934, entropy_loss = -4.4686, learner_queue_size = 32, _tick = 4443, _time = 1.6548e+09, train_seconds = 6082.1)
[2022-06-09 21:49:27,322][root][INFO] - Step 22819840 @ 3581.9 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 22819840, mean_episode_return = -39.179, mean_episode_step = 1922.2, total_loss = 212.53, pg_loss = 133.13, baseline_loss = 83.945, entropy_loss = -4.5466, learner_queue_size = 32, _tick = 4447, _time = 1.6548e+09, train_seconds = 6087.1)
[2022-06-09 21:49:32,326][root][INFO] - Step 22840320 @ 4092.8 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 22840320, mean_episode_return = 41.051, mean_episode_step = 1421.9, total_loss = -96.431, pg_loss = -109.79, baseline_loss = 17.712, entropy_loss = -4.3564, learner_queue_size = 32, _tick = 4453, _time = 1.6548e+09, train_seconds = 6092.1)
[2022-06-09 21:49:37,330][root][INFO] - Step 22858240 @ 3581.1 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 22858240, mean_episode_return = 136.41, mean_episode_step = 1877.3, total_loss = -68.485, pg_loss = -107.46, baseline_loss = 43.51, entropy_loss = -4.5383, learner_queue_size = 32, _tick = 4457, _time = 1.6548e+09, train_seconds = 6097.1)
[2022-06-09 21:49:42,334][root][INFO] - Step 22878720 @ 4092.7 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 22878720, mean_episode_return = 15.085, mean_episode_step = 1335.8, total_loss = -186.3, pg_loss = -205.92, baseline_loss = 24.067, entropy_loss = -4.4459, learner_queue_size = 32, _tick = 4462, _time = 1.6548e+09, train_seconds = 6102.1)
[2022-06-09 21:49:47,338][root][INFO] - Step 22896640 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 22896640, mean_episode_return = None, mean_episode_step = 1402.5, total_loss = 221.21, pg_loss = 146.24, baseline_loss = 79.417, entropy_loss = -4.4469, learner_queue_size = 32, _tick = 4463, _time = 1.6548e+09, train_seconds = 6107.1)
[2022-06-09 21:49:52,342][root][INFO] - Step 22917120 @ 4092.8 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 22917120, mean_episode_return = None, mean_episode_step = 1463.8, total_loss = 195.48, pg_loss = 143.67, baseline_loss = 56.457, entropy_loss = -4.6406, learner_queue_size = 32, _tick = 4464, _time = 1.6548e+09, train_seconds = 6112.1)
[2022-06-09 21:49:57,346][root][INFO] - Step 22935040 @ 3581.2 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 22935040, mean_episode_return = None, mean_episode_step = 1507.7, total_loss = 349.03, pg_loss = 243.05, baseline_loss = 110.62, entropy_loss = -4.6502, learner_queue_size = 32, _tick = 4466, _time = 1.6548e+09, train_seconds = 6117.2)
[2022-06-09 21:50:02,350][root][INFO] - Step 22952960 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 22952960, mean_episode_return = None, mean_episode_step = 1135.8, total_loss = 110.17, pg_loss = 47.5, baseline_loss = 67.317, entropy_loss = -4.6426, learner_queue_size = 32, _tick = 4468, _time = 1.6548e+09, train_seconds = 6122.2)
[2022-06-09 21:50:07,354][root][INFO] - Step 22970880 @ 3581.0 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 22970880, mean_episode_return = 39.891, mean_episode_step = 1775.2, total_loss = 98.06, pg_loss = 44.317, baseline_loss = 58.815, entropy_loss = -5.0714, learner_queue_size = 32, _tick = 4473, _time = 1.6548e+09, train_seconds = 6127.2)
[2022-06-09 21:50:12,358][root][INFO] - Step 22991360 @ 4092.8 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 22991360, mean_episode_return = 88.733, mean_episode_step = 1810.6, total_loss = 21.428, pg_loss = -6.9088, baseline_loss = 33.331, entropy_loss = -4.9939, learner_queue_size = 32, _tick = 4481, _time = 1.6548e+09, train_seconds = 6132.2)
[2022-06-09 21:50:17,362][root][INFO] - Step 23009280 @ 3581.1 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 23009280, mean_episode_return = 34.75, mean_episode_step = 1681.4, total_loss = 303.31, pg_loss = 135.94, baseline_loss = 172.1, entropy_loss = -4.7286, learner_queue_size = 32, _tick = 4487, _time = 1.6548e+09, train_seconds = 6137.2)
[2022-06-09 21:50:22,366][root][INFO] - Step 23029760 @ 4092.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 23029760, mean_episode_return = 102.71, mean_episode_step = 1754.9, total_loss = 307.77, pg_loss = 222.54, baseline_loss = 90.308, entropy_loss = -5.0784, learner_queue_size = 32, _tick = 4492, _time = 1.6548e+09, train_seconds = 6142.2)
[2022-06-09 21:50:27,370][root][INFO] - Step 23047680 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 23047680, mean_episode_return = None, mean_episode_step = 1770.5, total_loss = 385.85, pg_loss = 236.54, baseline_loss = 154.3, entropy_loss = -4.9929, learner_queue_size = 32, _tick = 4496, _time = 1.6548e+09, train_seconds = 6147.2)
[2022-06-09 21:50:32,374][root][INFO] - Step 23068160 @ 4092.8 SPS. Inference batcher size: 78. Learner queue size: 32. Other stats: (step = 23068160, mean_episode_return = None, mean_episode_step = 1409.4, total_loss = 22.389, pg_loss = -1.0831, baseline_loss = 28.128, entropy_loss = -4.6559, learner_queue_size = 32, _tick = 4500, _time = 1.6548e+09, train_seconds = 6152.2)
[2022-06-09 21:50:37,378][root][INFO] - Step 23086080 @ 3581.1 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 23086080, mean_episode_return = 71.857, mean_episode_step = 1546.2, total_loss = -35.928, pg_loss = -94.29, baseline_loss = 62.744, entropy_loss = -4.3818, learner_queue_size = 32, _tick = 4504, _time = 1.6548e+09, train_seconds = 6157.2)
[2022-06-09 21:50:42,382][root][INFO] - Step 23104000 @ 3581.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 23104000, mean_episode_return = 67.529, mean_episode_step = 1873.4, total_loss = -4.4972, pg_loss = -44.883, baseline_loss = 45.184, entropy_loss = -4.7983, learner_queue_size = 32, _tick = 4507, _time = 1.6548e+09, train_seconds = 6162.2)
[2022-06-09 21:50:47,386][root][INFO] - Step 23124480 @ 4092.8 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 23124480, mean_episode_return = 39.345, mean_episode_step = 1417.9, total_loss = -53.146, pg_loss = -84.842, baseline_loss = 36.061, entropy_loss = -4.3654, learner_queue_size = 32, _tick = 4512, _time = 1.6548e+09, train_seconds = 6167.2)
[2022-06-09 21:50:52,390][root][INFO] - Step 23142400 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 23142400, mean_episode_return = 47.131, mean_episode_step = 2111.9, total_loss = -103.93, pg_loss = -117.71, baseline_loss = 18.425, entropy_loss = -4.6423, learner_queue_size = 32, _tick = 4518, _time = 1.6548e+09, train_seconds = 6172.2)
[2022-06-09 21:50:57,394][root][INFO] - Step 23160320 @ 3581.2 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 23160320, mean_episode_return = 34.915, mean_episode_step = 1555.0, total_loss = 37.319, pg_loss = 6.33, baseline_loss = 35.635, entropy_loss = -4.6458, learner_queue_size = 32, _tick = 4521, _time = 1.6548e+09, train_seconds = 6177.2)
[2022-06-09 21:51:02,398][root][INFO] - Step 23180800 @ 4092.7 SPS. Inference batcher size: 85. Learner queue size: 32. Other stats: (step = 23180800, mean_episode_return = 53.321, mean_episode_step = 1512.5, total_loss = 744.15, pg_loss = 426.92, baseline_loss = 321.84, entropy_loss = -4.6069, learner_queue_size = 32, _tick = 4526, _time = 1.6548e+09, train_seconds = 6182.2)
[2022-06-09 21:51:07,402][root][INFO] - Step 23198720 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 23198720, mean_episode_return = None, mean_episode_step = 1701.2, total_loss = 83.721, pg_loss = 38.911, baseline_loss = 49.233, entropy_loss = -4.4239, learner_queue_size = 32, _tick = 4528, _time = 1.6548e+09, train_seconds = 6187.2)
[2022-06-09 21:51:12,406][root][INFO] - Step 23216640 @ 3581.2 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 23216640, mean_episode_return = 75.21, mean_episode_step = 1452.5, total_loss = 24.606, pg_loss = -5.095, baseline_loss = 34.312, entropy_loss = -4.6107, learner_queue_size = 32, _tick = 4533, _time = 1.6548e+09, train_seconds = 6192.2)
[2022-06-09 21:51:17,410][root][INFO] - Step 23234560 @ 3581.1 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (step = 23234560, mean_episode_return = None, mean_episode_step = 1504.5, total_loss = -75.652, pg_loss = -83.411, baseline_loss = 12.326, entropy_loss = -4.5674, learner_queue_size = 32, _tick = 4538, _time = 1.6548e+09, train_seconds = 6197.2)
[2022-06-09 21:51:22,414][root][INFO] - Step 23255040 @ 4092.7 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 23255040, mean_episode_return = 49.091, mean_episode_step = 1957.7, total_loss = 102.06, pg_loss = 14.32, baseline_loss = 92.484, entropy_loss = -4.7411, learner_queue_size = 32, _tick = 4544, _time = 1.6548e+09, train_seconds = 6202.2)
[2022-06-09 21:51:27,418][root][INFO] - Step 23272960 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 23272960, mean_episode_return = 67.691, mean_episode_step = 1611.0, total_loss = 61.806, pg_loss = 30.331, baseline_loss = 36.601, entropy_loss = -5.1259, learner_queue_size = 32, _tick = 4548, _time = 1.6548e+09, train_seconds = 6207.2)
[2022-06-09 21:51:32,422][root][INFO] - Step 23290880 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 23290880, mean_episode_return = None, mean_episode_step = 1769.9, total_loss = 6.8299, pg_loss = -7.8582, baseline_loss = 19.565, entropy_loss = -4.8765, learner_queue_size = 32, _tick = 4552, _time = 1.6548e+09, train_seconds = 6212.2)
[2022-06-09 21:51:37,426][root][INFO] - Step 23311360 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 23311360, mean_episode_return = None, mean_episode_step = 2017.2, total_loss = 35.037, pg_loss = 12.927, baseline_loss = 26.843, entropy_loss = -4.7335, learner_queue_size = 32, _tick = 4558, _time = 1.6548e+09, train_seconds = 6217.2)
[2022-06-09 21:51:42,430][root][INFO] - Step 23329280 @ 3581.2 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 23329280, mean_episode_return = None, mean_episode_step = 1683.5, total_loss = 71.834, pg_loss = 17.987, baseline_loss = 58.646, entropy_loss = -4.7983, learner_queue_size = 32, _tick = 4561, _time = 1.6548e+09, train_seconds = 6222.2)
[2022-06-09 21:51:47,434][root][INFO] - Step 23349760 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 23349760, mean_episode_return = 44.443, mean_episode_step = 1567.4, total_loss = 232.35, pg_loss = 161.06, baseline_loss = 76.43, entropy_loss = -5.1369, learner_queue_size = 32, _tick = 4566, _time = 1.6548e+09, train_seconds = 6227.2)
[2022-06-09 21:51:52,438][root][INFO] - Step 23367680 @ 3581.1 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 23367680, mean_episode_return = 78.626, mean_episode_step = 1393.7, total_loss = 8.8311, pg_loss = -8.0593, baseline_loss = 21.671, entropy_loss = -4.7808, learner_queue_size = 32, _tick = 4570, _time = 1.6548e+09, train_seconds = 6232.2)
[2022-06-09 21:51:57,442][root][INFO] - Step 23388160 @ 4092.8 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 23388160, mean_episode_return = None, mean_episode_step = 1521.0, total_loss = 237.15, pg_loss = 151.97, baseline_loss = 89.909, entropy_loss = -4.7309, learner_queue_size = 32, _tick = 4573, _time = 1.6548e+09, train_seconds = 6237.2)
[2022-06-09 21:52:02,446][root][INFO] - Step 23406080 @ 3581.2 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 23406080, mean_episode_return = None, mean_episode_step = 1417.4, total_loss = -18.251, pg_loss = -28.06, baseline_loss = 14.427, entropy_loss = -4.6186, learner_queue_size = 32, _tick = 4578, _time = 1.6548e+09, train_seconds = 6242.3)
[2022-06-09 21:52:07,450][root][INFO] - Step 23426560 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 23426560, mean_episode_return = 43.27, mean_episode_step = 1839.6, total_loss = 274.02, pg_loss = 211.33, baseline_loss = 67.61, entropy_loss = -4.9194, learner_queue_size = 32, _tick = 4581, _time = 1.6548e+09, train_seconds = 6247.3)
[2022-06-09 21:52:12,454][root][INFO] - Step 23444480 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 23444480, mean_episode_return = 39.005, mean_episode_step = 1307.9, total_loss = 13.412, pg_loss = -37.652, baseline_loss = 55.923, entropy_loss = -4.8597, learner_queue_size = 32, _tick = 4585, _time = 1.6548e+09, train_seconds = 6252.3)
[2022-06-09 21:52:17,458][root][INFO] - Step 23462400 @ 3581.2 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 23462400, mean_episode_return = 57.253, mean_episode_step = 1514.8, total_loss = 83.199, pg_loss = 10.754, baseline_loss = 77.319, entropy_loss = -4.8737, learner_queue_size = 32, _tick = 4590, _time = 1.6548e+09, train_seconds = 6257.3)
[2022-06-09 21:52:22,462][root][INFO] - Step 23480320 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 23480320, mean_episode_return = None, mean_episode_step = 1482.3, total_loss = 288.72, pg_loss = 231.51, baseline_loss = 61.922, entropy_loss = -4.7058, learner_queue_size = 32, _tick = 4593, _time = 1.6548e+09, train_seconds = 6262.3)
[2022-06-09 21:52:27,466][root][INFO] - Step 23500800 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 23500800, mean_episode_return = 53.657, mean_episode_step = 2315.6, total_loss = -44.307, pg_loss = -118.56, baseline_loss = 79.071, entropy_loss = -4.8215, learner_queue_size = 32, _tick = 4598, _time = 1.6548e+09, train_seconds = 6267.3)
[2022-06-09 21:52:32,470][root][INFO] - Step 23521280 @ 4092.7 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 23521280, mean_episode_return = 32.32, mean_episode_step = 1640.6, total_loss = 291.77, pg_loss = 167.16, baseline_loss = 129.39, entropy_loss = -4.784, learner_queue_size = 32, _tick = 4603, _time = 1.6548e+09, train_seconds = 6272.3)
[2022-06-09 21:52:37,474][root][INFO] - Step 23539200 @ 3580.9 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 23539200, mean_episode_return = 12.245, mean_episode_step = 1431.0, total_loss = 111.05, pg_loss = 7.1542, baseline_loss = 108.48, entropy_loss = -4.5882, learner_queue_size = 32, _tick = 4606, _time = 1.6548e+09, train_seconds = 6277.3)
[2022-06-09 21:52:42,478][root][INFO] - Step 23557120 @ 3581.4 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (step = 23557120, mean_episode_return = None, mean_episode_step = 1986.2, total_loss = 367.77, pg_loss = 255.17, baseline_loss = 117.44, entropy_loss = -4.8399, learner_queue_size = 32, _tick = 4610, _time = 1.6548e+09, train_seconds = 6282.3)
[2022-06-09 21:52:47,482][root][INFO] - Step 23577600 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 23577600, mean_episode_return = 13.58, mean_episode_step = 1849.2, total_loss = 241.29, pg_loss = 184.45, baseline_loss = 61.625, entropy_loss = -4.7824, learner_queue_size = 32, _tick = 4613, _time = 1.6548e+09, train_seconds = 6287.3)
[2022-06-09 21:52:52,486][root][INFO] - Step 23595520 @ 3581.2 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 23595520, mean_episode_return = None, mean_episode_step = 1730.6, total_loss = 270.62, pg_loss = 158.39, baseline_loss = 117.08, entropy_loss = -4.8499, learner_queue_size = 32, _tick = 4615, _time = 1.6548e+09, train_seconds = 6292.3)
[2022-06-09 21:52:57,490][root][INFO] - Step 23613440 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 23613440, mean_episode_return = None, mean_episode_step = 1429.3, total_loss = -166.61, pg_loss = -163.32, baseline_loss = 1.5909, entropy_loss = -4.8766, learner_queue_size = 32, _tick = 4619, _time = 1.6548e+09, train_seconds = 6297.3)
[2022-06-09 21:53:02,494][root][INFO] - Step 23631360 @ 3580.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 23631360, mean_episode_return = 57.013, mean_episode_step = 1605.9, total_loss = 410.65, pg_loss = 255.74, baseline_loss = 159.84, entropy_loss = -4.943, learner_queue_size = 32, _tick = 4622, _time = 1.6548e+09, train_seconds = 6302.3)
[2022-06-09 21:53:07,498][root][INFO] - Step 23651840 @ 4093.2 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 23651840, mean_episode_return = None, mean_episode_step = 1798.3, total_loss = 19.847, pg_loss = -5.695, baseline_loss = 30.438, entropy_loss = -4.8956, learner_queue_size = 32, _tick = 4626, _time = 1.6548e+09, train_seconds = 6307.3)
[2022-06-09 21:53:12,502][root][INFO] - Step 23669760 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 23669760, mean_episode_return = None, mean_episode_step = 2250.5, total_loss = -167.82, pg_loss = -164.57, baseline_loss = 1.7293, entropy_loss = -4.9808, learner_queue_size = 32, _tick = 4632, _time = 1.6548e+09, train_seconds = 6312.3)
[2022-06-09 21:53:17,506][root][INFO] - Step 23690240 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 23690240, mean_episode_return = 92.957, mean_episode_step = 1630.5, total_loss = 156.59, pg_loss = 75.525, baseline_loss = 85.949, entropy_loss = -4.8828, learner_queue_size = 32, _tick = 4637, _time = 1.6548e+09, train_seconds = 6317.3)
[2022-06-09 21:53:22,510][root][INFO] - Step 23708160 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 23708160, mean_episode_return = 107.74, mean_episode_step = 1961.2, total_loss = 125.51, pg_loss = 65.851, baseline_loss = 64.522, entropy_loss = -4.8622, learner_queue_size = 32, _tick = 4641, _time = 1.6548e+09, train_seconds = 6322.3)
[2022-06-09 21:53:27,514][root][INFO] - Step 23726080 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 23726080, mean_episode_return = 64.117, mean_episode_step = 1634.8, total_loss = 238.94, pg_loss = 127.37, baseline_loss = 116.43, entropy_loss = -4.8539, learner_queue_size = 32, _tick = 4646, _time = 1.6548e+09, train_seconds = 6327.3)
[2022-06-09 21:53:32,518][root][INFO] - Step 23746560 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 23746560, mean_episode_return = 34.736, mean_episode_step = 2043.1, total_loss = -103.53, pg_loss = -111.52, baseline_loss = 12.929, entropy_loss = -4.9373, learner_queue_size = 32, _tick = 4653, _time = 1.6548e+09, train_seconds = 6332.3)
[2022-06-09 21:53:37,522][root][INFO] - Step 23764480 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 23764480, mean_episode_return = 88.238, mean_episode_step = 1744.9, total_loss = 221.42, pg_loss = 130.8, baseline_loss = 95.6, entropy_loss = -4.9848, learner_queue_size = 32, _tick = 4657, _time = 1.6548e+09, train_seconds = 6337.3)
[2022-06-09 21:53:42,530][root][INFO] - Step 23784960 @ 4089.3 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 23784960, mean_episode_return = 45.979, mean_episode_step = 2032.8, total_loss = -29.471, pg_loss = -100.5, baseline_loss = 76.017, entropy_loss = -4.9858, learner_queue_size = 32, _tick = 4663, _time = 1.6548e+09, train_seconds = 6342.3)
[2022-06-09 21:53:47,534][root][INFO] - Step 23802880 @ 3581.3 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 23802880, mean_episode_return = -3.0302, mean_episode_step = 2204.8, total_loss = -230.01, pg_loss = -239.64, baseline_loss = 14.517, entropy_loss = -4.8838, learner_queue_size = 32, _tick = 4666, _time = 1.6548e+09, train_seconds = 6347.3)
[2022-06-09 21:53:52,539][root][INFO] - Step 23820800 @ 3580.6 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 23820800, mean_episode_return = None, mean_episode_step = 2160.2, total_loss = 424.11, pg_loss = 304.87, baseline_loss = 124.07, entropy_loss = -4.8283, learner_queue_size = 32, _tick = 4670, _time = 1.6548e+09, train_seconds = 6352.3)
[2022-06-09 21:53:57,542][root][INFO] - Step 23841280 @ 4093.3 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 23841280, mean_episode_return = 53.063, mean_episode_step = 2029.7, total_loss = 25.934, pg_loss = -6.9034, baseline_loss = 37.348, entropy_loss = -4.5109, learner_queue_size = 32, _tick = 4676, _time = 1.6548e+09, train_seconds = 6357.3)
[2022-06-09 21:54:02,546][root][INFO] - Step 23859200 @ 3581.2 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 23859200, mean_episode_return = 15.58, mean_episode_step = 1093.9, total_loss = 118.84, pg_loss = 58.52, baseline_loss = 63.999, entropy_loss = -3.6835, learner_queue_size = 32, _tick = 4680, _time = 1.6548e+09, train_seconds = 6362.4)
[2022-06-09 21:54:07,550][root][INFO] - Step 23879680 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 23879680, mean_episode_return = None, mean_episode_step = 1345.4, total_loss = 43.507, pg_loss = 22.179, baseline_loss = 26.111, entropy_loss = -4.7824, learner_queue_size = 32, _tick = 4680, _time = 1.6548e+09, train_seconds = 6367.4)
[2022-06-09 21:54:12,554][root][INFO] - Step 23897600 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 23897600, mean_episode_return = 24.17, mean_episode_step = 1814.5, total_loss = 58.095, pg_loss = 31.065, baseline_loss = 31.894, entropy_loss = -4.8637, learner_queue_size = 32, _tick = 4686, _time = 1.6548e+09, train_seconds = 6372.4)
[2022-06-09 21:54:17,558][root][INFO] - Step 23918080 @ 4092.6 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 23918080, mean_episode_return = None, mean_episode_step = 2247.8, total_loss = 217.4, pg_loss = 148.41, baseline_loss = 73.939, entropy_loss = -4.9462, learner_queue_size = 32, _tick = 4689, _time = 1.6548e+09, train_seconds = 6377.4)
[2022-06-09 21:54:22,562][root][INFO] - Step 23936000 @ 3581.3 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 23936000, mean_episode_return = None, mean_episode_step = 1628.5, total_loss = 116.24, pg_loss = 60.521, baseline_loss = 60.625, entropy_loss = -4.9084, learner_queue_size = 32, _tick = 4691, _time = 1.6548e+09, train_seconds = 6382.4)
[2022-06-09 21:54:27,566][root][INFO] - Step 23956480 @ 4092.7 SPS. Inference batcher size: 78. Learner queue size: 32. Other stats: (step = 23956480, mean_episode_return = 70.006, mean_episode_step = 1895.0, total_loss = -251.67, pg_loss = -265.93, baseline_loss = 19.179, entropy_loss = -4.9152, learner_queue_size = 32, _tick = 4693, _time = 1.6548e+09, train_seconds = 6387.4)
[2022-06-09 21:54:32,570][root][INFO] - Step 23974400 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 23974400, mean_episode_return = None, mean_episode_step = 1993.0, total_loss = 130.82, pg_loss = 94.027, baseline_loss = 41.915, entropy_loss = -5.1256, learner_queue_size = 32, _tick = 4697, _time = 1.6548e+09, train_seconds = 6392.4)
[2022-06-09 21:54:37,574][root][INFO] - Step 23994880 @ 4092.7 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 23994880, mean_episode_return = 48.392, mean_episode_step = 1914.5, total_loss = 679.37, pg_loss = 316.25, baseline_loss = 368.28, entropy_loss = -5.1533, learner_queue_size = 32, _tick = 4701, _time = 1.6548e+09, train_seconds = 6397.4)
[2022-06-09 21:54:42,578][root][INFO] - Step 24012800 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 24012800, mean_episode_return = None, mean_episode_step = 1879.6, total_loss = 333.84, pg_loss = 240.77, baseline_loss = 98.221, entropy_loss = -5.1556, learner_queue_size = 32, _tick = 4703, _time = 1.6548e+09, train_seconds = 6402.4)
[2022-06-09 21:54:47,582][root][INFO] - Step 24030720 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 24030720, mean_episode_return = 73.29, mean_episode_step = 1609.7, total_loss = 15.184, pg_loss = -45.529, baseline_loss = 65.843, entropy_loss = -5.1294, learner_queue_size = 32, _tick = 4707, _time = 1.6548e+09, train_seconds = 6407.4)
[2022-06-09 21:54:52,586][root][INFO] - Step 24051200 @ 4092.7 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 24051200, mean_episode_return = 51.399, mean_episode_step = 1434.6, total_loss = -183.85, pg_loss = -230.34, baseline_loss = 51.609, entropy_loss = -5.1249, learner_queue_size = 32, _tick = 4714, _time = 1.6548e+09, train_seconds = 6412.4)
[2022-06-09 21:54:57,590][root][INFO] - Step 24069120 @ 3580.9 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 24069120, mean_episode_return = 18.4, mean_episode_step = 1570.6, total_loss = 217.31, pg_loss = 149.67, baseline_loss = 72.612, entropy_loss = -4.972, learner_queue_size = 32, _tick = 4721, _time = 1.6548e+09, train_seconds = 6417.4)
[2022-06-09 21:55:02,594][root][INFO] - Step 24087040 @ 3581.3 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 24087040, mean_episode_return = None, mean_episode_step = 1871.3, total_loss = -62.842, pg_loss = -72.478, baseline_loss = 14.512, entropy_loss = -4.8761, learner_queue_size = 32, _tick = 4727, _time = 1.6548e+09, train_seconds = 6422.4)
[2022-06-09 21:55:07,598][root][INFO] - Step 24107520 @ 4092.6 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 24107520, mean_episode_return = 65.711, mean_episode_step = 2290.4, total_loss = 242.22, pg_loss = 149.42, baseline_loss = 97.783, entropy_loss = -4.9766, learner_queue_size = 32, _tick = 4730, _time = 1.6548e+09, train_seconds = 6427.4)
[2022-06-09 21:55:12,602][root][INFO] - Step 24125440 @ 3581.3 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 24125440, mean_episode_return = 48.539, mean_episode_step = 2164.0, total_loss = -88.946, pg_loss = -103.93, baseline_loss = 20.114, entropy_loss = -5.1296, learner_queue_size = 32, _tick = 4736, _time = 1.6548e+09, train_seconds = 6432.4)
[2022-06-09 21:55:17,606][root][INFO] - Step 24145920 @ 4092.7 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 24145920, mean_episode_return = 119.98, mean_episode_step = 2016.9, total_loss = 119.12, pg_loss = 64.286, baseline_loss = 59.973, entropy_loss = -5.1427, learner_queue_size = 32, _tick = 4743, _time = 1.6548e+09, train_seconds = 6437.4)
[2022-06-09 21:55:22,610][root][INFO] - Step 24163840 @ 3581.0 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 24163840, mean_episode_return = 32.77, mean_episode_step = 1779.7, total_loss = -193.45, pg_loss = -250.07, baseline_loss = 61.59, entropy_loss = -4.9675, learner_queue_size = 32, _tick = 4747, _time = 1.6548e+09, train_seconds = 6442.4)
[2022-06-09 21:55:27,614][root][INFO] - Step 24181760 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 24181760, mean_episode_return = None, mean_episode_step = 1581.7, total_loss = 51.393, pg_loss = 8.8991, baseline_loss = 47.463, entropy_loss = -4.9696, learner_queue_size = 32, _tick = 4753, _time = 1.6548e+09, train_seconds = 6447.4)
[2022-06-09 21:55:32,619][root][INFO] - Step 24199680 @ 3580.4 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 24199680, mean_episode_return = 92.325, mean_episode_step = 1949.8, total_loss = 220.64, pg_loss = 98.875, baseline_loss = 126.3, entropy_loss = -4.5369, learner_queue_size = 32, _tick = 4758, _time = 1.6548e+09, train_seconds = 6452.4)
[2022-06-09 21:55:37,622][root][INFO] - Step 24220160 @ 4093.6 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 24220160, mean_episode_return = None, mean_episode_step = 1226.3, total_loss = 152.91, pg_loss = 86.856, baseline_loss = 70.811, entropy_loss = -4.7587, learner_queue_size = 32, _tick = 4763, _time = 1.6548e+09, train_seconds = 6457.4)
[2022-06-09 21:55:42,626][root][INFO] - Step 24238080 @ 3581.1 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 24238080, mean_episode_return = None, mean_episode_step = 1647.1, total_loss = -71.073, pg_loss = -77.959, baseline_loss = 11.722, entropy_loss = -4.8357, learner_queue_size = 32, _tick = 4765, _time = 1.6548e+09, train_seconds = 6462.4)
[2022-06-09 21:55:47,630][root][INFO] - Step 24258560 @ 4092.6 SPS. Inference batcher size: 83. Learner queue size: 32. Other stats: (step = 24258560, mean_episode_return = None, mean_episode_step = 2163.0, total_loss = 125.3, pg_loss = 75.31, baseline_loss = 55.024, entropy_loss = -5.0291, learner_queue_size = 32, _tick = 4772, _time = 1.6548e+09, train_seconds = 6467.4)
[2022-06-09 21:55:52,634][root][INFO] - Step 24276480 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 24276480, mean_episode_return = 112.62, mean_episode_step = 1897.4, total_loss = -60.194, pg_loss = -65.063, baseline_loss = 9.2188, entropy_loss = -4.35, learner_queue_size = 32, _tick = 4776, _time = 1.6548e+09, train_seconds = 6472.4)
[2022-06-09 21:55:57,639][root][INFO] - Step 24296960 @ 4092.2 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (step = 24296960, mean_episode_return = None, mean_episode_step = 1915.2, total_loss = -68.335, pg_loss = -68.912, baseline_loss = 4.2047, entropy_loss = -3.628, learner_queue_size = 32, _tick = 4781, _time = 1.6548e+09, train_seconds = 6477.4)
[2022-06-09 21:56:02,642][root][INFO] - Step 24314880 @ 3581.7 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (step = 24314880, mean_episode_return = 39.205, mean_episode_step = 1858.9, total_loss = -108.19, pg_loss = -128.32, baseline_loss = 24.378, entropy_loss = -4.2451, learner_queue_size = 32, _tick = 4783, _time = 1.6548e+09, train_seconds = 6482.4)
[2022-06-09 21:56:07,646][root][INFO] - Step 24332800 @ 3581.1 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 24332800, mean_episode_return = None, mean_episode_step = 1754.4, total_loss = 255.27, pg_loss = 187.77, baseline_loss = 72.668, entropy_loss = -5.1692, learner_queue_size = 32, _tick = 4786, _time = 1.6548e+09, train_seconds = 6487.5)
[2022-06-09 21:56:12,650][root][INFO] - Step 24353280 @ 4092.8 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 24353280, mean_episode_return = 34.37, mean_episode_step = 1844.9, total_loss = 437.2, pg_loss = 296.98, baseline_loss = 145.6, entropy_loss = -5.3765, learner_queue_size = 32, _tick = 4791, _time = 1.6548e+09, train_seconds = 6492.5)
[2022-06-09 21:56:17,654][root][INFO] - Step 24371200 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 24371200, mean_episode_return = 47.323, mean_episode_step = 1811.4, total_loss = -115.1, pg_loss = -127.21, baseline_loss = 17.51, entropy_loss = -5.3999, learner_queue_size = 32, _tick = 4797, _time = 1.6548e+09, train_seconds = 6497.5)
[2022-06-09 21:56:22,658][root][INFO] - Step 24391680 @ 4092.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 24391680, mean_episode_return = None, mean_episode_step = 1615.0, total_loss = 389.86, pg_loss = 290.46, baseline_loss = 104.55, entropy_loss = -5.14, learner_queue_size = 32, _tick = 4802, _time = 1.6548e+09, train_seconds = 6502.5)
[2022-06-09 21:56:27,662][root][INFO] - Step 24409600 @ 3581.1 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 24409600, mean_episode_return = 30.981, mean_episode_step = 1789.1, total_loss = -73.212, pg_loss = -71.558, baseline_loss = 3.0311, entropy_loss = -4.685, learner_queue_size = 32, _tick = 4808, _time = 1.6548e+09, train_seconds = 6507.5)
[2022-06-09 21:56:32,666][root][INFO] - Step 24427520 @ 3581.2 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 24427520, mean_episode_return = 48.46, mean_episode_step = 2088.9, total_loss = -43.493, pg_loss = -44.395, baseline_loss = 5.4771, entropy_loss = -4.5748, learner_queue_size = 32, _tick = 4812, _time = 1.6548e+09, train_seconds = 6512.5)
[2022-06-09 21:56:37,670][root][INFO] - Step 24448000 @ 4092.7 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 24448000, mean_episode_return = 23.345, mean_episode_step = 1308.5, total_loss = 102.54, pg_loss = 34.955, baseline_loss = 72.647, entropy_loss = -5.0602, learner_queue_size = 32, _tick = 4816, _time = 1.6548e+09, train_seconds = 6517.5)
[2022-06-09 21:56:42,674][root][INFO] - Step 24465920 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 24465920, mean_episode_return = 26.311, mean_episode_step = 1878.6, total_loss = 71.102, pg_loss = 47.073, baseline_loss = 29.238, entropy_loss = -5.2097, learner_queue_size = 32, _tick = 4822, _time = 1.6548e+09, train_seconds = 6522.5)
[2022-06-09 21:56:47,678][root][INFO] - Step 24483840 @ 3581.1 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 24483840, mean_episode_return = 101.3, mean_episode_step = 1652.6, total_loss = 497.93, pg_loss = 326.9, baseline_loss = 176.14, entropy_loss = -5.1055, learner_queue_size = 32, _tick = 4829, _time = 1.6548e+09, train_seconds = 6527.5)
[2022-06-09 21:56:52,682][root][INFO] - Step 24504320 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 24504320, mean_episode_return = 65.141, mean_episode_step = 1447.8, total_loss = 92.837, pg_loss = 58.23, baseline_loss = 39.808, entropy_loss = -5.2007, learner_queue_size = 32, _tick = 4835, _time = 1.6548e+09, train_seconds = 6532.5)
[2022-06-09 21:56:57,686][root][INFO] - Step 24522240 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 24522240, mean_episode_return = 27.317, mean_episode_step = 1574.5, total_loss = 76.475, pg_loss = 23.06, baseline_loss = 58.591, entropy_loss = -5.1761, learner_queue_size = 32, _tick = 4841, _time = 1.6548e+09, train_seconds = 6537.5)
[2022-06-09 21:57:02,690][root][INFO] - Step 24542720 @ 4092.7 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 24542720, mean_episode_return = 28.032, mean_episode_step = 1777.3, total_loss = 39.382, pg_loss = 15.621, baseline_loss = 28.304, entropy_loss = -4.543, learner_queue_size = 32, _tick = 4847, _time = 1.6548e+09, train_seconds = 6542.5)
[2022-06-09 21:57:07,695][root][INFO] - Step 24560640 @ 3580.9 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 24560640, mean_episode_return = None, mean_episode_step = 1809.7, total_loss = -71.847, pg_loss = -72.998, baseline_loss = 5.9316, entropy_loss = -4.7802, learner_queue_size = 32, _tick = 4849, _time = 1.6548e+09, train_seconds = 6547.5)
[2022-06-09 21:57:12,698][root][INFO] - Step 24578560 @ 3581.3 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 24578560, mean_episode_return = 4.8197, mean_episode_step = 1547.3, total_loss = -11.383, pg_loss = -55.877, baseline_loss = 49.346, entropy_loss = -4.8512, learner_queue_size = 32, _tick = 4855, _time = 1.6548e+09, train_seconds = 6552.5)
[2022-06-09 21:57:17,702][root][INFO] - Step 24596480 @ 3581.2 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 24596480, mean_episode_return = -5.7703, mean_episode_step = 1045.6, total_loss = 236.33, pg_loss = 137.54, baseline_loss = 103.56, entropy_loss = -4.7727, learner_queue_size = 32, _tick = 4857, _time = 1.6548e+09, train_seconds = 6557.5)
[2022-06-09 21:57:22,706][root][INFO] - Step 24616960 @ 4092.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 24616960, mean_episode_return = 51.62, mean_episode_step = 2222.2, total_loss = -194.1, pg_loss = -202.48, baseline_loss = 13.326, entropy_loss = -4.9411, learner_queue_size = 32, _tick = 4862, _time = 1.6548e+09, train_seconds = 6562.5)
[2022-06-09 21:57:27,710][root][INFO] - Step 24634880 @ 3581.2 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 24634880, mean_episode_return = 94.03, mean_episode_step = 1350.4, total_loss = 267.68, pg_loss = 176.06, baseline_loss = 96.599, entropy_loss = -4.9751, learner_queue_size = 32, _tick = 4865, _time = 1.6548e+09, train_seconds = 6567.5)
[2022-06-09 21:57:32,714][root][INFO] - Step 24652800 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 24652800, mean_episode_return = 70.507, mean_episode_step = 2051.6, total_loss = -27.694, pg_loss = -70.988, baseline_loss = 48.339, entropy_loss = -5.0447, learner_queue_size = 32, _tick = 4871, _time = 1.6548e+09, train_seconds = 6572.5)
[2022-06-09 21:57:37,718][root][INFO] - Step 24673280 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 24673280, mean_episode_return = 76.33, mean_episode_step = 1524.0, total_loss = 66.039, pg_loss = 29.549, baseline_loss = 41.142, entropy_loss = -4.652, learner_queue_size = 32, _tick = 4876, _time = 1.6548e+09, train_seconds = 6577.5)
[2022-06-09 21:57:42,722][root][INFO] - Step 24691200 @ 3581.2 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (step = 24691200, mean_episode_return = 76.121, mean_episode_step = 1488.9, total_loss = -86.541, pg_loss = -94.756, baseline_loss = 12.793, entropy_loss = -4.5778, learner_queue_size = 32, _tick = 4882, _time = 1.6548e+09, train_seconds = 6582.5)
[2022-06-09 21:57:47,726][root][INFO] - Step 24709120 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 24709120, mean_episode_return = 183.82, mean_episode_step = 2143.7, total_loss = -35.783, pg_loss = -56.45, baseline_loss = 25.309, entropy_loss = -4.6428, learner_queue_size = 32, _tick = 4886, _time = 1.6548e+09, train_seconds = 6587.5)
[2022-06-09 21:57:52,730][root][INFO] - Step 24729600 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 24729600, mean_episode_return = 83.419, mean_episode_step = 1936.5, total_loss = 264.76, pg_loss = 171.36, baseline_loss = 98.206, entropy_loss = -4.8016, learner_queue_size = 32, _tick = 4892, _time = 1.6548e+09, train_seconds = 6592.5)
[2022-06-09 21:57:57,734][root][INFO] - Step 24747520 @ 3581.2 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 24747520, mean_episode_return = 152.84, mean_episode_step = 1581.6, total_loss = 25.317, pg_loss = 1.2562, baseline_loss = 28.946, entropy_loss = -4.8856, learner_queue_size = 32, _tick = 4896, _time = 1.6548e+09, train_seconds = 6597.5)
[2022-06-09 21:58:02,738][root][INFO] - Step 24768000 @ 4092.4 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 24768000, mean_episode_return = 65.55, mean_episode_step = 1284.3, total_loss = -93.109, pg_loss = -98.855, baseline_loss = 10.664, entropy_loss = -4.9188, learner_queue_size = 32, _tick = 4901, _time = 1.6548e+09, train_seconds = 6602.5)
[2022-06-09 21:58:07,746][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-09 21:58:07,888][root][INFO] - Step 24785920 @ 3578.5 SPS. Inference batcher size: 75. Learner queue size: 32. Other stats: (step = 24785920, mean_episode_return = 62.641, mean_episode_step = 1816.3, total_loss = -0.049338, pg_loss = -47.085, baseline_loss = 51.794, entropy_loss = -4.7584, learner_queue_size = 32, _tick = 4905, _time = 1.6548e+09, train_seconds = 6607.6)
[2022-06-09 21:58:12,890][root][INFO] - Step 24803840 @ 3483.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 24803840, mean_episode_return = None, mean_episode_step = 2113.0, total_loss = -14.544, pg_loss = -21.1, baseline_loss = 11.466, entropy_loss = -4.9106, learner_queue_size = 32, _tick = 4909, _time = 1.6548e+09, train_seconds = 6612.7)
[2022-06-09 21:58:17,894][root][INFO] - Step 24824320 @ 4092.7 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 24824320, mean_episode_return = 16.48, mean_episode_step = 1217.2, total_loss = 87.882, pg_loss = 46.441, baseline_loss = 46.429, entropy_loss = -4.988, learner_queue_size = 32, _tick = 4914, _time = 1.6548e+09, train_seconds = 6617.7)
[2022-06-09 21:58:22,898][root][INFO] - Step 24842240 @ 3581.2 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 24842240, mean_episode_return = None, mean_episode_step = 2118.0, total_loss = 156.39, pg_loss = 92.744, baseline_loss = 68.709, entropy_loss = -5.0579, learner_queue_size = 32, _tick = 4920, _time = 1.6548e+09, train_seconds = 6622.7)
[2022-06-09 21:58:27,902][root][INFO] - Step 24860160 @ 3581.0 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 24860160, mean_episode_return = 46.034, mean_episode_step = 2022.1, total_loss = -150.08, pg_loss = -172.49, baseline_loss = 27.303, entropy_loss = -4.8866, learner_queue_size = 32, _tick = 4925, _time = 1.6548e+09, train_seconds = 6627.7)
[2022-06-09 21:58:32,906][root][INFO] - Step 24878080 @ 3581.3 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (step = 24878080, mean_episode_return = 41.781, mean_episode_step = 1406.8, total_loss = 309.15, pg_loss = 191.96, baseline_loss = 122.16, entropy_loss = -4.9749, learner_queue_size = 32, _tick = 4929, _time = 1.6548e+09, train_seconds = 6632.7)
[2022-06-09 21:58:37,910][root][INFO] - Step 24898560 @ 4092.5 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (step = 24898560, mean_episode_return = 65.104, mean_episode_step = 1623.0, total_loss = 253.28, pg_loss = 161.29, baseline_loss = 96.631, entropy_loss = -4.6334, learner_queue_size = 32, _tick = 4935, _time = 1.6548e+09, train_seconds = 6637.7)
[2022-06-09 21:58:42,914][root][INFO] - Step 24916480 @ 3581.3 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 24916480, mean_episode_return = None, mean_episode_step = 1854.8, total_loss = 97.27, pg_loss = 62.807, baseline_loss = 39.269, entropy_loss = -4.8055, learner_queue_size = 32, _tick = 4940, _time = 1.6548e+09, train_seconds = 6642.7)
[2022-06-09 21:58:47,919][root][INFO] - Step 24936960 @ 4092.4 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 24936960, mean_episode_return = 31.163, mean_episode_step = 1925.2, total_loss = 107.82, pg_loss = 48.575, baseline_loss = 64.01, entropy_loss = -4.7612, learner_queue_size = 32, _tick = 4946, _time = 1.6548e+09, train_seconds = 6647.7)
[2022-06-09 21:58:52,922][root][INFO] - Step 24954880 @ 3581.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 24954880, mean_episode_return = None, mean_episode_step = 1597.2, total_loss = 89.34, pg_loss = 53.689, baseline_loss = 39.76, entropy_loss = -4.1089, learner_queue_size = 32, _tick = 4948, _time = 1.6548e+09, train_seconds = 6652.7)
[2022-06-09 21:58:57,926][root][INFO] - Step 24975360 @ 4092.7 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 24975360, mean_episode_return = None, mean_episode_step = 1401.2, total_loss = -33.716, pg_loss = -43.756, baseline_loss = 14.654, entropy_loss = -4.613, learner_queue_size = 32, _tick = 4951, _time = 1.6548e+09, train_seconds = 6657.7)
[2022-06-09 21:59:02,930][root][INFO] - Step 24993280 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 24993280, mean_episode_return = None, mean_episode_step = 1783.8, total_loss = -126.15, pg_loss = -124.18, baseline_loss = 2.7946, entropy_loss = -4.7665, learner_queue_size = 32, _tick = 4954, _time = 1.6548e+09, train_seconds = 6662.7)
[2022-06-09 21:59:07,934][root][INFO] - Step 25013760 @ 4092.8 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 25013760, mean_episode_return = -36.868, mean_episode_step = 2126.5, total_loss = 143.35, pg_loss = 46.273, baseline_loss = 102.09, entropy_loss = -5.0094, learner_queue_size = 32, _tick = 4959, _time = 1.6548e+09, train_seconds = 6667.7)
[2022-06-09 21:59:12,939][root][INFO] - Step 25031680 @ 3580.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 25031680, mean_episode_return = 29.16, mean_episode_step = 1624.2, total_loss = 226.04, pg_loss = 103.54, baseline_loss = 127.48, entropy_loss = -4.9772, learner_queue_size = 32, _tick = 4965, _time = 1.6548e+09, train_seconds = 6672.7)
[2022-06-09 21:59:17,942][root][INFO] - Step 25049600 @ 3581.6 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 25049600, mean_episode_return = None, mean_episode_step = 1325.0, total_loss = 229.56, pg_loss = 119.11, baseline_loss = 115.42, entropy_loss = -4.9734, learner_queue_size = 32, _tick = 4970, _time = 1.6548e+09, train_seconds = 6677.7)
[2022-06-09 21:59:22,946][root][INFO] - Step 25070080 @ 4092.6 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 25070080, mean_episode_return = None, mean_episode_step = 1366.5, total_loss = -1.4195, pg_loss = -18.627, baseline_loss = 21.922, entropy_loss = -4.7145, learner_queue_size = 32, _tick = 4977, _time = 1.6548e+09, train_seconds = 6682.8)
[2022-06-09 21:59:27,950][root][INFO] - Step 25088000 @ 3581.2 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 25088000, mean_episode_return = 144.09, mean_episode_step = 1587.8, total_loss = 158.21, pg_loss = 86.278, baseline_loss = 76.591, entropy_loss = -4.6541, learner_queue_size = 32, _tick = 4980, _time = 1.6548e+09, train_seconds = 6687.8)
[2022-06-09 21:59:32,954][root][INFO] - Step 25105920 @ 3581.2 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 25105920, mean_episode_return = 42.45, mean_episode_step = 1441.2, total_loss = -113.59, pg_loss = -155.85, baseline_loss = 47.086, entropy_loss = -4.8308, learner_queue_size = 32, _tick = 4986, _time = 1.6548e+09, train_seconds = 6692.8)
[2022-06-09 21:59:37,958][root][INFO] - Step 25126400 @ 4092.7 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 25126400, mean_episode_return = 22.99, mean_episode_step = 1956.5, total_loss = 30.285, pg_loss = 2.235, baseline_loss = 32.718, entropy_loss = -4.6682, learner_queue_size = 32, _tick = 4993, _time = 1.6548e+09, train_seconds = 6697.8)
[2022-06-09 21:59:42,962][root][INFO] - Step 25144320 @ 3580.8 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 25144320, mean_episode_return = -5.85, mean_episode_step = 1638.9, total_loss = -121.66, pg_loss = -146.06, baseline_loss = 29.075, entropy_loss = -4.6728, learner_queue_size = 32, _tick = 4996, _time = 1.6548e+09, train_seconds = 6702.8)
[2022-06-09 21:59:47,966][root][INFO] - Step 25162240 @ 3581.4 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 25162240, mean_episode_return = None, mean_episode_step = 1966.0, total_loss = 22.68, pg_loss = 2.795, baseline_loss = 24.844, entropy_loss = -4.9595, learner_queue_size = 32, _tick = 5000, _time = 1.6548e+09, train_seconds = 6707.8)
[2022-06-09 21:59:52,970][root][INFO] - Step 25182720 @ 4092.8 SPS. Inference batcher size: 83. Learner queue size: 32. Other stats: (step = 25182720, mean_episode_return = None, mean_episode_step = 1763.7, total_loss = -14.192, pg_loss = -25.901, baseline_loss = 16.533, entropy_loss = -4.8234, learner_queue_size = 32, _tick = 5004, _time = 1.6548e+09, train_seconds = 6712.8)
[2022-06-09 21:59:57,974][root][INFO] - Step 25200640 @ 3581.2 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 25200640, mean_episode_return = 0.38965, mean_episode_step = 1347.5, total_loss = 4.4406, pg_loss = -17.079, baseline_loss = 26.564, entropy_loss = -5.0446, learner_queue_size = 32, _tick = 5008, _time = 1.6548e+09, train_seconds = 6717.8)
[2022-06-09 22:00:02,978][root][INFO] - Step 25218560 @ 3581.1 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (step = 25218560, mean_episode_return = 48.13, mean_episode_step = 1590.2, total_loss = 132.09, pg_loss = 62.698, baseline_loss = 74.261, entropy_loss = -4.8708, learner_queue_size = 32, _tick = 5014, _time = 1.6548e+09, train_seconds = 6722.8)
[2022-06-09 22:00:07,982][root][INFO] - Step 25239040 @ 4092.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 25239040, mean_episode_return = 27.551, mean_episode_step = 1620.3, total_loss = 165.72, pg_loss = 96.885, baseline_loss = 73.618, entropy_loss = -4.7816, learner_queue_size = 32, _tick = 5019, _time = 1.6548e+09, train_seconds = 6727.8)
[2022-06-09 22:00:12,986][root][INFO] - Step 25256960 @ 3580.9 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 25256960, mean_episode_return = 41.98, mean_episode_step = 1418.9, total_loss = 201.24, pg_loss = 119.35, baseline_loss = 86.559, entropy_loss = -4.6723, learner_queue_size = 32, _tick = 5022, _time = 1.6548e+09, train_seconds = 6732.8)
[2022-06-09 22:00:17,990][root][INFO] - Step 25274880 @ 3581.4 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 25274880, mean_episode_return = 74.544, mean_episode_step = 1541.8, total_loss = 258.59, pg_loss = 86.769, baseline_loss = 176.5, entropy_loss = -4.6828, learner_queue_size = 32, _tick = 5028, _time = 1.6548e+09, train_seconds = 6737.8)
[2022-06-09 22:00:22,994][root][INFO] - Step 25295360 @ 4092.7 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (step = 25295360, mean_episode_return = 32.365, mean_episode_step = 1586.2, total_loss = 73.191, pg_loss = 27.744, baseline_loss = 49.928, entropy_loss = -4.4806, learner_queue_size = 32, _tick = 5033, _time = 1.6548e+09, train_seconds = 6742.8)
[2022-06-09 22:00:28,000][root][INFO] - Step 25313280 @ 3580.0 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 25313280, mean_episode_return = None, mean_episode_step = 1571.4, total_loss = -120.6, pg_loss = -122.29, baseline_loss = 6.2789, entropy_loss = -4.585, learner_queue_size = 32, _tick = 5035, _time = 1.6548e+09, train_seconds = 6747.8)
[2022-06-09 22:00:33,002][root][INFO] - Step 25333760 @ 4094.0 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (step = 25333760, mean_episode_return = 101.93, mean_episode_step = 1653.6, total_loss = 28.547, pg_loss = -1.852, baseline_loss = 34.731, entropy_loss = -4.3321, learner_queue_size = 32, _tick = 5043, _time = 1.6548e+09, train_seconds = 6752.8)
[2022-06-09 22:00:38,006][root][INFO] - Step 25351680 @ 3581.2 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 25351680, mean_episode_return = None, mean_episode_step = 1870.3, total_loss = 339.03, pg_loss = 235.1, baseline_loss = 108.42, entropy_loss = -4.4881, learner_queue_size = 32, _tick = 5047, _time = 1.6548e+09, train_seconds = 6757.8)
[2022-06-09 22:00:43,010][root][INFO] - Step 25369600 @ 3581.1 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 25369600, mean_episode_return = None, mean_episode_step = 1599.0, total_loss = 6.3546, pg_loss = -14.951, baseline_loss = 25.66, entropy_loss = -4.3549, learner_queue_size = 32, _tick = 5053, _time = 1.6548e+09, train_seconds = 6762.8)
[2022-06-09 22:00:48,014][root][INFO] - Step 25387520 @ 3581.2 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 25387520, mean_episode_return = 50.469, mean_episode_step = 1943.1, total_loss = 30.988, pg_loss = -11.866, baseline_loss = 47.6, entropy_loss = -4.7461, learner_queue_size = 32, _tick = 5059, _time = 1.6548e+09, train_seconds = 6767.8)
[2022-06-09 22:00:53,018][root][INFO] - Step 25408000 @ 4092.7 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 25408000, mean_episode_return = 62.82, mean_episode_step = 1549.1, total_loss = -73.129, pg_loss = -104.75, baseline_loss = 36.518, entropy_loss = -4.895, learner_queue_size = 32, _tick = 5067, _time = 1.6548e+09, train_seconds = 6772.8)
[2022-06-09 22:00:58,022][root][INFO] - Step 25425920 @ 3581.2 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 25425920, mean_episode_return = 111.12, mean_episode_step = 1327.2, total_loss = 81.187, pg_loss = 47.295, baseline_loss = 38.155, entropy_loss = -4.2634, learner_queue_size = 32, _tick = 5071, _time = 1.6548e+09, train_seconds = 6777.8)
[2022-06-09 22:01:03,026][root][INFO] - Step 25446400 @ 4092.7 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 25446400, mean_episode_return = 109.11, mean_episode_step = 1213.2, total_loss = -32.925, pg_loss = -57.922, baseline_loss = 29.599, entropy_loss = -4.6017, learner_queue_size = 32, _tick = 5078, _time = 1.6548e+09, train_seconds = 6782.8)
[2022-06-09 22:01:08,030][root][INFO] - Step 25464320 @ 3581.1 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 25464320, mean_episode_return = None, mean_episode_step = 1259.2, total_loss = 85.538, pg_loss = 40.492, baseline_loss = 49.869, entropy_loss = -4.8231, learner_queue_size = 32, _tick = 5081, _time = 1.6548e+09, train_seconds = 6787.8)
[2022-06-09 22:01:13,034][root][INFO] - Step 25482240 @ 3581.1 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 25482240, mean_episode_return = None, mean_episode_step = 1629.3, total_loss = -24.504, pg_loss = -38.632, baseline_loss = 19.044, entropy_loss = -4.9158, learner_queue_size = 32, _tick = 5082, _time = 1.6548e+09, train_seconds = 6792.8)
[2022-06-09 22:01:18,038][root][INFO] - Step 25502720 @ 4092.7 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 25502720, mean_episode_return = None, mean_episode_step = 1800.6, total_loss = 11.67, pg_loss = 0.30601, baseline_loss = 16.355, entropy_loss = -4.991, learner_queue_size = 32, _tick = 5087, _time = 1.6548e+09, train_seconds = 6797.8)
[2022-06-09 22:01:23,042][root][INFO] - Step 25520640 @ 3581.2 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 25520640, mean_episode_return = 87.069, mean_episode_step = 1543.5, total_loss = -36.254, pg_loss = -62.773, baseline_loss = 31.366, entropy_loss = -4.8473, learner_queue_size = 32, _tick = 5093, _time = 1.6548e+09, train_seconds = 6802.8)
[2022-06-09 22:01:28,046][root][INFO] - Step 25538560 @ 3580.9 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 25538560, mean_episode_return = 23.84, mean_episode_step = 1475.0, total_loss = -58.8, pg_loss = -79.206, baseline_loss = 25.207, entropy_loss = -4.8011, learner_queue_size = 32, _tick = 5098, _time = 1.6548e+09, train_seconds = 6807.9)
[2022-06-09 22:01:33,050][root][INFO] - Step 25559040 @ 4093.0 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 25559040, mean_episode_return = None, mean_episode_step = 1285.2, total_loss = 105.32, pg_loss = 71.737, baseline_loss = 38.51, entropy_loss = -4.9287, learner_queue_size = 32, _tick = 5101, _time = 1.6548e+09, train_seconds = 6812.9)
[2022-06-09 22:01:38,054][root][INFO] - Step 25576960 @ 3581.0 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 25576960, mean_episode_return = None, mean_episode_step = 1844.8, total_loss = -31.218, pg_loss = -53.168, baseline_loss = 26.946, entropy_loss = -4.9966, learner_queue_size = 32, _tick = 5104, _time = 1.6548e+09, train_seconds = 6817.9)
[2022-06-09 22:01:43,058][root][INFO] - Step 25594880 @ 3581.2 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 25594880, mean_episode_return = 23.32, mean_episode_step = 1716.7, total_loss = 77.118, pg_loss = 32.887, baseline_loss = 49.484, entropy_loss = -5.2536, learner_queue_size = 32, _tick = 5109, _time = 1.6548e+09, train_seconds = 6822.9)
[2022-06-09 22:01:48,062][root][INFO] - Step 25612800 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 25612800, mean_episode_return = 12.08, mean_episode_step = 1747.8, total_loss = 541.36, pg_loss = 407.58, baseline_loss = 139.29, entropy_loss = -5.5012, learner_queue_size = 32, _tick = 5114, _time = 1.6548e+09, train_seconds = 6827.9)
[2022-06-09 22:01:53,074][root][INFO] - Step 25633280 @ 4086.2 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 25633280, mean_episode_return = 43.679, mean_episode_step = 1592.3, total_loss = 154.57, pg_loss = 81.561, baseline_loss = 77.937, entropy_loss = -4.9337, learner_queue_size = 32, _tick = 5122, _time = 1.6548e+09, train_seconds = 6832.9)
[2022-06-09 22:01:58,078][root][INFO] - Step 25651200 @ 3581.2 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 25651200, mean_episode_return = 18.59, mean_episode_step = 1147.3, total_loss = 94.381, pg_loss = 46.037, baseline_loss = 52.835, entropy_loss = -4.4898, learner_queue_size = 32, _tick = 5127, _time = 1.6548e+09, train_seconds = 6837.9)
[2022-06-09 22:02:03,082][root][INFO] - Step 25669120 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 25669120, mean_episode_return = 62.976, mean_episode_step = 1458.7, total_loss = 106.83, pg_loss = 51.35, baseline_loss = 60.264, entropy_loss = -4.7835, learner_queue_size = 32, _tick = 5133, _time = 1.6548e+09, train_seconds = 6842.9)
[2022-06-09 22:02:08,089][root][INFO] - Step 25689600 @ 4090.2 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 25689600, mean_episode_return = 22.64, mean_episode_step = 1213.9, total_loss = 51.055, pg_loss = -1.9197, baseline_loss = 57.621, entropy_loss = -4.6467, learner_queue_size = 32, _tick = 5136, _time = 1.6548e+09, train_seconds = 6847.9)
[2022-06-09 22:02:13,094][root][INFO] - Step 25707520 @ 3580.5 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 25707520, mean_episode_return = 51.201, mean_episode_step = 1424.7, total_loss = -103.43, pg_loss = -125.32, baseline_loss = 26.575, entropy_loss = -4.6905, learner_queue_size = 32, _tick = 5141, _time = 1.6548e+09, train_seconds = 6852.9)
[2022-06-09 22:02:18,098][root][INFO] - Step 25725440 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 25725440, mean_episode_return = None, mean_episode_step = 1681.4, total_loss = -82.673, pg_loss = -89.986, baseline_loss = 12.19, entropy_loss = -4.8766, learner_queue_size = 32, _tick = 5145, _time = 1.6548e+09, train_seconds = 6857.9)
[2022-06-09 22:02:23,102][root][INFO] - Step 25745920 @ 4092.4 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (step = 25745920, mean_episode_return = 60.62, mean_episode_step = 1571.3, total_loss = -42.651, pg_loss = -139.92, baseline_loss = 101.91, entropy_loss = -4.6408, learner_queue_size = 32, _tick = 5148, _time = 1.6548e+09, train_seconds = 6862.9)
[2022-06-09 22:02:28,106][root][INFO] - Step 25763840 @ 3581.4 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 25763840, mean_episode_return = 26.029, mean_episode_step = 1357.2, total_loss = 63.607, pg_loss = 33.654, baseline_loss = 35.155, entropy_loss = -5.2009, learner_queue_size = 32, _tick = 5152, _time = 1.6548e+09, train_seconds = 6867.9)
[2022-06-09 22:02:33,110][root][INFO] - Step 25784320 @ 4092.7 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 25784320, mean_episode_return = 32.021, mean_episode_step = 1062.9, total_loss = -89.125, pg_loss = -112.29, baseline_loss = 27.957, entropy_loss = -4.796, learner_queue_size = 32, _tick = 5158, _time = 1.6548e+09, train_seconds = 6872.9)
[2022-06-09 22:02:38,115][root][INFO] - Step 25802240 @ 3580.8 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 25802240, mean_episode_return = None, mean_episode_step = 1370.7, total_loss = 116.48, pg_loss = 65.756, baseline_loss = 55.31, entropy_loss = -4.5864, learner_queue_size = 32, _tick = 5161, _time = 1.6548e+09, train_seconds = 6877.9)
[2022-06-09 22:02:43,118][root][INFO] - Step 25822720 @ 4093.0 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 25822720, mean_episode_return = None, mean_episode_step = 1451.0, total_loss = 113.97, pg_loss = 83.728, baseline_loss = 34.903, entropy_loss = -4.665, learner_queue_size = 32, _tick = 5165, _time = 1.6548e+09, train_seconds = 6882.9)
[2022-06-09 22:02:48,122][root][INFO] - Step 25840640 @ 3581.1 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 25840640, mean_episode_return = 126.56, mean_episode_step = 1829.8, total_loss = 7.4058, pg_loss = -46.195, baseline_loss = 58.326, entropy_loss = -4.725, learner_queue_size = 32, _tick = 5171, _time = 1.6548e+09, train_seconds = 6887.9)
[2022-06-09 22:02:53,126][root][INFO] - Step 25858560 @ 3581.2 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 25858560, mean_episode_return = None, mean_episode_step = 1710.3, total_loss = 15.816, pg_loss = 9.4482, baseline_loss = 11.453, entropy_loss = -5.0851, learner_queue_size = 32, _tick = 5175, _time = 1.6548e+09, train_seconds = 6892.9)
[2022-06-09 22:02:58,130][root][INFO] - Step 25879040 @ 4092.7 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 25879040, mean_episode_return = 30.991, mean_episode_step = 1502.1, total_loss = -233.03, pg_loss = -256.99, baseline_loss = 28.899, entropy_loss = -4.9315, learner_queue_size = 32, _tick = 5180, _time = 1.6548e+09, train_seconds = 6897.9)
[2022-06-09 22:03:03,134][root][INFO] - Step 25896960 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 25896960, mean_episode_return = 5.3695, mean_episode_step = 1516.9, total_loss = 152.73, pg_loss = 92.336, baseline_loss = 65.465, entropy_loss = -5.0653, learner_queue_size = 32, _tick = 5185, _time = 1.6548e+09, train_seconds = 6902.9)
[2022-06-09 22:03:08,138][root][INFO] - Step 25917440 @ 4092.8 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 25917440, mean_episode_return = 56.221, mean_episode_step = 1587.5, total_loss = 35.524, pg_loss = -39.709, baseline_loss = 80.291, entropy_loss = -5.0582, learner_queue_size = 32, _tick = 5190, _time = 1.6548e+09, train_seconds = 6907.9)
[2022-06-09 22:03:13,142][root][INFO] - Step 25935360 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 25935360, mean_episode_return = 61.133, mean_episode_step = 1509.7, total_loss = -90.517, pg_loss = -120.66, baseline_loss = 35.028, entropy_loss = -4.8904, learner_queue_size = 32, _tick = 5193, _time = 1.6548e+09, train_seconds = 6912.9)
[2022-06-09 22:03:18,146][root][INFO] - Step 25953280 @ 3581.0 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 25953280, mean_episode_return = 21.8, mean_episode_step = 1723.8, total_loss = 34.068, pg_loss = 21.004, baseline_loss = 18.409, entropy_loss = -5.3455, learner_queue_size = 32, _tick = 5195, _time = 1.6548e+09, train_seconds = 6918.0)
[2022-06-09 22:03:23,150][root][INFO] - Step 25973760 @ 4092.8 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 25973760, mean_episode_return = 232.25, mean_episode_step = 1470.4, total_loss = 334.47, pg_loss = 222.6, baseline_loss = 117.05, entropy_loss = -5.1727, learner_queue_size = 32, _tick = 5200, _time = 1.6548e+09, train_seconds = 6923.0)
[2022-06-09 22:03:28,154][root][INFO] - Step 25991680 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 25991680, mean_episode_return = 20.245, mean_episode_step = 1608.5, total_loss = -22.852, pg_loss = -55.507, baseline_loss = 37.637, entropy_loss = -4.9829, learner_queue_size = 32, _tick = 5204, _time = 1.6548e+09, train_seconds = 6928.0)
[2022-06-09 22:03:33,158][root][INFO] - Step 26009600 @ 3581.2 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 26009600, mean_episode_return = 37.684, mean_episode_step = 1451.4, total_loss = 112.13, pg_loss = 67.223, baseline_loss = 49.894, entropy_loss = -4.9903, learner_queue_size = 32, _tick = 5209, _time = 1.6548e+09, train_seconds = 6933.0)
[2022-06-09 22:03:38,162][root][INFO] - Step 26027520 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 26027520, mean_episode_return = 0.26964, mean_episode_step = 1749.8, total_loss = -83.357, pg_loss = -117.98, baseline_loss = 39.36, entropy_loss = -4.7415, learner_queue_size = 32, _tick = 5214, _time = 1.6548e+09, train_seconds = 6938.0)
[2022-06-09 22:03:43,166][root][INFO] - Step 26048000 @ 4092.7 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 26048000, mean_episode_return = 58.458, mean_episode_step = 1858.8, total_loss = -245.13, pg_loss = -270.3, baseline_loss = 30.185, entropy_loss = -5.0157, learner_queue_size = 32, _tick = 5220, _time = 1.6548e+09, train_seconds = 6943.0)
[2022-06-09 22:03:48,170][root][INFO] - Step 26065920 @ 3581.2 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 26065920, mean_episode_return = None, mean_episode_step = 1423.1, total_loss = 49.629, pg_loss = 9.505, baseline_loss = 45.225, entropy_loss = -5.1008, learner_queue_size = 32, _tick = 5223, _time = 1.6548e+09, train_seconds = 6948.0)
[2022-06-09 22:03:53,174][root][INFO] - Step 26086400 @ 4092.6 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 26086400, mean_episode_return = 55.572, mean_episode_step = 1820.9, total_loss = -65.124, pg_loss = -86.538, baseline_loss = 26.541, entropy_loss = -5.1266, learner_queue_size = 32, _tick = 5228, _time = 1.6548e+09, train_seconds = 6953.0)
[2022-06-09 22:03:58,178][root][INFO] - Step 26104320 @ 3581.2 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 26104320, mean_episode_return = None, mean_episode_step = 1546.5, total_loss = 97.694, pg_loss = 60.137, baseline_loss = 42.837, entropy_loss = -5.2807, learner_queue_size = 32, _tick = 5230, _time = 1.6548e+09, train_seconds = 6958.0)
[2022-06-09 22:04:03,182][root][INFO] - Step 26122240 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 26122240, mean_episode_return = 4.975, mean_episode_step = 1330.8, total_loss = -56.279, pg_loss = -105.12, baseline_loss = 54.088, entropy_loss = -5.2507, learner_queue_size = 32, _tick = 5236, _time = 1.6548e+09, train_seconds = 6963.0)
[2022-06-09 22:04:08,186][root][INFO] - Step 26142720 @ 4092.9 SPS. Inference batcher size: 82. Learner queue size: 32. Other stats: (step = 26142720, mean_episode_return = 36.761, mean_episode_step = 1604.8, total_loss = 274.67, pg_loss = 168.69, baseline_loss = 111.26, entropy_loss = -5.2892, learner_queue_size = 32, _tick = 5242, _time = 1.6548e+09, train_seconds = 6968.0)
[2022-06-09 22:04:13,190][root][INFO] - Step 26160640 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 26160640, mean_episode_return = 56.383, mean_episode_step = 1703.3, total_loss = -15.876, pg_loss = -61.988, baseline_loss = 51.339, entropy_loss = -5.226, learner_queue_size = 32, _tick = 5246, _time = 1.6548e+09, train_seconds = 6973.0)
[2022-06-09 22:04:18,194][root][INFO] - Step 26181120 @ 4092.7 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 26181120, mean_episode_return = 71.471, mean_episode_step = 1563.3, total_loss = 381.81, pg_loss = 221.27, baseline_loss = 165.69, entropy_loss = -5.1509, learner_queue_size = 32, _tick = 5251, _time = 1.6548e+09, train_seconds = 6978.0)
[2022-06-09 22:04:23,198][root][INFO] - Step 26199040 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 26199040, mean_episode_return = None, mean_episode_step = 1507.0, total_loss = -29.797, pg_loss = -35.947, baseline_loss = 11.207, entropy_loss = -5.0575, learner_queue_size = 32, _tick = 5256, _time = 1.6548e+09, train_seconds = 6983.0)
[2022-06-09 22:04:28,202][root][INFO] - Step 26216960 @ 3581.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 26216960, mean_episode_return = -9.1704, mean_episode_step = 1439.0, total_loss = 154.16, pg_loss = 92.475, baseline_loss = 66.764, entropy_loss = -5.0822, learner_queue_size = 32, _tick = 5260, _time = 1.6548e+09, train_seconds = 6988.0)
[2022-06-09 22:04:33,206][root][INFO] - Step 26237440 @ 4092.7 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 26237440, mean_episode_return = None, mean_episode_step = 1379.9, total_loss = 22.98, pg_loss = -7.8556, baseline_loss = 35.83, entropy_loss = -4.9943, learner_queue_size = 32, _tick = 5263, _time = 1.6548e+09, train_seconds = 6993.0)
[2022-06-09 22:04:38,210][root][INFO] - Step 26255360 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 26255360, mean_episode_return = 55.02, mean_episode_step = 1564.9, total_loss = 60.379, pg_loss = -9.7498, baseline_loss = 75.104, entropy_loss = -4.9752, learner_queue_size = 32, _tick = 5264, _time = 1.6548e+09, train_seconds = 6998.0)
[2022-06-09 22:04:43,214][root][INFO] - Step 26273280 @ 3581.2 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 26273280, mean_episode_return = 134.14, mean_episode_step = 1942.6, total_loss = -12.486, pg_loss = -69.317, baseline_loss = 61.964, entropy_loss = -5.1336, learner_queue_size = 32, _tick = 5266, _time = 1.6548e+09, train_seconds = 7003.0)
[2022-06-09 22:04:48,218][root][INFO] - Step 26293760 @ 4092.7 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 26293760, mean_episode_return = 65.561, mean_episode_step = 1560.7, total_loss = 236.04, pg_loss = 150.16, baseline_loss = 90.972, entropy_loss = -5.0867, learner_queue_size = 32, _tick = 5273, _time = 1.6548e+09, train_seconds = 7008.0)
[2022-06-09 22:04:53,222][root][INFO] - Step 26311680 @ 3581.1 SPS. Inference batcher size: 93. Learner queue size: 32. Other stats: (step = 26311680, mean_episode_return = None, mean_episode_step = 1539.2, total_loss = 21.157, pg_loss = -1.8659, baseline_loss = 28.137, entropy_loss = -5.1138, learner_queue_size = 32, _tick = 5277, _time = 1.6548e+09, train_seconds = 7013.0)
[2022-06-09 22:04:58,226][root][INFO] - Step 26332160 @ 4092.8 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 26332160, mean_episode_return = 50.321, mean_episode_step = 1491.7, total_loss = 342.68, pg_loss = 239.95, baseline_loss = 107.92, entropy_loss = -5.1894, learner_queue_size = 32, _tick = 5282, _time = 1.6548e+09, train_seconds = 7018.0)
[2022-06-09 22:05:03,230][root][INFO] - Step 26350080 @ 3581.1 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 26350080, mean_episode_return = None, mean_episode_step = 1875.0, total_loss = 67.862, pg_loss = 6.5956, baseline_loss = 66.52, entropy_loss = -5.2539, learner_queue_size = 32, _tick = 5285, _time = 1.6548e+09, train_seconds = 7023.0)
[2022-06-09 22:05:08,234][root][INFO] - Step 26368000 @ 3581.2 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 26368000, mean_episode_return = None, mean_episode_step = 1578.6, total_loss = 451.03, pg_loss = 317.29, baseline_loss = 138.91, entropy_loss = -5.1718, learner_queue_size = 32, _tick = 5289, _time = 1.6548e+09, train_seconds = 7028.0)
[2022-06-09 22:05:13,238][root][INFO] - Step 26388480 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 26388480, mean_episode_return = 39.124, mean_episode_step = 1843.3, total_loss = -68.409, pg_loss = -118.95, baseline_loss = 55.721, entropy_loss = -5.177, learner_queue_size = 32, _tick = 5294, _time = 1.6548e+09, train_seconds = 7033.0)
[2022-06-09 22:05:18,242][root][INFO] - Step 26406400 @ 3581.1 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 26406400, mean_episode_return = 57.122, mean_episode_step = 2325.6, total_loss = -148.57, pg_loss = -162.12, baseline_loss = 18.756, entropy_loss = -5.1977, learner_queue_size = 32, _tick = 5299, _time = 1.6548e+09, train_seconds = 7038.0)
[2022-06-09 22:05:23,246][root][INFO] - Step 26426880 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 26426880, mean_episode_return = None, mean_episode_step = 1926.4, total_loss = 81.495, pg_loss = 45.028, baseline_loss = 41.701, entropy_loss = -5.2347, learner_queue_size = 32, _tick = 5302, _time = 1.6548e+09, train_seconds = 7043.1)
[2022-06-09 22:05:28,250][root][INFO] - Step 26444800 @ 3581.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 26444800, mean_episode_return = None, mean_episode_step = 1823.7, total_loss = 104.69, pg_loss = 60.035, baseline_loss = 49.77, entropy_loss = -5.1161, learner_queue_size = 32, _tick = 5307, _time = 1.6548e+09, train_seconds = 7048.1)
[2022-06-09 22:05:33,254][root][INFO] - Step 26465280 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 26465280, mean_episode_return = 72.228, mean_episode_step = 1921.6, total_loss = -148.43, pg_loss = -155.02, baseline_loss = 11.661, entropy_loss = -5.0723, learner_queue_size = 32, _tick = 5312, _time = 1.6548e+09, train_seconds = 7053.1)
[2022-06-09 22:05:38,258][root][INFO] - Step 26483200 @ 3581.2 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 26483200, mean_episode_return = 79.107, mean_episode_step = 1546.7, total_loss = -133.14, pg_loss = -152.17, baseline_loss = 24.121, entropy_loss = -5.0886, learner_queue_size = 32, _tick = 5318, _time = 1.6548e+09, train_seconds = 7058.1)
[2022-06-09 22:05:43,262][root][INFO] - Step 26503680 @ 4092.7 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 26503680, mean_episode_return = None, mean_episode_step = 1687.2, total_loss = 57.942, pg_loss = 23.086, baseline_loss = 39.978, entropy_loss = -5.1228, learner_queue_size = 32, _tick = 5323, _time = 1.6548e+09, train_seconds = 7063.1)
[2022-06-09 22:05:48,266][root][INFO] - Step 26521600 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 26521600, mean_episode_return = 84.035, mean_episode_step = 1555.7, total_loss = 18.849, pg_loss = -24.126, baseline_loss = 48.103, entropy_loss = -5.1291, learner_queue_size = 32, _tick = 5327, _time = 1.6548e+09, train_seconds = 7068.1)
[2022-06-09 22:05:53,270][root][INFO] - Step 26542080 @ 4092.8 SPS. Inference batcher size: 109. Learner queue size: 32. Other stats: (step = 26542080, mean_episode_return = 65.918, mean_episode_step = 1513.9, total_loss = 276.74, pg_loss = 140.99, baseline_loss = 140.78, entropy_loss = -5.0296, learner_queue_size = 32, _tick = 5332, _time = 1.6548e+09, train_seconds = 7073.1)
[2022-06-09 22:05:58,274][root][INFO] - Step 26560000 @ 3581.0 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 26560000, mean_episode_return = 38.156, mean_episode_step = 1655.9, total_loss = 0.28915, pg_loss = -59.592, baseline_loss = 64.781, entropy_loss = -4.8991, learner_queue_size = 32, _tick = 5336, _time = 1.6548e+09, train_seconds = 7078.1)
[2022-06-09 22:06:03,278][root][INFO] - Step 26577920 @ 3581.2 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 26577920, mean_episode_return = 149.47, mean_episode_step = 1202.0, total_loss = 274.5, pg_loss = 146.78, baseline_loss = 132.7, entropy_loss = -4.9875, learner_queue_size = 32, _tick = 5341, _time = 1.6548e+09, train_seconds = 7083.1)
[2022-06-09 22:06:08,282][root][INFO] - Step 26598400 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 26598400, mean_episode_return = 122.3, mean_episode_step = 2025.9, total_loss = 37.158, pg_loss = -35.723, baseline_loss = 77.881, entropy_loss = -5.0009, learner_queue_size = 32, _tick = 5347, _time = 1.6548e+09, train_seconds = 7088.1)
[2022-06-09 22:06:13,286][root][INFO] - Step 26616320 @ 3581.2 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 26616320, mean_episode_return = 86.72, mean_episode_step = 1615.7, total_loss = -129.85, pg_loss = -129.21, baseline_loss = 3.9662, entropy_loss = -4.6079, learner_queue_size = 32, _tick = 5351, _time = 1.6548e+09, train_seconds = 7093.1)
[2022-06-09 22:06:18,290][root][INFO] - Step 26634240 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 26634240, mean_episode_return = 57.621, mean_episode_step = 1187.6, total_loss = 18.232, pg_loss = -49.031, baseline_loss = 72.029, entropy_loss = -4.766, learner_queue_size = 32, _tick = 5355, _time = 1.6548e+09, train_seconds = 7098.1)
[2022-06-09 22:06:23,294][root][INFO] - Step 26652160 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 26652160, mean_episode_return = 17.2, mean_episode_step = 1709.7, total_loss = -175.81, pg_loss = -183.55, baseline_loss = 12.741, entropy_loss = -4.9997, learner_queue_size = 32, _tick = 5359, _time = 1.6548e+09, train_seconds = 7103.1)
[2022-06-09 22:06:28,298][root][INFO] - Step 26672640 @ 4092.8 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 26672640, mean_episode_return = None, mean_episode_step = 1559.8, total_loss = 592.02, pg_loss = 437.27, baseline_loss = 159.84, entropy_loss = -5.0794, learner_queue_size = 32, _tick = 5362, _time = 1.6548e+09, train_seconds = 7108.1)
[2022-06-09 22:06:33,302][root][INFO] - Step 26690560 @ 3581.1 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 26690560, mean_episode_return = -5.6104, mean_episode_step = 1867.1, total_loss = 83.7, pg_loss = -4.2021, baseline_loss = 92.787, entropy_loss = -4.8848, learner_queue_size = 32, _tick = 5366, _time = 1.6548e+09, train_seconds = 7113.1)
[2022-06-09 22:06:38,308][root][INFO] - Step 26711040 @ 4091.4 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 26711040, mean_episode_return = None, mean_episode_step = 1854.4, total_loss = 133.01, pg_loss = 77.963, baseline_loss = 60.069, entropy_loss = -5.027, learner_queue_size = 32, _tick = 5369, _time = 1.6548e+09, train_seconds = 7118.1)
[2022-06-09 22:06:43,310][root][INFO] - Step 26728960 @ 3582.3 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (step = 26728960, mean_episode_return = 52.781, mean_episode_step = 1788.1, total_loss = -22.043, pg_loss = -58.642, baseline_loss = 41.493, entropy_loss = -4.8939, learner_queue_size = 32, _tick = 5372, _time = 1.6548e+09, train_seconds = 7123.1)
[2022-06-09 22:06:48,314][root][INFO] - Step 26749440 @ 4092.7 SPS. Inference batcher size: 85. Learner queue size: 32. Other stats: (step = 26749440, mean_episode_return = None, mean_episode_step = 2039.0, total_loss = 75.118, pg_loss = 40.274, baseline_loss = 39.879, entropy_loss = -5.0348, learner_queue_size = 32, _tick = 5374, _time = 1.6548e+09, train_seconds = 7128.1)
[2022-06-09 22:06:53,318][root][INFO] - Step 26767360 @ 3581.2 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 26767360, mean_episode_return = 142.79, mean_episode_step = 1857.7, total_loss = -43.101, pg_loss = -76.227, baseline_loss = 38.084, entropy_loss = -4.9584, learner_queue_size = 32, _tick = 5377, _time = 1.6548e+09, train_seconds = 7133.1)
[2022-06-09 22:06:58,322][root][INFO] - Step 26787840 @ 4092.7 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 26787840, mean_episode_return = None, mean_episode_step = 2021.8, total_loss = -105.84, pg_loss = -106.18, baseline_loss = 5.4451, entropy_loss = -5.1028, learner_queue_size = 32, _tick = 5378, _time = 1.6548e+09, train_seconds = 7138.1)
[2022-06-09 22:07:03,326][root][INFO] - Step 26805760 @ 3581.2 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 26805760, mean_episode_return = None, mean_episode_step = 2067.7, total_loss = 603.95, pg_loss = 418.21, baseline_loss = 190.77, entropy_loss = -5.0293, learner_queue_size = 32, _tick = 5381, _time = 1.6548e+09, train_seconds = 7143.1)
[2022-06-09 22:07:08,330][root][INFO] - Step 26823680 @ 3581.1 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 26823680, mean_episode_return = None, mean_episode_step = 1825.2, total_loss = 450.65, pg_loss = 291.41, baseline_loss = 164.34, entropy_loss = -5.1102, learner_queue_size = 32, _tick = 5384, _time = 1.6548e+09, train_seconds = 7148.1)
[2022-06-09 22:07:13,342][root][INFO] - Step 26844160 @ 4086.3 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 26844160, mean_episode_return = None, mean_episode_step = 2450.0, total_loss = -27.309, pg_loss = -45.781, baseline_loss = 23.388, entropy_loss = -4.9166, learner_queue_size = 32, _tick = 5387, _time = 1.6548e+09, train_seconds = 7153.1)
[2022-06-09 22:07:18,346][root][INFO] - Step 26862080 @ 3581.0 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 26862080, mean_episode_return = 69.951, mean_episode_step = 2428.2, total_loss = -217.22, pg_loss = -223.15, baseline_loss = 10.907, entropy_loss = -4.979, learner_queue_size = 32, _tick = 5392, _time = 1.6548e+09, train_seconds = 7158.2)
[2022-06-09 22:07:23,350][root][INFO] - Step 26882560 @ 4092.8 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 26882560, mean_episode_return = 15.976, mean_episode_step = 2189.7, total_loss = -104.09, pg_loss = -126.25, baseline_loss = 27.298, entropy_loss = -5.1358, learner_queue_size = 32, _tick = 5398, _time = 1.6548e+09, train_seconds = 7163.2)
[2022-06-09 22:07:28,354][root][INFO] - Step 26900480 @ 3581.2 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 26900480, mean_episode_return = 131.23, mean_episode_step = 2066.3, total_loss = -14.514, pg_loss = -22.442, baseline_loss = 12.664, entropy_loss = -4.7364, learner_queue_size = 32, _tick = 5404, _time = 1.6548e+09, train_seconds = 7168.2)
[2022-06-09 22:07:33,358][root][INFO] - Step 26920960 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 26920960, mean_episode_return = None, mean_episode_step = 1967.7, total_loss = -8.2536, pg_loss = -21.225, baseline_loss = 17.047, entropy_loss = -4.0764, learner_queue_size = 32, _tick = 5407, _time = 1.6548e+09, train_seconds = 7173.2)
[2022-06-09 22:07:38,362][root][INFO] - Step 26938880 @ 3580.9 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 26938880, mean_episode_return = 92.527, mean_episode_step = 2496.0, total_loss = -50.277, pg_loss = -56.619, baseline_loss = 11.449, entropy_loss = -5.1071, learner_queue_size = 32, _tick = 5410, _time = 1.6548e+09, train_seconds = 7178.2)
[2022-06-09 22:07:43,366][root][INFO] - Step 26956800 @ 3581.3 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 26956800, mean_episode_return = 2.6396, mean_episode_step = 2419.4, total_loss = 167.37, pg_loss = 93.781, baseline_loss = 78.84, entropy_loss = -5.2468, learner_queue_size = 32, _tick = 5414, _time = 1.6548e+09, train_seconds = 7183.2)
[2022-06-09 22:07:48,370][root][INFO] - Step 26977280 @ 4092.8 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 26977280, mean_episode_return = -47.778, mean_episode_step = 2963.2, total_loss = 160.16, pg_loss = 101.14, baseline_loss = 63.995, entropy_loss = -4.966, learner_queue_size = 32, _tick = 5418, _time = 1.6548e+09, train_seconds = 7188.2)
[2022-06-09 22:07:53,374][root][INFO] - Step 26995200 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 26995200, mean_episode_return = 69.298, mean_episode_step = 1891.6, total_loss = -99.687, pg_loss = -109.03, baseline_loss = 14.337, entropy_loss = -4.998, learner_queue_size = 32, _tick = 5422, _time = 1.6548e+09, train_seconds = 7193.2)
[2022-06-09 22:07:58,378][root][INFO] - Step 27015680 @ 4092.7 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 27015680, mean_episode_return = 39.456, mean_episode_step = 2209.7, total_loss = 311.79, pg_loss = 195.05, baseline_loss = 121.82, entropy_loss = -5.0896, learner_queue_size = 32, _tick = 5429, _time = 1.6548e+09, train_seconds = 7198.2)
[2022-06-09 22:08:03,382][root][INFO] - Step 27033600 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 27033600, mean_episode_return = 33.97, mean_episode_step = 1375.9, total_loss = 34.765, pg_loss = -14.301, baseline_loss = 53.744, entropy_loss = -4.6775, learner_queue_size = 32, _tick = 5435, _time = 1.6548e+09, train_seconds = 7203.2)
[2022-06-09 22:08:08,386][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-09 22:08:08,578][root][INFO] - Step 27051520 @ 3581.1 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (step = 27054080, mean_episode_return = 36.472, mean_episode_step = 1910.8, total_loss = 105.05, pg_loss = -2.1303, baseline_loss = 112.26, entropy_loss = -5.0744, learner_queue_size = 32, _tick = 5440, _time = 1.6548e+09, train_seconds = 7208.2)
[2022-06-09 22:08:13,582][root][INFO] - Step 27072000 @ 3941.4 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 27072000, mean_episode_return = None, mean_episode_step = 2181.3, total_loss = 75.267, pg_loss = 44.948, baseline_loss = 35.12, entropy_loss = -4.8003, learner_queue_size = 32, _tick = 5443, _time = 1.6548e+09, train_seconds = 7213.4)
[2022-06-09 22:08:18,586][root][INFO] - Step 27089920 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 27089920, mean_episode_return = 32.394, mean_episode_step = 1640.4, total_loss = -161.46, pg_loss = -176.84, baseline_loss = 20.134, entropy_loss = -4.7545, learner_queue_size = 32, _tick = 5448, _time = 1.6548e+09, train_seconds = 7218.4)
[2022-06-09 22:08:23,590][root][INFO] - Step 27110400 @ 4092.8 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 27110400, mean_episode_return = None, mean_episode_step = 1737.1, total_loss = -46.284, pg_loss = -56.391, baseline_loss = 15.017, entropy_loss = -4.9101, learner_queue_size = 32, _tick = 5453, _time = 1.6548e+09, train_seconds = 7223.4)
[2022-06-09 22:08:28,594][root][INFO] - Step 27128320 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 27128320, mean_episode_return = 50.28, mean_episode_step = 1558.2, total_loss = 82.601, pg_loss = 22.792, baseline_loss = 64.212, entropy_loss = -4.4035, learner_queue_size = 32, _tick = 5457, _time = 1.6548e+09, train_seconds = 7228.4)
[2022-06-09 22:08:33,599][root][INFO] - Step 27148800 @ 4092.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 27148800, mean_episode_return = 42.431, mean_episode_step = 1737.2, total_loss = 251.75, pg_loss = 150.09, baseline_loss = 104.97, entropy_loss = -3.3011, learner_queue_size = 32, _tick = 5461, _time = 1.6548e+09, train_seconds = 7233.4)
[2022-06-09 22:08:38,602][root][INFO] - Step 27166720 @ 3581.6 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 27166720, mean_episode_return = -3.7005, mean_episode_step = 2128.2, total_loss = -16.939, pg_loss = -29.985, baseline_loss = 17.815, entropy_loss = -4.7687, learner_queue_size = 32, _tick = 5466, _time = 1.6548e+09, train_seconds = 7238.4)
[2022-06-09 22:08:43,606][root][INFO] - Step 27187200 @ 4092.8 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 27187200, mean_episode_return = 66.038, mean_episode_step = 2458.9, total_loss = -91.343, pg_loss = -107.13, baseline_loss = 20.773, entropy_loss = -4.987, learner_queue_size = 32, _tick = 5470, _time = 1.6548e+09, train_seconds = 7243.4)
[2022-06-09 22:08:48,610][root][INFO] - Step 27205120 @ 3581.1 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 27205120, mean_episode_return = 105.2, mean_episode_step = 1863.2, total_loss = 81.118, pg_loss = 29.561, baseline_loss = 56.295, entropy_loss = -4.7382, learner_queue_size = 32, _tick = 5475, _time = 1.6548e+09, train_seconds = 7248.4)
[2022-06-09 22:08:53,614][root][INFO] - Step 27225600 @ 4092.8 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 27225600, mean_episode_return = None, mean_episode_step = 2206.9, total_loss = -89.259, pg_loss = -95.047, baseline_loss = 10.383, entropy_loss = -4.5956, learner_queue_size = 32, _tick = 5476, _time = 1.6548e+09, train_seconds = 7253.4)
[2022-06-09 22:08:58,618][root][INFO] - Step 27243520 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 27243520, mean_episode_return = None, mean_episode_step = 2114.4, total_loss = 111.63, pg_loss = 75.058, baseline_loss = 41.588, entropy_loss = -5.021, learner_queue_size = 32, _tick = 5479, _time = 1.6548e+09, train_seconds = 7258.4)
[2022-06-09 22:09:03,622][root][INFO] - Step 27264000 @ 4092.7 SPS. Inference batcher size: 79. Learner queue size: 32. Other stats: (step = 27264000, mean_episode_return = 62.222, mean_episode_step = 1752.6, total_loss = -69.247, pg_loss = -78.045, baseline_loss = 13.512, entropy_loss = -4.7148, learner_queue_size = 32, _tick = 5485, _time = 1.6548e+09, train_seconds = 7263.4)
[2022-06-09 22:09:08,626][root][INFO] - Step 27281920 @ 3581.2 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 27281920, mean_episode_return = None, mean_episode_step = 2410.5, total_loss = -4.8709, pg_loss = -20.035, baseline_loss = 20.222, entropy_loss = -5.0584, learner_queue_size = 32, _tick = 5488, _time = 1.6548e+09, train_seconds = 7268.4)
[2022-06-09 22:09:13,630][root][INFO] - Step 27299840 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 27299840, mean_episode_return = 9.2496, mean_episode_step = 2151.6, total_loss = -155.62, pg_loss = -155.16, baseline_loss = 4.3865, entropy_loss = -4.8472, learner_queue_size = 32, _tick = 5491, _time = 1.6548e+09, train_seconds = 7273.4)
[2022-06-09 22:09:18,634][root][INFO] - Step 27317760 @ 3581.2 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 27317760, mean_episode_return = 49.025, mean_episode_step = 1997.3, total_loss = 136.53, pg_loss = 57.85, baseline_loss = 83.552, entropy_loss = -4.8719, learner_queue_size = 32, _tick = 5497, _time = 1.6548e+09, train_seconds = 7278.4)
[2022-06-09 22:09:23,638][root][INFO] - Step 27335680 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 27335680, mean_episode_return = 76.322, mean_episode_step = 1873.4, total_loss = 1.636, pg_loss = -26.33, baseline_loss = 32.926, entropy_loss = -4.9603, learner_queue_size = 32, _tick = 5499, _time = 1.6548e+09, train_seconds = 7283.4)
[2022-06-09 22:09:28,642][root][INFO] - Step 27356160 @ 4092.7 SPS. Inference batcher size: 77. Learner queue size: 32. Other stats: (step = 27356160, mean_episode_return = 54.991, mean_episode_step = 2023.4, total_loss = 47.271, pg_loss = 6.7817, baseline_loss = 45.577, entropy_loss = -5.0872, learner_queue_size = 32, _tick = 5503, _time = 1.6548e+09, train_seconds = 7288.4)
[2022-06-09 22:09:33,646][root][INFO] - Step 27374080 @ 3581.1 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (step = 27374080, mean_episode_return = None, mean_episode_step = 2457.4, total_loss = -118.49, pg_loss = -120.63, baseline_loss = 7.0793, entropy_loss = -4.9352, learner_queue_size = 32, _tick = 5508, _time = 1.6548e+09, train_seconds = 7293.5)
[2022-06-09 22:09:38,650][root][INFO] - Step 27392000 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 27392000, mean_episode_return = 8.101, mean_episode_step = 1897.6, total_loss = 370.48, pg_loss = 234.33, baseline_loss = 141.11, entropy_loss = -4.9618, learner_queue_size = 32, _tick = 5513, _time = 1.6548e+09, train_seconds = 7298.5)
[2022-06-09 22:09:43,654][root][INFO] - Step 27412480 @ 4092.7 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 27412480, mean_episode_return = 66.524, mean_episode_step = 1747.0, total_loss = 246.69, pg_loss = 170.86, baseline_loss = 80.945, entropy_loss = -5.1186, learner_queue_size = 32, _tick = 5518, _time = 1.6548e+09, train_seconds = 7303.5)
[2022-06-09 22:09:48,658][root][INFO] - Step 27430400 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 27430400, mean_episode_return = 141.91, mean_episode_step = 1771.2, total_loss = 93.899, pg_loss = 34.453, baseline_loss = 64.111, entropy_loss = -4.666, learner_queue_size = 32, _tick = 5522, _time = 1.6548e+09, train_seconds = 7308.5)
[2022-06-09 22:09:53,662][root][INFO] - Step 27448320 @ 3581.0 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 27448320, mean_episode_return = 10.414, mean_episode_step = 1780.4, total_loss = -140.89, pg_loss = -153.01, baseline_loss = 16.923, entropy_loss = -4.8003, learner_queue_size = 32, _tick = 5527, _time = 1.6548e+09, train_seconds = 7313.5)
[2022-06-09 22:09:58,666][root][INFO] - Step 27468800 @ 4092.7 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 27468800, mean_episode_return = None, mean_episode_step = 1953.3, total_loss = 126.51, pg_loss = 85.638, baseline_loss = 46.082, entropy_loss = -5.2125, learner_queue_size = 32, _tick = 5529, _time = 1.6548e+09, train_seconds = 7318.5)
[2022-06-09 22:10:03,670][root][INFO] - Step 27486720 @ 3581.1 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 27486720, mean_episode_return = 8.5255, mean_episode_step = 2359.2, total_loss = -5.8854, pg_loss = -61.416, baseline_loss = 60.595, entropy_loss = -5.0643, learner_queue_size = 32, _tick = 5535, _time = 1.6548e+09, train_seconds = 7323.5)
[2022-06-09 22:10:08,674][root][INFO] - Step 27507200 @ 4092.6 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 27507200, mean_episode_return = None, mean_episode_step = 2272.9, total_loss = -41.976, pg_loss = -43.145, baseline_loss = 5.3681, entropy_loss = -4.1993, learner_queue_size = 32, _tick = 5538, _time = 1.6548e+09, train_seconds = 7328.5)
[2022-06-09 22:10:13,678][root][INFO] - Step 27525120 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 27525120, mean_episode_return = None, mean_episode_step = 2852.2, total_loss = -30.031, pg_loss = -36.628, baseline_loss = 11.484, entropy_loss = -4.8867, learner_queue_size = 32, _tick = 5541, _time = 1.6548e+09, train_seconds = 7333.5)
[2022-06-09 22:10:18,682][root][INFO] - Step 27543040 @ 3581.3 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 27543040, mean_episode_return = None, mean_episode_step = 1624.9, total_loss = 4.7584, pg_loss = -8.1088, baseline_loss = 17.936, entropy_loss = -5.0686, learner_queue_size = 32, _tick = 5546, _time = 1.6548e+09, train_seconds = 7338.5)
[2022-06-09 22:10:23,686][root][INFO] - Step 27563520 @ 4092.7 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 27563520, mean_episode_return = 104.47, mean_episode_step = 1682.8, total_loss = 9.8157, pg_loss = -14.144, baseline_loss = 28.814, entropy_loss = -4.8538, learner_queue_size = 32, _tick = 5552, _time = 1.6548e+09, train_seconds = 7343.5)
[2022-06-09 22:10:28,690][root][INFO] - Step 27581440 @ 3581.1 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 27581440, mean_episode_return = 7.1027, mean_episode_step = 1964.3, total_loss = 297.58, pg_loss = 180.1, baseline_loss = 122.42, entropy_loss = -4.9384, learner_queue_size = 32, _tick = 5555, _time = 1.6548e+09, train_seconds = 7348.5)
[2022-06-09 22:10:33,694][root][INFO] - Step 27601920 @ 4092.7 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 27601920, mean_episode_return = 29.989, mean_episode_step = 2096.0, total_loss = 65.278, pg_loss = 5.6704, baseline_loss = 64.183, entropy_loss = -4.5758, learner_queue_size = 32, _tick = 5561, _time = 1.6548e+09, train_seconds = 7353.5)
[2022-06-09 22:10:38,698][root][INFO] - Step 27619840 @ 3581.2 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 27619840, mean_episode_return = 45.259, mean_episode_step = 1447.8, total_loss = -5.9615, pg_loss = -43.561, baseline_loss = 41.549, entropy_loss = -3.9497, learner_queue_size = 32, _tick = 5564, _time = 1.6548e+09, train_seconds = 7358.5)
[2022-06-09 22:10:43,702][root][INFO] - Step 27637760 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 27637760, mean_episode_return = None, mean_episode_step = 2106.2, total_loss = -89.269, pg_loss = -90.865, baseline_loss = 6.3404, entropy_loss = -4.744, learner_queue_size = 32, _tick = 5569, _time = 1.6548e+09, train_seconds = 7363.5)
[2022-06-09 22:10:48,706][root][INFO] - Step 27658240 @ 4092.8 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 27658240, mean_episode_return = 46.662, mean_episode_step = 1873.5, total_loss = -105.72, pg_loss = -116.08, baseline_loss = 15.205, entropy_loss = -4.8483, learner_queue_size = 32, _tick = 5572, _time = 1.6548e+09, train_seconds = 7368.5)
[2022-06-09 22:10:53,711][root][INFO] - Step 27678720 @ 4091.9 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 27678720, mean_episode_return = 13.019, mean_episode_step = 1877.5, total_loss = -22.674, pg_loss = -48.421, baseline_loss = 30.491, entropy_loss = -4.7441, learner_queue_size = 32, _tick = 5577, _time = 1.6548e+09, train_seconds = 7373.5)
[2022-06-09 22:10:58,714][root][INFO] - Step 27696640 @ 3581.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 27696640, mean_episode_return = 117.26, mean_episode_step = 2274.0, total_loss = 66.262, pg_loss = 41.097, baseline_loss = 30.066, entropy_loss = -4.9017, learner_queue_size = 32, _tick = 5582, _time = 1.6548e+09, train_seconds = 7378.5)
[2022-06-09 22:11:03,718][root][INFO] - Step 27714560 @ 3581.2 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (step = 27714560, mean_episode_return = 87.66, mean_episode_step = 2091.5, total_loss = 279.34, pg_loss = 157.34, baseline_loss = 126.87, entropy_loss = -4.8654, learner_queue_size = 32, _tick = 5589, _time = 1.6548e+09, train_seconds = 7383.5)
[2022-06-09 22:11:08,724][root][INFO] - Step 27735040 @ 4091.1 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 27735040, mean_episode_return = None, mean_episode_step = 2351.1, total_loss = 9.9801, pg_loss = -4.863, baseline_loss = 19.92, entropy_loss = -5.0767, learner_queue_size = 32, _tick = 5594, _time = 1.6548e+09, train_seconds = 7388.5)
[2022-06-09 22:11:13,730][root][INFO] - Step 27752960 @ 3579.6 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 27752960, mean_episode_return = -4.7006, mean_episode_step = 1979.3, total_loss = 167.19, pg_loss = 101.01, baseline_loss = 70.965, entropy_loss = -4.7856, learner_queue_size = 32, _tick = 5600, _time = 1.6548e+09, train_seconds = 7393.5)
[2022-06-09 22:11:18,734][root][INFO] - Step 27770880 @ 3581.2 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 27770880, mean_episode_return = 86.972, mean_episode_step = 2169.1, total_loss = -5.3, pg_loss = -41.676, baseline_loss = 41.075, entropy_loss = -4.6993, learner_queue_size = 32, _tick = 5605, _time = 1.6548e+09, train_seconds = 7398.5)
[2022-06-09 22:11:23,738][root][INFO] - Step 27791360 @ 4092.6 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 27791360, mean_episode_return = 73.351, mean_episode_step = 2191.5, total_loss = -55.049, pg_loss = -82.53, baseline_loss = 32.389, entropy_loss = -4.908, learner_queue_size = 32, _tick = 5612, _time = 1.6548e+09, train_seconds = 7403.5)
[2022-06-09 22:11:28,742][root][INFO] - Step 27809280 @ 3581.2 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 27809280, mean_episode_return = 70.929, mean_episode_step = 1473.2, total_loss = 57.977, pg_loss = 1.337, baseline_loss = 61.59, entropy_loss = -4.9498, learner_queue_size = 32, _tick = 5617, _time = 1.6548e+09, train_seconds = 7408.5)
[2022-06-09 22:11:33,746][root][INFO] - Step 27829760 @ 4092.7 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 27829760, mean_episode_return = None, mean_episode_step = 2184.3, total_loss = 121.2, pg_loss = 58.073, baseline_loss = 67.398, entropy_loss = -4.2715, learner_queue_size = 32, _tick = 5621, _time = 1.6548e+09, train_seconds = 7413.6)
[2022-06-09 22:11:38,751][root][INFO] - Step 27847680 @ 3580.7 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 27847680, mean_episode_return = None, mean_episode_step = 2086.5, total_loss = 330.09, pg_loss = 212.57, baseline_loss = 122.1, entropy_loss = -4.5741, learner_queue_size = 32, _tick = 5625, _time = 1.6548e+09, train_seconds = 7418.6)
[2022-06-09 22:11:43,754][root][INFO] - Step 27865600 @ 3581.6 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 27865600, mean_episode_return = 53.305, mean_episode_step = 1440.9, total_loss = 188.91, pg_loss = 92.462, baseline_loss = 101.25, entropy_loss = -4.8058, learner_queue_size = 32, _tick = 5631, _time = 1.6548e+09, train_seconds = 7423.6)
[2022-06-09 22:11:48,759][root][INFO] - Step 27886080 @ 4091.9 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 27886080, mean_episode_return = None, mean_episode_step = 1604.6, total_loss = -9.5544, pg_loss = -15.985, baseline_loss = 11.326, entropy_loss = -4.8952, learner_queue_size = 32, _tick = 5635, _time = 1.6548e+09, train_seconds = 7428.6)
[2022-06-09 22:11:53,762][root][INFO] - Step 27904000 @ 3581.6 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (step = 27904000, mean_episode_return = None, mean_episode_step = 1636.4, total_loss = -114.04, pg_loss = -118.35, baseline_loss = 9.1865, entropy_loss = -4.8746, learner_queue_size = 32, _tick = 5637, _time = 1.6548e+09, train_seconds = 7433.6)
[2022-06-09 22:11:58,766][root][INFO] - Step 27924480 @ 4092.9 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 27924480, mean_episode_return = -47.755, mean_episode_step = 1888.5, total_loss = 569.01, pg_loss = 411.1, baseline_loss = 162.74, entropy_loss = -4.8249, learner_queue_size = 32, _tick = 5643, _time = 1.6548e+09, train_seconds = 7438.6)
[2022-06-09 22:12:03,770][root][INFO] - Step 27942400 @ 3581.2 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 27942400, mean_episode_return = 15.25, mean_episode_step = 1742.9, total_loss = 158.24, pg_loss = 102.86, baseline_loss = 60.078, entropy_loss = -4.6906, learner_queue_size = 32, _tick = 5647, _time = 1.6548e+09, train_seconds = 7443.6)
[2022-06-09 22:12:08,774][root][INFO] - Step 27960320 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 27960320, mean_episode_return = None, mean_episode_step = 1782.6, total_loss = 195.3, pg_loss = 123.31, baseline_loss = 76.427, entropy_loss = -4.4422, learner_queue_size = 32, _tick = 5652, _time = 1.6548e+09, train_seconds = 7448.6)
[2022-06-09 22:12:13,778][root][INFO] - Step 27980800 @ 4092.7 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (step = 27980800, mean_episode_return = 13.69, mean_episode_step = 1333.8, total_loss = -90.675, pg_loss = -102.52, baseline_loss = 16.504, entropy_loss = -4.6635, learner_queue_size = 32, _tick = 5657, _time = 1.6548e+09, train_seconds = 7453.6)
[2022-06-09 22:12:18,782][root][INFO] - Step 27998720 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 27998720, mean_episode_return = None, mean_episode_step = 1564.6, total_loss = 401.65, pg_loss = 243.85, baseline_loss = 162.66, entropy_loss = -4.8627, learner_queue_size = 32, _tick = 5660, _time = 1.6548e+09, train_seconds = 7458.6)
[2022-06-09 22:12:23,786][root][INFO] - Step 28019200 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 28019200, mean_episode_return = None, mean_episode_step = 2346.4, total_loss = 0.0058665, pg_loss = -14.55, baseline_loss = 19.281, entropy_loss = -4.7249, learner_queue_size = 32, _tick = 5665, _time = 1.6548e+09, train_seconds = 7463.6)
[2022-06-09 22:12:28,790][root][INFO] - Step 28037120 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 28037120, mean_episode_return = 25.64, mean_episode_step = 1525.4, total_loss = 311.85, pg_loss = 229.52, baseline_loss = 86.616, entropy_loss = -4.2857, learner_queue_size = 32, _tick = 5671, _time = 1.6548e+09, train_seconds = 7468.6)
[2022-06-09 22:12:33,794][root][INFO] - Step 28057600 @ 4092.8 SPS. Inference batcher size: 78. Learner queue size: 32. Other stats: (step = 28057600, mean_episode_return = 35.161, mean_episode_step = 2277.0, total_loss = -27.935, pg_loss = -57.52, baseline_loss = 34.292, entropy_loss = -4.7065, learner_queue_size = 32, _tick = 5678, _time = 1.6548e+09, train_seconds = 7473.6)
[2022-06-09 22:12:38,798][root][INFO] - Step 28072960 @ 3069.5 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 28072960, mean_episode_return = 87.365, mean_episode_step = 1389.1, total_loss = 212.95, pg_loss = 144.81, baseline_loss = 72.794, entropy_loss = -4.6493, learner_queue_size = 32, _tick = 5683, _time = 1.6548e+09, train_seconds = 7478.6)
[2022-06-09 22:12:43,802][root][INFO] - Step 28093440 @ 4092.8 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 28093440, mean_episode_return = 50.281, mean_episode_step = 1545.1, total_loss = 422.64, pg_loss = 225.51, baseline_loss = 201.03, entropy_loss = -3.9042, learner_queue_size = 32, _tick = 5688, _time = 1.6548e+09, train_seconds = 7483.6)
[2022-06-09 22:12:48,806][root][INFO] - Step 28111360 @ 3581.1 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 28111360, mean_episode_return = 46.771, mean_episode_step = 1910.0, total_loss = -30.139, pg_loss = -71.375, baseline_loss = 45.359, entropy_loss = -4.1227, learner_queue_size = 32, _tick = 5691, _time = 1.6548e+09, train_seconds = 7488.6)
[2022-06-09 22:12:53,810][root][INFO] - Step 28131840 @ 4092.5 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 28131840, mean_episode_return = None, mean_episode_step = 1946.1, total_loss = -68.01, pg_loss = -80.586, baseline_loss = 16.844, entropy_loss = -4.2677, learner_queue_size = 32, _tick = 5693, _time = 1.6548e+09, train_seconds = 7493.6)
[2022-06-09 22:12:58,814][root][INFO] - Step 28149760 @ 3581.2 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 28149760, mean_episode_return = 25.17, mean_episode_step = 1785.7, total_loss = 173.74, pg_loss = 111.43, baseline_loss = 67.076, entropy_loss = -4.7651, learner_queue_size = 32, _tick = 5697, _time = 1.6548e+09, train_seconds = 7498.6)
[2022-06-09 22:13:03,818][root][INFO] - Step 28170240 @ 4092.9 SPS. Inference batcher size: 89. Learner queue size: 32. Other stats: (step = 28170240, mean_episode_return = None, mean_episode_step = 2051.3, total_loss = 158.68, pg_loss = 109.53, baseline_loss = 53.529, entropy_loss = -4.3824, learner_queue_size = 32, _tick = 5702, _time = 1.6548e+09, train_seconds = 7503.6)
[2022-06-09 22:13:08,822][root][INFO] - Step 28188160 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 28188160, mean_episode_return = -3.95, mean_episode_step = 1949.4, total_loss = 126.83, pg_loss = 52.029, baseline_loss = 79.57, entropy_loss = -4.7734, learner_queue_size = 32, _tick = 5707, _time = 1.6548e+09, train_seconds = 7508.6)
[2022-06-09 22:13:13,826][root][INFO] - Step 28206080 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 28206080, mean_episode_return = 85.288, mean_episode_step = 1896.4, total_loss = 141.74, pg_loss = 103.41, baseline_loss = 43.221, entropy_loss = -4.8876, learner_queue_size = 32, _tick = 5712, _time = 1.6548e+09, train_seconds = 7513.6)
[2022-06-09 22:13:18,830][root][INFO] - Step 28226560 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 28226560, mean_episode_return = None, mean_episode_step = 1739.8, total_loss = 5.3761, pg_loss = -13.111, baseline_loss = 23.649, entropy_loss = -5.1616, learner_queue_size = 32, _tick = 5717, _time = 1.6548e+09, train_seconds = 7518.6)
[2022-06-09 22:13:23,834][root][INFO] - Step 28244480 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 28244480, mean_episode_return = 44.002, mean_episode_step = 1883.9, total_loss = 205.93, pg_loss = 146.15, baseline_loss = 64.385, entropy_loss = -4.6041, learner_queue_size = 32, _tick = 5724, _time = 1.6548e+09, train_seconds = 7523.6)
[2022-06-09 22:13:28,840][root][INFO] - Step 28262400 @ 3580.0 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 28262400, mean_episode_return = None, mean_episode_step = 1929.6, total_loss = 4.3438, pg_loss = -11.064, baseline_loss = 19.655, entropy_loss = -4.2477, learner_queue_size = 32, _tick = 5729, _time = 1.6548e+09, train_seconds = 7528.6)
[2022-06-09 22:13:33,842][root][INFO] - Step 28282880 @ 4094.0 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 28282880, mean_episode_return = 66.61, mean_episode_step = 1966.3, total_loss = -58.841, pg_loss = -96.214, baseline_loss = 41.544, entropy_loss = -4.1708, learner_queue_size = 32, _tick = 5733, _time = 1.6548e+09, train_seconds = 7533.6)
[2022-06-09 22:13:38,846][root][INFO] - Step 28300800 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 28300800, mean_episode_return = 87.806, mean_episode_step = 1604.7, total_loss = -10.779, pg_loss = -22.379, baseline_loss = 16.358, entropy_loss = -4.7583, learner_queue_size = 32, _tick = 5739, _time = 1.6548e+09, train_seconds = 7538.7)
[2022-06-09 22:13:43,850][root][INFO] - Step 28321280 @ 4092.8 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 28321280, mean_episode_return = 43.79, mean_episode_step = 1608.2, total_loss = -55.795, pg_loss = -81.312, baseline_loss = 29.97, entropy_loss = -4.4537, learner_queue_size = 32, _tick = 5744, _time = 1.6548e+09, train_seconds = 7543.7)
[2022-06-09 22:13:48,854][root][INFO] - Step 28339200 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 28339200, mean_episode_return = None, mean_episode_step = 1662.6, total_loss = 407.16, pg_loss = 272.96, baseline_loss = 138.61, entropy_loss = -4.4024, learner_queue_size = 32, _tick = 5749, _time = 1.6548e+09, train_seconds = 7548.7)
[2022-06-09 22:13:53,858][root][INFO] - Step 28359680 @ 4092.8 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 28359680, mean_episode_return = 64.129, mean_episode_step = 1442.8, total_loss = 167.24, pg_loss = 91.917, baseline_loss = 78.889, entropy_loss = -3.5672, learner_queue_size = 32, _tick = 5756, _time = 1.6548e+09, train_seconds = 7553.7)
[2022-06-09 22:13:58,862][root][INFO] - Step 28377600 @ 3581.1 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 28377600, mean_episode_return = 53.202, mean_episode_step = 1578.6, total_loss = 65.257, pg_loss = 26.188, baseline_loss = 42.862, entropy_loss = -3.7929, learner_queue_size = 32, _tick = 5761, _time = 1.6548e+09, train_seconds = 7558.7)
[2022-06-09 22:14:03,866][root][INFO] - Step 28395520 @ 3580.9 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 28395520, mean_episode_return = 10.79, mean_episode_step = 1672.5, total_loss = 59.191, pg_loss = 25.351, baseline_loss = 38.207, entropy_loss = -4.3665, learner_queue_size = 32, _tick = 5765, _time = 1.6548e+09, train_seconds = 7563.7)
[2022-06-09 22:14:08,876][root][INFO] - Step 28416000 @ 4088.4 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 28416000, mean_episode_return = None, mean_episode_step = 1874.3, total_loss = 8.6273, pg_loss = -29.043, baseline_loss = 41.84, entropy_loss = -4.1701, learner_queue_size = 32, _tick = 5767, _time = 1.6548e+09, train_seconds = 7568.7)
[2022-06-09 22:14:13,878][root][INFO] - Step 28433920 @ 3582.4 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 28433920, mean_episode_return = 55.411, mean_episode_step = 1567.4, total_loss = 43.969, pg_loss = -1.4775, baseline_loss = 50.049, entropy_loss = -4.6025, learner_queue_size = 32, _tick = 5772, _time = 1.6548e+09, train_seconds = 7573.7)
[2022-06-09 22:14:18,882][root][INFO] - Step 28451840 @ 3581.0 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 28451840, mean_episode_return = 19.59, mean_episode_step = 1515.3, total_loss = -66.495, pg_loss = -96.663, baseline_loss = 34.432, entropy_loss = -4.2638, learner_queue_size = 32, _tick = 5777, _time = 1.6548e+09, train_seconds = 7578.7)
[2022-06-09 22:14:23,886][root][INFO] - Step 28472320 @ 4092.8 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 28472320, mean_episode_return = 6.8896, mean_episode_step = 1655.0, total_loss = 58.504, pg_loss = -6.163, baseline_loss = 68.698, entropy_loss = -4.0311, learner_queue_size = 32, _tick = 5780, _time = 1.6548e+09, train_seconds = 7583.7)
[2022-06-09 22:14:28,890][root][INFO] - Step 28490240 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 28490240, mean_episode_return = None, mean_episode_step = 1988.0, total_loss = 131.0, pg_loss = 71.527, baseline_loss = 63.594, entropy_loss = -4.1199, learner_queue_size = 32, _tick = 5784, _time = 1.6548e+09, train_seconds = 7588.7)
[2022-06-09 22:14:33,894][root][INFO] - Step 28510720 @ 4092.7 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 28510720, mean_episode_return = 62.499, mean_episode_step = 1928.2, total_loss = -143.62, pg_loss = -157.25, baseline_loss = 17.839, entropy_loss = -4.2034, learner_queue_size = 32, _tick = 5787, _time = 1.6548e+09, train_seconds = 7593.7)
[2022-06-09 22:14:38,898][root][INFO] - Step 28528640 @ 3581.1 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 28528640, mean_episode_return = 61.111, mean_episode_step = 1816.5, total_loss = 52.469, pg_loss = 35.07, baseline_loss = 22.03, entropy_loss = -4.6306, learner_queue_size = 32, _tick = 5791, _time = 1.6548e+09, train_seconds = 7598.7)
[2022-06-09 22:14:43,902][root][INFO] - Step 28546560 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 28546560, mean_episode_return = 52.22, mean_episode_step = 1830.6, total_loss = -78.867, pg_loss = -98.747, baseline_loss = 24.278, entropy_loss = -4.3971, learner_queue_size = 32, _tick = 5796, _time = 1.6548e+09, train_seconds = 7603.7)
[2022-06-09 22:14:48,906][root][INFO] - Step 28567040 @ 4092.8 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 28567040, mean_episode_return = 35.292, mean_episode_step = 1789.0, total_loss = 43.463, pg_loss = -7.5007, baseline_loss = 55.362, entropy_loss = -4.3984, learner_queue_size = 32, _tick = 5801, _time = 1.6548e+09, train_seconds = 7608.7)
[2022-06-09 22:14:53,910][root][INFO] - Step 28584960 @ 3581.2 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 28584960, mean_episode_return = 76.868, mean_episode_step = 1812.6, total_loss = 167.36, pg_loss = 92.808, baseline_loss = 79.37, entropy_loss = -4.8143, learner_queue_size = 32, _tick = 5803, _time = 1.6548e+09, train_seconds = 7613.7)
[2022-06-09 22:14:58,914][root][INFO] - Step 28605440 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 28605440, mean_episode_return = 23.575, mean_episode_step = 1700.2, total_loss = -70.137, pg_loss = -93.862, baseline_loss = 28.261, entropy_loss = -4.5367, learner_queue_size = 32, _tick = 5808, _time = 1.6548e+09, train_seconds = 7618.7)
[2022-06-09 22:15:03,918][root][INFO] - Step 28623360 @ 3581.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 28623360, mean_episode_return = 43.171, mean_episode_step = 1773.8, total_loss = -112.31, pg_loss = -138.06, baseline_loss = 30.257, entropy_loss = -4.5077, learner_queue_size = 32, _tick = 5811, _time = 1.6548e+09, train_seconds = 7623.7)
[2022-06-09 22:15:08,922][root][INFO] - Step 28643840 @ 4092.7 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 28643840, mean_episode_return = 60.382, mean_episode_step = 2020.4, total_loss = 46.882, pg_loss = 3.3745, baseline_loss = 48.184, entropy_loss = -4.6762, learner_queue_size = 32, _tick = 5814, _time = 1.6548e+09, train_seconds = 7628.7)
[2022-06-09 22:15:13,926][root][INFO] - Step 28661760 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 28661760, mean_episode_return = 19.04, mean_episode_step = 1734.8, total_loss = -6.3233, pg_loss = -18.047, baseline_loss = 15.687, entropy_loss = -3.9638, learner_queue_size = 32, _tick = 5818, _time = 1.6548e+09, train_seconds = 7633.7)
[2022-06-09 22:15:18,930][root][INFO] - Step 28682240 @ 4092.7 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 28682240, mean_episode_return = None, mean_episode_step = 2356.2, total_loss = 80.923, pg_loss = 43.663, baseline_loss = 41.922, entropy_loss = -4.6631, learner_queue_size = 32, _tick = 5820, _time = 1.6548e+09, train_seconds = 7638.7)
[2022-06-09 22:15:23,934][root][INFO] - Step 28700160 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 28700160, mean_episode_return = None, mean_episode_step = 1734.9, total_loss = -7.9653, pg_loss = -35.053, baseline_loss = 31.766, entropy_loss = -4.6788, learner_queue_size = 32, _tick = 5822, _time = 1.6548e+09, train_seconds = 7643.7)
[2022-06-09 22:15:28,938][root][INFO] - Step 28720640 @ 4092.5 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 28720640, mean_episode_return = 94.595, mean_episode_step = 2086.2, total_loss = 244.11, pg_loss = 160.03, baseline_loss = 88.645, entropy_loss = -4.5689, learner_queue_size = 32, _tick = 5827, _time = 1.6548e+09, train_seconds = 7648.7)
[2022-06-09 22:15:33,942][root][INFO] - Step 28738560 @ 3581.3 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 28738560, mean_episode_return = 17.491, mean_episode_step = 2113.4, total_loss = -145.42, pg_loss = -148.4, baseline_loss = 7.3984, entropy_loss = -4.4213, learner_queue_size = 32, _tick = 5833, _time = 1.6548e+09, train_seconds = 7653.7)
[2022-06-09 22:15:38,946][root][INFO] - Step 28756480 @ 3581.2 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 28756480, mean_episode_return = 39.999, mean_episode_step = 2584.6, total_loss = 160.81, pg_loss = 87.249, baseline_loss = 78.191, entropy_loss = -4.6343, learner_queue_size = 32, _tick = 5836, _time = 1.6548e+09, train_seconds = 7658.8)
[2022-06-09 22:15:43,950][root][INFO] - Step 28776960 @ 4092.8 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 28776960, mean_episode_return = 57.414, mean_episode_step = 2539.1, total_loss = -1.6017, pg_loss = -40.283, baseline_loss = 43.484, entropy_loss = -4.8029, learner_queue_size = 32, _tick = 5841, _time = 1.6548e+09, train_seconds = 7663.8)
[2022-06-09 22:15:48,954][root][INFO] - Step 28794880 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 28794880, mean_episode_return = None, mean_episode_step = 1973.7, total_loss = 226.03, pg_loss = 138.26, baseline_loss = 92.398, entropy_loss = -4.6308, learner_queue_size = 32, _tick = 5844, _time = 1.6548e+09, train_seconds = 7668.8)
[2022-06-09 22:15:53,958][root][INFO] - Step 28812800 @ 3581.2 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 28812800, mean_episode_return = 101.21, mean_episode_step = 2430.5, total_loss = -121.0, pg_loss = -133.91, baseline_loss = 17.572, entropy_loss = -4.6695, learner_queue_size = 32, _tick = 5849, _time = 1.6548e+09, train_seconds = 7673.8)
[2022-06-09 22:15:58,962][root][INFO] - Step 28830720 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 28830720, mean_episode_return = None, mean_episode_step = 2255.0, total_loss = 129.72, pg_loss = 70.328, baseline_loss = 64.067, entropy_loss = -4.6792, learner_queue_size = 32, _tick = 5852, _time = 1.6548e+09, train_seconds = 7678.8)
[2022-06-09 22:16:03,966][root][INFO] - Step 28851200 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 28851200, mean_episode_return = 62.41, mean_episode_step = 1905.0, total_loss = -124.96, pg_loss = -146.39, baseline_loss = 26.174, entropy_loss = -4.745, learner_queue_size = 32, _tick = 5859, _time = 1.6548e+09, train_seconds = 7683.8)
[2022-06-09 22:16:08,970][root][INFO] - Step 28869120 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 28869120, mean_episode_return = None, mean_episode_step = 2053.1, total_loss = 276.67, pg_loss = 225.74, baseline_loss = 55.806, entropy_loss = -4.8701, learner_queue_size = 32, _tick = 5862, _time = 1.6548e+09, train_seconds = 7688.8)
[2022-06-09 22:16:13,974][root][INFO] - Step 28889600 @ 4092.8 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 28889600, mean_episode_return = None, mean_episode_step = 1860.8, total_loss = 512.54, pg_loss = 183.63, baseline_loss = 333.72, entropy_loss = -4.8179, learner_queue_size = 32, _tick = 5867, _time = 1.6548e+09, train_seconds = 7693.8)
[2022-06-09 22:16:18,978][root][INFO] - Step 28907520 @ 3581.1 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (step = 28907520, mean_episode_return = 54.53, mean_episode_step = 2402.7, total_loss = -80.104, pg_loss = -95.243, baseline_loss = 19.948, entropy_loss = -4.8087, learner_queue_size = 32, _tick = 5872, _time = 1.6548e+09, train_seconds = 7698.8)
[2022-06-09 22:16:23,982][root][INFO] - Step 28925440 @ 3581.1 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 28925440, mean_episode_return = 59.049, mean_episode_step = 2264.0, total_loss = -223.93, pg_loss = -234.1, baseline_loss = 14.907, entropy_loss = -4.7341, learner_queue_size = 32, _tick = 5876, _time = 1.6548e+09, train_seconds = 7703.8)
[2022-06-09 22:16:28,986][root][INFO] - Step 28945920 @ 4092.7 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 28945920, mean_episode_return = None, mean_episode_step = 1643.1, total_loss = 149.85, pg_loss = 106.46, baseline_loss = 48.285, entropy_loss = -4.898, learner_queue_size = 32, _tick = 5881, _time = 1.6548e+09, train_seconds = 7708.8)
[2022-06-09 22:16:33,990][root][INFO] - Step 28963840 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 28963840, mean_episode_return = 8.5897, mean_episode_step = 1755.0, total_loss = 22.475, pg_loss = -12.399, baseline_loss = 39.733, entropy_loss = -4.8596, learner_queue_size = 32, _tick = 5886, _time = 1.6548e+09, train_seconds = 7713.8)
[2022-06-09 22:16:38,994][root][INFO] - Step 28984320 @ 4092.8 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 28984320, mean_episode_return = -24.228, mean_episode_step = 2410.5, total_loss = -54.93, pg_loss = -68.824, baseline_loss = 18.792, entropy_loss = -4.8979, learner_queue_size = 32, _tick = 5893, _time = 1.6548e+09, train_seconds = 7718.8)
[2022-06-09 22:16:43,998][root][INFO] - Step 29002240 @ 3580.9 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 29002240, mean_episode_return = None, mean_episode_step = 1976.1, total_loss = -109.15, pg_loss = -113.9, baseline_loss = 9.6269, entropy_loss = -4.8819, learner_queue_size = 32, _tick = 5895, _time = 1.6548e+09, train_seconds = 7723.8)
[2022-06-09 22:16:49,002][root][INFO] - Step 29020160 @ 3581.3 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 29020160, mean_episode_return = None, mean_episode_step = 2022.8, total_loss = -103.13, pg_loss = -104.98, baseline_loss = 6.6206, entropy_loss = -4.7786, learner_queue_size = 32, _tick = 5898, _time = 1.6548e+09, train_seconds = 7728.8)
[2022-06-09 22:16:54,006][root][INFO] - Step 29040640 @ 4092.7 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 29040640, mean_episode_return = 6.9948, mean_episode_step = 1585.2, total_loss = 82.937, pg_loss = 35.079, baseline_loss = 52.337, entropy_loss = -4.4797, learner_queue_size = 32, _tick = 5904, _time = 1.6548e+09, train_seconds = 7733.8)
[2022-06-09 22:16:59,010][root][INFO] - Step 29058560 @ 3581.2 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 29058560, mean_episode_return = None, mean_episode_step = 1670.2, total_loss = 181.06, pg_loss = 85.119, baseline_loss = 100.27, entropy_loss = -4.3301, learner_queue_size = 32, _tick = 5908, _time = 1.6548e+09, train_seconds = 7738.8)
[2022-06-09 22:17:04,014][root][INFO] - Step 29079040 @ 4092.6 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 29079040, mean_episode_return = 162.36, mean_episode_step = 1697.7, total_loss = -20.272, pg_loss = -39.472, baseline_loss = 23.998, entropy_loss = -4.7976, learner_queue_size = 32, _tick = 5914, _time = 1.6548e+09, train_seconds = 7743.8)
[2022-06-09 22:17:09,018][root][INFO] - Step 29096960 @ 3581.2 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 29096960, mean_episode_return = None, mean_episode_step = 2432.4, total_loss = 298.41, pg_loss = 224.6, baseline_loss = 78.656, entropy_loss = -4.8528, learner_queue_size = 32, _tick = 5917, _time = 1.6548e+09, train_seconds = 7748.8)
[2022-06-09 22:17:14,022][root][INFO] - Step 29114880 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 29114880, mean_episode_return = 109.85, mean_episode_step = 1892.9, total_loss = 210.24, pg_loss = 139.76, baseline_loss = 75.454, entropy_loss = -4.9684, learner_queue_size = 32, _tick = 5920, _time = 1.6548e+09, train_seconds = 7753.8)
[2022-06-09 22:17:19,026][root][INFO] - Step 29135360 @ 4092.8 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 29135360, mean_episode_return = 94.072, mean_episode_step = 1892.8, total_loss = 111.83, pg_loss = 61.88, baseline_loss = 54.857, entropy_loss = -4.904, learner_queue_size = 32, _tick = 5925, _time = 1.6548e+09, train_seconds = 7758.8)
[2022-06-09 22:17:24,030][root][INFO] - Step 29153280 @ 3581.2 SPS. Inference batcher size: 95. Learner queue size: 32. Other stats: (step = 29153280, mean_episode_return = 19.473, mean_episode_step = 1585.5, total_loss = -116.07, pg_loss = -172.97, baseline_loss = 61.733, entropy_loss = -4.8335, learner_queue_size = 32, _tick = 5930, _time = 1.6548e+09, train_seconds = 7763.8)
[2022-06-09 22:17:29,035][root][INFO] - Step 29173760 @ 4091.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 29173760, mean_episode_return = None, mean_episode_step = 1732.7, total_loss = -107.38, pg_loss = -111.28, baseline_loss = 8.7241, entropy_loss = -4.8196, learner_queue_size = 32, _tick = 5936, _time = 1.6548e+09, train_seconds = 7768.8)
[2022-06-09 22:17:34,038][root][INFO] - Step 29191680 @ 3582.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 29191680, mean_episode_return = 55.584, mean_episode_step = 1851.8, total_loss = -38.76, pg_loss = -65.276, baseline_loss = 31.431, entropy_loss = -4.9151, learner_queue_size = 32, _tick = 5942, _time = 1.6548e+09, train_seconds = 7773.8)
[2022-06-09 22:17:39,042][root][INFO] - Step 29212160 @ 4092.7 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 29212160, mean_episode_return = None, mean_episode_step = 1576.1, total_loss = 322.67, pg_loss = 241.18, baseline_loss = 86.365, entropy_loss = -4.8715, learner_queue_size = 32, _tick = 5947, _time = 1.6548e+09, train_seconds = 7778.8)
[2022-06-09 22:17:44,046][root][INFO] - Step 29230080 @ 3581.2 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 29230080, mean_episode_return = None, mean_episode_step = 1718.6, total_loss = 256.48, pg_loss = 178.94, baseline_loss = 82.335, entropy_loss = -4.7968, learner_queue_size = 32, _tick = 5951, _time = 1.6548e+09, train_seconds = 7783.9)
[2022-06-09 22:17:49,050][root][INFO] - Step 29248000 @ 3581.1 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 29248000, mean_episode_return = 11.86, mean_episode_step = 1529.5, total_loss = 106.16, pg_loss = 56.446, baseline_loss = 54.332, entropy_loss = -4.6158, learner_queue_size = 32, _tick = 5958, _time = 1.6548e+09, train_seconds = 7788.9)
[2022-06-09 22:17:54,054][root][INFO] - Step 29268480 @ 4092.7 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 29268480, mean_episode_return = 51.572, mean_episode_step = 1568.4, total_loss = -59.025, pg_loss = -61.913, baseline_loss = 7.735, entropy_loss = -4.8469, learner_queue_size = 32, _tick = 5964, _time = 1.6548e+09, train_seconds = 7793.9)
[2022-06-09 22:17:59,058][root][INFO] - Step 29286400 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 29286400, mean_episode_return = 4.7894, mean_episode_step = 1919.7, total_loss = 332.2, pg_loss = 199.92, baseline_loss = 137.18, entropy_loss = -4.9037, learner_queue_size = 32, _tick = 5965, _time = 1.6548e+09, train_seconds = 7798.9)
[2022-06-09 22:18:04,062][root][INFO] - Step 29304320 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 29304320, mean_episode_return = 103.1, mean_episode_step = 1932.7, total_loss = 35.901, pg_loss = -42.347, baseline_loss = 83.176, entropy_loss = -4.9275, learner_queue_size = 32, _tick = 5971, _time = 1.6548e+09, train_seconds = 7803.9)
[2022-06-09 22:18:09,066][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-09 22:18:09,198][root][INFO] - Step 29324800 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 29324800, mean_episode_return = None, mean_episode_step = 1824.1, total_loss = 34.004, pg_loss = 2.7961, baseline_loss = 35.929, entropy_loss = -4.721, learner_queue_size = 32, _tick = 5975, _time = 1.6548e+09, train_seconds = 7808.9)
[2022-06-09 22:18:14,202][root][INFO] - Step 29342720 @ 3489.1 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 29342720, mean_episode_return = 77.805, mean_episode_step = 1803.4, total_loss = 69.461, pg_loss = 36.998, baseline_loss = 36.733, entropy_loss = -4.2704, learner_queue_size = 32, _tick = 5981, _time = 1.6548e+09, train_seconds = 7814.0)
[2022-06-09 22:18:19,206][root][INFO] - Step 29363200 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 29363200, mean_episode_return = None, mean_episode_step = 1614.2, total_loss = 252.54, pg_loss = 174.88, baseline_loss = 82.437, entropy_loss = -4.7743, learner_queue_size = 32, _tick = 5984, _time = 1.6548e+09, train_seconds = 7819.0)
[2022-06-09 22:18:24,211][root][INFO] - Step 29381120 @ 3580.2 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 29381120, mean_episode_return = 19.03, mean_episode_step = 1798.7, total_loss = 170.35, pg_loss = 110.43, baseline_loss = 64.804, entropy_loss = -4.8843, learner_queue_size = 32, _tick = 5988, _time = 1.6548e+09, train_seconds = 7824.0)
[2022-06-09 22:18:29,214][root][INFO] - Step 29401600 @ 4093.9 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 29401600, mean_episode_return = 59.279, mean_episode_step = 2006.1, total_loss = 187.69, pg_loss = 31.522, baseline_loss = 160.97, entropy_loss = -4.8003, learner_queue_size = 32, _tick = 5993, _time = 1.6548e+09, train_seconds = 7829.0)
[2022-06-09 22:18:34,218][root][INFO] - Step 29419520 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 29419520, mean_episode_return = None, mean_episode_step = 1795.7, total_loss = 53.115, pg_loss = 4.8471, baseline_loss = 52.958, entropy_loss = -4.69, learner_queue_size = 32, _tick = 5996, _time = 1.6548e+09, train_seconds = 7834.0)
[2022-06-09 22:18:39,222][root][INFO] - Step 29437440 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 29437440, mean_episode_return = 21.75, mean_episode_step = 1729.4, total_loss = 280.47, pg_loss = 163.83, baseline_loss = 121.4, entropy_loss = -4.768, learner_queue_size = 32, _tick = 6000, _time = 1.6548e+09, train_seconds = 7839.0)
[2022-06-09 22:18:44,226][root][INFO] - Step 29455360 @ 3581.1 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 29455360, mean_episode_return = 69.389, mean_episode_step = 1777.3, total_loss = -100.77, pg_loss = -126.77, baseline_loss = 30.728, entropy_loss = -4.7333, learner_queue_size = 32, _tick = 6005, _time = 1.6548e+09, train_seconds = 7844.0)
[2022-06-09 22:18:49,230][root][INFO] - Step 29475840 @ 4092.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 29475840, mean_episode_return = None, mean_episode_step = 1933.4, total_loss = -77.135, pg_loss = -83.644, baseline_loss = 11.358, entropy_loss = -4.8487, learner_queue_size = 32, _tick = 6008, _time = 1.6548e+09, train_seconds = 7849.0)
[2022-06-09 22:18:54,234][root][INFO] - Step 29496320 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 29496320, mean_episode_return = None, mean_episode_step = 2013.3, total_loss = 103.44, pg_loss = 44.82, baseline_loss = 63.691, entropy_loss = -5.0749, learner_queue_size = 32, _tick = 6015, _time = 1.6548e+09, train_seconds = 7854.0)
[2022-06-09 22:18:59,238][root][INFO] - Step 29514240 @ 3581.1 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 29514240, mean_episode_return = 12.1, mean_episode_step = 1728.9, total_loss = 68.246, pg_loss = 23.108, baseline_loss = 49.745, entropy_loss = -4.6074, learner_queue_size = 32, _tick = 6021, _time = 1.6548e+09, train_seconds = 7859.0)
[2022-06-09 22:19:04,242][root][INFO] - Step 29532160 @ 3581.1 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 29532160, mean_episode_return = 56.88, mean_episode_step = 1606.3, total_loss = 33.36, pg_loss = -33.404, baseline_loss = 71.193, entropy_loss = -4.4296, learner_queue_size = 32, _tick = 6025, _time = 1.6548e+09, train_seconds = 7864.0)
[2022-06-09 22:19:09,246][root][INFO] - Step 29552640 @ 4092.5 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 29552640, mean_episode_return = 89.79, mean_episode_step = 1625.0, total_loss = 72.166, pg_loss = -11.329, baseline_loss = 88.226, entropy_loss = -4.7309, learner_queue_size = 32, _tick = 6031, _time = 1.6548e+09, train_seconds = 7869.1)
[2022-06-09 22:19:14,250][root][INFO] - Step 29570560 @ 3581.3 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 29570560, mean_episode_return = 46.422, mean_episode_step = 1776.3, total_loss = 1.0368, pg_loss = -12.218, baseline_loss = 18.219, entropy_loss = -4.9647, learner_queue_size = 32, _tick = 6037, _time = 1.6548e+09, train_seconds = 7874.1)
[2022-06-09 22:19:19,254][root][INFO] - Step 29591040 @ 4092.7 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 29591040, mean_episode_return = 78.441, mean_episode_step = 1899.7, total_loss = -6.411, pg_loss = -22.966, baseline_loss = 21.686, entropy_loss = -5.1313, learner_queue_size = 32, _tick = 6042, _time = 1.6548e+09, train_seconds = 7879.1)
[2022-06-09 22:19:24,258][root][INFO] - Step 29608960 @ 3580.8 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 29608960, mean_episode_return = None, mean_episode_step = 1291.2, total_loss = 122.25, pg_loss = 68.262, baseline_loss = 58.946, entropy_loss = -4.9582, learner_queue_size = 32, _tick = 6046, _time = 1.6548e+09, train_seconds = 7884.1)
[2022-06-09 22:19:29,262][root][INFO] - Step 29626880 @ 3581.5 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 29626880, mean_episode_return = 53.004, mean_episode_step = 1192.6, total_loss = -93.36, pg_loss = -147.69, baseline_loss = 59.145, entropy_loss = -4.8124, learner_queue_size = 32, _tick = 6052, _time = 1.6548e+09, train_seconds = 7889.1)
[2022-06-09 22:19:34,266][root][INFO] - Step 29644800 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 29644800, mean_episode_return = 15.305, mean_episode_step = 1550.0, total_loss = -120.68, pg_loss = -153.27, baseline_loss = 37.339, entropy_loss = -4.7477, learner_queue_size = 32, _tick = 6056, _time = 1.6548e+09, train_seconds = 7894.1)
[2022-06-09 22:19:39,270][root][INFO] - Step 29665280 @ 4092.6 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 29665280, mean_episode_return = None, mean_episode_step = 1670.2, total_loss = 201.99, pg_loss = 129.25, baseline_loss = 77.566, entropy_loss = -4.835, learner_queue_size = 32, _tick = 6062, _time = 1.6548e+09, train_seconds = 7899.1)
[2022-06-09 22:19:44,274][root][INFO] - Step 29683200 @ 3581.3 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 29683200, mean_episode_return = 50.537, mean_episode_step = 1360.0, total_loss = -71.591, pg_loss = -106.63, baseline_loss = 39.809, entropy_loss = -4.7727, learner_queue_size = 32, _tick = 6066, _time = 1.6548e+09, train_seconds = 7904.1)
[2022-06-09 22:19:49,278][root][INFO] - Step 29703680 @ 4092.7 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 29703680, mean_episode_return = 41.141, mean_episode_step = 1429.7, total_loss = -68.522, pg_loss = -81.724, baseline_loss = 18.283, entropy_loss = -5.0802, learner_queue_size = 32, _tick = 6071, _time = 1.6548e+09, train_seconds = 7909.1)
[2022-06-09 22:19:54,282][root][INFO] - Step 29721600 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 29721600, mean_episode_return = None, mean_episode_step = 1594.3, total_loss = 18.998, pg_loss = 2.332, baseline_loss = 21.593, entropy_loss = -4.9271, learner_queue_size = 32, _tick = 6076, _time = 1.6548e+09, train_seconds = 7914.1)
[2022-06-09 22:19:59,286][root][INFO] - Step 29739520 @ 3580.8 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 29739520, mean_episode_return = 112.19, mean_episode_step = 1527.7, total_loss = -70.512, pg_loss = -91.659, baseline_loss = 25.851, entropy_loss = -4.7039, learner_queue_size = 32, _tick = 6082, _time = 1.6548e+09, train_seconds = 7919.1)
[2022-06-09 22:20:04,293][root][INFO] - Step 29760000 @ 4090.9 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 29760000, mean_episode_return = None, mean_episode_step = 1698.6, total_loss = 35.702, pg_loss = 28.796, baseline_loss = 10.877, entropy_loss = -3.9719, learner_queue_size = 32, _tick = 6087, _time = 1.6548e+09, train_seconds = 7924.1)
[2022-06-09 22:20:09,298][root][INFO] - Step 29777920 @ 3580.2 SPS. Inference batcher size: 73. Learner queue size: 32. Other stats: (step = 29777920, mean_episode_return = 25.625, mean_episode_step = 1722.0, total_loss = 177.49, pg_loss = 121.04, baseline_loss = 61.254, entropy_loss = -4.8005, learner_queue_size = 32, _tick = 6090, _time = 1.6548e+09, train_seconds = 7929.1)
[2022-06-09 22:20:14,302][root][INFO] - Step 29795840 @ 3581.0 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 29795840, mean_episode_return = None, mean_episode_step = 1408.7, total_loss = 62.956, pg_loss = 31.885, baseline_loss = 35.959, entropy_loss = -4.8881, learner_queue_size = 32, _tick = 6093, _time = 1.6548e+09, train_seconds = 7934.1)
[2022-06-09 22:20:19,307][root][INFO] - Step 29813760 @ 3580.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 29813760, mean_episode_return = None, mean_episode_step = 1525.0, total_loss = 149.46, pg_loss = 108.41, baseline_loss = 46.052, entropy_loss = -5.0038, learner_queue_size = 32, _tick = 6095, _time = 1.6548e+09, train_seconds = 7939.1)
[2022-06-09 22:20:24,310][root][INFO] - Step 29834240 @ 4093.3 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 29834240, mean_episode_return = 46.081, mean_episode_step = 1794.7, total_loss = 48.285, pg_loss = 1.8063, baseline_loss = 51.379, entropy_loss = -4.9001, learner_queue_size = 32, _tick = 6100, _time = 1.6548e+09, train_seconds = 7944.1)
[2022-06-09 22:20:29,314][root][INFO] - Step 29849600 @ 3069.5 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 29849600, mean_episode_return = 140.85, mean_episode_step = 1782.6, total_loss = -56.52, pg_loss = -77.016, baseline_loss = 25.392, entropy_loss = -4.8954, learner_queue_size = 32, _tick = 6106, _time = 1.6548e+09, train_seconds = 7949.1)
[2022-06-09 22:20:34,318][root][INFO] - Step 29867520 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 29867520, mean_episode_return = 47.76, mean_episode_step = 1296.8, total_loss = 104.76, pg_loss = 66.177, baseline_loss = 43.502, entropy_loss = -4.9167, learner_queue_size = 32, _tick = 6109, _time = 1.6548e+09, train_seconds = 7954.1)
[2022-06-09 22:20:39,322][root][INFO] - Step 29888000 @ 4092.7 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 29888000, mean_episode_return = 91.347, mean_episode_step = 1977.0, total_loss = -189.18, pg_loss = -198.69, baseline_loss = 14.772, entropy_loss = -5.2596, learner_queue_size = 32, _tick = 6115, _time = 1.6548e+09, train_seconds = 7959.1)
[2022-06-09 22:20:44,326][root][INFO] - Step 29905920 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 29905920, mean_episode_return = None, mean_episode_step = 1388.1, total_loss = 35.005, pg_loss = 20.118, baseline_loss = 19.857, entropy_loss = -4.9698, learner_queue_size = 32, _tick = 6119, _time = 1.6548e+09, train_seconds = 7964.1)
[2022-06-09 22:20:49,330][root][INFO] - Step 29926400 @ 4092.7 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 29926400, mean_episode_return = None, mean_episode_step = 1399.5, total_loss = 25.799, pg_loss = 12.444, baseline_loss = 17.639, entropy_loss = -4.2841, learner_queue_size = 32, _tick = 6125, _time = 1.6548e+09, train_seconds = 7969.1)
[2022-06-09 22:20:54,334][root][INFO] - Step 29944320 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 29944320, mean_episode_return = None, mean_episode_step = 1387.7, total_loss = 72.59, pg_loss = 21.696, baseline_loss = 55.34, entropy_loss = -4.4461, learner_queue_size = 32, _tick = 6130, _time = 1.6548e+09, train_seconds = 7974.1)
[2022-06-09 22:20:59,338][root][INFO] - Step 29964800 @ 4092.6 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 29964800, mean_episode_return = 13.4, mean_episode_step = 1293.9, total_loss = -4.1191, pg_loss = -12.526, baseline_loss = 13.39, entropy_loss = -4.9829, learner_queue_size = 32, _tick = 6136, _time = 1.6548e+09, train_seconds = 7979.1)
[2022-06-09 22:21:04,342][root][INFO] - Step 29982720 @ 3581.2 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 29982720, mean_episode_return = 120.54, mean_episode_step = 1432.2, total_loss = 241.24, pg_loss = 176.42, baseline_loss = 69.917, entropy_loss = -5.0926, learner_queue_size = 32, _tick = 6139, _time = 1.6548e+09, train_seconds = 7984.1)
[2022-06-09 22:21:09,346][root][INFO] - Step 30000640 @ 3581.2 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 30000640, mean_episode_return = None, mean_episode_step = 1923.0, total_loss = -36.315, pg_loss = -40.783, baseline_loss = 9.4086, entropy_loss = -4.9409, learner_queue_size = 32, _tick = 6142, _time = 1.6548e+09, train_seconds = 7989.2)
[2022-06-09 22:21:14,350][root][INFO] - Step 30021120 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 30021120, mean_episode_return = 10.805, mean_episode_step = 1495.9, total_loss = 183.14, pg_loss = 69.745, baseline_loss = 118.44, entropy_loss = -5.0476, learner_queue_size = 32, _tick = 6148, _time = 1.6548e+09, train_seconds = 7994.2)
[2022-06-09 22:21:19,354][root][INFO] - Step 30041600 @ 4092.8 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 30041600, mean_episode_return = 12.72, mean_episode_step = 1489.3, total_loss = 91.9, pg_loss = 43.057, baseline_loss = 53.691, entropy_loss = -4.8488, learner_queue_size = 32, _tick = 6153, _time = 1.6548e+09, train_seconds = 7999.2)
[2022-06-09 22:21:24,358][root][INFO] - Step 30059520 @ 3581.1 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 30059520, mean_episode_return = 106.61, mean_episode_step = 1960.7, total_loss = 76.562, pg_loss = 49.809, baseline_loss = 31.908, entropy_loss = -5.1561, learner_queue_size = 32, _tick = 6159, _time = 1.6548e+09, train_seconds = 8004.2)
[2022-06-09 22:21:29,362][root][INFO] - Step 30077440 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 30077440, mean_episode_return = 74.956, mean_episode_step = 1641.3, total_loss = 35.357, pg_loss = -16.006, baseline_loss = 56.237, entropy_loss = -4.8737, learner_queue_size = 32, _tick = 6165, _time = 1.6548e+09, train_seconds = 8009.2)
[2022-06-09 22:21:34,366][root][INFO] - Step 30097920 @ 4092.7 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (step = 30097920, mean_episode_return = 63.342, mean_episode_step = 1660.0, total_loss = 183.06, pg_loss = 114.78, baseline_loss = 73.117, entropy_loss = -4.8376, learner_queue_size = 32, _tick = 6172, _time = 1.6548e+09, train_seconds = 8014.2)
[2022-06-09 22:21:39,370][root][INFO] - Step 30118400 @ 4092.7 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 30118400, mean_episode_return = 186.6, mean_episode_step = 1070.2, total_loss = -63.559, pg_loss = -97.561, baseline_loss = 38.369, entropy_loss = -4.3665, learner_queue_size = 32, _tick = 6179, _time = 1.6548e+09, train_seconds = 8019.2)
[2022-06-09 22:21:44,374][root][INFO] - Step 30136320 @ 3581.0 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 30136320, mean_episode_return = 38.111, mean_episode_step = 1009.3, total_loss = 14.502, pg_loss = -9.747, baseline_loss = 29.066, entropy_loss = -4.8165, learner_queue_size = 32, _tick = 6183, _time = 1.6548e+09, train_seconds = 8024.2)
[2022-06-09 22:21:49,378][root][INFO] - Step 30154240 @ 3581.3 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 30154240, mean_episode_return = None, mean_episode_step = 1296.8, total_loss = -120.5, pg_loss = -125.96, baseline_loss = 10.226, entropy_loss = -4.7662, learner_queue_size = 32, _tick = 6187, _time = 1.6548e+09, train_seconds = 8029.2)
[2022-06-09 22:21:54,382][root][INFO] - Step 30174720 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 30174720, mean_episode_return = 20.825, mean_episode_step = 1059.2, total_loss = 907.13, pg_loss = 274.16, baseline_loss = 637.67, entropy_loss = -4.7052, learner_queue_size = 32, _tick = 6195, _time = 1.6548e+09, train_seconds = 8034.2)
[2022-06-09 22:21:59,386][root][INFO] - Step 30192640 @ 3581.2 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 30192640, mean_episode_return = 19.985, mean_episode_step = 1680.9, total_loss = 231.62, pg_loss = 82.628, baseline_loss = 153.48, entropy_loss = -4.4811, learner_queue_size = 32, _tick = 6200, _time = 1.6548e+09, train_seconds = 8039.2)
[2022-06-09 22:22:04,390][root][INFO] - Step 30210560 @ 3581.0 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 30210560, mean_episode_return = None, mean_episode_step = 1379.6, total_loss = 66.164, pg_loss = 16.373, baseline_loss = 54.428, entropy_loss = -4.6369, learner_queue_size = 32, _tick = 6205, _time = 1.6548e+09, train_seconds = 8044.2)
[2022-06-09 22:22:09,394][root][INFO] - Step 30231040 @ 4092.9 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 30231040, mean_episode_return = 51.641, mean_episode_step = 1766.9, total_loss = 192.19, pg_loss = 97.733, baseline_loss = 99.16, entropy_loss = -4.7026, learner_queue_size = 32, _tick = 6211, _time = 1.6548e+09, train_seconds = 8049.2)
[2022-06-09 22:22:14,398][root][INFO] - Step 30248960 @ 3581.1 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 30248960, mean_episode_return = 103.19, mean_episode_step = 1286.9, total_loss = 120.23, pg_loss = 62.392, baseline_loss = 62.739, entropy_loss = -4.8986, learner_queue_size = 32, _tick = 6216, _time = 1.6548e+09, train_seconds = 8054.2)
[2022-06-09 22:22:19,403][root][INFO] - Step 30266880 @ 3580.1 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 30266880, mean_episode_return = 22.139, mean_episode_step = 1246.7, total_loss = 68.192, pg_loss = 20.581, baseline_loss = 52.376, entropy_loss = -4.765, learner_queue_size = 32, _tick = 6223, _time = 1.6548e+09, train_seconds = 8059.2)
[2022-06-09 22:22:24,406][root][INFO] - Step 30287360 @ 4094.0 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 30287360, mean_episode_return = None, mean_episode_step = 1682.0, total_loss = 54.893, pg_loss = 24.672, baseline_loss = 35.054, entropy_loss = -4.8333, learner_queue_size = 32, _tick = 6229, _time = 1.6548e+09, train_seconds = 8064.2)
[2022-06-09 22:22:29,412][root][INFO] - Step 30305280 @ 3579.7 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 30305280, mean_episode_return = 48.165, mean_episode_step = 1428.1, total_loss = -49.32, pg_loss = -72.057, baseline_loss = 27.645, entropy_loss = -4.9083, learner_queue_size = 32, _tick = 6235, _time = 1.6548e+09, train_seconds = 8069.2)
[2022-06-09 22:22:34,414][root][INFO] - Step 30325760 @ 4094.3 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 30325760, mean_episode_return = 65.247, mean_episode_step = 1750.5, total_loss = -158.51, pg_loss = -168.17, baseline_loss = 14.479, entropy_loss = -4.8146, learner_queue_size = 32, _tick = 6240, _time = 1.6548e+09, train_seconds = 8074.2)
[2022-06-09 22:22:39,418][root][INFO] - Step 30343680 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 30343680, mean_episode_return = 98.905, mean_episode_step = 1317.1, total_loss = 1.2465, pg_loss = -34.557, baseline_loss = 40.499, entropy_loss = -4.6959, learner_queue_size = 32, _tick = 6244, _time = 1.6548e+09, train_seconds = 8079.2)
[2022-06-09 22:22:44,422][root][INFO] - Step 30361600 @ 3581.2 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 30361600, mean_episode_return = 71.01, mean_episode_step = 1395.9, total_loss = -6.6176, pg_loss = -23.874, baseline_loss = 22.244, entropy_loss = -4.9879, learner_queue_size = 32, _tick = 6250, _time = 1.6548e+09, train_seconds = 8084.2)
[2022-06-09 22:22:49,426][root][INFO] - Step 30379520 @ 3581.1 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 30379520, mean_episode_return = 61.939, mean_episode_step = 1271.7, total_loss = -74.963, pg_loss = -105.37, baseline_loss = 35.061, entropy_loss = -4.6552, learner_queue_size = 32, _tick = 6255, _time = 1.6548e+09, train_seconds = 8089.2)
[2022-06-09 22:22:54,430][root][INFO] - Step 30400000 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 30400000, mean_episode_return = 18.53, mean_episode_step = 1336.2, total_loss = 41.829, pg_loss = -14.343, baseline_loss = 60.792, entropy_loss = -4.62, learner_queue_size = 32, _tick = 6261, _time = 1.6548e+09, train_seconds = 8094.2)
[2022-06-09 22:22:59,434][root][INFO] - Step 30417920 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 30417920, mean_episode_return = 69.78, mean_episode_step = 1313.7, total_loss = -7.2094, pg_loss = -47.139, baseline_loss = 44.754, entropy_loss = -4.8244, learner_queue_size = 32, _tick = 6266, _time = 1.6548e+09, train_seconds = 8099.2)
[2022-06-09 22:23:04,438][root][INFO] - Step 30435840 @ 3581.2 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 30435840, mean_episode_return = 28.25, mean_episode_step = 1482.5, total_loss = 86.283, pg_loss = 43.681, baseline_loss = 45.876, entropy_loss = -3.2741, learner_queue_size = 32, _tick = 6272, _time = 1.6548e+09, train_seconds = 8104.2)
[2022-06-09 22:23:09,442][root][INFO] - Step 30456320 @ 4092.6 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 30456320, mean_episode_return = 26.66, mean_episode_step = 1128.3, total_loss = -27.193, pg_loss = -48.273, baseline_loss = 25.818, entropy_loss = -4.7371, learner_queue_size = 32, _tick = 6278, _time = 1.6548e+09, train_seconds = 8109.2)
[2022-06-09 22:23:14,446][root][INFO] - Step 30474240 @ 3581.0 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 30474240, mean_episode_return = None, mean_episode_step = 1058.3, total_loss = 327.43, pg_loss = 218.92, baseline_loss = 112.98, entropy_loss = -4.4741, learner_queue_size = 32, _tick = 6281, _time = 1.6548e+09, train_seconds = 8114.3)
[2022-06-09 22:23:19,450][root][INFO] - Step 30492160 @ 3581.3 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 30492160, mean_episode_return = 28.28, mean_episode_step = 1615.4, total_loss = -34.659, pg_loss = -95.758, baseline_loss = 65.857, entropy_loss = -4.7581, learner_queue_size = 32, _tick = 6285, _time = 1.6548e+09, train_seconds = 8119.3)
[2022-06-09 22:23:24,454][root][INFO] - Step 30510080 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 30510080, mean_episode_return = 1.0995, mean_episode_step = 1409.3, total_loss = 1.1997, pg_loss = -27.127, baseline_loss = 33.041, entropy_loss = -4.7148, learner_queue_size = 32, _tick = 6290, _time = 1.6548e+09, train_seconds = 8124.3)
[2022-06-09 22:23:29,458][root][INFO] - Step 30530560 @ 4092.8 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 30530560, mean_episode_return = 115.89, mean_episode_step = 1610.4, total_loss = -17.173, pg_loss = -57.06, baseline_loss = 44.713, entropy_loss = -4.8267, learner_queue_size = 32, _tick = 6296, _time = 1.6548e+09, train_seconds = 8129.3)
[2022-06-09 22:23:34,462][root][INFO] - Step 30548480 @ 3581.2 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 30548480, mean_episode_return = 7.2598, mean_episode_step = 1530.9, total_loss = 366.63, pg_loss = 276.87, baseline_loss = 94.724, entropy_loss = -4.9659, learner_queue_size = 32, _tick = 6302, _time = 1.6548e+09, train_seconds = 8134.3)
[2022-06-09 22:23:39,466][root][INFO] - Step 30568960 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 30568960, mean_episode_return = 140.74, mean_episode_step = 1334.9, total_loss = -158.55, pg_loss = -182.49, baseline_loss = 28.75, entropy_loss = -4.8151, learner_queue_size = 32, _tick = 6308, _time = 1.6548e+09, train_seconds = 8139.3)
[2022-06-09 22:23:44,470][root][INFO] - Step 30586880 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 30586880, mean_episode_return = 125.17, mean_episode_step = 1149.5, total_loss = 213.7, pg_loss = 149.25, baseline_loss = 69.159, entropy_loss = -4.709, learner_queue_size = 32, _tick = 6313, _time = 1.6548e+09, train_seconds = 8144.3)
[2022-06-09 22:23:49,474][root][INFO] - Step 30607360 @ 4092.7 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 30607360, mean_episode_return = 186.54, mean_episode_step = 1455.4, total_loss = 103.44, pg_loss = 54.246, baseline_loss = 52.73, entropy_loss = -3.5335, learner_queue_size = 32, _tick = 6320, _time = 1.6548e+09, train_seconds = 8149.3)
[2022-06-09 22:23:54,478][root][INFO] - Step 30625280 @ 3581.1 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (step = 30625280, mean_episode_return = 20.37, mean_episode_step = 1393.5, total_loss = -34.693, pg_loss = -68.789, baseline_loss = 38.762, entropy_loss = -4.6658, learner_queue_size = 32, _tick = 6323, _time = 1.6548e+09, train_seconds = 8154.3)
[2022-06-09 22:23:59,482][root][INFO] - Step 30643200 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 30643200, mean_episode_return = 43.495, mean_episode_step = 1564.6, total_loss = 25.696, pg_loss = -29.12, baseline_loss = 59.682, entropy_loss = -4.8658, learner_queue_size = 32, _tick = 6327, _time = 1.6548e+09, train_seconds = 8159.3)
[2022-06-09 22:24:04,486][root][INFO] - Step 30663680 @ 4092.7 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 30663680, mean_episode_return = 38.151, mean_episode_step = 1652.5, total_loss = 236.0, pg_loss = 140.79, baseline_loss = 100.17, entropy_loss = -4.9526, learner_queue_size = 32, _tick = 6333, _time = 1.6548e+09, train_seconds = 8164.3)
[2022-06-09 22:24:09,490][root][INFO] - Step 30681600 @ 3581.2 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 30681600, mean_episode_return = -3.4102, mean_episode_step = 1779.7, total_loss = -24.532, pg_loss = -46.166, baseline_loss = 26.765, entropy_loss = -5.1308, learner_queue_size = 32, _tick = 6339, _time = 1.6548e+09, train_seconds = 8169.3)
[2022-06-09 22:24:14,494][root][INFO] - Step 30702080 @ 4092.7 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 30702080, mean_episode_return = 21.08, mean_episode_step = 1397.4, total_loss = -80.053, pg_loss = -110.62, baseline_loss = 35.315, entropy_loss = -4.7446, learner_queue_size = 32, _tick = 6344, _time = 1.6548e+09, train_seconds = 8174.3)
[2022-06-09 22:24:19,498][root][INFO] - Step 30720000 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 30720000, mean_episode_return = 16.947, mean_episode_step = 1659.9, total_loss = -62.558, pg_loss = -113.8, baseline_loss = 56.416, entropy_loss = -5.1725, learner_queue_size = 32, _tick = 6350, _time = 1.6548e+09, train_seconds = 8179.3)
[2022-06-09 22:24:24,502][root][INFO] - Step 30737920 @ 3581.1 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 30737920, mean_episode_return = 6.14, mean_episode_step = 1317.3, total_loss = -59.961, pg_loss = -85.205, baseline_loss = 30.398, entropy_loss = -5.1539, learner_queue_size = 32, _tick = 6357, _time = 1.6548e+09, train_seconds = 8184.3)
[2022-06-09 22:24:29,506][root][INFO] - Step 30758400 @ 4092.7 SPS. Inference batcher size: 81. Learner queue size: 32. Other stats: (step = 30758400, mean_episode_return = 98.542, mean_episode_step = 1720.1, total_loss = 388.91, pg_loss = 190.85, baseline_loss = 202.76, entropy_loss = -4.703, learner_queue_size = 32, _tick = 6365, _time = 1.6548e+09, train_seconds = 8189.3)
[2022-06-09 22:24:34,510][root][INFO] - Step 30776320 @ 3581.0 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 30776320, mean_episode_return = None, mean_episode_step = 1401.8, total_loss = -8.1778, pg_loss = -36.226, baseline_loss = 32.935, entropy_loss = -4.8866, learner_queue_size = 32, _tick = 6369, _time = 1.6548e+09, train_seconds = 8194.3)
[2022-06-09 22:24:39,514][root][INFO] - Step 30794240 @ 3581.3 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 30794240, mean_episode_return = 71.23, mean_episode_step = 1309.3, total_loss = -2.7259, pg_loss = -37.394, baseline_loss = 39.626, entropy_loss = -4.9574, learner_queue_size = 32, _tick = 6375, _time = 1.6548e+09, train_seconds = 8199.3)
[2022-06-09 22:24:44,518][root][INFO] - Step 30812160 @ 3581.1 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 30812160, mean_episode_return = 65.355, mean_episode_step = 1253.5, total_loss = 32.695, pg_loss = -21.127, baseline_loss = 58.241, entropy_loss = -4.418, learner_queue_size = 32, _tick = 6380, _time = 1.6548e+09, train_seconds = 8204.3)
[2022-06-09 22:24:49,523][root][INFO] - Step 30832640 @ 4092.1 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 30832640, mean_episode_return = None, mean_episode_step = 1376.5, total_loss = 115.36, pg_loss = 96.196, baseline_loss = 24.06, entropy_loss = -4.8932, learner_queue_size = 32, _tick = 6386, _time = 1.6548e+09, train_seconds = 8209.3)
[2022-06-09 22:24:54,526][root][INFO] - Step 30850560 @ 3581.7 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 30850560, mean_episode_return = 53.173, mean_episode_step = 1024.0, total_loss = 75.755, pg_loss = 27.724, baseline_loss = 52.823, entropy_loss = -4.7922, learner_queue_size = 32, _tick = 6392, _time = 1.6548e+09, train_seconds = 8214.3)
[2022-06-09 22:24:59,530][root][INFO] - Step 30868480 @ 3581.1 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 30868480, mean_episode_return = 27.456, mean_episode_step = 976.49, total_loss = -64.038, pg_loss = -80.898, baseline_loss = 21.654, entropy_loss = -4.7937, learner_queue_size = 32, _tick = 6398, _time = 1.6548e+09, train_seconds = 8219.3)
[2022-06-09 22:25:04,534][root][INFO] - Step 30888960 @ 4092.7 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 30888960, mean_episode_return = None, mean_episode_step = 1197.8, total_loss = 359.75, pg_loss = 250.08, baseline_loss = 114.57, entropy_loss = -4.8983, learner_queue_size = 32, _tick = 6403, _time = 1.6548e+09, train_seconds = 8224.3)
[2022-06-09 22:25:09,538][root][INFO] - Step 30906880 @ 3581.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 30906880, mean_episode_return = 39.985, mean_episode_step = 1341.8, total_loss = 2.4649, pg_loss = -20.514, baseline_loss = 27.446, entropy_loss = -4.4671, learner_queue_size = 32, _tick = 6410, _time = 1.6548e+09, train_seconds = 8229.3)
[2022-06-09 22:25:14,542][root][INFO] - Step 30924800 @ 3581.1 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 30924800, mean_episode_return = None, mean_episode_step = 1522.2, total_loss = 204.81, pg_loss = 156.08, baseline_loss = 53.762, entropy_loss = -5.0374, learner_queue_size = 32, _tick = 6414, _time = 1.6548e+09, train_seconds = 8234.3)
[2022-06-09 22:25:19,546][root][INFO] - Step 30945280 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 30945280, mean_episode_return = None, mean_episode_step = 1266.5, total_loss = -97.421, pg_loss = -110.12, baseline_loss = 17.657, entropy_loss = -4.9566, learner_queue_size = 32, _tick = 6417, _time = 1.6548e+09, train_seconds = 8239.4)
[2022-06-09 22:25:24,550][root][INFO] - Step 30963200 @ 3581.2 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 30963200, mean_episode_return = 50.771, mean_episode_step = 905.72, total_loss = 343.96, pg_loss = 236.85, baseline_loss = 111.96, entropy_loss = -4.8472, learner_queue_size = 32, _tick = 6422, _time = 1.6548e+09, train_seconds = 8244.4)
[2022-06-09 22:25:29,554][root][INFO] - Step 30983680 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 30983680, mean_episode_return = None, mean_episode_step = 1272.3, total_loss = 62.842, pg_loss = -24.024, baseline_loss = 91.628, entropy_loss = -4.7614, learner_queue_size = 32, _tick = 6428, _time = 1.6548e+09, train_seconds = 8249.4)
[2022-06-09 22:25:34,558][root][INFO] - Step 31001600 @ 3581.1 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 31001600, mean_episode_return = 63.013, mean_episode_step = 1346.2, total_loss = -1.7999, pg_loss = -21.416, baseline_loss = 24.376, entropy_loss = -4.7596, learner_queue_size = 32, _tick = 6433, _time = 1.6548e+09, train_seconds = 8254.4)
[2022-06-09 22:25:39,562][root][INFO] - Step 31019520 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 31019520, mean_episode_return = 8.9495, mean_episode_step = 1382.0, total_loss = 50.247, pg_loss = 11.635, baseline_loss = 42.933, entropy_loss = -4.3209, learner_queue_size = 32, _tick = 6439, _time = 1.6548e+09, train_seconds = 8259.4)
[2022-06-09 22:25:44,566][root][INFO] - Step 31037440 @ 3581.2 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 31037440, mean_episode_return = None, mean_episode_step = 1219.0, total_loss = -17.48, pg_loss = -30.703, baseline_loss = 18.012, entropy_loss = -4.7897, learner_queue_size = 32, _tick = 6445, _time = 1.6548e+09, train_seconds = 8264.4)
[2022-06-09 22:25:49,570][root][INFO] - Step 31057920 @ 4092.7 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (step = 31057920, mean_episode_return = 41.339, mean_episode_step = 1385.5, total_loss = 204.06, pg_loss = 130.45, baseline_loss = 77.899, entropy_loss = -4.2874, learner_queue_size = 32, _tick = 6450, _time = 1.6548e+09, train_seconds = 8269.4)
[2022-06-09 22:25:54,574][root][INFO] - Step 31075840 @ 3581.1 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 31075840, mean_episode_return = None, mean_episode_step = 1419.2, total_loss = -83.672, pg_loss = -101.34, baseline_loss = 22.014, entropy_loss = -4.3429, learner_queue_size = 32, _tick = 6453, _time = 1.6548e+09, train_seconds = 8274.4)
[2022-06-09 22:25:59,578][root][INFO] - Step 31096320 @ 4092.6 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 31096320, mean_episode_return = -7.3604, mean_episode_step = 1124.7, total_loss = 84.321, pg_loss = 61.572, baseline_loss = 27.832, entropy_loss = -5.0831, learner_queue_size = 32, _tick = 6457, _time = 1.6548e+09, train_seconds = 8279.4)
[2022-06-09 22:26:04,582][root][INFO] - Step 31114240 @ 3581.2 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 31114240, mean_episode_return = 89.74, mean_episode_step = 1427.1, total_loss = -74.163, pg_loss = -86.6, baseline_loss = 17.134, entropy_loss = -4.6973, learner_queue_size = 32, _tick = 6462, _time = 1.6548e+09, train_seconds = 8284.4)
[2022-06-09 22:26:09,586][root][INFO] - Step 31132160 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 31132160, mean_episode_return = None, mean_episode_step = 1200.9, total_loss = 207.62, pg_loss = 159.72, baseline_loss = 52.642, entropy_loss = -4.7444, learner_queue_size = 32, _tick = 6466, _time = 1.6548e+09, train_seconds = 8289.4)
[2022-06-09 22:26:14,590][root][INFO] - Step 31150080 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 31150080, mean_episode_return = 85.147, mean_episode_step = 1365.3, total_loss = -121.94, pg_loss = -134.7, baseline_loss = 17.633, entropy_loss = -4.8662, learner_queue_size = 32, _tick = 6473, _time = 1.6548e+09, train_seconds = 8294.4)
[2022-06-09 22:26:19,595][root][INFO] - Step 31170560 @ 4092.3 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 31170560, mean_episode_return = 98.17, mean_episode_step = 1326.1, total_loss = -49.767, pg_loss = -65.09, baseline_loss = 19.843, entropy_loss = -4.519, learner_queue_size = 32, _tick = 6481, _time = 1.6548e+09, train_seconds = 8299.4)
[2022-06-09 22:26:24,598][root][INFO] - Step 31188480 @ 3581.6 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (step = 31188480, mean_episode_return = 187.65, mean_episode_step = 1083.5, total_loss = 805.64, pg_loss = 574.82, baseline_loss = 235.58, entropy_loss = -4.7589, learner_queue_size = 32, _tick = 6487, _time = 1.6548e+09, train_seconds = 8304.4)
[2022-06-09 22:26:29,602][root][INFO] - Step 31208960 @ 4092.8 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 31208960, mean_episode_return = 42.305, mean_episode_step = 1103.3, total_loss = 70.296, pg_loss = 48.184, baseline_loss = 27.115, entropy_loss = -5.0037, learner_queue_size = 32, _tick = 6493, _time = 1.6548e+09, train_seconds = 8309.4)
[2022-06-09 22:26:34,606][root][INFO] - Step 31226880 @ 3581.1 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 31226880, mean_episode_return = 56.387, mean_episode_step = 1114.3, total_loss = 203.57, pg_loss = 156.72, baseline_loss = 51.654, entropy_loss = -4.8082, learner_queue_size = 32, _tick = 6499, _time = 1.6548e+09, train_seconds = 8314.4)
[2022-06-09 22:26:39,610][root][INFO] - Step 31247360 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 31247360, mean_episode_return = 32.983, mean_episode_step = 1072.3, total_loss = -134.85, pg_loss = -186.55, baseline_loss = 56.197, entropy_loss = -4.4948, learner_queue_size = 32, _tick = 6505, _time = 1.6548e+09, train_seconds = 8319.4)
[2022-06-09 22:26:44,616][root][INFO] - Step 31265280 @ 3579.7 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 31265280, mean_episode_return = 32.34, mean_episode_step = 1074.9, total_loss = 101.38, pg_loss = 66.078, baseline_loss = 40.259, entropy_loss = -4.953, learner_queue_size = 32, _tick = 6509, _time = 1.6548e+09, train_seconds = 8324.4)
[2022-06-09 22:26:49,622][root][INFO] - Step 31283200 @ 3579.7 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 31283200, mean_episode_return = 26.88, mean_episode_step = 1285.5, total_loss = 72.731, pg_loss = 9.1933, baseline_loss = 68.379, entropy_loss = -4.8416, learner_queue_size = 32, _tick = 6516, _time = 1.6548e+09, train_seconds = 8329.4)
[2022-06-09 22:26:54,626][root][INFO] - Step 31301120 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 31301120, mean_episode_return = 78.265, mean_episode_step = 1205.2, total_loss = 62.426, pg_loss = -6.6736, baseline_loss = 73.265, entropy_loss = -4.1659, learner_queue_size = 32, _tick = 6521, _time = 1.6548e+09, train_seconds = 8334.4)
[2022-06-09 22:26:59,630][root][INFO] - Step 31321600 @ 4092.5 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 31321600, mean_episode_return = 141.54, mean_episode_step = 1488.2, total_loss = 323.53, pg_loss = 231.52, baseline_loss = 96.972, entropy_loss = -4.9602, learner_queue_size = 32, _tick = 6526, _time = 1.6548e+09, train_seconds = 8339.4)
[2022-06-09 22:27:04,634][root][INFO] - Step 31339520 @ 3581.4 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 31339520, mean_episode_return = 80.53, mean_episode_step = 1380.6, total_loss = 409.94, pg_loss = 282.36, baseline_loss = 132.54, entropy_loss = -4.9678, learner_queue_size = 32, _tick = 6531, _time = 1.6548e+09, train_seconds = 8344.4)
[2022-06-09 22:27:09,638][root][INFO] - Step 31357440 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 31357440, mean_episode_return = 30.827, mean_episode_step = 1339.5, total_loss = -108.96, pg_loss = -131.15, baseline_loss = 27.101, entropy_loss = -4.9108, learner_queue_size = 32, _tick = 6537, _time = 1.6548e+09, train_seconds = 8349.4)
[2022-06-09 22:27:14,642][root][INFO] - Step 31377920 @ 4092.7 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 31377920, mean_episode_return = None, mean_episode_step = 1405.2, total_loss = 410.64, pg_loss = 318.93, baseline_loss = 96.693, entropy_loss = -4.9851, learner_queue_size = 32, _tick = 6542, _time = 1.6548e+09, train_seconds = 8354.4)
[2022-06-09 22:27:19,646][root][INFO] - Step 31393280 @ 3069.5 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 31393280, mean_episode_return = 22.04, mean_episode_step = 1570.8, total_loss = 205.13, pg_loss = 120.83, baseline_loss = 88.991, entropy_loss = -4.6938, learner_queue_size = 32, _tick = 6546, _time = 1.6548e+09, train_seconds = 8359.5)
[2022-06-09 22:27:24,650][root][INFO] - Step 31413760 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 31413760, mean_episode_return = 83.966, mean_episode_step = 1225.8, total_loss = -114.04, pg_loss = -150.86, baseline_loss = 41.639, entropy_loss = -4.8185, learner_queue_size = 32, _tick = 6552, _time = 1.6548e+09, train_seconds = 8364.5)
[2022-06-09 22:27:29,654][root][INFO] - Step 31431680 @ 3581.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 31431680, mean_episode_return = None, mean_episode_step = 1014.2, total_loss = 123.95, pg_loss = 90.545, baseline_loss = 38.362, entropy_loss = -4.957, learner_queue_size = 32, _tick = 6556, _time = 1.6548e+09, train_seconds = 8369.5)
[2022-06-09 22:27:34,658][root][INFO] - Step 31452160 @ 4092.8 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 31452160, mean_episode_return = 65.373, mean_episode_step = 1216.6, total_loss = 12.555, pg_loss = -60.858, baseline_loss = 78.283, entropy_loss = -4.8698, learner_queue_size = 32, _tick = 6559, _time = 1.6548e+09, train_seconds = 8374.5)
[2022-06-09 22:27:39,663][root][INFO] - Step 31470080 @ 3580.7 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 31470080, mean_episode_return = 78.832, mean_episode_step = 1284.6, total_loss = 119.37, pg_loss = 51.376, baseline_loss = 72.595, entropy_loss = -4.6021, learner_queue_size = 32, _tick = 6564, _time = 1.6548e+09, train_seconds = 8379.5)
[2022-06-09 22:27:44,666][root][INFO] - Step 31488000 @ 3581.6 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 31488000, mean_episode_return = 135.88, mean_episode_step = 1790.6, total_loss = 108.45, pg_loss = 23.019, baseline_loss = 90.174, entropy_loss = -4.7458, learner_queue_size = 32, _tick = 6568, _time = 1.6548e+09, train_seconds = 8384.5)
[2022-06-09 22:27:49,670][root][INFO] - Step 31508480 @ 4092.4 SPS. Inference batcher size: 95. Learner queue size: 32. Other stats: (step = 31508480, mean_episode_return = 97.514, mean_episode_step = 1434.3, total_loss = -122.4, pg_loss = -134.68, baseline_loss = 17.37, entropy_loss = -5.083, learner_queue_size = 32, _tick = 6575, _time = 1.6548e+09, train_seconds = 8389.5)
[2022-06-09 22:27:54,674][root][INFO] - Step 31526400 @ 3581.4 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 31526400, mean_episode_return = None, mean_episode_step = 1292.9, total_loss = 361.17, pg_loss = 304.8, baseline_loss = 61.374, entropy_loss = -5.0037, learner_queue_size = 32, _tick = 6579, _time = 1.6548e+09, train_seconds = 8394.5)
[2022-06-09 22:27:59,678][root][INFO] - Step 31544320 @ 3581.1 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 31544320, mean_episode_return = 53.539, mean_episode_step = 1195.4, total_loss = -55.253, pg_loss = -81.907, baseline_loss = 31.657, entropy_loss = -5.0033, learner_queue_size = 32, _tick = 6584, _time = 1.6548e+09, train_seconds = 8399.5)
[2022-06-09 22:28:04,682][root][INFO] - Step 31564800 @ 4092.7 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 31564800, mean_episode_return = 97.9, mean_episode_step = 1331.8, total_loss = 146.43, pg_loss = 75.01, baseline_loss = 76.359, entropy_loss = -4.9423, learner_queue_size = 32, _tick = 6590, _time = 1.6548e+09, train_seconds = 8404.5)
[2022-06-09 22:28:09,686][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-09 22:28:09,815][root][INFO] - Step 31582720 @ 3580.8 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 31582720, mean_episode_return = 115.12, mean_episode_step = 1508.8, total_loss = -77.668, pg_loss = -122.64, baseline_loss = 50.013, entropy_loss = -5.0367, learner_queue_size = 32, _tick = 6594, _time = 1.6548e+09, train_seconds = 8409.5)
[2022-06-09 22:28:14,818][root][INFO] - Step 31600640 @ 3492.0 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 31600640, mean_episode_return = None, mean_episode_step = 1166.4, total_loss = 290.55, pg_loss = 201.03, baseline_loss = 94.38, entropy_loss = -4.8664, learner_queue_size = 32, _tick = 6597, _time = 1.6548e+09, train_seconds = 8414.6)
[2022-06-09 22:28:19,822][root][INFO] - Step 31618560 @ 3581.3 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 31618560, mean_episode_return = 54.35, mean_episode_step = 1707.5, total_loss = 175.11, pg_loss = 90.913, baseline_loss = 89.07, entropy_loss = -4.8772, learner_queue_size = 32, _tick = 6602, _time = 1.6548e+09, train_seconds = 8419.6)
[2022-06-09 22:28:24,826][root][INFO] - Step 31636480 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 31636480, mean_episode_return = 89.479, mean_episode_step = 1591.0, total_loss = 106.39, pg_loss = 36.772, baseline_loss = 74.607, entropy_loss = -4.9845, learner_queue_size = 32, _tick = 6608, _time = 1.6548e+09, train_seconds = 8424.6)
[2022-06-09 22:28:29,830][root][INFO] - Step 31656960 @ 4092.6 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 31656960, mean_episode_return = 17.72, mean_episode_step = 1139.9, total_loss = 206.5, pg_loss = 126.59, baseline_loss = 84.945, entropy_loss = -5.0363, learner_queue_size = 32, _tick = 6614, _time = 1.6548e+09, train_seconds = 8429.6)
[2022-06-09 22:28:34,834][root][INFO] - Step 31674880 @ 3581.3 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 31674880, mean_episode_return = None, mean_episode_step = 1439.2, total_loss = 22.511, pg_loss = -12.096, baseline_loss = 39.559, entropy_loss = -4.9522, learner_queue_size = 32, _tick = 6618, _time = 1.6548e+09, train_seconds = 8434.6)
[2022-06-09 22:28:39,838][root][INFO] - Step 31692800 @ 3581.1 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 31692800, mean_episode_return = 26.44, mean_episode_step = 1073.6, total_loss = -6.0975, pg_loss = -46.563, baseline_loss = 45.485, entropy_loss = -5.0189, learner_queue_size = 32, _tick = 6624, _time = 1.6548e+09, train_seconds = 8439.6)
[2022-06-09 22:28:44,842][root][INFO] - Step 31710720 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 31710720, mean_episode_return = 138.27, mean_episode_step = 1125.0, total_loss = 178.94, pg_loss = 102.58, baseline_loss = 81.463, entropy_loss = -5.0965, learner_queue_size = 32, _tick = 6629, _time = 1.6548e+09, train_seconds = 8444.6)
[2022-06-09 22:28:49,846][root][INFO] - Step 31731200 @ 4092.7 SPS. Inference batcher size: 91. Learner queue size: 32. Other stats: (step = 31731200, mean_episode_return = 70.719, mean_episode_step = 1002.0, total_loss = 184.71, pg_loss = 77.576, baseline_loss = 111.94, entropy_loss = -4.8072, learner_queue_size = 32, _tick = 6634, _time = 1.6548e+09, train_seconds = 8449.7)
[2022-06-09 22:28:54,850][root][INFO] - Step 31749120 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 31749120, mean_episode_return = 52.86, mean_episode_step = 1280.4, total_loss = 26.403, pg_loss = -45.019, baseline_loss = 76.402, entropy_loss = -4.979, learner_queue_size = 32, _tick = 6640, _time = 1.6548e+09, train_seconds = 8454.7)
[2022-06-09 22:28:59,854][root][INFO] - Step 31769600 @ 4092.8 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 31769600, mean_episode_return = 19.065, mean_episode_step = 1462.0, total_loss = 78.575, pg_loss = 41.292, baseline_loss = 42.309, entropy_loss = -5.0255, learner_queue_size = 32, _tick = 6647, _time = 1.6548e+09, train_seconds = 8459.7)
[2022-06-09 22:29:04,858][root][INFO] - Step 31787520 @ 3581.2 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (step = 31787520, mean_episode_return = 72.29, mean_episode_step = 1197.1, total_loss = -23.113, pg_loss = -60.436, baseline_loss = 42.338, entropy_loss = -5.0146, learner_queue_size = 32, _tick = 6654, _time = 1.6548e+09, train_seconds = 8464.7)
[2022-06-09 22:29:09,862][root][INFO] - Step 31805440 @ 3581.1 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 31805440, mean_episode_return = 44.703, mean_episode_step = 1552.1, total_loss = -58.435, pg_loss = -66.067, baseline_loss = 12.622, entropy_loss = -4.9901, learner_queue_size = 32, _tick = 6660, _time = 1.6548e+09, train_seconds = 8469.7)
[2022-06-09 22:29:14,866][root][INFO] - Step 31825920 @ 4092.4 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (step = 31825920, mean_episode_return = 19.24, mean_episode_step = 1065.7, total_loss = 190.68, pg_loss = 69.04, baseline_loss = 126.61, entropy_loss = -4.9681, learner_queue_size = 32, _tick = 6667, _time = 1.6548e+09, train_seconds = 8474.7)
[2022-06-09 22:29:19,870][root][INFO] - Step 31843840 @ 3581.5 SPS. Inference batcher size: 80. Learner queue size: 32. Other stats: (step = 31843840, mean_episode_return = None, mean_episode_step = 1473.4, total_loss = 133.96, pg_loss = 44.704, baseline_loss = 94.224, entropy_loss = -4.9669, learner_queue_size = 32, _tick = 6671, _time = 1.6548e+09, train_seconds = 8479.7)
[2022-06-09 22:29:24,874][root][INFO] - Step 31864320 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 31864320, mean_episode_return = None, mean_episode_step = 1123.3, total_loss = 239.02, pg_loss = 197.11, baseline_loss = 46.93, entropy_loss = -5.023, learner_queue_size = 32, _tick = 6678, _time = 1.6548e+09, train_seconds = 8484.7)
[2022-06-09 22:29:29,878][root][INFO] - Step 31882240 @ 3581.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 31882240, mean_episode_return = None, mean_episode_step = 1128.5, total_loss = -91.72, pg_loss = -102.14, baseline_loss = 15.361, entropy_loss = -4.9384, learner_queue_size = 32, _tick = 6682, _time = 1.6548e+09, train_seconds = 8489.7)
[2022-06-09 22:29:34,882][root][INFO] - Step 31900160 @ 3581.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 31900160, mean_episode_return = None, mean_episode_step = 1143.5, total_loss = 186.1, pg_loss = 133.14, baseline_loss = 58.085, entropy_loss = -5.1244, learner_queue_size = 32, _tick = 6687, _time = 1.6548e+09, train_seconds = 8494.7)
[2022-06-09 22:29:39,888][root][INFO] - Step 31920640 @ 4090.9 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 31920640, mean_episode_return = 39.8, mean_episode_step = 1429.0, total_loss = 104.06, pg_loss = 39.492, baseline_loss = 69.628, entropy_loss = -5.0571, learner_queue_size = 32, _tick = 6693, _time = 1.6548e+09, train_seconds = 8499.7)
[2022-06-09 22:29:44,894][root][INFO] - Step 31938560 @ 3579.8 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 31938560, mean_episode_return = None, mean_episode_step = 1135.0, total_loss = 158.49, pg_loss = 115.24, baseline_loss = 48.155, entropy_loss = -4.9067, learner_queue_size = 32, _tick = 6698, _time = 1.6548e+09, train_seconds = 8504.7)
[2022-06-09 22:29:49,898][root][INFO] - Step 31959040 @ 4092.8 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 31959040, mean_episode_return = 42.22, mean_episode_step = 1110.4, total_loss = -67.46, pg_loss = -86.191, baseline_loss = 23.481, entropy_loss = -4.75, learner_queue_size = 32, _tick = 6703, _time = 1.6548e+09, train_seconds = 8509.7)
[2022-06-09 22:29:54,902][root][INFO] - Step 31976960 @ 3581.1 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 31976960, mean_episode_return = None, mean_episode_step = 996.47, total_loss = 200.72, pg_loss = 128.38, baseline_loss = 77.306, entropy_loss = -4.963, learner_queue_size = 32, _tick = 6708, _time = 1.6548e+09, train_seconds = 8514.7)
[2022-06-09 22:29:59,906][root][INFO] - Step 31994880 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 31994880, mean_episode_return = 73.625, mean_episode_step = 940.99, total_loss = 211.0, pg_loss = 102.92, baseline_loss = 112.67, entropy_loss = -4.5894, learner_queue_size = 32, _tick = 6713, _time = 1.6548e+09, train_seconds = 8519.7)
[2022-06-09 22:30:04,910][root][INFO] - Step 32015360 @ 4092.7 SPS. Inference batcher size: 114. Learner queue size: 32. Other stats: (step = 32015360, mean_episode_return = 29.46, mean_episode_step = 1634.1, total_loss = 210.77, pg_loss = 115.35, baseline_loss = 100.32, entropy_loss = -4.9052, learner_queue_size = 32, _tick = 6720, _time = 1.6548e+09, train_seconds = 8524.7)
[2022-06-09 22:30:09,914][root][INFO] - Step 32033280 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 32033280, mean_episode_return = 67.557, mean_episode_step = 1126.6, total_loss = 79.433, pg_loss = 38.589, baseline_loss = 45.736, entropy_loss = -4.8918, learner_queue_size = 32, _tick = 6726, _time = 1.6548e+09, train_seconds = 8529.7)
[2022-06-09 22:30:14,918][root][INFO] - Step 32053760 @ 4092.8 SPS. Inference batcher size: 79. Learner queue size: 32. Other stats: (step = 32053760, mean_episode_return = 43.39, mean_episode_step = 1098.0, total_loss = 117.24, pg_loss = 60.646, baseline_loss = 60.847, entropy_loss = -4.256, learner_queue_size = 32, _tick = 6733, _time = 1.6548e+09, train_seconds = 8534.7)
[2022-06-09 22:30:19,922][root][INFO] - Step 32071680 @ 3581.1 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 32071680, mean_episode_return = 2.8699, mean_episode_step = 1047.1, total_loss = -72.321, pg_loss = -94.084, baseline_loss = 26.531, entropy_loss = -4.7681, learner_queue_size = 32, _tick = 6738, _time = 1.6548e+09, train_seconds = 8539.7)
[2022-06-09 22:30:24,926][root][INFO] - Step 32089600 @ 3581.1 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 32089600, mean_episode_return = 30.76, mean_episode_step = 839.39, total_loss = -72.155, pg_loss = -112.89, baseline_loss = 45.561, entropy_loss = -4.8305, learner_queue_size = 32, _tick = 6742, _time = 1.6548e+09, train_seconds = 8544.7)
[2022-06-09 22:30:29,930][root][INFO] - Step 32110080 @ 4092.7 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 32110080, mean_episode_return = 76.952, mean_episode_step = 927.29, total_loss = -90.958, pg_loss = -102.41, baseline_loss = 16.011, entropy_loss = -4.5546, learner_queue_size = 32, _tick = 6748, _time = 1.6548e+09, train_seconds = 8549.7)
[2022-06-09 22:30:34,934][root][INFO] - Step 32128000 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 32128000, mean_episode_return = None, mean_episode_step = 1351.2, total_loss = 417.18, pg_loss = 236.66, baseline_loss = 185.13, entropy_loss = -4.6143, learner_queue_size = 32, _tick = 6753, _time = 1.6548e+09, train_seconds = 8554.7)
[2022-06-09 22:30:39,938][root][INFO] - Step 32145920 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 32145920, mean_episode_return = 34.031, mean_episode_step = 1453.9, total_loss = 203.69, pg_loss = 117.69, baseline_loss = 90.649, entropy_loss = -4.6538, learner_queue_size = 32, _tick = 6755, _time = 1.6548e+09, train_seconds = 8559.7)
[2022-06-09 22:30:44,942][root][INFO] - Step 32166400 @ 4092.7 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 32166400, mean_episode_return = 10.51, mean_episode_step = 1064.5, total_loss = 103.21, pg_loss = 42.154, baseline_loss = 65.808, entropy_loss = -4.7563, learner_queue_size = 32, _tick = 6760, _time = 1.6548e+09, train_seconds = 8564.7)
[2022-06-09 22:30:49,946][root][INFO] - Step 32184320 @ 3581.2 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 32184320, mean_episode_return = 27.02, mean_episode_step = 1170.8, total_loss = -244.63, pg_loss = -270.88, baseline_loss = 30.813, entropy_loss = -4.5641, learner_queue_size = 32, _tick = 6763, _time = 1.6548e+09, train_seconds = 8569.8)
[2022-06-09 22:30:54,950][root][INFO] - Step 32204800 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 32204800, mean_episode_return = -13.81, mean_episode_step = 1208.0, total_loss = 346.39, pg_loss = 240.42, baseline_loss = 110.65, entropy_loss = -4.6808, learner_queue_size = 32, _tick = 6769, _time = 1.6548e+09, train_seconds = 8574.8)
[2022-06-09 22:30:59,954][root][INFO] - Step 32222720 @ 3581.2 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 32222720, mean_episode_return = 59.081, mean_episode_step = 1281.4, total_loss = 356.43, pg_loss = 217.7, baseline_loss = 143.54, entropy_loss = -4.8106, learner_queue_size = 32, _tick = 6775, _time = 1.6548e+09, train_seconds = 8579.8)
[2022-06-09 22:31:04,959][root][INFO] - Step 32243200 @ 4092.2 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 32243200, mean_episode_return = 38.86, mean_episode_step = 1579.4, total_loss = -45.779, pg_loss = -77.131, baseline_loss = 36.051, entropy_loss = -4.6994, learner_queue_size = 32, _tick = 6782, _time = 1.6548e+09, train_seconds = 8584.8)
[2022-06-09 22:31:09,962][root][INFO] - Step 32261120 @ 3581.6 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 32261120, mean_episode_return = 38.176, mean_episode_step = 1304.2, total_loss = -17.257, pg_loss = -67.181, baseline_loss = 54.821, entropy_loss = -4.8971, learner_queue_size = 32, _tick = 6785, _time = 1.6548e+09, train_seconds = 8589.8)
[2022-06-09 22:31:14,966][root][INFO] - Step 32279040 @ 3581.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 32279040, mean_episode_return = None, mean_episode_step = 1491.0, total_loss = 92.775, pg_loss = 55.07, baseline_loss = 42.613, entropy_loss = -4.9089, learner_queue_size = 32, _tick = 6788, _time = 1.6548e+09, train_seconds = 8594.8)
[2022-06-09 22:31:19,970][root][INFO] - Step 32299520 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 32299520, mean_episode_return = None, mean_episode_step = 1363.5, total_loss = 282.31, pg_loss = 185.31, baseline_loss = 102.02, entropy_loss = -5.0219, learner_queue_size = 32, _tick = 6793, _time = 1.6548e+09, train_seconds = 8599.8)
[2022-06-09 22:31:24,974][root][INFO] - Step 32317440 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 32317440, mean_episode_return = 21.04, mean_episode_step = 1559.7, total_loss = -43.659, pg_loss = -66.67, baseline_loss = 27.609, entropy_loss = -4.5982, learner_queue_size = 32, _tick = 6797, _time = 1.6548e+09, train_seconds = 8604.8)
[2022-06-09 22:31:29,978][root][INFO] - Step 32337920 @ 4092.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (step = 32337920, mean_episode_return = 87.488, mean_episode_step = 1380.8, total_loss = -190.73, pg_loss = -227.23, baseline_loss = 40.972, entropy_loss = -4.4675, learner_queue_size = 32, _tick = 6804, _time = 1.6548e+09, train_seconds = 8609.8)
[2022-06-09 22:31:34,982][root][INFO] - Step 32355840 @ 3581.3 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 32355840, mean_episode_return = 27.761, mean_episode_step = 1337.1, total_loss = 123.06, pg_loss = 20.764, baseline_loss = 107.22, entropy_loss = -4.928, learner_queue_size = 32, _tick = 6809, _time = 1.6548e+09, train_seconds = 8614.8)
[2022-06-09 22:31:39,988][root][INFO] - Step 32373760 @ 3579.8 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 32373760, mean_episode_return = 50.311, mean_episode_step = 1044.3, total_loss = -52.477, pg_loss = -81.673, baseline_loss = 34.119, entropy_loss = -4.923, learner_queue_size = 32, _tick = 6814, _time = 1.6548e+09, train_seconds = 8619.8)
[2022-06-09 22:31:44,990][root][INFO] - Step 32394240 @ 4094.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 32394240, mean_episode_return = 134.82, mean_episode_step = 1173.3, total_loss = 0.40335, pg_loss = -12.607, baseline_loss = 18.273, entropy_loss = -5.2632, learner_queue_size = 32, _tick = 6821, _time = 1.6548e+09, train_seconds = 8624.8)
[2022-06-09 22:31:49,994][root][INFO] - Step 32412160 @ 3581.1 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 32412160, mean_episode_return = None, mean_episode_step = 1600.5, total_loss = 0.82994, pg_loss = -21.396, baseline_loss = 27.055, entropy_loss = -4.829, learner_queue_size = 32, _tick = 6826, _time = 1.6548e+09, train_seconds = 8629.8)
[2022-06-09 22:31:54,998][root][INFO] - Step 32430080 @ 3581.2 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 32430080, mean_episode_return = 227.5, mean_episode_step = 1207.7, total_loss = 129.07, pg_loss = 68.68, baseline_loss = 65.19, entropy_loss = -4.8017, learner_queue_size = 32, _tick = 6831, _time = 1.6548e+09, train_seconds = 8634.8)
[2022-06-09 22:32:00,002][root][INFO] - Step 32450560 @ 4092.8 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 32450560, mean_episode_return = 13.86, mean_episode_step = 1011.2, total_loss = 193.53, pg_loss = 101.28, baseline_loss = 97.177, entropy_loss = -4.9292, learner_queue_size = 32, _tick = 6838, _time = 1.6548e+09, train_seconds = 8639.8)
[2022-06-09 22:32:05,006][root][INFO] - Step 32468480 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 32468480, mean_episode_return = None, mean_episode_step = 1533.3, total_loss = 77.579, pg_loss = 50.19, baseline_loss = 32.272, entropy_loss = -4.8831, learner_queue_size = 32, _tick = 6841, _time = 1.6548e+09, train_seconds = 8644.8)
[2022-06-09 22:32:10,010][root][INFO] - Step 32488960 @ 4092.8 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 32488960, mean_episode_return = None, mean_episode_step = 1228.1, total_loss = 178.04, pg_loss = 126.06, baseline_loss = 56.91, entropy_loss = -4.927, learner_queue_size = 32, _tick = 6846, _time = 1.6548e+09, train_seconds = 8649.8)
[2022-06-09 22:32:15,014][root][INFO] - Step 32506880 @ 3581.1 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 32506880, mean_episode_return = 17.934, mean_episode_step = 1413.7, total_loss = 94.339, pg_loss = 28.875, baseline_loss = 70.318, entropy_loss = -4.8539, learner_queue_size = 32, _tick = 6853, _time = 1.6548e+09, train_seconds = 8654.8)
[2022-06-09 22:32:20,018][root][INFO] - Step 32527360 @ 4092.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 32527360, mean_episode_return = 82.259, mean_episode_step = 1497.5, total_loss = 60.138, pg_loss = 21.419, baseline_loss = 43.678, entropy_loss = -4.9587, learner_queue_size = 32, _tick = 6859, _time = 1.6548e+09, train_seconds = 8659.8)
[2022-06-09 22:32:25,022][root][INFO] - Step 32545280 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 32545280, mean_episode_return = 50.227, mean_episode_step = 1351.0, total_loss = -98.437, pg_loss = -132.93, baseline_loss = 39.463, entropy_loss = -4.9713, learner_queue_size = 32, _tick = 6865, _time = 1.6548e+09, train_seconds = 8664.8)
[2022-06-09 22:32:30,026][root][INFO] - Step 32565760 @ 4092.8 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 32565760, mean_episode_return = 94.886, mean_episode_step = 1181.0, total_loss = 105.96, pg_loss = 15.658, baseline_loss = 95.067, entropy_loss = -4.7663, learner_queue_size = 32, _tick = 6871, _time = 1.6548e+09, train_seconds = 8669.8)
[2022-06-09 22:32:35,030][root][INFO] - Step 32583680 @ 3581.0 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 32583680, mean_episode_return = 42.71, mean_episode_step = 1397.5, total_loss = -45.73, pg_loss = -81.552, baseline_loss = 40.636, entropy_loss = -4.8143, learner_queue_size = 32, _tick = 6877, _time = 1.6548e+09, train_seconds = 8674.8)
[2022-06-09 22:32:40,034][root][INFO] - Step 32601600 @ 3581.2 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 32601600, mean_episode_return = 8.8213, mean_episode_step = 1397.3, total_loss = 388.22, pg_loss = 272.8, baseline_loss = 120.19, entropy_loss = -4.7758, learner_queue_size = 32, _tick = 6882, _time = 1.6548e+09, train_seconds = 8679.8)
[2022-06-09 22:32:45,038][root][INFO] - Step 32622080 @ 4092.7 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 32622080, mean_episode_return = -6.1305, mean_episode_step = 1060.7, total_loss = 236.52, pg_loss = 125.41, baseline_loss = 116.16, entropy_loss = -5.0447, learner_queue_size = 32, _tick = 6890, _time = 1.6548e+09, train_seconds = 8684.8)
[2022-06-09 22:32:50,042][root][INFO] - Step 32640000 @ 3581.1 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 32640000, mean_episode_return = 64.325, mean_episode_step = 1308.9, total_loss = 129.11, pg_loss = 32.54, baseline_loss = 101.33, entropy_loss = -4.7595, learner_queue_size = 32, _tick = 6896, _time = 1.6548e+09, train_seconds = 8689.8)
[2022-06-09 22:32:55,046][root][INFO] - Step 32657920 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 32657920, mean_episode_return = None, mean_episode_step = 1331.5, total_loss = 30.754, pg_loss = -5.6304, baseline_loss = 41.401, entropy_loss = -5.0168, learner_queue_size = 32, _tick = 6901, _time = 1.6548e+09, train_seconds = 8694.9)
[2022-06-09 22:33:00,051][root][INFO] - Step 32678400 @ 4091.6 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 32678400, mean_episode_return = 34.635, mean_episode_step = 1223.1, total_loss = -27.983, pg_loss = -64.707, baseline_loss = 41.739, entropy_loss = -5.0153, learner_queue_size = 32, _tick = 6907, _time = 1.6548e+09, train_seconds = 8699.9)
[2022-06-09 22:33:05,054][root][INFO] - Step 32696320 @ 3582.2 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 32696320, mean_episode_return = None, mean_episode_step = 1498.0, total_loss = 73.841, pg_loss = 6.9261, baseline_loss = 71.827, entropy_loss = -4.9121, learner_queue_size = 32, _tick = 6911, _time = 1.6548e+09, train_seconds = 8704.9)
[2022-06-09 22:33:10,058][root][INFO] - Step 32716800 @ 4092.7 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 32716800, mean_episode_return = 94.443, mean_episode_step = 1173.6, total_loss = -130.48, pg_loss = -179.04, baseline_loss = 53.183, entropy_loss = -4.6221, learner_queue_size = 32, _tick = 6916, _time = 1.6548e+09, train_seconds = 8709.9)
[2022-06-09 22:33:15,062][root][INFO] - Step 32734720 @ 3581.2 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 32734720, mean_episode_return = 95.639, mean_episode_step = 1198.5, total_loss = -46.009, pg_loss = -71.775, baseline_loss = 30.716, entropy_loss = -4.9506, learner_queue_size = 32, _tick = 6921, _time = 1.6548e+09, train_seconds = 8714.9)
[2022-06-09 22:33:20,066][root][INFO] - Step 32755200 @ 4092.7 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 32755200, mean_episode_return = 85.708, mean_episode_step = 1256.2, total_loss = 11.505, pg_loss = -7.5211, baseline_loss = 24.053, entropy_loss = -5.0277, learner_queue_size = 32, _tick = 6926, _time = 1.6548e+09, train_seconds = 8719.9)
[2022-06-09 22:33:25,070][root][INFO] - Step 32773120 @ 3581.2 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 32773120, mean_episode_return = 77.228, mean_episode_step = 1432.4, total_loss = 124.1, pg_loss = 71.98, baseline_loss = 57.182, entropy_loss = -5.0634, learner_queue_size = 32, _tick = 6932, _time = 1.6548e+09, train_seconds = 8724.9)
[2022-06-09 22:33:30,074][root][INFO] - Step 32793600 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 32793600, mean_episode_return = 90.09, mean_episode_step = 1365.9, total_loss = 188.57, pg_loss = 123.94, baseline_loss = 69.719, entropy_loss = -5.0844, learner_queue_size = 32, _tick = 6937, _time = 1.6548e+09, train_seconds = 8729.9)
[2022-06-09 22:33:35,078][root][INFO] - Step 32811520 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 32811520, mean_episode_return = 74.381, mean_episode_step = 1197.0, total_loss = 352.44, pg_loss = 196.63, baseline_loss = 160.84, entropy_loss = -5.034, learner_queue_size = 32, _tick = 6943, _time = 1.6548e+09, train_seconds = 8734.9)
[2022-06-09 22:33:40,082][root][INFO] - Step 32832000 @ 4092.7 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 32832000, mean_episode_return = None, mean_episode_step = 1191.0, total_loss = 391.8, pg_loss = 296.62, baseline_loss = 100.01, entropy_loss = -4.8212, learner_queue_size = 32, _tick = 6948, _time = 1.6548e+09, train_seconds = 8739.9)
[2022-06-09 22:33:45,086][root][INFO] - Step 32849920 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 32849920, mean_episode_return = -32.481, mean_episode_step = 1122.4, total_loss = 151.06, pg_loss = 91.731, baseline_loss = 64.419, entropy_loss = -5.094, learner_queue_size = 32, _tick = 6953, _time = 1.6548e+09, train_seconds = 8744.9)
[2022-06-09 22:33:50,090][root][INFO] - Step 32867840 @ 3581.2 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 32867840, mean_episode_return = None, mean_episode_step = 1405.1, total_loss = -5.2152, pg_loss = -15.157, baseline_loss = 14.918, entropy_loss = -4.9764, learner_queue_size = 32, _tick = 6957, _time = 1.6548e+09, train_seconds = 8749.9)
[2022-06-09 22:33:55,094][root][INFO] - Step 32888320 @ 4092.7 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 32888320, mean_episode_return = 74.314, mean_episode_step = 1277.0, total_loss = 133.63, pg_loss = 35.362, baseline_loss = 103.25, entropy_loss = -4.9793, learner_queue_size = 32, _tick = 6963, _time = 1.6548e+09, train_seconds = 8754.9)
[2022-06-09 22:34:00,098][root][INFO] - Step 32906240 @ 3581.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 32906240, mean_episode_return = None, mean_episode_step = 1403.2, total_loss = 481.79, pg_loss = 319.83, baseline_loss = 167.06, entropy_loss = -5.1098, learner_queue_size = 32, _tick = 6968, _time = 1.6548e+09, train_seconds = 8759.9)
[2022-06-09 22:34:05,102][root][INFO] - Step 32924160 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 32924160, mean_episode_return = None, mean_episode_step = 1060.1, total_loss = 297.52, pg_loss = 218.75, baseline_loss = 83.686, entropy_loss = -4.9113, learner_queue_size = 32, _tick = 6972, _time = 1.6548e+09, train_seconds = 8764.9)
[2022-06-09 22:34:10,106][root][INFO] - Step 32944640 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 32944640, mean_episode_return = None, mean_episode_step = 1459.8, total_loss = -19.022, pg_loss = -53.375, baseline_loss = 39.29, entropy_loss = -4.9365, learner_queue_size = 32, _tick = 6978, _time = 1.6548e+09, train_seconds = 8769.9)
[2022-06-09 22:34:15,110][root][INFO] - Step 32962560 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 32962560, mean_episode_return = 87.92, mean_episode_step = 1290.7, total_loss = 51.921, pg_loss = 20.21, baseline_loss = 36.554, entropy_loss = -4.8439, learner_queue_size = 32, _tick = 6983, _time = 1.6548e+09, train_seconds = 8774.9)
[2022-06-09 22:34:20,114][root][INFO] - Step 32980480 @ 3581.2 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 32980480, mean_episode_return = 71.7, mean_episode_step = 1222.5, total_loss = 233.67, pg_loss = 125.12, baseline_loss = 113.32, entropy_loss = -4.7622, learner_queue_size = 32, _tick = 6988, _time = 1.6548e+09, train_seconds = 8779.9)
[2022-06-09 22:34:25,118][root][INFO] - Step 33000960 @ 4092.7 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 33000960, mean_episode_return = 124.33, mean_episode_step = 1105.9, total_loss = 51.18, pg_loss = 0.06154, baseline_loss = 56.035, entropy_loss = -4.9166, learner_queue_size = 32, _tick = 6994, _time = 1.6548e+09, train_seconds = 8784.9)
[2022-06-09 22:34:30,122][root][INFO] - Step 33018880 @ 3581.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 33018880, mean_episode_return = 43.194, mean_episode_step = 1354.9, total_loss = 55.254, pg_loss = 7.8822, baseline_loss = 52.396, entropy_loss = -5.0244, learner_queue_size = 32, _tick = 7000, _time = 1.6548e+09, train_seconds = 8789.9)
[2022-06-09 22:34:35,126][root][INFO] - Step 33036800 @ 3581.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 33036800, mean_episode_return = None, mean_episode_step = 1196.2, total_loss = 206.01, pg_loss = 128.73, baseline_loss = 82.376, entropy_loss = -5.0967, learner_queue_size = 32, _tick = 7003, _time = 1.6548e+09, train_seconds = 8794.9)
[2022-06-09 22:34:40,130][root][INFO] - Step 33054720 @ 3581.1 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 33054720, mean_episode_return = 52.201, mean_episode_step = 1009.4, total_loss = -41.595, pg_loss = -80.36, baseline_loss = 43.751, entropy_loss = -4.9864, learner_queue_size = 32, _tick = 7009, _time = 1.6548e+09, train_seconds = 8799.9)
[2022-06-09 22:34:45,134][root][INFO] - Step 33075200 @ 4092.8 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 33075200, mean_episode_return = 20.815, mean_episode_step = 1209.0, total_loss = -41.311, pg_loss = -47.258, baseline_loss = 11.123, entropy_loss = -5.1761, learner_queue_size = 32, _tick = 7015, _time = 1.6548e+09, train_seconds = 8804.9)
[2022-06-09 22:34:50,138][root][INFO] - Step 33093120 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 33093120, mean_episode_return = 84.376, mean_episode_step = 1168.8, total_loss = 383.49, pg_loss = 292.02, baseline_loss = 96.716, entropy_loss = -5.2447, learner_queue_size = 32, _tick = 7019, _time = 1.6548e+09, train_seconds = 8809.9)
[2022-06-09 22:34:55,142][root][INFO] - Step 33111040 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 33111040, mean_episode_return = 88.643, mean_episode_step = 1224.1, total_loss = 8.4276, pg_loss = -23.009, baseline_loss = 36.43, entropy_loss = -4.9933, learner_queue_size = 32, _tick = 7025, _time = 1.6548e+09, train_seconds = 8814.9)
[2022-06-09 22:35:00,147][root][INFO] - Step 33131520 @ 4091.9 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (step = 33131520, mean_episode_return = None, mean_episode_step = 1234.0, total_loss = 1012.0, pg_loss = 803.96, baseline_loss = 212.98, entropy_loss = -4.9052, learner_queue_size = 32, _tick = 7032, _time = 1.6548e+09, train_seconds = 8820.0)
[2022-06-09 22:35:05,150][root][INFO] - Step 33149440 @ 3581.9 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 33149440, mean_episode_return = 1.26, mean_episode_step = 1363.3, total_loss = 195.81, pg_loss = 107.62, baseline_loss = 93.145, entropy_loss = -4.952, learner_queue_size = 32, _tick = 7036, _time = 1.6548e+09, train_seconds = 8825.0)
[2022-06-09 22:35:10,154][root][INFO] - Step 33169920 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 33169920, mean_episode_return = 158.1, mean_episode_step = 1488.7, total_loss = -24.307, pg_loss = -37.572, baseline_loss = 18.312, entropy_loss = -5.0475, learner_queue_size = 32, _tick = 7043, _time = 1.6548e+09, train_seconds = 8830.0)
[2022-06-09 22:35:15,158][root][INFO] - Step 33187840 @ 3581.2 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 33187840, mean_episode_return = 107.22, mean_episode_step = 1288.3, total_loss = 24.312, pg_loss = 0.76724, baseline_loss = 28.478, entropy_loss = -4.9331, learner_queue_size = 32, _tick = 7047, _time = 1.6548e+09, train_seconds = 8835.0)
[2022-06-09 22:35:20,162][root][INFO] - Step 33205760 @ 3581.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 33205760, mean_episode_return = 23.655, mean_episode_step = 1219.8, total_loss = -56.129, pg_loss = -103.02, baseline_loss = 51.883, entropy_loss = -4.9913, learner_queue_size = 32, _tick = 7053, _time = 1.6548e+09, train_seconds = 8840.0)
[2022-06-09 22:35:25,166][root][INFO] - Step 33226240 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 33226240, mean_episode_return = None, mean_episode_step = 1437.3, total_loss = 64.619, pg_loss = 33.644, baseline_loss = 35.92, entropy_loss = -4.9444, learner_queue_size = 32, _tick = 7060, _time = 1.6548e+09, train_seconds = 8845.0)
[2022-06-09 22:35:30,170][root][INFO] - Step 33244160 @ 3581.2 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 33244160, mean_episode_return = 133.75, mean_episode_step = 1196.9, total_loss = 265.55, pg_loss = 182.71, baseline_loss = 87.743, entropy_loss = -4.8994, learner_queue_size = 32, _tick = 7066, _time = 1.6548e+09, train_seconds = 8850.0)
[2022-06-09 22:35:35,174][root][INFO] - Step 33262080 @ 3581.2 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 33262080, mean_episode_return = 41.645, mean_episode_step = 1190.4, total_loss = 314.4, pg_loss = 201.99, baseline_loss = 117.25, entropy_loss = -4.835, learner_queue_size = 32, _tick = 7072, _time = 1.6548e+09, train_seconds = 8855.0)
[2022-06-09 22:35:40,178][root][INFO] - Step 33282560 @ 4092.6 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 33282560, mean_episode_return = 82.598, mean_episode_step = 1213.5, total_loss = -174.06, pg_loss = -204.64, baseline_loss = 35.6, entropy_loss = -5.0237, learner_queue_size = 32, _tick = 7076, _time = 1.6548e+09, train_seconds = 8860.0)
[2022-06-09 22:35:45,182][root][INFO] - Step 33303040 @ 4092.8 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 33303040, mean_episode_return = 80.642, mean_episode_step = 1315.7, total_loss = 82.674, pg_loss = 26.87, baseline_loss = 60.891, entropy_loss = -5.0868, learner_queue_size = 32, _tick = 7083, _time = 1.6548e+09, train_seconds = 8865.0)
[2022-06-09 22:35:50,186][root][INFO] - Step 33320960 @ 3581.1 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 33320960, mean_episode_return = 0.039873, mean_episode_step = 1154.0, total_loss = -14.043, pg_loss = -38.028, baseline_loss = 29.09, entropy_loss = -5.1045, learner_queue_size = 32, _tick = 7089, _time = 1.6548e+09, train_seconds = 8870.0)
[2022-06-09 22:35:55,190][root][INFO] - Step 33338880 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 33338880, mean_episode_return = 18.85, mean_episode_step = 1527.4, total_loss = 296.34, pg_loss = 205.65, baseline_loss = 95.736, entropy_loss = -5.0461, learner_queue_size = 32, _tick = 7095, _time = 1.6548e+09, train_seconds = 8875.0)
[2022-06-09 22:36:00,194][root][INFO] - Step 33359360 @ 4092.7 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 33359360, mean_episode_return = 117.17, mean_episode_step = 1138.3, total_loss = 222.83, pg_loss = 153.75, baseline_loss = 73.965, entropy_loss = -4.8894, learner_queue_size = 32, _tick = 7100, _time = 1.6548e+09, train_seconds = 8880.0)
[2022-06-09 22:36:05,198][root][INFO] - Step 33377280 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 33377280, mean_episode_return = 33.194, mean_episode_step = 1172.1, total_loss = -133.65, pg_loss = -145.2, baseline_loss = 16.395, entropy_loss = -4.8491, learner_queue_size = 32, _tick = 7106, _time = 1.6548e+09, train_seconds = 8885.0)
[2022-06-09 22:36:10,203][root][INFO] - Step 33397760 @ 4092.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 33397760, mean_episode_return = 39.354, mean_episode_step = 1326.0, total_loss = -154.14, pg_loss = -200.75, baseline_loss = 51.421, entropy_loss = -4.81, learner_queue_size = 32, _tick = 7110, _time = 1.6548e+09, train_seconds = 8890.0)
[2022-06-09 22:36:15,206][root][INFO] - Step 33415680 @ 3581.6 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 33415680, mean_episode_return = 68.517, mean_episode_step = 1474.3, total_loss = -24.33, pg_loss = -71.563, baseline_loss = 52.357, entropy_loss = -5.1251, learner_queue_size = 32, _tick = 7115, _time = 1.6548e+09, train_seconds = 8895.0)
[2022-06-09 22:36:20,210][root][INFO] - Step 33433600 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 33433600, mean_episode_return = None, mean_episode_step = 1070.5, total_loss = -33.752, pg_loss = -60.178, baseline_loss = 31.529, entropy_loss = -5.1031, learner_queue_size = 32, _tick = 7119, _time = 1.6548e+09, train_seconds = 8900.0)
[2022-06-09 22:36:25,214][root][INFO] - Step 33454080 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 33454080, mean_episode_return = None, mean_episode_step = 1043.3, total_loss = -85.239, pg_loss = -99.968, baseline_loss = 19.766, entropy_loss = -5.0377, learner_queue_size = 32, _tick = 7122, _time = 1.6548e+09, train_seconds = 8905.0)
[2022-06-09 22:36:30,218][root][INFO] - Step 33472000 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 33472000, mean_episode_return = 21.73, mean_episode_step = 1370.2, total_loss = 94.057, pg_loss = 48.291, baseline_loss = 50.861, entropy_loss = -5.0946, learner_queue_size = 32, _tick = 7127, _time = 1.6548e+09, train_seconds = 8910.0)
[2022-06-09 22:36:35,222][root][INFO] - Step 33492480 @ 4092.8 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 33492480, mean_episode_return = 45.584, mean_episode_step = 1082.6, total_loss = 276.37, pg_loss = 206.1, baseline_loss = 75.199, entropy_loss = -4.9276, learner_queue_size = 32, _tick = 7135, _time = 1.6548e+09, train_seconds = 8915.0)
[2022-06-09 22:36:40,226][root][INFO] - Step 33510400 @ 3581.1 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 33510400, mean_episode_return = None, mean_episode_step = 1176.6, total_loss = 107.47, pg_loss = 69.201, baseline_loss = 42.96, entropy_loss = -4.69, learner_queue_size = 32, _tick = 7140, _time = 1.6548e+09, train_seconds = 8920.0)
[2022-06-09 22:36:45,230][root][INFO] - Step 33530880 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 33530880, mean_episode_return = None, mean_episode_step = 1046.5, total_loss = 159.52, pg_loss = 83.193, baseline_loss = 80.799, entropy_loss = -4.4744, learner_queue_size = 32, _tick = 7144, _time = 1.6548e+09, train_seconds = 8925.0)
[2022-06-09 22:36:50,234][root][INFO] - Step 33548800 @ 3581.0 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 33548800, mean_episode_return = 49.751, mean_episode_step = 1278.8, total_loss = 43.62, pg_loss = -24.012, baseline_loss = 72.424, entropy_loss = -4.7916, learner_queue_size = 32, _tick = 7149, _time = 1.6548e+09, train_seconds = 8930.0)
[2022-06-09 22:36:55,239][root][INFO] - Step 33569280 @ 4092.2 SPS. Inference batcher size: 80. Learner queue size: 32. Other stats: (step = 33569280, mean_episode_return = 22.11, mean_episode_step = 1302.9, total_loss = -87.404, pg_loss = -98.699, baseline_loss = 16.283, entropy_loss = -4.9882, learner_queue_size = 32, _tick = 7157, _time = 1.6548e+09, train_seconds = 8935.0)
[2022-06-09 22:37:00,242][root][INFO] - Step 33587200 @ 3581.8 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 33587200, mean_episode_return = 57.12, mean_episode_step = 1196.6, total_loss = 269.0, pg_loss = 202.34, baseline_loss = 71.614, entropy_loss = -4.9508, learner_queue_size = 32, _tick = 7163, _time = 1.6548e+09, train_seconds = 8940.0)
[2022-06-09 22:37:05,247][root][INFO] - Step 33605120 @ 3580.7 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 33605120, mean_episode_return = 54.047, mean_episode_step = 1043.0, total_loss = 250.23, pg_loss = 139.6, baseline_loss = 115.55, entropy_loss = -4.9264, learner_queue_size = 32, _tick = 7170, _time = 1.6548e+09, train_seconds = 8945.1)
[2022-06-09 22:37:10,250][root][INFO] - Step 33623040 @ 3581.6 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 33623040, mean_episode_return = 50.316, mean_episode_step = 1338.5, total_loss = 234.56, pg_loss = 148.92, baseline_loss = 90.566, entropy_loss = -4.9322, learner_queue_size = 32, _tick = 7175, _time = 1.6548e+09, train_seconds = 8950.1)
[2022-06-09 22:37:15,254][root][INFO] - Step 33643520 @ 4092.6 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 33643520, mean_episode_return = None, mean_episode_step = 1264.6, total_loss = 70.693, pg_loss = 30.162, baseline_loss = 45.386, entropy_loss = -4.8557, learner_queue_size = 32, _tick = 7180, _time = 1.6548e+09, train_seconds = 8955.1)
[2022-06-09 22:37:20,258][root][INFO] - Step 33661440 @ 3581.2 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 33661440, mean_episode_return = -4.1801, mean_episode_step = 956.31, total_loss = 23.251, pg_loss = -20.097, baseline_loss = 48.156, entropy_loss = -4.8074, learner_queue_size = 32, _tick = 7185, _time = 1.6548e+09, train_seconds = 8960.1)
[2022-06-09 22:37:25,262][root][INFO] - Step 33681920 @ 4092.8 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 33681920, mean_episode_return = 72.378, mean_episode_step = 1466.2, total_loss = 224.35, pg_loss = 162.05, baseline_loss = 67.252, entropy_loss = -4.9527, learner_queue_size = 32, _tick = 7190, _time = 1.6548e+09, train_seconds = 8965.1)
[2022-06-09 22:37:30,266][root][INFO] - Step 33699840 @ 3581.1 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 33699840, mean_episode_return = None, mean_episode_step = 1497.4, total_loss = 108.83, pg_loss = 65.787, baseline_loss = 47.996, entropy_loss = -4.9555, learner_queue_size = 32, _tick = 7193, _time = 1.6548e+09, train_seconds = 8970.1)
[2022-06-09 22:37:35,270][root][INFO] - Step 33717760 @ 3581.2 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 33717760, mean_episode_return = None, mean_episode_step = 1468.6, total_loss = 386.59, pg_loss = 273.32, baseline_loss = 118.19, entropy_loss = -4.9173, learner_queue_size = 32, _tick = 7199, _time = 1.6548e+09, train_seconds = 8975.1)
[2022-06-09 22:37:40,274][root][INFO] - Step 33738240 @ 4092.7 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 33738240, mean_episode_return = 27.22, mean_episode_step = 1420.9, total_loss = 360.55, pg_loss = 235.78, baseline_loss = 129.52, entropy_loss = -4.7555, learner_queue_size = 32, _tick = 7205, _time = 1.6548e+09, train_seconds = 8980.1)
[2022-06-09 22:37:45,278][root][INFO] - Step 33756160 @ 3581.2 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 33756160, mean_episode_return = 45.361, mean_episode_step = 1529.1, total_loss = -29.464, pg_loss = -88.195, baseline_loss = 63.403, entropy_loss = -4.6714, learner_queue_size = 32, _tick = 7211, _time = 1.6548e+09, train_seconds = 8985.1)
[2022-06-09 22:37:50,282][root][INFO] - Step 33774080 @ 3581.1 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 33774080, mean_episode_return = None, mean_episode_step = 1822.5, total_loss = -97.876, pg_loss = -120.32, baseline_loss = 27.405, entropy_loss = -4.9589, learner_queue_size = 32, _tick = 7215, _time = 1.6548e+09, train_seconds = 8990.1)
[2022-06-09 22:37:55,286][root][INFO] - Step 33792000 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 33792000, mean_episode_return = None, mean_episode_step = 1537.4, total_loss = 145.7, pg_loss = 96.703, baseline_loss = 54.039, entropy_loss = -5.0372, learner_queue_size = 32, _tick = 7219, _time = 1.6548e+09, train_seconds = 8995.1)
[2022-06-09 22:38:00,290][root][INFO] - Step 33812480 @ 4092.7 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 33812480, mean_episode_return = 40.442, mean_episode_step = 1619.2, total_loss = -30.134, pg_loss = -47.87, baseline_loss = 22.705, entropy_loss = -4.9693, learner_queue_size = 32, _tick = 7225, _time = 1.6548e+09, train_seconds = 9000.1)
[2022-06-09 22:38:05,294][root][INFO] - Step 33830400 @ 3581.2 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 33830400, mean_episode_return = None, mean_episode_step = 1302.6, total_loss = 64.756, pg_loss = 19.967, baseline_loss = 49.878, entropy_loss = -5.0892, learner_queue_size = 32, _tick = 7230, _time = 1.6548e+09, train_seconds = 9005.1)
[2022-06-09 22:38:10,299][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-09 22:38:10,575][root][INFO] - Step 33848320 @ 3580.7 SPS. Inference batcher size: 93. Learner queue size: 32. Other stats: (step = 33850880, mean_episode_return = None, mean_episode_step = 1220.0, total_loss = 102.81, pg_loss = 40.095, baseline_loss = 67.176, entropy_loss = -4.4627, learner_queue_size = 32, _tick = 7237, _time = 1.6548e+09, train_seconds = 9010.1)
[2022-06-09 22:38:15,582][root][INFO] - Step 33868800 @ 3876.3 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 33868800, mean_episode_return = 35.705, mean_episode_step = 1044.6, total_loss = -44.654, pg_loss = -86.365, baseline_loss = 46.3, entropy_loss = -4.589, learner_queue_size = 32, _tick = 7243, _time = 1.6548e+09, train_seconds = 9015.4)
[2022-06-09 22:38:20,586][root][INFO] - Step 33886720 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 33886720, mean_episode_return = None, mean_episode_step = 1362.2, total_loss = 92.014, pg_loss = 71.662, baseline_loss = 25.629, entropy_loss = -5.2764, learner_queue_size = 32, _tick = 7246, _time = 1.6548e+09, train_seconds = 9020.4)
[2022-06-09 22:38:25,590][root][INFO] - Step 33904640 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 33904640, mean_episode_return = 76.349, mean_episode_step = 1372.6, total_loss = 261.04, pg_loss = 161.07, baseline_loss = 105.18, entropy_loss = -5.2091, learner_queue_size = 32, _tick = 7252, _time = 1.6548e+09, train_seconds = 9025.4)
[2022-06-09 22:38:30,594][root][INFO] - Step 33925120 @ 4092.8 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 33925120, mean_episode_return = 133.83, mean_episode_step = 1012.1, total_loss = 135.08, pg_loss = 84.696, baseline_loss = 55.509, entropy_loss = -5.1293, learner_queue_size = 32, _tick = 7257, _time = 1.6548e+09, train_seconds = 9030.4)
[2022-06-09 22:38:35,598][root][INFO] - Step 33943040 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 33943040, mean_episode_return = None, mean_episode_step = 1148.9, total_loss = 5.433, pg_loss = -19.647, baseline_loss = 30.274, entropy_loss = -5.1942, learner_queue_size = 32, _tick = 7262, _time = 1.6548e+09, train_seconds = 9035.4)
[2022-06-09 22:38:40,602][root][INFO] - Step 33963520 @ 4092.8 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 33963520, mean_episode_return = -12.66, mean_episode_step = 1292.2, total_loss = 430.42, pg_loss = 294.05, baseline_loss = 141.69, entropy_loss = -5.3139, learner_queue_size = 32, _tick = 7270, _time = 1.6548e+09, train_seconds = 9040.4)
[2022-06-09 22:38:45,606][root][INFO] - Step 33981440 @ 3581.1 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 33981440, mean_episode_return = 24.47, mean_episode_step = 1133.7, total_loss = 76.213, pg_loss = 27.678, baseline_loss = 53.54, entropy_loss = -5.0051, learner_queue_size = 32, _tick = 7275, _time = 1.6548e+09, train_seconds = 9045.4)
[2022-06-09 22:38:50,611][root][INFO] - Step 33999360 @ 3580.7 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (step = 33999360, mean_episode_return = 33.765, mean_episode_step = 1135.6, total_loss = 145.48, pg_loss = 53.766, baseline_loss = 96.672, entropy_loss = -4.9566, learner_queue_size = 32, _tick = 7280, _time = 1.6548e+09, train_seconds = 9050.4)
[2022-06-09 22:38:55,614][root][INFO] - Step 34017280 @ 3581.6 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 34017280, mean_episode_return = -12.26, mean_episode_step = 1325.1, total_loss = -42.995, pg_loss = -98.546, baseline_loss = 60.549, entropy_loss = -4.998, learner_queue_size = 32, _tick = 7286, _time = 1.6548e+09, train_seconds = 9055.4)
[2022-06-09 22:39:00,618][root][INFO] - Step 34037760 @ 4092.5 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 34037760, mean_episode_return = 95.119, mean_episode_step = 1241.8, total_loss = 131.18, pg_loss = 101.52, baseline_loss = 34.906, entropy_loss = -5.2453, learner_queue_size = 32, _tick = 7290, _time = 1.6548e+09, train_seconds = 9060.4)
[2022-06-09 22:39:05,622][root][INFO] - Step 34055680 @ 3581.2 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 34055680, mean_episode_return = 13.66, mean_episode_step = 1407.3, total_loss = 128.8, pg_loss = 87.301, baseline_loss = 46.31, entropy_loss = -4.8068, learner_queue_size = 32, _tick = 7295, _time = 1.6548e+09, train_seconds = 9065.4)
[2022-06-09 22:39:10,626][root][INFO] - Step 34073600 @ 3581.2 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 34073600, mean_episode_return = 72.87, mean_episode_step = 1024.1, total_loss = 280.41, pg_loss = 178.21, baseline_loss = 107.12, entropy_loss = -4.9183, learner_queue_size = 32, _tick = 7302, _time = 1.6548e+09, train_seconds = 9070.4)
[2022-06-09 22:39:15,630][root][INFO] - Step 34091520 @ 3581.1 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 34091520, mean_episode_return = 11.91, mean_episode_step = 1047.8, total_loss = 135.93, pg_loss = 77.412, baseline_loss = 63.446, entropy_loss = -4.9318, learner_queue_size = 32, _tick = 7308, _time = 1.6548e+09, train_seconds = 9075.4)
[2022-06-09 22:39:20,634][root][INFO] - Step 34109440 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 34109440, mean_episode_return = None, mean_episode_step = 1372.8, total_loss = 277.23, pg_loss = 192.69, baseline_loss = 89.641, entropy_loss = -5.1015, learner_queue_size = 32, _tick = 7313, _time = 1.6548e+09, train_seconds = 9080.4)
[2022-06-09 22:39:25,638][root][INFO] - Step 34129920 @ 4092.7 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 34129920, mean_episode_return = None, mean_episode_step = 1313.8, total_loss = 185.55, pg_loss = 124.79, baseline_loss = 65.814, entropy_loss = -5.0545, learner_queue_size = 32, _tick = 7317, _time = 1.6548e+09, train_seconds = 9085.4)
[2022-06-09 22:39:30,642][root][INFO] - Step 34147840 @ 3581.3 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 34147840, mean_episode_return = 41.411, mean_episode_step = 1430.0, total_loss = 1.862, pg_loss = -35.487, baseline_loss = 42.258, entropy_loss = -4.9087, learner_queue_size = 32, _tick = 7322, _time = 1.6548e+09, train_seconds = 9090.4)
[2022-06-09 22:39:35,646][root][INFO] - Step 34165760 @ 3581.1 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 34165760, mean_episode_return = 28.905, mean_episode_step = 1113.6, total_loss = -163.14, pg_loss = -203.33, baseline_loss = 45.063, entropy_loss = -4.8741, learner_queue_size = 32, _tick = 7328, _time = 1.6548e+09, train_seconds = 9095.5)
[2022-06-09 22:39:40,652][root][INFO] - Step 34186240 @ 4091.1 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 34186240, mean_episode_return = 8.87, mean_episode_step = 979.91, total_loss = -96.813, pg_loss = -114.48, baseline_loss = 22.828, entropy_loss = -5.1579, learner_queue_size = 32, _tick = 7335, _time = 1.6548e+09, train_seconds = 9100.5)
[2022-06-09 22:39:45,658][root][INFO] - Step 34204160 @ 3579.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 34204160, mean_episode_return = 73.601, mean_episode_step = 1171.3, total_loss = -4.9698, pg_loss = -39.767, baseline_loss = 39.791, entropy_loss = -4.9932, learner_queue_size = 32, _tick = 7341, _time = 1.6548e+09, train_seconds = 9105.5)
[2022-06-09 22:39:50,663][root][INFO] - Step 34222080 @ 3580.5 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 34222080, mean_episode_return = 23.816, mean_episode_step = 1353.2, total_loss = -40.588, pg_loss = -83.956, baseline_loss = 48.298, entropy_loss = -4.9299, learner_queue_size = 32, _tick = 7347, _time = 1.6548e+09, train_seconds = 9110.5)
[2022-06-09 22:39:55,666][root][INFO] - Step 34242560 @ 4093.4 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 34242560, mean_episode_return = None, mean_episode_step = 958.81, total_loss = 98.993, pg_loss = 67.326, baseline_loss = 36.971, entropy_loss = -5.3046, learner_queue_size = 32, _tick = 7353, _time = 1.6548e+09, train_seconds = 9115.5)
[2022-06-09 22:40:00,670][root][INFO] - Step 34260480 @ 3581.2 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 34260480, mean_episode_return = None, mean_episode_step = 1466.9, total_loss = 80.617, pg_loss = 44.817, baseline_loss = 41.11, entropy_loss = -5.3103, learner_queue_size = 32, _tick = 7358, _time = 1.6548e+09, train_seconds = 9120.5)
[2022-06-09 22:40:05,674][root][INFO] - Step 34280960 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 34280960, mean_episode_return = 58.565, mean_episode_step = 1161.8, total_loss = 34.153, pg_loss = -12.277, baseline_loss = 51.445, entropy_loss = -5.0151, learner_queue_size = 32, _tick = 7365, _time = 1.6548e+09, train_seconds = 9125.5)
[2022-06-09 22:40:10,678][root][INFO] - Step 34298880 @ 3581.2 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (step = 34298880, mean_episode_return = None, mean_episode_step = 1220.1, total_loss = 350.42, pg_loss = 222.02, baseline_loss = 133.27, entropy_loss = -4.8652, learner_queue_size = 32, _tick = 7371, _time = 1.6548e+09, train_seconds = 9130.5)
[2022-06-09 22:40:15,682][root][INFO] - Step 34316800 @ 3581.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 34316800, mean_episode_return = 72.549, mean_episode_step = 1179.4, total_loss = 67.83, pg_loss = -28.4, baseline_loss = 101.38, entropy_loss = -5.1463, learner_queue_size = 32, _tick = 7377, _time = 1.6548e+09, train_seconds = 9135.5)
[2022-06-09 22:40:20,686][root][INFO] - Step 34337280 @ 4092.4 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 34337280, mean_episode_return = 44.151, mean_episode_step = 1345.6, total_loss = -152.38, pg_loss = -175.66, baseline_loss = 28.419, entropy_loss = -5.1331, learner_queue_size = 32, _tick = 7382, _time = 1.6548e+09, train_seconds = 9140.5)
[2022-06-09 22:40:25,692][root][INFO] - Step 34355200 @ 3580.1 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 34355200, mean_episode_return = 21.84, mean_episode_step = 1161.8, total_loss = -65.308, pg_loss = -141.34, baseline_loss = 81.073, entropy_loss = -5.041, learner_queue_size = 32, _tick = 7388, _time = 1.6548e+09, train_seconds = 9145.5)
[2022-06-09 22:40:30,694][root][INFO] - Step 34373120 @ 3582.4 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (step = 34373120, mean_episode_return = 84.464, mean_episode_step = 1146.6, total_loss = 105.3, pg_loss = 16.107, baseline_loss = 94.138, entropy_loss = -4.9433, learner_queue_size = 32, _tick = 7391, _time = 1.6548e+09, train_seconds = 9150.5)
[2022-06-09 22:40:35,698][root][INFO] - Step 34391040 @ 3581.1 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 34391040, mean_episode_return = 41.131, mean_episode_step = 1365.0, total_loss = 2.3549, pg_loss = -19.313, baseline_loss = 26.106, entropy_loss = -4.4385, learner_queue_size = 32, _tick = 7397, _time = 1.6548e+09, train_seconds = 9155.5)
[2022-06-09 22:40:40,702][root][INFO] - Step 34411520 @ 4092.8 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 34411520, mean_episode_return = None, mean_episode_step = 971.22, total_loss = 182.6, pg_loss = 101.33, baseline_loss = 86.175, entropy_loss = -4.8976, learner_queue_size = 32, _tick = 7401, _time = 1.6548e+09, train_seconds = 9160.5)
[2022-06-09 22:40:45,706][root][INFO] - Step 34429440 @ 3581.2 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 34429440, mean_episode_return = 73.469, mean_episode_step = 1420.8, total_loss = -98.29, pg_loss = -109.4, baseline_loss = 16.258, entropy_loss = -5.1508, learner_queue_size = 32, _tick = 7406, _time = 1.6548e+09, train_seconds = 9165.5)
[2022-06-09 22:40:50,710][root][INFO] - Step 34449920 @ 4092.7 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 34449920, mean_episode_return = 10.51, mean_episode_step = 1115.0, total_loss = -8.9057, pg_loss = -51.261, baseline_loss = 47.307, entropy_loss = -4.9523, learner_queue_size = 32, _tick = 7413, _time = 1.6548e+09, train_seconds = 9170.5)
[2022-06-09 22:40:55,718][root][INFO] - Step 34467840 @ 3578.3 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 34467840, mean_episode_return = 48.663, mean_episode_step = 1320.4, total_loss = -14.393, pg_loss = -54.809, baseline_loss = 45.419, entropy_loss = -5.0031, learner_queue_size = 32, _tick = 7418, _time = 1.6548e+09, train_seconds = 9175.5)
[2022-06-09 22:41:00,722][root][INFO] - Step 34485760 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 34485760, mean_episode_return = None, mean_episode_step = 1187.9, total_loss = 306.9, pg_loss = 201.68, baseline_loss = 110.2, entropy_loss = -4.979, learner_queue_size = 32, _tick = 7423, _time = 1.6548e+09, train_seconds = 9180.5)
[2022-06-09 22:41:05,726][root][INFO] - Step 34506240 @ 4092.8 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 34506240, mean_episode_return = None, mean_episode_step = 1200.0, total_loss = 452.27, pg_loss = 338.88, baseline_loss = 118.02, entropy_loss = -4.6298, learner_queue_size = 32, _tick = 7430, _time = 1.6548e+09, train_seconds = 9185.5)
[2022-06-09 22:41:10,730][root][INFO] - Step 34524160 @ 3581.1 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 34524160, mean_episode_return = None, mean_episode_step = 1079.4, total_loss = 31.474, pg_loss = -8.0122, baseline_loss = 44.415, entropy_loss = -4.9294, learner_queue_size = 32, _tick = 7435, _time = 1.6548e+09, train_seconds = 9190.5)
[2022-06-09 22:41:15,734][root][INFO] - Step 34542080 @ 3581.2 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 34542080, mean_episode_return = 42.67, mean_episode_step = 1015.5, total_loss = 183.7, pg_loss = 77.18, baseline_loss = 111.6, entropy_loss = -5.0787, learner_queue_size = 32, _tick = 7440, _time = 1.6548e+09, train_seconds = 9195.5)
[2022-06-09 22:41:20,738][root][INFO] - Step 34562560 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 34562560, mean_episode_return = None, mean_episode_step = 1414.7, total_loss = -36.174, pg_loss = -67.929, baseline_loss = 36.794, entropy_loss = -5.0396, learner_queue_size = 32, _tick = 7446, _time = 1.6548e+09, train_seconds = 9200.5)
[2022-06-09 22:41:25,744][root][INFO] - Step 34580480 @ 3579.6 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 34580480, mean_episode_return = 60.606, mean_episode_step = 1243.8, total_loss = 1.3463, pg_loss = -30.162, baseline_loss = 36.519, entropy_loss = -5.0103, learner_queue_size = 32, _tick = 7451, _time = 1.6548e+09, train_seconds = 9205.6)
[2022-06-09 22:41:30,750][root][INFO] - Step 34598400 @ 3580.0 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 34598400, mean_episode_return = 15.17, mean_episode_step = 1370.8, total_loss = -173.48, pg_loss = -203.99, baseline_loss = 35.609, entropy_loss = -5.1005, learner_queue_size = 32, _tick = 7456, _time = 1.6548e+09, train_seconds = 9210.6)
[2022-06-09 22:41:35,754][root][INFO] - Step 34616320 @ 3581.0 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 34616320, mean_episode_return = 43.038, mean_episode_step = 1296.5, total_loss = 70.328, pg_loss = 5.0869, baseline_loss = 70.386, entropy_loss = -5.145, learner_queue_size = 32, _tick = 7462, _time = 1.6548e+09, train_seconds = 9215.6)
[2022-06-09 22:41:40,758][root][INFO] - Step 34636800 @ 4092.6 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 34636800, mean_episode_return = 78.291, mean_episode_step = 1093.1, total_loss = 64.255, pg_loss = 7.172, baseline_loss = 62.193, entropy_loss = -5.1103, learner_queue_size = 32, _tick = 7467, _time = 1.6548e+09, train_seconds = 9220.6)
[2022-06-09 22:41:45,768][root][INFO] - Step 34654720 @ 3577.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 34654720, mean_episode_return = 98.771, mean_episode_step = 1404.9, total_loss = -45.897, pg_loss = -86.569, baseline_loss = 45.441, entropy_loss = -4.7691, learner_queue_size = 32, _tick = 7473, _time = 1.6548e+09, train_seconds = 9225.6)
[2022-06-09 22:41:50,770][root][INFO] - Step 34675200 @ 4093.9 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 34675200, mean_episode_return = 23.74, mean_episode_step = 887.42, total_loss = -69.036, pg_loss = -95.57, baseline_loss = 31.515, entropy_loss = -4.9808, learner_queue_size = 32, _tick = 7479, _time = 1.6548e+09, train_seconds = 9230.6)
[2022-06-09 22:41:55,778][root][INFO] - Step 34693120 @ 3578.6 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 34693120, mean_episode_return = 89.889, mean_episode_step = 1107.1, total_loss = 28.714, pg_loss = -25.544, baseline_loss = 59.258, entropy_loss = -5.0007, learner_queue_size = 32, _tick = 7485, _time = 1.6548e+09, train_seconds = 9235.6)
[2022-06-09 22:42:00,782][root][INFO] - Step 34713600 @ 4092.8 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 34713600, mean_episode_return = None, mean_episode_step = 993.47, total_loss = 138.52, pg_loss = 96.9, baseline_loss = 46.768, entropy_loss = -5.1471, learner_queue_size = 32, _tick = 7490, _time = 1.6548e+09, train_seconds = 9240.6)
[2022-06-09 22:42:05,786][root][INFO] - Step 34731520 @ 3581.2 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (step = 34731520, mean_episode_return = 23.208, mean_episode_step = 1137.6, total_loss = -44.646, pg_loss = -113.97, baseline_loss = 74.219, entropy_loss = -4.8927, learner_queue_size = 32, _tick = 7494, _time = 1.6548e+09, train_seconds = 9245.6)
[2022-06-09 22:42:10,790][root][INFO] - Step 34749440 @ 3581.1 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 34749440, mean_episode_return = 30.03, mean_episode_step = 1047.2, total_loss = -17.256, pg_loss = -44.622, baseline_loss = 32.479, entropy_loss = -5.1134, learner_queue_size = 32, _tick = 7500, _time = 1.6548e+09, train_seconds = 9250.6)
[2022-06-09 22:42:15,794][root][INFO] - Step 34769920 @ 4092.7 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (step = 34769920, mean_episode_return = 108.62, mean_episode_step = 1503.0, total_loss = 312.85, pg_loss = 230.81, baseline_loss = 87.259, entropy_loss = -5.2193, learner_queue_size = 32, _tick = 7506, _time = 1.6548e+09, train_seconds = 9255.6)
[2022-06-09 22:42:20,798][root][INFO] - Step 34787840 @ 3581.1 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 34787840, mean_episode_return = 59.329, mean_episode_step = 1526.1, total_loss = 10.977, pg_loss = -20.429, baseline_loss = 36.596, entropy_loss = -5.1907, learner_queue_size = 32, _tick = 7512, _time = 1.6548e+09, train_seconds = 9260.6)
[2022-06-09 22:42:25,802][root][INFO] - Step 34808320 @ 4092.8 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 34808320, mean_episode_return = None, mean_episode_step = 1238.8, total_loss = 260.68, pg_loss = 181.44, baseline_loss = 84.309, entropy_loss = -5.0628, learner_queue_size = 32, _tick = 7517, _time = 1.6548e+09, train_seconds = 9265.6)
[2022-06-09 22:42:30,806][root][INFO] - Step 34823680 @ 3069.5 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 34823680, mean_episode_return = None, mean_episode_step = 1039.0, total_loss = 21.853, pg_loss = -20.025, baseline_loss = 46.272, entropy_loss = -4.3937, learner_queue_size = 32, _tick = 7520, _time = 1.6548e+09, train_seconds = 9270.6)
[2022-06-09 22:42:35,810][root][INFO] - Step 34841600 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 34841600, mean_episode_return = None, mean_episode_step = 1600.2, total_loss = 487.6, pg_loss = 290.3, baseline_loss = 202.49, entropy_loss = -5.1879, learner_queue_size = 32, _tick = 7524, _time = 1.6548e+09, train_seconds = 9275.6)
[2022-06-09 22:42:40,812][root][INFO] - Step 34859520 @ 3582.9 SPS. Inference batcher size: 76. Learner queue size: 32. Other stats: (step = 34859520, mean_episode_return = None, mean_episode_step = 1385.1, total_loss = -97.235, pg_loss = -119.26, baseline_loss = 26.789, entropy_loss = -4.7632, learner_queue_size = 32, _tick = 7528, _time = 1.6548e+09, train_seconds = 9280.6)
[2022-06-09 22:42:45,814][root][INFO] - Step 34880000 @ 4093.9 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 34880000, mean_episode_return = 120.95, mean_episode_step = 1214.0, total_loss = 140.31, pg_loss = 59.134, baseline_loss = 86.244, entropy_loss = -5.0691, learner_queue_size = 32, _tick = 7534, _time = 1.6548e+09, train_seconds = 9285.6)
[2022-06-09 22:42:50,818][root][INFO] - Step 34897920 @ 3581.2 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 34897920, mean_episode_return = 72.285, mean_episode_step = 1295.7, total_loss = 93.164, pg_loss = 31.001, baseline_loss = 67.098, entropy_loss = -4.9342, learner_queue_size = 32, _tick = 7540, _time = 1.6548e+09, train_seconds = 9290.6)
[2022-06-09 22:42:55,822][root][INFO] - Step 34918400 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 34918400, mean_episode_return = 252.24, mean_episode_step = 1121.0, total_loss = 60.125, pg_loss = 17.818, baseline_loss = 47.429, entropy_loss = -5.1218, learner_queue_size = 32, _tick = 7547, _time = 1.6548e+09, train_seconds = 9295.6)
[2022-06-09 22:43:00,826][root][INFO] - Step 34936320 @ 3581.1 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 34936320, mean_episode_return = 54.63, mean_episode_step = 1743.4, total_loss = 566.87, pg_loss = 183.99, baseline_loss = 387.92, entropy_loss = -5.0341, learner_queue_size = 32, _tick = 7551, _time = 1.6548e+09, train_seconds = 9300.6)
[2022-06-09 22:43:05,828][root][INFO] - Step 34956800 @ 4094.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 34956800, mean_episode_return = None, mean_episode_step = 1162.4, total_loss = 72.436, pg_loss = 32.065, baseline_loss = 45.269, entropy_loss = -4.897, learner_queue_size = 32, _tick = 7555, _time = 1.6548e+09, train_seconds = 9305.6)
[2022-06-09 22:43:10,830][root][INFO] - Step 34974720 @ 3582.3 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (step = 34974720, mean_episode_return = 56.412, mean_episode_step = 1139.0, total_loss = -11.107, pg_loss = -25.033, baseline_loss = 19.197, entropy_loss = -5.2712, learner_queue_size = 32, _tick = 7560, _time = 1.6548e+09, train_seconds = 9310.6)
[2022-06-09 22:43:15,834][root][INFO] - Step 34992640 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 34992640, mean_episode_return = 63.63, mean_episode_step = 1163.2, total_loss = 129.97, pg_loss = 67.048, baseline_loss = 68.182, entropy_loss = -5.2573, learner_queue_size = 32, _tick = 7565, _time = 1.6548e+09, train_seconds = 9315.6)
[2022-06-09 22:43:20,838][root][INFO] - Step 35013120 @ 4092.8 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 35013120, mean_episode_return = 92.94, mean_episode_step = 1182.5, total_loss = -147.3, pg_loss = -203.52, baseline_loss = 61.307, entropy_loss = -5.0893, learner_queue_size = 32, _tick = 7571, _time = 1.6548e+09, train_seconds = 9320.6)
[2022-06-09 22:43:25,842][root][INFO] - Step 35031040 @ 3581.2 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 35031040, mean_episode_return = 18.9, mean_episode_step = 1325.2, total_loss = 7.9243, pg_loss = -63.507, baseline_loss = 76.597, entropy_loss = -5.1652, learner_queue_size = 32, _tick = 7575, _time = 1.6548e+09, train_seconds = 9325.6)
[2022-06-09 22:43:30,846][root][INFO] - Step 35048960 @ 3581.0 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 35048960, mean_episode_return = 53.635, mean_episode_step = 1440.2, total_loss = 120.9, pg_loss = 68.114, baseline_loss = 58.035, entropy_loss = -5.2477, learner_queue_size = 32, _tick = 7581, _time = 1.6548e+09, train_seconds = 9330.7)
[2022-06-09 22:43:35,850][root][INFO] - Step 35069440 @ 4092.9 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 35069440, mean_episode_return = 35.114, mean_episode_step = 1346.2, total_loss = 234.0, pg_loss = 160.95, baseline_loss = 78.284, entropy_loss = -5.2352, learner_queue_size = 32, _tick = 7586, _time = 1.6548e+09, train_seconds = 9335.7)
[2022-06-09 22:43:40,854][root][INFO] - Step 35087360 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 35087360, mean_episode_return = 5.8997, mean_episode_step = 1211.7, total_loss = 179.11, pg_loss = 120.93, baseline_loss = 63.082, entropy_loss = -4.8982, learner_queue_size = 32, _tick = 7593, _time = 1.6548e+09, train_seconds = 9340.7)
[2022-06-09 22:43:45,858][root][INFO] - Step 35107840 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 35107840, mean_episode_return = 33.847, mean_episode_step = 1663.5, total_loss = -90.005, pg_loss = -121.0, baseline_loss = 35.923, entropy_loss = -4.9302, learner_queue_size = 32, _tick = 7599, _time = 1.6548e+09, train_seconds = 9345.7)
[2022-06-09 22:43:50,862][root][INFO] - Step 35125760 @ 3581.1 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 35125760, mean_episode_return = 10.36, mean_episode_step = 1504.0, total_loss = 114.61, pg_loss = 94.567, baseline_loss = 25.381, entropy_loss = -5.3363, learner_queue_size = 32, _tick = 7603, _time = 1.6548e+09, train_seconds = 9350.7)
[2022-06-09 22:43:55,882][root][INFO] - Step 35146240 @ 4079.5 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 35146240, mean_episode_return = 73.89, mean_episode_step = 1223.2, total_loss = 244.01, pg_loss = 167.96, baseline_loss = 81.39, entropy_loss = -5.3416, learner_queue_size = 32, _tick = 7610, _time = 1.6548e+09, train_seconds = 9355.7)
[2022-06-09 22:44:00,886][root][INFO] - Step 35164160 @ 3581.2 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 35164160, mean_episode_return = 81.494, mean_episode_step = 1094.4, total_loss = -48.854, pg_loss = -72.798, baseline_loss = 29.117, entropy_loss = -5.1728, learner_queue_size = 32, _tick = 7615, _time = 1.6548e+09, train_seconds = 9360.7)
[2022-06-09 22:44:05,890][root][INFO] - Step 35182080 @ 3581.2 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 35182080, mean_episode_return = 54.935, mean_episode_step = 1314.2, total_loss = 516.38, pg_loss = 286.55, baseline_loss = 235.19, entropy_loss = -5.3609, learner_queue_size = 32, _tick = 7620, _time = 1.6548e+09, train_seconds = 9365.7)
[2022-06-09 22:44:10,894][root][INFO] - Step 35200000 @ 3581.2 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 35200000, mean_episode_return = 66.684, mean_episode_step = 1096.7, total_loss = 208.49, pg_loss = 142.37, baseline_loss = 71.438, entropy_loss = -5.3243, learner_queue_size = 32, _tick = 7625, _time = 1.6548e+09, train_seconds = 9370.7)
[2022-06-09 22:44:15,898][root][INFO] - Step 35220480 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 35220480, mean_episode_return = 9.4698, mean_episode_step = 1206.6, total_loss = 363.22, pg_loss = 260.17, baseline_loss = 107.86, entropy_loss = -4.8125, learner_queue_size = 32, _tick = 7632, _time = 1.6548e+09, train_seconds = 9375.7)
[2022-06-09 22:44:20,902][root][INFO] - Step 35238400 @ 3581.1 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 35238400, mean_episode_return = None, mean_episode_step = 1398.4, total_loss = -114.0, pg_loss = -131.82, baseline_loss = 22.579, entropy_loss = -4.7577, learner_queue_size = 32, _tick = 7637, _time = 1.6548e+09, train_seconds = 9380.7)
[2022-06-09 22:44:25,906][root][INFO] - Step 35258880 @ 4092.8 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 35258880, mean_episode_return = None, mean_episode_step = 1417.2, total_loss = 42.313, pg_loss = 0.91072, baseline_loss = 46.647, entropy_loss = -5.2442, learner_queue_size = 32, _tick = 7642, _time = 1.6548e+09, train_seconds = 9385.7)
[2022-06-09 22:44:30,911][root][INFO] - Step 35276800 @ 3580.8 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 35276800, mean_episode_return = None, mean_episode_step = 1673.0, total_loss = 403.32, pg_loss = 246.96, baseline_loss = 161.71, entropy_loss = -5.3505, learner_queue_size = 32, _tick = 7646, _time = 1.6548e+09, train_seconds = 9390.7)
[2022-06-09 22:44:35,914][root][INFO] - Step 35297280 @ 4093.1 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 35297280, mean_episode_return = 3.6594, mean_episode_step = 936.39, total_loss = 26.723, pg_loss = 0.14008, baseline_loss = 31.254, entropy_loss = -4.671, learner_queue_size = 32, _tick = 7654, _time = 1.6548e+09, train_seconds = 9395.7)
[2022-06-09 22:44:40,918][root][INFO] - Step 35315200 @ 3581.2 SPS. Inference batcher size: 94. Learner queue size: 32. Other stats: (step = 35315200, mean_episode_return = 72.88, mean_episode_step = 1096.6, total_loss = 4.9341, pg_loss = -51.756, baseline_loss = 61.319, entropy_loss = -4.6296, learner_queue_size = 32, _tick = 7658, _time = 1.6548e+09, train_seconds = 9400.7)
[2022-06-09 22:44:45,922][root][INFO] - Step 35335680 @ 4092.7 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 35335680, mean_episode_return = 112.32, mean_episode_step = 1056.5, total_loss = 59.465, pg_loss = 12.239, baseline_loss = 52.235, entropy_loss = -5.009, learner_queue_size = 32, _tick = 7663, _time = 1.6548e+09, train_seconds = 9405.7)
[2022-06-09 22:44:50,926][root][INFO] - Step 35356160 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 35356160, mean_episode_return = None, mean_episode_step = 1648.4, total_loss = 293.67, pg_loss = 235.15, baseline_loss = 63.932, entropy_loss = -5.407, learner_queue_size = 32, _tick = 7669, _time = 1.6548e+09, train_seconds = 9410.7)
[2022-06-09 22:44:55,932][root][INFO] - Step 35374080 @ 3580.0 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 35374080, mean_episode_return = None, mean_episode_step = 1112.7, total_loss = 405.24, pg_loss = 321.2, baseline_loss = 89.277, entropy_loss = -5.2365, learner_queue_size = 32, _tick = 7672, _time = 1.6548e+09, train_seconds = 9415.7)
[2022-06-09 22:45:00,934][root][INFO] - Step 35392000 @ 3582.3 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 35392000, mean_episode_return = 92.558, mean_episode_step = 1268.1, total_loss = 527.67, pg_loss = 349.14, baseline_loss = 183.63, entropy_loss = -5.0938, learner_queue_size = 32, _tick = 7678, _time = 1.6548e+09, train_seconds = 9420.7)
[2022-06-09 22:45:05,938][root][INFO] - Step 35409920 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 35409920, mean_episode_return = 67.001, mean_episode_step = 963.2, total_loss = 165.89, pg_loss = 95.113, baseline_loss = 75.62, entropy_loss = -4.8381, learner_queue_size = 32, _tick = 7683, _time = 1.6548e+09, train_seconds = 9425.7)
[2022-06-09 22:45:10,942][root][INFO] - Step 35430400 @ 4092.7 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (step = 35430400, mean_episode_return = 83.16, mean_episode_step = 1300.7, total_loss = 103.87, pg_loss = 49.239, baseline_loss = 59.82, entropy_loss = -5.188, learner_queue_size = 32, _tick = 7689, _time = 1.6548e+09, train_seconds = 9430.7)
[2022-06-09 22:45:15,946][root][INFO] - Step 35448320 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 35448320, mean_episode_return = 75.99, mean_episode_step = 1175.7, total_loss = 22.034, pg_loss = -16.33, baseline_loss = 43.242, entropy_loss = -4.8773, learner_queue_size = 32, _tick = 7696, _time = 1.6548e+09, train_seconds = 9435.8)
[2022-06-09 22:45:20,950][root][INFO] - Step 35466240 @ 3581.0 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 35466240, mean_episode_return = None, mean_episode_step = 1198.8, total_loss = 76.585, pg_loss = 22.177, baseline_loss = 59.32, entropy_loss = -4.9117, learner_queue_size = 32, _tick = 7702, _time = 1.6548e+09, train_seconds = 9440.8)
[2022-06-09 22:45:25,954][root][INFO] - Step 35486720 @ 4092.6 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (step = 35486720, mean_episode_return = None, mean_episode_step = 1312.2, total_loss = 11.5, pg_loss = -7.6816, baseline_loss = 23.801, entropy_loss = -4.619, learner_queue_size = 32, _tick = 7705, _time = 1.6548e+09, train_seconds = 9445.8)
[2022-06-09 22:45:30,960][root][INFO] - Step 35507200 @ 4092.4 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 35507200, mean_episode_return = 14.951, mean_episode_step = 1010.4, total_loss = 421.42, pg_loss = 273.9, baseline_loss = 152.46, entropy_loss = -4.9393, learner_queue_size = 32, _tick = 7712, _time = 1.6548e+09, train_seconds = 9450.8)
[2022-06-09 22:45:35,967][root][INFO] - Step 35525120 @ 3578.0 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 35525120, mean_episode_return = None, mean_episode_step = 1366.1, total_loss = -48.044, pg_loss = -60.177, baseline_loss = 17.454, entropy_loss = -5.3213, learner_queue_size = 32, _tick = 7716, _time = 1.6548e+09, train_seconds = 9455.8)
[2022-06-09 22:45:40,969][root][INFO] - Step 35543040 @ 3582.5 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 35543040, mean_episode_return = -4.9901, mean_episode_step = 1311.9, total_loss = 110.12, pg_loss = 59.706, baseline_loss = 55.857, entropy_loss = -5.4461, learner_queue_size = 32, _tick = 7723, _time = 1.6548e+09, train_seconds = 9460.8)
[2022-06-09 22:45:45,974][root][INFO] - Step 35563520 @ 4092.0 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 35563520, mean_episode_return = 74.335, mean_episode_step = 1176.5, total_loss = 292.7, pg_loss = 213.25, baseline_loss = 84.835, entropy_loss = -5.3813, learner_queue_size = 32, _tick = 7729, _time = 1.6548e+09, train_seconds = 9465.8)
[2022-06-09 22:45:50,978][root][INFO] - Step 35581440 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 35581440, mean_episode_return = -9.5301, mean_episode_step = 1504.1, total_loss = 35.516, pg_loss = -0.79946, baseline_loss = 41.519, entropy_loss = -5.2035, learner_queue_size = 32, _tick = 7734, _time = 1.6548e+09, train_seconds = 9470.8)
[2022-06-09 22:45:55,982][root][INFO] - Step 35599360 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 35599360, mean_episode_return = 65.561, mean_episode_step = 1130.6, total_loss = 80.461, pg_loss = 8.4978, baseline_loss = 77.046, entropy_loss = -5.0832, learner_queue_size = 32, _tick = 7740, _time = 1.6548e+09, train_seconds = 9475.8)
[2022-06-09 22:46:00,987][root][INFO] - Step 35619840 @ 4092.2 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 35619840, mean_episode_return = None, mean_episode_step = 1443.7, total_loss = 1.7818, pg_loss = -27.966, baseline_loss = 35.009, entropy_loss = -5.2617, learner_queue_size = 32, _tick = 7745, _time = 1.6548e+09, train_seconds = 9480.8)
[2022-06-09 22:46:05,992][root][INFO] - Step 35637760 @ 3580.3 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 35637760, mean_episode_return = 133.89, mean_episode_step = 1209.0, total_loss = 108.58, pg_loss = 59.343, baseline_loss = 54.463, entropy_loss = -5.2245, learner_queue_size = 32, _tick = 7750, _time = 1.6548e+09, train_seconds = 9485.8)
[2022-06-09 22:46:10,998][root][INFO] - Step 35655680 @ 3579.6 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 35655680, mean_episode_return = 76.775, mean_episode_step = 1297.6, total_loss = -20.098, pg_loss = -72.884, baseline_loss = 57.984, entropy_loss = -5.1976, learner_queue_size = 32, _tick = 7755, _time = 1.6548e+09, train_seconds = 9490.8)
[2022-06-09 22:46:16,002][root][INFO] - Step 35676160 @ 4092.7 SPS. Inference batcher size: 107. Learner queue size: 32. Other stats: (step = 35676160, mean_episode_return = 35.492, mean_episode_step = 1663.4, total_loss = -121.17, pg_loss = -195.04, baseline_loss = 79.091, entropy_loss = -5.2136, learner_queue_size = 32, _tick = 7760, _time = 1.6548e+09, train_seconds = 9495.8)
[2022-06-09 22:46:21,006][root][INFO] - Step 35694080 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 35694080, mean_episode_return = 99.01, mean_episode_step = 1454.9, total_loss = -78.308, pg_loss = -101.73, baseline_loss = 28.526, entropy_loss = -5.109, learner_queue_size = 32, _tick = 7766, _time = 1.6548e+09, train_seconds = 9500.8)
[2022-06-09 22:46:26,012][root][INFO] - Step 35712000 @ 3579.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 35712000, mean_episode_return = 28.446, mean_episode_step = 1493.9, total_loss = 308.4, pg_loss = 198.71, baseline_loss = 114.82, entropy_loss = -5.1259, learner_queue_size = 32, _tick = 7772, _time = 1.6548e+09, train_seconds = 9505.8)
[2022-06-09 22:46:31,018][root][INFO] - Step 35732480 @ 4091.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 35732480, mean_episode_return = 15.35, mean_episode_step = 1391.5, total_loss = 65.442, pg_loss = 24.648, baseline_loss = 45.867, entropy_loss = -5.073, learner_queue_size = 32, _tick = 7778, _time = 1.6548e+09, train_seconds = 9510.8)
[2022-06-09 22:46:36,022][root][INFO] - Step 35750400 @ 3581.1 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 35750400, mean_episode_return = 297.23, mean_episode_step = 1619.2, total_loss = -117.76, pg_loss = -167.26, baseline_loss = 54.523, entropy_loss = -5.0211, learner_queue_size = 32, _tick = 7784, _time = 1.6548e+09, train_seconds = 9515.8)
[2022-06-09 22:46:41,026][root][INFO] - Step 35768320 @ 3581.2 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 35768320, mean_episode_return = 94.024, mean_episode_step = 1388.5, total_loss = -144.06, pg_loss = -173.33, baseline_loss = 34.512, entropy_loss = -5.242, learner_queue_size = 32, _tick = 7791, _time = 1.6548e+09, train_seconds = 9520.8)
[2022-06-09 22:46:46,030][root][INFO] - Step 35788800 @ 4092.7 SPS. Inference batcher size: 86. Learner queue size: 32. Other stats: (step = 35788800, mean_episode_return = 22.11, mean_episode_step = 1545.0, total_loss = 70.725, pg_loss = 36.622, baseline_loss = 39.401, entropy_loss = -5.2991, learner_queue_size = 32, _tick = 7798, _time = 1.6548e+09, train_seconds = 9525.8)
[2022-06-09 22:46:51,034][root][INFO] - Step 35806720 @ 3581.2 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 35806720, mean_episode_return = 9.2247, mean_episode_step = 1530.6, total_loss = 9.0584, pg_loss = -23.956, baseline_loss = 38.324, entropy_loss = -5.3099, learner_queue_size = 32, _tick = 7805, _time = 1.6548e+09, train_seconds = 9530.8)
[2022-06-09 22:46:56,038][root][INFO] - Step 35824640 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 35824640, mean_episode_return = 64.88, mean_episode_step = 1282.8, total_loss = 182.56, pg_loss = 94.838, baseline_loss = 92.683, entropy_loss = -4.9622, learner_queue_size = 32, _tick = 7809, _time = 1.6548e+09, train_seconds = 9535.8)
[2022-06-09 22:47:01,042][root][INFO] - Step 35845120 @ 4092.7 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 35845120, mean_episode_return = None, mean_episode_step = 1324.3, total_loss = 128.12, pg_loss = 36.403, baseline_loss = 96.776, entropy_loss = -5.0571, learner_queue_size = 32, _tick = 7812, _time = 1.6548e+09, train_seconds = 9540.8)
[2022-06-09 22:47:06,047][root][INFO] - Step 35863040 @ 3580.1 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 35863040, mean_episode_return = 120.54, mean_episode_step = 1601.2, total_loss = 459.8, pg_loss = 213.15, baseline_loss = 251.73, entropy_loss = -5.0668, learner_queue_size = 32, _tick = 7817, _time = 1.6548e+09, train_seconds = 9545.9)
[2022-06-09 22:47:11,050][root][INFO] - Step 35883520 @ 4094.0 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 35883520, mean_episode_return = None, mean_episode_step = 716.56, total_loss = -76.847, pg_loss = -98.949, baseline_loss = 26.983, entropy_loss = -4.8815, learner_queue_size = 32, _tick = 7822, _time = 1.6548e+09, train_seconds = 9550.9)
[2022-06-09 22:47:16,054][root][INFO] - Step 35901440 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 35901440, mean_episode_return = 53.107, mean_episode_step = 1045.8, total_loss = 138.36, pg_loss = 77.56, baseline_loss = 66.121, entropy_loss = -5.3181, learner_queue_size = 32, _tick = 7829, _time = 1.6548e+09, train_seconds = 9555.9)
[2022-06-09 22:47:21,058][root][INFO] - Step 35919360 @ 3581.0 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 35919360, mean_episode_return = 102.51, mean_episode_step = 1176.2, total_loss = -131.72, pg_loss = -162.15, baseline_loss = 35.77, entropy_loss = -5.339, learner_queue_size = 32, _tick = 7835, _time = 1.6548e+09, train_seconds = 9560.9)
[2022-06-09 22:47:26,066][root][INFO] - Step 35939840 @ 4089.5 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 35939840, mean_episode_return = None, mean_episode_step = 1032.5, total_loss = 66.481, pg_loss = 25.797, baseline_loss = 46.019, entropy_loss = -5.3347, learner_queue_size = 32, _tick = 7840, _time = 1.6548e+09, train_seconds = 9565.9)
[2022-06-09 22:47:31,070][root][INFO] - Step 35957760 @ 3581.2 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 35957760, mean_episode_return = None, mean_episode_step = 1547.8, total_loss = -4.8074, pg_loss = -20.581, baseline_loss = 21.087, entropy_loss = -5.3127, learner_queue_size = 32, _tick = 7843, _time = 1.6548e+09, train_seconds = 9570.9)
[2022-06-09 22:47:36,074][root][INFO] - Step 35975680 @ 3581.2 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 35975680, mean_episode_return = 47.51, mean_episode_step = 1182.9, total_loss = 344.53, pg_loss = 259.06, baseline_loss = 90.634, entropy_loss = -5.1705, learner_queue_size = 32, _tick = 7848, _time = 1.6548e+09, train_seconds = 9575.9)
[2022-06-09 22:47:41,079][root][INFO] - Step 35996160 @ 4092.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 35996160, mean_episode_return = None, mean_episode_step = 970.47, total_loss = 11.0, pg_loss = -17.068, baseline_loss = 32.611, entropy_loss = -4.5429, learner_queue_size = 32, _tick = 7852, _time = 1.6548e+09, train_seconds = 9580.9)
[2022-06-09 22:47:46,082][root][INFO] - Step 36014080 @ 3581.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 36014080, mean_episode_return = None, mean_episode_step = 1178.5, total_loss = 181.25, pg_loss = 115.66, baseline_loss = 70.459, entropy_loss = -4.8713, learner_queue_size = 32, _tick = 7857, _time = 1.6548e+09, train_seconds = 9585.9)
[2022-06-09 22:47:51,086][root][INFO] - Step 36034560 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 36034560, mean_episode_return = 28.56, mean_episode_step = 1357.1, total_loss = -86.89, pg_loss = -97.072, baseline_loss = 15.469, entropy_loss = -5.2864, learner_queue_size = 32, _tick = 7864, _time = 1.6548e+09, train_seconds = 9590.9)
[2022-06-09 22:47:56,090][root][INFO] - Step 36052480 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 36052480, mean_episode_return = None, mean_episode_step = 1316.9, total_loss = 411.21, pg_loss = 307.25, baseline_loss = 109.16, entropy_loss = -5.2002, learner_queue_size = 32, _tick = 7866, _time = 1.6548e+09, train_seconds = 9595.9)
[2022-06-09 22:48:01,094][root][INFO] - Step 36070400 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 36070400, mean_episode_return = -18.99, mean_episode_step = 1200.3, total_loss = 3.5143, pg_loss = -20.516, baseline_loss = 29.189, entropy_loss = -5.158, learner_queue_size = 32, _tick = 7872, _time = 1.6548e+09, train_seconds = 9600.9)
[2022-06-09 22:48:06,098][root][INFO] - Step 36090880 @ 4092.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 36090880, mean_episode_return = 22.69, mean_episode_step = 1020.4, total_loss = -91.649, pg_loss = -138.44, baseline_loss = 51.475, entropy_loss = -4.6855, learner_queue_size = 32, _tick = 7880, _time = 1.6548e+09, train_seconds = 9605.9)
[2022-06-09 22:48:11,102][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-09 22:48:11,247][root][INFO] - Step 36108800 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 36108800, mean_episode_return = 80.599, mean_episode_step = 1452.4, total_loss = 125.9, pg_loss = 66.331, baseline_loss = 64.474, entropy_loss = -4.9011, learner_queue_size = 32, _tick = 7886, _time = 1.6548e+09, train_seconds = 9610.9)
[2022-06-09 22:48:16,250][root][INFO] - Step 36129280 @ 3978.3 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 36129280, mean_episode_return = 58.754, mean_episode_step = 1100.3, total_loss = -160.0, pg_loss = -206.94, baseline_loss = 51.638, entropy_loss = -4.6965, learner_queue_size = 32, _tick = 7894, _time = 1.6548e+09, train_seconds = 9616.1)
[2022-06-09 22:48:21,254][root][INFO] - Step 36147200 @ 3581.2 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 36147200, mean_episode_return = 17.41, mean_episode_step = 908.61, total_loss = 15.977, pg_loss = -11.367, baseline_loss = 32.323, entropy_loss = -4.9795, learner_queue_size = 32, _tick = 7898, _time = 1.6548e+09, train_seconds = 9621.1)
[2022-06-09 22:48:26,258][root][INFO] - Step 36165120 @ 3581.1 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 36165120, mean_episode_return = 74.479, mean_episode_step = 1021.9, total_loss = 275.3, pg_loss = 197.98, baseline_loss = 82.337, entropy_loss = -5.0253, learner_queue_size = 32, _tick = 7904, _time = 1.6548e+09, train_seconds = 9626.1)
[2022-06-09 22:48:31,262][root][INFO] - Step 36185600 @ 4092.6 SPS. Inference batcher size: 79. Learner queue size: 32. Other stats: (step = 36185600, mean_episode_return = 76.819, mean_episode_step = 1384.2, total_loss = 756.0, pg_loss = 452.08, baseline_loss = 308.91, entropy_loss = -4.9908, learner_queue_size = 32, _tick = 7911, _time = 1.6548e+09, train_seconds = 9631.1)
[2022-06-09 22:48:36,268][root][INFO] - Step 36203520 @ 3581.2 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 36203520, mean_episode_return = None, mean_episode_step = 992.16, total_loss = 44.968, pg_loss = 7.691, baseline_loss = 41.907, entropy_loss = -4.6304, learner_queue_size = 32, _tick = 7915, _time = 1.6548e+09, train_seconds = 9636.1)
[2022-06-09 22:48:41,274][root][INFO] - Step 36224000 @ 4089.5 SPS. Inference batcher size: 105. Learner queue size: 32. Other stats: (step = 36224000, mean_episode_return = 34.5, mean_episode_step = 1543.6, total_loss = -116.4, pg_loss = -141.74, baseline_loss = 30.666, entropy_loss = -5.3277, learner_queue_size = 32, _tick = 7921, _time = 1.6548e+09, train_seconds = 9641.1)
[2022-06-09 22:48:46,278][root][INFO] - Step 36241920 @ 3581.1 SPS. Inference batcher size: 80. Learner queue size: 32. Other stats: (step = 36241920, mean_episode_return = 52.345, mean_episode_step = 1554.0, total_loss = -34.29, pg_loss = -83.282, baseline_loss = 54.454, entropy_loss = -5.4616, learner_queue_size = 32, _tick = 7925, _time = 1.6548e+09, train_seconds = 9646.1)
[2022-06-09 22:48:51,282][root][INFO] - Step 36259840 @ 3581.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 36259840, mean_episode_return = 67.65, mean_episode_step = 965.73, total_loss = 377.34, pg_loss = 278.38, baseline_loss = 104.31, entropy_loss = -5.3521, learner_queue_size = 32, _tick = 7931, _time = 1.6548e+09, train_seconds = 9651.1)
[2022-06-09 22:48:56,286][root][INFO] - Step 36280320 @ 4092.3 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 36280320, mean_episode_return = 73.99, mean_episode_step = 1056.4, total_loss = 15.387, pg_loss = -9.3718, baseline_loss = 30.16, entropy_loss = -5.4017, learner_queue_size = 32, _tick = 7939, _time = 1.6548e+09, train_seconds = 9656.1)
[2022-06-09 22:49:01,290][root][INFO] - Step 36298240 @ 3581.5 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 36298240, mean_episode_return = 42.929, mean_episode_step = 1355.3, total_loss = 111.07, pg_loss = 62.711, baseline_loss = 53.7, entropy_loss = -5.34, learner_queue_size = 32, _tick = 7945, _time = 1.6548e+09, train_seconds = 9661.1)
[2022-06-09 22:49:06,294][root][INFO] - Step 36316160 @ 3581.1 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 36316160, mean_episode_return = 94.899, mean_episode_step = 1238.3, total_loss = 22.385, pg_loss = -29.971, baseline_loss = 56.681, entropy_loss = -4.3264, learner_queue_size = 32, _tick = 7950, _time = 1.6548e+09, train_seconds = 9666.1)
[2022-06-09 22:49:11,299][root][INFO] - Step 36336640 @ 4091.7 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 36336640, mean_episode_return = 134.17, mean_episode_step = 853.46, total_loss = 63.578, pg_loss = 35.572, baseline_loss = 33.371, entropy_loss = -5.3661, learner_queue_size = 32, _tick = 7956, _time = 1.6548e+09, train_seconds = 9671.1)
[2022-06-09 22:49:16,302][root][INFO] - Step 36354560 @ 3581.9 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 36354560, mean_episode_return = None, mean_episode_step = 1615.6, total_loss = -38.587, pg_loss = -65.394, baseline_loss = 32.223, entropy_loss = -5.4158, learner_queue_size = 32, _tick = 7960, _time = 1.6548e+09, train_seconds = 9676.1)
[2022-06-09 22:49:21,310][root][INFO] - Step 36372480 @ 3578.4 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 36372480, mean_episode_return = 95.314, mean_episode_step = 974.27, total_loss = 40.482, pg_loss = -3.4688, baseline_loss = 49.237, entropy_loss = -5.2864, learner_queue_size = 32, _tick = 7966, _time = 1.6548e+09, train_seconds = 9681.1)
[2022-06-09 22:49:26,314][root][INFO] - Step 36392960 @ 4092.7 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 36392960, mean_episode_return = None, mean_episode_step = 1309.3, total_loss = -30.979, pg_loss = -106.34, baseline_loss = 80.55, entropy_loss = -5.1931, learner_queue_size = 32, _tick = 7970, _time = 1.6548e+09, train_seconds = 9686.1)
[2022-06-09 22:49:31,318][root][INFO] - Step 36410880 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 36410880, mean_episode_return = 55.83, mean_episode_step = 1173.4, total_loss = 99.838, pg_loss = 25.666, baseline_loss = 79.355, entropy_loss = -5.1827, learner_queue_size = 32, _tick = 7976, _time = 1.6548e+09, train_seconds = 9691.1)
[2022-06-09 22:49:36,323][root][INFO] - Step 36428800 @ 3580.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 36428800, mean_episode_return = None, mean_episode_step = 914.78, total_loss = -172.53, pg_loss = -198.25, baseline_loss = 30.897, entropy_loss = -5.1788, learner_queue_size = 32, _tick = 7981, _time = 1.6548e+09, train_seconds = 9696.1)
[2022-06-09 22:49:41,326][root][INFO] - Step 36449280 @ 4093.9 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 36449280, mean_episode_return = 58.506, mean_episode_step = 977.26, total_loss = 65.988, pg_loss = -54.153, baseline_loss = 125.44, entropy_loss = -5.3, learner_queue_size = 32, _tick = 7984, _time = 1.6548e+09, train_seconds = 9701.1)
[2022-06-09 22:49:46,330][root][INFO] - Step 36467200 @ 3580.9 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 36467200, mean_episode_return = None, mean_episode_step = 963.09, total_loss = -64.502, pg_loss = -115.31, baseline_loss = 56.121, entropy_loss = -5.3086, learner_queue_size = 32, _tick = 7988, _time = 1.6548e+09, train_seconds = 9706.1)
[2022-06-09 22:49:51,334][root][INFO] - Step 36485120 @ 3581.4 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 36485120, mean_episode_return = 86.09, mean_episode_step = 1238.9, total_loss = 369.87, pg_loss = 254.65, baseline_loss = 120.55, entropy_loss = -5.332, learner_queue_size = 32, _tick = 7994, _time = 1.6548e+09, train_seconds = 9711.1)
[2022-06-09 22:49:56,338][root][INFO] - Step 36505600 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 36505600, mean_episode_return = 49.041, mean_episode_step = 1673.9, total_loss = -112.33, pg_loss = -206.07, baseline_loss = 98.961, entropy_loss = -5.2225, learner_queue_size = 32, _tick = 8002, _time = 1.6548e+09, train_seconds = 9716.1)
[2022-06-09 22:50:01,342][root][INFO] - Step 36523520 @ 3581.1 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 36523520, mean_episode_return = 55.701, mean_episode_step = 1348.8, total_loss = 16.072, pg_loss = -4.9079, baseline_loss = 26.471, entropy_loss = -5.4907, learner_queue_size = 32, _tick = 8009, _time = 1.6548e+09, train_seconds = 9721.1)
[2022-06-09 22:50:06,346][root][INFO] - Step 36541440 @ 3581.1 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 36541440, mean_episode_return = 41.696, mean_episode_step = 1191.2, total_loss = 19.17, pg_loss = 6.0946, baseline_loss = 18.534, entropy_loss = -5.4593, learner_queue_size = 32, _tick = 8015, _time = 1.6548e+09, train_seconds = 9726.2)
[2022-06-09 22:50:11,350][root][INFO] - Step 36559360 @ 3581.1 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 36559360, mean_episode_return = None, mean_episode_step = 1527.5, total_loss = 67.832, pg_loss = 29.437, baseline_loss = 43.686, entropy_loss = -5.2905, learner_queue_size = 32, _tick = 8020, _time = 1.6548e+09, train_seconds = 9731.2)
[2022-06-09 22:50:16,354][root][INFO] - Step 36579840 @ 4092.7 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 36579840, mean_episode_return = None, mean_episode_step = 1344.8, total_loss = 59.931, pg_loss = 37.441, baseline_loss = 27.779, entropy_loss = -5.2887, learner_queue_size = 32, _tick = 8026, _time = 1.6548e+09, train_seconds = 9736.2)
[2022-06-09 22:50:21,358][root][INFO] - Step 36597760 @ 3581.1 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 36597760, mean_episode_return = None, mean_episode_step = 1079.6, total_loss = 143.52, pg_loss = 80.76, baseline_loss = 68.083, entropy_loss = -5.3189, learner_queue_size = 32, _tick = 8032, _time = 1.6548e+09, train_seconds = 9741.2)
[2022-06-09 22:50:26,362][root][INFO] - Step 36615680 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 36615680, mean_episode_return = 15.34, mean_episode_step = 1130.1, total_loss = -80.152, pg_loss = -94.717, baseline_loss = 19.931, entropy_loss = -5.3659, learner_queue_size = 32, _tick = 8037, _time = 1.6548e+09, train_seconds = 9746.2)
[2022-06-09 22:50:31,366][root][INFO] - Step 36633600 @ 3581.3 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 36633600, mean_episode_return = 56.6, mean_episode_step = 1004.2, total_loss = 216.38, pg_loss = 104.7, baseline_loss = 117.02, entropy_loss = -5.3319, learner_queue_size = 32, _tick = 8043, _time = 1.6548e+09, train_seconds = 9751.2)
[2022-06-09 22:50:36,370][root][INFO] - Step 36654080 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 36654080, mean_episode_return = 53.305, mean_episode_step = 798.01, total_loss = 724.11, pg_loss = 530.46, baseline_loss = 198.91, entropy_loss = -5.2617, learner_queue_size = 32, _tick = 8051, _time = 1.6548e+09, train_seconds = 9756.2)
[2022-06-09 22:50:41,374][root][INFO] - Step 36672000 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 36672000, mean_episode_return = 106.1, mean_episode_step = 1099.8, total_loss = -56.785, pg_loss = -74.182, baseline_loss = 22.67, entropy_loss = -5.2729, learner_queue_size = 32, _tick = 8055, _time = 1.6548e+09, train_seconds = 9761.2)
[2022-06-09 22:50:46,378][root][INFO] - Step 36692480 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 36692480, mean_episode_return = 75.461, mean_episode_step = 1405.2, total_loss = 258.32, pg_loss = 124.75, baseline_loss = 138.62, entropy_loss = -5.0526, learner_queue_size = 32, _tick = 8060, _time = 1.6548e+09, train_seconds = 9766.2)
[2022-06-09 22:50:51,382][root][INFO] - Step 36710400 @ 3581.1 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 36710400, mean_episode_return = 18.91, mean_episode_step = 1082.2, total_loss = 24.253, pg_loss = -78.07, baseline_loss = 106.93, entropy_loss = -4.6018, learner_queue_size = 32, _tick = 8064, _time = 1.6548e+09, train_seconds = 9771.2)
[2022-06-09 22:50:56,386][root][INFO] - Step 36728320 @ 3581.1 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 36728320, mean_episode_return = 1.28, mean_episode_step = 1125.5, total_loss = 472.16, pg_loss = 323.32, baseline_loss = 153.93, entropy_loss = -5.0901, learner_queue_size = 32, _tick = 8069, _time = 1.6548e+09, train_seconds = 9776.2)
[2022-06-09 22:51:01,390][root][INFO] - Step 36746240 @ 3581.1 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 36746240, mean_episode_return = None, mean_episode_step = 1319.5, total_loss = 70.838, pg_loss = 34.407, baseline_loss = 41.775, entropy_loss = -5.3442, learner_queue_size = 32, _tick = 8072, _time = 1.6548e+09, train_seconds = 9781.2)
[2022-06-09 22:51:06,394][root][INFO] - Step 36764160 @ 3581.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 36764160, mean_episode_return = -3.04, mean_episode_step = 1534.1, total_loss = 146.11, pg_loss = 88.534, baseline_loss = 62.754, entropy_loss = -5.182, learner_queue_size = 32, _tick = 8076, _time = 1.6548e+09, train_seconds = 9786.2)
[2022-06-09 22:51:11,398][root][INFO] - Step 36782080 @ 3581.2 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 36782080, mean_episode_return = 41.729, mean_episode_step = 1221.0, total_loss = -25.666, pg_loss = -66.045, baseline_loss = 45.68, entropy_loss = -5.3015, learner_queue_size = 32, _tick = 8081, _time = 1.6548e+09, train_seconds = 9791.2)
[2022-06-09 22:51:16,402][root][INFO] - Step 36802560 @ 4092.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 36802560, mean_episode_return = 51.8, mean_episode_step = 1267.5, total_loss = 11.489, pg_loss = -16.884, baseline_loss = 33.885, entropy_loss = -5.512, learner_queue_size = 32, _tick = 8088, _time = 1.6548e+09, train_seconds = 9796.2)
[2022-06-09 22:51:21,406][root][INFO] - Step 36820480 @ 3581.2 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 36820480, mean_episode_return = 23.85, mean_episode_step = 1442.5, total_loss = 204.14, pg_loss = 136.18, baseline_loss = 73.486, entropy_loss = -5.5209, learner_queue_size = 32, _tick = 8093, _time = 1.6548e+09, train_seconds = 9801.2)
[2022-06-09 22:51:26,410][root][INFO] - Step 36838400 @ 3581.1 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (step = 36838400, mean_episode_return = 19.967, mean_episode_step = 907.44, total_loss = 3.6181, pg_loss = -33.085, baseline_loss = 42.193, entropy_loss = -5.49, learner_queue_size = 32, _tick = 8100, _time = 1.6548e+09, train_seconds = 9806.2)
[2022-06-09 22:51:31,414][root][INFO] - Step 36856320 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 36856320, mean_episode_return = 100.31, mean_episode_step = 1308.8, total_loss = 325.53, pg_loss = 204.03, baseline_loss = 126.77, entropy_loss = -5.2718, learner_queue_size = 32, _tick = 8106, _time = 1.6548e+09, train_seconds = 9811.2)
[2022-06-09 22:51:36,418][root][INFO] - Step 36876800 @ 4092.8 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (step = 36876800, mean_episode_return = -8.7601, mean_episode_step = 1624.4, total_loss = 39.889, pg_loss = 2.6128, baseline_loss = 42.355, entropy_loss = -5.0785, learner_queue_size = 32, _tick = 8113, _time = 1.6548e+09, train_seconds = 9816.2)
[2022-06-09 22:51:41,422][root][INFO] - Step 36894720 @ 3581.1 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 36894720, mean_episode_return = None, mean_episode_step = 1087.1, total_loss = 129.73, pg_loss = 86.635, baseline_loss = 48.374, entropy_loss = -5.2794, learner_queue_size = 32, _tick = 8118, _time = 1.6548e+09, train_seconds = 9821.2)
[2022-06-09 22:51:46,426][root][INFO] - Step 36915200 @ 4092.7 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 36915200, mean_episode_return = None, mean_episode_step = 1353.8, total_loss = 122.23, pg_loss = 64.551, baseline_loss = 63.165, entropy_loss = -5.4898, learner_queue_size = 32, _tick = 8124, _time = 1.6548e+09, train_seconds = 9826.2)
[2022-06-09 22:51:51,430][root][INFO] - Step 36933120 @ 3581.1 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 36933120, mean_episode_return = 86.46, mean_episode_step = 1215.5, total_loss = 18.752, pg_loss = -25.495, baseline_loss = 49.632, entropy_loss = -5.3855, learner_queue_size = 32, _tick = 8126, _time = 1.6548e+09, train_seconds = 9831.2)
[2022-06-09 22:51:56,434][root][INFO] - Step 36951040 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 36951040, mean_episode_return = 77.68, mean_episode_step = 1146.2, total_loss = -88.6, pg_loss = -108.05, baseline_loss = 24.853, entropy_loss = -5.3991, learner_queue_size = 32, _tick = 8132, _time = 1.6548e+09, train_seconds = 9836.2)
[2022-06-09 22:52:01,438][root][INFO] - Step 36968960 @ 3581.1 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 36968960, mean_episode_return = -23.276, mean_episode_step = 1369.4, total_loss = 77.344, pg_loss = 41.401, baseline_loss = 41.359, entropy_loss = -5.4168, learner_queue_size = 32, _tick = 8138, _time = 1.6548e+09, train_seconds = 9841.2)
[2022-06-09 22:52:06,442][root][INFO] - Step 36989440 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 36989440, mean_episode_return = 75.618, mean_episode_step = 1411.3, total_loss = 24.768, pg_loss = -29.137, baseline_loss = 59.299, entropy_loss = -5.3948, learner_queue_size = 32, _tick = 8143, _time = 1.6548e+09, train_seconds = 9846.2)
[2022-06-09 22:52:11,446][root][INFO] - Step 37007360 @ 3581.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 37007360, mean_episode_return = 24.53, mean_episode_step = 1454.0, total_loss = 157.44, pg_loss = 90.756, baseline_loss = 71.963, entropy_loss = -5.2765, learner_queue_size = 32, _tick = 8149, _time = 1.6548e+09, train_seconds = 9851.3)
[2022-06-09 22:52:16,451][root][INFO] - Step 37027840 @ 4092.0 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 37027840, mean_episode_return = None, mean_episode_step = 1008.6, total_loss = 93.489, pg_loss = 45.287, baseline_loss = 53.491, entropy_loss = -5.289, learner_queue_size = 32, _tick = 8153, _time = 1.6548e+09, train_seconds = 9856.3)
[2022-06-09 22:52:21,454][root][INFO] - Step 37045760 @ 3581.7 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (step = 37045760, mean_episode_return = 92.72, mean_episode_step = 1241.7, total_loss = -2.5227, pg_loss = -42.441, baseline_loss = 45.1, entropy_loss = -5.1815, learner_queue_size = 32, _tick = 8159, _time = 1.6548e+09, train_seconds = 9861.3)
[2022-06-09 22:52:26,458][root][INFO] - Step 37063680 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 37063680, mean_episode_return = 22.19, mean_episode_step = 1703.5, total_loss = 52.796, pg_loss = 13.439, baseline_loss = 44.689, entropy_loss = -5.3324, learner_queue_size = 32, _tick = 8166, _time = 1.6548e+09, train_seconds = 9866.3)
[2022-06-09 22:52:31,462][root][INFO] - Step 37081600 @ 3581.1 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 37081600, mean_episode_return = 70.301, mean_episode_step = 1341.4, total_loss = 286.67, pg_loss = 198.5, baseline_loss = 93.558, entropy_loss = -5.3803, learner_queue_size = 32, _tick = 8173, _time = 1.6548e+09, train_seconds = 9871.3)
[2022-06-09 22:52:36,466][root][INFO] - Step 37102080 @ 4092.8 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 37102080, mean_episode_return = 36.881, mean_episode_step = 1464.2, total_loss = 401.37, pg_loss = 289.74, baseline_loss = 117.05, entropy_loss = -5.4209, learner_queue_size = 32, _tick = 8179, _time = 1.6548e+09, train_seconds = 9876.3)
[2022-06-09 22:52:41,470][root][INFO] - Step 37120000 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 37120000, mean_episode_return = None, mean_episode_step = 1169.7, total_loss = 69.201, pg_loss = 34.797, baseline_loss = 39.754, entropy_loss = -5.35, learner_queue_size = 32, _tick = 8182, _time = 1.6548e+09, train_seconds = 9881.3)
[2022-06-09 22:52:46,474][root][INFO] - Step 37140480 @ 4092.7 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 37140480, mean_episode_return = 13.665, mean_episode_step = 1302.9, total_loss = 221.18, pg_loss = 166.18, baseline_loss = 60.399, entropy_loss = -5.3988, learner_queue_size = 32, _tick = 8188, _time = 1.6548e+09, train_seconds = 9886.3)
[2022-06-09 22:52:51,478][root][INFO] - Step 37158400 @ 3581.2 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 37158400, mean_episode_return = 9.3398, mean_episode_step = 1249.6, total_loss = 284.92, pg_loss = 200.68, baseline_loss = 89.716, entropy_loss = -5.4782, learner_queue_size = 32, _tick = 8193, _time = 1.6548e+09, train_seconds = 9891.3)
[2022-06-09 22:52:56,482][root][INFO] - Step 37178880 @ 4092.8 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 37178880, mean_episode_return = None, mean_episode_step = 1324.2, total_loss = 151.18, pg_loss = 114.82, baseline_loss = 41.874, entropy_loss = -5.509, learner_queue_size = 32, _tick = 8198, _time = 1.6548e+09, train_seconds = 9896.3)
[2022-06-09 22:53:01,486][root][INFO] - Step 37196800 @ 3581.1 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 37196800, mean_episode_return = 28.379, mean_episode_step = 1770.8, total_loss = 512.39, pg_loss = 384.59, baseline_loss = 133.18, entropy_loss = -5.3891, learner_queue_size = 32, _tick = 8205, _time = 1.6548e+09, train_seconds = 9901.3)
[2022-06-09 22:53:06,490][root][INFO] - Step 37214720 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 37214720, mean_episode_return = 41.353, mean_episode_step = 1288.1, total_loss = -187.45, pg_loss = -195.31, baseline_loss = 13.231, entropy_loss = -5.3708, learner_queue_size = 32, _tick = 8209, _time = 1.6548e+09, train_seconds = 9906.3)
[2022-06-09 22:53:11,494][root][INFO] - Step 37235200 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 37235200, mean_episode_return = None, mean_episode_step = 1058.4, total_loss = 251.55, pg_loss = 175.59, baseline_loss = 81.411, entropy_loss = -5.4509, learner_queue_size = 32, _tick = 8215, _time = 1.6548e+09, train_seconds = 9911.3)
[2022-06-09 22:53:16,499][root][INFO] - Step 37253120 @ 3580.3 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 37253120, mean_episode_return = 57.514, mean_episode_step = 1518.0, total_loss = 576.85, pg_loss = 438.66, baseline_loss = 143.66, entropy_loss = -5.4775, learner_queue_size = 32, _tick = 8221, _time = 1.6548e+09, train_seconds = 9916.3)
[2022-06-09 22:53:21,502][root][INFO] - Step 37271040 @ 3581.9 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (step = 37271040, mean_episode_return = None, mean_episode_step = 1393.0, total_loss = 370.65, pg_loss = 260.07, baseline_loss = 116.01, entropy_loss = -5.4282, learner_queue_size = 32, _tick = 8225, _time = 1.6548e+09, train_seconds = 9921.3)
[2022-06-09 22:53:26,506][root][INFO] - Step 37288960 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 37288960, mean_episode_return = 73.92, mean_episode_step = 1527.8, total_loss = 297.82, pg_loss = 205.91, baseline_loss = 97.317, entropy_loss = -5.4019, learner_queue_size = 32, _tick = 8231, _time = 1.6548e+09, train_seconds = 9926.3)
[2022-06-09 22:53:31,510][root][INFO] - Step 37309440 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 37309440, mean_episode_return = None, mean_episode_step = 1708.2, total_loss = 119.88, pg_loss = 89.568, baseline_loss = 35.693, entropy_loss = -5.3857, learner_queue_size = 32, _tick = 8235, _time = 1.6548e+09, train_seconds = 9931.3)
[2022-06-09 22:53:36,514][root][INFO] - Step 37327360 @ 3581.1 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (step = 37327360, mean_episode_return = 47.5, mean_episode_step = 1435.5, total_loss = -97.7, pg_loss = -141.68, baseline_loss = 49.171, entropy_loss = -5.1947, learner_queue_size = 32, _tick = 8239, _time = 1.6548e+09, train_seconds = 9936.3)
[2022-06-09 22:53:41,518][root][INFO] - Step 37347840 @ 4092.8 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 37347840, mean_episode_return = None, mean_episode_step = 1603.7, total_loss = -41.899, pg_loss = -70.901, baseline_loss = 34.286, entropy_loss = -5.2845, learner_queue_size = 32, _tick = 8245, _time = 1.6548e+09, train_seconds = 9941.3)
[2022-06-09 22:53:46,522][root][INFO] - Step 37365760 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 37365760, mean_episode_return = None, mean_episode_step = 1165.3, total_loss = 184.99, pg_loss = 130.48, baseline_loss = 59.925, entropy_loss = -5.4128, learner_queue_size = 32, _tick = 8250, _time = 1.6548e+09, train_seconds = 9946.3)
[2022-06-09 22:53:51,526][root][INFO] - Step 37383680 @ 3581.0 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 37383680, mean_episode_return = None, mean_episode_step = 1095.1, total_loss = -25.016, pg_loss = -57.045, baseline_loss = 37.46, entropy_loss = -5.4308, learner_queue_size = 32, _tick = 8254, _time = 1.6548e+09, train_seconds = 9951.3)
[2022-06-09 22:53:56,530][root][INFO] - Step 37404160 @ 4092.9 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 37404160, mean_episode_return = 45.743, mean_episode_step = 1576.4, total_loss = 23.315, pg_loss = -10.505, baseline_loss = 39.184, entropy_loss = -5.365, learner_queue_size = 32, _tick = 8259, _time = 1.6548e+09, train_seconds = 9956.3)
[2022-06-09 22:54:01,534][root][INFO] - Step 37422080 @ 3581.2 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 37422080, mean_episode_return = 32.38, mean_episode_step = 1398.2, total_loss = -216.67, pg_loss = -221.02, baseline_loss = 9.8326, entropy_loss = -5.483, learner_queue_size = 32, _tick = 8265, _time = 1.6548e+09, train_seconds = 9961.3)
[2022-06-09 22:54:06,539][root][INFO] - Step 37440000 @ 3580.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 37440000, mean_episode_return = None, mean_episode_step = 2140.5, total_loss = 194.81, pg_loss = 158.2, baseline_loss = 42.04, entropy_loss = -5.4326, learner_queue_size = 32, _tick = 8269, _time = 1.6548e+09, train_seconds = 9966.3)
[2022-06-09 22:54:11,542][root][INFO] - Step 37460480 @ 4093.2 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 37460480, mean_episode_return = 19.46, mean_episode_step = 1472.9, total_loss = 84.511, pg_loss = -21.053, baseline_loss = 110.63, entropy_loss = -5.0702, learner_queue_size = 32, _tick = 8276, _time = 1.6548e+09, train_seconds = 9971.3)
[2022-06-09 22:54:16,546][root][INFO] - Step 37478400 @ 3581.1 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 37478400, mean_episode_return = None, mean_episode_step = 1582.9, total_loss = -6.9021, pg_loss = -20.843, baseline_loss = 19.406, entropy_loss = -5.4652, learner_queue_size = 32, _tick = 8280, _time = 1.6548e+09, train_seconds = 9976.4)
[2022-06-09 22:54:21,550][root][INFO] - Step 37496320 @ 3581.2 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (step = 37496320, mean_episode_return = None, mean_episode_step = 1473.0, total_loss = 59.082, pg_loss = 15.615, baseline_loss = 48.815, entropy_loss = -5.3481, learner_queue_size = 32, _tick = 8285, _time = 1.6548e+09, train_seconds = 9981.4)
[2022-06-09 22:54:26,554][root][INFO] - Step 37516800 @ 4092.7 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 37516800, mean_episode_return = 79.86, mean_episode_step = 1718.4, total_loss = -78.885, pg_loss = -98.194, baseline_loss = 24.465, entropy_loss = -5.156, learner_queue_size = 32, _tick = 8291, _time = 1.6548e+09, train_seconds = 9986.4)
[2022-06-09 22:54:31,558][root][INFO] - Step 37537280 @ 4092.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 37537280, mean_episode_return = 55.582, mean_episode_step = 1694.5, total_loss = -26.637, pg_loss = -66.122, baseline_loss = 44.891, entropy_loss = -5.4067, learner_queue_size = 32, _tick = 8297, _time = 1.6548e+09, train_seconds = 9991.4)
[2022-06-09 22:54:36,562][root][INFO] - Step 37555200 @ 3581.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 37555200, mean_episode_return = 132.75, mean_episode_step = 1149.9, total_loss = -154.57, pg_loss = -164.74, baseline_loss = 15.52, entropy_loss = -5.3516, learner_queue_size = 32, _tick = 8302, _time = 1.6548e+09, train_seconds = 9996.4)
[2022-06-09 22:54:41,566][root][INFO] - Step 37573120 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 37573120, mean_episode_return = 26.685, mean_episode_step = 1208.9, total_loss = 227.36, pg_loss = 145.12, baseline_loss = 87.575, entropy_loss = -5.3288, learner_queue_size = 32, _tick = 8307, _time = 1.6548e+09, train_seconds = 1.0001e+04)
[2022-06-09 22:54:46,570][root][INFO] - Step 37591040 @ 3581.2 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 37591040, mean_episode_return = 24.146, mean_episode_step = 1824.0, total_loss = 172.05, pg_loss = 102.07, baseline_loss = 75.282, entropy_loss = -5.3007, learner_queue_size = 32, _tick = 8313, _time = 1.6548e+09, train_seconds = 1.0006e+04)
[2022-06-09 22:54:51,574][root][INFO] - Step 37611520 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 37611520, mean_episode_return = -15.27, mean_episode_step = 1611.0, total_loss = -87.327, pg_loss = -113.63, baseline_loss = 31.34, entropy_loss = -5.0365, learner_queue_size = 32, _tick = 8318, _time = 1.6548e+09, train_seconds = 1.0011e+04)
[2022-06-09 22:54:56,578][root][INFO] - Step 37629440 @ 3581.1 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (step = 37629440, mean_episode_return = 81.631, mean_episode_step = 1619.4, total_loss = -90.013, pg_loss = -128.26, baseline_loss = 43.39, entropy_loss = -5.1418, learner_queue_size = 32, _tick = 8322, _time = 1.6548e+09, train_seconds = 1.0016e+04)
[2022-06-09 22:55:01,582][root][INFO] - Step 37647360 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 37647360, mean_episode_return = 62.802, mean_episode_step = 1388.5, total_loss = -36.971, pg_loss = -63.772, baseline_loss = 32.178, entropy_loss = -5.3766, learner_queue_size = 32, _tick = 8327, _time = 1.6548e+09, train_seconds = 1.0021e+04)
[2022-06-09 22:55:06,586][root][INFO] - Step 37667840 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 37667840, mean_episode_return = None, mean_episode_step = 1838.3, total_loss = -180.35, pg_loss = -181.6, baseline_loss = 6.7357, entropy_loss = -5.4858, learner_queue_size = 32, _tick = 8333, _time = 1.6548e+09, train_seconds = 1.0026e+04)
[2022-06-09 22:55:11,590][root][INFO] - Step 37685760 @ 3581.2 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 37685760, mean_episode_return = 44.25, mean_episode_step = 1311.2, total_loss = 45.758, pg_loss = 22.396, baseline_loss = 28.814, entropy_loss = -5.452, learner_queue_size = 32, _tick = 8339, _time = 1.6548e+09, train_seconds = 1.0031e+04)
[2022-06-09 22:55:16,594][root][INFO] - Step 37706240 @ 4092.7 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 37706240, mean_episode_return = 64.181, mean_episode_step = 1384.4, total_loss = -66.955, pg_loss = -99.593, baseline_loss = 38.069, entropy_loss = -5.4313, learner_queue_size = 32, _tick = 8343, _time = 1.6548e+09, train_seconds = 1.0036e+04)
[2022-06-09 22:55:21,598][root][INFO] - Step 37724160 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 37724160, mean_episode_return = 24.39, mean_episode_step = 1946.7, total_loss = -192.4, pg_loss = -197.55, baseline_loss = 10.597, entropy_loss = -5.4496, learner_queue_size = 32, _tick = 8350, _time = 1.6548e+09, train_seconds = 1.0041e+04)
[2022-06-09 22:55:26,602][root][INFO] - Step 37742080 @ 3581.2 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 37742080, mean_episode_return = 55.159, mean_episode_step = 1473.4, total_loss = -71.78, pg_loss = -95.941, baseline_loss = 29.36, entropy_loss = -5.1993, learner_queue_size = 32, _tick = 8356, _time = 1.6548e+09, train_seconds = 1.0046e+04)
[2022-06-09 22:55:31,606][root][INFO] - Step 37762560 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 37762560, mean_episode_return = None, mean_episode_step = 1573.6, total_loss = 80.858, pg_loss = 11.719, baseline_loss = 74.441, entropy_loss = -5.3025, learner_queue_size = 32, _tick = 8361, _time = 1.6548e+09, train_seconds = 1.0051e+04)
[2022-06-09 22:55:36,610][root][INFO] - Step 37780480 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 37780480, mean_episode_return = None, mean_episode_step = 1454.4, total_loss = 146.83, pg_loss = 61.995, baseline_loss = 90.356, entropy_loss = -5.522, learner_queue_size = 32, _tick = 8366, _time = 1.6548e+09, train_seconds = 1.0056e+04)
[2022-06-09 22:55:41,615][root][INFO] - Step 37800960 @ 4091.8 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 37800960, mean_episode_return = 38.682, mean_episode_step = 1010.7, total_loss = -48.334, pg_loss = -82.204, baseline_loss = 39.245, entropy_loss = -5.3754, learner_queue_size = 32, _tick = 8373, _time = 1.6548e+09, train_seconds = 1.0061e+04)
[2022-06-09 22:55:46,618][root][INFO] - Step 37818880 @ 3581.6 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 37818880, mean_episode_return = 102.23, mean_episode_step = 1711.6, total_loss = 348.58, pg_loss = 247.23, baseline_loss = 106.64, entropy_loss = -5.2936, learner_queue_size = 32, _tick = 8379, _time = 1.6548e+09, train_seconds = 1.0066e+04)
[2022-06-09 22:55:51,622][root][INFO] - Step 37836800 @ 3581.4 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 37836800, mean_episode_return = 54.32, mean_episode_step = 1721.4, total_loss = 105.66, pg_loss = 37.271, baseline_loss = 73.745, entropy_loss = -5.3544, learner_queue_size = 32, _tick = 8385, _time = 1.6548e+09, train_seconds = 1.0071e+04)
[2022-06-09 22:55:56,626][root][INFO] - Step 37857280 @ 4092.7 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 37857280, mean_episode_return = 44.59, mean_episode_step = 1722.8, total_loss = 539.73, pg_loss = 347.83, baseline_loss = 197.32, entropy_loss = -5.4159, learner_queue_size = 32, _tick = 8391, _time = 1.6548e+09, train_seconds = 1.0076e+04)
[2022-06-09 22:56:01,630][root][INFO] - Step 37875200 @ 3581.2 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (step = 37875200, mean_episode_return = -4.84, mean_episode_step = 1025.0, total_loss = 131.76, pg_loss = 71.134, baseline_loss = 66.061, entropy_loss = -5.4383, learner_queue_size = 32, _tick = 8396, _time = 1.6548e+09, train_seconds = 1.0081e+04)
[2022-06-09 22:56:06,634][root][INFO] - Step 37895680 @ 4092.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 37895680, mean_episode_return = None, mean_episode_step = 1679.3, total_loss = -117.05, pg_loss = -137.63, baseline_loss = 25.767, entropy_loss = -5.1915, learner_queue_size = 32, _tick = 8402, _time = 1.6548e+09, train_seconds = 1.0086e+04)
[2022-06-09 22:56:11,638][root][INFO] - Step 37913600 @ 3581.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 37913600, mean_episode_return = None, mean_episode_step = 2328.2, total_loss = 223.04, pg_loss = 137.51, baseline_loss = 90.957, entropy_loss = -5.4279, learner_queue_size = 32, _tick = 8408, _time = 1.6548e+09, train_seconds = 1.0091e+04)
[2022-06-09 22:56:16,642][root][INFO] - Step 37934080 @ 4092.8 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 37934080, mean_episode_return = None, mean_episode_step = 1346.4, total_loss = 75.847, pg_loss = -7.475, baseline_loss = 88.764, entropy_loss = -5.4425, learner_queue_size = 32, _tick = 8415, _time = 1.6548e+09, train_seconds = 1.0096e+04)
[2022-06-09 22:56:21,646][root][INFO] - Step 37952000 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 37952000, mean_episode_return = 43.965, mean_episode_step = 1118.6, total_loss = 72.937, pg_loss = -12.012, baseline_loss = 90.282, entropy_loss = -5.3331, learner_queue_size = 32, _tick = 8420, _time = 1.6548e+09, train_seconds = 1.0102e+04)
[2022-06-09 22:56:26,650][root][INFO] - Step 37969920 @ 3580.9 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 37969920, mean_episode_return = 59.031, mean_episode_step = 1152.5, total_loss = 200.63, pg_loss = 128.4, baseline_loss = 77.655, entropy_loss = -5.4256, learner_queue_size = 32, _tick = 8426, _time = 1.6548e+09, train_seconds = 1.0106e+04)
[2022-06-09 22:56:31,654][root][INFO] - Step 37990400 @ 4092.9 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 37990400, mean_episode_return = 11.85, mean_episode_step = 1074.9, total_loss = 61.322, pg_loss = 28.103, baseline_loss = 38.625, entropy_loss = -5.4062, learner_queue_size = 32, _tick = 8433, _time = 1.6548e+09, train_seconds = 1.0112e+04)
[2022-06-09 22:56:36,658][root][INFO] - Step 38008320 @ 3581.2 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 38008320, mean_episode_return = 65.226, mean_episode_step = 1041.8, total_loss = 129.38, pg_loss = 41.164, baseline_loss = 93.632, entropy_loss = -5.4154, learner_queue_size = 32, _tick = 8440, _time = 1.6548e+09, train_seconds = 1.0116e+04)
[2022-06-09 22:56:41,662][root][INFO] - Step 38026240 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 38026240, mean_episode_return = 25.16, mean_episode_step = 1152.5, total_loss = 61.4, pg_loss = 3.9034, baseline_loss = 62.755, entropy_loss = -5.2588, learner_queue_size = 32, _tick = 8446, _time = 1.6548e+09, train_seconds = 1.0122e+04)
[2022-06-09 22:56:46,666][root][INFO] - Step 38046720 @ 4092.7 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 38046720, mean_episode_return = 4.2996, mean_episode_step = 1086.9, total_loss = 142.96, pg_loss = 68.829, baseline_loss = 79.393, entropy_loss = -5.2605, learner_queue_size = 32, _tick = 8454, _time = 1.6548e+09, train_seconds = 1.0126e+04)
[2022-06-09 22:56:51,670][root][INFO] - Step 38064640 @ 3581.2 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 38064640, mean_episode_return = 112.65, mean_episode_step = 1015.6, total_loss = -49.486, pg_loss = -90.321, baseline_loss = 46.22, entropy_loss = -5.3856, learner_queue_size = 32, _tick = 8458, _time = 1.6548e+09, train_seconds = 1.0132e+04)
[2022-06-09 22:56:56,674][root][INFO] - Step 38082560 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 38082560, mean_episode_return = 71.888, mean_episode_step = 1066.8, total_loss = 587.71, pg_loss = 416.22, baseline_loss = 176.87, entropy_loss = -5.3896, learner_queue_size = 32, _tick = 8464, _time = 1.6548e+09, train_seconds = 1.0136e+04)
[2022-06-09 22:57:01,678][root][INFO] - Step 38100480 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 38100480, mean_episode_return = 55.606, mean_episode_step = 1155.4, total_loss = 29.288, pg_loss = -15.35, baseline_loss = 49.946, entropy_loss = -5.3086, learner_queue_size = 32, _tick = 8467, _time = 1.6548e+09, train_seconds = 1.0142e+04)
[2022-06-09 22:57:06,682][root][INFO] - Step 38120960 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 38120960, mean_episode_return = 18.245, mean_episode_step = 1565.2, total_loss = 172.51, pg_loss = 91.333, baseline_loss = 86.557, entropy_loss = -5.3822, learner_queue_size = 32, _tick = 8474, _time = 1.6548e+09, train_seconds = 1.0146e+04)
[2022-06-09 22:57:11,686][root][INFO] - Step 38138880 @ 3581.2 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 38138880, mean_episode_return = 14.33, mean_episode_step = 1964.3, total_loss = 97.362, pg_loss = 30.184, baseline_loss = 72.381, entropy_loss = -5.2026, learner_queue_size = 32, _tick = 8478, _time = 1.6548e+09, train_seconds = 1.0152e+04)
[2022-06-09 22:57:16,690][root][INFO] - Step 38159360 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 38159360, mean_episode_return = -7.3305, mean_episode_step = 1406.6, total_loss = 46.442, pg_loss = -18.242, baseline_loss = 69.747, entropy_loss = -5.0628, learner_queue_size = 32, _tick = 8484, _time = 1.6548e+09, train_seconds = 1.0156e+04)
[2022-06-09 22:57:21,694][root][INFO] - Step 38177280 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 38177280, mean_episode_return = 33.005, mean_episode_step = 1785.2, total_loss = 53.706, pg_loss = -8.985, baseline_loss = 68.005, entropy_loss = -5.314, learner_queue_size = 32, _tick = 8489, _time = 1.6548e+09, train_seconds = 1.0162e+04)
[2022-06-09 22:57:26,698][root][INFO] - Step 38195200 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 38195200, mean_episode_return = None, mean_episode_step = 1048.4, total_loss = -168.5, pg_loss = -194.12, baseline_loss = 30.834, entropy_loss = -5.2171, learner_queue_size = 32, _tick = 8493, _time = 1.6548e+09, train_seconds = 1.0166e+04)
[2022-06-09 22:57:31,703][root][INFO] - Step 38215680 @ 4092.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 38215680, mean_episode_return = 18.13, mean_episode_step = 1198.9, total_loss = 1132.2, pg_loss = 403.82, baseline_loss = 733.64, entropy_loss = -5.2784, learner_queue_size = 32, _tick = 8498, _time = 1.6548e+09, train_seconds = 1.0172e+04)
[2022-06-09 22:57:36,706][root][INFO] - Step 38233600 @ 3581.8 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 38233600, mean_episode_return = 166.18, mean_episode_step = 1313.4, total_loss = -68.962, pg_loss = -122.56, baseline_loss = 58.833, entropy_loss = -5.2324, learner_queue_size = 32, _tick = 8503, _time = 1.6548e+09, train_seconds = 1.0176e+04)
[2022-06-09 22:57:41,716][root][INFO] - Step 38254080 @ 4088.0 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 38254080, mean_episode_return = None, mean_episode_step = 1558.9, total_loss = -52.531, pg_loss = -122.61, baseline_loss = 75.402, entropy_loss = -5.3225, learner_queue_size = 32, _tick = 8509, _time = 1.6548e+09, train_seconds = 1.0182e+04)
[2022-06-09 22:57:46,718][root][INFO] - Step 38272000 @ 3582.4 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 38272000, mean_episode_return = 21.912, mean_episode_step = 1317.8, total_loss = 102.49, pg_loss = 59.057, baseline_loss = 48.883, entropy_loss = -5.449, learner_queue_size = 32, _tick = 8516, _time = 1.6548e+09, train_seconds = 1.0186e+04)
[2022-06-09 22:57:51,722][root][INFO] - Step 38292480 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 38292480, mean_episode_return = 187.55, mean_episode_step = 1303.7, total_loss = -148.28, pg_loss = -160.77, baseline_loss = 17.696, entropy_loss = -5.203, learner_queue_size = 32, _tick = 8524, _time = 1.6548e+09, train_seconds = 1.0192e+04)
[2022-06-09 22:57:56,726][root][INFO] - Step 38310400 @ 3581.1 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 38310400, mean_episode_return = 19.755, mean_episode_step = 1017.0, total_loss = 178.61, pg_loss = 118.79, baseline_loss = 64.76, entropy_loss = -4.9376, learner_queue_size = 32, _tick = 8530, _time = 1.6548e+09, train_seconds = 1.0196e+04)
[2022-06-09 22:58:01,730][root][INFO] - Step 38328320 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 38328320, mean_episode_return = None, mean_episode_step = 1272.6, total_loss = -11.154, pg_loss = -44.137, baseline_loss = 38.398, entropy_loss = -5.4153, learner_queue_size = 32, _tick = 8535, _time = 1.6548e+09, train_seconds = 1.0202e+04)
[2022-06-09 22:58:06,734][root][INFO] - Step 38348800 @ 4092.7 SPS. Inference batcher size: 84. Learner queue size: 32. Other stats: (step = 38348800, mean_episode_return = None, mean_episode_step = 1229.4, total_loss = 48.948, pg_loss = -5.6796, baseline_loss = 60.096, entropy_loss = -5.4687, learner_queue_size = 32, _tick = 8542, _time = 1.6548e+09, train_seconds = 1.0206e+04)
[2022-06-09 22:58:11,738][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-09 22:58:11,880][root][INFO] - Step 38366720 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 38366720, mean_episode_return = 6.6747, mean_episode_step = 1242.7, total_loss = 325.66, pg_loss = 249.47, baseline_loss = 81.715, entropy_loss = -5.5228, learner_queue_size = 32, _tick = 8548, _time = 1.6548e+09, train_seconds = 1.0212e+04)
[2022-06-09 22:58:16,886][root][INFO] - Step 38384640 @ 3481.0 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 38384640, mean_episode_return = None, mean_episode_step = 983.0, total_loss = 299.46, pg_loss = 222.92, baseline_loss = 81.775, entropy_loss = -5.2329, learner_queue_size = 32, _tick = 8553, _time = 1.6548e+09, train_seconds = 1.0217e+04)
[2022-06-09 22:58:21,890][root][INFO] - Step 38405120 @ 4092.7 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 38405120, mean_episode_return = 74.146, mean_episode_step = 1546.2, total_loss = 106.99, pg_loss = 54.192, baseline_loss = 58.326, entropy_loss = -5.5255, learner_queue_size = 32, _tick = 8559, _time = 1.6548e+09, train_seconds = 1.0222e+04)
[2022-06-09 22:58:26,894][root][INFO] - Step 38423040 @ 3581.2 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 38423040, mean_episode_return = 86.49, mean_episode_step = 1084.9, total_loss = -99.724, pg_loss = -138.04, baseline_loss = 43.535, entropy_loss = -5.2236, learner_queue_size = 32, _tick = 8566, _time = 1.6548e+09, train_seconds = 1.0227e+04)
[2022-06-09 22:58:31,898][root][INFO] - Step 38440960 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 38440960, mean_episode_return = 49.361, mean_episode_step = 1145.7, total_loss = -128.71, pg_loss = -151.59, baseline_loss = 28.057, entropy_loss = -5.1752, learner_queue_size = 32, _tick = 8571, _time = 1.6548e+09, train_seconds = 1.0232e+04)
[2022-06-09 22:58:36,902][root][INFO] - Step 38461440 @ 4092.5 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 38461440, mean_episode_return = None, mean_episode_step = 1318.7, total_loss = -83.015, pg_loss = -114.64, baseline_loss = 36.735, entropy_loss = -5.1147, learner_queue_size = 32, _tick = 8575, _time = 1.6548e+09, train_seconds = 1.0237e+04)
[2022-06-09 22:58:41,906][root][INFO] - Step 38479360 @ 3581.3 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 38479360, mean_episode_return = 92.129, mean_episode_step = 1341.3, total_loss = -28.162, pg_loss = -83.049, baseline_loss = 60.003, entropy_loss = -5.1164, learner_queue_size = 32, _tick = 8581, _time = 1.6548e+09, train_seconds = 1.0242e+04)
[2022-06-09 22:58:46,910][root][INFO] - Step 38499840 @ 4092.7 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 38499840, mean_episode_return = None, mean_episode_step = 1297.4, total_loss = 201.91, pg_loss = 128.35, baseline_loss = 78.726, entropy_loss = -5.1597, learner_queue_size = 32, _tick = 8584, _time = 1.6548e+09, train_seconds = 1.0247e+04)
[2022-06-09 22:58:51,914][root][INFO] - Step 38517760 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 38517760, mean_episode_return = 26.3, mean_episode_step = 1103.3, total_loss = -201.38, pg_loss = -234.47, baseline_loss = 38.388, entropy_loss = -5.2999, learner_queue_size = 32, _tick = 8590, _time = 1.6548e+09, train_seconds = 1.0252e+04)
[2022-06-09 22:58:56,918][root][INFO] - Step 38535680 @ 3581.2 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 38535680, mean_episode_return = None, mean_episode_step = 1306.3, total_loss = -2.4537, pg_loss = -36.891, baseline_loss = 39.841, entropy_loss = -5.4037, learner_queue_size = 32, _tick = 8593, _time = 1.6548e+09, train_seconds = 1.0257e+04)
[2022-06-09 22:59:01,922][root][INFO] - Step 38556160 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 38556160, mean_episode_return = 1.3399, mean_episode_step = 1329.2, total_loss = 460.61, pg_loss = 307.85, baseline_loss = 158.0, entropy_loss = -5.2434, learner_queue_size = 32, _tick = 8599, _time = 1.6548e+09, train_seconds = 1.0262e+04)
[2022-06-09 22:59:06,926][root][INFO] - Step 38574080 @ 3581.1 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 38574080, mean_episode_return = 34.491, mean_episode_step = 1252.3, total_loss = -110.59, pg_loss = -140.05, baseline_loss = 34.674, entropy_loss = -5.2092, learner_queue_size = 32, _tick = 8604, _time = 1.6548e+09, train_seconds = 1.0267e+04)
[2022-06-09 22:59:11,930][root][INFO] - Step 38592000 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 38592000, mean_episode_return = None, mean_episode_step = 1153.8, total_loss = 95.788, pg_loss = 35.12, baseline_loss = 66.006, entropy_loss = -5.3379, learner_queue_size = 32, _tick = 8608, _time = 1.6548e+09, train_seconds = 1.0272e+04)
[2022-06-09 22:59:16,934][root][INFO] - Step 38612480 @ 4092.8 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 38612480, mean_episode_return = 43.591, mean_episode_step = 1608.7, total_loss = -94.779, pg_loss = -138.58, baseline_loss = 49.058, entropy_loss = -5.2549, learner_queue_size = 32, _tick = 8615, _time = 1.6548e+09, train_seconds = 1.0277e+04)
[2022-06-09 22:59:21,938][root][INFO] - Step 38630400 @ 3581.1 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 38630400, mean_episode_return = 157.29, mean_episode_step = 1650.6, total_loss = -70.519, pg_loss = -82.592, baseline_loss = 16.716, entropy_loss = -4.643, learner_queue_size = 32, _tick = 8621, _time = 1.6548e+09, train_seconds = 1.0282e+04)
[2022-06-09 22:59:26,942][root][INFO] - Step 38650880 @ 4092.8 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 38650880, mean_episode_return = 71.61, mean_episode_step = 1285.1, total_loss = 181.9, pg_loss = 116.78, baseline_loss = 69.981, entropy_loss = -4.8613, learner_queue_size = 32, _tick = 8627, _time = 1.6548e+09, train_seconds = 1.0287e+04)
[2022-06-09 22:59:31,946][root][INFO] - Step 38668800 @ 3581.1 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (step = 38668800, mean_episode_return = 34.104, mean_episode_step = 1129.2, total_loss = 68.268, pg_loss = 9.615, baseline_loss = 63.65, entropy_loss = -4.9975, learner_queue_size = 32, _tick = 8630, _time = 1.6548e+09, train_seconds = 1.0292e+04)
[2022-06-09 22:59:36,950][root][INFO] - Step 38689280 @ 4092.7 SPS. Inference batcher size: 73. Learner queue size: 32. Other stats: (step = 38689280, mean_episode_return = 52.27, mean_episode_step = 1412.6, total_loss = -63.614, pg_loss = -98.089, baseline_loss = 39.697, entropy_loss = -5.2217, learner_queue_size = 32, _tick = 8635, _time = 1.6548e+09, train_seconds = 1.0297e+04)
[2022-06-09 22:59:41,954][root][INFO] - Step 38707200 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 38707200, mean_episode_return = 51.775, mean_episode_step = 1285.8, total_loss = 17.146, pg_loss = -11.085, baseline_loss = 33.557, entropy_loss = -5.3261, learner_queue_size = 32, _tick = 8642, _time = 1.6548e+09, train_seconds = 1.0302e+04)
[2022-06-09 22:59:46,958][root][INFO] - Step 38727680 @ 4092.7 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 38727680, mean_episode_return = 3.5497, mean_episode_step = 1585.7, total_loss = 108.0, pg_loss = 61.281, baseline_loss = 52.092, entropy_loss = -5.3763, learner_queue_size = 32, _tick = 8650, _time = 1.6548e+09, train_seconds = 1.0307e+04)
[2022-06-09 22:59:51,962][root][INFO] - Step 38745600 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 38745600, mean_episode_return = 71.634, mean_episode_step = 1066.5, total_loss = 570.11, pg_loss = 440.77, baseline_loss = 134.47, entropy_loss = -5.1348, learner_queue_size = 32, _tick = 8656, _time = 1.6548e+09, train_seconds = 1.0312e+04)
[2022-06-09 22:59:56,966][root][INFO] - Step 38763520 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 38763520, mean_episode_return = 15.473, mean_episode_step = 1193.2, total_loss = 117.41, pg_loss = 55.495, baseline_loss = 67.043, entropy_loss = -5.1289, learner_queue_size = 32, _tick = 8663, _time = 1.6548e+09, train_seconds = 1.0317e+04)
[2022-06-09 23:00:01,971][root][INFO] - Step 38784000 @ 4091.9 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 38784000, mean_episode_return = 47.811, mean_episode_step = 928.66, total_loss = 70.579, pg_loss = 23.989, baseline_loss = 51.896, entropy_loss = -5.3053, learner_queue_size = 32, _tick = 8671, _time = 1.6548e+09, train_seconds = 1.0322e+04)
[2022-06-09 23:00:06,974][root][INFO] - Step 38801920 @ 3581.8 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 38801920, mean_episode_return = 30.133, mean_episode_step = 1096.7, total_loss = 132.21, pg_loss = 74.956, baseline_loss = 62.202, entropy_loss = -4.9522, learner_queue_size = 32, _tick = 8677, _time = 1.6548e+09, train_seconds = 1.0327e+04)
[2022-06-09 23:00:11,978][root][INFO] - Step 38822400 @ 4092.4 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 38822400, mean_episode_return = 88.964, mean_episode_step = 1261.5, total_loss = -108.87, pg_loss = -146.23, baseline_loss = 42.243, entropy_loss = -4.8774, learner_queue_size = 32, _tick = 8681, _time = 1.6548e+09, train_seconds = 1.0332e+04)
[2022-06-09 23:00:16,982][root][INFO] - Step 38840320 @ 3581.3 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 38840320, mean_episode_return = None, mean_episode_step = 1194.7, total_loss = 79.333, pg_loss = 52.969, baseline_loss = 31.712, entropy_loss = -5.3476, learner_queue_size = 32, _tick = 8686, _time = 1.6548e+09, train_seconds = 1.0337e+04)
[2022-06-09 23:00:21,986][root][INFO] - Step 38860800 @ 4092.9 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 38860800, mean_episode_return = 27.585, mean_episode_step = 1159.7, total_loss = 140.25, pg_loss = 82.582, baseline_loss = 63.139, entropy_loss = -5.476, learner_queue_size = 32, _tick = 8692, _time = 1.6548e+09, train_seconds = 1.0342e+04)
[2022-06-09 23:00:26,990][root][INFO] - Step 38878720 @ 3581.1 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 38878720, mean_episode_return = 144.81, mean_episode_step = 1011.3, total_loss = -28.295, pg_loss = -93.732, baseline_loss = 70.735, entropy_loss = -5.2984, learner_queue_size = 32, _tick = 8699, _time = 1.6548e+09, train_seconds = 1.0347e+04)
[2022-06-09 23:00:31,994][root][INFO] - Step 38899200 @ 4092.7 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 38899200, mean_episode_return = None, mean_episode_step = 999.59, total_loss = 348.7, pg_loss = 289.25, baseline_loss = 64.603, entropy_loss = -5.1596, learner_queue_size = 32, _tick = 8704, _time = 1.6548e+09, train_seconds = 1.0352e+04)
[2022-06-09 23:00:36,998][root][INFO] - Step 38917120 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 38917120, mean_episode_return = 64.706, mean_episode_step = 1027.0, total_loss = 184.72, pg_loss = 63.595, baseline_loss = 126.38, entropy_loss = -5.2562, learner_queue_size = 32, _tick = 8709, _time = 1.6548e+09, train_seconds = 1.0357e+04)
[2022-06-09 23:00:42,002][root][INFO] - Step 38935040 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 38935040, mean_episode_return = 36.6, mean_episode_step = 1086.5, total_loss = -212.61, pg_loss = -227.03, baseline_loss = 19.745, entropy_loss = -5.3247, learner_queue_size = 32, _tick = 8715, _time = 1.6548e+09, train_seconds = 1.0362e+04)
[2022-06-09 23:00:47,006][root][INFO] - Step 38955520 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 38955520, mean_episode_return = 25.955, mean_episode_step = 1072.3, total_loss = 65.069, pg_loss = 29.375, baseline_loss = 41.267, entropy_loss = -5.5732, learner_queue_size = 32, _tick = 8723, _time = 1.6548e+09, train_seconds = 1.0367e+04)
[2022-06-09 23:00:52,010][root][INFO] - Step 38973440 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 38973440, mean_episode_return = 41.03, mean_episode_step = 1046.4, total_loss = 180.8, pg_loss = 94.522, baseline_loss = 91.74, entropy_loss = -5.4603, learner_queue_size = 32, _tick = 8730, _time = 1.6548e+09, train_seconds = 1.0372e+04)
[2022-06-09 23:00:57,015][root][INFO] - Step 38993920 @ 4091.8 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (step = 38993920, mean_episode_return = 183.02, mean_episode_step = 1199.1, total_loss = 337.04, pg_loss = 234.51, baseline_loss = 107.94, entropy_loss = -5.4022, learner_queue_size = 32, _tick = 8735, _time = 1.6548e+09, train_seconds = 1.0377e+04)
[2022-06-09 23:01:02,018][root][INFO] - Step 39011840 @ 3581.9 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 39011840, mean_episode_return = 53.99, mean_episode_step = 1167.7, total_loss = 465.31, pg_loss = 245.49, baseline_loss = 224.91, entropy_loss = -5.0928, learner_queue_size = 32, _tick = 8742, _time = 1.6548e+09, train_seconds = 1.0382e+04)
[2022-06-09 23:01:07,022][root][INFO] - Step 39032320 @ 4092.7 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (step = 39032320, mean_episode_return = None, mean_episode_step = 1584.0, total_loss = -132.67, pg_loss = -151.55, baseline_loss = 23.899, entropy_loss = -5.0194, learner_queue_size = 32, _tick = 8746, _time = 1.6548e+09, train_seconds = 1.0387e+04)
[2022-06-09 23:01:12,026][root][INFO] - Step 39050240 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 39050240, mean_episode_return = 75.08, mean_episode_step = 1131.6, total_loss = 323.35, pg_loss = 225.36, baseline_loss = 103.3, entropy_loss = -5.3051, learner_queue_size = 32, _tick = 8750, _time = 1.6548e+09, train_seconds = 1.0392e+04)
[2022-06-09 23:01:17,030][root][INFO] - Step 39068160 @ 3581.2 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 39068160, mean_episode_return = 41.456, mean_episode_step = 1097.2, total_loss = 652.61, pg_loss = 463.72, baseline_loss = 194.36, entropy_loss = -5.4764, learner_queue_size = 32, _tick = 8755, _time = 1.6548e+09, train_seconds = 1.0397e+04)
[2022-06-09 23:01:22,034][root][INFO] - Step 39086080 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 39086080, mean_episode_return = 33.71, mean_episode_step = 1587.0, total_loss = 161.23, pg_loss = 102.87, baseline_loss = 63.461, entropy_loss = -5.1017, learner_queue_size = 32, _tick = 8760, _time = 1.6548e+09, train_seconds = 1.0402e+04)
[2022-06-09 23:01:27,038][root][INFO] - Step 39106560 @ 4092.7 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (step = 39106560, mean_episode_return = 50.64, mean_episode_step = 1330.6, total_loss = 251.44, pg_loss = 87.553, baseline_loss = 168.78, entropy_loss = -4.888, learner_queue_size = 32, _tick = 8766, _time = 1.6548e+09, train_seconds = 1.0407e+04)
[2022-06-09 23:01:32,042][root][INFO] - Step 39124480 @ 3581.2 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 39124480, mean_episode_return = 35.565, mean_episode_step = 941.65, total_loss = -54.81, pg_loss = -92.22, baseline_loss = 42.803, entropy_loss = -5.3935, learner_queue_size = 32, _tick = 8771, _time = 1.6548e+09, train_seconds = 1.0412e+04)
[2022-06-09 23:01:37,046][root][INFO] - Step 39144960 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 39144960, mean_episode_return = 172.4, mean_episode_step = 1185.6, total_loss = -90.211, pg_loss = -113.24, baseline_loss = 28.557, entropy_loss = -5.5269, learner_queue_size = 32, _tick = 8777, _time = 1.6548e+09, train_seconds = 1.0417e+04)
[2022-06-09 23:01:42,050][root][INFO] - Step 39162880 @ 3581.2 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 39162880, mean_episode_return = 33.88, mean_episode_step = 1179.7, total_loss = 77.306, pg_loss = -7.3343, baseline_loss = 90.168, entropy_loss = -5.5273, learner_queue_size = 32, _tick = 8783, _time = 1.6548e+09, train_seconds = 1.0422e+04)
[2022-06-09 23:01:47,054][root][INFO] - Step 39180800 @ 3581.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 39180800, mean_episode_return = None, mean_episode_step = 1504.7, total_loss = -32.493, pg_loss = -60.407, baseline_loss = 33.321, entropy_loss = -5.4073, learner_queue_size = 32, _tick = 8788, _time = 1.6548e+09, train_seconds = 1.0427e+04)
[2022-06-09 23:01:52,059][root][INFO] - Step 39198720 @ 3580.6 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 39198720, mean_episode_return = 43.507, mean_episode_step = 808.15, total_loss = -28.464, pg_loss = -105.23, baseline_loss = 82.086, entropy_loss = -5.3247, learner_queue_size = 32, _tick = 8792, _time = 1.6548e+09, train_seconds = 1.0432e+04)
[2022-06-09 23:01:57,062][root][INFO] - Step 39219200 @ 4093.3 SPS. Inference batcher size: 76. Learner queue size: 32. Other stats: (step = 39219200, mean_episode_return = 16.78, mean_episode_step = 1293.6, total_loss = -10.623, pg_loss = -69.493, baseline_loss = 64.372, entropy_loss = -5.5013, learner_queue_size = 32, _tick = 8798, _time = 1.6548e+09, train_seconds = 1.0437e+04)
[2022-06-09 23:02:02,066][root][INFO] - Step 39237120 @ 3581.0 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 39237120, mean_episode_return = 51.519, mean_episode_step = 1387.1, total_loss = -123.88, pg_loss = -138.76, baseline_loss = 20.371, entropy_loss = -5.4958, learner_queue_size = 32, _tick = 8803, _time = 1.6548e+09, train_seconds = 1.0442e+04)
[2022-06-09 23:02:07,070][root][INFO] - Step 39255040 @ 3581.2 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (step = 39255040, mean_episode_return = 54.389, mean_episode_step = 1681.7, total_loss = -129.15, pg_loss = -166.73, baseline_loss = 42.601, entropy_loss = -5.0251, learner_queue_size = 32, _tick = 8808, _time = 1.6548e+09, train_seconds = 1.0447e+04)
[2022-06-09 23:02:12,074][root][INFO] - Step 39275520 @ 4092.7 SPS. Inference batcher size: 87. Learner queue size: 32. Other stats: (step = 39275520, mean_episode_return = 86.38, mean_episode_step = 1091.5, total_loss = 321.45, pg_loss = 207.32, baseline_loss = 119.05, entropy_loss = -4.9166, learner_queue_size = 32, _tick = 8816, _time = 1.6548e+09, train_seconds = 1.0452e+04)
[2022-06-09 23:02:17,078][root][INFO] - Step 39293440 @ 3581.1 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 39293440, mean_episode_return = 65.585, mean_episode_step = 1737.5, total_loss = -87.201, pg_loss = -116.37, baseline_loss = 34.362, entropy_loss = -5.195, learner_queue_size = 32, _tick = 8822, _time = 1.6548e+09, train_seconds = 1.0457e+04)
[2022-06-09 23:02:22,082][root][INFO] - Step 39311360 @ 3581.2 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 39311360, mean_episode_return = None, mean_episode_step = 1177.7, total_loss = 238.5, pg_loss = 185.51, baseline_loss = 58.483, entropy_loss = -5.4933, learner_queue_size = 32, _tick = 8828, _time = 1.6548e+09, train_seconds = 1.0462e+04)
[2022-06-09 23:02:27,086][root][INFO] - Step 39331840 @ 4092.7 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 39331840, mean_episode_return = 55.319, mean_episode_step = 923.58, total_loss = -88.367, pg_loss = -152.87, baseline_loss = 69.775, entropy_loss = -5.2702, learner_queue_size = 32, _tick = 8834, _time = 1.6548e+09, train_seconds = 1.0467e+04)
[2022-06-09 23:02:32,090][root][INFO] - Step 39349760 @ 3581.2 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 39349760, mean_episode_return = None, mean_episode_step = 1328.8, total_loss = 249.61, pg_loss = 176.12, baseline_loss = 78.748, entropy_loss = -5.2631, learner_queue_size = 32, _tick = 8839, _time = 1.6548e+09, train_seconds = 1.0472e+04)
[2022-06-09 23:02:37,094][root][INFO] - Step 39367680 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 39367680, mean_episode_return = 18.54, mean_episode_step = 1145.4, total_loss = 60.75, pg_loss = 17.3, baseline_loss = 48.373, entropy_loss = -4.9228, learner_queue_size = 32, _tick = 8845, _time = 1.6548e+09, train_seconds = 1.0477e+04)
[2022-06-09 23:02:42,098][root][INFO] - Step 39388160 @ 4092.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 39388160, mean_episode_return = 69.551, mean_episode_step = 1161.5, total_loss = -14.907, pg_loss = -70.1, baseline_loss = 60.553, entropy_loss = -5.359, learner_queue_size = 32, _tick = 8852, _time = 1.6548e+09, train_seconds = 1.0482e+04)
[2022-06-09 23:02:47,102][root][INFO] - Step 39406080 @ 3581.4 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 39406080, mean_episode_return = 48.832, mean_episode_step = 1590.4, total_loss = 202.17, pg_loss = 106.89, baseline_loss = 100.7, entropy_loss = -5.4212, learner_queue_size = 32, _tick = 8859, _time = 1.6548e+09, train_seconds = 1.0487e+04)
[2022-06-09 23:02:52,106][root][INFO] - Step 39424000 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 39424000, mean_episode_return = 44.637, mean_episode_step = 1272.1, total_loss = 23.405, pg_loss = -3.8757, baseline_loss = 32.855, entropy_loss = -5.5747, learner_queue_size = 32, _tick = 8863, _time = 1.6548e+09, train_seconds = 1.0492e+04)
[2022-06-09 23:02:57,110][root][INFO] - Step 39441920 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 39441920, mean_episode_return = 28.076, mean_episode_step = 886.65, total_loss = 104.4, pg_loss = 65.256, baseline_loss = 44.234, entropy_loss = -5.086, learner_queue_size = 32, _tick = 8867, _time = 1.6548e+09, train_seconds = 1.0497e+04)
[2022-06-09 23:03:02,116][root][INFO] - Step 39459840 @ 3579.7 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (step = 39459840, mean_episode_return = 32.83, mean_episode_step = 1230.2, total_loss = 40.826, pg_loss = -10.298, baseline_loss = 55.841, entropy_loss = -4.7167, learner_queue_size = 32, _tick = 8872, _time = 1.6548e+09, train_seconds = 1.0502e+04)
[2022-06-09 23:03:07,118][root][INFO] - Step 39480320 @ 4094.3 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 39480320, mean_episode_return = None, mean_episode_step = 1165.2, total_loss = 217.55, pg_loss = 172.12, baseline_loss = 50.862, entropy_loss = -5.4323, learner_queue_size = 32, _tick = 8876, _time = 1.6548e+09, train_seconds = 1.0507e+04)
[2022-06-09 23:03:12,122][root][INFO] - Step 39498240 @ 3581.2 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (step = 39498240, mean_episode_return = 70.64, mean_episode_step = 1353.0, total_loss = 88.519, pg_loss = 20.186, baseline_loss = 73.671, entropy_loss = -5.3382, learner_queue_size = 32, _tick = 8881, _time = 1.6548e+09, train_seconds = 1.0512e+04)
[2022-06-09 23:03:17,126][root][INFO] - Step 39518720 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 39518720, mean_episode_return = 114.24, mean_episode_step = 1187.4, total_loss = 276.77, pg_loss = 177.23, baseline_loss = 104.86, entropy_loss = -5.3154, learner_queue_size = 32, _tick = 8888, _time = 1.6548e+09, train_seconds = 1.0517e+04)
[2022-06-09 23:03:22,130][root][INFO] - Step 39536640 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 39536640, mean_episode_return = 107.13, mean_episode_step = 1386.5, total_loss = -135.75, pg_loss = -145.01, baseline_loss = 14.794, entropy_loss = -5.5329, learner_queue_size = 32, _tick = 8891, _time = 1.6548e+09, train_seconds = 1.0522e+04)
[2022-06-09 23:03:27,134][root][INFO] - Step 39554560 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 39554560, mean_episode_return = 93.586, mean_episode_step = 1366.0, total_loss = 226.91, pg_loss = 112.58, baseline_loss = 119.78, entropy_loss = -5.4447, learner_queue_size = 32, _tick = 8896, _time = 1.6548e+09, train_seconds = 1.0527e+04)
[2022-06-09 23:03:32,138][root][INFO] - Step 39572480 @ 3581.1 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 39572480, mean_episode_return = 78.481, mean_episode_step = 1321.7, total_loss = 63.795, pg_loss = 33.533, baseline_loss = 35.505, entropy_loss = -5.243, learner_queue_size = 32, _tick = 8903, _time = 1.6548e+09, train_seconds = 1.0532e+04)
[2022-06-09 23:03:37,142][root][INFO] - Step 39590400 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 39590400, mean_episode_return = 6.6997, mean_episode_step = 1216.6, total_loss = -10.57, pg_loss = -47.154, baseline_loss = 41.552, entropy_loss = -4.9687, learner_queue_size = 32, _tick = 8910, _time = 1.6548e+09, train_seconds = 1.0537e+04)
[2022-06-09 23:03:42,146][root][INFO] - Step 39610880 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 39610880, mean_episode_return = None, mean_episode_step = 1154.6, total_loss = 128.41, pg_loss = 80.67, baseline_loss = 52.512, entropy_loss = -4.7739, learner_queue_size = 32, _tick = 8915, _time = 1.6548e+09, train_seconds = 1.0542e+04)
[2022-06-09 23:03:47,150][root][INFO] - Step 39628800 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 39628800, mean_episode_return = 28.395, mean_episode_step = 1342.8, total_loss = -79.225, pg_loss = -166.91, baseline_loss = 92.541, entropy_loss = -4.8557, learner_queue_size = 32, _tick = 8921, _time = 1.6548e+09, train_seconds = 1.0547e+04)
[2022-06-09 23:03:52,154][root][INFO] - Step 39649280 @ 4092.5 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 39649280, mean_episode_return = 47.641, mean_episode_step = 1277.8, total_loss = 31.258, pg_loss = 1.7528, baseline_loss = 34.831, entropy_loss = -5.3255, learner_queue_size = 32, _tick = 8928, _time = 1.6548e+09, train_seconds = 1.0552e+04)
[2022-06-09 23:03:57,158][root][INFO] - Step 39667200 @ 3581.2 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 39667200, mean_episode_return = 51.441, mean_episode_step = 1557.1, total_loss = 21.953, pg_loss = -2.7998, baseline_loss = 29.959, entropy_loss = -5.2061, learner_queue_size = 32, _tick = 8935, _time = 1.6548e+09, train_seconds = 1.0557e+04)
[2022-06-09 23:04:02,162][root][INFO] - Step 39685120 @ 3581.3 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 39685120, mean_episode_return = 31.105, mean_episode_step = 1371.1, total_loss = -67.123, pg_loss = -126.19, baseline_loss = 64.117, entropy_loss = -5.0503, learner_queue_size = 32, _tick = 8940, _time = 1.6548e+09, train_seconds = 1.0562e+04)
[2022-06-09 23:04:07,166][root][INFO] - Step 39705600 @ 4092.7 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (step = 39705600, mean_episode_return = None, mean_episode_step = 1055.0, total_loss = -2.7401, pg_loss = -27.028, baseline_loss = 29.686, entropy_loss = -5.3987, learner_queue_size = 32, _tick = 8946, _time = 1.6548e+09, train_seconds = 1.0567e+04)
[2022-06-09 23:04:12,170][root][INFO] - Step 39723520 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 39723520, mean_episode_return = 17.88, mean_episode_step = 1320.1, total_loss = -86.22, pg_loss = -143.38, baseline_loss = 62.271, entropy_loss = -5.1099, learner_queue_size = 32, _tick = 8951, _time = 1.6548e+09, train_seconds = 1.0572e+04)
[2022-06-09 23:04:17,174][root][INFO] - Step 39744000 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 39744000, mean_episode_return = 102.15, mean_episode_step = 1096.0, total_loss = 94.723, pg_loss = -34.779, baseline_loss = 134.63, entropy_loss = -5.1257, learner_queue_size = 32, _tick = 8958, _time = 1.6548e+09, train_seconds = 1.0577e+04)
[2022-06-09 23:04:22,178][root][INFO] - Step 39761920 @ 3581.1 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 39761920, mean_episode_return = None, mean_episode_step = 1302.6, total_loss = 189.73, pg_loss = 114.66, baseline_loss = 80.267, entropy_loss = -5.2014, learner_queue_size = 32, _tick = 8960, _time = 1.6548e+09, train_seconds = 1.0582e+04)
[2022-06-09 23:04:27,182][root][INFO] - Step 39782400 @ 4092.7 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (step = 39782400, mean_episode_return = 56.885, mean_episode_step = 1744.8, total_loss = -68.612, pg_loss = -101.47, baseline_loss = 37.988, entropy_loss = -5.1333, learner_queue_size = 32, _tick = 8966, _time = 1.6548e+09, train_seconds = 1.0587e+04)
[2022-06-09 23:04:32,186][root][INFO] - Step 39800320 @ 3581.1 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 39800320, mean_episode_return = 109.17, mean_episode_step = 1002.2, total_loss = 70.121, pg_loss = -23.004, baseline_loss = 98.342, entropy_loss = -5.2176, learner_queue_size = 32, _tick = 8971, _time = 1.6548e+09, train_seconds = 1.0592e+04)
[2022-06-09 23:04:37,190][root][INFO] - Step 39818240 @ 3581.2 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 39818240, mean_episode_return = 43.64, mean_episode_step = 1051.8, total_loss = -142.04, pg_loss = -163.31, baseline_loss = 26.517, entropy_loss = -5.2439, learner_queue_size = 32, _tick = 8976, _time = 1.6548e+09, train_seconds = 1.0597e+04)
[2022-06-09 23:04:42,194][root][INFO] - Step 39836160 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 39836160, mean_episode_return = 103.57, mean_episode_step = 930.63, total_loss = 53.901, pg_loss = 8.0022, baseline_loss = 51.31, entropy_loss = -5.4112, learner_queue_size = 32, _tick = 8980, _time = 1.6548e+09, train_seconds = 1.0602e+04)
[2022-06-09 23:04:47,198][root][INFO] - Step 39856640 @ 4092.8 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 39856640, mean_episode_return = 28.915, mean_episode_step = 1037.8, total_loss = 145.4, pg_loss = 88.554, baseline_loss = 62.166, entropy_loss = -5.3182, learner_queue_size = 32, _tick = 8986, _time = 1.6548e+09, train_seconds = 1.0607e+04)
[2022-06-09 23:04:52,202][root][INFO] - Step 39874560 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 39874560, mean_episode_return = 65.784, mean_episode_step = 900.81, total_loss = -31.844, pg_loss = -64.984, baseline_loss = 38.468, entropy_loss = -5.328, learner_queue_size = 32, _tick = 8993, _time = 1.6548e+09, train_seconds = 1.0612e+04)
[2022-06-09 23:04:57,206][root][INFO] - Step 39892480 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 39892480, mean_episode_return = 53.541, mean_episode_step = 1167.9, total_loss = 76.241, pg_loss = 35.123, baseline_loss = 46.396, entropy_loss = -5.278, learner_queue_size = 32, _tick = 8999, _time = 1.6548e+09, train_seconds = 1.0617e+04)
[2022-06-09 23:05:02,210][root][INFO] - Step 39910400 @ 3581.2 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 39910400, mean_episode_return = 259.52, mean_episode_step = 1239.4, total_loss = -18.292, pg_loss = -65.415, baseline_loss = 52.416, entropy_loss = -5.2929, learner_queue_size = 32, _tick = 9006, _time = 1.6548e+09, train_seconds = 1.0622e+04)
[2022-06-09 23:05:07,214][root][INFO] - Step 39930880 @ 4092.8 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 39930880, mean_episode_return = 29.7, mean_episode_step = 1420.9, total_loss = -107.15, pg_loss = -173.93, baseline_loss = 71.923, entropy_loss = -5.1417, learner_queue_size = 32, _tick = 9012, _time = 1.6548e+09, train_seconds = 1.0627e+04)
[2022-06-09 23:05:12,218][root][INFO] - Step 39948800 @ 3581.1 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (step = 39948800, mean_episode_return = None, mean_episode_step = 932.38, total_loss = 90.977, pg_loss = 55.569, baseline_loss = 40.699, entropy_loss = -5.2904, learner_queue_size = 32, _tick = 9017, _time = 1.6548e+09, train_seconds = 1.0632e+04)
[2022-06-09 23:05:17,222][root][INFO] - Step 39966720 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 39966720, mean_episode_return = 113.67, mean_episode_step = 1103.8, total_loss = 51.428, pg_loss = 3.798, baseline_loss = 52.958, entropy_loss = -5.3282, learner_queue_size = 32, _tick = 9022, _time = 1.6548e+09, train_seconds = 1.0637e+04)
[2022-06-09 23:05:22,226][root][INFO] - Step 39987200 @ 4092.7 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 39987200, mean_episode_return = 64.996, mean_episode_step = 1033.5, total_loss = 215.7, pg_loss = 140.96, baseline_loss = 80.093, entropy_loss = -5.3541, learner_queue_size = 32, _tick = 9030, _time = 1.6548e+09, train_seconds = 1.0642e+04)
[2022-06-09 23:05:27,230][root][INFO] - Step 40005120 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 40005120, mean_episode_return = 80.581, mean_episode_step = 1003.5, total_loss = 116.39, pg_loss = 18.953, baseline_loss = 102.69, entropy_loss = -5.2492, learner_queue_size = 32, _tick = 9036, _time = 1.6548e+09, train_seconds = 1.0647e+04)
[2022-06-09 23:05:32,234][root][INFO] - Step 40023040 @ 3581.1 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 40023040, mean_episode_return = None, mean_episode_step = 1214.3, total_loss = 49.258, pg_loss = 8.9783, baseline_loss = 45.608, entropy_loss = -5.3286, learner_queue_size = 32, _tick = 9042, _time = 1.6548e+09, train_seconds = 1.0652e+04)
[2022-06-09 23:05:37,240][root][INFO] - Step 40040960 @ 3579.6 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 40040960, mean_episode_return = 26.265, mean_episode_step = 1104.8, total_loss = -113.04, pg_loss = -128.32, baseline_loss = 20.738, entropy_loss = -5.4617, learner_queue_size = 32, _tick = 9047, _time = 1.6548e+09, train_seconds = 1.0657e+04)
[2022-06-09 23:05:42,246][root][INFO] - Step 40061440 @ 4091.2 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 40061440, mean_episode_return = 75.066, mean_episode_step = 1017.2, total_loss = -130.21, pg_loss = -167.48, baseline_loss = 42.667, entropy_loss = -5.4041, learner_queue_size = 32, _tick = 9052, _time = 1.6548e+09, train_seconds = 1.0662e+04)
[2022-06-09 23:05:47,250][root][INFO] - Step 40079360 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 40079360, mean_episode_return = 73.681, mean_episode_step = 1708.2, total_loss = 296.11, pg_loss = 230.19, baseline_loss = 71.455, entropy_loss = -5.5406, learner_queue_size = 32, _tick = 9055, _time = 1.6548e+09, train_seconds = 1.0667e+04)
[2022-06-09 23:05:52,254][root][INFO] - Step 40097280 @ 3581.2 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 40097280, mean_episode_return = 49.631, mean_episode_step = 1621.3, total_loss = 416.76, pg_loss = 315.09, baseline_loss = 107.2, entropy_loss = -5.5277, learner_queue_size = 32, _tick = 9060, _time = 1.6548e+09, train_seconds = 1.0672e+04)
[2022-06-09 23:05:57,258][root][INFO] - Step 40117760 @ 4092.7 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 40117760, mean_episode_return = 57.4, mean_episode_step = 1151.6, total_loss = -88.744, pg_loss = -116.12, baseline_loss = 32.755, entropy_loss = -5.3749, learner_queue_size = 32, _tick = 9066, _time = 1.6548e+09, train_seconds = 1.0677e+04)
[2022-06-09 23:06:02,262][root][INFO] - Step 40135680 @ 3581.1 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 40135680, mean_episode_return = -9.4401, mean_episode_step = 1654.8, total_loss = -75.196, pg_loss = -104.18, baseline_loss = 34.376, entropy_loss = -5.3913, learner_queue_size = 32, _tick = 9072, _time = 1.6548e+09, train_seconds = 1.0682e+04)
[2022-06-09 23:06:07,266][root][INFO] - Step 40153600 @ 3581.2 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 40153600, mean_episode_return = 10.58, mean_episode_step = 1410.0, total_loss = 641.72, pg_loss = 482.6, baseline_loss = 164.73, entropy_loss = -5.6174, learner_queue_size = 32, _tick = 9079, _time = 1.6548e+09, train_seconds = 1.0687e+04)
[2022-06-09 23:06:12,270][root][INFO] - Step 40174080 @ 4092.7 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 40174080, mean_episode_return = 72.599, mean_episode_step = 1168.8, total_loss = 78.595, pg_loss = 8.6378, baseline_loss = 75.497, entropy_loss = -5.5398, learner_queue_size = 32, _tick = 9086, _time = 1.6548e+09, train_seconds = 1.0692e+04)
[2022-06-09 23:06:17,274][root][INFO] - Step 40192000 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 40192000, mean_episode_return = 128.49, mean_episode_step = 1306.2, total_loss = -12.952, pg_loss = -55.123, baseline_loss = 47.729, entropy_loss = -5.5581, learner_queue_size = 32, _tick = 9090, _time = 1.6548e+09, train_seconds = 1.0697e+04)
[2022-06-09 23:06:22,278][root][INFO] - Step 40209920 @ 3581.0 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 40209920, mean_episode_return = None, mean_episode_step = 1827.2, total_loss = 236.76, pg_loss = 160.12, baseline_loss = 82.164, entropy_loss = -5.5195, learner_queue_size = 32, _tick = 9096, _time = 1.6548e+09, train_seconds = 1.0702e+04)
[2022-06-09 23:06:27,282][root][INFO] - Step 40230400 @ 4092.9 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 40230400, mean_episode_return = 23.063, mean_episode_step = 1019.5, total_loss = -35.655, pg_loss = -83.452, baseline_loss = 53.189, entropy_loss = -5.392, learner_queue_size = 32, _tick = 9102, _time = 1.6548e+09, train_seconds = 1.0707e+04)
[2022-06-09 23:06:32,286][root][INFO] - Step 40248320 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 40248320, mean_episode_return = 7.005, mean_episode_step = 1543.9, total_loss = -153.64, pg_loss = -201.95, baseline_loss = 53.578, entropy_loss = -5.2656, learner_queue_size = 32, _tick = 9107, _time = 1.6548e+09, train_seconds = 1.0712e+04)
[2022-06-09 23:06:37,290][root][INFO] - Step 40268800 @ 4092.7 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 40268800, mean_episode_return = None, mean_episode_step = 1061.3, total_loss = -83.317, pg_loss = -113.27, baseline_loss = 35.333, entropy_loss = -5.377, learner_queue_size = 32, _tick = 9113, _time = 1.6548e+09, train_seconds = 1.0717e+04)
[2022-06-09 23:06:42,294][root][INFO] - Step 40286720 @ 3580.8 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 40286720, mean_episode_return = 16.91, mean_episode_step = 1117.2, total_loss = -76.206, pg_loss = -92.941, baseline_loss = 22.231, entropy_loss = -5.4965, learner_queue_size = 32, _tick = 9120, _time = 1.6548e+09, train_seconds = 1.0722e+04)
[2022-06-09 23:06:47,298][root][INFO] - Step 40304640 @ 3581.4 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 40304640, mean_episode_return = 51.863, mean_episode_step = 1439.6, total_loss = 57.112, pg_loss = 14.932, baseline_loss = 47.426, entropy_loss = -5.2466, learner_queue_size = 32, _tick = 9126, _time = 1.6548e+09, train_seconds = 1.0727e+04)
[2022-06-09 23:06:52,302][root][INFO] - Step 40325120 @ 4092.7 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 40325120, mean_episode_return = 19.715, mean_episode_step = 1130.8, total_loss = -10.856, pg_loss = -70.41, baseline_loss = 64.559, entropy_loss = -5.0051, learner_queue_size = 32, _tick = 9133, _time = 1.6548e+09, train_seconds = 1.0732e+04)
[2022-06-09 23:06:57,306][root][INFO] - Step 40343040 @ 3581.2 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 40343040, mean_episode_return = 43.871, mean_episode_step = 1165.9, total_loss = 97.519, pg_loss = 42.648, baseline_loss = 59.174, entropy_loss = -4.3029, learner_queue_size = 32, _tick = 9138, _time = 1.6548e+09, train_seconds = 1.0737e+04)
[2022-06-09 23:07:02,310][root][INFO] - Step 40363520 @ 4092.7 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 40363520, mean_episode_return = 80.25, mean_episode_step = 807.31, total_loss = -44.011, pg_loss = -70.213, baseline_loss = 30.979, entropy_loss = -4.7766, learner_queue_size = 32, _tick = 9146, _time = 1.6548e+09, train_seconds = 1.0742e+04)
[2022-06-09 23:07:07,314][root][INFO] - Step 40381440 @ 3581.1 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 40381440, mean_episode_return = None, mean_episode_step = 1381.7, total_loss = -59.562, pg_loss = -64.03, baseline_loss = 10.011, entropy_loss = -5.5429, learner_queue_size = 32, _tick = 9151, _time = 1.6548e+09, train_seconds = 1.0747e+04)
[2022-06-09 23:07:12,318][root][INFO] - Step 40399360 @ 3581.2 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 40399360, mean_episode_return = 34.83, mean_episode_step = 862.23, total_loss = 197.13, pg_loss = 137.77, baseline_loss = 64.961, entropy_loss = -5.6025, learner_queue_size = 32, _tick = 9157, _time = 1.6548e+09, train_seconds = 1.0752e+04)
[2022-06-09 23:07:17,322][root][INFO] - Step 40417280 @ 3581.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 40417280, mean_episode_return = 29.23, mean_episode_step = 993.22, total_loss = 352.27, pg_loss = 222.0, baseline_loss = 135.69, entropy_loss = -5.4165, learner_queue_size = 32, _tick = 9163, _time = 1.6548e+09, train_seconds = 1.0757e+04)
[2022-06-09 23:07:22,326][root][INFO] - Step 40437760 @ 4092.7 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 40437760, mean_episode_return = 72.499, mean_episode_step = 1069.6, total_loss = 167.97, pg_loss = 72.721, baseline_loss = 100.75, entropy_loss = -5.5057, learner_queue_size = 32, _tick = 9168, _time = 1.6548e+09, train_seconds = 1.0762e+04)
[2022-06-09 23:07:27,330][root][INFO] - Step 40455680 @ 3581.1 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 40455680, mean_episode_return = -13.73, mean_episode_step = 1166.1, total_loss = 102.65, pg_loss = 12.456, baseline_loss = 95.712, entropy_loss = -5.5224, learner_queue_size = 32, _tick = 9174, _time = 1.6548e+09, train_seconds = 1.0767e+04)
[2022-06-09 23:07:32,336][root][INFO] - Step 40473600 @ 3579.5 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 40473600, mean_episode_return = -4.0601, mean_episode_step = 1389.9, total_loss = -62.611, pg_loss = -80.967, baseline_loss = 23.901, entropy_loss = -5.5462, learner_queue_size = 32, _tick = 9180, _time = 1.6548e+09, train_seconds = 1.0772e+04)
[2022-06-09 23:07:37,342][root][INFO] - Step 40491520 @ 3580.0 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 40491520, mean_episode_return = 26.28, mean_episode_step = 1340.9, total_loss = 137.92, pg_loss = 57.026, baseline_loss = 86.413, entropy_loss = -5.5159, learner_queue_size = 32, _tick = 9187, _time = 1.6548e+09, train_seconds = 1.0777e+04)
[2022-06-09 23:07:42,347][root][INFO] - Step 40512000 @ 4092.7 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 40512000, mean_episode_return = 15.355, mean_episode_step = 1034.0, total_loss = -48.51, pg_loss = -79.862, baseline_loss = 36.824, entropy_loss = -5.4719, learner_queue_size = 32, _tick = 9194, _time = 1.6548e+09, train_seconds = 1.0782e+04)
[2022-06-09 23:07:47,350][root][INFO] - Step 40529920 @ 3581.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 40529920, mean_episode_return = 65.283, mean_episode_step = 1347.4, total_loss = 195.99, pg_loss = 138.26, baseline_loss = 63.312, entropy_loss = -5.5815, learner_queue_size = 32, _tick = 9200, _time = 1.6548e+09, train_seconds = 1.0787e+04)
[2022-06-09 23:07:52,354][root][INFO] - Step 40547840 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 40547840, mean_episode_return = 27.58, mean_episode_step = 987.91, total_loss = 196.38, pg_loss = 148.39, baseline_loss = 53.465, entropy_loss = -5.4697, learner_queue_size = 32, _tick = 9205, _time = 1.6548e+09, train_seconds = 1.0792e+04)
[2022-06-09 23:07:57,358][root][INFO] - Step 40568320 @ 4092.6 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 40568320, mean_episode_return = 48.397, mean_episode_step = 1088.9, total_loss = 76.47, pg_loss = -3.5097, baseline_loss = 85.391, entropy_loss = -5.4115, learner_queue_size = 32, _tick = 9212, _time = 1.6548e+09, train_seconds = 1.0797e+04)
[2022-06-09 23:08:02,362][root][INFO] - Step 40586240 @ 3581.2 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 40586240, mean_episode_return = 48.073, mean_episode_step = 1133.4, total_loss = -179.31, pg_loss = -200.0, baseline_loss = 26.138, entropy_loss = -5.4397, learner_queue_size = 32, _tick = 9215, _time = 1.6548e+09, train_seconds = 1.0802e+04)
[2022-06-09 23:08:07,366][root][INFO] - Step 40604160 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 40604160, mean_episode_return = None, mean_episode_step = 1033.1, total_loss = 513.09, pg_loss = 364.16, baseline_loss = 154.25, entropy_loss = -5.3144, learner_queue_size = 32, _tick = 9220, _time = 1.6548e+09, train_seconds = 1.0807e+04)
[2022-06-09 23:08:12,370][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-09 23:08:12,506][root][INFO] - Step 40624640 @ 4092.7 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 40624640, mean_episode_return = 82.09, mean_episode_step = 1633.7, total_loss = -221.38, pg_loss = -262.99, baseline_loss = 46.553, entropy_loss = -4.9467, learner_queue_size = 32, _tick = 9225, _time = 1.6548e+09, train_seconds = 1.0812e+04)
[2022-06-09 23:08:17,510][root][INFO] - Step 40642560 @ 3486.3 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 40642560, mean_episode_return = None, mean_episode_step = 804.31, total_loss = 21.368, pg_loss = -20.494, baseline_loss = 46.554, entropy_loss = -4.6926, learner_queue_size = 32, _tick = 9229, _time = 1.6548e+09, train_seconds = 1.0817e+04)
[2022-06-09 23:08:22,514][root][INFO] - Step 40660480 @ 3581.3 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 40660480, mean_episode_return = 73.431, mean_episode_step = 1410.3, total_loss = 62.931, pg_loss = 17.209, baseline_loss = 51.134, entropy_loss = -5.4121, learner_queue_size = 32, _tick = 9235, _time = 1.6548e+09, train_seconds = 1.0822e+04)
[2022-06-09 23:08:27,518][root][INFO] - Step 40680960 @ 4092.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 40680960, mean_episode_return = 53.57, mean_episode_step = 1294.2, total_loss = 44.29, pg_loss = 13.635, baseline_loss = 36.162, entropy_loss = -5.5072, learner_queue_size = 32, _tick = 9242, _time = 1.6548e+09, train_seconds = 1.0827e+04)
[2022-06-09 23:08:32,522][root][INFO] - Step 40698880 @ 3581.0 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 40698880, mean_episode_return = 35.994, mean_episode_step = 1223.9, total_loss = 97.786, pg_loss = 21.1, baseline_loss = 81.96, entropy_loss = -5.2738, learner_queue_size = 32, _tick = 9248, _time = 1.6548e+09, train_seconds = 1.0832e+04)
[2022-06-09 23:08:37,526][root][INFO] - Step 40716800 @ 3581.2 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 40716800, mean_episode_return = 108.76, mean_episode_step = 1194.7, total_loss = -75.123, pg_loss = -98.943, baseline_loss = 29.246, entropy_loss = -5.4257, learner_queue_size = 32, _tick = 9254, _time = 1.6548e+09, train_seconds = 1.0837e+04)
[2022-06-09 23:08:42,531][root][INFO] - Step 40737280 @ 4092.8 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 40737280, mean_episode_return = 61.14, mean_episode_step = 1002.1, total_loss = 43.0, pg_loss = -11.978, baseline_loss = 60.196, entropy_loss = -5.2178, learner_queue_size = 32, _tick = 9260, _time = 1.6548e+09, train_seconds = 1.0842e+04)
[2022-06-09 23:08:47,534][root][INFO] - Step 40755200 @ 3581.0 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 40755200, mean_episode_return = None, mean_episode_step = 1605.6, total_loss = -1.3822, pg_loss = -31.386, baseline_loss = 35.574, entropy_loss = -5.5703, learner_queue_size = 32, _tick = 9266, _time = 1.6548e+09, train_seconds = 1.0847e+04)
[2022-06-09 23:08:52,538][root][INFO] - Step 40773120 @ 3581.2 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 40773120, mean_episode_return = None, mean_episode_step = 1409.5, total_loss = 108.97, pg_loss = 72.31, baseline_loss = 42.024, entropy_loss = -5.3602, learner_queue_size = 32, _tick = 9272, _time = 1.6548e+09, train_seconds = 1.0852e+04)
[2022-06-09 23:08:57,542][root][INFO] - Step 40791040 @ 3581.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 40791040, mean_episode_return = 34.471, mean_episode_step = 1380.2, total_loss = 100.06, pg_loss = 63.182, baseline_loss = 42.265, entropy_loss = -5.388, learner_queue_size = 32, _tick = 9278, _time = 1.6548e+09, train_seconds = 1.0857e+04)
[2022-06-09 23:09:02,546][root][INFO] - Step 40811520 @ 4092.8 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 40811520, mean_episode_return = 78.865, mean_episode_step = 1189.3, total_loss = 228.61, pg_loss = 167.15, baseline_loss = 66.89, entropy_loss = -5.4399, learner_queue_size = 32, _tick = 9285, _time = 1.6548e+09, train_seconds = 1.0862e+04)
[2022-06-09 23:09:07,550][root][INFO] - Step 40829440 @ 3581.2 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 40829440, mean_episode_return = 50.17, mean_episode_step = 936.26, total_loss = 115.35, pg_loss = 65.415, baseline_loss = 55.228, entropy_loss = -5.2904, learner_queue_size = 32, _tick = 9291, _time = 1.6548e+09, train_seconds = 1.0867e+04)
[2022-06-09 23:09:12,554][root][INFO] - Step 40847360 @ 3581.1 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 40847360, mean_episode_return = None, mean_episode_step = 897.25, total_loss = 466.56, pg_loss = 241.29, baseline_loss = 230.64, entropy_loss = -5.3743, learner_queue_size = 32, _tick = 9297, _time = 1.6548e+09, train_seconds = 1.0872e+04)
[2022-06-09 23:09:17,558][root][INFO] - Step 40867840 @ 4092.8 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 40867840, mean_episode_return = 5.3698, mean_episode_step = 846.03, total_loss = 1.0912, pg_loss = -96.843, baseline_loss = 103.3, entropy_loss = -5.3606, learner_queue_size = 32, _tick = 9303, _time = 1.6548e+09, train_seconds = 1.0877e+04)
[2022-06-09 23:09:22,562][root][INFO] - Step 40885760 @ 3580.9 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 40885760, mean_episode_return = 95.725, mean_episode_step = 861.54, total_loss = -67.439, pg_loss = -103.22, baseline_loss = 40.979, entropy_loss = -5.2011, learner_queue_size = 32, _tick = 9310, _time = 1.6548e+09, train_seconds = 1.0882e+04)
[2022-06-09 23:09:27,567][root][INFO] - Step 40906240 @ 4091.9 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 40906240, mean_episode_return = 42.823, mean_episode_step = 1068.2, total_loss = 99.7, pg_loss = 34.307, baseline_loss = 70.597, entropy_loss = -5.2044, learner_queue_size = 32, _tick = 9317, _time = 1.6548e+09, train_seconds = 1.0887e+04)
[2022-06-09 23:09:32,570][root][INFO] - Step 40924160 @ 3582.1 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 40924160, mean_episode_return = 38.419, mean_episode_step = 975.75, total_loss = -140.27, pg_loss = -197.66, baseline_loss = 62.561, entropy_loss = -5.1762, learner_queue_size = 32, _tick = 9322, _time = 1.6548e+09, train_seconds = 1.0892e+04)
[2022-06-09 23:09:37,574][root][INFO] - Step 40942080 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 40942080, mean_episode_return = None, mean_episode_step = 1425.7, total_loss = -130.58, pg_loss = -158.48, baseline_loss = 33.314, entropy_loss = -5.4127, learner_queue_size = 32, _tick = 9325, _time = 1.6548e+09, train_seconds = 1.0897e+04)
[2022-06-09 23:09:42,578][root][INFO] - Step 40960000 @ 3581.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 40960000, mean_episode_return = 18.77, mean_episode_step = 1073.3, total_loss = 153.09, pg_loss = 93.244, baseline_loss = 65.404, entropy_loss = -5.5622, learner_queue_size = 32, _tick = 9330, _time = 1.6548e+09, train_seconds = 1.0902e+04)
[2022-06-09 23:09:47,582][root][INFO] - Step 40980480 @ 4092.7 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 40980480, mean_episode_return = 66.08, mean_episode_step = 954.83, total_loss = 9.4232, pg_loss = -49.447, baseline_loss = 63.997, entropy_loss = -5.1276, learner_queue_size = 32, _tick = 9338, _time = 1.6548e+09, train_seconds = 1.0907e+04)
[2022-06-09 23:09:52,586][root][INFO] - Step 40998400 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 40998400, mean_episode_return = 52.095, mean_episode_step = 955.81, total_loss = -201.98, pg_loss = -257.89, baseline_loss = 61.348, entropy_loss = -5.4295, learner_queue_size = 32, _tick = 9344, _time = 1.6548e+09, train_seconds = 1.0912e+04)
[2022-06-09 23:09:57,590][root][INFO] - Step 41016320 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 41016320, mean_episode_return = 46.86, mean_episode_step = 988.75, total_loss = -29.302, pg_loss = -82.243, baseline_loss = 58.524, entropy_loss = -5.5835, learner_queue_size = 32, _tick = 9349, _time = 1.6548e+09, train_seconds = 1.0917e+04)
[2022-06-09 23:10:02,594][root][INFO] - Step 41034240 @ 3581.1 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 41034240, mean_episode_return = 55.741, mean_episode_step = 965.27, total_loss = 382.25, pg_loss = 272.65, baseline_loss = 115.24, entropy_loss = -5.6455, learner_queue_size = 32, _tick = 9354, _time = 1.6548e+09, train_seconds = 1.0922e+04)
[2022-06-09 23:10:07,599][root][INFO] - Step 41052160 @ 3580.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 41052160, mean_episode_return = None, mean_episode_step = 1026.2, total_loss = 196.57, pg_loss = 148.73, baseline_loss = 53.283, entropy_loss = -5.4479, learner_queue_size = 32, _tick = 9358, _time = 1.6548e+09, train_seconds = 1.0927e+04)
[2022-06-09 23:10:12,602][root][INFO] - Step 41072640 @ 4094.0 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 41072640, mean_episode_return = 76.229, mean_episode_step = 995.68, total_loss = 277.25, pg_loss = 157.77, baseline_loss = 124.85, entropy_loss = -5.3761, learner_queue_size = 32, _tick = 9365, _time = 1.6548e+09, train_seconds = 1.0932e+04)
[2022-06-09 23:10:17,607][root][INFO] - Step 41090560 @ 3580.2 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 41090560, mean_episode_return = 40.431, mean_episode_step = 940.17, total_loss = 68.816, pg_loss = 35.226, baseline_loss = 38.65, entropy_loss = -5.0595, learner_queue_size = 32, _tick = 9371, _time = 1.6548e+09, train_seconds = 1.0937e+04)
[2022-06-09 23:10:22,614][root][INFO] - Step 41108480 @ 3579.2 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 41108480, mean_episode_return = 126.01, mean_episode_step = 1023.1, total_loss = -15.177, pg_loss = -38.391, baseline_loss = 28.69, entropy_loss = -5.4748, learner_queue_size = 32, _tick = 9378, _time = 1.6548e+09, train_seconds = 1.0942e+04)
[2022-06-09 23:10:27,618][root][INFO] - Step 41128960 @ 4092.7 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 41128960, mean_episode_return = 61.96, mean_episode_step = 1039.2, total_loss = -101.96, pg_loss = -125.26, baseline_loss = 28.857, entropy_loss = -5.5566, learner_queue_size = 32, _tick = 9384, _time = 1.6548e+09, train_seconds = 1.0947e+04)
[2022-06-09 23:10:32,622][root][INFO] - Step 41146880 @ 3581.2 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 41146880, mean_episode_return = 161.43, mean_episode_step = 1116.5, total_loss = -75.317, pg_loss = -112.16, baseline_loss = 42.328, entropy_loss = -5.4834, learner_queue_size = 32, _tick = 9390, _time = 1.6548e+09, train_seconds = 1.0952e+04)
[2022-06-09 23:10:37,626][root][INFO] - Step 41167360 @ 4092.7 SPS. Inference batcher size: 84. Learner queue size: 32. Other stats: (step = 41167360, mean_episode_return = 47.807, mean_episode_step = 1023.4, total_loss = 73.142, pg_loss = -19.783, baseline_loss = 98.467, entropy_loss = -5.5424, learner_queue_size = 32, _tick = 9396, _time = 1.6548e+09, train_seconds = 1.0957e+04)
[2022-06-09 23:10:42,630][root][INFO] - Step 41185280 @ 3581.1 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 41185280, mean_episode_return = None, mean_episode_step = 940.88, total_loss = 152.06, pg_loss = 98.916, baseline_loss = 58.636, entropy_loss = -5.4903, learner_queue_size = 32, _tick = 9400, _time = 1.6548e+09, train_seconds = 1.0962e+04)
[2022-06-09 23:10:47,634][root][INFO] - Step 41203200 @ 3581.2 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 41203200, mean_episode_return = 25.265, mean_episode_step = 1092.2, total_loss = -116.02, pg_loss = -135.5, baseline_loss = 25.086, entropy_loss = -5.6079, learner_queue_size = 32, _tick = 9407, _time = 1.6548e+09, train_seconds = 1.0967e+04)
[2022-06-09 23:10:52,638][root][INFO] - Step 41221120 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 41221120, mean_episode_return = 84.719, mean_episode_step = 886.22, total_loss = 154.38, pg_loss = 56.207, baseline_loss = 103.73, entropy_loss = -5.5591, learner_queue_size = 32, _tick = 9413, _time = 1.6548e+09, train_seconds = 1.0972e+04)
[2022-06-09 23:10:57,642][root][INFO] - Step 41241600 @ 4092.7 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 41241600, mean_episode_return = 62.94, mean_episode_step = 1037.4, total_loss = 315.99, pg_loss = 224.1, baseline_loss = 97.607, entropy_loss = -5.714, learner_queue_size = 32, _tick = 9419, _time = 1.6548e+09, train_seconds = 1.0977e+04)
[2022-06-09 23:11:02,646][root][INFO] - Step 41259520 @ 3581.0 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 41259520, mean_episode_return = 12.84, mean_episode_step = 1016.6, total_loss = -166.76, pg_loss = -193.48, baseline_loss = 32.298, entropy_loss = -5.5776, learner_queue_size = 32, _tick = 9426, _time = 1.6548e+09, train_seconds = 1.0982e+04)
[2022-06-09 23:11:07,650][root][INFO] - Step 41277440 @ 3581.4 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (step = 41277440, mean_episode_return = 53.74, mean_episode_step = 1028.9, total_loss = 239.29, pg_loss = 165.56, baseline_loss = 79.169, entropy_loss = -5.445, learner_queue_size = 32, _tick = 9432, _time = 1.6548e+09, train_seconds = 1.0988e+04)
[2022-06-09 23:11:12,654][root][INFO] - Step 41297920 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 41297920, mean_episode_return = 83.12, mean_episode_step = 836.73, total_loss = 53.113, pg_loss = -8.1234, baseline_loss = 66.643, entropy_loss = -5.4064, learner_queue_size = 32, _tick = 9437, _time = 1.6548e+09, train_seconds = 1.0992e+04)
[2022-06-09 23:11:17,658][root][INFO] - Step 41315840 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 41315840, mean_episode_return = 61.969, mean_episode_step = 1289.6, total_loss = -132.05, pg_loss = -167.33, baseline_loss = 40.81, entropy_loss = -5.526, learner_queue_size = 32, _tick = 9442, _time = 1.6548e+09, train_seconds = 1.0998e+04)
[2022-06-09 23:11:22,662][root][INFO] - Step 41336320 @ 4092.7 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 41336320, mean_episode_return = 92.857, mean_episode_step = 1035.8, total_loss = 329.08, pg_loss = 216.49, baseline_loss = 118.26, entropy_loss = -5.6721, learner_queue_size = 32, _tick = 9449, _time = 1.6548e+09, train_seconds = 1.1002e+04)
[2022-06-09 23:11:27,666][root][INFO] - Step 41354240 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 41354240, mean_episode_return = 24.785, mean_episode_step = 1449.1, total_loss = 188.0, pg_loss = 150.47, baseline_loss = 43.178, entropy_loss = -5.6521, learner_queue_size = 32, _tick = 9455, _time = 1.6548e+09, train_seconds = 1.1008e+04)
[2022-06-09 23:11:32,670][root][INFO] - Step 41372160 @ 3580.9 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 41372160, mean_episode_return = 30.132, mean_episode_step = 934.19, total_loss = 450.63, pg_loss = 347.12, baseline_loss = 109.13, entropy_loss = -5.6089, learner_queue_size = 32, _tick = 9462, _time = 1.6548e+09, train_seconds = 1.1012e+04)
[2022-06-09 23:11:37,674][root][INFO] - Step 41392640 @ 4093.0 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 41392640, mean_episode_return = None, mean_episode_step = 717.56, total_loss = 98.471, pg_loss = 30.014, baseline_loss = 73.982, entropy_loss = -5.5244, learner_queue_size = 32, _tick = 9468, _time = 1.6548e+09, train_seconds = 1.1018e+04)
[2022-06-09 23:11:42,678][root][INFO] - Step 41410560 @ 3581.1 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 41410560, mean_episode_return = 47.22, mean_episode_step = 1086.8, total_loss = 138.94, pg_loss = 50.826, baseline_loss = 93.69, entropy_loss = -5.5786, learner_queue_size = 32, _tick = 9472, _time = 1.6548e+09, train_seconds = 1.1022e+04)
[2022-06-09 23:11:47,682][root][INFO] - Step 41428480 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 41428480, mean_episode_return = 75.627, mean_episode_step = 959.43, total_loss = 1456.0, pg_loss = 631.87, baseline_loss = 829.79, entropy_loss = -5.6347, learner_queue_size = 32, _tick = 9478, _time = 1.6548e+09, train_seconds = 1.1028e+04)
[2022-06-09 23:11:52,686][root][INFO] - Step 41448960 @ 4092.7 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 41448960, mean_episode_return = 26.67, mean_episode_step = 1270.0, total_loss = -33.92, pg_loss = -79.93, baseline_loss = 51.501, entropy_loss = -5.4902, learner_queue_size = 32, _tick = 9486, _time = 1.6548e+09, train_seconds = 1.1032e+04)
[2022-06-09 23:11:57,690][root][INFO] - Step 41466880 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 41466880, mean_episode_return = 141.71, mean_episode_step = 1108.1, total_loss = -39.257, pg_loss = -85.932, baseline_loss = 51.892, entropy_loss = -5.2164, learner_queue_size = 32, _tick = 9491, _time = 1.6548e+09, train_seconds = 1.1038e+04)
[2022-06-09 23:12:02,694][root][INFO] - Step 41484800 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 41484800, mean_episode_return = 78.07, mean_episode_step = 834.16, total_loss = -22.953, pg_loss = -63.887, baseline_loss = 46.571, entropy_loss = -5.6365, learner_queue_size = 32, _tick = 9497, _time = 1.6548e+09, train_seconds = 1.1042e+04)
[2022-06-09 23:12:07,698][root][INFO] - Step 41502720 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 41502720, mean_episode_return = None, mean_episode_step = 1129.2, total_loss = 433.14, pg_loss = 312.5, baseline_loss = 126.11, entropy_loss = -5.4753, learner_queue_size = 32, _tick = 9503, _time = 1.6548e+09, train_seconds = 1.1048e+04)
[2022-06-09 23:12:12,702][root][INFO] - Step 41523200 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 41523200, mean_episode_return = None, mean_episode_step = 1008.0, total_loss = 15.317, pg_loss = -38.568, baseline_loss = 59.105, entropy_loss = -5.2198, learner_queue_size = 32, _tick = 9508, _time = 1.6548e+09, train_seconds = 1.1052e+04)
[2022-06-09 23:12:17,706][root][INFO] - Step 41541120 @ 3581.1 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 41541120, mean_episode_return = 54.03, mean_episode_step = 1447.3, total_loss = -92.303, pg_loss = -124.06, baseline_loss = 37.175, entropy_loss = -5.4187, learner_queue_size = 32, _tick = 9514, _time = 1.6548e+09, train_seconds = 1.1058e+04)
[2022-06-09 23:12:22,710][root][INFO] - Step 41561600 @ 4092.7 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (step = 41561600, mean_episode_return = None, mean_episode_step = 1104.9, total_loss = -104.31, pg_loss = -117.47, baseline_loss = 18.92, entropy_loss = -5.7618, learner_queue_size = 32, _tick = 9519, _time = 1.6548e+09, train_seconds = 1.1062e+04)
[2022-06-09 23:12:27,714][root][INFO] - Step 41579520 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 41579520, mean_episode_return = 84.486, mean_episode_step = 992.24, total_loss = -190.33, pg_loss = -250.32, baseline_loss = 65.661, entropy_loss = -5.6668, learner_queue_size = 32, _tick = 9526, _time = 1.6548e+09, train_seconds = 1.1068e+04)
[2022-06-09 23:12:32,718][root][INFO] - Step 41600000 @ 4092.7 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 41600000, mean_episode_return = None, mean_episode_step = 1040.7, total_loss = 72.211, pg_loss = 37.579, baseline_loss = 40.205, entropy_loss = -5.5728, learner_queue_size = 32, _tick = 9531, _time = 1.6548e+09, train_seconds = 1.1072e+04)
[2022-06-09 23:12:37,722][root][INFO] - Step 41617920 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 41617920, mean_episode_return = -4.71, mean_episode_step = 1046.1, total_loss = 179.95, pg_loss = 110.2, baseline_loss = 75.354, entropy_loss = -5.6005, learner_queue_size = 32, _tick = 9538, _time = 1.6548e+09, train_seconds = 1.1078e+04)
[2022-06-09 23:12:42,726][root][INFO] - Step 41635840 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 41635840, mean_episode_return = 64.354, mean_episode_step = 920.6, total_loss = 103.65, pg_loss = -24.164, baseline_loss = 133.33, entropy_loss = -5.5202, learner_queue_size = 32, _tick = 9545, _time = 1.6548e+09, train_seconds = 1.1082e+04)
[2022-06-09 23:12:47,731][root][INFO] - Step 41656320 @ 4091.5 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 41656320, mean_episode_return = None, mean_episode_step = 1354.9, total_loss = 235.24, pg_loss = 157.69, baseline_loss = 82.961, entropy_loss = -5.4162, learner_queue_size = 32, _tick = 9551, _time = 1.6548e+09, train_seconds = 1.1088e+04)
[2022-06-09 23:12:52,734][root][INFO] - Step 41674240 @ 3582.2 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 41674240, mean_episode_return = 32.66, mean_episode_step = 1048.3, total_loss = 286.65, pg_loss = 206.65, baseline_loss = 85.163, entropy_loss = -5.1656, learner_queue_size = 32, _tick = 9557, _time = 1.6548e+09, train_seconds = 1.1092e+04)
[2022-06-09 23:12:57,740][root][INFO] - Step 41692160 @ 3579.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 41692160, mean_episode_return = None, mean_episode_step = 1289.2, total_loss = 286.99, pg_loss = 194.05, baseline_loss = 97.896, entropy_loss = -4.9585, learner_queue_size = 32, _tick = 9561, _time = 1.6548e+09, train_seconds = 1.1098e+04)
[2022-06-09 23:13:02,746][root][INFO] - Step 41712640 @ 4091.1 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 41712640, mean_episode_return = 144.86, mean_episode_step = 1178.9, total_loss = -117.19, pg_loss = -149.29, baseline_loss = 37.385, entropy_loss = -5.2823, learner_queue_size = 32, _tick = 9568, _time = 1.6548e+09, train_seconds = 1.1103e+04)
[2022-06-09 23:13:07,750][root][INFO] - Step 41730560 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 41730560, mean_episode_return = 66.611, mean_episode_step = 1564.8, total_loss = -134.87, pg_loss = -161.6, baseline_loss = 32.491, entropy_loss = -5.7535, learner_queue_size = 32, _tick = 9574, _time = 1.6548e+09, train_seconds = 1.1108e+04)
[2022-06-09 23:13:12,754][root][INFO] - Step 41751040 @ 4092.8 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 41751040, mean_episode_return = 18.24, mean_episode_step = 1051.8, total_loss = -214.2, pg_loss = -301.04, baseline_loss = 92.513, entropy_loss = -5.6771, learner_queue_size = 32, _tick = 9578, _time = 1.6548e+09, train_seconds = 1.1113e+04)
[2022-06-09 23:13:17,758][root][INFO] - Step 41768960 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 41768960, mean_episode_return = 72.829, mean_episode_step = 1169.0, total_loss = -55.453, pg_loss = -138.31, baseline_loss = 88.546, entropy_loss = -5.6935, learner_queue_size = 32, _tick = 9585, _time = 1.6548e+09, train_seconds = 1.1118e+04)
[2022-06-09 23:13:22,763][root][INFO] - Step 41789440 @ 4092.3 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 41789440, mean_episode_return = 53.531, mean_episode_step = 1678.4, total_loss = -74.357, pg_loss = -102.91, baseline_loss = 34.124, entropy_loss = -5.5693, learner_queue_size = 32, _tick = 9592, _time = 1.6548e+09, train_seconds = 1.1123e+04)
[2022-06-09 23:13:27,767][root][INFO] - Step 41807360 @ 3581.0 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 41807360, mean_episode_return = 50.51, mean_episode_step = 1715.8, total_loss = 201.05, pg_loss = 119.0, baseline_loss = 87.579, entropy_loss = -5.5338, learner_queue_size = 32, _tick = 9597, _time = 1.6548e+09, train_seconds = 1.1128e+04)
[2022-06-09 23:13:32,770][root][INFO] - Step 41825280 @ 3581.6 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 41825280, mean_episode_return = 47.47, mean_episode_step = 1371.9, total_loss = 1.4278e+04, pg_loss = 2316.0, baseline_loss = 1.1967e+04, entropy_loss = -5.5271, learner_queue_size = 32, _tick = 9604, _time = 1.6548e+09, train_seconds = 1.1133e+04)
[2022-06-09 23:13:37,777][root][INFO] - Step 41843200 @ 3579.0 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 41843200, mean_episode_return = 35.05, mean_episode_step = 1065.7, total_loss = 245.87, pg_loss = 169.0, baseline_loss = 82.28, entropy_loss = -5.405, learner_queue_size = 32, _tick = 9608, _time = 1.6548e+09, train_seconds = 1.1138e+04)
[2022-06-09 23:13:42,782][root][INFO] - Step 41863680 @ 4091.9 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 41863680, mean_episode_return = 89.43, mean_episode_step = 989.64, total_loss = 40.898, pg_loss = -0.25461, baseline_loss = 46.49, entropy_loss = -5.3376, learner_queue_size = 32, _tick = 9615, _time = 1.6548e+09, train_seconds = 1.1143e+04)
[2022-06-09 23:13:47,786][root][INFO] - Step 41881600 @ 3581.2 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 41881600, mean_episode_return = 18.62, mean_episode_step = 1087.8, total_loss = -33.113, pg_loss = -94.294, baseline_loss = 66.52, entropy_loss = -5.3384, learner_queue_size = 32, _tick = 9620, _time = 1.6548e+09, train_seconds = 1.1148e+04)
[2022-06-09 23:13:52,792][root][INFO] - Step 41899520 @ 3579.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 41899520, mean_episode_return = None, mean_episode_step = 1113.2, total_loss = 308.2, pg_loss = 224.53, baseline_loss = 89.067, entropy_loss = -5.3931, learner_queue_size = 32, _tick = 9625, _time = 1.6548e+09, train_seconds = 1.1153e+04)
[2022-06-09 23:13:57,798][root][INFO] - Step 41920000 @ 4091.2 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 41920000, mean_episode_return = 73.921, mean_episode_step = 1050.5, total_loss = -325.66, pg_loss = -388.64, baseline_loss = 68.188, entropy_loss = -5.2079, learner_queue_size = 32, _tick = 9631, _time = 1.6548e+09, train_seconds = 1.1158e+04)
[2022-06-09 23:14:02,802][root][INFO] - Step 41937920 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 41937920, mean_episode_return = 34.651, mean_episode_step = 1081.3, total_loss = 188.63, pg_loss = 118.05, baseline_loss = 76.059, entropy_loss = -5.4763, learner_queue_size = 32, _tick = 9637, _time = 1.6548e+09, train_seconds = 1.1163e+04)
[2022-06-09 23:14:07,806][root][INFO] - Step 41955840 @ 3581.2 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 41955840, mean_episode_return = None, mean_episode_step = 1034.2, total_loss = 37.989, pg_loss = 6.0598, baseline_loss = 37.551, entropy_loss = -5.622, learner_queue_size = 32, _tick = 9642, _time = 1.6548e+09, train_seconds = 1.1168e+04)
[2022-06-09 23:14:12,810][root][INFO] - Step 41976320 @ 4092.7 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 41976320, mean_episode_return = 93.956, mean_episode_step = 963.23, total_loss = -134.77, pg_loss = -198.55, baseline_loss = 69.231, entropy_loss = -5.4497, learner_queue_size = 32, _tick = 9648, _time = 1.6548e+09, train_seconds = 1.1173e+04)
[2022-06-09 23:14:17,814][root][INFO] - Step 41994240 @ 3581.1 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 41994240, mean_episode_return = 122.13, mean_episode_step = 1135.0, total_loss = -39.623, pg_loss = -55.782, baseline_loss = 21.956, entropy_loss = -5.7965, learner_queue_size = 32, _tick = 9653, _time = 1.6548e+09, train_seconds = 1.1178e+04)
[2022-06-09 23:14:22,818][root][INFO] - Step 42014720 @ 4092.8 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 42014720, mean_episode_return = None, mean_episode_step = 893.47, total_loss = 53.928, pg_loss = 20.779, baseline_loss = 38.62, entropy_loss = -5.4716, learner_queue_size = 32, _tick = 9659, _time = 1.6548e+09, train_seconds = 1.1183e+04)
[2022-06-09 23:14:27,822][root][INFO] - Step 42032640 @ 3580.9 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (step = 42032640, mean_episode_return = None, mean_episode_step = 911.69, total_loss = 488.35, pg_loss = 395.03, baseline_loss = 98.86, entropy_loss = -5.5462, learner_queue_size = 32, _tick = 9664, _time = 1.6548e+09, train_seconds = 1.1188e+04)
[2022-06-09 23:14:32,826][root][INFO] - Step 42050560 @ 3581.4 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 42050560, mean_episode_return = None, mean_episode_step = 1288.5, total_loss = 115.94, pg_loss = 86.711, baseline_loss = 34.755, entropy_loss = -5.5248, learner_queue_size = 32, _tick = 9666, _time = 1.6548e+09, train_seconds = 1.1193e+04)
[2022-06-09 23:14:37,830][root][INFO] - Step 42071040 @ 4092.5 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 42071040, mean_episode_return = 56.976, mean_episode_step = 1152.0, total_loss = -24.892, pg_loss = -50.841, baseline_loss = 31.359, entropy_loss = -5.4096, learner_queue_size = 32, _tick = 9672, _time = 1.6548e+09, train_seconds = 1.1198e+04)
[2022-06-09 23:14:42,834][root][INFO] - Step 42088960 @ 3581.3 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 42088960, mean_episode_return = None, mean_episode_step = 1680.5, total_loss = 35.401, pg_loss = 5.8699, baseline_loss = 35.038, entropy_loss = -5.5067, learner_queue_size = 32, _tick = 9674, _time = 1.6548e+09, train_seconds = 1.1203e+04)
[2022-06-09 23:14:47,838][root][INFO] - Step 42106880 @ 3581.1 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 42106880, mean_episode_return = 20.34, mean_episode_step = 1217.4, total_loss = -32.957, pg_loss = -91.358, baseline_loss = 63.918, entropy_loss = -5.5163, learner_queue_size = 32, _tick = 9680, _time = 1.6548e+09, train_seconds = 1.1208e+04)
[2022-06-09 23:14:52,842][root][INFO] - Step 42127360 @ 4092.7 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 42127360, mean_episode_return = 38.665, mean_episode_step = 999.38, total_loss = 68.366, pg_loss = 2.312, baseline_loss = 71.564, entropy_loss = -5.5104, learner_queue_size = 32, _tick = 9687, _time = 1.6548e+09, train_seconds = 1.1213e+04)
[2022-06-09 23:14:57,846][root][INFO] - Step 42145280 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 42145280, mean_episode_return = None, mean_episode_step = 1229.0, total_loss = 42.563, pg_loss = 10.328, baseline_loss = 37.551, entropy_loss = -5.3162, learner_queue_size = 32, _tick = 9691, _time = 1.6548e+09, train_seconds = 1.1218e+04)
[2022-06-09 23:15:02,850][root][INFO] - Step 42165760 @ 4092.7 SPS. Inference batcher size: 80. Learner queue size: 32. Other stats: (step = 42165760, mean_episode_return = 18.49, mean_episode_step = 1631.9, total_loss = 143.27, pg_loss = 72.314, baseline_loss = 76.243, entropy_loss = -5.2853, learner_queue_size = 32, _tick = 9698, _time = 1.6548e+09, train_seconds = 1.1223e+04)
[2022-06-09 23:15:07,854][root][INFO] - Step 42183680 @ 3581.2 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 42183680, mean_episode_return = None, mean_episode_step = 1005.7, total_loss = -48.266, pg_loss = -99.653, baseline_loss = 56.669, entropy_loss = -5.2822, learner_queue_size = 32, _tick = 9703, _time = 1.6548e+09, train_seconds = 1.1228e+04)
[2022-06-09 23:15:12,858][root][INFO] - Step 42204160 @ 4092.7 SPS. Inference batcher size: 75. Learner queue size: 32. Other stats: (step = 42204160, mean_episode_return = None, mean_episode_step = 1146.2, total_loss = -110.54, pg_loss = -141.03, baseline_loss = 35.977, entropy_loss = -5.4961, learner_queue_size = 32, _tick = 9707, _time = 1.6548e+09, train_seconds = 1.1233e+04)
[2022-06-09 23:15:17,862][root][INFO] - Step 42222080 @ 3581.1 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (step = 42222080, mean_episode_return = None, mean_episode_step = 1180.8, total_loss = 235.67, pg_loss = 138.81, baseline_loss = 102.48, entropy_loss = -5.6083, learner_queue_size = 32, _tick = 9712, _time = 1.6548e+09, train_seconds = 1.1238e+04)
[2022-06-09 23:15:22,866][root][INFO] - Step 42240000 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 42240000, mean_episode_return = 115.47, mean_episode_step = 1269.7, total_loss = 175.6, pg_loss = 91.262, baseline_loss = 89.83, entropy_loss = -5.493, learner_queue_size = 32, _tick = 9717, _time = 1.6548e+09, train_seconds = 1.1243e+04)
[2022-06-09 23:15:27,870][root][INFO] - Step 42260480 @ 4092.8 SPS. Inference batcher size: 75. Learner queue size: 32. Other stats: (step = 42260480, mean_episode_return = None, mean_episode_step = 1304.4, total_loss = 127.43, pg_loss = 70.429, baseline_loss = 62.48, entropy_loss = -5.4758, learner_queue_size = 32, _tick = 9723, _time = 1.6548e+09, train_seconds = 1.1248e+04)
[2022-06-09 23:15:32,874][root][INFO] - Step 42278400 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 42278400, mean_episode_return = 72.408, mean_episode_step = 1619.6, total_loss = 274.22, pg_loss = 181.41, baseline_loss = 98.264, entropy_loss = -5.4499, learner_queue_size = 32, _tick = 9728, _time = 1.6548e+09, train_seconds = 1.1253e+04)
[2022-06-09 23:15:37,878][root][INFO] - Step 42296320 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 42296320, mean_episode_return = None, mean_episode_step = 1101.2, total_loss = 337.29, pg_loss = 194.69, baseline_loss = 147.99, entropy_loss = -5.3931, learner_queue_size = 32, _tick = 9733, _time = 1.6548e+09, train_seconds = 1.1258e+04)
[2022-06-09 23:15:42,882][root][INFO] - Step 42314240 @ 3580.9 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 42314240, mean_episode_return = 37.96, mean_episode_step = 1075.2, total_loss = 162.37, pg_loss = 102.33, baseline_loss = 65.607, entropy_loss = -5.5661, learner_queue_size = 32, _tick = 9739, _time = 1.6548e+09, train_seconds = 1.1263e+04)
[2022-06-09 23:15:47,886][root][INFO] - Step 42332160 @ 3581.5 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 42332160, mean_episode_return = 44.12, mean_episode_step = 1113.1, total_loss = 197.26, pg_loss = 108.41, baseline_loss = 94.498, entropy_loss = -5.6475, learner_queue_size = 32, _tick = 9744, _time = 1.6548e+09, train_seconds = 1.1268e+04)
[2022-06-09 23:15:52,890][root][INFO] - Step 42352640 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 42352640, mean_episode_return = None, mean_episode_step = 1054.9, total_loss = 147.91, pg_loss = 67.134, baseline_loss = 86.123, entropy_loss = -5.3509, learner_queue_size = 32, _tick = 9748, _time = 1.6548e+09, train_seconds = 1.1273e+04)
[2022-06-09 23:15:57,895][root][INFO] - Step 42370560 @ 3580.3 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 42370560, mean_episode_return = 135.15, mean_episode_step = 923.95, total_loss = 235.39, pg_loss = 125.64, baseline_loss = 115.11, entropy_loss = -5.359, learner_queue_size = 32, _tick = 9753, _time = 1.6548e+09, train_seconds = 1.1278e+04)
[2022-06-09 23:16:02,898][root][INFO] - Step 42388480 @ 3581.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 42388480, mean_episode_return = 36.496, mean_episode_step = 1232.1, total_loss = 125.5, pg_loss = 73.645, baseline_loss = 56.911, entropy_loss = -5.0551, learner_queue_size = 32, _tick = 9759, _time = 1.6548e+09, train_seconds = 1.1283e+04)
[2022-06-09 23:16:07,903][root][INFO] - Step 42408960 @ 4092.1 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 42408960, mean_episode_return = 35.89, mean_episode_step = 1139.7, total_loss = 22.026, pg_loss = -36.163, baseline_loss = 63.679, entropy_loss = -5.4901, learner_queue_size = 32, _tick = 9767, _time = 1.6548e+09, train_seconds = 1.1288e+04)
[2022-06-09 23:16:12,906][root][INFO] - Step 42426880 @ 3581.8 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 42426880, mean_episode_return = 92.595, mean_episode_step = 1382.2, total_loss = -90.716, pg_loss = -115.87, baseline_loss = 30.592, entropy_loss = -5.4393, learner_queue_size = 32, _tick = 9772, _time = 1.6548e+09, train_seconds = 1.1293e+04)
[2022-06-09 23:16:17,910][root][INFO] - Step 42444800 @ 3581.2 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 42444800, mean_episode_return = 38.047, mean_episode_step = 1337.4, total_loss = 302.32, pg_loss = 224.96, baseline_loss = 82.779, entropy_loss = -5.4242, learner_queue_size = 32, _tick = 9779, _time = 1.6548e+09, train_seconds = 1.1298e+04)
[2022-06-09 23:16:22,914][root][INFO] - Step 42465280 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 42465280, mean_episode_return = 93.68, mean_episode_step = 915.06, total_loss = -70.356, pg_loss = -123.2, baseline_loss = 57.844, entropy_loss = -4.9988, learner_queue_size = 32, _tick = 9785, _time = 1.6548e+09, train_seconds = 1.1303e+04)
[2022-06-09 23:16:27,918][root][INFO] - Step 42483200 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 42483200, mean_episode_return = None, mean_episode_step = 1163.7, total_loss = 176.56, pg_loss = 109.75, baseline_loss = 72.624, entropy_loss = -5.8125, learner_queue_size = 32, _tick = 9790, _time = 1.6548e+09, train_seconds = 1.1308e+04)
[2022-06-09 23:16:32,922][root][INFO] - Step 42503680 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 42503680, mean_episode_return = 61.189, mean_episode_step = 858.11, total_loss = 446.12, pg_loss = 290.42, baseline_loss = 161.44, entropy_loss = -5.731, learner_queue_size = 32, _tick = 9796, _time = 1.6548e+09, train_seconds = 1.1313e+04)
[2022-06-09 23:16:37,927][root][INFO] - Step 42521600 @ 3580.7 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 42521600, mean_episode_return = 89.584, mean_episode_step = 1586.4, total_loss = -40.666, pg_loss = -87.797, baseline_loss = 52.756, entropy_loss = -5.6253, learner_queue_size = 32, _tick = 9802, _time = 1.6548e+09, train_seconds = 1.1318e+04)
[2022-06-09 23:16:42,930][root][INFO] - Step 42539520 @ 3581.6 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 42539520, mean_episode_return = 68.23, mean_episode_step = 1111.3, total_loss = -39.625, pg_loss = -84.24, baseline_loss = 50.326, entropy_loss = -5.7113, learner_queue_size = 32, _tick = 9808, _time = 1.6548e+09, train_seconds = 1.1323e+04)
[2022-06-09 23:16:47,934][root][INFO] - Step 42557440 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 42557440, mean_episode_return = 47.181, mean_episode_step = 1046.2, total_loss = 75.11, pg_loss = 19.96, baseline_loss = 60.802, entropy_loss = -5.6521, learner_queue_size = 32, _tick = 9814, _time = 1.6548e+09, train_seconds = 1.1328e+04)
[2022-06-09 23:16:52,938][root][INFO] - Step 42577920 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 42577920, mean_episode_return = 129.94, mean_episode_step = 1076.0, total_loss = 167.18, pg_loss = 64.436, baseline_loss = 108.36, entropy_loss = -5.6174, learner_queue_size = 32, _tick = 9821, _time = 1.6548e+09, train_seconds = 1.1333e+04)
[2022-06-09 23:16:57,942][root][INFO] - Step 42595840 @ 3581.2 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 42595840, mean_episode_return = 51.408, mean_episode_step = 795.88, total_loss = -76.517, pg_loss = -120.18, baseline_loss = 49.156, entropy_loss = -5.4981, learner_queue_size = 32, _tick = 9825, _time = 1.6548e+09, train_seconds = 1.1338e+04)
[2022-06-09 23:17:02,947][root][INFO] - Step 42616320 @ 4092.4 SPS. Inference batcher size: 81. Learner queue size: 32. Other stats: (step = 42616320, mean_episode_return = 45.741, mean_episode_step = 1028.8, total_loss = 56.897, pg_loss = 12.886, baseline_loss = 49.423, entropy_loss = -5.4109, learner_queue_size = 32, _tick = 9830, _time = 1.6548e+09, train_seconds = 1.1343e+04)
[2022-06-09 23:17:07,950][root][INFO] - Step 42634240 @ 3581.4 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 42634240, mean_episode_return = 34.19, mean_episode_step = 988.59, total_loss = 177.23, pg_loss = 88.555, baseline_loss = 94.253, entropy_loss = -5.5783, learner_queue_size = 32, _tick = 9837, _time = 1.6548e+09, train_seconds = 1.1348e+04)
[2022-06-09 23:17:12,954][root][INFO] - Step 42652160 @ 3581.1 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 42652160, mean_episode_return = None, mean_episode_step = 997.47, total_loss = 310.07, pg_loss = 217.12, baseline_loss = 98.576, entropy_loss = -5.6314, learner_queue_size = 32, _tick = 9842, _time = 1.6548e+09, train_seconds = 1.1353e+04)
[2022-06-09 23:17:17,958][root][INFO] - Step 42672640 @ 4092.4 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (step = 42672640, mean_episode_return = 124.91, mean_episode_step = 973.84, total_loss = 48.47, pg_loss = -14.759, baseline_loss = 68.741, entropy_loss = -5.512, learner_queue_size = 32, _tick = 9846, _time = 1.6548e+09, train_seconds = 1.1358e+04)
[2022-06-09 23:17:22,962][root][INFO] - Step 42690560 @ 3581.4 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 42690560, mean_episode_return = 132.37, mean_episode_step = 1027.6, total_loss = 182.15, pg_loss = 114.2, baseline_loss = 73.537, entropy_loss = -5.5777, learner_queue_size = 32, _tick = 9852, _time = 1.6548e+09, train_seconds = 1.1363e+04)
[2022-06-09 23:17:27,966][root][INFO] - Step 42708480 @ 3581.2 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (step = 42708480, mean_episode_return = 134.36, mean_episode_step = 1060.9, total_loss = 163.69, pg_loss = 70.266, baseline_loss = 98.991, entropy_loss = -5.5643, learner_queue_size = 32, _tick = 9857, _time = 1.6548e+09, train_seconds = 1.1368e+04)
[2022-06-09 23:17:32,972][root][INFO] - Step 42726400 @ 3579.6 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 42726400, mean_episode_return = 52.705, mean_episode_step = 798.25, total_loss = -105.07, pg_loss = -148.78, baseline_loss = 49.273, entropy_loss = -5.5663, learner_queue_size = 32, _tick = 9864, _time = 1.6548e+09, train_seconds = 1.1373e+04)
[2022-06-09 23:17:37,978][root][INFO] - Step 42746880 @ 4091.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 42746880, mean_episode_return = 74.465, mean_episode_step = 1077.3, total_loss = -84.157, pg_loss = -92.747, baseline_loss = 14.267, entropy_loss = -5.677, learner_queue_size = 32, _tick = 9870, _time = 1.6548e+09, train_seconds = 1.1378e+04)
[2022-06-09 23:17:42,982][root][INFO] - Step 42764800 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 42764800, mean_episode_return = 43.129, mean_episode_step = 1513.4, total_loss = 62.035, pg_loss = 14.459, baseline_loss = 53.255, entropy_loss = -5.6796, learner_queue_size = 32, _tick = 9876, _time = 1.6548e+09, train_seconds = 1.1383e+04)
[2022-06-09 23:17:47,986][root][INFO] - Step 42782720 @ 3581.2 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 42782720, mean_episode_return = 62.061, mean_episode_step = 1095.2, total_loss = 420.08, pg_loss = 305.8, baseline_loss = 119.94, entropy_loss = -5.6626, learner_queue_size = 32, _tick = 9882, _time = 1.6548e+09, train_seconds = 1.1388e+04)
[2022-06-09 23:17:52,990][root][INFO] - Step 42803200 @ 4092.7 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 42803200, mean_episode_return = None, mean_episode_step = 1039.0, total_loss = -72.357, pg_loss = -105.8, baseline_loss = 39.073, entropy_loss = -5.6321, learner_queue_size = 32, _tick = 9889, _time = 1.6548e+09, train_seconds = 1.1393e+04)
[2022-06-09 23:17:57,994][root][INFO] - Step 42821120 @ 3581.1 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 42821120, mean_episode_return = 72.41, mean_episode_step = 888.18, total_loss = -66.414, pg_loss = -102.44, baseline_loss = 41.655, entropy_loss = -5.6309, learner_queue_size = 32, _tick = 9895, _time = 1.6548e+09, train_seconds = 1.1398e+04)
[2022-06-09 23:18:02,998][root][INFO] - Step 42839040 @ 3581.1 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 42839040, mean_episode_return = 14.9, mean_episode_step = 1141.3, total_loss = 112.75, pg_loss = 64.565, baseline_loss = 53.784, entropy_loss = -5.5988, learner_queue_size = 32, _tick = 9899, _time = 1.6548e+09, train_seconds = 1.1403e+04)
[2022-06-09 23:18:08,002][root][INFO] - Step 42859520 @ 4092.7 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 42859520, mean_episode_return = 20.48, mean_episode_step = 1275.4, total_loss = -60.916, pg_loss = -126.32, baseline_loss = 71.002, entropy_loss = -5.5962, learner_queue_size = 32, _tick = 9905, _time = 1.6548e+09, train_seconds = 1.1408e+04)
[2022-06-09 23:18:13,006][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-09 23:18:13,148][root][INFO] - Step 42877440 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 42877440, mean_episode_return = 48.18, mean_episode_step = 907.59, total_loss = -82.37, pg_loss = -121.59, baseline_loss = 44.77, entropy_loss = -5.5483, learner_queue_size = 32, _tick = 9910, _time = 1.6548e+09, train_seconds = 1.1413e+04)
[2022-06-09 23:18:18,154][root][INFO] - Step 42895360 @ 3480.9 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 42895360, mean_episode_return = 34.206, mean_episode_step = 1199.5, total_loss = -246.18, pg_loss = -305.19, baseline_loss = 64.552, entropy_loss = -5.5339, learner_queue_size = 32, _tick = 9915, _time = 1.6548e+09, train_seconds = 1.1418e+04)
[2022-06-09 23:18:23,158][root][INFO] - Step 42915840 @ 4092.5 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 42915840, mean_episode_return = 12.81, mean_episode_step = 1062.7, total_loss = -228.5, pg_loss = -232.14, baseline_loss = 9.2477, entropy_loss = -5.607, learner_queue_size = 32, _tick = 9920, _time = 1.6548e+09, train_seconds = 1.1423e+04)
[2022-06-09 23:18:28,162][root][INFO] - Step 42933760 @ 3581.4 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 42933760, mean_episode_return = None, mean_episode_step = 1471.5, total_loss = 41.01, pg_loss = 4.6783, baseline_loss = 41.884, entropy_loss = -5.5526, learner_queue_size = 32, _tick = 9923, _time = 1.6548e+09, train_seconds = 1.1428e+04)
[2022-06-09 23:18:33,166][root][INFO] - Step 42954240 @ 4092.7 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 42954240, mean_episode_return = 134.83, mean_episode_step = 1701.7, total_loss = -64.393, pg_loss = -84.505, baseline_loss = 25.611, entropy_loss = -5.4986, learner_queue_size = 32, _tick = 9930, _time = 1.6548e+09, train_seconds = 1.1433e+04)
[2022-06-09 23:18:38,170][root][INFO] - Step 42972160 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 42972160, mean_episode_return = 74.66, mean_episode_step = 1046.6, total_loss = 313.53, pg_loss = 187.42, baseline_loss = 131.56, entropy_loss = -5.4472, learner_queue_size = 32, _tick = 9936, _time = 1.6548e+09, train_seconds = 1.1438e+04)
[2022-06-09 23:18:43,174][root][INFO] - Step 42992640 @ 4092.6 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 42992640, mean_episode_return = None, mean_episode_step = 1049.2, total_loss = 144.19, pg_loss = 109.05, baseline_loss = 40.489, entropy_loss = -5.35, learner_queue_size = 32, _tick = 9940, _time = 1.6548e+09, train_seconds = 1.1443e+04)
[2022-06-09 23:18:48,178][root][INFO] - Step 43010560 @ 3581.2 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 43010560, mean_episode_return = 36.615, mean_episode_step = 1318.5, total_loss = 125.15, pg_loss = 53.917, baseline_loss = 76.493, entropy_loss = -5.257, learner_queue_size = 32, _tick = 9944, _time = 1.6548e+09, train_seconds = 1.1448e+04)
[2022-06-09 23:18:53,182][root][INFO] - Step 43031040 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 43031040, mean_episode_return = None, mean_episode_step = 1289.7, total_loss = -62.823, pg_loss = -96.026, baseline_loss = 38.512, entropy_loss = -5.3093, learner_queue_size = 32, _tick = 9951, _time = 1.6548e+09, train_seconds = 1.1453e+04)
[2022-06-09 23:18:58,186][root][INFO] - Step 43048960 @ 3581.2 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 43048960, mean_episode_return = 41.681, mean_episode_step = 883.18, total_loss = -155.18, pg_loss = -164.8, baseline_loss = 15.046, entropy_loss = -5.4179, learner_queue_size = 32, _tick = 9956, _time = 1.6548e+09, train_seconds = 1.1458e+04)
[2022-06-09 23:19:03,190][root][INFO] - Step 43066880 @ 3581.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 43066880, mean_episode_return = 80.779, mean_episode_step = 1273.7, total_loss = 426.82, pg_loss = 253.57, baseline_loss = 178.52, entropy_loss = -5.2783, learner_queue_size = 32, _tick = 9962, _time = 1.6548e+09, train_seconds = 1.1463e+04)
[2022-06-09 23:19:08,194][root][INFO] - Step 43087360 @ 4092.8 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (step = 43087360, mean_episode_return = None, mean_episode_step = 1945.9, total_loss = 59.168, pg_loss = 17.295, baseline_loss = 46.98, entropy_loss = -5.1074, learner_queue_size = 32, _tick = 9969, _time = 1.6548e+09, train_seconds = 1.1468e+04)
[2022-06-09 23:19:13,198][root][INFO] - Step 43105280 @ 3581.1 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 43105280, mean_episode_return = 113.24, mean_episode_step = 1425.8, total_loss = 79.478, pg_loss = 12.294, baseline_loss = 72.4, entropy_loss = -5.2162, learner_queue_size = 32, _tick = 9974, _time = 1.6548e+09, train_seconds = 1.1473e+04)
[2022-06-09 23:19:18,202][root][INFO] - Step 43125760 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 43125760, mean_episode_return = 73.18, mean_episode_step = 1276.3, total_loss = 42.106, pg_loss = -44.36, baseline_loss = 91.649, entropy_loss = -5.1838, learner_queue_size = 32, _tick = 9981, _time = 1.6548e+09, train_seconds = 1.1478e+04)
[2022-06-09 23:19:23,206][root][INFO] - Step 43138560 @ 2558.0 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (step = 43138560, mean_episode_return = None, mean_episode_step = 1560.2, total_loss = 331.14, pg_loss = 260.18, baseline_loss = 76.136, entropy_loss = -5.1675, learner_queue_size = 32, _tick = 9984, _time = 1.6548e+09, train_seconds = 1.1483e+04)
[2022-06-09 23:19:28,210][root][INFO] - Step 43156480 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 43156480, mean_episode_return = 67.025, mean_episode_step = 1625.2, total_loss = 98.81, pg_loss = 69.871, baseline_loss = 34.198, entropy_loss = -5.2582, learner_queue_size = 32, _tick = 9990, _time = 1.6548e+09, train_seconds = 1.1488e+04)
[2022-06-09 23:19:33,215][root][INFO] - Step 43176960 @ 4091.9 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 43176960, mean_episode_return = 66.75, mean_episode_step = 1237.8, total_loss = 85.841, pg_loss = 69.273, baseline_loss = 22.121, entropy_loss = -5.5526, learner_queue_size = 32, _tick = 9996, _time = 1.6548e+09, train_seconds = 1.1493e+04)
[2022-06-09 23:19:38,218][root][INFO] - Step 43194880 @ 3581.8 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 43194880, mean_episode_return = 70.02, mean_episode_step = 1721.4, total_loss = 12.746, pg_loss = -49.533, baseline_loss = 67.663, entropy_loss = -5.3834, learner_queue_size = 32, _tick = 10003, _time = 1.6548e+09, train_seconds = 1.1498e+04)
[2022-06-09 23:19:43,222][root][INFO] - Step 43212800 @ 3581.2 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 43212800, mean_episode_return = 84.276, mean_episode_step = 1749.3, total_loss = 63.689, pg_loss = 3.4406, baseline_loss = 65.66, entropy_loss = -5.4113, learner_queue_size = 32, _tick = 10010, _time = 1.6548e+09, train_seconds = 1.1503e+04)
[2022-06-09 23:19:48,226][root][INFO] - Step 43233280 @ 4092.7 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 43233280, mean_episode_return = 66.116, mean_episode_step = 1343.9, total_loss = -0.53382, pg_loss = -50.489, baseline_loss = 55.178, entropy_loss = -5.2233, learner_queue_size = 32, _tick = 10017, _time = 1.6548e+09, train_seconds = 1.1508e+04)
[2022-06-09 23:19:53,230][root][INFO] - Step 43251200 @ 3581.2 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 43251200, mean_episode_return = 43.492, mean_episode_step = 1107.8, total_loss = 66.638, pg_loss = 11.262, baseline_loss = 60.289, entropy_loss = -4.9133, learner_queue_size = 32, _tick = 10024, _time = 1.6548e+09, train_seconds = 1.1513e+04)
[2022-06-09 23:19:58,234][root][INFO] - Step 43269120 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 43269120, mean_episode_return = 41.363, mean_episode_step = 908.15, total_loss = 123.74, pg_loss = 52.088, baseline_loss = 76.977, entropy_loss = -5.3195, learner_queue_size = 32, _tick = 10030, _time = 1.6548e+09, train_seconds = 1.1518e+04)
[2022-06-09 23:20:03,238][root][INFO] - Step 43289600 @ 4092.8 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 43289600, mean_episode_return = 32.265, mean_episode_step = 1410.0, total_loss = -133.24, pg_loss = -188.31, baseline_loss = 60.265, entropy_loss = -5.1981, learner_queue_size = 32, _tick = 10035, _time = 1.6548e+09, train_seconds = 1.1523e+04)
[2022-06-09 23:20:08,242][root][INFO] - Step 43307520 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 43307520, mean_episode_return = None, mean_episode_step = 1152.3, total_loss = -18.384, pg_loss = -36.165, baseline_loss = 23.28, entropy_loss = -5.4992, learner_queue_size = 32, _tick = 10040, _time = 1.6548e+09, train_seconds = 1.1528e+04)
[2022-06-09 23:20:13,246][root][INFO] - Step 43325440 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 43325440, mean_episode_return = 28.581, mean_episode_step = 1572.2, total_loss = 114.48, pg_loss = 47.439, baseline_loss = 72.602, entropy_loss = -5.559, learner_queue_size = 32, _tick = 10046, _time = 1.6548e+09, train_seconds = 1.1533e+04)
[2022-06-09 23:20:18,250][root][INFO] - Step 43345920 @ 4092.6 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 43345920, mean_episode_return = 44.761, mean_episode_step = 1250.7, total_loss = 137.87, pg_loss = 103.38, baseline_loss = 39.957, entropy_loss = -5.469, learner_queue_size = 32, _tick = 10054, _time = 1.6548e+09, train_seconds = 1.1538e+04)
[2022-06-09 23:20:23,254][root][INFO] - Step 43363840 @ 3581.2 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 43363840, mean_episode_return = 21.93, mean_episode_step = 1168.3, total_loss = -92.471, pg_loss = -109.82, baseline_loss = 22.611, entropy_loss = -5.2663, learner_queue_size = 32, _tick = 10060, _time = 1.6548e+09, train_seconds = 1.1543e+04)
[2022-06-09 23:20:28,258][root][INFO] - Step 43381760 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 43381760, mean_episode_return = 31.18, mean_episode_step = 931.51, total_loss = -37.474, pg_loss = -56.154, baseline_loss = 23.925, entropy_loss = -5.2446, learner_queue_size = 32, _tick = 10067, _time = 1.6548e+09, train_seconds = 1.1548e+04)
[2022-06-09 23:20:33,262][root][INFO] - Step 43402240 @ 4092.7 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 43402240, mean_episode_return = 69.8, mean_episode_step = 1052.3, total_loss = 471.19, pg_loss = 302.83, baseline_loss = 173.5, entropy_loss = -5.1404, learner_queue_size = 32, _tick = 10074, _time = 1.6548e+09, train_seconds = 1.1553e+04)
[2022-06-09 23:20:38,266][root][INFO] - Step 43420160 @ 3581.2 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 43420160, mean_episode_return = 35.146, mean_episode_step = 2116.1, total_loss = 33.335, pg_loss = -30.74, baseline_loss = 69.303, entropy_loss = -5.2285, learner_queue_size = 32, _tick = 10078, _time = 1.6548e+09, train_seconds = 1.1558e+04)
[2022-06-09 23:20:43,270][root][INFO] - Step 43440640 @ 4092.7 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 43440640, mean_episode_return = None, mean_episode_step = 1698.5, total_loss = 241.7, pg_loss = 177.49, baseline_loss = 69.658, entropy_loss = -5.4489, learner_queue_size = 32, _tick = 10080, _time = 1.6548e+09, train_seconds = 1.1563e+04)
[2022-06-09 23:20:48,274][root][INFO] - Step 43458560 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 43458560, mean_episode_return = None, mean_episode_step = 1559.3, total_loss = 321.48, pg_loss = 259.93, baseline_loss = 67.114, entropy_loss = -5.5645, learner_queue_size = 32, _tick = 10085, _time = 1.6548e+09, train_seconds = 1.1568e+04)
[2022-06-09 23:20:53,278][root][INFO] - Step 43476480 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 43476480, mean_episode_return = -6.6803, mean_episode_step = 1467.7, total_loss = -125.88, pg_loss = -149.12, baseline_loss = 28.565, entropy_loss = -5.3216, learner_queue_size = 32, _tick = 10091, _time = 1.6548e+09, train_seconds = 1.1573e+04)
[2022-06-09 23:20:58,282][root][INFO] - Step 43496960 @ 4092.5 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 43496960, mean_episode_return = 45.93, mean_episode_step = 1468.2, total_loss = 141.59, pg_loss = 61.865, baseline_loss = 84.894, entropy_loss = -5.168, learner_queue_size = 32, _tick = 10097, _time = 1.6548e+09, train_seconds = 1.1578e+04)
[2022-06-09 23:21:03,286][root][INFO] - Step 43514880 @ 3581.3 SPS. Inference batcher size: 77. Learner queue size: 32. Other stats: (step = 43514880, mean_episode_return = 20.13, mean_episode_step = 1604.9, total_loss = -36.9, pg_loss = -91.474, baseline_loss = 59.948, entropy_loss = -5.3746, learner_queue_size = 32, _tick = 10103, _time = 1.6548e+09, train_seconds = 1.1583e+04)
[2022-06-09 23:21:08,290][root][INFO] - Step 43532800 @ 3581.1 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 43532800, mean_episode_return = None, mean_episode_step = 1104.1, total_loss = 183.36, pg_loss = 91.973, baseline_loss = 96.738, entropy_loss = -5.3481, learner_queue_size = 32, _tick = 10107, _time = 1.6548e+09, train_seconds = 1.1588e+04)
[2022-06-09 23:21:13,294][root][INFO] - Step 43550720 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 43550720, mean_episode_return = None, mean_episode_step = 1775.1, total_loss = -27.015, pg_loss = -50.901, baseline_loss = 29.159, entropy_loss = -5.2725, learner_queue_size = 32, _tick = 10112, _time = 1.6548e+09, train_seconds = 1.1593e+04)
[2022-06-09 23:21:18,299][root][INFO] - Step 43568640 @ 3580.4 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 43568640, mean_episode_return = 19.61, mean_episode_step = 2242.3, total_loss = -5.769, pg_loss = -67.241, baseline_loss = 67.052, entropy_loss = -5.5805, learner_queue_size = 32, _tick = 10118, _time = 1.6548e+09, train_seconds = 1.1598e+04)
[2022-06-09 23:21:23,302][root][INFO] - Step 43589120 @ 4093.5 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 43589120, mean_episode_return = 40.39, mean_episode_step = 2055.7, total_loss = -32.388, pg_loss = -92.006, baseline_loss = 65.166, entropy_loss = -5.5474, learner_queue_size = 32, _tick = 10123, _time = 1.6548e+09, train_seconds = 1.1603e+04)
[2022-06-09 23:21:28,306][root][INFO] - Step 43607040 @ 3581.2 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 43607040, mean_episode_return = 91.729, mean_episode_step = 1195.1, total_loss = 10.837, pg_loss = -22.657, baseline_loss = 38.981, entropy_loss = -5.4869, learner_queue_size = 32, _tick = 10129, _time = 1.6548e+09, train_seconds = 1.1608e+04)
[2022-06-09 23:21:33,310][root][INFO] - Step 43627520 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 43627520, mean_episode_return = 73.713, mean_episode_step = 2048.5, total_loss = -128.77, pg_loss = -157.36, baseline_loss = 34.035, entropy_loss = -5.4473, learner_queue_size = 32, _tick = 10133, _time = 1.6548e+09, train_seconds = 1.1613e+04)
[2022-06-09 23:21:38,314][root][INFO] - Step 43645440 @ 3581.1 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 43645440, mean_episode_return = 45.557, mean_episode_step = 1542.5, total_loss = 59.719, pg_loss = 16.408, baseline_loss = 48.676, entropy_loss = -5.3642, learner_queue_size = 32, _tick = 10139, _time = 1.6548e+09, train_seconds = 1.1618e+04)
[2022-06-09 23:21:43,319][root][INFO] - Step 43665920 @ 4091.9 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 43665920, mean_episode_return = 47.981, mean_episode_step = 1381.1, total_loss = -55.988, pg_loss = -123.12, baseline_loss = 72.399, entropy_loss = -5.2716, learner_queue_size = 32, _tick = 10144, _time = 1.6548e+09, train_seconds = 1.1623e+04)
[2022-06-09 23:21:48,322][root][INFO] - Step 43683840 @ 3581.7 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 43683840, mean_episode_return = 40.877, mean_episode_step = 1756.4, total_loss = -165.9, pg_loss = -227.09, baseline_loss = 66.445, entropy_loss = -5.2544, learner_queue_size = 32, _tick = 10148, _time = 1.6548e+09, train_seconds = 1.1628e+04)
[2022-06-09 23:21:53,326][root][INFO] - Step 43701760 @ 3581.2 SPS. Inference batcher size: 87. Learner queue size: 32. Other stats: (step = 43701760, mean_episode_return = 52.661, mean_episode_step = 799.33, total_loss = -107.68, pg_loss = -159.16, baseline_loss = 56.698, entropy_loss = -5.2148, learner_queue_size = 32, _tick = 10153, _time = 1.6548e+09, train_seconds = 1.1633e+04)
[2022-06-09 23:21:58,330][root][INFO] - Step 43719680 @ 3581.1 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 43719680, mean_episode_return = 81.801, mean_episode_step = 1165.4, total_loss = -113.95, pg_loss = -175.84, baseline_loss = 67.342, entropy_loss = -5.4514, learner_queue_size = 32, _tick = 10159, _time = 1.6548e+09, train_seconds = 1.1638e+04)
[2022-06-09 23:22:03,334][root][INFO] - Step 43737600 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 43737600, mean_episode_return = 120.9, mean_episode_step = 1351.9, total_loss = -4.2723, pg_loss = -30.558, baseline_loss = 31.748, entropy_loss = -5.4625, learner_queue_size = 32, _tick = 10164, _time = 1.6548e+09, train_seconds = 1.1643e+04)
[2022-06-09 23:22:08,338][root][INFO] - Step 43758080 @ 4092.7 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 43758080, mean_episode_return = None, mean_episode_step = 999.19, total_loss = 220.5, pg_loss = 137.84, baseline_loss = 88.096, entropy_loss = -5.4403, learner_queue_size = 32, _tick = 10168, _time = 1.6548e+09, train_seconds = 1.1648e+04)
[2022-06-09 23:22:13,342][root][INFO] - Step 43776000 @ 3581.1 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 43776000, mean_episode_return = 6.5297, mean_episode_step = 825.13, total_loss = 23.191, pg_loss = -22.366, baseline_loss = 50.988, entropy_loss = -5.4309, learner_queue_size = 32, _tick = 10174, _time = 1.6548e+09, train_seconds = 1.1653e+04)
[2022-06-09 23:22:18,346][root][INFO] - Step 43793920 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 43793920, mean_episode_return = 42.201, mean_episode_step = 1161.2, total_loss = 180.13, pg_loss = 111.93, baseline_loss = 73.711, entropy_loss = -5.504, learner_queue_size = 32, _tick = 10178, _time = 1.6548e+09, train_seconds = 1.1658e+04)
[2022-06-09 23:22:23,350][root][INFO] - Step 43814400 @ 4092.7 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 43814400, mean_episode_return = 101.26, mean_episode_step = 1027.5, total_loss = 103.91, pg_loss = 36.667, baseline_loss = 72.586, entropy_loss = -5.3387, learner_queue_size = 32, _tick = 10186, _time = 1.6548e+09, train_seconds = 1.1663e+04)
[2022-06-09 23:22:28,354][root][INFO] - Step 43832320 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 43832320, mean_episode_return = None, mean_episode_step = 1030.7, total_loss = 447.31, pg_loss = 238.08, baseline_loss = 214.5, entropy_loss = -5.2706, learner_queue_size = 32, _tick = 10192, _time = 1.6548e+09, train_seconds = 1.1668e+04)
[2022-06-09 23:22:33,358][root][INFO] - Step 43852800 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 43852800, mean_episode_return = 75.27, mean_episode_step = 1039.5, total_loss = 233.98, pg_loss = 119.74, baseline_loss = 119.75, entropy_loss = -5.5133, learner_queue_size = 32, _tick = 10199, _time = 1.6548e+09, train_seconds = 1.1673e+04)
[2022-06-09 23:22:38,362][root][INFO] - Step 43870720 @ 3581.1 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 43870720, mean_episode_return = None, mean_episode_step = 994.16, total_loss = 314.87, pg_loss = 234.6, baseline_loss = 85.71, entropy_loss = -5.4416, learner_queue_size = 32, _tick = 10204, _time = 1.6548e+09, train_seconds = 1.1678e+04)
[2022-06-09 23:22:43,366][root][INFO] - Step 43888640 @ 3581.2 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (step = 43888640, mean_episode_return = 37.528, mean_episode_step = 1643.6, total_loss = -104.48, pg_loss = -192.12, baseline_loss = 92.875, entropy_loss = -5.2346, learner_queue_size = 32, _tick = 10208, _time = 1.6548e+09, train_seconds = 1.1683e+04)
[2022-06-09 23:22:48,370][root][INFO] - Step 43906560 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 43906560, mean_episode_return = 11.555, mean_episode_step = 1051.3, total_loss = 141.21, pg_loss = 27.197, baseline_loss = 119.26, entropy_loss = -5.2485, learner_queue_size = 32, _tick = 10214, _time = 1.6548e+09, train_seconds = 1.1688e+04)
[2022-06-09 23:22:53,374][root][INFO] - Step 43927040 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 43927040, mean_episode_return = 76.701, mean_episode_step = 816.3, total_loss = -99.499, pg_loss = -140.28, baseline_loss = 45.954, entropy_loss = -5.1767, learner_queue_size = 32, _tick = 10219, _time = 1.6548e+09, train_seconds = 1.1693e+04)
[2022-06-09 23:22:58,378][root][INFO] - Step 43944960 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 43944960, mean_episode_return = 56.662, mean_episode_step = 850.17, total_loss = 62.564, pg_loss = -0.50466, baseline_loss = 68.186, entropy_loss = -5.1172, learner_queue_size = 32, _tick = 10224, _time = 1.6548e+09, train_seconds = 1.1698e+04)
[2022-06-09 23:23:03,382][root][INFO] - Step 43962880 @ 3581.1 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 43962880, mean_episode_return = 35.842, mean_episode_step = 1405.6, total_loss = 74.906, pg_loss = 12.662, baseline_loss = 67.505, entropy_loss = -5.2604, learner_queue_size = 32, _tick = 10228, _time = 1.6548e+09, train_seconds = 1.1703e+04)
[2022-06-09 23:23:08,386][root][INFO] - Step 43983360 @ 4092.7 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 43983360, mean_episode_return = 82.839, mean_episode_step = 1015.9, total_loss = 34.393, pg_loss = -10.448, baseline_loss = 50.17, entropy_loss = -5.3283, learner_queue_size = 32, _tick = 10236, _time = 1.6548e+09, train_seconds = 1.1708e+04)
[2022-06-09 23:23:13,390][root][INFO] - Step 44001280 @ 3581.2 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 44001280, mean_episode_return = 51.13, mean_episode_step = 958.01, total_loss = 89.641, pg_loss = 25.229, baseline_loss = 69.717, entropy_loss = -5.3051, learner_queue_size = 32, _tick = 10242, _time = 1.6548e+09, train_seconds = 1.1713e+04)
[2022-06-09 23:23:18,394][root][INFO] - Step 44019200 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 44019200, mean_episode_return = None, mean_episode_step = 1970.3, total_loss = 260.24, pg_loss = 149.89, baseline_loss = 115.4, entropy_loss = -5.0568, learner_queue_size = 32, _tick = 10245, _time = 1.6548e+09, train_seconds = 1.1718e+04)
[2022-06-09 23:23:23,398][root][INFO] - Step 44039680 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 44039680, mean_episode_return = 65.4, mean_episode_step = 1120.5, total_loss = -117.0, pg_loss = -133.6, baseline_loss = 21.954, entropy_loss = -5.3551, learner_queue_size = 32, _tick = 10251, _time = 1.6548e+09, train_seconds = 1.1723e+04)
[2022-06-09 23:23:28,402][root][INFO] - Step 44057600 @ 3581.0 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 44057600, mean_episode_return = 63.129, mean_episode_step = 1248.2, total_loss = -35.414, pg_loss = -79.582, baseline_loss = 49.612, entropy_loss = -5.4437, learner_queue_size = 32, _tick = 10256, _time = 1.6548e+09, train_seconds = 1.1728e+04)
[2022-06-09 23:23:33,406][root][INFO] - Step 44075520 @ 3581.3 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (step = 44075520, mean_episode_return = 61.691, mean_episode_step = 1079.5, total_loss = 228.6, pg_loss = 158.6, baseline_loss = 75.289, entropy_loss = -5.2836, learner_queue_size = 32, _tick = 10260, _time = 1.6548e+09, train_seconds = 1.1733e+04)
[2022-06-09 23:23:38,410][root][INFO] - Step 44096000 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 44096000, mean_episode_return = 65.82, mean_episode_step = 1448.7, total_loss = 98.89, pg_loss = 12.448, baseline_loss = 91.74, entropy_loss = -5.2983, learner_queue_size = 32, _tick = 10267, _time = 1.6548e+09, train_seconds = 1.1738e+04)
[2022-06-09 23:23:43,414][root][INFO] - Step 44113920 @ 3581.2 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 44113920, mean_episode_return = 26.605, mean_episode_step = 2074.0, total_loss = -173.46, pg_loss = -190.03, baseline_loss = 21.923, entropy_loss = -5.3605, learner_queue_size = 32, _tick = 10274, _time = 1.6548e+09, train_seconds = 1.1743e+04)
[2022-06-09 23:23:48,418][root][INFO] - Step 44131840 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 44131840, mean_episode_return = 40.6, mean_episode_step = 1695.4, total_loss = 8.0149, pg_loss = -15.035, baseline_loss = 28.454, entropy_loss = -5.4043, learner_queue_size = 32, _tick = 10279, _time = 1.6548e+09, train_seconds = 1.1748e+04)
[2022-06-09 23:23:53,422][root][INFO] - Step 44149760 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 44149760, mean_episode_return = 12.045, mean_episode_step = 1336.6, total_loss = 226.61, pg_loss = 146.16, baseline_loss = 85.901, entropy_loss = -5.4482, learner_queue_size = 32, _tick = 10286, _time = 1.6548e+09, train_seconds = 1.1753e+04)
[2022-06-09 23:23:58,426][root][INFO] - Step 44167680 @ 3581.2 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 44167680, mean_episode_return = None, mean_episode_step = 1447.3, total_loss = 109.59, pg_loss = 56.676, baseline_loss = 58.165, entropy_loss = -5.2539, learner_queue_size = 32, _tick = 10290, _time = 1.6548e+09, train_seconds = 1.1758e+04)
[2022-06-09 23:24:03,430][root][INFO] - Step 44185600 @ 3581.2 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 44185600, mean_episode_return = 60.943, mean_episode_step = 844.86, total_loss = 97.655, pg_loss = 24.697, baseline_loss = 78.335, entropy_loss = -5.3772, learner_queue_size = 32, _tick = 10297, _time = 1.6548e+09, train_seconds = 1.1763e+04)
[2022-06-09 23:24:08,434][root][INFO] - Step 44206080 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 44206080, mean_episode_return = 121.76, mean_episode_step = 1277.8, total_loss = -37.582, pg_loss = -88.81, baseline_loss = 56.495, entropy_loss = -5.2675, learner_queue_size = 32, _tick = 10304, _time = 1.6548e+09, train_seconds = 1.1768e+04)
[2022-06-09 23:24:13,439][root][INFO] - Step 44224000 @ 3580.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 44224000, mean_episode_return = None, mean_episode_step = 1130.0, total_loss = -25.881, pg_loss = -37.905, baseline_loss = 17.494, entropy_loss = -5.4702, learner_queue_size = 32, _tick = 10309, _time = 1.6548e+09, train_seconds = 1.1773e+04)
[2022-06-09 23:24:18,442][root][INFO] - Step 44241920 @ 3582.1 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (step = 44241920, mean_episode_return = None, mean_episode_step = 1256.2, total_loss = 183.11, pg_loss = 99.535, baseline_loss = 89.004, entropy_loss = -5.426, learner_queue_size = 32, _tick = 10314, _time = 1.6548e+09, train_seconds = 1.1778e+04)
[2022-06-09 23:24:23,446][root][INFO] - Step 44259840 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 44259840, mean_episode_return = 33.077, mean_episode_step = 1310.4, total_loss = 172.46, pg_loss = 45.349, baseline_loss = 132.16, entropy_loss = -5.0441, learner_queue_size = 32, _tick = 10320, _time = 1.6548e+09, train_seconds = 1.1783e+04)
[2022-06-09 23:24:28,450][root][INFO] - Step 44280320 @ 4092.7 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 44280320, mean_episode_return = 92.52, mean_episode_step = 1191.6, total_loss = -26.132, pg_loss = -114.92, baseline_loss = 93.488, entropy_loss = -4.7014, learner_queue_size = 32, _tick = 10328, _time = 1.6548e+09, train_seconds = 1.1788e+04)
[2022-06-09 23:24:33,454][root][INFO] - Step 44298240 @ 3581.2 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 44298240, mean_episode_return = 37.87, mean_episode_step = 1083.9, total_loss = -231.15, pg_loss = -368.1, baseline_loss = 141.56, entropy_loss = -4.6173, learner_queue_size = 32, _tick = 10334, _time = 1.6548e+09, train_seconds = 1.1793e+04)
[2022-06-09 23:24:38,458][root][INFO] - Step 44318720 @ 4092.3 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 44318720, mean_episode_return = None, mean_episode_step = 1083.3, total_loss = -0.41401, pg_loss = -16.56, baseline_loss = 21.554, entropy_loss = -5.4082, learner_queue_size = 32, _tick = 10341, _time = 1.6548e+09, train_seconds = 1.1798e+04)
[2022-06-09 23:24:43,462][root][INFO] - Step 44336640 @ 3581.4 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 44336640, mean_episode_return = -58.902, mean_episode_step = 1816.6, total_loss = -12.546, pg_loss = -33.807, baseline_loss = 26.649, entropy_loss = -5.3881, learner_queue_size = 32, _tick = 10347, _time = 1.6548e+09, train_seconds = 1.1803e+04)
[2022-06-09 23:24:48,466][root][INFO] - Step 44354560 @ 3581.2 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 44354560, mean_episode_return = 101.29, mean_episode_step = 1448.6, total_loss = -36.106, pg_loss = -74.101, baseline_loss = 43.265, entropy_loss = -5.2705, learner_queue_size = 32, _tick = 10352, _time = 1.6548e+09, train_seconds = 1.1808e+04)
[2022-06-09 23:24:53,470][root][INFO] - Step 44375040 @ 4092.7 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 44375040, mean_episode_return = 169.05, mean_episode_step = 919.82, total_loss = 212.93, pg_loss = 152.49, baseline_loss = 65.686, entropy_loss = -5.246, learner_queue_size = 32, _tick = 10359, _time = 1.6548e+09, train_seconds = 1.1813e+04)
[2022-06-09 23:24:58,474][root][INFO] - Step 44392960 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 44392960, mean_episode_return = 40.82, mean_episode_step = 1410.6, total_loss = 105.05, pg_loss = 59.516, baseline_loss = 50.839, entropy_loss = -5.3047, learner_queue_size = 32, _tick = 10366, _time = 1.6548e+09, train_seconds = 1.1818e+04)
[2022-06-09 23:25:03,478][root][INFO] - Step 44410880 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 44410880, mean_episode_return = 75.706, mean_episode_step = 875.42, total_loss = 80.749, pg_loss = 31.201, baseline_loss = 54.828, entropy_loss = -5.2796, learner_queue_size = 32, _tick = 10373, _time = 1.6548e+09, train_seconds = 1.1823e+04)
[2022-06-09 23:25:08,482][root][INFO] - Step 44428800 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 44428800, mean_episode_return = 17.05, mean_episode_step = 893.62, total_loss = -51.575, pg_loss = -97.869, baseline_loss = 51.399, entropy_loss = -5.104, learner_queue_size = 32, _tick = 10380, _time = 1.6548e+09, train_seconds = 1.1828e+04)
[2022-06-09 23:25:13,486][root][INFO] - Step 44449280 @ 4092.8 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 44449280, mean_episode_return = 12.31, mean_episode_step = 1102.6, total_loss = 28.148, pg_loss = -22.642, baseline_loss = 55.85, entropy_loss = -5.0606, learner_queue_size = 32, _tick = 10386, _time = 1.6548e+09, train_seconds = 1.1833e+04)
[2022-06-09 23:25:18,490][root][INFO] - Step 44467200 @ 3581.2 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (step = 44467200, mean_episode_return = 49.69, mean_episode_step = 1125.0, total_loss = -34.197, pg_loss = -107.33, baseline_loss = 78.02, entropy_loss = -4.8865, learner_queue_size = 32, _tick = 10393, _time = 1.6548e+09, train_seconds = 1.1838e+04)
[2022-06-09 23:25:23,494][root][INFO] - Step 44485120 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 44485120, mean_episode_return = 109.48, mean_episode_step = 1100.0, total_loss = 192.81, pg_loss = 114.57, baseline_loss = 82.749, entropy_loss = -4.5013, learner_queue_size = 32, _tick = 10398, _time = 1.6548e+09, train_seconds = 1.1843e+04)
[2022-06-09 23:25:28,498][root][INFO] - Step 44505600 @ 4092.4 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 44505600, mean_episode_return = 42.951, mean_episode_step = 1147.9, total_loss = -80.119, pg_loss = -123.59, baseline_loss = 47.721, entropy_loss = -4.2501, learner_queue_size = 32, _tick = 10404, _time = 1.6548e+09, train_seconds = 1.1848e+04)
[2022-06-09 23:25:33,502][root][INFO] - Step 44523520 @ 3581.5 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 44523520, mean_episode_return = 54.393, mean_episode_step = 1032.6, total_loss = -204.29, pg_loss = -260.73, baseline_loss = 60.93, entropy_loss = -4.485, learner_queue_size = 32, _tick = 10410, _time = 1.6548e+09, train_seconds = 1.1853e+04)
[2022-06-09 23:25:38,506][root][INFO] - Step 44544000 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 44544000, mean_episode_return = 39.211, mean_episode_step = 1212.4, total_loss = 115.11, pg_loss = 79.851, baseline_loss = 40.621, entropy_loss = -5.3606, learner_queue_size = 32, _tick = 10417, _time = 1.6548e+09, train_seconds = 1.1858e+04)
[2022-06-09 23:25:43,510][root][INFO] - Step 44561920 @ 3581.0 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 44561920, mean_episode_return = 52.936, mean_episode_step = 1287.7, total_loss = 102.8, pg_loss = -2.9757, baseline_loss = 111.14, entropy_loss = -5.3705, learner_queue_size = 32, _tick = 10422, _time = 1.6548e+09, train_seconds = 1.1863e+04)
[2022-06-09 23:25:48,514][root][INFO] - Step 44579840 @ 3581.2 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 44579840, mean_episode_return = 21.007, mean_episode_step = 1318.0, total_loss = 264.86, pg_loss = 152.9, baseline_loss = 117.0, entropy_loss = -5.0394, learner_queue_size = 32, _tick = 10427, _time = 1.6548e+09, train_seconds = 1.1868e+04)
[2022-06-09 23:25:53,518][root][INFO] - Step 44600320 @ 4092.8 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 44600320, mean_episode_return = 72.611, mean_episode_step = 1300.0, total_loss = 94.88, pg_loss = -15.483, baseline_loss = 115.33, entropy_loss = -4.9689, learner_queue_size = 32, _tick = 10434, _time = 1.6548e+09, train_seconds = 1.1873e+04)
[2022-06-09 23:25:58,524][root][INFO] - Step 44618240 @ 3579.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 44618240, mean_episode_return = 44.139, mean_episode_step = 878.45, total_loss = 233.35, pg_loss = 158.86, baseline_loss = 79.549, entropy_loss = -5.0546, learner_queue_size = 32, _tick = 10439, _time = 1.6548e+09, train_seconds = 1.1878e+04)
[2022-06-09 23:26:03,530][root][INFO] - Step 44636160 @ 3579.7 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 44636160, mean_episode_return = 13.93, mean_episode_step = 717.14, total_loss = 110.3, pg_loss = 42.921, baseline_loss = 72.516, entropy_loss = -5.1363, learner_queue_size = 32, _tick = 10444, _time = 1.6548e+09, train_seconds = 1.1883e+04)
[2022-06-09 23:26:08,534][root][INFO] - Step 44656640 @ 4092.6 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 44656640, mean_episode_return = 41.386, mean_episode_step = 881.13, total_loss = 192.63, pg_loss = 90.798, baseline_loss = 106.93, entropy_loss = -5.0932, learner_queue_size = 32, _tick = 10450, _time = 1.6548e+09, train_seconds = 1.1888e+04)
[2022-06-09 23:26:13,538][root][INFO] - Step 44674560 @ 3581.2 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 44674560, mean_episode_return = 29.593, mean_episode_step = 974.9, total_loss = -88.905, pg_loss = -137.09, baseline_loss = 53.48, entropy_loss = -5.2971, learner_queue_size = 32, _tick = 10457, _time = 1.6548e+09, train_seconds = 1.1893e+04)
[2022-06-09 23:26:18,542][root][INFO] - Step 44695040 @ 4092.7 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 44695040, mean_episode_return = None, mean_episode_step = 1753.3, total_loss = 94.924, pg_loss = 63.703, baseline_loss = 36.698, entropy_loss = -5.4764, learner_queue_size = 32, _tick = 10463, _time = 1.6548e+09, train_seconds = 1.1898e+04)
[2022-06-09 23:26:23,546][root][INFO] - Step 44712960 @ 3581.2 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 44712960, mean_episode_return = 66.94, mean_episode_step = 1049.1, total_loss = 101.04, pg_loss = 26.521, baseline_loss = 79.907, entropy_loss = -5.3882, learner_queue_size = 32, _tick = 10469, _time = 1.6548e+09, train_seconds = 1.1903e+04)
[2022-06-09 23:26:28,550][root][INFO] - Step 44733440 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 44733440, mean_episode_return = None, mean_episode_step = 1137.7, total_loss = 36.96, pg_loss = 12.827, baseline_loss = 29.315, entropy_loss = -5.1813, learner_queue_size = 32, _tick = 10476, _time = 1.6548e+09, train_seconds = 1.1908e+04)
[2022-06-09 23:26:33,554][root][INFO] - Step 44751360 @ 3581.2 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (step = 44751360, mean_episode_return = 50.981, mean_episode_step = 1531.7, total_loss = -144.25, pg_loss = -167.86, baseline_loss = 28.849, entropy_loss = -5.235, learner_queue_size = 32, _tick = 10483, _time = 1.6548e+09, train_seconds = 1.1913e+04)
[2022-06-09 23:26:38,558][root][INFO] - Step 44769280 @ 3581.1 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 44769280, mean_episode_return = 49.95, mean_episode_step = 991.68, total_loss = 5.2175, pg_loss = -63.994, baseline_loss = 74.422, entropy_loss = -5.2107, learner_queue_size = 32, _tick = 10490, _time = 1.6548e+09, train_seconds = 1.1918e+04)
[2022-06-09 23:26:43,562][root][INFO] - Step 44789760 @ 4092.7 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 44789760, mean_episode_return = 6.3897, mean_episode_step = 898.64, total_loss = -43.285, pg_loss = -77.432, baseline_loss = 39.384, entropy_loss = -5.2379, learner_queue_size = 32, _tick = 10498, _time = 1.6548e+09, train_seconds = 1.1923e+04)
[2022-06-09 23:26:48,566][root][INFO] - Step 44807680 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 44807680, mean_episode_return = 58.327, mean_episode_step = 1706.2, total_loss = 71.303, pg_loss = -4.901, baseline_loss = 81.552, entropy_loss = -5.348, learner_queue_size = 32, _tick = 10502, _time = 1.6548e+09, train_seconds = 1.1928e+04)
[2022-06-09 23:26:53,570][root][INFO] - Step 44825600 @ 3581.2 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 44825600, mean_episode_return = 64.952, mean_episode_step = 689.42, total_loss = 87.437, pg_loss = 45.43, baseline_loss = 47.418, entropy_loss = -5.4107, learner_queue_size = 32, _tick = 10507, _time = 1.6548e+09, train_seconds = 1.1933e+04)
[2022-06-09 23:26:58,576][root][INFO] - Step 44843520 @ 3579.8 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 44843520, mean_episode_return = None, mean_episode_step = 872.53, total_loss = 167.32, pg_loss = 112.66, baseline_loss = 59.902, entropy_loss = -5.2407, learner_queue_size = 32, _tick = 10512, _time = 1.6548e+09, train_seconds = 1.1938e+04)
[2022-06-09 23:27:03,578][root][INFO] - Step 44864000 @ 4094.2 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 44864000, mean_episode_return = 72.663, mean_episode_step = 1377.8, total_loss = -157.94, pg_loss = -228.81, baseline_loss = 75.968, entropy_loss = -5.1015, learner_queue_size = 32, _tick = 10517, _time = 1.6548e+09, train_seconds = 1.1943e+04)
[2022-06-09 23:27:08,585][root][INFO] - Step 44881920 @ 3579.2 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 44881920, mean_episode_return = 42.741, mean_episode_step = 989.84, total_loss = 1.09, pg_loss = -43.969, baseline_loss = 50.303, entropy_loss = -5.2437, learner_queue_size = 32, _tick = 10521, _time = 1.6548e+09, train_seconds = 1.1948e+04)
[2022-06-09 23:27:13,590][root][INFO] - Step 44899840 @ 3580.2 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 44899840, mean_episode_return = None, mean_episode_step = 1523.3, total_loss = -50.133, pg_loss = -69.868, baseline_loss = 25.079, entropy_loss = -5.3443, learner_queue_size = 32, _tick = 10525, _time = 1.6548e+09, train_seconds = 1.1953e+04)
[2022-06-09 23:27:18,596][root][INFO] - Step 44920320 @ 4091.2 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (step = 44920320, mean_episode_return = 17.27, mean_episode_step = 1311.9, total_loss = 76.554, pg_loss = 24.484, baseline_loss = 57.333, entropy_loss = -5.263, learner_queue_size = 32, _tick = 10531, _time = 1.6548e+09, train_seconds = 1.1958e+04)
[2022-06-09 23:27:23,602][root][INFO] - Step 44938240 @ 3579.5 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 44938240, mean_episode_return = 64.79, mean_episode_step = 970.33, total_loss = 155.24, pg_loss = 100.49, baseline_loss = 60.103, entropy_loss = -5.3555, learner_queue_size = 32, _tick = 10536, _time = 1.6548e+09, train_seconds = 1.1963e+04)
[2022-06-09 23:27:28,606][root][INFO] - Step 44958720 @ 4092.8 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 44958720, mean_episode_return = 93.554, mean_episode_step = 1055.0, total_loss = 420.2, pg_loss = 317.49, baseline_loss = 108.15, entropy_loss = -5.4338, learner_queue_size = 32, _tick = 10544, _time = 1.6548e+09, train_seconds = 1.1968e+04)
[2022-06-09 23:27:33,610][root][INFO] - Step 44976640 @ 3581.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 44976640, mean_episode_return = 27.544, mean_episode_step = 1192.8, total_loss = 48.341, pg_loss = -24.358, baseline_loss = 77.905, entropy_loss = -5.2066, learner_queue_size = 32, _tick = 10551, _time = 1.6548e+09, train_seconds = 1.1973e+04)
[2022-06-09 23:27:38,614][root][INFO] - Step 44997120 @ 4092.7 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 44997120, mean_episode_return = 60.618, mean_episode_step = 1380.1, total_loss = 82.462, pg_loss = 27.154, baseline_loss = 60.646, entropy_loss = -5.3385, learner_queue_size = 32, _tick = 10559, _time = 1.6548e+09, train_seconds = 1.1978e+04)
[2022-06-09 23:27:43,618][root][INFO] - Step 45015040 @ 3581.1 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 45015040, mean_episode_return = 33.676, mean_episode_step = 1040.1, total_loss = -44.047, pg_loss = -104.32, baseline_loss = 65.51, entropy_loss = -5.2384, learner_queue_size = 32, _tick = 10563, _time = 1.6548e+09, train_seconds = 1.1983e+04)
[2022-06-09 23:27:48,622][root][INFO] - Step 45032960 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 45032960, mean_episode_return = 64.85, mean_episode_step = 1484.0, total_loss = -42.134, pg_loss = -82.993, baseline_loss = 46.096, entropy_loss = -5.2363, learner_queue_size = 32, _tick = 10568, _time = 1.6548e+09, train_seconds = 1.1988e+04)
[2022-06-09 23:27:53,626][root][INFO] - Step 45053440 @ 4092.8 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 45053440, mean_episode_return = None, mean_episode_step = 1192.3, total_loss = 198.58, pg_loss = 118.49, baseline_loss = 85.312, entropy_loss = -5.229, learner_queue_size = 32, _tick = 10573, _time = 1.6548e+09, train_seconds = 1.1993e+04)
[2022-06-09 23:27:58,630][root][INFO] - Step 45071360 @ 3581.1 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 45071360, mean_episode_return = 80.81, mean_episode_step = 928.82, total_loss = -2.3106, pg_loss = -49.672, baseline_loss = 52.846, entropy_loss = -5.485, learner_queue_size = 32, _tick = 10578, _time = 1.6548e+09, train_seconds = 1.1998e+04)
[2022-06-09 23:28:03,634][root][INFO] - Step 45089280 @ 3581.1 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 45089280, mean_episode_return = None, mean_episode_step = 1359.8, total_loss = 74.054, pg_loss = 26.021, baseline_loss = 53.568, entropy_loss = -5.5349, learner_queue_size = 32, _tick = 10583, _time = 1.6548e+09, train_seconds = 1.2003e+04)
[2022-06-09 23:28:08,638][root][INFO] - Step 45107200 @ 3581.2 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 45107200, mean_episode_return = 62.11, mean_episode_step = 1403.9, total_loss = 41.408, pg_loss = -15.253, baseline_loss = 62.154, entropy_loss = -5.4927, learner_queue_size = 32, _tick = 10589, _time = 1.6548e+09, train_seconds = 1.2008e+04)
[2022-06-09 23:28:13,642][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-09 23:28:13,781][root][INFO] - Step 45127680 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 45127680, mean_episode_return = 32.09, mean_episode_step = 1252.8, total_loss = 182.52, pg_loss = 121.41, baseline_loss = 66.368, entropy_loss = -5.2605, learner_queue_size = 32, _tick = 10597, _time = 1.6548e+09, train_seconds = 1.2013e+04)
[2022-06-09 23:28:18,786][root][INFO] - Step 45145600 @ 3483.8 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 45145600, mean_episode_return = 85.951, mean_episode_step = 957.92, total_loss = 96.301, pg_loss = 44.202, baseline_loss = 57.199, entropy_loss = -5.1001, learner_queue_size = 32, _tick = 10604, _time = 1.6548e+09, train_seconds = 1.2019e+04)
[2022-06-09 23:28:23,790][root][INFO] - Step 45166080 @ 4092.7 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 45166080, mean_episode_return = 29.83, mean_episode_step = 1742.0, total_loss = -170.95, pg_loss = -204.34, baseline_loss = 38.292, entropy_loss = -4.9032, learner_queue_size = 32, _tick = 10609, _time = 1.6548e+09, train_seconds = 1.2024e+04)
[2022-06-09 23:28:28,794][root][INFO] - Step 45184000 @ 3581.1 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 45184000, mean_episode_return = 31.2, mean_episode_step = 2031.7, total_loss = 8.8905, pg_loss = -48.293, baseline_loss = 62.395, entropy_loss = -5.2115, learner_queue_size = 32, _tick = 10615, _time = 1.6548e+09, train_seconds = 1.2029e+04)
[2022-06-09 23:28:33,798][root][INFO] - Step 45201920 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 45201920, mean_episode_return = None, mean_episode_step = 1974.2, total_loss = 8.0386, pg_loss = -11.939, baseline_loss = 25.332, entropy_loss = -5.3541, learner_queue_size = 32, _tick = 10619, _time = 1.6548e+09, train_seconds = 1.2034e+04)
[2022-06-09 23:28:38,802][root][INFO] - Step 45222400 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 45222400, mean_episode_return = 139.28, mean_episode_step = 931.88, total_loss = 9.9598, pg_loss = -44.357, baseline_loss = 59.615, entropy_loss = -5.2983, learner_queue_size = 32, _tick = 10626, _time = 1.6548e+09, train_seconds = 1.2039e+04)
[2022-06-09 23:28:43,808][root][INFO] - Step 45240320 @ 3579.7 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 45240320, mean_episode_return = None, mean_episode_step = 1180.4, total_loss = -32.644, pg_loss = -59.782, baseline_loss = 32.315, entropy_loss = -5.1765, learner_queue_size = 32, _tick = 10632, _time = 1.6548e+09, train_seconds = 1.2044e+04)
[2022-06-09 23:28:48,814][root][INFO] - Step 45260800 @ 4091.1 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 45260800, mean_episode_return = None, mean_episode_step = 1301.0, total_loss = -60.317, pg_loss = -68.305, baseline_loss = 13.4, entropy_loss = -5.4124, learner_queue_size = 32, _tick = 10635, _time = 1.6548e+09, train_seconds = 1.2049e+04)
[2022-06-09 23:28:53,818][root][INFO] - Step 45278720 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 45278720, mean_episode_return = 66.24, mean_episode_step = 1111.5, total_loss = 179.15, pg_loss = 97.989, baseline_loss = 86.529, entropy_loss = -5.3679, learner_queue_size = 32, _tick = 10641, _time = 1.6548e+09, train_seconds = 1.2054e+04)
[2022-06-09 23:28:58,822][root][INFO] - Step 45299200 @ 4092.9 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 45299200, mean_episode_return = 176.1, mean_episode_step = 1249.3, total_loss = -82.773, pg_loss = -110.28, baseline_loss = 32.842, entropy_loss = -5.3377, learner_queue_size = 32, _tick = 10648, _time = 1.6548e+09, train_seconds = 1.2059e+04)
[2022-06-09 23:29:03,826][root][INFO] - Step 45317120 @ 3581.2 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 45317120, mean_episode_return = 98.51, mean_episode_step = 1126.9, total_loss = -29.633, pg_loss = -60.747, baseline_loss = 36.492, entropy_loss = -5.3783, learner_queue_size = 32, _tick = 10655, _time = 1.6548e+09, train_seconds = 1.2064e+04)
[2022-06-09 23:29:08,830][root][INFO] - Step 45337600 @ 4092.6 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 45337600, mean_episode_return = 44.351, mean_episode_step = 1595.0, total_loss = 140.06, pg_loss = 82.948, baseline_loss = 62.491, entropy_loss = -5.3827, learner_queue_size = 32, _tick = 10660, _time = 1.6548e+09, train_seconds = 1.2069e+04)
[2022-06-09 23:29:13,834][root][INFO] - Step 45355520 @ 3581.2 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 45355520, mean_episode_return = 47.93, mean_episode_step = 943.2, total_loss = -0.26496, pg_loss = -69.275, baseline_loss = 74.3, entropy_loss = -5.2896, learner_queue_size = 32, _tick = 10667, _time = 1.6548e+09, train_seconds = 1.2074e+04)
[2022-06-09 23:29:18,838][root][INFO] - Step 45376000 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 45376000, mean_episode_return = None, mean_episode_step = 1083.0, total_loss = 83.311, pg_loss = 47.881, baseline_loss = 40.699, entropy_loss = -5.269, learner_queue_size = 32, _tick = 10673, _time = 1.6548e+09, train_seconds = 1.2079e+04)
[2022-06-09 23:29:23,842][root][INFO] - Step 45393920 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 45393920, mean_episode_return = 117.02, mean_episode_step = 1242.2, total_loss = 152.81, pg_loss = 48.561, baseline_loss = 109.67, entropy_loss = -5.4267, learner_queue_size = 32, _tick = 10679, _time = 1.6548e+09, train_seconds = 1.2084e+04)
[2022-06-09 23:29:28,846][root][INFO] - Step 45411840 @ 3581.1 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 45411840, mean_episode_return = 66.887, mean_episode_step = 1406.7, total_loss = 50.332, pg_loss = 0.89658, baseline_loss = 54.891, entropy_loss = -5.4552, learner_queue_size = 32, _tick = 10686, _time = 1.6548e+09, train_seconds = 1.2089e+04)
[2022-06-09 23:29:33,850][root][INFO] - Step 45429760 @ 3581.1 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 45429760, mean_episode_return = None, mean_episode_step = 1347.2, total_loss = 102.23, pg_loss = 40.45, baseline_loss = 67.247, entropy_loss = -5.4702, learner_queue_size = 32, _tick = 10687, _time = 1.6548e+09, train_seconds = 1.2094e+04)
[2022-06-09 23:29:38,854][root][INFO] - Step 45447680 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 45447680, mean_episode_return = 50.34, mean_episode_step = 1179.0, total_loss = 72.391, pg_loss = 19.859, baseline_loss = 57.831, entropy_loss = -5.2989, learner_queue_size = 32, _tick = 10693, _time = 1.6548e+09, train_seconds = 1.2099e+04)
[2022-06-09 23:29:43,858][root][INFO] - Step 45468160 @ 4092.7 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 45468160, mean_episode_return = 23.071, mean_episode_step = 1017.6, total_loss = -185.27, pg_loss = -206.42, baseline_loss = 26.509, entropy_loss = -5.3576, learner_queue_size = 32, _tick = 10700, _time = 1.6548e+09, train_seconds = 1.2104e+04)
[2022-06-09 23:29:48,862][root][INFO] - Step 45486080 @ 3581.2 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 45486080, mean_episode_return = 99.247, mean_episode_step = 1103.6, total_loss = -11.347, pg_loss = -50.787, baseline_loss = 44.994, entropy_loss = -5.5546, learner_queue_size = 32, _tick = 10705, _time = 1.6548e+09, train_seconds = 1.2109e+04)
[2022-06-09 23:29:53,867][root][INFO] - Step 45504000 @ 3580.5 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 45504000, mean_episode_return = 18.7, mean_episode_step = 1084.1, total_loss = 86.934, pg_loss = 44.658, baseline_loss = 47.765, entropy_loss = -5.4887, learner_queue_size = 32, _tick = 10711, _time = 1.6548e+09, train_seconds = 1.2114e+04)
[2022-06-09 23:29:58,870][root][INFO] - Step 45524480 @ 4093.5 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 45524480, mean_episode_return = 83.019, mean_episode_step = 960.08, total_loss = -62.723, pg_loss = -95.562, baseline_loss = 38.108, entropy_loss = -5.2699, learner_queue_size = 32, _tick = 10718, _time = 1.6548e+09, train_seconds = 1.2119e+04)
[2022-06-09 23:30:03,874][root][INFO] - Step 45539840 @ 3069.5 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (step = 45539840, mean_episode_return = 50.181, mean_episode_step = 1120.0, total_loss = -72.051, pg_loss = -99.988, baseline_loss = 33.47, entropy_loss = -5.534, learner_queue_size = 32, _tick = 10724, _time = 1.6548e+09, train_seconds = 1.2124e+04)
[2022-06-09 23:30:08,878][root][INFO] - Step 45557760 @ 3581.2 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 45557760, mean_episode_return = 129.14, mean_episode_step = 1425.3, total_loss = 119.65, pg_loss = 74.802, baseline_loss = 50.454, entropy_loss = -5.6033, learner_queue_size = 32, _tick = 10729, _time = 1.6548e+09, train_seconds = 1.2129e+04)
[2022-06-09 23:30:13,883][root][INFO] - Step 45575680 @ 3580.4 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 45575680, mean_episode_return = 33.831, mean_episode_step = 1052.6, total_loss = -10.852, pg_loss = -30.446, baseline_loss = 25.045, entropy_loss = -5.4514, learner_queue_size = 32, _tick = 10736, _time = 1.6548e+09, train_seconds = 1.2134e+04)
[2022-06-09 23:30:18,886][root][INFO] - Step 45596160 @ 4093.5 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 45596160, mean_episode_return = 5.775, mean_episode_step = 1487.2, total_loss = -43.966, pg_loss = -96.347, baseline_loss = 57.768, entropy_loss = -5.387, learner_queue_size = 32, _tick = 10743, _time = 1.6548e+09, train_seconds = 1.2139e+04)
[2022-06-09 23:30:23,890][root][INFO] - Step 45614080 @ 3581.2 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 45614080, mean_episode_return = 15.66, mean_episode_step = 1011.3, total_loss = -74.587, pg_loss = -89.286, baseline_loss = 19.912, entropy_loss = -5.2126, learner_queue_size = 32, _tick = 10749, _time = 1.6548e+09, train_seconds = 1.2144e+04)
[2022-06-09 23:30:28,894][root][INFO] - Step 45632000 @ 3581.2 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 45632000, mean_episode_return = None, mean_episode_step = 1093.9, total_loss = 229.79, pg_loss = 160.77, baseline_loss = 74.413, entropy_loss = -5.3978, learner_queue_size = 32, _tick = 10753, _time = 1.6548e+09, train_seconds = 1.2149e+04)
[2022-06-09 23:30:33,898][root][INFO] - Step 45649920 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 45649920, mean_episode_return = 42.02, mean_episode_step = 1177.6, total_loss = -9.0469, pg_loss = -69.164, baseline_loss = 65.378, entropy_loss = -5.2607, learner_queue_size = 32, _tick = 10759, _time = 1.6548e+09, train_seconds = 1.2154e+04)
[2022-06-09 23:30:38,902][root][INFO] - Step 45670400 @ 4092.7 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 45670400, mean_episode_return = None, mean_episode_step = 1218.4, total_loss = -145.89, pg_loss = -152.79, baseline_loss = 12.301, entropy_loss = -5.4065, learner_queue_size = 32, _tick = 10765, _time = 1.6548e+09, train_seconds = 1.2159e+04)
[2022-06-09 23:30:43,906][root][INFO] - Step 45688320 @ 3581.1 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 45688320, mean_episode_return = None, mean_episode_step = 1483.2, total_loss = 577.81, pg_loss = 449.03, baseline_loss = 134.24, entropy_loss = -5.462, learner_queue_size = 32, _tick = 10769, _time = 1.6548e+09, train_seconds = 1.2164e+04)
[2022-06-09 23:30:48,910][root][INFO] - Step 45706240 @ 3581.2 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 45706240, mean_episode_return = 92.109, mean_episode_step = 1800.6, total_loss = -104.29, pg_loss = -143.22, baseline_loss = 44.449, entropy_loss = -5.5244, learner_queue_size = 32, _tick = 10772, _time = 1.6548e+09, train_seconds = 1.2169e+04)
[2022-06-09 23:30:53,914][root][INFO] - Step 45724160 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 45724160, mean_episode_return = 37.089, mean_episode_step = 1626.4, total_loss = 49.207, pg_loss = 2.611, baseline_loss = 52.057, entropy_loss = -5.4613, learner_queue_size = 32, _tick = 10779, _time = 1.6548e+09, train_seconds = 1.2174e+04)
[2022-06-09 23:30:58,918][root][INFO] - Step 45742080 @ 3581.2 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 45742080, mean_episode_return = 62.619, mean_episode_step = 923.28, total_loss = 241.0, pg_loss = 113.0, baseline_loss = 133.37, entropy_loss = -5.3629, learner_queue_size = 32, _tick = 10785, _time = 1.6548e+09, train_seconds = 1.2179e+04)
[2022-06-09 23:31:03,922][root][INFO] - Step 45762560 @ 4092.5 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 45762560, mean_episode_return = 60.191, mean_episode_step = 1895.2, total_loss = 14.765, pg_loss = -11.48, baseline_loss = 31.809, entropy_loss = -5.5642, learner_queue_size = 32, _tick = 10789, _time = 1.6548e+09, train_seconds = 1.2184e+04)
[2022-06-09 23:31:08,926][root][INFO] - Step 45780480 @ 3581.3 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 45780480, mean_episode_return = 82.46, mean_episode_step = 1601.5, total_loss = 199.44, pg_loss = 113.32, baseline_loss = 91.562, entropy_loss = -5.438, learner_queue_size = 32, _tick = 10796, _time = 1.6548e+09, train_seconds = 1.2189e+04)
[2022-06-09 23:31:13,930][root][INFO] - Step 45800960 @ 4092.7 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 45800960, mean_episode_return = 71.44, mean_episode_step = 1183.1, total_loss = 195.36, pg_loss = 126.4, baseline_loss = 74.336, entropy_loss = -5.3751, learner_queue_size = 32, _tick = 10804, _time = 1.6548e+09, train_seconds = 1.2194e+04)
[2022-06-09 23:31:18,934][root][INFO] - Step 45818880 @ 3581.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 45818880, mean_episode_return = 106.77, mean_episode_step = 1447.5, total_loss = 0.30096, pg_loss = -58.003, baseline_loss = 63.72, entropy_loss = -5.4163, learner_queue_size = 32, _tick = 10808, _time = 1.6548e+09, train_seconds = 1.2199e+04)
[2022-06-09 23:31:23,938][root][INFO] - Step 45836800 @ 3581.2 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 45836800, mean_episode_return = 22.09, mean_episode_step = 1752.5, total_loss = -76.855, pg_loss = -99.903, baseline_loss = 28.4, entropy_loss = -5.3528, learner_queue_size = 32, _tick = 10814, _time = 1.6548e+09, train_seconds = 1.2204e+04)
[2022-06-09 23:31:28,944][root][INFO] - Step 45857280 @ 4091.2 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 45857280, mean_episode_return = 43.5, mean_episode_step = 1186.9, total_loss = -161.39, pg_loss = -195.76, baseline_loss = 39.946, entropy_loss = -5.5744, learner_queue_size = 32, _tick = 10821, _time = 1.6548e+09, train_seconds = 1.2209e+04)
[2022-06-09 23:31:33,946][root][INFO] - Step 45875200 @ 3582.5 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 45875200, mean_episode_return = None, mean_episode_step = 1832.1, total_loss = 304.42, pg_loss = 187.79, baseline_loss = 122.18, entropy_loss = -5.5449, learner_queue_size = 32, _tick = 10826, _time = 1.6548e+09, train_seconds = 1.2214e+04)
[2022-06-09 23:31:38,950][root][INFO] - Step 45893120 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 45893120, mean_episode_return = 27.24, mean_episode_step = 1103.8, total_loss = 119.32, pg_loss = 45.771, baseline_loss = 79.028, entropy_loss = -5.4775, learner_queue_size = 32, _tick = 10832, _time = 1.6548e+09, train_seconds = 1.2219e+04)
[2022-06-09 23:31:43,954][root][INFO] - Step 45911040 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 45911040, mean_episode_return = 104.51, mean_episode_step = 1693.0, total_loss = 481.87, pg_loss = 343.1, baseline_loss = 144.35, entropy_loss = -5.5767, learner_queue_size = 32, _tick = 10839, _time = 1.6548e+09, train_seconds = 1.2224e+04)
[2022-06-09 23:31:48,958][root][INFO] - Step 45928960 @ 3581.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 45928960, mean_episode_return = None, mean_episode_step = 1150.6, total_loss = 52.019, pg_loss = -11.952, baseline_loss = 69.429, entropy_loss = -5.4576, learner_queue_size = 32, _tick = 10843, _time = 1.6548e+09, train_seconds = 1.2229e+04)
[2022-06-09 23:31:53,963][root][INFO] - Step 45949440 @ 4092.2 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 45949440, mean_episode_return = 41.879, mean_episode_step = 1140.8, total_loss = 111.81, pg_loss = 31.977, baseline_loss = 85.344, entropy_loss = -5.5112, learner_queue_size = 32, _tick = 10851, _time = 1.6548e+09, train_seconds = 1.2234e+04)
[2022-06-09 23:31:58,966][root][INFO] - Step 45967360 @ 3581.6 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 45967360, mean_episode_return = 59.12, mean_episode_step = 1702.8, total_loss = 159.08, pg_loss = 97.036, baseline_loss = 67.819, entropy_loss = -5.778, learner_queue_size = 32, _tick = 10856, _time = 1.6548e+09, train_seconds = 1.2239e+04)
[2022-06-09 23:32:03,970][root][INFO] - Step 45987840 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 45987840, mean_episode_return = -8.0901, mean_episode_step = 1363.9, total_loss = 121.26, pg_loss = 52.292, baseline_loss = 74.506, entropy_loss = -5.5383, learner_queue_size = 32, _tick = 10862, _time = 1.6548e+09, train_seconds = 1.2244e+04)
[2022-06-09 23:32:08,974][root][INFO] - Step 46005760 @ 3581.1 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 46005760, mean_episode_return = 58.45, mean_episode_step = 1929.3, total_loss = 296.06, pg_loss = 207.55, baseline_loss = 94.055, entropy_loss = -5.5518, learner_queue_size = 32, _tick = 10866, _time = 1.6548e+09, train_seconds = 1.2249e+04)
[2022-06-09 23:32:13,978][root][INFO] - Step 46023680 @ 3581.2 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 46023680, mean_episode_return = -4.13, mean_episode_step = 983.91, total_loss = -213.81, pg_loss = -239.27, baseline_loss = 31.018, entropy_loss = -5.5539, learner_queue_size = 32, _tick = 10871, _time = 1.6548e+09, train_seconds = 1.2254e+04)
[2022-06-09 23:32:18,982][root][INFO] - Step 46041600 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 46041600, mean_episode_return = 68.056, mean_episode_step = 1478.1, total_loss = 251.67, pg_loss = 157.63, baseline_loss = 99.564, entropy_loss = -5.5269, learner_queue_size = 32, _tick = 10875, _time = 1.6548e+09, train_seconds = 1.2259e+04)
[2022-06-09 23:32:23,986][root][INFO] - Step 46062080 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 46062080, mean_episode_return = 36.075, mean_episode_step = 1335.5, total_loss = 225.52, pg_loss = 149.85, baseline_loss = 81.151, entropy_loss = -5.4869, learner_queue_size = 32, _tick = 10881, _time = 1.6548e+09, train_seconds = 1.2264e+04)
[2022-06-09 23:32:28,990][root][INFO] - Step 46080000 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 46080000, mean_episode_return = 91.829, mean_episode_step = 1659.1, total_loss = -44.362, pg_loss = -87.039, baseline_loss = 48.072, entropy_loss = -5.3946, learner_queue_size = 32, _tick = 10886, _time = 1.6548e+09, train_seconds = 1.2269e+04)
[2022-06-09 23:32:33,994][root][INFO] - Step 46097920 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 46097920, mean_episode_return = 77.998, mean_episode_step = 1904.5, total_loss = -149.07, pg_loss = -183.27, baseline_loss = 39.67, entropy_loss = -5.4699, learner_queue_size = 32, _tick = 10893, _time = 1.6548e+09, train_seconds = 1.2274e+04)
[2022-06-09 23:32:38,998][root][INFO] - Step 46115840 @ 3581.0 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 46115840, mean_episode_return = 4.9395, mean_episode_step = 1732.8, total_loss = -24.911, pg_loss = -78.172, baseline_loss = 58.705, entropy_loss = -5.4443, learner_queue_size = 32, _tick = 10898, _time = 1.6548e+09, train_seconds = 1.2279e+04)
[2022-06-09 23:32:44,002][root][INFO] - Step 46136320 @ 4093.0 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 46136320, mean_episode_return = 104.54, mean_episode_step = 1250.3, total_loss = -124.69, pg_loss = -152.17, baseline_loss = 32.954, entropy_loss = -5.4782, learner_queue_size = 32, _tick = 10905, _time = 1.6548e+09, train_seconds = 1.2284e+04)
[2022-06-09 23:32:49,006][root][INFO] - Step 46154240 @ 3581.1 SPS. Inference batcher size: 81. Learner queue size: 32. Other stats: (step = 46154240, mean_episode_return = 28.691, mean_episode_step = 961.16, total_loss = 192.04, pg_loss = 133.5, baseline_loss = 64.024, entropy_loss = -5.4841, learner_queue_size = 32, _tick = 10912, _time = 1.6548e+09, train_seconds = 1.2289e+04)
[2022-06-09 23:32:54,010][root][INFO] - Step 46172160 @ 3581.1 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 46172160, mean_episode_return = 211.39, mean_episode_step = 1272.8, total_loss = -78.456, pg_loss = -112.2, baseline_loss = 39.103, entropy_loss = -5.3623, learner_queue_size = 32, _tick = 10917, _time = 1.6548e+09, train_seconds = 1.2294e+04)
[2022-06-09 23:32:59,014][root][INFO] - Step 46192640 @ 4092.6 SPS. Inference batcher size: 78. Learner queue size: 32. Other stats: (step = 46192640, mean_episode_return = None, mean_episode_step = 1089.5, total_loss = 48.962, pg_loss = 0.10945, baseline_loss = 54.241, entropy_loss = -5.3892, learner_queue_size = 32, _tick = 10923, _time = 1.6548e+09, train_seconds = 1.2299e+04)
[2022-06-09 23:33:04,018][root][INFO] - Step 46210560 @ 3581.3 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 46210560, mean_episode_return = 42.465, mean_episode_step = 1158.0, total_loss = 186.94, pg_loss = 115.11, baseline_loss = 77.408, entropy_loss = -5.5772, learner_queue_size = 32, _tick = 10929, _time = 1.6548e+09, train_seconds = 1.2304e+04)
[2022-06-09 23:33:09,022][root][INFO] - Step 46231040 @ 4092.8 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 46231040, mean_episode_return = 63.03, mean_episode_step = 2006.1, total_loss = 129.21, pg_loss = 50.156, baseline_loss = 84.475, entropy_loss = -5.4164, learner_queue_size = 32, _tick = 10937, _time = 1.6548e+09, train_seconds = 1.2309e+04)
[2022-06-09 23:33:14,026][root][INFO] - Step 46248960 @ 3581.2 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 46248960, mean_episode_return = None, mean_episode_step = 1548.0, total_loss = -93.889, pg_loss = -119.76, baseline_loss = 31.359, entropy_loss = -5.4897, learner_queue_size = 32, _tick = 10943, _time = 1.6548e+09, train_seconds = 1.2314e+04)
[2022-06-09 23:33:19,030][root][INFO] - Step 46266880 @ 3580.9 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 46266880, mean_episode_return = 80.275, mean_episode_step = 859.25, total_loss = 32.365, pg_loss = -39.824, baseline_loss = 77.613, entropy_loss = -5.4237, learner_queue_size = 32, _tick = 10949, _time = 1.6548e+09, train_seconds = 1.2319e+04)
[2022-06-09 23:33:24,034][root][INFO] - Step 46284800 @ 3581.4 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 46284800, mean_episode_return = None, mean_episode_step = 1677.6, total_loss = -35.931, pg_loss = -74.103, baseline_loss = 43.693, entropy_loss = -5.5208, learner_queue_size = 32, _tick = 10955, _time = 1.6548e+09, train_seconds = 1.2324e+04)
[2022-06-09 23:33:29,038][root][INFO] - Step 46305280 @ 4092.7 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (step = 46305280, mean_episode_return = 87.885, mean_episode_step = 1026.2, total_loss = 193.84, pg_loss = 125.22, baseline_loss = 74.175, entropy_loss = -5.5469, learner_queue_size = 32, _tick = 10962, _time = 1.6548e+09, train_seconds = 1.2329e+04)
[2022-06-09 23:33:34,042][root][INFO] - Step 46323200 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 46323200, mean_episode_return = None, mean_episode_step = 1432.8, total_loss = 306.64, pg_loss = 241.75, baseline_loss = 70.435, entropy_loss = -5.543, learner_queue_size = 32, _tick = 10965, _time = 1.6548e+09, train_seconds = 1.2334e+04)
[2022-06-09 23:33:39,046][root][INFO] - Step 46341120 @ 3581.2 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 46341120, mean_episode_return = 4.98, mean_episode_step = 1058.4, total_loss = -13.938, pg_loss = -31.402, baseline_loss = 22.926, entropy_loss = -5.4613, learner_queue_size = 32, _tick = 10971, _time = 1.6548e+09, train_seconds = 1.2339e+04)
[2022-06-09 23:33:44,050][root][INFO] - Step 46359040 @ 3581.1 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 46359040, mean_episode_return = 62.004, mean_episode_step = 1283.4, total_loss = 575.44, pg_loss = 403.82, baseline_loss = 177.08, entropy_loss = -5.4626, learner_queue_size = 32, _tick = 10978, _time = 1.6548e+09, train_seconds = 1.2344e+04)
[2022-06-09 23:33:49,054][root][INFO] - Step 46379520 @ 4092.8 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 46379520, mean_episode_return = 130.46, mean_episode_step = 1032.6, total_loss = -30.813, pg_loss = -157.63, baseline_loss = 132.22, entropy_loss = -5.4019, learner_queue_size = 32, _tick = 10985, _time = 1.6548e+09, train_seconds = 1.2349e+04)
[2022-06-09 23:33:54,058][root][INFO] - Step 46397440 @ 3581.2 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 46397440, mean_episode_return = 3.0398, mean_episode_step = 1777.1, total_loss = 57.336, pg_loss = 1.1623, baseline_loss = 61.798, entropy_loss = -5.6236, learner_queue_size = 32, _tick = 10990, _time = 1.6548e+09, train_seconds = 1.2354e+04)
[2022-06-09 23:33:59,062][root][INFO] - Step 46415360 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 46415360, mean_episode_return = 114.11, mean_episode_step = 1115.8, total_loss = 189.31, pg_loss = 136.96, baseline_loss = 58.007, entropy_loss = -5.6598, learner_queue_size = 32, _tick = 10995, _time = 1.6548e+09, train_seconds = 1.2359e+04)
[2022-06-09 23:34:04,069][root][INFO] - Step 46435840 @ 4089.9 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 46435840, mean_episode_return = 75.83, mean_episode_step = 941.74, total_loss = 452.92, pg_loss = 286.7, baseline_loss = 171.76, entropy_loss = -5.5478, learner_queue_size = 32, _tick = 10998, _time = 1.6548e+09, train_seconds = 1.2364e+04)
[2022-06-09 23:34:09,074][root][INFO] - Step 46453760 @ 3580.7 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 46453760, mean_episode_return = 94.298, mean_episode_step = 1119.0, total_loss = -6.0719, pg_loss = -37.201, baseline_loss = 36.339, entropy_loss = -5.2097, learner_queue_size = 32, _tick = 11004, _time = 1.6548e+09, train_seconds = 1.2369e+04)
[2022-06-09 23:34:14,078][root][INFO] - Step 46471680 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 46471680, mean_episode_return = 62.491, mean_episode_step = 1262.1, total_loss = -138.78, pg_loss = -158.38, baseline_loss = 25.132, entropy_loss = -5.5242, learner_queue_size = 32, _tick = 11009, _time = 1.6548e+09, train_seconds = 1.2374e+04)
[2022-06-09 23:34:19,082][root][INFO] - Step 46492160 @ 4092.8 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 46492160, mean_episode_return = 65.084, mean_episode_step = 1029.0, total_loss = 432.61, pg_loss = 355.31, baseline_loss = 82.896, entropy_loss = -5.5988, learner_queue_size = 32, _tick = 11017, _time = 1.6548e+09, train_seconds = 1.2379e+04)
[2022-06-09 23:34:24,086][root][INFO] - Step 46510080 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 46510080, mean_episode_return = 59.289, mean_episode_step = 1077.6, total_loss = 371.44, pg_loss = 251.13, baseline_loss = 125.93, entropy_loss = -5.6238, learner_queue_size = 32, _tick = 11023, _time = 1.6548e+09, train_seconds = 1.2384e+04)
[2022-06-09 23:34:29,090][root][INFO] - Step 46528000 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 46528000, mean_episode_return = 58.734, mean_episode_step = 859.47, total_loss = 667.75, pg_loss = 508.01, baseline_loss = 165.28, entropy_loss = -5.5355, learner_queue_size = 32, _tick = 11029, _time = 1.6548e+09, train_seconds = 1.2389e+04)
[2022-06-09 23:34:34,094][root][INFO] - Step 46545920 @ 3581.2 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 46545920, mean_episode_return = 37.32, mean_episode_step = 688.75, total_loss = -60.335, pg_loss = -107.6, baseline_loss = 52.547, entropy_loss = -5.2839, learner_queue_size = 32, _tick = 11036, _time = 1.6548e+09, train_seconds = 1.2394e+04)
[2022-06-09 23:34:39,098][root][INFO] - Step 46566400 @ 4092.5 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 46566400, mean_episode_return = 50.49, mean_episode_step = 1000.9, total_loss = -39.61, pg_loss = -94.993, baseline_loss = 60.804, entropy_loss = -5.4215, learner_queue_size = 32, _tick = 11043, _time = 1.6548e+09, train_seconds = 1.2399e+04)
[2022-06-09 23:34:44,102][root][INFO] - Step 46584320 @ 3581.3 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 46584320, mean_episode_return = 19.33, mean_episode_step = 1602.8, total_loss = 287.14, pg_loss = 183.46, baseline_loss = 109.24, entropy_loss = -5.5562, learner_queue_size = 32, _tick = 11047, _time = 1.6548e+09, train_seconds = 1.2404e+04)
[2022-06-09 23:34:49,106][root][INFO] - Step 46602240 @ 3581.2 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 46602240, mean_episode_return = 63.24, mean_episode_step = 1288.1, total_loss = 77.075, pg_loss = 51.872, baseline_loss = 30.893, entropy_loss = -5.6904, learner_queue_size = 32, _tick = 11051, _time = 1.6548e+09, train_seconds = 1.2409e+04)
[2022-06-09 23:34:54,110][root][INFO] - Step 46622720 @ 4092.7 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 46622720, mean_episode_return = 44.725, mean_episode_step = 1509.3, total_loss = 117.77, pg_loss = 19.121, baseline_loss = 104.17, entropy_loss = -5.528, learner_queue_size = 32, _tick = 11058, _time = 1.6548e+09, train_seconds = 1.2414e+04)
[2022-06-09 23:34:59,114][root][INFO] - Step 46640640 @ 3581.1 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 46640640, mean_episode_return = 51.556, mean_episode_step = 922.0, total_loss = -66.616, pg_loss = -114.32, baseline_loss = 53.173, entropy_loss = -5.4736, learner_queue_size = 32, _tick = 11062, _time = 1.6548e+09, train_seconds = 1.2419e+04)
[2022-06-09 23:35:04,118][root][INFO] - Step 46658560 @ 3581.1 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 46658560, mean_episode_return = None, mean_episode_step = 977.12, total_loss = 219.02, pg_loss = 149.07, baseline_loss = 75.548, entropy_loss = -5.601, learner_queue_size = 32, _tick = 11064, _time = 1.6548e+09, train_seconds = 1.2424e+04)
[2022-06-09 23:35:09,122][root][INFO] - Step 46676480 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 46676480, mean_episode_return = 29.49, mean_episode_step = 859.8, total_loss = -115.1, pg_loss = -174.73, baseline_loss = 65.229, entropy_loss = -5.5946, learner_queue_size = 32, _tick = 11070, _time = 1.6548e+09, train_seconds = 1.2429e+04)
[2022-06-09 23:35:14,126][root][INFO] - Step 46696960 @ 4092.5 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 46696960, mean_episode_return = 15.377, mean_episode_step = 968.21, total_loss = 278.72, pg_loss = 174.91, baseline_loss = 109.44, entropy_loss = -5.6277, learner_queue_size = 32, _tick = 11076, _time = 1.6548e+09, train_seconds = 1.2434e+04)
[2022-06-09 23:35:19,130][root][INFO] - Step 46714880 @ 3581.4 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 46714880, mean_episode_return = 64.247, mean_episode_step = 931.55, total_loss = -87.421, pg_loss = -200.03, baseline_loss = 118.14, entropy_loss = -5.534, learner_queue_size = 32, _tick = 11083, _time = 1.6548e+09, train_seconds = 1.2439e+04)
[2022-06-09 23:35:24,134][root][INFO] - Step 46735360 @ 4092.6 SPS. Inference batcher size: 78. Learner queue size: 32. Other stats: (step = 46735360, mean_episode_return = 29.83, mean_episode_step = 922.44, total_loss = -74.012, pg_loss = -116.82, baseline_loss = 48.337, entropy_loss = -5.5279, learner_queue_size = 32, _tick = 11090, _time = 1.6548e+09, train_seconds = 1.2444e+04)
[2022-06-09 23:35:29,139][root][INFO] - Step 46753280 @ 3580.6 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 46753280, mean_episode_return = 33.03, mean_episode_step = 991.97, total_loss = 98.381, pg_loss = 36.244, baseline_loss = 67.712, entropy_loss = -5.5755, learner_queue_size = 32, _tick = 11096, _time = 1.6548e+09, train_seconds = 1.2449e+04)
[2022-06-09 23:35:34,142][root][INFO] - Step 46771200 @ 3581.7 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 46771200, mean_episode_return = 151.6, mean_episode_step = 760.07, total_loss = 382.94, pg_loss = 228.62, baseline_loss = 159.91, entropy_loss = -5.5795, learner_queue_size = 32, _tick = 11103, _time = 1.6548e+09, train_seconds = 1.2454e+04)
[2022-06-09 23:35:39,146][root][INFO] - Step 46791680 @ 4092.8 SPS. Inference batcher size: 78. Learner queue size: 32. Other stats: (step = 46791680, mean_episode_return = None, mean_episode_step = 1116.9, total_loss = -67.189, pg_loss = -91.543, baseline_loss = 29.915, entropy_loss = -5.5611, learner_queue_size = 32, _tick = 11109, _time = 1.6548e+09, train_seconds = 1.2459e+04)
[2022-06-09 23:35:44,150][root][INFO] - Step 46809600 @ 3581.2 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 46809600, mean_episode_return = 142.46, mean_episode_step = 1255.3, total_loss = -5.5755, pg_loss = -61.497, baseline_loss = 61.444, entropy_loss = -5.5229, learner_queue_size = 32, _tick = 11111, _time = 1.6548e+09, train_seconds = 1.2464e+04)
[2022-06-09 23:35:49,154][root][INFO] - Step 46830080 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 46830080, mean_episode_return = 31.865, mean_episode_step = 1570.0, total_loss = 91.82, pg_loss = -17.215, baseline_loss = 114.33, entropy_loss = -5.2957, learner_queue_size = 32, _tick = 11118, _time = 1.6548e+09, train_seconds = 1.2469e+04)
[2022-06-09 23:35:54,158][root][INFO] - Step 46848000 @ 3581.1 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (step = 46848000, mean_episode_return = 42.151, mean_episode_step = 2401.7, total_loss = 126.57, pg_loss = 79.764, baseline_loss = 52.338, entropy_loss = -5.5345, learner_queue_size = 32, _tick = 11123, _time = 1.6548e+09, train_seconds = 1.2474e+04)
[2022-06-09 23:35:59,162][root][INFO] - Step 46868480 @ 4092.7 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 46868480, mean_episode_return = 32.246, mean_episode_step = 1023.8, total_loss = 143.2, pg_loss = 77.047, baseline_loss = 71.762, entropy_loss = -5.6056, learner_queue_size = 32, _tick = 11130, _time = 1.6548e+09, train_seconds = 1.2479e+04)
[2022-06-09 23:36:04,166][root][INFO] - Step 46886400 @ 3580.8 SPS. Inference batcher size: 81. Learner queue size: 32. Other stats: (step = 46886400, mean_episode_return = -64.974, mean_episode_step = 1162.0, total_loss = 72.693, pg_loss = 46.158, baseline_loss = 32.16, entropy_loss = -5.6252, learner_queue_size = 32, _tick = 11135, _time = 1.6548e+09, train_seconds = 1.2484e+04)
[2022-06-09 23:36:09,170][root][INFO] - Step 46904320 @ 3581.4 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 46904320, mean_episode_return = None, mean_episode_step = 676.97, total_loss = -16.865, pg_loss = -28.602, baseline_loss = 17.381, entropy_loss = -5.6443, learner_queue_size = 32, _tick = 11140, _time = 1.6548e+09, train_seconds = 1.2489e+04)
[2022-06-09 23:36:14,174][root][INFO] - Step 46922240 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 46922240, mean_episode_return = 22.0, mean_episode_step = 1210.6, total_loss = 95.693, pg_loss = 61.821, baseline_loss = 39.435, entropy_loss = -5.5629, learner_queue_size = 32, _tick = 11147, _time = 1.6548e+09, train_seconds = 1.2494e+04)
[2022-06-09 23:36:19,178][root][INFO] - Step 46940160 @ 3581.2 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 46940160, mean_episode_return = 43.33, mean_episode_step = 944.28, total_loss = 228.74, pg_loss = 160.74, baseline_loss = 73.475, entropy_loss = -5.4788, learner_queue_size = 32, _tick = 11153, _time = 1.6548e+09, train_seconds = 1.2499e+04)
[2022-06-09 23:36:24,182][root][INFO] - Step 46960640 @ 4092.7 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 46960640, mean_episode_return = 11.27, mean_episode_step = 1437.9, total_loss = 329.36, pg_loss = 263.56, baseline_loss = 71.254, entropy_loss = -5.4537, learner_queue_size = 32, _tick = 11160, _time = 1.6548e+09, train_seconds = 1.2504e+04)
[2022-06-09 23:36:29,186][root][INFO] - Step 46978560 @ 3580.9 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 46978560, mean_episode_return = 65.69, mean_episode_step = 782.49, total_loss = 46.39, pg_loss = -15.48, baseline_loss = 66.528, entropy_loss = -4.6575, learner_queue_size = 32, _tick = 11164, _time = 1.6548e+09, train_seconds = 1.2509e+04)
[2022-06-09 23:36:34,190][root][INFO] - Step 46999040 @ 4093.0 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 46999040, mean_episode_return = 10.115, mean_episode_step = 980.91, total_loss = -24.059, pg_loss = -59.177, baseline_loss = 40.335, entropy_loss = -5.2169, learner_queue_size = 32, _tick = 11170, _time = 1.6548e+09, train_seconds = 1.2514e+04)
[2022-06-09 23:36:39,194][root][INFO] - Step 47016960 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 47016960, mean_episode_return = 80.35, mean_episode_step = 1272.7, total_loss = -165.94, pg_loss = -211.78, baseline_loss = 51.128, entropy_loss = -5.2875, learner_queue_size = 32, _tick = 11176, _time = 1.6548e+09, train_seconds = 1.2519e+04)
[2022-06-09 23:36:44,198][root][INFO] - Step 47034880 @ 3581.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 47034880, mean_episode_return = 14.2, mean_episode_step = 807.22, total_loss = 152.93, pg_loss = 75.657, baseline_loss = 82.597, entropy_loss = -5.3247, learner_queue_size = 32, _tick = 11182, _time = 1.6548e+09, train_seconds = 1.2524e+04)
[2022-06-09 23:36:49,202][root][INFO] - Step 47055360 @ 4092.8 SPS. Inference batcher size: 79. Learner queue size: 32. Other stats: (step = 47055360, mean_episode_return = 57.755, mean_episode_step = 947.74, total_loss = 194.76, pg_loss = 123.99, baseline_loss = 76.127, entropy_loss = -5.3594, learner_queue_size = 32, _tick = 11189, _time = 1.6548e+09, train_seconds = 1.2529e+04)
[2022-06-09 23:36:54,206][root][INFO] - Step 47073280 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 47073280, mean_episode_return = None, mean_episode_step = 1001.3, total_loss = 123.89, pg_loss = 72.364, baseline_loss = 56.876, entropy_loss = -5.3453, learner_queue_size = 32, _tick = 11195, _time = 1.6548e+09, train_seconds = 1.2534e+04)
[2022-06-09 23:36:59,211][root][INFO] - Step 47091200 @ 3580.1 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (step = 47091200, mean_episode_return = 37.53, mean_episode_step = 897.8, total_loss = 96.032, pg_loss = 55.036, baseline_loss = 46.271, entropy_loss = -5.2749, learner_queue_size = 32, _tick = 11198, _time = 1.6548e+09, train_seconds = 1.2539e+04)
[2022-06-09 23:37:04,214][root][INFO] - Step 47111680 @ 4093.6 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 47111680, mean_episode_return = 107.15, mean_episode_step = 790.51, total_loss = 240.76, pg_loss = 148.14, baseline_loss = 98.004, entropy_loss = -5.3758, learner_queue_size = 32, _tick = 11204, _time = 1.6548e+09, train_seconds = 1.2544e+04)
[2022-06-09 23:37:09,218][root][INFO] - Step 47129600 @ 3581.4 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 47129600, mean_episode_return = 86.573, mean_episode_step = 967.17, total_loss = -70.962, pg_loss = -185.86, baseline_loss = 120.38, entropy_loss = -5.4876, learner_queue_size = 32, _tick = 11210, _time = 1.6548e+09, train_seconds = 1.2549e+04)
[2022-06-09 23:37:14,222][root][INFO] - Step 47147520 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 47147520, mean_episode_return = 38.72, mean_episode_step = 993.37, total_loss = 64.818, pg_loss = 6.7745, baseline_loss = 63.489, entropy_loss = -5.4461, learner_queue_size = 32, _tick = 11215, _time = 1.6548e+09, train_seconds = 1.2554e+04)
[2022-06-09 23:37:19,226][root][INFO] - Step 47168000 @ 4092.8 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 47168000, mean_episode_return = 55.71, mean_episode_step = 1319.3, total_loss = 106.82, pg_loss = 20.477, baseline_loss = 91.828, entropy_loss = -5.4836, learner_queue_size = 32, _tick = 11221, _time = 1.6548e+09, train_seconds = 1.2559e+04)
[2022-06-09 23:37:24,230][root][INFO] - Step 47185920 @ 3581.2 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 47185920, mean_episode_return = None, mean_episode_step = 1203.9, total_loss = 0.029945, pg_loss = -23.38, baseline_loss = 28.913, entropy_loss = -5.5029, learner_queue_size = 32, _tick = 11227, _time = 1.6548e+09, train_seconds = 1.2564e+04)
[2022-06-09 23:37:29,234][root][INFO] - Step 47203840 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 47203840, mean_episode_return = 79.559, mean_episode_step = 1123.3, total_loss = 290.26, pg_loss = 219.12, baseline_loss = 76.679, entropy_loss = -5.5379, learner_queue_size = 32, _tick = 11231, _time = 1.6548e+09, train_seconds = 1.2569e+04)
[2022-06-09 23:37:34,238][root][INFO] - Step 47224320 @ 4092.8 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 47224320, mean_episode_return = 41.38, mean_episode_step = 1074.4, total_loss = 345.1, pg_loss = 185.06, baseline_loss = 165.4, entropy_loss = -5.3607, learner_queue_size = 32, _tick = 11237, _time = 1.6548e+09, train_seconds = 1.2574e+04)
[2022-06-09 23:37:39,242][root][INFO] - Step 47242240 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 47242240, mean_episode_return = 45.806, mean_episode_step = 1030.5, total_loss = 262.42, pg_loss = 172.04, baseline_loss = 95.509, entropy_loss = -5.1276, learner_queue_size = 32, _tick = 11244, _time = 1.6548e+09, train_seconds = 1.2579e+04)
[2022-06-09 23:37:44,246][root][INFO] - Step 47260160 @ 3581.1 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 47260160, mean_episode_return = 79.24, mean_episode_step = 1069.7, total_loss = -113.19, pg_loss = -170.16, baseline_loss = 62.31, entropy_loss = -5.3386, learner_queue_size = 32, _tick = 11249, _time = 1.6548e+09, train_seconds = 1.2584e+04)
[2022-06-09 23:37:49,250][root][INFO] - Step 47280640 @ 4092.7 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 47280640, mean_episode_return = 146.95, mean_episode_step = 1136.1, total_loss = -136.69, pg_loss = -151.09, baseline_loss = 19.882, entropy_loss = -5.4772, learner_queue_size = 32, _tick = 11256, _time = 1.6548e+09, train_seconds = 1.2589e+04)
[2022-06-09 23:37:54,254][root][INFO] - Step 47298560 @ 3581.1 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 47298560, mean_episode_return = 76.44, mean_episode_step = 1070.6, total_loss = 110.63, pg_loss = 80.982, baseline_loss = 35.349, entropy_loss = -5.7027, learner_queue_size = 32, _tick = 11263, _time = 1.6548e+09, train_seconds = 1.2594e+04)
[2022-06-09 23:37:59,258][root][INFO] - Step 47316480 @ 3581.1 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 47316480, mean_episode_return = None, mean_episode_step = 1189.3, total_loss = 288.96, pg_loss = 242.25, baseline_loss = 52.308, entropy_loss = -5.6039, learner_queue_size = 32, _tick = 11268, _time = 1.6548e+09, train_seconds = 1.2599e+04)
[2022-06-09 23:38:04,262][root][INFO] - Step 47334400 @ 3581.1 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 47334400, mean_episode_return = 244.02, mean_episode_step = 793.57, total_loss = 426.19, pg_loss = 297.44, baseline_loss = 134.34, entropy_loss = -5.5847, learner_queue_size = 32, _tick = 11274, _time = 1.6548e+09, train_seconds = 1.2604e+04)
[2022-06-09 23:38:09,266][root][INFO] - Step 47354880 @ 4092.8 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 47354880, mean_episode_return = 59.354, mean_episode_step = 990.32, total_loss = -97.133, pg_loss = -130.44, baseline_loss = 38.818, entropy_loss = -5.5129, learner_queue_size = 32, _tick = 11279, _time = 1.6548e+09, train_seconds = 1.2609e+04)
[2022-06-09 23:38:14,270][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-09 23:38:14,420][root][INFO] - Step 47372800 @ 3580.9 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 47372800, mean_episode_return = 20.125, mean_episode_step = 1074.7, total_loss = -9.3258, pg_loss = -60.158, baseline_loss = 56.346, entropy_loss = -5.5141, learner_queue_size = 32, _tick = 11284, _time = 1.6548e+09, train_seconds = 1.2614e+04)
[2022-06-09 23:38:19,422][root][INFO] - Step 47393280 @ 3975.4 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 47393280, mean_episode_return = None, mean_episode_step = 1148.6, total_loss = 327.51, pg_loss = 167.92, baseline_loss = 165.02, entropy_loss = -5.4282, learner_queue_size = 32, _tick = 11290, _time = 1.6548e+09, train_seconds = 1.2619e+04)
[2022-06-09 23:38:24,426][root][INFO] - Step 47411200 @ 3581.2 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 47411200, mean_episode_return = 92.425, mean_episode_step = 1372.8, total_loss = 86.83, pg_loss = -19.561, baseline_loss = 111.87, entropy_loss = -5.4804, learner_queue_size = 32, _tick = 11294, _time = 1.6548e+09, train_seconds = 1.2624e+04)
[2022-06-09 23:38:29,430][root][INFO] - Step 47429120 @ 3581.1 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 47429120, mean_episode_return = 86.424, mean_episode_step = 987.81, total_loss = 48.45, pg_loss = -34.836, baseline_loss = 88.772, entropy_loss = -5.4852, learner_queue_size = 32, _tick = 11299, _time = 1.6548e+09, train_seconds = 1.2629e+04)
[2022-06-09 23:38:34,434][root][INFO] - Step 47447040 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 47447040, mean_episode_return = None, mean_episode_step = 1306.2, total_loss = 182.24, pg_loss = 126.25, baseline_loss = 61.379, entropy_loss = -5.3872, learner_queue_size = 32, _tick = 11303, _time = 1.6548e+09, train_seconds = 1.2634e+04)
[2022-06-09 23:38:39,438][root][INFO] - Step 47464960 @ 3581.2 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 47464960, mean_episode_return = 84.399, mean_episode_step = 995.18, total_loss = 14.545, pg_loss = -24.439, baseline_loss = 44.435, entropy_loss = -5.4507, learner_queue_size = 32, _tick = 11309, _time = 1.6548e+09, train_seconds = 1.2639e+04)
[2022-06-09 23:38:44,442][root][INFO] - Step 47482880 @ 3581.2 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 47482880, mean_episode_return = 69.45, mean_episode_step = 1312.1, total_loss = -83.085, pg_loss = -92.044, baseline_loss = 14.347, entropy_loss = -5.3875, learner_queue_size = 32, _tick = 11316, _time = 1.6548e+09, train_seconds = 1.2644e+04)
[2022-06-09 23:38:49,446][root][INFO] - Step 47503360 @ 4092.6 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 47503360, mean_episode_return = 81.529, mean_episode_step = 1081.9, total_loss = 209.95, pg_loss = 149.5, baseline_loss = 65.869, entropy_loss = -5.4215, learner_queue_size = 32, _tick = 11322, _time = 1.6548e+09, train_seconds = 1.2649e+04)
[2022-06-09 23:38:54,450][root][INFO] - Step 47521280 @ 3581.2 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 47521280, mean_episode_return = 67.11, mean_episode_step = 1235.1, total_loss = 40.971, pg_loss = -15.319, baseline_loss = 61.743, entropy_loss = -5.4531, learner_queue_size = 32, _tick = 11326, _time = 1.6548e+09, train_seconds = 1.2654e+04)
[2022-06-09 23:38:59,454][root][INFO] - Step 47539200 @ 3581.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 47539200, mean_episode_return = 58.684, mean_episode_step = 1095.5, total_loss = 46.082, pg_loss = -41.1, baseline_loss = 92.682, entropy_loss = -5.4999, learner_queue_size = 32, _tick = 11331, _time = 1.6548e+09, train_seconds = 1.2659e+04)
[2022-06-09 23:39:04,458][root][INFO] - Step 47559680 @ 4092.2 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 47559680, mean_episode_return = 28.385, mean_episode_step = 971.96, total_loss = 39.867, pg_loss = -24.116, baseline_loss = 69.498, entropy_loss = -5.5152, learner_queue_size = 32, _tick = 11338, _time = 1.6548e+09, train_seconds = 1.2664e+04)
[2022-06-09 23:39:09,462][root][INFO] - Step 47577600 @ 3581.5 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 47577600, mean_episode_return = 87.027, mean_episode_step = 980.47, total_loss = 253.73, pg_loss = 177.65, baseline_loss = 81.689, entropy_loss = -5.6139, learner_queue_size = 32, _tick = 11343, _time = 1.6548e+09, train_seconds = 1.2669e+04)
[2022-06-09 23:39:14,466][root][INFO] - Step 47595520 @ 3581.2 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 47595520, mean_episode_return = 7.2798, mean_episode_step = 881.86, total_loss = 257.58, pg_loss = 156.14, baseline_loss = 107.06, entropy_loss = -5.6158, learner_queue_size = 32, _tick = 11348, _time = 1.6548e+09, train_seconds = 1.2674e+04)
[2022-06-09 23:39:19,470][root][INFO] - Step 47616000 @ 4092.7 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 47616000, mean_episode_return = 84.693, mean_episode_step = 999.48, total_loss = 302.19, pg_loss = 167.81, baseline_loss = 139.91, entropy_loss = -5.5324, learner_queue_size = 32, _tick = 11356, _time = 1.6548e+09, train_seconds = 1.2679e+04)
[2022-06-09 23:39:24,474][root][INFO] - Step 47633920 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 47633920, mean_episode_return = 20.31, mean_episode_step = 1079.2, total_loss = 146.43, pg_loss = 47.388, baseline_loss = 104.64, entropy_loss = -5.5915, learner_queue_size = 32, _tick = 11361, _time = 1.6548e+09, train_seconds = 1.2684e+04)
[2022-06-09 23:39:29,478][root][INFO] - Step 47654400 @ 4092.3 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 47654400, mean_episode_return = 113.7, mean_episode_step = 946.75, total_loss = 24.304, pg_loss = -38.63, baseline_loss = 68.417, entropy_loss = -5.4827, learner_queue_size = 32, _tick = 11368, _time = 1.6548e+09, train_seconds = 1.2689e+04)
[2022-06-09 23:39:34,482][root][INFO] - Step 47672320 @ 3581.5 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 47672320, mean_episode_return = 129.99, mean_episode_step = 870.34, total_loss = 352.87, pg_loss = 245.81, baseline_loss = 112.58, entropy_loss = -5.5293, learner_queue_size = 32, _tick = 11372, _time = 1.6548e+09, train_seconds = 1.2694e+04)
[2022-06-09 23:39:39,486][root][INFO] - Step 47692800 @ 4092.5 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 47692800, mean_episode_return = 89.847, mean_episode_step = 1147.6, total_loss = 186.44, pg_loss = 120.34, baseline_loss = 71.75, entropy_loss = -5.6411, learner_queue_size = 32, _tick = 11378, _time = 1.6548e+09, train_seconds = 1.2699e+04)
[2022-06-09 23:39:44,494][root][INFO] - Step 47710720 @ 3578.4 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 47710720, mean_episode_return = None, mean_episode_step = 1273.4, total_loss = -17.638, pg_loss = -32.029, baseline_loss = 19.93, entropy_loss = -5.5392, learner_queue_size = 32, _tick = 11382, _time = 1.6548e+09, train_seconds = 1.2704e+04)
[2022-06-09 23:39:49,498][root][INFO] - Step 47728640 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 47728640, mean_episode_return = 38.847, mean_episode_step = 1255.4, total_loss = -115.07, pg_loss = -150.64, baseline_loss = 41.105, entropy_loss = -5.535, learner_queue_size = 32, _tick = 11388, _time = 1.6548e+09, train_seconds = 1.2709e+04)
[2022-06-09 23:39:54,502][root][INFO] - Step 47749120 @ 4092.7 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 47749120, mean_episode_return = 71.835, mean_episode_step = 1141.8, total_loss = 6.019, pg_loss = -33.885, baseline_loss = 45.45, entropy_loss = -5.5452, learner_queue_size = 32, _tick = 11394, _time = 1.6548e+09, train_seconds = 1.2714e+04)
[2022-06-09 23:39:59,506][root][INFO] - Step 47767040 @ 3581.1 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 47767040, mean_episode_return = 48.831, mean_episode_step = 1145.5, total_loss = 249.03, pg_loss = 180.33, baseline_loss = 74.081, entropy_loss = -5.3896, learner_queue_size = 32, _tick = 11400, _time = 1.6548e+09, train_seconds = 1.2719e+04)
[2022-06-09 23:40:04,510][root][INFO] - Step 47784960 @ 3581.1 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 47784960, mean_episode_return = 17.35, mean_episode_step = 1210.2, total_loss = -62.501, pg_loss = -100.82, baseline_loss = 43.794, entropy_loss = -5.4793, learner_queue_size = 32, _tick = 11404, _time = 1.6548e+09, train_seconds = 1.2724e+04)
[2022-06-09 23:40:09,514][root][INFO] - Step 47805440 @ 4092.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 47805440, mean_episode_return = None, mean_episode_step = 989.97, total_loss = -21.927, pg_loss = -40.492, baseline_loss = 23.902, entropy_loss = -5.337, learner_queue_size = 32, _tick = 11411, _time = 1.6548e+09, train_seconds = 1.2729e+04)
[2022-06-09 23:40:14,518][root][INFO] - Step 47823360 @ 3581.0 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 47823360, mean_episode_return = 73.905, mean_episode_step = 1021.6, total_loss = -129.08, pg_loss = -173.02, baseline_loss = 49.291, entropy_loss = -5.3518, learner_queue_size = 32, _tick = 11417, _time = 1.6548e+09, train_seconds = 1.2734e+04)
[2022-06-09 23:40:19,522][root][INFO] - Step 47841280 @ 3581.2 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 47841280, mean_episode_return = 11.915, mean_episode_step = 1075.2, total_loss = 149.36, pg_loss = 62.507, baseline_loss = 92.223, entropy_loss = -5.3679, learner_queue_size = 32, _tick = 11422, _time = 1.6548e+09, train_seconds = 1.2739e+04)
[2022-06-09 23:40:24,526][root][INFO] - Step 47861760 @ 4092.6 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 47861760, mean_episode_return = 34.23, mean_episode_step = 1127.0, total_loss = 143.06, pg_loss = 66.467, baseline_loss = 81.871, entropy_loss = -5.2779, learner_queue_size = 32, _tick = 11429, _time = 1.6548e+09, train_seconds = 1.2744e+04)
[2022-06-09 23:40:29,530][root][INFO] - Step 47879680 @ 3581.3 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 47879680, mean_episode_return = 19.34, mean_episode_step = 1022.9, total_loss = -36.902, pg_loss = -136.22, baseline_loss = 104.62, entropy_loss = -5.2969, learner_queue_size = 32, _tick = 11434, _time = 1.6548e+09, train_seconds = 1.2749e+04)
[2022-06-09 23:40:34,534][root][INFO] - Step 47900160 @ 4092.7 SPS. Inference batcher size: 92. Learner queue size: 32. Other stats: (step = 47900160, mean_episode_return = 41.241, mean_episode_step = 1046.7, total_loss = 141.88, pg_loss = 69.951, baseline_loss = 77.422, entropy_loss = -5.4926, learner_queue_size = 32, _tick = 11441, _time = 1.6548e+09, train_seconds = 1.2754e+04)
[2022-06-09 23:40:39,538][root][INFO] - Step 47918080 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 47918080, mean_episode_return = None, mean_episode_step = 1378.2, total_loss = 319.82, pg_loss = 251.16, baseline_loss = 74.196, entropy_loss = -5.5312, learner_queue_size = 32, _tick = 11447, _time = 1.6548e+09, train_seconds = 1.2759e+04)
[2022-06-09 23:40:44,542][root][INFO] - Step 47936000 @ 3581.2 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 47936000, mean_episode_return = 44.833, mean_episode_step = 1243.4, total_loss = -114.72, pg_loss = -156.94, baseline_loss = 47.697, entropy_loss = -5.4732, learner_queue_size = 32, _tick = 11453, _time = 1.6548e+09, train_seconds = 1.2764e+04)
[2022-06-09 23:40:49,546][root][INFO] - Step 47953920 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 47953920, mean_episode_return = 31.785, mean_episode_step = 1240.8, total_loss = 114.61, pg_loss = 36.404, baseline_loss = 83.661, entropy_loss = -5.456, learner_queue_size = 32, _tick = 11460, _time = 1.6548e+09, train_seconds = 1.2769e+04)
[2022-06-09 23:40:54,550][root][INFO] - Step 47974400 @ 4092.8 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 47974400, mean_episode_return = 56.82, mean_episode_step = 1156.2, total_loss = 192.25, pg_loss = 116.05, baseline_loss = 81.54, entropy_loss = -5.3331, learner_queue_size = 32, _tick = 11467, _time = 1.6548e+09, train_seconds = 1.2774e+04)
[2022-06-09 23:40:59,554][root][INFO] - Step 47992320 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 47992320, mean_episode_return = None, mean_episode_step = 1306.0, total_loss = -117.82, pg_loss = -179.67, baseline_loss = 67.306, entropy_loss = -5.4543, learner_queue_size = 32, _tick = 11471, _time = 1.6548e+09, train_seconds = 1.2779e+04)
[2022-06-09 23:41:04,559][root][INFO] - Step 48010240 @ 3580.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 48010240, mean_episode_return = 46.286, mean_episode_step = 1276.0, total_loss = 14.802, pg_loss = -14.444, baseline_loss = 34.541, entropy_loss = -5.2951, learner_queue_size = 32, _tick = 11476, _time = 1.6548e+09, train_seconds = 1.2784e+04)
[2022-06-09 23:41:09,562][root][INFO] - Step 48030720 @ 4093.2 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 48030720, mean_episode_return = 25.19, mean_episode_step = 1248.4, total_loss = 118.54, pg_loss = 46.413, baseline_loss = 77.592, entropy_loss = -5.467, learner_queue_size = 32, _tick = 11481, _time = 1.6548e+09, train_seconds = 1.2789e+04)
[2022-06-09 23:41:14,566][root][INFO] - Step 48048640 @ 3581.2 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 48048640, mean_episode_return = 22.98, mean_episode_step = 1518.8, total_loss = 228.25, pg_loss = 166.15, baseline_loss = 67.541, entropy_loss = -5.4485, learner_queue_size = 32, _tick = 11487, _time = 1.6548e+09, train_seconds = 1.2794e+04)
[2022-06-09 23:41:19,570][root][INFO] - Step 48066560 @ 3581.1 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 48066560, mean_episode_return = -16.461, mean_episode_step = 1199.1, total_loss = 230.29, pg_loss = 154.19, baseline_loss = 81.497, entropy_loss = -5.3943, learner_queue_size = 32, _tick = 11493, _time = 1.6548e+09, train_seconds = 1.2799e+04)
[2022-06-09 23:41:24,574][root][INFO] - Step 48087040 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 48087040, mean_episode_return = None, mean_episode_step = 852.44, total_loss = -15.658, pg_loss = -53.126, baseline_loss = 42.913, entropy_loss = -5.4442, learner_queue_size = 32, _tick = 11500, _time = 1.6548e+09, train_seconds = 1.2804e+04)
[2022-06-09 23:41:29,578][root][INFO] - Step 48104960 @ 3581.2 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 48104960, mean_episode_return = 56.859, mean_episode_step = 1421.8, total_loss = 156.6, pg_loss = 76.439, baseline_loss = 85.607, entropy_loss = -5.4494, learner_queue_size = 32, _tick = 11506, _time = 1.6548e+09, train_seconds = 1.2809e+04)
[2022-06-09 23:41:34,582][root][INFO] - Step 48122880 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 48122880, mean_episode_return = None, mean_episode_step = 1064.8, total_loss = 346.96, pg_loss = 270.69, baseline_loss = 81.606, entropy_loss = -5.3373, learner_queue_size = 32, _tick = 11509, _time = 1.6548e+09, train_seconds = 1.2814e+04)
[2022-06-09 23:41:39,586][root][INFO] - Step 48140800 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 48140800, mean_episode_return = 41.317, mean_episode_step = 1214.4, total_loss = -143.69, pg_loss = -189.7, baseline_loss = 51.194, entropy_loss = -5.1823, learner_queue_size = 32, _tick = 11515, _time = 1.6548e+09, train_seconds = 1.2819e+04)
[2022-06-09 23:41:44,590][root][INFO] - Step 48161280 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 48161280, mean_episode_return = 0.79, mean_episode_step = 1251.9, total_loss = 111.09, pg_loss = 27.38, baseline_loss = 89.036, entropy_loss = -5.3282, learner_queue_size = 32, _tick = 11523, _time = 1.6548e+09, train_seconds = 1.2824e+04)
[2022-06-09 23:41:49,594][root][INFO] - Step 48179200 @ 3581.2 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 48179200, mean_episode_return = 42.305, mean_episode_step = 894.3, total_loss = 103.48, pg_loss = 23.574, baseline_loss = 85.1, entropy_loss = -5.1919, learner_queue_size = 32, _tick = 11526, _time = 1.6548e+09, train_seconds = 1.2829e+04)
[2022-06-09 23:41:54,598][root][INFO] - Step 48199680 @ 4092.5 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 48199680, mean_episode_return = 140.32, mean_episode_step = 1195.1, total_loss = -8.1975, pg_loss = -44.426, baseline_loss = 41.485, entropy_loss = -5.2565, learner_queue_size = 32, _tick = 11530, _time = 1.6548e+09, train_seconds = 1.2834e+04)
[2022-06-09 23:41:59,602][root][INFO] - Step 48217600 @ 3581.3 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 48217600, mean_episode_return = None, mean_episode_step = 1000.6, total_loss = -65.144, pg_loss = -104.79, baseline_loss = 44.7, entropy_loss = -5.0582, learner_queue_size = 32, _tick = 11533, _time = 1.6548e+09, train_seconds = 1.2839e+04)
[2022-06-09 23:42:04,606][root][INFO] - Step 48235520 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 48235520, mean_episode_return = 38.35, mean_episode_step = 1116.6, total_loss = 262.05, pg_loss = 161.54, baseline_loss = 105.81, entropy_loss = -5.3089, learner_queue_size = 32, _tick = 11539, _time = 1.6548e+09, train_seconds = 1.2844e+04)
[2022-06-09 23:42:09,610][root][INFO] - Step 48256000 @ 4092.7 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 48256000, mean_episode_return = 27.18, mean_episode_step = 1057.8, total_loss = 208.72, pg_loss = 129.99, baseline_loss = 83.842, entropy_loss = -5.1173, learner_queue_size = 32, _tick = 11544, _time = 1.6548e+09, train_seconds = 1.2849e+04)
[2022-06-09 23:42:14,614][root][INFO] - Step 48273920 @ 3581.1 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 48273920, mean_episode_return = 133.75, mean_episode_step = 1271.2, total_loss = -71.588, pg_loss = -98.533, baseline_loss = 31.594, entropy_loss = -4.649, learner_queue_size = 32, _tick = 11549, _time = 1.6548e+09, train_seconds = 1.2854e+04)
[2022-06-09 23:42:19,618][root][INFO] - Step 48291840 @ 3581.2 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 48291840, mean_episode_return = None, mean_episode_step = 1181.5, total_loss = -102.38, pg_loss = -129.45, baseline_loss = 32.137, entropy_loss = -5.0676, learner_queue_size = 32, _tick = 11553, _time = 1.6548e+09, train_seconds = 1.2859e+04)
[2022-06-09 23:42:24,622][root][INFO] - Step 48312320 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 48312320, mean_episode_return = None, mean_episode_step = 1114.0, total_loss = -117.5, pg_loss = -136.87, baseline_loss = 24.668, entropy_loss = -5.2926, learner_queue_size = 32, _tick = 11560, _time = 1.6548e+09, train_seconds = 1.2864e+04)
[2022-06-09 23:42:29,626][root][INFO] - Step 48330240 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 48330240, mean_episode_return = 90.128, mean_episode_step = 954.99, total_loss = -66.15, pg_loss = -92.327, baseline_loss = 31.446, entropy_loss = -5.269, learner_queue_size = 32, _tick = 11567, _time = 1.6548e+09, train_seconds = 1.2869e+04)
[2022-06-09 23:42:34,630][root][INFO] - Step 48350720 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 48350720, mean_episode_return = 76.851, mean_episode_step = 1630.3, total_loss = 4.4794, pg_loss = -30.252, baseline_loss = 39.88, entropy_loss = -5.1483, learner_queue_size = 32, _tick = 11573, _time = 1.6548e+09, train_seconds = 1.2874e+04)
[2022-06-09 23:42:39,634][root][INFO] - Step 48368640 @ 3581.2 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 48368640, mean_episode_return = None, mean_episode_step = 1179.7, total_loss = 208.84, pg_loss = 156.48, baseline_loss = 57.32, entropy_loss = -4.9614, learner_queue_size = 32, _tick = 11579, _time = 1.6548e+09, train_seconds = 1.2879e+04)
[2022-06-09 23:42:44,638][root][INFO] - Step 48389120 @ 4092.6 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 48389120, mean_episode_return = 115.4, mean_episode_step = 1123.4, total_loss = 99.238, pg_loss = 36.769, baseline_loss = 67.748, entropy_loss = -5.279, learner_queue_size = 32, _tick = 11585, _time = 1.6548e+09, train_seconds = 1.2884e+04)
[2022-06-09 23:42:49,642][root][INFO] - Step 48407040 @ 3581.2 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 48407040, mean_episode_return = 64.919, mean_episode_step = 803.57, total_loss = 210.68, pg_loss = 99.197, baseline_loss = 116.71, entropy_loss = -5.2286, learner_queue_size = 32, _tick = 11590, _time = 1.6548e+09, train_seconds = 1.2889e+04)
[2022-06-09 23:42:54,646][root][INFO] - Step 48424960 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 48424960, mean_episode_return = 38.462, mean_episode_step = 979.59, total_loss = -37.605, pg_loss = -52.522, baseline_loss = 19.984, entropy_loss = -5.0664, learner_queue_size = 32, _tick = 11596, _time = 1.6548e+09, train_seconds = 1.2894e+04)
[2022-06-09 23:42:59,650][root][INFO] - Step 48442880 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 48442880, mean_episode_return = 196.86, mean_episode_step = 1058.1, total_loss = 223.37, pg_loss = 100.8, baseline_loss = 127.62, entropy_loss = -5.0466, learner_queue_size = 32, _tick = 11603, _time = 1.6548e+09, train_seconds = 1.29e+04)
[2022-06-09 23:43:04,654][root][INFO] - Step 48458240 @ 3069.6 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 48458240, mean_episode_return = -5.7303, mean_episode_step = 940.44, total_loss = -26.652, pg_loss = -136.0, baseline_loss = 114.65, entropy_loss = -5.2977, learner_queue_size = 32, _tick = 11608, _time = 1.6548e+09, train_seconds = 1.2904e+04)
[2022-06-09 23:43:09,658][root][INFO] - Step 48476160 @ 3581.0 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 48476160, mean_episode_return = None, mean_episode_step = 927.12, total_loss = 212.47, pg_loss = 162.09, baseline_loss = 55.806, entropy_loss = -5.4263, learner_queue_size = 32, _tick = 11614, _time = 1.6548e+09, train_seconds = 1.291e+04)
[2022-06-09 23:43:14,662][root][INFO] - Step 48494080 @ 3581.2 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (step = 48494080, mean_episode_return = None, mean_episode_step = 1152.5, total_loss = 96.366, pg_loss = 63.097, baseline_loss = 38.544, entropy_loss = -5.2741, learner_queue_size = 32, _tick = 11619, _time = 1.6548e+09, train_seconds = 1.2914e+04)
[2022-06-09 23:43:19,666][root][INFO] - Step 48514560 @ 4092.7 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 48514560, mean_episode_return = 71.861, mean_episode_step = 1324.8, total_loss = -108.92, pg_loss = -118.89, baseline_loss = 15.04, entropy_loss = -5.0667, learner_queue_size = 32, _tick = 11625, _time = 1.6548e+09, train_seconds = 1.292e+04)
[2022-06-09 23:43:24,670][root][INFO] - Step 48532480 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 48532480, mean_episode_return = None, mean_episode_step = 1132.8, total_loss = 124.71, pg_loss = 87.746, baseline_loss = 41.871, entropy_loss = -4.9088, learner_queue_size = 32, _tick = 11631, _time = 1.6548e+09, train_seconds = 1.2924e+04)
[2022-06-09 23:43:29,674][root][INFO] - Step 48550400 @ 3581.1 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 48550400, mean_episode_return = 39.46, mean_episode_step = 964.19, total_loss = -98.694, pg_loss = -160.81, baseline_loss = 67.324, entropy_loss = -5.2086, learner_queue_size = 32, _tick = 11637, _time = 1.6548e+09, train_seconds = 1.293e+04)
[2022-06-09 23:43:34,678][root][INFO] - Step 48568320 @ 3581.2 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 48568320, mean_episode_return = None, mean_episode_step = 981.12, total_loss = 53.54, pg_loss = 19.738, baseline_loss = 39.107, entropy_loss = -5.3056, learner_queue_size = 32, _tick = 11641, _time = 1.6548e+09, train_seconds = 1.2934e+04)
[2022-06-09 23:43:39,682][root][INFO] - Step 48588800 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 48588800, mean_episode_return = None, mean_episode_step = 1048.8, total_loss = 78.833, pg_loss = 23.332, baseline_loss = 60.791, entropy_loss = -5.2896, learner_queue_size = 32, _tick = 11646, _time = 1.6548e+09, train_seconds = 1.294e+04)
[2022-06-09 23:43:44,686][root][INFO] - Step 48606720 @ 3581.0 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 48606720, mean_episode_return = None, mean_episode_step = 1203.8, total_loss = 149.77, pg_loss = 110.78, baseline_loss = 44.405, entropy_loss = -5.4095, learner_queue_size = 32, _tick = 11651, _time = 1.6548e+09, train_seconds = 1.2944e+04)
[2022-06-09 23:43:49,690][root][INFO] - Step 48624640 @ 3581.2 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (step = 48624640, mean_episode_return = 84.009, mean_episode_step = 842.37, total_loss = 217.67, pg_loss = 160.48, baseline_loss = 62.568, entropy_loss = -5.3868, learner_queue_size = 32, _tick = 11658, _time = 1.6548e+09, train_seconds = 1.295e+04)
[2022-06-09 23:43:54,694][root][INFO] - Step 48642560 @ 3581.2 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (step = 48642560, mean_episode_return = 29.82, mean_episode_step = 1230.9, total_loss = 173.02, pg_loss = 122.22, baseline_loss = 56.251, entropy_loss = -5.4456, learner_queue_size = 32, _tick = 11665, _time = 1.6548e+09, train_seconds = 1.2954e+04)
[2022-06-09 23:43:59,698][root][INFO] - Step 48663040 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 48663040, mean_episode_return = 111.09, mean_episode_step = 1052.0, total_loss = 76.336, pg_loss = 26.913, baseline_loss = 54.497, entropy_loss = -5.075, learner_queue_size = 32, _tick = 11671, _time = 1.6548e+09, train_seconds = 1.296e+04)
[2022-06-09 23:44:04,702][root][INFO] - Step 48680960 @ 3580.8 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 48680960, mean_episode_return = None, mean_episode_step = 1600.5, total_loss = -41.386, pg_loss = -58.652, baseline_loss = 22.625, entropy_loss = -5.3585, learner_queue_size = 32, _tick = 11674, _time = 1.6548e+09, train_seconds = 1.2964e+04)
[2022-06-09 23:44:09,706][root][INFO] - Step 48698880 @ 3581.5 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 48698880, mean_episode_return = 47.57, mean_episode_step = 1221.3, total_loss = -115.38, pg_loss = -158.8, baseline_loss = 48.682, entropy_loss = -5.2573, learner_queue_size = 32, _tick = 11681, _time = 1.6548e+09, train_seconds = 1.297e+04)
[2022-06-09 23:44:14,710][root][INFO] - Step 48719360 @ 4092.7 SPS. Inference batcher size: 79. Learner queue size: 32. Other stats: (step = 48719360, mean_episode_return = 68.309, mean_episode_step = 1215.5, total_loss = 324.38, pg_loss = 225.54, baseline_loss = 103.99, entropy_loss = -5.1485, learner_queue_size = 32, _tick = 11689, _time = 1.6548e+09, train_seconds = 1.2974e+04)
[2022-06-09 23:44:19,714][root][INFO] - Step 48737280 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 48737280, mean_episode_return = 88.535, mean_episode_step = 1639.9, total_loss = 128.63, pg_loss = 70.196, baseline_loss = 63.736, entropy_loss = -5.3014, learner_queue_size = 32, _tick = 11695, _time = 1.6548e+09, train_seconds = 1.298e+04)
[2022-06-09 23:44:24,718][root][INFO] - Step 48755200 @ 3581.0 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 48755200, mean_episode_return = 57.843, mean_episode_step = 1375.8, total_loss = 80.984, pg_loss = 21.205, baseline_loss = 65.202, entropy_loss = -5.4231, learner_queue_size = 32, _tick = 11701, _time = 1.6548e+09, train_seconds = 1.2984e+04)
[2022-06-09 23:44:29,722][root][INFO] - Step 48775680 @ 4092.9 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 48775680, mean_episode_return = 45.805, mean_episode_step = 881.88, total_loss = -176.29, pg_loss = -195.13, baseline_loss = 24.297, entropy_loss = -5.4532, learner_queue_size = 32, _tick = 11709, _time = 1.6548e+09, train_seconds = 1.299e+04)
[2022-06-09 23:44:34,726][root][INFO] - Step 48793600 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 48793600, mean_episode_return = 31.05, mean_episode_step = 992.34, total_loss = -53.706, pg_loss = -70.603, baseline_loss = 22.371, entropy_loss = -5.4744, learner_queue_size = 32, _tick = 11714, _time = 1.6548e+09, train_seconds = 1.2994e+04)
[2022-06-09 23:44:39,730][root][INFO] - Step 48811520 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 48811520, mean_episode_return = 30.3, mean_episode_step = 1388.9, total_loss = -165.11, pg_loss = -184.84, baseline_loss = 25.196, entropy_loss = -5.4686, learner_queue_size = 32, _tick = 11718, _time = 1.6548e+09, train_seconds = 1.3e+04)
[2022-06-09 23:44:44,734][root][INFO] - Step 48826880 @ 3069.5 SPS. Inference batcher size: 78. Learner queue size: 32. Other stats: (step = 48826880, mean_episode_return = 95.756, mean_episode_step = 1335.7, total_loss = 70.315, pg_loss = 11.707, baseline_loss = 63.987, entropy_loss = -5.3798, learner_queue_size = 32, _tick = 11723, _time = 1.6548e+09, train_seconds = 1.3004e+04)
[2022-06-09 23:44:49,738][root][INFO] - Step 48844800 @ 3581.1 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 48844800, mean_episode_return = None, mean_episode_step = 1648.4, total_loss = 99.005, pg_loss = 69.986, baseline_loss = 34.337, entropy_loss = -5.3173, learner_queue_size = 32, _tick = 11726, _time = 1.6548e+09, train_seconds = 1.301e+04)
[2022-06-09 23:44:54,746][root][INFO] - Step 48862720 @ 3578.4 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 48862720, mean_episode_return = 44.16, mean_episode_step = 1167.5, total_loss = -63.815, pg_loss = -144.02, baseline_loss = 85.534, entropy_loss = -5.3281, learner_queue_size = 32, _tick = 11732, _time = 1.6548e+09, train_seconds = 1.3015e+04)
[2022-06-09 23:44:59,750][root][INFO] - Step 48880640 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 48880640, mean_episode_return = 82.081, mean_episode_step = 942.39, total_loss = 530.77, pg_loss = 393.47, baseline_loss = 142.58, entropy_loss = -5.2864, learner_queue_size = 32, _tick = 11737, _time = 1.6548e+09, train_seconds = 1.302e+04)
[2022-06-09 23:45:04,754][root][INFO] - Step 48901120 @ 4092.4 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 48901120, mean_episode_return = 47.527, mean_episode_step = 992.48, total_loss = -19.576, pg_loss = -74.998, baseline_loss = 60.648, entropy_loss = -5.2255, learner_queue_size = 32, _tick = 11742, _time = 1.6548e+09, train_seconds = 1.3025e+04)
[2022-06-09 23:45:09,758][root][INFO] - Step 48919040 @ 3581.4 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 48919040, mean_episode_return = None, mean_episode_step = 1051.8, total_loss = 119.42, pg_loss = 56.174, baseline_loss = 68.659, entropy_loss = -5.4092, learner_queue_size = 32, _tick = 11746, _time = 1.6548e+09, train_seconds = 1.303e+04)
[2022-06-09 23:45:14,762][root][INFO] - Step 48939520 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 48939520, mean_episode_return = 38.19, mean_episode_step = 937.17, total_loss = -99.404, pg_loss = -124.33, baseline_loss = 30.38, entropy_loss = -5.4566, learner_queue_size = 32, _tick = 11752, _time = 1.6548e+09, train_seconds = 1.3035e+04)
[2022-06-09 23:45:19,766][root][INFO] - Step 48957440 @ 3581.2 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 48957440, mean_episode_return = 130.96, mean_episode_step = 1048.2, total_loss = -95.286, pg_loss = -116.26, baseline_loss = 26.421, entropy_loss = -5.4514, learner_queue_size = 32, _tick = 11758, _time = 1.6548e+09, train_seconds = 1.304e+04)
[2022-06-09 23:45:24,770][root][INFO] - Step 48975360 @ 3581.0 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 48975360, mean_episode_return = 64.023, mean_episode_step = 849.79, total_loss = -163.95, pg_loss = -188.17, baseline_loss = 29.617, entropy_loss = -5.399, learner_queue_size = 32, _tick = 11764, _time = 1.6548e+09, train_seconds = 1.3045e+04)
[2022-06-09 23:45:29,774][root][INFO] - Step 48995840 @ 4092.9 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 48995840, mean_episode_return = 201.99, mean_episode_step = 919.07, total_loss = -186.03, pg_loss = -213.86, baseline_loss = 33.178, entropy_loss = -5.35, learner_queue_size = 32, _tick = 11772, _time = 1.6548e+09, train_seconds = 1.305e+04)
[2022-06-09 23:45:34,778][root][INFO] - Step 49013760 @ 3580.9 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 49013760, mean_episode_return = None, mean_episode_step = 1300.2, total_loss = 263.86, pg_loss = 172.71, baseline_loss = 96.403, entropy_loss = -5.2457, learner_queue_size = 32, _tick = 11777, _time = 1.6548e+09, train_seconds = 1.3055e+04)
[2022-06-09 23:45:39,782][root][INFO] - Step 49034240 @ 4092.9 SPS. Inference batcher size: 93. Learner queue size: 32. Other stats: (step = 49034240, mean_episode_return = 12.35, mean_episode_step = 921.82, total_loss = 225.92, pg_loss = 150.65, baseline_loss = 80.642, entropy_loss = -5.3628, learner_queue_size = 32, _tick = 11785, _time = 1.6548e+09, train_seconds = 1.306e+04)
[2022-06-09 23:45:44,786][root][INFO] - Step 49052160 @ 3581.2 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (step = 49052160, mean_episode_return = 62.367, mean_episode_step = 982.36, total_loss = 290.25, pg_loss = 158.1, baseline_loss = 137.41, entropy_loss = -5.2651, learner_queue_size = 32, _tick = 11792, _time = 1.6548e+09, train_seconds = 1.3065e+04)
[2022-06-09 23:45:49,790][root][INFO] - Step 49070080 @ 3580.9 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 49070080, mean_episode_return = 25.01, mean_episode_step = 837.94, total_loss = 168.35, pg_loss = 75.386, baseline_loss = 98.213, entropy_loss = -5.2478, learner_queue_size = 32, _tick = 11797, _time = 1.6548e+09, train_seconds = 1.307e+04)
[2022-06-09 23:45:54,794][root][INFO] - Step 49090560 @ 4093.0 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 49090560, mean_episode_return = 144.57, mean_episode_step = 985.7, total_loss = 87.972, pg_loss = 15.134, baseline_loss = 78.317, entropy_loss = -5.4792, learner_queue_size = 32, _tick = 11804, _time = 1.6548e+09, train_seconds = 1.3075e+04)
[2022-06-09 23:45:59,798][root][INFO] - Step 49108480 @ 3581.2 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 49108480, mean_episode_return = 59.017, mean_episode_step = 869.92, total_loss = 348.29, pg_loss = 237.06, baseline_loss = 116.65, entropy_loss = -5.4137, learner_queue_size = 32, _tick = 11811, _time = 1.6548e+09, train_seconds = 1.308e+04)
[2022-06-09 23:46:04,802][root][INFO] - Step 49126400 @ 3581.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 49126400, mean_episode_return = None, mean_episode_step = 1031.1, total_loss = 96.839, pg_loss = 59.247, baseline_loss = 42.864, entropy_loss = -5.2716, learner_queue_size = 32, _tick = 11815, _time = 1.6548e+09, train_seconds = 1.3085e+04)
[2022-06-09 23:46:09,806][root][INFO] - Step 49146880 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 49146880, mean_episode_return = 45.68, mean_episode_step = 923.34, total_loss = -19.351, pg_loss = -64.682, baseline_loss = 50.479, entropy_loss = -5.1486, learner_queue_size = 32, _tick = 11820, _time = 1.6548e+09, train_seconds = 1.309e+04)
[2022-06-09 23:46:14,810][root][INFO] - Step 49164800 @ 3581.1 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 49164800, mean_episode_return = 78.55, mean_episode_step = 918.29, total_loss = -5.5054, pg_loss = -40.941, baseline_loss = 40.839, entropy_loss = -5.4043, learner_queue_size = 32, _tick = 11826, _time = 1.6548e+09, train_seconds = 1.3095e+04)
[2022-06-09 23:46:19,814][root][INFO] - Step 49182720 @ 3580.8 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 49182720, mean_episode_return = 68.555, mean_episode_step = 901.67, total_loss = 358.22, pg_loss = 252.69, baseline_loss = 111.04, entropy_loss = -5.5062, learner_queue_size = 32, _tick = 11831, _time = 1.6548e+09, train_seconds = 1.31e+04)
[2022-06-09 23:46:24,818][root][INFO] - Step 49200640 @ 3581.4 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 49200640, mean_episode_return = 110.54, mean_episode_step = 986.4, total_loss = 68.145, pg_loss = 24.381, baseline_loss = 49.215, entropy_loss = -5.4513, learner_queue_size = 32, _tick = 11838, _time = 1.6548e+09, train_seconds = 1.3105e+04)
[2022-06-09 23:46:29,822][root][INFO] - Step 49221120 @ 4092.6 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (step = 49221120, mean_episode_return = 104.09, mean_episode_step = 1023.8, total_loss = 536.81, pg_loss = 402.66, baseline_loss = 139.57, entropy_loss = -5.4248, learner_queue_size = 32, _tick = 11845, _time = 1.6548e+09, train_seconds = 1.311e+04)
[2022-06-09 23:46:34,826][root][INFO] - Step 49239040 @ 3581.2 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 49239040, mean_episode_return = 77.44, mean_episode_step = 1031.3, total_loss = 156.81, pg_loss = 70.978, baseline_loss = 91.177, entropy_loss = -5.3468, learner_queue_size = 32, _tick = 11852, _time = 1.6548e+09, train_seconds = 1.3115e+04)
[2022-06-09 23:46:39,830][root][INFO] - Step 49259520 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 49259520, mean_episode_return = 81.853, mean_episode_step = 842.86, total_loss = -103.97, pg_loss = -151.53, baseline_loss = 52.756, entropy_loss = -5.1978, learner_queue_size = 32, _tick = 11859, _time = 1.6548e+09, train_seconds = 1.312e+04)
[2022-06-09 23:46:44,834][root][INFO] - Step 49277440 @ 3581.0 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 49277440, mean_episode_return = 137.55, mean_episode_step = 1765.9, total_loss = -4.1741, pg_loss = -66.379, baseline_loss = 67.427, entropy_loss = -5.2221, learner_queue_size = 32, _tick = 11866, _time = 1.6548e+09, train_seconds = 1.3125e+04)
[2022-06-09 23:46:49,838][root][INFO] - Step 49295360 @ 3581.2 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 49295360, mean_episode_return = 8.4398, mean_episode_step = 962.39, total_loss = -13.208, pg_loss = -38.465, baseline_loss = 30.69, entropy_loss = -5.4331, learner_queue_size = 32, _tick = 11870, _time = 1.6548e+09, train_seconds = 1.313e+04)
[2022-06-09 23:46:54,842][root][INFO] - Step 49315840 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 49315840, mean_episode_return = 11.34, mean_episode_step = 858.01, total_loss = -46.054, pg_loss = -81.412, baseline_loss = 40.69, entropy_loss = -5.3324, learner_queue_size = 32, _tick = 11877, _time = 1.6548e+09, train_seconds = 1.3135e+04)
[2022-06-09 23:46:59,848][root][INFO] - Step 49333760 @ 3579.5 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 49333760, mean_episode_return = 36.212, mean_episode_step = 1304.0, total_loss = 86.421, pg_loss = 44.799, baseline_loss = 47.083, entropy_loss = -5.4603, learner_queue_size = 32, _tick = 11882, _time = 1.6548e+09, train_seconds = 1.314e+04)
[2022-06-09 23:47:04,854][root][INFO] - Step 49351680 @ 3579.8 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 49351680, mean_episode_return = 51.192, mean_episode_step = 862.74, total_loss = -111.71, pg_loss = -161.44, baseline_loss = 54.972, entropy_loss = -5.2368, learner_queue_size = 32, _tick = 11888, _time = 1.6548e+09, train_seconds = 1.3145e+04)
[2022-06-09 23:47:09,858][root][INFO] - Step 49369600 @ 3581.2 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 49369600, mean_episode_return = None, mean_episode_step = 936.97, total_loss = -150.83, pg_loss = -180.86, baseline_loss = 35.274, entropy_loss = -5.2408, learner_queue_size = 32, _tick = 11894, _time = 1.6548e+09, train_seconds = 1.315e+04)
[2022-06-09 23:47:14,862][root][INFO] - Step 49390080 @ 4092.7 SPS. Inference batcher size: 88. Learner queue size: 32. Other stats: (step = 49390080, mean_episode_return = 66.32, mean_episode_step = 880.9, total_loss = -175.84, pg_loss = -186.13, baseline_loss = 15.552, entropy_loss = -5.2625, learner_queue_size = 32, _tick = 11900, _time = 1.6548e+09, train_seconds = 1.3155e+04)
[2022-06-09 23:47:19,866][root][INFO] - Step 49408000 @ 3581.2 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 49408000, mean_episode_return = 31.86, mean_episode_step = 995.34, total_loss = 113.66, pg_loss = 80.802, baseline_loss = 38.289, entropy_loss = -5.4353, learner_queue_size = 32, _tick = 11906, _time = 1.6548e+09, train_seconds = 1.316e+04)
[2022-06-09 23:47:24,870][root][INFO] - Step 49425920 @ 3581.1 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 49425920, mean_episode_return = 33.73, mean_episode_step = 1139.2, total_loss = -137.52, pg_loss = -192.77, baseline_loss = 60.583, entropy_loss = -5.3324, learner_queue_size = 32, _tick = 11911, _time = 1.6548e+09, train_seconds = 1.3165e+04)
[2022-06-09 23:47:29,874][root][INFO] - Step 49446400 @ 4092.8 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 49446400, mean_episode_return = 80.7, mean_episode_step = 928.21, total_loss = 194.07, pg_loss = 103.72, baseline_loss = 95.521, entropy_loss = -5.1644, learner_queue_size = 32, _tick = 11917, _time = 1.6548e+09, train_seconds = 1.317e+04)
[2022-06-09 23:47:34,878][root][INFO] - Step 49464320 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 49464320, mean_episode_return = 13.65, mean_episode_step = 919.64, total_loss = 393.2, pg_loss = 233.58, baseline_loss = 164.99, entropy_loss = -5.361, learner_queue_size = 32, _tick = 11924, _time = 1.6548e+09, train_seconds = 1.3175e+04)
[2022-06-09 23:47:39,882][root][INFO] - Step 49484800 @ 4092.8 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 49484800, mean_episode_return = 56.22, mean_episode_step = 1019.0, total_loss = -50.158, pg_loss = -113.54, baseline_loss = 68.804, entropy_loss = -5.417, learner_queue_size = 32, _tick = 11931, _time = 1.6548e+09, train_seconds = 1.318e+04)
[2022-06-09 23:47:44,886][root][INFO] - Step 49502720 @ 3581.1 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 49502720, mean_episode_return = 31.485, mean_episode_step = 1152.4, total_loss = 317.65, pg_loss = 194.14, baseline_loss = 128.92, entropy_loss = -5.4047, learner_queue_size = 32, _tick = 11938, _time = 1.6548e+09, train_seconds = 1.3185e+04)
[2022-06-09 23:47:49,890][root][INFO] - Step 49520640 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 49520640, mean_episode_return = -10.92, mean_episode_step = 1112.9, total_loss = 136.55, pg_loss = 74.72, baseline_loss = 67.082, entropy_loss = -5.251, learner_queue_size = 32, _tick = 11945, _time = 1.6548e+09, train_seconds = 1.319e+04)
[2022-06-09 23:47:54,894][root][INFO] - Step 49538560 @ 3580.9 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 49538560, mean_episode_return = 64.14, mean_episode_step = 1008.4, total_loss = -47.78, pg_loss = -100.53, baseline_loss = 58.144, entropy_loss = -5.3948, learner_queue_size = 32, _tick = 11952, _time = 1.6548e+09, train_seconds = 1.3195e+04)
[2022-06-09 23:47:59,898][root][INFO] - Step 49559040 @ 4093.0 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (step = 49559040, mean_episode_return = None, mean_episode_step = 1062.3, total_loss = 399.28, pg_loss = 256.19, baseline_loss = 148.56, entropy_loss = -5.4735, learner_queue_size = 32, _tick = 11958, _time = 1.6548e+09, train_seconds = 1.32e+04)
[2022-06-09 23:48:04,902][root][INFO] - Step 49576960 @ 3581.2 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 49576960, mean_episode_return = 104.27, mean_episode_step = 1235.0, total_loss = 452.67, pg_loss = 346.75, baseline_loss = 111.26, entropy_loss = -5.3437, learner_queue_size = 32, _tick = 11962, _time = 1.6548e+09, train_seconds = 1.3205e+04)
[2022-06-09 23:48:09,906][root][INFO] - Step 49594880 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 49594880, mean_episode_return = 129.52, mean_episode_step = 908.26, total_loss = 438.27, pg_loss = 313.48, baseline_loss = 129.99, entropy_loss = -5.1969, learner_queue_size = 32, _tick = 11968, _time = 1.6548e+09, train_seconds = 1.321e+04)
[2022-06-09 23:48:14,910][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-09 23:48:15,100][root][INFO] - Step 49615360 @ 4092.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 49615360, mean_episode_return = 23.302, mean_episode_step = 1570.3, total_loss = -5.0263, pg_loss = -60.453, baseline_loss = 60.742, entropy_loss = -5.3155, learner_queue_size = 32, _tick = 11975, _time = 1.6548e+09, train_seconds = 1.3215e+04)
[2022-06-09 23:48:20,106][root][INFO] - Step 49633280 @ 3449.0 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 49633280, mean_episode_return = None, mean_episode_step = 1092.1, total_loss = 7.7027, pg_loss = -25.67, baseline_loss = 38.752, entropy_loss = -5.3789, learner_queue_size = 32, _tick = 11980, _time = 1.6548e+09, train_seconds = 1.322e+04)
[2022-06-09 23:48:25,110][root][INFO] - Step 49653760 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 49653760, mean_episode_return = 70.054, mean_episode_step = 960.51, total_loss = 361.42, pg_loss = 177.45, baseline_loss = 189.4, entropy_loss = -5.4235, learner_queue_size = 32, _tick = 11986, _time = 1.6548e+09, train_seconds = 1.3225e+04)
[2022-06-09 23:48:30,114][root][INFO] - Step 49671680 @ 3581.1 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 49671680, mean_episode_return = 60.26, mean_episode_step = 1499.2, total_loss = -46.213, pg_loss = -90.934, baseline_loss = 50.147, entropy_loss = -5.4252, learner_queue_size = 32, _tick = 11992, _time = 1.6548e+09, train_seconds = 1.323e+04)
[2022-06-09 23:48:35,118][root][INFO] - Step 49689600 @ 3581.2 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 49689600, mean_episode_return = 56.416, mean_episode_step = 1062.8, total_loss = 29.692, pg_loss = -11.448, baseline_loss = 46.506, entropy_loss = -5.3664, learner_queue_size = 32, _tick = 11998, _time = 1.6548e+09, train_seconds = 1.3235e+04)
[2022-06-09 23:48:40,122][root][INFO] - Step 49710080 @ 4092.7 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 49710080, mean_episode_return = -9.1301, mean_episode_step = 1019.3, total_loss = 37.249, pg_loss = -10.911, baseline_loss = 53.399, entropy_loss = -5.239, learner_queue_size = 32, _tick = 12005, _time = 1.6548e+09, train_seconds = 1.324e+04)
[2022-06-09 23:48:45,126][root][INFO] - Step 49725440 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 49725440, mean_episode_return = -5.95, mean_episode_step = 1041.9, total_loss = 68.773, pg_loss = 11.128, baseline_loss = 62.865, entropy_loss = -5.2194, learner_queue_size = 32, _tick = 12010, _time = 1.6548e+09, train_seconds = 1.3245e+04)
[2022-06-09 23:48:50,130][root][INFO] - Step 49745920 @ 4092.6 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (step = 49745920, mean_episode_return = None, mean_episode_step = 1037.3, total_loss = 50.823, pg_loss = -12.889, baseline_loss = 68.953, entropy_loss = -5.2413, learner_queue_size = 32, _tick = 12016, _time = 1.6548e+09, train_seconds = 1.325e+04)
[2022-06-09 23:48:55,134][root][INFO] - Step 49763840 @ 3581.2 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 49763840, mean_episode_return = 48.5, mean_episode_step = 1854.8, total_loss = -59.875, pg_loss = -123.18, baseline_loss = 68.73, entropy_loss = -5.4287, learner_queue_size = 32, _tick = 12020, _time = 1.6548e+09, train_seconds = 1.3255e+04)
[2022-06-09 23:49:00,138][root][INFO] - Step 49781760 @ 3581.2 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 49781760, mean_episode_return = 58.191, mean_episode_step = 982.08, total_loss = 163.97, pg_loss = 120.81, baseline_loss = 48.61, entropy_loss = -5.4441, learner_queue_size = 32, _tick = 12026, _time = 1.6548e+09, train_seconds = 1.326e+04)
[2022-06-09 23:49:05,142][root][INFO] - Step 49802240 @ 4092.6 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 49802240, mean_episode_return = 11.57, mean_episode_step = 985.04, total_loss = 96.29, pg_loss = 52.42, baseline_loss = 49.41, entropy_loss = -5.5395, learner_queue_size = 32, _tick = 12032, _time = 1.6548e+09, train_seconds = 1.3265e+04)
[2022-06-09 23:49:10,146][root][INFO] - Step 49820160 @ 3581.3 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 49820160, mean_episode_return = 7.1298, mean_episode_step = 1132.3, total_loss = 154.36, pg_loss = 131.51, baseline_loss = 28.509, entropy_loss = -5.6555, learner_queue_size = 32, _tick = 12037, _time = 1.6548e+09, train_seconds = 1.327e+04)
[2022-06-09 23:49:15,150][root][INFO] - Step 49840640 @ 4092.5 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 49840640, mean_episode_return = None, mean_episode_step = 1615.0, total_loss = 392.97, pg_loss = 316.41, baseline_loss = 82.045, entropy_loss = -5.4847, learner_queue_size = 32, _tick = 12043, _time = 1.6548e+09, train_seconds = 1.3275e+04)
[2022-06-09 23:49:20,154][root][INFO] - Step 49858560 @ 3581.3 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 49858560, mean_episode_return = 67.79, mean_episode_step = 1028.6, total_loss = 377.89, pg_loss = 225.0, baseline_loss = 158.3, entropy_loss = -5.4115, learner_queue_size = 32, _tick = 12049, _time = 1.6548e+09, train_seconds = 1.328e+04)
[2022-06-09 23:49:25,158][root][INFO] - Step 49876480 @ 3581.2 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 49876480, mean_episode_return = 60.286, mean_episode_step = 1343.5, total_loss = 9.3649, pg_loss = -33.286, baseline_loss = 47.717, entropy_loss = -5.066, learner_queue_size = 32, _tick = 12052, _time = 1.6548e+09, train_seconds = 1.3285e+04)
[2022-06-09 23:49:30,162][root][INFO] - Step 49894400 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 49894400, mean_episode_return = 59.754, mean_episode_step = 1478.2, total_loss = 70.169, pg_loss = 43.572, baseline_loss = 32.222, entropy_loss = -5.6256, learner_queue_size = 32, _tick = 12057, _time = 1.6548e+09, train_seconds = 1.329e+04)
[2022-06-09 23:49:35,166][root][INFO] - Step 49912320 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 49912320, mean_episode_return = 57.587, mean_episode_step = 1087.5, total_loss = 428.6, pg_loss = 295.43, baseline_loss = 138.43, entropy_loss = -5.2613, learner_queue_size = 32, _tick = 12063, _time = 1.6548e+09, train_seconds = 1.3295e+04)
[2022-06-09 23:49:40,170][root][INFO] - Step 49932800 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 49932800, mean_episode_return = None, mean_episode_step = 1072.3, total_loss = -21.45, pg_loss = -36.151, baseline_loss = 20.201, entropy_loss = -5.4997, learner_queue_size = 32, _tick = 12067, _time = 1.6548e+09, train_seconds = 1.33e+04)
[2022-06-09 23:49:45,174][root][INFO] - Step 49950720 @ 3581.2 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 49950720, mean_episode_return = None, mean_episode_step = 1096.0, total_loss = -38.223, pg_loss = -79.056, baseline_loss = 46.224, entropy_loss = -5.3916, learner_queue_size = 32, _tick = 12072, _time = 1.6548e+09, train_seconds = 1.3305e+04)
[2022-06-09 23:49:50,178][root][INFO] - Step 49968640 @ 3581.2 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 49968640, mean_episode_return = 31.135, mean_episode_step = 1096.1, total_loss = 412.62, pg_loss = 354.86, baseline_loss = 63.214, entropy_loss = -5.4621, learner_queue_size = 32, _tick = 12079, _time = 1.6548e+09, train_seconds = 1.331e+04)
[2022-06-09 23:49:55,182][root][INFO] - Step 49989120 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 49989120, mean_episode_return = 57.565, mean_episode_step = 1067.4, total_loss = -137.81, pg_loss = -152.24, baseline_loss = 19.885, entropy_loss = -5.4587, learner_queue_size = 32, _tick = 12087, _time = 1.6548e+09, train_seconds = 1.3315e+04)
[2022-06-09 23:50:00,186][root][INFO] - Step 50007040 @ 3581.1 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 50007040, mean_episode_return = 62.027, mean_episode_step = 936.86, total_loss = 436.19, pg_loss = 333.76, baseline_loss = 107.94, entropy_loss = -5.5099, learner_queue_size = 32, _tick = 12093, _time = 1.6548e+09, train_seconds = 1.332e+04)
[2022-06-09 23:50:05,190][root][INFO] - Step 50024960 @ 3581.2 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 50024960, mean_episode_return = 97.656, mean_episode_step = 1040.5, total_loss = 27.554, pg_loss = -28.993, baseline_loss = 61.959, entropy_loss = -5.4119, learner_queue_size = 32, _tick = 12099, _time = 1.6548e+09, train_seconds = 1.3325e+04)
[2022-06-09 23:50:10,194][root][INFO] - Step 50045440 @ 4092.7 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 50045440, mean_episode_return = 78.393, mean_episode_step = 1078.3, total_loss = 309.87, pg_loss = 207.04, baseline_loss = 108.22, entropy_loss = -5.381, learner_queue_size = 32, _tick = 12107, _time = 1.6548e+09, train_seconds = 1.333e+04)
[2022-06-09 23:50:15,198][root][INFO] - Step 50063360 @ 3580.9 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 50063360, mean_episode_return = 64.313, mean_episode_step = 889.64, total_loss = 71.216, pg_loss = -1.5814, baseline_loss = 77.893, entropy_loss = -5.0961, learner_queue_size = 32, _tick = 12113, _time = 1.6548e+09, train_seconds = 1.3335e+04)
[2022-06-09 23:50:20,206][root][INFO] - Step 50081280 @ 3578.5 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 50081280, mean_episode_return = None, mean_episode_step = 965.34, total_loss = -69.584, pg_loss = -82.441, baseline_loss = 18.23, entropy_loss = -5.3724, learner_queue_size = 32, _tick = 12119, _time = 1.6548e+09, train_seconds = 1.334e+04)
[2022-06-09 23:50:25,210][root][INFO] - Step 50101760 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 50101760, mean_episode_return = 77.46, mean_episode_step = 916.35, total_loss = 238.94, pg_loss = 180.15, baseline_loss = 64.323, entropy_loss = -5.5334, learner_queue_size = 32, _tick = 12126, _time = 1.6548e+09, train_seconds = 1.3345e+04)
[2022-06-09 23:50:30,214][root][INFO] - Step 50119680 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 50119680, mean_episode_return = None, mean_episode_step = 1597.1, total_loss = 462.0, pg_loss = 372.84, baseline_loss = 94.566, entropy_loss = -5.4022, learner_queue_size = 32, _tick = 12131, _time = 1.6548e+09, train_seconds = 1.335e+04)
[2022-06-09 23:50:35,218][root][INFO] - Step 50140160 @ 4092.8 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 50140160, mean_episode_return = 20.7, mean_episode_step = 1123.9, total_loss = 155.83, pg_loss = 98.18, baseline_loss = 63.09, entropy_loss = -5.438, learner_queue_size = 32, _tick = 12136, _time = 1.6548e+09, train_seconds = 1.3355e+04)
[2022-06-09 23:50:40,222][root][INFO] - Step 50158080 @ 3581.0 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 50158080, mean_episode_return = 18.341, mean_episode_step = 934.26, total_loss = 255.72, pg_loss = 190.44, baseline_loss = 70.658, entropy_loss = -5.3716, learner_queue_size = 32, _tick = 12141, _time = 1.6548e+09, train_seconds = 1.336e+04)
[2022-06-09 23:50:45,226][root][INFO] - Step 50176000 @ 3581.3 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 50176000, mean_episode_return = 62.305, mean_episode_step = 796.05, total_loss = -78.333, pg_loss = -156.24, baseline_loss = 83.306, entropy_loss = -5.3981, learner_queue_size = 32, _tick = 12146, _time = 1.6548e+09, train_seconds = 1.3365e+04)
[2022-06-09 23:50:50,230][root][INFO] - Step 50196480 @ 4092.8 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 50196480, mean_episode_return = 64.845, mean_episode_step = 1486.7, total_loss = -88.93, pg_loss = -120.45, baseline_loss = 37.012, entropy_loss = -5.4909, learner_queue_size = 32, _tick = 12152, _time = 1.6548e+09, train_seconds = 1.337e+04)
[2022-06-09 23:50:55,234][root][INFO] - Step 50214400 @ 3581.1 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 50214400, mean_episode_return = None, mean_episode_step = 1552.1, total_loss = -21.955, pg_loss = -47.977, baseline_loss = 31.499, entropy_loss = -5.4765, learner_queue_size = 32, _tick = 12156, _time = 1.6548e+09, train_seconds = 1.3375e+04)
[2022-06-09 23:51:00,238][root][INFO] - Step 50232320 @ 3581.2 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 50232320, mean_episode_return = None, mean_episode_step = 1024.1, total_loss = -2.4275, pg_loss = -45.618, baseline_loss = 48.739, entropy_loss = -5.5481, learner_queue_size = 32, _tick = 12162, _time = 1.6548e+09, train_seconds = 1.338e+04)
[2022-06-09 23:51:05,242][root][INFO] - Step 50252800 @ 4092.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 50252800, mean_episode_return = -10.42, mean_episode_step = 1401.0, total_loss = 50.116, pg_loss = 8.3838, baseline_loss = 47.219, entropy_loss = -5.4869, learner_queue_size = 32, _tick = 12168, _time = 1.6548e+09, train_seconds = 1.3385e+04)
[2022-06-09 23:51:10,246][root][INFO] - Step 50270720 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 50270720, mean_episode_return = 116.72, mean_episode_step = 956.7, total_loss = -35.447, pg_loss = -56.323, baseline_loss = 26.438, entropy_loss = -5.5625, learner_queue_size = 32, _tick = 12174, _time = 1.6548e+09, train_seconds = 1.339e+04)
[2022-06-09 23:51:15,250][root][INFO] - Step 50291200 @ 4092.8 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 50291200, mean_episode_return = 71.29, mean_episode_step = 927.29, total_loss = 146.16, pg_loss = 107.59, baseline_loss = 44.058, entropy_loss = -5.4852, learner_queue_size = 32, _tick = 12180, _time = 1.6548e+09, train_seconds = 1.3395e+04)
[2022-06-09 23:51:20,254][root][INFO] - Step 50309120 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 50309120, mean_episode_return = 4.9399, mean_episode_step = 866.78, total_loss = 238.09, pg_loss = 172.0, baseline_loss = 71.553, entropy_loss = -5.4635, learner_queue_size = 32, _tick = 12184, _time = 1.6548e+09, train_seconds = 1.34e+04)
[2022-06-09 23:51:25,258][root][INFO] - Step 50327040 @ 3581.2 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 50327040, mean_episode_return = 105.92, mean_episode_step = 1778.5, total_loss = 85.073, pg_loss = 34.426, baseline_loss = 56.057, entropy_loss = -5.4096, learner_queue_size = 32, _tick = 12190, _time = 1.6548e+09, train_seconds = 1.3405e+04)
[2022-06-09 23:51:30,262][root][INFO] - Step 50347520 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 50347520, mean_episode_return = 59.505, mean_episode_step = 1126.4, total_loss = 21.191, pg_loss = -61.372, baseline_loss = 87.961, entropy_loss = -5.3974, learner_queue_size = 32, _tick = 12196, _time = 1.6548e+09, train_seconds = 1.341e+04)
[2022-06-09 23:51:35,266][root][INFO] - Step 50365440 @ 3581.1 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 50365440, mean_episode_return = 35.322, mean_episode_step = 965.23, total_loss = 104.17, pg_loss = 36.163, baseline_loss = 73.376, entropy_loss = -5.3679, learner_queue_size = 32, _tick = 12202, _time = 1.6548e+09, train_seconds = 1.3415e+04)
[2022-06-09 23:51:40,270][root][INFO] - Step 50383360 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 50383360, mean_episode_return = 68.451, mean_episode_step = 960.67, total_loss = -9.866, pg_loss = -60.848, baseline_loss = 56.32, entropy_loss = -5.3373, learner_queue_size = 32, _tick = 12208, _time = 1.6548e+09, train_seconds = 1.342e+04)
[2022-06-09 23:51:45,276][root][INFO] - Step 50401280 @ 3579.9 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 50401280, mean_episode_return = 17.78, mean_episode_step = 1172.5, total_loss = 275.51, pg_loss = 188.02, baseline_loss = 92.87, entropy_loss = -5.3801, learner_queue_size = 32, _tick = 12215, _time = 1.6548e+09, train_seconds = 1.3425e+04)
[2022-06-09 23:51:50,278][root][INFO] - Step 50421760 @ 4094.2 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 50421760, mean_episode_return = -1.16, mean_episode_step = 1030.2, total_loss = -5.4277, pg_loss = -40.302, baseline_loss = 40.256, entropy_loss = -5.3817, learner_queue_size = 32, _tick = 12222, _time = 1.6548e+09, train_seconds = 1.343e+04)
[2022-06-09 23:51:55,282][root][INFO] - Step 50439680 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 50439680, mean_episode_return = None, mean_episode_step = 998.06, total_loss = 232.49, pg_loss = 171.97, baseline_loss = 65.897, entropy_loss = -5.3824, learner_queue_size = 32, _tick = 12225, _time = 1.6548e+09, train_seconds = 1.3435e+04)
[2022-06-09 23:52:00,286][root][INFO] - Step 50457600 @ 3581.2 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 50457600, mean_episode_return = None, mean_episode_step = 1193.8, total_loss = 268.76, pg_loss = 193.75, baseline_loss = 80.299, entropy_loss = -5.2876, learner_queue_size = 32, _tick = 12229, _time = 1.6548e+09, train_seconds = 1.344e+04)
[2022-06-09 23:52:05,290][root][INFO] - Step 50478080 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 50478080, mean_episode_return = 102.05, mean_episode_step = 974.3, total_loss = 7.2487, pg_loss = -78.63, baseline_loss = 91.174, entropy_loss = -5.2962, learner_queue_size = 32, _tick = 12236, _time = 1.6548e+09, train_seconds = 1.3445e+04)
[2022-06-09 23:52:10,294][root][INFO] - Step 50496000 @ 3581.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 50496000, mean_episode_return = None, mean_episode_step = 1680.3, total_loss = 65.236, pg_loss = 37.809, baseline_loss = 32.912, entropy_loss = -5.485, learner_queue_size = 32, _tick = 12240, _time = 1.6548e+09, train_seconds = 1.345e+04)
[2022-06-09 23:52:15,298][root][INFO] - Step 50516480 @ 4092.6 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 50516480, mean_episode_return = 75.565, mean_episode_step = 890.16, total_loss = 207.63, pg_loss = 138.12, baseline_loss = 74.863, entropy_loss = -5.3622, learner_queue_size = 32, _tick = 12247, _time = 1.6548e+09, train_seconds = 1.3455e+04)
[2022-06-09 23:52:20,302][root][INFO] - Step 50534400 @ 3581.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 50534400, mean_episode_return = 66.094, mean_episode_step = 1120.7, total_loss = 99.302, pg_loss = 1.6448, baseline_loss = 102.87, entropy_loss = -5.2172, learner_queue_size = 32, _tick = 12251, _time = 1.6548e+09, train_seconds = 1.346e+04)
[2022-06-09 23:52:25,306][root][INFO] - Step 50552320 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 50552320, mean_episode_return = 89.19, mean_episode_step = 1011.8, total_loss = 308.38, pg_loss = 218.6, baseline_loss = 95.04, entropy_loss = -5.2595, learner_queue_size = 32, _tick = 12256, _time = 1.6548e+09, train_seconds = 1.3465e+04)
[2022-06-09 23:52:30,310][root][INFO] - Step 50570240 @ 3581.2 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 50570240, mean_episode_return = 86.579, mean_episode_step = 1175.0, total_loss = 90.583, pg_loss = 27.724, baseline_loss = 68.196, entropy_loss = -5.3373, learner_queue_size = 32, _tick = 12262, _time = 1.6548e+09, train_seconds = 1.347e+04)
[2022-06-09 23:52:35,315][root][INFO] - Step 50590720 @ 4091.7 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 50590720, mean_episode_return = 40.32, mean_episode_step = 793.4, total_loss = 4.3322, pg_loss = -47.394, baseline_loss = 57.005, entropy_loss = -5.2793, learner_queue_size = 32, _tick = 12269, _time = 1.6548e+09, train_seconds = 1.3475e+04)
[2022-06-09 23:52:40,318][root][INFO] - Step 50608640 @ 3582.0 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 50608640, mean_episode_return = 51.495, mean_episode_step = 1182.4, total_loss = -161.9, pg_loss = -180.2, baseline_loss = 23.569, entropy_loss = -5.2641, learner_queue_size = 32, _tick = 12276, _time = 1.6548e+09, train_seconds = 1.348e+04)
[2022-06-09 23:52:45,322][root][INFO] - Step 50629120 @ 4092.7 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 50629120, mean_episode_return = 24.927, mean_episode_step = 1056.1, total_loss = -28.128, pg_loss = -50.52, baseline_loss = 27.83, entropy_loss = -5.4377, learner_queue_size = 32, _tick = 12282, _time = 1.6548e+09, train_seconds = 1.3485e+04)
[2022-06-09 23:52:50,326][root][INFO] - Step 50647040 @ 3581.2 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 50647040, mean_episode_return = -0.34, mean_episode_step = 979.74, total_loss = -23.642, pg_loss = -37.777, baseline_loss = 19.518, entropy_loss = -5.3826, learner_queue_size = 32, _tick = 12285, _time = 1.6548e+09, train_seconds = 1.349e+04)
[2022-06-09 23:52:55,331][root][INFO] - Step 50664960 @ 3580.8 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 50664960, mean_episode_return = 46.721, mean_episode_step = 1165.1, total_loss = 170.6, pg_loss = 126.66, baseline_loss = 49.218, entropy_loss = -5.2788, learner_queue_size = 32, _tick = 12290, _time = 1.6548e+09, train_seconds = 1.3495e+04)
[2022-06-09 23:53:00,334][root][INFO] - Step 50685440 @ 4092.9 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 50685440, mean_episode_return = 80.325, mean_episode_step = 1102.7, total_loss = 154.94, pg_loss = 80.92, baseline_loss = 79.294, entropy_loss = -5.2713, learner_queue_size = 32, _tick = 12297, _time = 1.6548e+09, train_seconds = 1.35e+04)
[2022-06-09 23:53:05,338][root][INFO] - Step 50703360 @ 3581.3 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 50703360, mean_episode_return = 53.77, mean_episode_step = 1109.4, total_loss = 122.35, pg_loss = 56.424, baseline_loss = 71.227, entropy_loss = -5.3042, learner_queue_size = 32, _tick = 12302, _time = 1.6548e+09, train_seconds = 1.3505e+04)
[2022-06-09 23:53:10,342][root][INFO] - Step 50721280 @ 3581.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 50721280, mean_episode_return = 108.82, mean_episode_step = 1079.9, total_loss = 132.96, pg_loss = 88.101, baseline_loss = 50.115, entropy_loss = -5.2521, learner_queue_size = 32, _tick = 12306, _time = 1.6548e+09, train_seconds = 1.351e+04)
[2022-06-09 23:53:15,346][root][INFO] - Step 50741760 @ 4092.7 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 50741760, mean_episode_return = 39.551, mean_episode_step = 1102.5, total_loss = 225.14, pg_loss = 133.86, baseline_loss = 96.459, entropy_loss = -5.1787, learner_queue_size = 32, _tick = 12312, _time = 1.6548e+09, train_seconds = 1.3515e+04)
[2022-06-09 23:53:20,350][root][INFO] - Step 50759680 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 50759680, mean_episode_return = None, mean_episode_step = 1049.0, total_loss = 121.62, pg_loss = 52.445, baseline_loss = 74.292, entropy_loss = -5.1221, learner_queue_size = 32, _tick = 12315, _time = 1.6548e+09, train_seconds = 1.352e+04)
[2022-06-09 23:53:25,354][root][INFO] - Step 50780160 @ 4092.8 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 50780160, mean_episode_return = 22.647, mean_episode_step = 1230.9, total_loss = 87.917, pg_loss = -2.7885, baseline_loss = 95.887, entropy_loss = -5.181, learner_queue_size = 32, _tick = 12321, _time = 1.6548e+09, train_seconds = 1.3525e+04)
[2022-06-09 23:53:30,358][root][INFO] - Step 50798080 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 50798080, mean_episode_return = 29.101, mean_episode_step = 876.51, total_loss = 157.53, pg_loss = 78.943, baseline_loss = 83.673, entropy_loss = -5.0848, learner_queue_size = 32, _tick = 12328, _time = 1.6548e+09, train_seconds = 1.353e+04)
[2022-06-09 23:53:35,362][root][INFO] - Step 50816000 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 50816000, mean_episode_return = -6.27, mean_episode_step = 921.27, total_loss = 35.947, pg_loss = -42.774, baseline_loss = 83.676, entropy_loss = -4.9553, learner_queue_size = 32, _tick = 12333, _time = 1.6548e+09, train_seconds = 1.3535e+04)
[2022-06-09 23:53:40,366][root][INFO] - Step 50836480 @ 4092.5 SPS. Inference batcher size: 78. Learner queue size: 32. Other stats: (step = 50836480, mean_episode_return = 5.5396, mean_episode_step = 1125.2, total_loss = -185.96, pg_loss = -219.69, baseline_loss = 38.812, entropy_loss = -5.0798, learner_queue_size = 32, _tick = 12339, _time = 1.6548e+09, train_seconds = 1.354e+04)
[2022-06-09 23:53:45,370][root][INFO] - Step 50854400 @ 3581.3 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 50854400, mean_episode_return = -80.589, mean_episode_step = 1319.7, total_loss = 39.369, pg_loss = 10.922, baseline_loss = 33.877, entropy_loss = -5.4294, learner_queue_size = 32, _tick = 12346, _time = 1.6548e+09, train_seconds = 1.3545e+04)
[2022-06-09 23:53:50,374][root][INFO] - Step 50872320 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 50872320, mean_episode_return = 21.895, mean_episode_step = 1045.0, total_loss = 7.2944, pg_loss = -41.825, baseline_loss = 54.437, entropy_loss = -5.3177, learner_queue_size = 32, _tick = 12352, _time = 1.6548e+09, train_seconds = 1.355e+04)
[2022-06-09 23:53:55,378][root][INFO] - Step 50892800 @ 4092.8 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 50892800, mean_episode_return = 17.357, mean_episode_step = 920.79, total_loss = 53.269, pg_loss = -28.086, baseline_loss = 86.671, entropy_loss = -5.3157, learner_queue_size = 32, _tick = 12359, _time = 1.6548e+09, train_seconds = 1.3555e+04)
[2022-06-09 23:54:00,382][root][INFO] - Step 50910720 @ 3581.0 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 50910720, mean_episode_return = None, mean_episode_step = 790.91, total_loss = 16.729, pg_loss = -39.947, baseline_loss = 61.921, entropy_loss = -5.246, learner_queue_size = 32, _tick = 12363, _time = 1.6548e+09, train_seconds = 1.356e+04)
[2022-06-09 23:54:05,386][root][INFO] - Step 50928640 @ 3581.2 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 50928640, mean_episode_return = 106.31, mean_episode_step = 1063.0, total_loss = 543.29, pg_loss = 422.61, baseline_loss = 125.99, entropy_loss = -5.3122, learner_queue_size = 32, _tick = 12368, _time = 1.6548e+09, train_seconds = 1.3565e+04)
[2022-06-09 23:54:10,390][root][INFO] - Step 50949120 @ 4092.6 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 50949120, mean_episode_return = 40.24, mean_episode_step = 1083.7, total_loss = 160.45, pg_loss = 54.278, baseline_loss = 111.51, entropy_loss = -5.3381, learner_queue_size = 32, _tick = 12372, _time = 1.6548e+09, train_seconds = 1.357e+04)
[2022-06-09 23:54:15,394][root][INFO] - Step 50967040 @ 3581.3 SPS. Inference batcher size: 79. Learner queue size: 32. Other stats: (step = 50967040, mean_episode_return = 37.489, mean_episode_step = 963.26, total_loss = 431.34, pg_loss = 302.63, baseline_loss = 133.99, entropy_loss = -5.2806, learner_queue_size = 32, _tick = 12379, _time = 1.6548e+09, train_seconds = 1.3575e+04)
[2022-06-09 23:54:20,398][root][INFO] - Step 50984960 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 50984960, mean_episode_return = None, mean_episode_step = 1054.5, total_loss = 122.49, pg_loss = 73.922, baseline_loss = 53.672, entropy_loss = -5.1089, learner_queue_size = 32, _tick = 12384, _time = 1.6548e+09, train_seconds = 1.358e+04)
[2022-06-09 23:54:25,402][root][INFO] - Step 51005440 @ 4092.8 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 51005440, mean_episode_return = None, mean_episode_step = 1314.8, total_loss = 241.61, pg_loss = 150.59, baseline_loss = 96.387, entropy_loss = -5.3735, learner_queue_size = 32, _tick = 12390, _time = 1.6548e+09, train_seconds = 1.3585e+04)
[2022-06-09 23:54:30,406][root][INFO] - Step 51023360 @ 3580.9 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 51023360, mean_episode_return = 91.52, mean_episode_step = 1012.0, total_loss = -75.788, pg_loss = -99.082, baseline_loss = 28.606, entropy_loss = -5.3113, learner_queue_size = 32, _tick = 12394, _time = 1.6548e+09, train_seconds = 1.359e+04)
[2022-06-09 23:54:35,410][root][INFO] - Step 51043840 @ 4092.9 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 51043840, mean_episode_return = None, mean_episode_step = 1186.8, total_loss = 274.53, pg_loss = 206.25, baseline_loss = 73.691, entropy_loss = -5.4083, learner_queue_size = 32, _tick = 12401, _time = 1.6548e+09, train_seconds = 1.3595e+04)
[2022-06-09 23:54:40,414][root][INFO] - Step 51061760 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 51061760, mean_episode_return = 67.145, mean_episode_step = 1117.0, total_loss = 201.35, pg_loss = 129.47, baseline_loss = 77.131, entropy_loss = -5.2551, learner_queue_size = 32, _tick = 12407, _time = 1.6548e+09, train_seconds = 1.36e+04)
[2022-06-09 23:54:45,418][root][INFO] - Step 51082240 @ 4092.8 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 51082240, mean_episode_return = 90.56, mean_episode_step = 1008.9, total_loss = -132.53, pg_loss = -170.26, baseline_loss = 42.782, entropy_loss = -5.0457, learner_queue_size = 32, _tick = 12411, _time = 1.6548e+09, train_seconds = 1.3605e+04)
[2022-06-09 23:54:50,422][root][INFO] - Step 51100160 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 51100160, mean_episode_return = None, mean_episode_step = 1167.6, total_loss = 153.43, pg_loss = 80.889, baseline_loss = 77.626, entropy_loss = -5.0841, learner_queue_size = 32, _tick = 12416, _time = 1.6548e+09, train_seconds = 1.361e+04)
[2022-06-09 23:54:55,426][root][INFO] - Step 51120640 @ 4092.8 SPS. Inference batcher size: 79. Learner queue size: 32. Other stats: (step = 51120640, mean_episode_return = 61.261, mean_episode_step = 1127.4, total_loss = 162.61, pg_loss = 88.259, baseline_loss = 79.504, entropy_loss = -5.1529, learner_queue_size = 32, _tick = 12421, _time = 1.6548e+09, train_seconds = 1.3615e+04)
[2022-06-09 23:55:00,430][root][INFO] - Step 51138560 @ 3581.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 51138560, mean_episode_return = 43.893, mean_episode_step = 1084.4, total_loss = -5.734, pg_loss = -39.556, baseline_loss = 38.95, entropy_loss = -5.128, learner_queue_size = 32, _tick = 12426, _time = 1.6548e+09, train_seconds = 1.362e+04)
[2022-06-09 23:55:05,435][root][INFO] - Step 51159040 @ 4092.2 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 51159040, mean_episode_return = 4.9194, mean_episode_step = 1368.3, total_loss = 73.932, pg_loss = 28.975, baseline_loss = 49.996, entropy_loss = -5.0385, learner_queue_size = 32, _tick = 12434, _time = 1.6548e+09, train_seconds = 1.3625e+04)
[2022-06-09 23:55:10,438][root][INFO] - Step 51176960 @ 3581.6 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 51176960, mean_episode_return = 8.8097, mean_episode_step = 1115.5, total_loss = -53.76, pg_loss = -65.794, baseline_loss = 16.841, entropy_loss = -4.8071, learner_queue_size = 32, _tick = 12441, _time = 1.6548e+09, train_seconds = 1.363e+04)
[2022-06-09 23:55:15,443][root][INFO] - Step 51194880 @ 3580.8 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 51194880, mean_episode_return = 66.31, mean_episode_step = 1113.1, total_loss = -149.02, pg_loss = -168.95, baseline_loss = 24.61, entropy_loss = -4.677, learner_queue_size = 32, _tick = 12447, _time = 1.6548e+09, train_seconds = 1.3635e+04)
[2022-06-09 23:55:20,446][root][INFO] - Step 51212800 @ 3581.5 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 51212800, mean_episode_return = 3.8396, mean_episode_step = 1011.5, total_loss = -86.796, pg_loss = -104.25, baseline_loss = 22.605, entropy_loss = -5.1468, learner_queue_size = 32, _tick = 12452, _time = 1.6548e+09, train_seconds = 1.364e+04)
[2022-06-09 23:55:25,450][root][INFO] - Step 51230720 @ 3581.1 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 51230720, mean_episode_return = 106.01, mean_episode_step = 915.82, total_loss = 527.79, pg_loss = 400.91, baseline_loss = 132.06, entropy_loss = -5.1748, learner_queue_size = 32, _tick = 12458, _time = 1.6548e+09, train_seconds = 1.3645e+04)
[2022-06-09 23:55:30,454][root][INFO] - Step 51248640 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 51248640, mean_episode_return = 128.47, mean_episode_step = 1136.9, total_loss = 118.76, pg_loss = 45.033, baseline_loss = 78.915, entropy_loss = -5.1877, learner_queue_size = 32, _tick = 12464, _time = 1.6548e+09, train_seconds = 1.365e+04)
[2022-06-09 23:55:35,458][root][INFO] - Step 51269120 @ 4092.8 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 51269120, mean_episode_return = 33.76, mean_episode_step = 1228.0, total_loss = 75.326, pg_loss = 18.446, baseline_loss = 62.085, entropy_loss = -5.2054, learner_queue_size = 32, _tick = 12470, _time = 1.6548e+09, train_seconds = 1.3655e+04)
[2022-06-09 23:55:40,462][root][INFO] - Step 51287040 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 51287040, mean_episode_return = -0.36999, mean_episode_step = 1104.4, total_loss = 79.49, pg_loss = 47.841, baseline_loss = 36.751, entropy_loss = -5.1024, learner_queue_size = 32, _tick = 12477, _time = 1.6548e+09, train_seconds = 1.366e+04)
[2022-06-09 23:55:45,466][root][INFO] - Step 51304960 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 51304960, mean_episode_return = 72.641, mean_episode_step = 958.63, total_loss = 187.22, pg_loss = 111.2, baseline_loss = 80.975, entropy_loss = -4.9588, learner_queue_size = 32, _tick = 12483, _time = 1.6548e+09, train_seconds = 1.3665e+04)
[2022-06-09 23:55:50,470][root][INFO] - Step 51325440 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 51325440, mean_episode_return = 34.88, mean_episode_step = 1065.3, total_loss = -29.057, pg_loss = -68.411, baseline_loss = 44.215, entropy_loss = -4.8606, learner_queue_size = 32, _tick = 12490, _time = 1.6548e+09, train_seconds = 1.367e+04)
[2022-06-09 23:55:55,474][root][INFO] - Step 51343360 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 51343360, mean_episode_return = 168.45, mean_episode_step = 1067.0, total_loss = -48.936, pg_loss = -99.387, baseline_loss = 55.393, entropy_loss = -4.9428, learner_queue_size = 32, _tick = 12494, _time = 1.6548e+09, train_seconds = 1.3675e+04)
[2022-06-09 23:56:00,478][root][INFO] - Step 51361280 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 51361280, mean_episode_return = 34.69, mean_episode_step = 831.66, total_loss = 267.25, pg_loss = 171.41, baseline_loss = 101.09, entropy_loss = -5.2516, learner_queue_size = 32, _tick = 12499, _time = 1.6548e+09, train_seconds = 1.368e+04)
[2022-06-09 23:56:05,482][root][INFO] - Step 51379200 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 51379200, mean_episode_return = None, mean_episode_step = 972.53, total_loss = 41.728, pg_loss = 6.2496, baseline_loss = 40.661, entropy_loss = -5.1821, learner_queue_size = 32, _tick = 12505, _time = 1.6548e+09, train_seconds = 1.3685e+04)
[2022-06-09 23:56:10,486][root][INFO] - Step 51399680 @ 4092.6 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 51399680, mean_episode_return = -1.6797, mean_episode_step = 1499.4, total_loss = 54.345, pg_loss = -12.744, baseline_loss = 72.223, entropy_loss = -5.1335, learner_queue_size = 32, _tick = 12512, _time = 1.6548e+09, train_seconds = 1.369e+04)
[2022-06-09 23:56:15,490][root][INFO] - Step 51417600 @ 3581.3 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 51417600, mean_episode_return = -4.8204, mean_episode_step = 1304.9, total_loss = 53.27, pg_loss = -0.2348, baseline_loss = 58.746, entropy_loss = -5.2411, learner_queue_size = 32, _tick = 12518, _time = 1.6548e+09, train_seconds = 1.3695e+04)
[2022-06-09 23:56:20,494][root][INFO] - Step 51438080 @ 4092.8 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 51438080, mean_episode_return = 20.595, mean_episode_step = 1023.1, total_loss = 131.59, pg_loss = 75.848, baseline_loss = 60.811, entropy_loss = -5.0701, learner_queue_size = 32, _tick = 12523, _time = 1.6548e+09, train_seconds = 1.37e+04)
[2022-06-09 23:56:25,498][root][INFO] - Step 51456000 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 51456000, mean_episode_return = 41.621, mean_episode_step = 1253.0, total_loss = -153.45, pg_loss = -214.57, baseline_loss = 66.155, entropy_loss = -5.0344, learner_queue_size = 32, _tick = 12530, _time = 1.6548e+09, train_seconds = 1.3705e+04)
[2022-06-09 23:56:30,502][root][INFO] - Step 51473920 @ 3581.1 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 51473920, mean_episode_return = 103.73, mean_episode_step = 830.59, total_loss = 309.19, pg_loss = 215.11, baseline_loss = 99.259, entropy_loss = -5.1802, learner_queue_size = 32, _tick = 12534, _time = 1.6548e+09, train_seconds = 1.371e+04)
[2022-06-09 23:56:35,506][root][INFO] - Step 51494400 @ 4092.7 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 51494400, mean_episode_return = 144.98, mean_episode_step = 1025.3, total_loss = 21.967, pg_loss = -37.195, baseline_loss = 64.198, entropy_loss = -5.036, learner_queue_size = 32, _tick = 12541, _time = 1.6548e+09, train_seconds = 1.3715e+04)
[2022-06-09 23:56:40,510][root][INFO] - Step 51512320 @ 3581.1 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 51512320, mean_episode_return = 73.499, mean_episode_step = 1407.7, total_loss = 260.86, pg_loss = 114.58, baseline_loss = 151.47, entropy_loss = -5.1874, learner_queue_size = 32, _tick = 12547, _time = 1.6548e+09, train_seconds = 1.372e+04)
[2022-06-09 23:56:45,516][root][INFO] - Step 51530240 @ 3579.4 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 51530240, mean_episode_return = None, mean_episode_step = 1271.0, total_loss = 162.31, pg_loss = 117.59, baseline_loss = 50.078, entropy_loss = -5.3553, learner_queue_size = 32, _tick = 12551, _time = 1.6548e+09, train_seconds = 1.3725e+04)
[2022-06-09 23:56:50,522][root][INFO] - Step 51548160 @ 3580.0 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 51548160, mean_episode_return = 33.83, mean_episode_step = 1091.6, total_loss = 178.03, pg_loss = 123.86, baseline_loss = 59.401, entropy_loss = -5.2275, learner_queue_size = 32, _tick = 12557, _time = 1.6548e+09, train_seconds = 1.373e+04)
[2022-06-09 23:56:55,526][root][INFO] - Step 51568640 @ 4092.8 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 51568640, mean_episode_return = None, mean_episode_step = 1386.3, total_loss = 108.53, pg_loss = 63.438, baseline_loss = 50.281, entropy_loss = -5.1864, learner_queue_size = 32, _tick = 12563, _time = 1.6548e+09, train_seconds = 1.3735e+04)
[2022-06-09 23:57:00,530][root][INFO] - Step 51586560 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 51586560, mean_episode_return = 79.485, mean_episode_step = 1427.1, total_loss = 181.46, pg_loss = 24.386, baseline_loss = 162.19, entropy_loss = -5.1159, learner_queue_size = 32, _tick = 12566, _time = 1.6548e+09, train_seconds = 1.374e+04)
[2022-06-09 23:57:05,534][root][INFO] - Step 51604480 @ 3581.2 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 51604480, mean_episode_return = None, mean_episode_step = 1007.2, total_loss = -114.19, pg_loss = -140.43, baseline_loss = 31.456, entropy_loss = -5.2135, learner_queue_size = 32, _tick = 12570, _time = 1.6548e+09, train_seconds = 1.3745e+04)
[2022-06-09 23:57:10,538][root][INFO] - Step 51624960 @ 4092.7 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 51624960, mean_episode_return = 44.26, mean_episode_step = 1208.5, total_loss = 314.7, pg_loss = 220.75, baseline_loss = 99.15, entropy_loss = -5.205, learner_queue_size = 32, _tick = 12577, _time = 1.6548e+09, train_seconds = 1.375e+04)
[2022-06-09 23:57:15,542][root][INFO] - Step 51642880 @ 3581.1 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 51642880, mean_episode_return = 74.795, mean_episode_step = 1148.1, total_loss = -137.62, pg_loss = -156.64, baseline_loss = 24.244, entropy_loss = -5.2253, learner_queue_size = 32, _tick = 12583, _time = 1.6548e+09, train_seconds = 1.3755e+04)
[2022-06-09 23:57:20,546][root][INFO] - Step 51660800 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 51660800, mean_episode_return = 32.278, mean_episode_step = 1170.1, total_loss = -192.84, pg_loss = -264.71, baseline_loss = 77.036, entropy_loss = -5.1686, learner_queue_size = 32, _tick = 12590, _time = 1.6548e+09, train_seconds = 1.376e+04)
[2022-06-09 23:57:25,550][root][INFO] - Step 51678720 @ 3581.2 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 51678720, mean_episode_return = 52.125, mean_episode_step = 797.18, total_loss = -144.34, pg_loss = -187.58, baseline_loss = 48.271, entropy_loss = -5.027, learner_queue_size = 32, _tick = 12596, _time = 1.6548e+09, train_seconds = 1.3765e+04)
[2022-06-09 23:57:30,554][root][INFO] - Step 51696640 @ 3581.2 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 51696640, mean_episode_return = 68.915, mean_episode_step = 1289.3, total_loss = 73.658, pg_loss = 4.714, baseline_loss = 74.11, entropy_loss = -5.1656, learner_queue_size = 32, _tick = 12602, _time = 1.6548e+09, train_seconds = 1.377e+04)
[2022-06-09 23:57:35,558][root][INFO] - Step 51712000 @ 3069.5 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (step = 51712000, mean_episode_return = None, mean_episode_step = 1426.9, total_loss = 34.226, pg_loss = 9.6421, baseline_loss = 29.912, entropy_loss = -5.3285, learner_queue_size = 32, _tick = 12603, _time = 1.6548e+09, train_seconds = 1.3775e+04)
[2022-06-09 23:57:40,562][root][INFO] - Step 51729920 @ 3581.2 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 51729920, mean_episode_return = 107.41, mean_episode_step = 1110.6, total_loss = -95.524, pg_loss = -128.02, baseline_loss = 37.725, entropy_loss = -5.2334, learner_queue_size = 32, _tick = 12608, _time = 1.6548e+09, train_seconds = 1.378e+04)
[2022-06-09 23:57:45,566][root][INFO] - Step 51747840 @ 3581.1 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 51747840, mean_episode_return = None, mean_episode_step = 1146.1, total_loss = 204.56, pg_loss = 125.06, baseline_loss = 84.774, entropy_loss = -5.269, learner_queue_size = 32, _tick = 12614, _time = 1.6548e+09, train_seconds = 1.3785e+04)
[2022-06-09 23:57:50,570][root][INFO] - Step 51765760 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 51765760, mean_episode_return = 14.441, mean_episode_step = 1035.8, total_loss = 301.0, pg_loss = 134.42, baseline_loss = 171.54, entropy_loss = -4.958, learner_queue_size = 32, _tick = 12620, _time = 1.6548e+09, train_seconds = 1.379e+04)
[2022-06-09 23:57:55,577][root][INFO] - Step 51786240 @ 4090.2 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 51786240, mean_episode_return = 53.681, mean_episode_step = 1488.4, total_loss = -173.34, pg_loss = -210.95, baseline_loss = 42.676, entropy_loss = -5.0603, learner_queue_size = 32, _tick = 12627, _time = 1.6548e+09, train_seconds = 1.3795e+04)
[2022-06-09 23:58:00,582][root][INFO] - Step 51804160 @ 3580.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 51804160, mean_episode_return = 112.82, mean_episode_step = 1119.7, total_loss = -244.4, pg_loss = -255.06, baseline_loss = 15.855, entropy_loss = -5.1944, learner_queue_size = 32, _tick = 12630, _time = 1.6548e+09, train_seconds = 1.38e+04)
[2022-06-09 23:58:05,586][root][INFO] - Step 51819520 @ 3069.5 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 51819520, mean_episode_return = None, mean_episode_step = 1044.7, total_loss = -66.028, pg_loss = -94.125, baseline_loss = 33.471, entropy_loss = -5.3738, learner_queue_size = 32, _tick = 12635, _time = 1.6548e+09, train_seconds = 1.3805e+04)
[2022-06-09 23:58:10,590][root][INFO] - Step 51837440 @ 3581.2 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 51837440, mean_episode_return = 61.595, mean_episode_step = 1374.0, total_loss = 83.482, pg_loss = 1.1116, baseline_loss = 87.588, entropy_loss = -5.2185, learner_queue_size = 32, _tick = 12642, _time = 1.6548e+09, train_seconds = 1.381e+04)
[2022-06-09 23:58:15,594][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-09 23:58:15,765][root][INFO] - Step 51857920 @ 4092.6 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 51857920, mean_episode_return = 29.44, mean_episode_step = 871.26, total_loss = -58.209, pg_loss = -88.956, baseline_loss = 36.035, entropy_loss = -5.2878, learner_queue_size = 32, _tick = 12650, _time = 1.6548e+09, train_seconds = 1.3815e+04)
[2022-06-09 23:58:20,770][root][INFO] - Step 51875840 @ 3462.3 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 51875840, mean_episode_return = 80.907, mean_episode_step = 1065.8, total_loss = 271.27, pg_loss = 182.06, baseline_loss = 94.567, entropy_loss = -5.3543, learner_queue_size = 32, _tick = 12656, _time = 1.6548e+09, train_seconds = 1.3821e+04)
[2022-06-09 23:58:25,774][root][INFO] - Step 51893760 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 51893760, mean_episode_return = None, mean_episode_step = 1566.3, total_loss = -71.368, pg_loss = -93.852, baseline_loss = 27.799, entropy_loss = -5.3154, learner_queue_size = 32, _tick = 12662, _time = 1.6548e+09, train_seconds = 1.3826e+04)
[2022-06-09 23:58:30,778][root][INFO] - Step 51914240 @ 4092.4 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 51914240, mean_episode_return = None, mean_episode_step = 1079.7, total_loss = 25.457, pg_loss = -12.988, baseline_loss = 43.679, entropy_loss = -5.2339, learner_queue_size = 32, _tick = 12666, _time = 1.6548e+09, train_seconds = 1.3831e+04)
[2022-06-09 23:58:35,782][root][INFO] - Step 51932160 @ 3581.3 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 51932160, mean_episode_return = None, mean_episode_step = 1048.2, total_loss = 160.05, pg_loss = 84.711, baseline_loss = 80.527, entropy_loss = -5.1901, learner_queue_size = 32, _tick = 12671, _time = 1.6548e+09, train_seconds = 1.3836e+04)
[2022-06-09 23:58:40,786][root][INFO] - Step 51950080 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 51950080, mean_episode_return = 16.65, mean_episode_step = 825.07, total_loss = -41.035, pg_loss = -59.281, baseline_loss = 23.551, entropy_loss = -5.3053, learner_queue_size = 32, _tick = 12678, _time = 1.6548e+09, train_seconds = 1.3841e+04)
[2022-06-09 23:58:45,790][root][INFO] - Step 51970560 @ 4092.7 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 51970560, mean_episode_return = 29.92, mean_episode_step = 885.44, total_loss = 4.3975, pg_loss = -42.974, baseline_loss = 52.514, entropy_loss = -5.142, learner_queue_size = 32, _tick = 12685, _time = 1.6548e+09, train_seconds = 1.3846e+04)
[2022-06-09 23:58:50,794][root][INFO] - Step 51988480 @ 3581.2 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 51988480, mean_episode_return = None, mean_episode_step = 1040.0, total_loss = 415.57, pg_loss = 308.98, baseline_loss = 111.94, entropy_loss = -5.3476, learner_queue_size = 32, _tick = 12688, _time = 1.6548e+09, train_seconds = 1.3851e+04)
[2022-06-09 23:58:55,798][root][INFO] - Step 52006400 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 52006400, mean_episode_return = 50.69, mean_episode_step = 1065.1, total_loss = -353.38, pg_loss = -362.1, baseline_loss = 13.986, entropy_loss = -5.2732, learner_queue_size = 32, _tick = 12692, _time = 1.6548e+09, train_seconds = 1.3856e+04)
[2022-06-09 23:59:00,802][root][INFO] - Step 52024320 @ 3581.2 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 52024320, mean_episode_return = 24.377, mean_episode_step = 1389.0, total_loss = 506.12, pg_loss = 365.03, baseline_loss = 146.42, entropy_loss = -5.3306, learner_queue_size = 32, _tick = 12698, _time = 1.6548e+09, train_seconds = 1.3861e+04)
[2022-06-09 23:59:05,806][root][INFO] - Step 52044800 @ 4092.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 52044800, mean_episode_return = None, mean_episode_step = 1157.0, total_loss = -8.0598, pg_loss = -31.326, baseline_loss = 28.611, entropy_loss = -5.3448, learner_queue_size = 32, _tick = 12704, _time = 1.6548e+09, train_seconds = 1.3866e+04)
[2022-06-09 23:59:10,810][root][INFO] - Step 52062720 @ 3581.1 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 52062720, mean_episode_return = None, mean_episode_step = 1080.0, total_loss = -12.891, pg_loss = -46.712, baseline_loss = 39.122, entropy_loss = -5.3004, learner_queue_size = 32, _tick = 12709, _time = 1.6548e+09, train_seconds = 1.3871e+04)
[2022-06-09 23:59:15,814][root][INFO] - Step 52080640 @ 3581.2 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 52080640, mean_episode_return = 46.624, mean_episode_step = 1159.7, total_loss = 12.421, pg_loss = -11.32, baseline_loss = 29.209, entropy_loss = -5.4678, learner_queue_size = 32, _tick = 12715, _time = 1.6548e+09, train_seconds = 1.3876e+04)
[2022-06-09 23:59:20,818][root][INFO] - Step 52101120 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 52101120, mean_episode_return = 50.75, mean_episode_step = 1138.9, total_loss = 306.14, pg_loss = 229.42, baseline_loss = 82.15, entropy_loss = -5.4318, learner_queue_size = 32, _tick = 12723, _time = 1.6548e+09, train_seconds = 1.3881e+04)
[2022-06-09 23:59:25,822][root][INFO] - Step 52119040 @ 3581.1 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 52119040, mean_episode_return = 46.34, mean_episode_step = 925.72, total_loss = 175.45, pg_loss = 119.57, baseline_loss = 61.161, entropy_loss = -5.2872, learner_queue_size = 32, _tick = 12730, _time = 1.6548e+09, train_seconds = 1.3886e+04)
[2022-06-09 23:59:30,826][root][INFO] - Step 52136960 @ 3581.2 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 52136960, mean_episode_return = None, mean_episode_step = 1142.2, total_loss = 355.4, pg_loss = 245.33, baseline_loss = 115.42, entropy_loss = -5.3427, learner_queue_size = 32, _tick = 12736, _time = 1.6548e+09, train_seconds = 1.3891e+04)
[2022-06-09 23:59:35,830][root][INFO] - Step 52157440 @ 4092.8 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 52157440, mean_episode_return = 82.801, mean_episode_step = 1035.4, total_loss = 140.67, pg_loss = 62.394, baseline_loss = 83.533, entropy_loss = -5.2572, learner_queue_size = 32, _tick = 12742, _time = 1.6548e+09, train_seconds = 1.3896e+04)
[2022-06-09 23:59:40,834][root][INFO] - Step 52175360 @ 3581.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 52175360, mean_episode_return = 129.52, mean_episode_step = 1115.5, total_loss = -77.651, pg_loss = -127.18, baseline_loss = 54.716, entropy_loss = -5.1844, learner_queue_size = 32, _tick = 12748, _time = 1.6548e+09, train_seconds = 1.3901e+04)
[2022-06-09 23:59:45,840][root][INFO] - Step 52193280 @ 3579.8 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 52193280, mean_episode_return = None, mean_episode_step = 1080.3, total_loss = 116.65, pg_loss = 37.382, baseline_loss = 84.541, entropy_loss = -5.2742, learner_queue_size = 32, _tick = 12752, _time = 1.6548e+09, train_seconds = 1.3906e+04)
[2022-06-09 23:59:50,842][root][INFO] - Step 52213760 @ 4094.1 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 52213760, mean_episode_return = 16.96, mean_episode_step = 1118.9, total_loss = 33.821, pg_loss = 3.1692, baseline_loss = 35.765, entropy_loss = -5.1132, learner_queue_size = 32, _tick = 12757, _time = 1.6548e+09, train_seconds = 1.3911e+04)
[2022-06-09 23:59:55,846][root][INFO] - Step 52231680 @ 3581.2 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 52231680, mean_episode_return = 163.34, mean_episode_step = 814.1, total_loss = 2.9266, pg_loss = -63.99, baseline_loss = 72.052, entropy_loss = -5.1354, learner_queue_size = 32, _tick = 12763, _time = 1.6548e+09, train_seconds = 1.3916e+04)
[2022-06-10 00:00:00,850][root][INFO] - Step 52249600 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 52249600, mean_episode_return = 57.435, mean_episode_step = 997.7, total_loss = 62.233, pg_loss = 3.2694, baseline_loss = 64.217, entropy_loss = -5.2534, learner_queue_size = 32, _tick = 12768, _time = 1.6548e+09, train_seconds = 1.3921e+04)
[2022-06-10 00:00:05,854][root][INFO] - Step 52270080 @ 4092.7 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 52270080, mean_episode_return = 10.61, mean_episode_step = 1520.5, total_loss = 8.8347, pg_loss = -24.363, baseline_loss = 38.535, entropy_loss = -5.338, learner_queue_size = 32, _tick = 12775, _time = 1.6548e+09, train_seconds = 1.3926e+04)
[2022-06-10 00:00:10,858][root][INFO] - Step 52288000 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 52288000, mean_episode_return = None, mean_episode_step = 1170.8, total_loss = -162.58, pg_loss = -176.1, baseline_loss = 18.744, entropy_loss = -5.2325, learner_queue_size = 32, _tick = 12779, _time = 1.6548e+09, train_seconds = 1.3931e+04)
[2022-06-10 00:00:15,862][root][INFO] - Step 52305920 @ 3581.2 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 52305920, mean_episode_return = None, mean_episode_step = 1345.1, total_loss = 136.66, pg_loss = 85.965, baseline_loss = 55.918, entropy_loss = -5.2229, learner_queue_size = 32, _tick = 12784, _time = 1.6548e+09, train_seconds = 1.3936e+04)
[2022-06-10 00:00:20,866][root][INFO] - Step 52326400 @ 4092.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 52326400, mean_episode_return = 75.435, mean_episode_step = 1203.0, total_loss = 202.76, pg_loss = 130.8, baseline_loss = 77.342, entropy_loss = -5.3814, learner_queue_size = 32, _tick = 12791, _time = 1.6548e+09, train_seconds = 1.3941e+04)
[2022-06-10 00:00:25,870][root][INFO] - Step 52344320 @ 3581.1 SPS. Inference batcher size: 73. Learner queue size: 32. Other stats: (step = 52344320, mean_episode_return = None, mean_episode_step = 907.59, total_loss = 213.34, pg_loss = 139.08, baseline_loss = 79.565, entropy_loss = -5.2994, learner_queue_size = 32, _tick = 12796, _time = 1.6548e+09, train_seconds = 1.3946e+04)
[2022-06-10 00:00:30,874][root][INFO] - Step 52362240 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 52362240, mean_episode_return = 25.75, mean_episode_step = 997.41, total_loss = 238.41, pg_loss = 145.46, baseline_loss = 98.271, entropy_loss = -5.3186, learner_queue_size = 32, _tick = 12801, _time = 1.6548e+09, train_seconds = 1.3951e+04)
[2022-06-10 00:00:35,878][root][INFO] - Step 52380160 @ 3580.9 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 52380160, mean_episode_return = None, mean_episode_step = 938.03, total_loss = 410.13, pg_loss = 298.66, baseline_loss = 116.84, entropy_loss = -5.3753, learner_queue_size = 32, _tick = 12806, _time = 1.6548e+09, train_seconds = 1.3956e+04)
[2022-06-10 00:00:40,882][root][INFO] - Step 52400640 @ 4092.9 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 52400640, mean_episode_return = 35.74, mean_episode_step = 1080.8, total_loss = 952.44, pg_loss = 704.28, baseline_loss = 253.58, entropy_loss = -5.4221, learner_queue_size = 32, _tick = 12814, _time = 1.6548e+09, train_seconds = 1.3961e+04)
[2022-06-10 00:00:45,886][root][INFO] - Step 52418560 @ 3581.1 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 52418560, mean_episode_return = 4.2496, mean_episode_step = 1526.1, total_loss = -44.052, pg_loss = -90.897, baseline_loss = 52.245, entropy_loss = -5.4, learner_queue_size = 32, _tick = 12820, _time = 1.6548e+09, train_seconds = 1.3966e+04)
[2022-06-10 00:00:50,890][root][INFO] - Step 52436480 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 52436480, mean_episode_return = 126.96, mean_episode_step = 945.18, total_loss = -342.49, pg_loss = -398.55, baseline_loss = 61.439, entropy_loss = -5.3756, learner_queue_size = 32, _tick = 12825, _time = 1.6548e+09, train_seconds = 1.3971e+04)
[2022-06-10 00:00:55,894][root][INFO] - Step 52456960 @ 4092.8 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 52456960, mean_episode_return = 78.34, mean_episode_step = 1210.6, total_loss = 151.4, pg_loss = 82.757, baseline_loss = 74.1, entropy_loss = -5.4565, learner_queue_size = 32, _tick = 12833, _time = 1.6548e+09, train_seconds = 1.3976e+04)
[2022-06-10 00:01:00,898][root][INFO] - Step 52474880 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 52474880, mean_episode_return = None, mean_episode_step = 1466.1, total_loss = 164.38, pg_loss = 118.29, baseline_loss = 51.464, entropy_loss = -5.3779, learner_queue_size = 32, _tick = 12839, _time = 1.6548e+09, train_seconds = 1.3981e+04)
[2022-06-10 00:01:05,902][root][INFO] - Step 52495360 @ 4092.6 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 52495360, mean_episode_return = 3.5298, mean_episode_step = 828.32, total_loss = 2.5409, pg_loss = -77.274, baseline_loss = 85.087, entropy_loss = -5.2728, learner_queue_size = 32, _tick = 12844, _time = 1.6548e+09, train_seconds = 1.3986e+04)
[2022-06-10 00:01:10,906][root][INFO] - Step 52513280 @ 3581.2 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (step = 52513280, mean_episode_return = 49.725, mean_episode_step = 982.28, total_loss = -229.8, pg_loss = -243.16, baseline_loss = 18.727, entropy_loss = -5.3732, learner_queue_size = 32, _tick = 12851, _time = 1.6548e+09, train_seconds = 1.3991e+04)
[2022-06-10 00:01:15,910][root][INFO] - Step 52531200 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 52531200, mean_episode_return = 117.85, mean_episode_step = 974.45, total_loss = 134.52, pg_loss = 91.214, baseline_loss = 48.662, entropy_loss = -5.3567, learner_queue_size = 32, _tick = 12857, _time = 1.6548e+09, train_seconds = 1.3996e+04)
[2022-06-10 00:01:20,914][root][INFO] - Step 52551680 @ 4092.8 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 52551680, mean_episode_return = 5.5065, mean_episode_step = 1073.0, total_loss = 38.573, pg_loss = -19.298, baseline_loss = 63.258, entropy_loss = -5.3866, learner_queue_size = 32, _tick = 12863, _time = 1.6548e+09, train_seconds = 1.4001e+04)
[2022-06-10 00:01:25,918][root][INFO] - Step 52569600 @ 3581.0 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 52569600, mean_episode_return = 69.96, mean_episode_step = 1227.7, total_loss = -47.994, pg_loss = -86.804, baseline_loss = 44.194, entropy_loss = -5.3837, learner_queue_size = 32, _tick = 12870, _time = 1.6548e+09, train_seconds = 1.4006e+04)
[2022-06-10 00:01:30,922][root][INFO] - Step 52587520 @ 3581.2 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 52587520, mean_episode_return = 21.41, mean_episode_step = 864.24, total_loss = 335.51, pg_loss = 231.36, baseline_loss = 109.53, entropy_loss = -5.3817, learner_queue_size = 32, _tick = 12877, _time = 1.6548e+09, train_seconds = 1.4011e+04)
[2022-06-10 00:01:35,926][root][INFO] - Step 52605440 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 52605440, mean_episode_return = None, mean_episode_step = 911.97, total_loss = -31.175, pg_loss = -61.012, baseline_loss = 35.257, entropy_loss = -5.42, learner_queue_size = 32, _tick = 12882, _time = 1.6548e+09, train_seconds = 1.4016e+04)
[2022-06-10 00:01:40,930][root][INFO] - Step 52625920 @ 4092.8 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 52625920, mean_episode_return = None, mean_episode_step = 1210.4, total_loss = 329.63, pg_loss = 211.59, baseline_loss = 123.56, entropy_loss = -5.5295, learner_queue_size = 32, _tick = 12888, _time = 1.6548e+09, train_seconds = 1.4021e+04)
[2022-06-10 00:01:45,934][root][INFO] - Step 52643840 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 52643840, mean_episode_return = 25.43, mean_episode_step = 1165.7, total_loss = -225.88, pg_loss = -259.41, baseline_loss = 38.963, entropy_loss = -5.4245, learner_queue_size = 32, _tick = 12894, _time = 1.6548e+09, train_seconds = 1.4026e+04)
[2022-06-10 00:01:50,938][root][INFO] - Step 52661760 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 52661760, mean_episode_return = 66.651, mean_episode_step = 940.6, total_loss = 255.67, pg_loss = 150.38, baseline_loss = 110.64, entropy_loss = -5.3568, learner_queue_size = 32, _tick = 12898, _time = 1.6548e+09, train_seconds = 1.4031e+04)
[2022-06-10 00:01:55,942][root][INFO] - Step 52682240 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 52682240, mean_episode_return = 58.459, mean_episode_step = 898.93, total_loss = -243.67, pg_loss = -386.17, baseline_loss = 147.74, entropy_loss = -5.2343, learner_queue_size = 32, _tick = 12904, _time = 1.6548e+09, train_seconds = 1.4036e+04)
[2022-06-10 00:02:00,946][root][INFO] - Step 52700160 @ 3581.2 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 52700160, mean_episode_return = 9.5897, mean_episode_step = 1193.7, total_loss = -9.8789, pg_loss = -32.318, baseline_loss = 27.79, entropy_loss = -5.3515, learner_queue_size = 32, _tick = 12911, _time = 1.6548e+09, train_seconds = 1.4041e+04)
[2022-06-10 00:02:05,950][root][INFO] - Step 52720640 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 52720640, mean_episode_return = 116.9, mean_episode_step = 1480.2, total_loss = 254.51, pg_loss = 182.83, baseline_loss = 77.119, entropy_loss = -5.4294, learner_queue_size = 32, _tick = 12918, _time = 1.6548e+09, train_seconds = 1.4046e+04)
[2022-06-10 00:02:10,954][root][INFO] - Step 52738560 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 52738560, mean_episode_return = 107.66, mean_episode_step = 1113.7, total_loss = 712.77, pg_loss = 569.35, baseline_loss = 148.84, entropy_loss = -5.4214, learner_queue_size = 32, _tick = 12924, _time = 1.6548e+09, train_seconds = 1.4051e+04)
[2022-06-10 00:02:15,958][root][INFO] - Step 52756480 @ 3581.2 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 52756480, mean_episode_return = 30.881, mean_episode_step = 932.94, total_loss = -30.385, pg_loss = -66.479, baseline_loss = 41.44, entropy_loss = -5.3454, learner_queue_size = 32, _tick = 12928, _time = 1.6548e+09, train_seconds = 1.4056e+04)
[2022-06-10 00:02:20,962][root][INFO] - Step 52776960 @ 4092.8 SPS. Inference batcher size: 91. Learner queue size: 32. Other stats: (step = 52776960, mean_episode_return = 64.22, mean_episode_step = 1167.8, total_loss = -152.71, pg_loss = -166.38, baseline_loss = 18.953, entropy_loss = -5.282, learner_queue_size = 32, _tick = 12934, _time = 1.6548e+09, train_seconds = 1.4061e+04)
[2022-06-10 00:02:25,970][root][INFO] - Step 52794880 @ 3578.2 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 52794880, mean_episode_return = -1.1052, mean_episode_step = 1038.8, total_loss = 120.46, pg_loss = 46.404, baseline_loss = 79.407, entropy_loss = -5.3492, learner_queue_size = 32, _tick = 12939, _time = 1.6548e+09, train_seconds = 1.4066e+04)
[2022-06-10 00:02:30,974][root][INFO] - Step 52812800 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 52812800, mean_episode_return = None, mean_episode_step = 916.62, total_loss = 368.99, pg_loss = 259.64, baseline_loss = 114.61, entropy_loss = -5.2612, learner_queue_size = 32, _tick = 12944, _time = 1.6548e+09, train_seconds = 1.4071e+04)
[2022-06-10 00:02:35,978][root][INFO] - Step 52830720 @ 3581.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 52830720, mean_episode_return = 4.99, mean_episode_step = 1243.5, total_loss = 72.078, pg_loss = -31.307, baseline_loss = 108.73, entropy_loss = -5.3469, learner_queue_size = 32, _tick = 12949, _time = 1.6548e+09, train_seconds = 1.4076e+04)
[2022-06-10 00:02:40,982][root][INFO] - Step 52851200 @ 4092.7 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 52851200, mean_episode_return = 51.716, mean_episode_step = 1344.2, total_loss = -98.26, pg_loss = -136.68, baseline_loss = 43.76, entropy_loss = -5.3445, learner_queue_size = 32, _tick = 12955, _time = 1.6548e+09, train_seconds = 1.4081e+04)
[2022-06-10 00:02:45,987][root][INFO] - Step 52869120 @ 3580.2 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 52869120, mean_episode_return = 15.28, mean_episode_step = 1093.7, total_loss = 58.298, pg_loss = 17.498, baseline_loss = 46.275, entropy_loss = -5.4753, learner_queue_size = 32, _tick = 12960, _time = 1.6548e+09, train_seconds = 1.4086e+04)
[2022-06-10 00:02:50,994][root][INFO] - Step 52887040 @ 3579.1 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 52887040, mean_episode_return = None, mean_episode_step = 980.78, total_loss = -69.008, pg_loss = -84.055, baseline_loss = 20.387, entropy_loss = -5.3393, learner_queue_size = 32, _tick = 12966, _time = 1.6548e+09, train_seconds = 1.4091e+04)
[2022-06-10 00:02:55,998][root][INFO] - Step 52907520 @ 4092.9 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 52907520, mean_episode_return = 22.35, mean_episode_step = 1151.9, total_loss = -37.287, pg_loss = -49.662, baseline_loss = 17.636, entropy_loss = -5.2612, learner_queue_size = 32, _tick = 12970, _time = 1.6548e+09, train_seconds = 1.4096e+04)
[2022-06-10 00:03:01,002][root][INFO] - Step 52925440 @ 3581.2 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 52925440, mean_episode_return = 25.09, mean_episode_step = 994.54, total_loss = 50.3, pg_loss = 10.452, baseline_loss = 44.864, entropy_loss = -5.0152, learner_queue_size = 32, _tick = 12976, _time = 1.6548e+09, train_seconds = 1.4101e+04)
[2022-06-10 00:03:06,006][root][INFO] - Step 52945920 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 52945920, mean_episode_return = 74.021, mean_episode_step = 1044.6, total_loss = -94.339, pg_loss = -124.96, baseline_loss = 35.51, entropy_loss = -4.8913, learner_queue_size = 32, _tick = 12981, _time = 1.6548e+09, train_seconds = 1.4106e+04)
[2022-06-10 00:03:11,010][root][INFO] - Step 52963840 @ 3581.2 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (step = 52963840, mean_episode_return = None, mean_episode_step = 1257.8, total_loss = 349.52, pg_loss = 223.13, baseline_loss = 131.39, entropy_loss = -5.0066, learner_queue_size = 32, _tick = 12984, _time = 1.6548e+09, train_seconds = 1.4111e+04)
[2022-06-10 00:03:16,014][root][INFO] - Step 52981760 @ 3581.0 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 52981760, mean_episode_return = None, mean_episode_step = 1566.8, total_loss = 276.71, pg_loss = 192.42, baseline_loss = 89.347, entropy_loss = -5.0546, learner_queue_size = 32, _tick = 12990, _time = 1.6548e+09, train_seconds = 1.4116e+04)
[2022-06-10 00:03:21,019][root][INFO] - Step 53002240 @ 4092.0 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 53002240, mean_episode_return = 36.965, mean_episode_step = 1205.8, total_loss = 470.61, pg_loss = 352.82, baseline_loss = 122.93, entropy_loss = -5.1486, learner_queue_size = 32, _tick = 12996, _time = 1.6548e+09, train_seconds = 1.4121e+04)
[2022-06-10 00:03:26,022][root][INFO] - Step 53020160 @ 3581.8 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 53020160, mean_episode_return = 43.296, mean_episode_step = 1077.6, total_loss = 272.25, pg_loss = 142.52, baseline_loss = 134.96, entropy_loss = -5.2295, learner_queue_size = 32, _tick = 13002, _time = 1.6548e+09, train_seconds = 1.4126e+04)
[2022-06-10 00:03:31,027][root][INFO] - Step 53040640 @ 4091.7 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 53040640, mean_episode_return = 13.03, mean_episode_step = 1692.9, total_loss = 242.4, pg_loss = 143.95, baseline_loss = 103.7, entropy_loss = -5.2559, learner_queue_size = 32, _tick = 13009, _time = 1.6548e+09, train_seconds = 1.4131e+04)
[2022-06-10 00:03:36,034][root][INFO] - Step 53058560 @ 3579.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 53058560, mean_episode_return = 47.121, mean_episode_step = 1060.7, total_loss = -182.02, pg_loss = -195.41, baseline_loss = 18.521, entropy_loss = -5.1256, learner_queue_size = 32, _tick = 13014, _time = 1.6548e+09, train_seconds = 1.4136e+04)
[2022-06-10 00:03:41,039][root][INFO] - Step 53076480 @ 3579.9 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 53076480, mean_episode_return = 49.14, mean_episode_step = 1029.1, total_loss = 78.988, pg_loss = 16.272, baseline_loss = 67.846, entropy_loss = -5.1306, learner_queue_size = 32, _tick = 13019, _time = 1.6548e+09, train_seconds = 1.4141e+04)
[2022-06-10 00:03:46,045][root][INFO] - Step 53096960 @ 4091.4 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 53096960, mean_episode_return = 36.81, mean_episode_step = 996.48, total_loss = -82.966, pg_loss = -99.329, baseline_loss = 21.447, entropy_loss = -5.0839, learner_queue_size = 32, _tick = 13025, _time = 1.6548e+09, train_seconds = 1.4146e+04)
[2022-06-10 00:03:51,051][root][INFO] - Step 53114880 @ 3579.8 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 53114880, mean_episode_return = None, mean_episode_step = 1064.3, total_loss = 485.44, pg_loss = 345.2, baseline_loss = 145.51, entropy_loss = -5.2673, learner_queue_size = 32, _tick = 13030, _time = 1.6548e+09, train_seconds = 1.4151e+04)
[2022-06-10 00:03:56,054][root][INFO] - Step 53132800 @ 3581.8 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 53132800, mean_episode_return = None, mean_episode_step = 1150.8, total_loss = -93.092, pg_loss = -119.22, baseline_loss = 31.472, entropy_loss = -5.3399, learner_queue_size = 32, _tick = 13035, _time = 1.6548e+09, train_seconds = 1.4156e+04)
[2022-06-10 00:04:01,058][root][INFO] - Step 53150720 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 53150720, mean_episode_return = 29.94, mean_episode_step = 994.85, total_loss = 120.93, pg_loss = 17.331, baseline_loss = 108.95, entropy_loss = -5.346, learner_queue_size = 32, _tick = 13042, _time = 1.6548e+09, train_seconds = 1.4161e+04)
[2022-06-10 00:04:06,062][root][INFO] - Step 53168640 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 53168640, mean_episode_return = None, mean_episode_step = 1014.5, total_loss = 40.324, pg_loss = -4.5171, baseline_loss = 50.187, entropy_loss = -5.3463, learner_queue_size = 32, _tick = 13047, _time = 1.6548e+09, train_seconds = 1.4166e+04)
[2022-06-10 00:04:11,066][root][INFO] - Step 53189120 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 53189120, mean_episode_return = 107.34, mean_episode_step = 936.91, total_loss = 336.51, pg_loss = 252.93, baseline_loss = 88.891, entropy_loss = -5.3108, learner_queue_size = 32, _tick = 13054, _time = 1.6548e+09, train_seconds = 1.4171e+04)
[2022-06-10 00:04:16,070][root][INFO] - Step 53207040 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 53207040, mean_episode_return = 63.789, mean_episode_step = 710.4, total_loss = 164.18, pg_loss = 116.48, baseline_loss = 53.052, entropy_loss = -5.3478, learner_queue_size = 32, _tick = 13060, _time = 1.6548e+09, train_seconds = 1.4176e+04)
[2022-06-10 00:04:21,074][root][INFO] - Step 53227520 @ 4092.8 SPS. Inference batcher size: 75. Learner queue size: 32. Other stats: (step = 53227520, mean_episode_return = 5.9199, mean_episode_step = 1465.0, total_loss = -125.52, pg_loss = -160.6, baseline_loss = 40.282, entropy_loss = -5.1976, learner_queue_size = 32, _tick = 13066, _time = 1.6548e+09, train_seconds = 1.4181e+04)
[2022-06-10 00:04:26,080][root][INFO] - Step 53245440 @ 3579.6 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 53245440, mean_episode_return = 55.596, mean_episode_step = 897.74, total_loss = -98.443, pg_loss = -169.53, baseline_loss = 76.189, entropy_loss = -5.1017, learner_queue_size = 32, _tick = 13071, _time = 1.6548e+09, train_seconds = 1.4186e+04)
[2022-06-10 00:04:31,086][root][INFO] - Step 53265920 @ 4091.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 53265920, mean_episode_return = 36.5, mean_episode_step = 937.82, total_loss = 396.79, pg_loss = 257.64, baseline_loss = 144.24, entropy_loss = -5.0879, learner_queue_size = 32, _tick = 13078, _time = 1.6548e+09, train_seconds = 1.4191e+04)
[2022-06-10 00:04:36,090][root][INFO] - Step 53283840 @ 3581.1 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 53283840, mean_episode_return = 158.91, mean_episode_step = 1032.1, total_loss = -7.7732, pg_loss = -44.227, baseline_loss = 41.603, entropy_loss = -5.149, learner_queue_size = 32, _tick = 13084, _time = 1.6548e+09, train_seconds = 1.4196e+04)
[2022-06-10 00:04:41,094][root][INFO] - Step 53301760 @ 3581.2 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 53301760, mean_episode_return = 51.55, mean_episode_step = 1054.6, total_loss = -142.54, pg_loss = -151.61, baseline_loss = 14.429, entropy_loss = -5.3618, learner_queue_size = 32, _tick = 13089, _time = 1.6548e+09, train_seconds = 1.4201e+04)
[2022-06-10 00:04:46,098][root][INFO] - Step 53322240 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 53322240, mean_episode_return = 48.53, mean_episode_step = 1219.2, total_loss = 46.941, pg_loss = 15.834, baseline_loss = 36.295, entropy_loss = -5.1877, learner_queue_size = 32, _tick = 13096, _time = 1.6548e+09, train_seconds = 1.4206e+04)
[2022-06-10 00:04:51,102][root][INFO] - Step 53340160 @ 3581.2 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 53340160, mean_episode_return = 57.751, mean_episode_step = 964.64, total_loss = 67.806, pg_loss = -0.81003, baseline_loss = 73.803, entropy_loss = -5.1868, learner_queue_size = 32, _tick = 13103, _time = 1.6548e+09, train_seconds = 1.4211e+04)
[2022-06-10 00:04:56,107][root][INFO] - Step 53360640 @ 4092.6 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 53360640, mean_episode_return = 108.4, mean_episode_step = 878.86, total_loss = 382.07, pg_loss = 282.0, baseline_loss = 105.24, entropy_loss = -5.176, learner_queue_size = 32, _tick = 13110, _time = 1.6548e+09, train_seconds = 1.4216e+04)
[2022-06-10 00:05:01,110][root][INFO] - Step 53378560 @ 3581.2 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 53378560, mean_episode_return = None, mean_episode_step = 1130.0, total_loss = 43.152, pg_loss = -41.693, baseline_loss = 90.163, entropy_loss = -5.3181, learner_queue_size = 32, _tick = 13115, _time = 1.6548e+09, train_seconds = 1.4221e+04)
[2022-06-10 00:05:06,114][root][INFO] - Step 53396480 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 53396480, mean_episode_return = 86.76, mean_episode_step = 1008.3, total_loss = -343.87, pg_loss = -364.67, baseline_loss = 26.125, entropy_loss = -5.322, learner_queue_size = 32, _tick = 13121, _time = 1.6548e+09, train_seconds = 1.4226e+04)
[2022-06-10 00:05:11,118][root][INFO] - Step 53414400 @ 3581.2 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 53414400, mean_episode_return = 49.647, mean_episode_step = 1014.3, total_loss = 70.096, pg_loss = 7.2856, baseline_loss = 68.159, entropy_loss = -5.3494, learner_queue_size = 32, _tick = 13126, _time = 1.6548e+09, train_seconds = 1.4231e+04)
[2022-06-10 00:05:16,122][root][INFO] - Step 53434880 @ 4092.6 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 53434880, mean_episode_return = None, mean_episode_step = 1022.7, total_loss = 162.21, pg_loss = 86.881, baseline_loss = 80.67, entropy_loss = -5.3369, learner_queue_size = 32, _tick = 13132, _time = 1.6548e+09, train_seconds = 1.4236e+04)
[2022-06-10 00:05:21,126][root][INFO] - Step 53452800 @ 3581.2 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 53452800, mean_episode_return = 53.776, mean_episode_step = 947.63, total_loss = 266.07, pg_loss = 157.42, baseline_loss = 113.96, entropy_loss = -5.3134, learner_queue_size = 32, _tick = 13139, _time = 1.6548e+09, train_seconds = 1.4241e+04)
[2022-06-10 00:05:26,130][root][INFO] - Step 53470720 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 53470720, mean_episode_return = 31.061, mean_episode_step = 1119.0, total_loss = 232.34, pg_loss = 148.29, baseline_loss = 89.412, entropy_loss = -5.3666, learner_queue_size = 32, _tick = 13146, _time = 1.6548e+09, train_seconds = 1.4246e+04)
[2022-06-10 00:05:31,134][root][INFO] - Step 53491200 @ 4092.7 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 53491200, mean_episode_return = 138.31, mean_episode_step = 992.62, total_loss = 94.829, pg_loss = 28.57, baseline_loss = 71.618, entropy_loss = -5.3588, learner_queue_size = 32, _tick = 13152, _time = 1.6548e+09, train_seconds = 1.4251e+04)
[2022-06-10 00:05:36,138][root][INFO] - Step 53509120 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 53509120, mean_episode_return = 18.55, mean_episode_step = 1011.7, total_loss = -31.225, pg_loss = -93.509, baseline_loss = 67.641, entropy_loss = -5.3567, learner_queue_size = 32, _tick = 13159, _time = 1.6548e+09, train_seconds = 1.4256e+04)
[2022-06-10 00:05:41,142][root][INFO] - Step 53527040 @ 3581.2 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 53527040, mean_episode_return = 81.229, mean_episode_step = 694.58, total_loss = -103.72, pg_loss = -142.42, baseline_loss = 44.116, entropy_loss = -5.4158, learner_queue_size = 32, _tick = 13165, _time = 1.6548e+09, train_seconds = 1.4261e+04)
[2022-06-10 00:05:46,146][root][INFO] - Step 53547520 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 53547520, mean_episode_return = 77.84, mean_episode_step = 1380.9, total_loss = -36.24, pg_loss = -65.11, baseline_loss = 34.236, entropy_loss = -5.3658, learner_queue_size = 32, _tick = 13171, _time = 1.6548e+09, train_seconds = 1.4266e+04)
[2022-06-10 00:05:51,150][root][INFO] - Step 53565440 @ 3581.1 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 53565440, mean_episode_return = 55.993, mean_episode_step = 882.02, total_loss = 299.69, pg_loss = 208.52, baseline_loss = 96.387, entropy_loss = -5.2201, learner_queue_size = 32, _tick = 13178, _time = 1.6548e+09, train_seconds = 1.4271e+04)
[2022-06-10 00:05:56,155][root][INFO] - Step 53585920 @ 4091.5 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 53585920, mean_episode_return = None, mean_episode_step = 1417.4, total_loss = 162.43, pg_loss = 116.78, baseline_loss = 50.917, entropy_loss = -5.2579, learner_queue_size = 32, _tick = 13182, _time = 1.6548e+09, train_seconds = 1.4276e+04)
[2022-06-10 00:06:01,158][root][INFO] - Step 53603840 @ 3582.1 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 53603840, mean_episode_return = 25.315, mean_episode_step = 1114.7, total_loss = 82.919, pg_loss = -43.749, baseline_loss = 131.78, entropy_loss = -5.1119, learner_queue_size = 32, _tick = 13189, _time = 1.6548e+09, train_seconds = 1.4281e+04)
[2022-06-10 00:06:06,162][root][INFO] - Step 53621760 @ 3581.2 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 53621760, mean_episode_return = 118.99, mean_episode_step = 1047.5, total_loss = 68.934, pg_loss = 12.661, baseline_loss = 61.331, entropy_loss = -5.0585, learner_queue_size = 32, _tick = 13194, _time = 1.6548e+09, train_seconds = 1.4286e+04)
[2022-06-10 00:06:11,166][root][INFO] - Step 53642240 @ 4092.6 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 53642240, mean_episode_return = 32.581, mean_episode_step = 888.35, total_loss = 155.16, pg_loss = 56.846, baseline_loss = 103.43, entropy_loss = -5.1179, learner_queue_size = 32, _tick = 13199, _time = 1.6548e+09, train_seconds = 1.4291e+04)
[2022-06-10 00:06:16,170][root][INFO] - Step 53660160 @ 3581.2 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 53660160, mean_episode_return = 48.63, mean_episode_step = 1259.9, total_loss = 117.38, pg_loss = 52.785, baseline_loss = 69.775, entropy_loss = -5.1801, learner_queue_size = 32, _tick = 13204, _time = 1.6548e+09, train_seconds = 1.4296e+04)
[2022-06-10 00:06:21,174][root][INFO] - Step 53678080 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 53678080, mean_episode_return = 77.04, mean_episode_step = 1016.2, total_loss = 117.96, pg_loss = 59.742, baseline_loss = 63.431, entropy_loss = -5.2125, learner_queue_size = 32, _tick = 13211, _time = 1.6548e+09, train_seconds = 1.4301e+04)
[2022-06-10 00:06:26,178][root][INFO] - Step 53698560 @ 4092.8 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 53698560, mean_episode_return = 44.841, mean_episode_step = 909.36, total_loss = 280.47, pg_loss = 170.31, baseline_loss = 115.34, entropy_loss = -5.1797, learner_queue_size = 32, _tick = 13219, _time = 1.6548e+09, train_seconds = 1.4306e+04)
[2022-06-10 00:06:31,182][root][INFO] - Step 53716480 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 53716480, mean_episode_return = 26.676, mean_episode_step = 941.71, total_loss = 95.92, pg_loss = 26.468, baseline_loss = 74.524, entropy_loss = -5.0717, learner_queue_size = 32, _tick = 13224, _time = 1.6548e+09, train_seconds = 1.4311e+04)
[2022-06-10 00:06:36,186][root][INFO] - Step 53734400 @ 3581.2 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 53734400, mean_episode_return = 65.651, mean_episode_step = 956.08, total_loss = -5.9324, pg_loss = -33.383, baseline_loss = 32.81, entropy_loss = -5.3591, learner_queue_size = 32, _tick = 13231, _time = 1.6548e+09, train_seconds = 1.4316e+04)
[2022-06-10 00:06:41,190][root][INFO] - Step 53754880 @ 4092.7 SPS. Inference batcher size: 78. Learner queue size: 32. Other stats: (step = 53754880, mean_episode_return = 43.906, mean_episode_step = 877.94, total_loss = -37.465, pg_loss = -80.044, baseline_loss = 47.714, entropy_loss = -5.1356, learner_queue_size = 32, _tick = 13237, _time = 1.6548e+09, train_seconds = 1.4321e+04)
[2022-06-10 00:06:46,194][root][INFO] - Step 53772800 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 53772800, mean_episode_return = 43.251, mean_episode_step = 796.09, total_loss = 247.83, pg_loss = 168.77, baseline_loss = 84.147, entropy_loss = -5.0867, learner_queue_size = 32, _tick = 13242, _time = 1.6548e+09, train_seconds = 1.4326e+04)
[2022-06-10 00:06:51,198][root][INFO] - Step 53790720 @ 3581.2 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 53790720, mean_episode_return = 64.996, mean_episode_step = 757.35, total_loss = 141.62, pg_loss = 3.9494, baseline_loss = 142.93, entropy_loss = -5.2572, learner_queue_size = 32, _tick = 13248, _time = 1.6548e+09, train_seconds = 1.4331e+04)
[2022-06-10 00:06:56,203][root][INFO] - Step 53808640 @ 3580.4 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 53808640, mean_episode_return = None, mean_episode_step = 1268.2, total_loss = -104.31, pg_loss = -115.22, baseline_loss = 16.246, entropy_loss = -5.3303, learner_queue_size = 32, _tick = 13252, _time = 1.6548e+09, train_seconds = 1.4336e+04)
[2022-06-10 00:07:01,207][root][INFO] - Step 53829120 @ 4092.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 53829120, mean_episode_return = 14.553, mean_episode_step = 955.23, total_loss = -13.412, pg_loss = -65.672, baseline_loss = 57.667, entropy_loss = -5.4068, learner_queue_size = 32, _tick = 13260, _time = 1.6548e+09, train_seconds = 1.4341e+04)
[2022-06-10 00:07:06,210][root][INFO] - Step 53847040 @ 3581.8 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 53847040, mean_episode_return = 94.582, mean_episode_step = 993.36, total_loss = 174.67, pg_loss = 133.9, baseline_loss = 46.025, entropy_loss = -5.2545, learner_queue_size = 32, _tick = 13266, _time = 1.6548e+09, train_seconds = 1.4346e+04)
[2022-06-10 00:07:11,214][root][INFO] - Step 53867520 @ 4092.8 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 53867520, mean_episode_return = 6.8997, mean_episode_step = 1000.9, total_loss = -53.556, pg_loss = -84.069, baseline_loss = 35.289, entropy_loss = -4.7756, learner_queue_size = 32, _tick = 13274, _time = 1.6548e+09, train_seconds = 1.4351e+04)
[2022-06-10 00:07:16,218][root][INFO] - Step 53885440 @ 3581.1 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (step = 53885440, mean_episode_return = 45.9, mean_episode_step = 1352.3, total_loss = -31.39, pg_loss = -48.59, baseline_loss = 22.422, entropy_loss = -5.2223, learner_queue_size = 32, _tick = 13280, _time = 1.6548e+09, train_seconds = 1.4356e+04)
[2022-06-10 00:07:21,222][root][INFO] - Step 53903360 @ 3581.2 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 53903360, mean_episode_return = None, mean_episode_step = 919.81, total_loss = -74.402, pg_loss = -105.93, baseline_loss = 36.91, entropy_loss = -5.3783, learner_queue_size = 32, _tick = 13284, _time = 1.6548e+09, train_seconds = 1.4361e+04)
[2022-06-10 00:07:26,227][root][INFO] - Step 53921280 @ 3580.7 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 53921280, mean_episode_return = 26.214, mean_episode_step = 718.38, total_loss = -23.01, pg_loss = -43.714, baseline_loss = 26.174, entropy_loss = -5.4699, learner_queue_size = 32, _tick = 13288, _time = 1.6548e+09, train_seconds = 1.4366e+04)
[2022-06-10 00:07:31,231][root][INFO] - Step 53941760 @ 4092.7 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 53941760, mean_episode_return = 58.462, mean_episode_step = 1172.0, total_loss = -100.49, pg_loss = -122.76, baseline_loss = 27.691, entropy_loss = -5.4232, learner_queue_size = 32, _tick = 13295, _time = 1.6548e+09, train_seconds = 1.4371e+04)
[2022-06-10 00:07:36,234][root][INFO] - Step 53959680 @ 3581.6 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 53959680, mean_episode_return = 100.44, mean_episode_step = 1821.9, total_loss = -107.46, pg_loss = -133.48, baseline_loss = 31.406, entropy_loss = -5.3906, learner_queue_size = 32, _tick = 13301, _time = 1.6548e+09, train_seconds = 1.4376e+04)
[2022-06-10 00:07:41,238][root][INFO] - Step 53977600 @ 3581.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 53977600, mean_episode_return = None, mean_episode_step = 985.84, total_loss = -20.117, pg_loss = -46.052, baseline_loss = 31.28, entropy_loss = -5.3449, learner_queue_size = 32, _tick = 13306, _time = 1.6548e+09, train_seconds = 1.4381e+04)
[2022-06-10 00:07:46,242][root][INFO] - Step 53998080 @ 4092.7 SPS. Inference batcher size: 66. Learner queue size: 31. Other stats: (step = 53998080, mean_episode_return = None, mean_episode_step = 1603.6, total_loss = 323.61, pg_loss = 217.14, baseline_loss = 111.81, entropy_loss = -5.3311, learner_queue_size = 32, _tick = 13313, _time = 1.6548e+09, train_seconds = 1.4386e+04)
[2022-06-10 00:07:51,246][root][INFO] - Step 54016000 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 54016000, mean_episode_return = 88.171, mean_episode_step = 1120.3, total_loss = -155.32, pg_loss = -168.21, baseline_loss = 18.219, entropy_loss = -5.3269, learner_queue_size = 32, _tick = 13320, _time = 1.6548e+09, train_seconds = 1.4391e+04)
[2022-06-10 00:07:56,250][root][INFO] - Step 54036480 @ 4092.7 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 54036480, mean_episode_return = 112.27, mean_episode_step = 1098.5, total_loss = 131.04, pg_loss = 87.036, baseline_loss = 49.364, entropy_loss = -5.3565, learner_queue_size = 32, _tick = 13327, _time = 1.6548e+09, train_seconds = 1.4396e+04)
[2022-06-10 00:08:01,254][root][INFO] - Step 54054400 @ 3581.1 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 54054400, mean_episode_return = 47.331, mean_episode_step = 1252.9, total_loss = -79.827, pg_loss = -95.666, baseline_loss = 21.251, entropy_loss = -5.4123, learner_queue_size = 32, _tick = 13331, _time = 1.6548e+09, train_seconds = 1.4401e+04)
[2022-06-10 00:08:06,258][root][INFO] - Step 54072320 @ 3581.2 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 54072320, mean_episode_return = None, mean_episode_step = 1117.2, total_loss = 51.494, pg_loss = 27.324, baseline_loss = 29.515, entropy_loss = -5.3449, learner_queue_size = 32, _tick = 13336, _time = 1.6548e+09, train_seconds = 1.4406e+04)
[2022-06-10 00:08:11,262][root][INFO] - Step 54092800 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 54092800, mean_episode_return = 29.44, mean_episode_step = 1093.9, total_loss = -209.03, pg_loss = -225.56, baseline_loss = 21.82, entropy_loss = -5.2923, learner_queue_size = 32, _tick = 13341, _time = 1.6548e+09, train_seconds = 1.4411e+04)
[2022-06-10 00:08:16,266][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 00:08:16,390][root][INFO] - Step 54110720 @ 3580.8 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 54110720, mean_episode_return = 45.065, mean_episode_step = 1149.8, total_loss = 86.131, pg_loss = -7.1256, baseline_loss = 98.49, entropy_loss = -5.2335, learner_queue_size = 32, _tick = 13348, _time = 1.6548e+09, train_seconds = 1.4416e+04)
[2022-06-10 00:08:21,394][root][INFO] - Step 54128640 @ 3494.9 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 54128640, mean_episode_return = 35.679, mean_episode_step = 1699.5, total_loss = -28.629, pg_loss = -60.628, baseline_loss = 37.201, entropy_loss = -5.2026, learner_queue_size = 32, _tick = 13353, _time = 1.6548e+09, train_seconds = 1.4421e+04)
[2022-06-10 00:08:26,402][root][INFO] - Step 54149120 @ 4089.5 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 54149120, mean_episode_return = 43.61, mean_episode_step = 948.88, total_loss = -232.58, pg_loss = -247.17, baseline_loss = 19.72, entropy_loss = -5.1303, learner_queue_size = 32, _tick = 13360, _time = 1.6548e+09, train_seconds = 1.4426e+04)
[2022-06-10 00:08:31,406][root][INFO] - Step 54167040 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 54167040, mean_episode_return = 113.61, mean_episode_step = 1070.4, total_loss = 122.87, pg_loss = 68.275, baseline_loss = 59.819, entropy_loss = -5.2198, learner_queue_size = 32, _tick = 13367, _time = 1.6548e+09, train_seconds = 1.4431e+04)
[2022-06-10 00:08:36,410][root][INFO] - Step 54184960 @ 3581.2 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 54184960, mean_episode_return = 91.609, mean_episode_step = 1013.0, total_loss = 68.578, pg_loss = 8.1102, baseline_loss = 65.64, entropy_loss = -5.1721, learner_queue_size = 32, _tick = 13374, _time = 1.6548e+09, train_seconds = 1.4436e+04)
[2022-06-10 00:08:41,414][root][INFO] - Step 54205440 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 54205440, mean_episode_return = 52.426, mean_episode_step = 1067.2, total_loss = 375.32, pg_loss = 288.23, baseline_loss = 92.28, entropy_loss = -5.1891, learner_queue_size = 32, _tick = 13382, _time = 1.6548e+09, train_seconds = 1.4441e+04)
[2022-06-10 00:08:46,418][root][INFO] - Step 54223360 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 54223360, mean_episode_return = 144.56, mean_episode_step = 1209.2, total_loss = -118.97, pg_loss = -133.71, baseline_loss = 19.857, entropy_loss = -5.1152, learner_queue_size = 32, _tick = 13389, _time = 1.6548e+09, train_seconds = 1.4446e+04)
[2022-06-10 00:08:51,422][root][INFO] - Step 54243840 @ 4092.8 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 54243840, mean_episode_return = None, mean_episode_step = 949.38, total_loss = 19.225, pg_loss = -20.917, baseline_loss = 45.183, entropy_loss = -5.0405, learner_queue_size = 32, _tick = 13396, _time = 1.6548e+09, train_seconds = 1.4451e+04)
[2022-06-10 00:08:56,426][root][INFO] - Step 54261760 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 54261760, mean_episode_return = -17.13, mean_episode_step = 1053.2, total_loss = 33.603, pg_loss = -1.6303, baseline_loss = 40.381, entropy_loss = -5.1479, learner_queue_size = 32, _tick = 13402, _time = 1.6548e+09, train_seconds = 1.4456e+04)
[2022-06-10 00:09:01,430][root][INFO] - Step 54279680 @ 3581.1 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 54279680, mean_episode_return = 70.29, mean_episode_step = 1123.2, total_loss = -2.6585, pg_loss = -35.705, baseline_loss = 38.321, entropy_loss = -5.2741, learner_queue_size = 32, _tick = 13409, _time = 1.6548e+09, train_seconds = 1.4461e+04)
[2022-06-10 00:09:06,434][root][INFO] - Step 54300160 @ 4092.7 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 54300160, mean_episode_return = 26.927, mean_episode_step = 882.31, total_loss = 133.83, pg_loss = 33.93, baseline_loss = 105.04, entropy_loss = -5.1439, learner_queue_size = 32, _tick = 13416, _time = 1.6548e+09, train_seconds = 1.4466e+04)
[2022-06-10 00:09:11,438][root][INFO] - Step 54318080 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 54318080, mean_episode_return = 60.774, mean_episode_step = 897.33, total_loss = 28.433, pg_loss = -40.0, baseline_loss = 73.351, entropy_loss = -4.9186, learner_queue_size = 32, _tick = 13421, _time = 1.6548e+09, train_seconds = 1.4471e+04)
[2022-06-10 00:09:16,442][root][INFO] - Step 54336000 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 54336000, mean_episode_return = 42.546, mean_episode_step = 847.61, total_loss = 41.696, pg_loss = -23.135, baseline_loss = 69.921, entropy_loss = -5.0905, learner_queue_size = 32, _tick = 13427, _time = 1.6548e+09, train_seconds = 1.4476e+04)
[2022-06-10 00:09:21,447][root][INFO] - Step 54353920 @ 3580.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 54353920, mean_episode_return = 90.079, mean_episode_step = 934.18, total_loss = 76.268, pg_loss = -1.87, baseline_loss = 82.93, entropy_loss = -4.7915, learner_queue_size = 32, _tick = 13433, _time = 1.6548e+09, train_seconds = 1.4481e+04)
[2022-06-10 00:09:26,450][root][INFO] - Step 54374400 @ 4093.2 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 54374400, mean_episode_return = 68.31, mean_episode_step = 1014.1, total_loss = 7759.1, pg_loss = 1266.6, baseline_loss = 6497.5, entropy_loss = -4.9579, learner_queue_size = 32, _tick = 13439, _time = 1.6548e+09, train_seconds = 1.4486e+04)
[2022-06-10 00:09:31,454][root][INFO] - Step 54392320 @ 3581.2 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 54392320, mean_episode_return = 18.14, mean_episode_step = 896.71, total_loss = -200.36, pg_loss = -257.61, baseline_loss = 62.205, entropy_loss = -4.9538, learner_queue_size = 32, _tick = 13445, _time = 1.6548e+09, train_seconds = 1.4491e+04)
[2022-06-10 00:09:36,458][root][INFO] - Step 54410240 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 54410240, mean_episode_return = 21.25, mean_episode_step = 1148.0, total_loss = 120.7, pg_loss = 72.738, baseline_loss = 53.316, entropy_loss = -5.3493, learner_queue_size = 32, _tick = 13450, _time = 1.6548e+09, train_seconds = 1.4496e+04)
[2022-06-10 00:09:41,462][root][INFO] - Step 54428160 @ 3581.1 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 54428160, mean_episode_return = -7.0504, mean_episode_step = 979.86, total_loss = 137.62, pg_loss = 88.658, baseline_loss = 54.212, entropy_loss = -5.2469, learner_queue_size = 32, _tick = 13455, _time = 1.6548e+09, train_seconds = 1.4501e+04)
[2022-06-10 00:09:46,467][root][INFO] - Step 54448640 @ 4091.7 SPS. Inference batcher size: 87. Learner queue size: 32. Other stats: (step = 54448640, mean_episode_return = 36.971, mean_episode_step = 904.12, total_loss = 525.94, pg_loss = 397.03, baseline_loss = 133.98, entropy_loss = -5.0768, learner_queue_size = 32, _tick = 13462, _time = 1.6548e+09, train_seconds = 1.4506e+04)
[2022-06-10 00:09:51,470][root][INFO] - Step 54466560 @ 3582.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 54466560, mean_episode_return = 105.2, mean_episode_step = 949.46, total_loss = 6.6047, pg_loss = -54.538, baseline_loss = 66.301, entropy_loss = -5.159, learner_queue_size = 32, _tick = 13468, _time = 1.6548e+09, train_seconds = 1.4511e+04)
[2022-06-10 00:09:56,474][root][INFO] - Step 54484480 @ 3581.1 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 54484480, mean_episode_return = 33.0, mean_episode_step = 901.15, total_loss = -176.59, pg_loss = -200.1, baseline_loss = 28.75, entropy_loss = -5.2438, learner_queue_size = 32, _tick = 13474, _time = 1.6548e+09, train_seconds = 1.4516e+04)
[2022-06-10 00:10:01,478][root][INFO] - Step 54502400 @ 3581.1 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (step = 54502400, mean_episode_return = -1.26, mean_episode_step = 886.27, total_loss = 83.845, pg_loss = -3.9214, baseline_loss = 93.0, entropy_loss = -5.2331, learner_queue_size = 32, _tick = 13481, _time = 1.6548e+09, train_seconds = 1.4521e+04)
[2022-06-10 00:10:06,490][root][INFO] - Step 54520320 @ 3575.4 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 54520320, mean_episode_return = 79.935, mean_episode_step = 1200.8, total_loss = 195.25, pg_loss = 114.68, baseline_loss = 85.811, entropy_loss = -5.2441, learner_queue_size = 32, _tick = 13485, _time = 1.6548e+09, train_seconds = 1.4526e+04)
[2022-06-10 00:10:11,494][root][INFO] - Step 54538240 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 54538240, mean_episode_return = 69.583, mean_episode_step = 1618.7, total_loss = 59.104, pg_loss = -15.48, baseline_loss = 79.827, entropy_loss = -5.243, learner_queue_size = 32, _tick = 13489, _time = 1.6548e+09, train_seconds = 1.4531e+04)
[2022-06-10 00:10:16,498][root][INFO] - Step 54556160 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 54556160, mean_episode_return = 123.15, mean_episode_step = 1070.0, total_loss = 129.75, pg_loss = 18.095, baseline_loss = 116.82, entropy_loss = -5.1628, learner_queue_size = 32, _tick = 13496, _time = 1.6548e+09, train_seconds = 1.4536e+04)
[2022-06-10 00:10:21,502][root][INFO] - Step 54576640 @ 4092.7 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 54576640, mean_episode_return = 30.265, mean_episode_step = 1666.0, total_loss = 4.1793, pg_loss = -67.242, baseline_loss = 76.72, entropy_loss = -5.2996, learner_queue_size = 32, _tick = 13503, _time = 1.6548e+09, train_seconds = 1.4541e+04)
[2022-06-10 00:10:26,506][root][INFO] - Step 54594560 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 54594560, mean_episode_return = 60.218, mean_episode_step = 1008.0, total_loss = 73.04, pg_loss = 15.597, baseline_loss = 62.679, entropy_loss = -5.2359, learner_queue_size = 32, _tick = 13510, _time = 1.6548e+09, train_seconds = 1.4546e+04)
[2022-06-10 00:10:31,510][root][INFO] - Step 54615040 @ 4092.7 SPS. Inference batcher size: 88. Learner queue size: 32. Other stats: (step = 54615040, mean_episode_return = 184.85, mean_episode_step = 1082.8, total_loss = -45.888, pg_loss = -114.9, baseline_loss = 74.218, entropy_loss = -5.2083, learner_queue_size = 32, _tick = 13517, _time = 1.6548e+09, train_seconds = 1.4551e+04)
[2022-06-10 00:10:36,514][root][INFO] - Step 54632960 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 54632960, mean_episode_return = 129.73, mean_episode_step = 929.34, total_loss = -48.414, pg_loss = -96.901, baseline_loss = 53.66, entropy_loss = -5.174, learner_queue_size = 32, _tick = 13523, _time = 1.6548e+09, train_seconds = 1.4556e+04)
[2022-06-10 00:10:41,518][root][INFO] - Step 54650880 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 54650880, mean_episode_return = None, mean_episode_step = 1171.9, total_loss = 211.9, pg_loss = 146.87, baseline_loss = 70.386, entropy_loss = -5.351, learner_queue_size = 32, _tick = 13526, _time = 1.6548e+09, train_seconds = 1.4561e+04)
[2022-06-10 00:10:46,522][root][INFO] - Step 54668800 @ 3581.2 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 54668800, mean_episode_return = 70.479, mean_episode_step = 1530.3, total_loss = -166.02, pg_loss = -202.63, baseline_loss = 41.792, entropy_loss = -5.1795, learner_queue_size = 32, _tick = 13533, _time = 1.6548e+09, train_seconds = 1.4566e+04)
[2022-06-10 00:10:51,526][root][INFO] - Step 54686720 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 54686720, mean_episode_return = 66.313, mean_episode_step = 937.67, total_loss = 5.5969, pg_loss = -50.992, baseline_loss = 61.498, entropy_loss = -4.9091, learner_queue_size = 32, _tick = 13540, _time = 1.6548e+09, train_seconds = 1.4571e+04)
[2022-06-10 00:10:56,530][root][INFO] - Step 54707200 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 54707200, mean_episode_return = 49.81, mean_episode_step = 967.51, total_loss = 376.81, pg_loss = 270.65, baseline_loss = 111.07, entropy_loss = -4.9164, learner_queue_size = 32, _tick = 13548, _time = 1.6548e+09, train_seconds = 1.4576e+04)
[2022-06-10 00:11:01,534][root][INFO] - Step 54725120 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 54725120, mean_episode_return = 71.59, mean_episode_step = 895.11, total_loss = 372.6, pg_loss = 294.8, baseline_loss = 82.904, entropy_loss = -5.0998, learner_queue_size = 32, _tick = 13555, _time = 1.6548e+09, train_seconds = 1.4581e+04)
[2022-06-10 00:11:06,538][root][INFO] - Step 54743040 @ 3581.1 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 54743040, mean_episode_return = None, mean_episode_step = 923.09, total_loss = 207.29, pg_loss = 139.2, baseline_loss = 73.192, entropy_loss = -5.0999, learner_queue_size = 32, _tick = 13560, _time = 1.6548e+09, train_seconds = 1.4586e+04)
[2022-06-10 00:11:11,542][root][INFO] - Step 54760960 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 54760960, mean_episode_return = 55.36, mean_episode_step = 1171.1, total_loss = -110.72, pg_loss = -167.19, baseline_loss = 61.489, entropy_loss = -5.013, learner_queue_size = 32, _tick = 13566, _time = 1.6548e+09, train_seconds = 1.4591e+04)
[2022-06-10 00:11:16,546][root][INFO] - Step 54781440 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 54781440, mean_episode_return = 45.981, mean_episode_step = 1178.1, total_loss = 407.66, pg_loss = 320.85, baseline_loss = 92.068, entropy_loss = -5.266, learner_queue_size = 32, _tick = 13572, _time = 1.6548e+09, train_seconds = 1.4596e+04)
[2022-06-10 00:11:21,550][root][INFO] - Step 54799360 @ 3581.2 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 54799360, mean_episode_return = None, mean_episode_step = 905.91, total_loss = 218.15, pg_loss = 117.49, baseline_loss = 105.89, entropy_loss = -5.2353, learner_queue_size = 32, _tick = 13577, _time = 1.6548e+09, train_seconds = 1.4601e+04)
[2022-06-10 00:11:26,554][root][INFO] - Step 54819840 @ 4092.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (step = 54819840, mean_episode_return = 59.231, mean_episode_step = 706.29, total_loss = 57.233, pg_loss = 18.393, baseline_loss = 43.886, entropy_loss = -5.0455, learner_queue_size = 32, _tick = 13583, _time = 1.6548e+09, train_seconds = 1.4606e+04)
[2022-06-10 00:11:31,558][root][INFO] - Step 54837760 @ 3581.3 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 54837760, mean_episode_return = 115.86, mean_episode_step = 758.76, total_loss = -175.8, pg_loss = -252.48, baseline_loss = 81.832, entropy_loss = -5.1492, learner_queue_size = 32, _tick = 13588, _time = 1.6548e+09, train_seconds = 1.4611e+04)
[2022-06-10 00:11:36,562][root][INFO] - Step 54855680 @ 3581.0 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 54855680, mean_episode_return = -3.1, mean_episode_step = 1191.2, total_loss = 62.936, pg_loss = 23.64, baseline_loss = 44.294, entropy_loss = -4.9973, learner_queue_size = 32, _tick = 13593, _time = 1.6548e+09, train_seconds = 1.4616e+04)
[2022-06-10 00:11:41,566][root][INFO] - Step 54876160 @ 4092.9 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 54876160, mean_episode_return = None, mean_episode_step = 848.38, total_loss = 59.862, pg_loss = 7.0937, baseline_loss = 57.844, entropy_loss = -5.0755, learner_queue_size = 32, _tick = 13599, _time = 1.6548e+09, train_seconds = 1.4621e+04)
[2022-06-10 00:11:46,570][root][INFO] - Step 54894080 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 54894080, mean_episode_return = None, mean_episode_step = 1090.1, total_loss = 195.82, pg_loss = 117.69, baseline_loss = 83.374, entropy_loss = -5.2362, learner_queue_size = 32, _tick = 13603, _time = 1.6548e+09, train_seconds = 1.4626e+04)
[2022-06-10 00:11:51,574][root][INFO] - Step 54912000 @ 3581.2 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 54912000, mean_episode_return = 27.645, mean_episode_step = 972.93, total_loss = 39.456, pg_loss = -3.9114, baseline_loss = 48.639, entropy_loss = -5.2715, learner_queue_size = 32, _tick = 13608, _time = 1.6548e+09, train_seconds = 1.4631e+04)
[2022-06-10 00:11:56,578][root][INFO] - Step 54929920 @ 3581.1 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 54929920, mean_episode_return = 25.3, mean_episode_step = 1457.7, total_loss = -93.7, pg_loss = -130.1, baseline_loss = 41.435, entropy_loss = -5.0342, learner_queue_size = 32, _tick = 13613, _time = 1.6548e+09, train_seconds = 1.4636e+04)
[2022-06-10 00:12:01,582][root][INFO] - Step 54950400 @ 4092.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 54950400, mean_episode_return = 12.68, mean_episode_step = 1271.9, total_loss = -97.778, pg_loss = -118.19, baseline_loss = 25.564, entropy_loss = -5.1526, learner_queue_size = 32, _tick = 13620, _time = 1.6548e+09, train_seconds = 1.4641e+04)
[2022-06-10 00:12:06,586][root][INFO] - Step 54968320 @ 3581.1 SPS. Inference batcher size: 86. Learner queue size: 32. Other stats: (step = 54968320, mean_episode_return = 80.668, mean_episode_step = 1048.2, total_loss = -135.45, pg_loss = -148.06, baseline_loss = 17.898, entropy_loss = -5.2886, learner_queue_size = 32, _tick = 13626, _time = 1.6548e+09, train_seconds = 1.4646e+04)
[2022-06-10 00:12:11,590][root][INFO] - Step 54986240 @ 3581.1 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (step = 54986240, mean_episode_return = 45.383, mean_episode_step = 758.51, total_loss = 112.56, pg_loss = 49.149, baseline_loss = 68.625, entropy_loss = -5.2111, learner_queue_size = 32, _tick = 13631, _time = 1.6548e+09, train_seconds = 1.4651e+04)
[2022-06-10 00:12:16,594][root][INFO] - Step 55004160 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 55004160, mean_episode_return = 36.081, mean_episode_step = 1018.7, total_loss = 32.407, pg_loss = -10.412, baseline_loss = 47.953, entropy_loss = -5.134, learner_queue_size = 32, _tick = 13637, _time = 1.6548e+09, train_seconds = 1.4656e+04)
[2022-06-10 00:12:21,598][root][INFO] - Step 55022080 @ 3581.2 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 55022080, mean_episode_return = 49.13, mean_episode_step = 1016.9, total_loss = -63.567, pg_loss = -131.3, baseline_loss = 72.993, entropy_loss = -5.2618, learner_queue_size = 32, _tick = 13642, _time = 1.6548e+09, train_seconds = 1.4661e+04)
[2022-06-10 00:12:26,602][root][INFO] - Step 55042560 @ 4092.7 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 55042560, mean_episode_return = 12.86, mean_episode_step = 1361.2, total_loss = 232.24, pg_loss = 170.67, baseline_loss = 66.807, entropy_loss = -5.238, learner_queue_size = 32, _tick = 13650, _time = 1.6548e+09, train_seconds = 1.4666e+04)
[2022-06-10 00:12:31,607][root][INFO] - Step 55060480 @ 3580.4 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 55060480, mean_episode_return = 45.875, mean_episode_step = 1181.5, total_loss = 295.56, pg_loss = 16.443, baseline_loss = 284.29, entropy_loss = -5.1713, learner_queue_size = 32, _tick = 13656, _time = 1.6548e+09, train_seconds = 1.4671e+04)
[2022-06-10 00:12:36,610][root][INFO] - Step 55080960 @ 4093.5 SPS. Inference batcher size: 90. Learner queue size: 32. Other stats: (step = 55080960, mean_episode_return = 74.53, mean_episode_step = 711.03, total_loss = 157.52, pg_loss = 79.621, baseline_loss = 82.875, entropy_loss = -4.9781, learner_queue_size = 32, _tick = 13664, _time = 1.6548e+09, train_seconds = 1.4676e+04)
[2022-06-10 00:12:41,614][root][INFO] - Step 55098880 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 55098880, mean_episode_return = 35.555, mean_episode_step = 934.37, total_loss = 278.01, pg_loss = 182.1, baseline_loss = 101.17, entropy_loss = -5.2586, learner_queue_size = 32, _tick = 13671, _time = 1.6548e+09, train_seconds = 1.4681e+04)
[2022-06-10 00:12:46,618][root][INFO] - Step 55116800 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 55116800, mean_episode_return = 82.157, mean_episode_step = 1015.3, total_loss = 18.798, pg_loss = -19.383, baseline_loss = 43.257, entropy_loss = -5.0763, learner_queue_size = 32, _tick = 13677, _time = 1.6548e+09, train_seconds = 1.4686e+04)
[2022-06-10 00:12:51,622][root][INFO] - Step 55137280 @ 4092.8 SPS. Inference batcher size: 85. Learner queue size: 32. Other stats: (step = 55137280, mean_episode_return = 18.49, mean_episode_step = 1488.5, total_loss = -96.799, pg_loss = -119.64, baseline_loss = 27.936, entropy_loss = -5.0907, learner_queue_size = 32, _tick = 13684, _time = 1.6548e+09, train_seconds = 1.4691e+04)
[2022-06-10 00:12:56,626][root][INFO] - Step 55155200 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 55155200, mean_episode_return = None, mean_episode_step = 804.41, total_loss = 198.32, pg_loss = 149.07, baseline_loss = 54.291, entropy_loss = -5.0408, learner_queue_size = 32, _tick = 13689, _time = 1.6548e+09, train_seconds = 1.4696e+04)
[2022-06-10 00:13:01,630][root][INFO] - Step 55175680 @ 4092.4 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 55175680, mean_episode_return = 41.168, mean_episode_step = 904.12, total_loss = -75.231, pg_loss = -197.55, baseline_loss = 127.27, entropy_loss = -4.9486, learner_queue_size = 32, _tick = 13694, _time = 1.6548e+09, train_seconds = 1.4701e+04)
[2022-06-10 00:13:06,634][root][INFO] - Step 55193600 @ 3581.0 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 55193600, mean_episode_return = 92.555, mean_episode_step = 959.98, total_loss = 213.67, pg_loss = 126.2, baseline_loss = 92.566, entropy_loss = -5.0958, learner_queue_size = 32, _tick = 13700, _time = 1.6548e+09, train_seconds = 1.4706e+04)
[2022-06-10 00:13:11,638][root][INFO] - Step 55211520 @ 3581.6 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 55211520, mean_episode_return = None, mean_episode_step = 1589.6, total_loss = -156.22, pg_loss = -180.14, baseline_loss = 29.152, entropy_loss = -5.2357, learner_queue_size = 32, _tick = 13704, _time = 1.6548e+09, train_seconds = 1.4711e+04)
[2022-06-10 00:13:16,642][root][INFO] - Step 55229440 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 55229440, mean_episode_return = None, mean_episode_step = 1828.6, total_loss = 243.28, pg_loss = 152.84, baseline_loss = 95.851, entropy_loss = -5.4131, learner_queue_size = 32, _tick = 13709, _time = 1.6548e+09, train_seconds = 1.4716e+04)
[2022-06-10 00:13:21,646][root][INFO] - Step 55249920 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 55249920, mean_episode_return = None, mean_episode_step = 1043.5, total_loss = 114.36, pg_loss = 61.696, baseline_loss = 57.921, entropy_loss = -5.2564, learner_queue_size = 32, _tick = 13715, _time = 1.6548e+09, train_seconds = 1.4722e+04)
[2022-06-10 00:13:26,650][root][INFO] - Step 55267840 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 55267840, mean_episode_return = 18.1, mean_episode_step = 931.26, total_loss = 99.163, pg_loss = 43.412, baseline_loss = 61.1, entropy_loss = -5.348, learner_queue_size = 32, _tick = 13721, _time = 1.6548e+09, train_seconds = 1.4726e+04)
[2022-06-10 00:13:31,656][root][INFO] - Step 55285760 @ 3579.6 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 55285760, mean_episode_return = None, mean_episode_step = 867.06, total_loss = -95.972, pg_loss = -132.33, baseline_loss = 41.827, entropy_loss = -5.4664, learner_queue_size = 32, _tick = 13726, _time = 1.6548e+09, train_seconds = 1.4732e+04)
[2022-06-10 00:13:36,662][root][INFO] - Step 55306240 @ 4091.2 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 55306240, mean_episode_return = None, mean_episode_step = 879.97, total_loss = -1.1941, pg_loss = -28.087, baseline_loss = 32.308, entropy_loss = -5.4153, learner_queue_size = 32, _tick = 13731, _time = 1.6548e+09, train_seconds = 1.4736e+04)
[2022-06-10 00:13:41,666][root][INFO] - Step 55324160 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 55324160, mean_episode_return = 24.664, mean_episode_step = 983.72, total_loss = 455.58, pg_loss = 361.41, baseline_loss = 99.656, entropy_loss = -5.4853, learner_queue_size = 32, _tick = 13735, _time = 1.6548e+09, train_seconds = 1.4742e+04)
[2022-06-10 00:13:46,670][root][INFO] - Step 55342080 @ 3581.2 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 55342080, mean_episode_return = 93.289, mean_episode_step = 1407.1, total_loss = 265.02, pg_loss = 219.43, baseline_loss = 51.081, entropy_loss = -5.4945, learner_queue_size = 32, _tick = 13740, _time = 1.6548e+09, train_seconds = 1.4746e+04)
[2022-06-10 00:13:51,674][root][INFO] - Step 55360000 @ 3581.1 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (step = 55360000, mean_episode_return = 37.99, mean_episode_step = 1647.1, total_loss = 138.72, pg_loss = 90.635, baseline_loss = 53.468, entropy_loss = -5.3863, learner_queue_size = 32, _tick = 13747, _time = 1.6548e+09, train_seconds = 1.4752e+04)
[2022-06-10 00:13:56,679][root][INFO] - Step 55380480 @ 4092.0 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 55380480, mean_episode_return = 36.225, mean_episode_step = 1712.3, total_loss = 65.801, pg_loss = -1.9661, baseline_loss = 73.059, entropy_loss = -5.2925, learner_queue_size = 32, _tick = 13752, _time = 1.6548e+09, train_seconds = 1.4756e+04)
[2022-06-10 00:14:01,682][root][INFO] - Step 55398400 @ 3581.8 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 55398400, mean_episode_return = 85.21, mean_episode_step = 1400.9, total_loss = -47.369, pg_loss = -114.12, baseline_loss = 71.684, entropy_loss = -4.9351, learner_queue_size = 32, _tick = 13758, _time = 1.6548e+09, train_seconds = 1.4762e+04)
[2022-06-10 00:14:06,686][root][INFO] - Step 55418880 @ 4092.5 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 55418880, mean_episode_return = 77.93, mean_episode_step = 1216.0, total_loss = 190.97, pg_loss = 125.28, baseline_loss = 70.867, entropy_loss = -5.1728, learner_queue_size = 32, _tick = 13766, _time = 1.6548e+09, train_seconds = 1.4766e+04)
[2022-06-10 00:14:11,690][root][INFO] - Step 55436800 @ 3581.3 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 55436800, mean_episode_return = 2.12, mean_episode_step = 973.02, total_loss = -39.572, pg_loss = -77.205, baseline_loss = 42.944, entropy_loss = -5.311, learner_queue_size = 32, _tick = 13773, _time = 1.6548e+09, train_seconds = 1.4772e+04)
[2022-06-10 00:14:16,694][root][INFO] - Step 55457280 @ 4092.8 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 55457280, mean_episode_return = 47.764, mean_episode_step = 1064.7, total_loss = 386.98, pg_loss = 284.34, baseline_loss = 107.85, entropy_loss = -5.2196, learner_queue_size = 32, _tick = 13780, _time = 1.6548e+09, train_seconds = 1.4776e+04)
[2022-06-10 00:14:21,698][root][INFO] - Step 55475200 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 55475200, mean_episode_return = 42.111, mean_episode_step = 955.5, total_loss = -92.226, pg_loss = -118.5, baseline_loss = 31.453, entropy_loss = -5.1761, learner_queue_size = 32, _tick = 13787, _time = 1.6548e+09, train_seconds = 1.4782e+04)
[2022-06-10 00:14:26,702][root][INFO] - Step 55493120 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 55493120, mean_episode_return = 48.465, mean_episode_step = 1028.3, total_loss = 62.166, pg_loss = -40.278, baseline_loss = 107.71, entropy_loss = -5.2631, learner_queue_size = 32, _tick = 13793, _time = 1.6548e+09, train_seconds = 1.4786e+04)
[2022-06-10 00:14:31,706][root][INFO] - Step 55513600 @ 4092.6 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 55513600, mean_episode_return = 19.715, mean_episode_step = 1751.8, total_loss = 4.6838, pg_loss = -37.288, baseline_loss = 47.0, entropy_loss = -5.028, learner_queue_size = 32, _tick = 13801, _time = 1.6548e+09, train_seconds = 1.4792e+04)
[2022-06-10 00:14:36,710][root][INFO] - Step 55531520 @ 3581.3 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 55531520, mean_episode_return = 94.244, mean_episode_step = 1273.8, total_loss = -152.48, pg_loss = -189.84, baseline_loss = 42.332, entropy_loss = -4.9766, learner_queue_size = 32, _tick = 13806, _time = 1.6548e+09, train_seconds = 1.4796e+04)
[2022-06-10 00:14:41,714][root][INFO] - Step 55549440 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 55549440, mean_episode_return = 163.91, mean_episode_step = 1228.5, total_loss = 10.64, pg_loss = -37.423, baseline_loss = 53.103, entropy_loss = -5.04, learner_queue_size = 32, _tick = 13812, _time = 1.6548e+09, train_seconds = 1.4802e+04)
[2022-06-10 00:14:46,718][root][INFO] - Step 55567360 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 55567360, mean_episode_return = 103.1, mean_episode_step = 1128.6, total_loss = 241.72, pg_loss = 122.84, baseline_loss = 124.05, entropy_loss = -5.1647, learner_queue_size = 32, _tick = 13819, _time = 1.6548e+09, train_seconds = 1.4806e+04)
[2022-06-10 00:14:51,722][root][INFO] - Step 55585280 @ 3581.2 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 55585280, mean_episode_return = 18.34, mean_episode_step = 1667.1, total_loss = 326.79, pg_loss = 213.35, baseline_loss = 118.69, entropy_loss = -5.2466, learner_queue_size = 32, _tick = 13825, _time = 1.6548e+09, train_seconds = 1.4812e+04)
[2022-06-10 00:14:56,727][root][INFO] - Step 55603200 @ 3580.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 55603200, mean_episode_return = 81.32, mean_episode_step = 1180.9, total_loss = 389.59, pg_loss = 290.68, baseline_loss = 104.25, entropy_loss = -5.3448, learner_queue_size = 32, _tick = 13831, _time = 1.6548e+09, train_seconds = 1.4816e+04)
[2022-06-10 00:15:01,730][root][INFO] - Step 55623680 @ 4093.0 SPS. Inference batcher size: 75. Learner queue size: 32. Other stats: (step = 55623680, mean_episode_return = 51.53, mean_episode_step = 1748.6, total_loss = -82.683, pg_loss = -122.78, baseline_loss = 45.408, entropy_loss = -5.3158, learner_queue_size = 32, _tick = 13838, _time = 1.6548e+09, train_seconds = 1.4822e+04)
[2022-06-10 00:15:06,734][root][INFO] - Step 55641600 @ 3581.3 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 55641600, mean_episode_return = 192.0, mean_episode_step = 1547.3, total_loss = 23.274, pg_loss = -15.679, baseline_loss = 44.309, entropy_loss = -5.3569, learner_queue_size = 32, _tick = 13843, _time = 1.6548e+09, train_seconds = 1.4826e+04)
[2022-06-10 00:15:11,738][root][INFO] - Step 55659520 @ 3581.0 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 55659520, mean_episode_return = None, mean_episode_step = 914.16, total_loss = 179.1, pg_loss = 128.64, baseline_loss = 55.854, entropy_loss = -5.3892, learner_queue_size = 32, _tick = 13847, _time = 1.6548e+09, train_seconds = 1.4832e+04)
[2022-06-10 00:15:16,742][root][INFO] - Step 55680000 @ 4092.9 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 55680000, mean_episode_return = None, mean_episode_step = 1226.2, total_loss = 90.754, pg_loss = 54.926, baseline_loss = 41.216, entropy_loss = -5.3873, learner_queue_size = 32, _tick = 13853, _time = 1.6548e+09, train_seconds = 1.4836e+04)
[2022-06-10 00:15:21,746][root][INFO] - Step 55697920 @ 3581.0 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 55697920, mean_episode_return = 54.244, mean_episode_step = 899.21, total_loss = -44.438, pg_loss = -87.777, baseline_loss = 48.672, entropy_loss = -5.3339, learner_queue_size = 32, _tick = 13858, _time = 1.6548e+09, train_seconds = 1.4842e+04)
[2022-06-10 00:15:26,750][root][INFO] - Step 55715840 @ 3581.3 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 55715840, mean_episode_return = 44.193, mean_episode_step = 1204.9, total_loss = -157.23, pg_loss = -173.45, baseline_loss = 21.516, entropy_loss = -5.303, learner_queue_size = 32, _tick = 13862, _time = 1.6548e+09, train_seconds = 1.4847e+04)
[2022-06-10 00:15:31,754][root][INFO] - Step 55733760 @ 3581.1 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 55733760, mean_episode_return = 65.85, mean_episode_step = 1322.1, total_loss = -166.46, pg_loss = -189.72, baseline_loss = 28.553, entropy_loss = -5.2927, learner_queue_size = 32, _tick = 13866, _time = 1.6548e+09, train_seconds = 1.4852e+04)
[2022-06-10 00:15:36,758][root][INFO] - Step 55754240 @ 4092.5 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 55754240, mean_episode_return = 19.24, mean_episode_step = 1006.5, total_loss = -18.303, pg_loss = -60.024, baseline_loss = 47.029, entropy_loss = -5.3071, learner_queue_size = 32, _tick = 13873, _time = 1.6548e+09, train_seconds = 1.4857e+04)
[2022-06-10 00:15:41,762][root][INFO] - Step 55772160 @ 3581.4 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 55772160, mean_episode_return = 114.33, mean_episode_step = 1559.0, total_loss = 7.9891, pg_loss = -103.26, baseline_loss = 116.59, entropy_loss = -5.3466, learner_queue_size = 32, _tick = 13875, _time = 1.6548e+09, train_seconds = 1.4862e+04)
[2022-06-10 00:15:46,766][root][INFO] - Step 55792640 @ 4092.7 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 55792640, mean_episode_return = -4.6552, mean_episode_step = 1546.5, total_loss = 2.4358, pg_loss = -28.128, baseline_loss = 35.973, entropy_loss = -5.4089, learner_queue_size = 32, _tick = 13882, _time = 1.6548e+09, train_seconds = 1.4867e+04)
[2022-06-10 00:15:51,770][root][INFO] - Step 55810560 @ 3581.1 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 55810560, mean_episode_return = 18.6, mean_episode_step = 1060.8, total_loss = -157.08, pg_loss = -167.66, baseline_loss = 15.98, entropy_loss = -5.4007, learner_queue_size = 32, _tick = 13887, _time = 1.6548e+09, train_seconds = 1.4872e+04)
[2022-06-10 00:15:56,774][root][INFO] - Step 55831040 @ 4092.8 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 55831040, mean_episode_return = 64.504, mean_episode_step = 1129.5, total_loss = -42.219, pg_loss = -73.924, baseline_loss = 37.053, entropy_loss = -5.3483, learner_queue_size = 32, _tick = 13894, _time = 1.6548e+09, train_seconds = 1.4877e+04)
[2022-06-10 00:16:01,778][root][INFO] - Step 55848960 @ 3581.1 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 55848960, mean_episode_return = 18.768, mean_episode_step = 1055.4, total_loss = 102.45, pg_loss = 48.024, baseline_loss = 59.749, entropy_loss = -5.3197, learner_queue_size = 32, _tick = 13899, _time = 1.6548e+09, train_seconds = 1.4882e+04)
[2022-06-10 00:16:06,782][root][INFO] - Step 55866880 @ 3581.1 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 55866880, mean_episode_return = 169.6, mean_episode_step = 1215.8, total_loss = -220.97, pg_loss = -257.6, baseline_loss = 42.026, entropy_loss = -5.4018, learner_queue_size = 32, _tick = 13906, _time = 1.6548e+09, train_seconds = 1.4887e+04)
[2022-06-10 00:16:11,786][root][INFO] - Step 55884800 @ 3581.1 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 55884800, mean_episode_return = None, mean_episode_step = 880.56, total_loss = 4.4132, pg_loss = -16.388, baseline_loss = 26.105, entropy_loss = -5.3036, learner_queue_size = 32, _tick = 13911, _time = 1.6548e+09, train_seconds = 1.4892e+04)
[2022-06-10 00:16:16,790][root][INFO] - Step 55905280 @ 4092.8 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 55905280, mean_episode_return = 73.271, mean_episode_step = 989.0, total_loss = 165.59, pg_loss = 86.095, baseline_loss = 84.706, entropy_loss = -5.2119, learner_queue_size = 32, _tick = 13918, _time = 1.6548e+09, train_seconds = 1.4897e+04)
[2022-06-10 00:16:21,794][root][INFO] - Step 55923200 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 55923200, mean_episode_return = 133.63, mean_episode_step = 2096.7, total_loss = -54.376, pg_loss = -85.976, baseline_loss = 36.913, entropy_loss = -5.3122, learner_queue_size = 32, _tick = 13922, _time = 1.6548e+09, train_seconds = 1.4902e+04)
[2022-06-10 00:16:26,798][root][INFO] - Step 55941120 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 55941120, mean_episode_return = None, mean_episode_step = 1018.8, total_loss = -37.708, pg_loss = -110.93, baseline_loss = 78.267, entropy_loss = -5.0465, learner_queue_size = 32, _tick = 13926, _time = 1.6548e+09, train_seconds = 1.4907e+04)
[2022-06-10 00:16:31,802][root][INFO] - Step 55959040 @ 3581.1 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (step = 55959040, mean_episode_return = -0.82, mean_episode_step = 1089.9, total_loss = 185.48, pg_loss = 83.393, baseline_loss = 107.25, entropy_loss = -5.1666, learner_queue_size = 32, _tick = 13931, _time = 1.6548e+09, train_seconds = 1.4912e+04)
[2022-06-10 00:16:36,806][root][INFO] - Step 55979520 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 55979520, mean_episode_return = 60.344, mean_episode_step = 921.35, total_loss = 240.03, pg_loss = 141.79, baseline_loss = 103.35, entropy_loss = -5.1119, learner_queue_size = 32, _tick = 13937, _time = 1.6548e+09, train_seconds = 1.4917e+04)
[2022-06-10 00:16:41,810][root][INFO] - Step 55997440 @ 3581.2 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 55997440, mean_episode_return = 38.927, mean_episode_step = 926.16, total_loss = -114.33, pg_loss = -152.46, baseline_loss = 43.432, entropy_loss = -5.308, learner_queue_size = 32, _tick = 13943, _time = 1.6548e+09, train_seconds = 1.4922e+04)
[2022-06-10 00:16:46,814][root][INFO] - Step 56017920 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 56017920, mean_episode_return = 57.92, mean_episode_step = 1120.2, total_loss = 260.42, pg_loss = 155.81, baseline_loss = 109.86, entropy_loss = -5.2508, learner_queue_size = 32, _tick = 13949, _time = 1.6548e+09, train_seconds = 1.4927e+04)
[2022-06-10 00:16:51,821][root][INFO] - Step 56035840 @ 3578.7 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 56035840, mean_episode_return = 136.67, mean_episode_step = 1004.4, total_loss = 115.08, pg_loss = 54.118, baseline_loss = 66.247, entropy_loss = -5.282, learner_queue_size = 32, _tick = 13955, _time = 1.6548e+09, train_seconds = 1.4932e+04)
[2022-06-10 00:16:56,826][root][INFO] - Step 56051200 @ 3069.2 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 56051200, mean_episode_return = 34.105, mean_episode_step = 1087.7, total_loss = 19.222, pg_loss = -27.415, baseline_loss = 52.019, entropy_loss = -5.3819, learner_queue_size = 32, _tick = 13960, _time = 1.6548e+09, train_seconds = 1.4937e+04)
[2022-06-10 00:17:01,830][root][INFO] - Step 56071680 @ 4092.4 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 56071680, mean_episode_return = 57.095, mean_episode_step = 1168.0, total_loss = 199.43, pg_loss = 97.068, baseline_loss = 107.67, entropy_loss = -5.3076, learner_queue_size = 32, _tick = 13967, _time = 1.6548e+09, train_seconds = 1.4942e+04)
[2022-06-10 00:17:06,834][root][INFO] - Step 56089600 @ 3581.4 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 56089600, mean_episode_return = 66.348, mean_episode_step = 1109.3, total_loss = -37.167, pg_loss = -60.55, baseline_loss = 28.771, entropy_loss = -5.3881, learner_queue_size = 32, _tick = 13970, _time = 1.6548e+09, train_seconds = 1.4947e+04)
[2022-06-10 00:17:11,838][root][INFO] - Step 56107520 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 56107520, mean_episode_return = 55.481, mean_episode_step = 1849.2, total_loss = 80.875, pg_loss = 31.297, baseline_loss = 55.015, entropy_loss = -5.4373, learner_queue_size = 32, _tick = 13974, _time = 1.6548e+09, train_seconds = 1.4952e+04)
[2022-06-10 00:17:16,842][root][INFO] - Step 56128000 @ 4092.7 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 56128000, mean_episode_return = 51.163, mean_episode_step = 1207.4, total_loss = -8.0844, pg_loss = -31.918, baseline_loss = 29.232, entropy_loss = -5.3986, learner_queue_size = 32, _tick = 13981, _time = 1.6548e+09, train_seconds = 1.4957e+04)
[2022-06-10 00:17:21,846][root][INFO] - Step 56145920 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 56145920, mean_episode_return = 34.862, mean_episode_step = 1749.1, total_loss = -15.311, pg_loss = -66.72, baseline_loss = 56.686, entropy_loss = -5.2772, learner_queue_size = 32, _tick = 13986, _time = 1.6548e+09, train_seconds = 1.4962e+04)
[2022-06-10 00:17:26,850][root][INFO] - Step 56166400 @ 4092.8 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 56166400, mean_episode_return = 49.716, mean_episode_step = 1308.6, total_loss = 107.55, pg_loss = 57.662, baseline_loss = 55.26, entropy_loss = -5.3697, learner_queue_size = 32, _tick = 13994, _time = 1.6548e+09, train_seconds = 1.4967e+04)
[2022-06-10 00:17:31,854][root][INFO] - Step 56184320 @ 3581.1 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 56184320, mean_episode_return = 5.2894, mean_episode_step = 1128.9, total_loss = -50.83, pg_loss = -77.701, baseline_loss = 32.188, entropy_loss = -5.3163, learner_queue_size = 32, _tick = 13999, _time = 1.6548e+09, train_seconds = 1.4972e+04)
[2022-06-10 00:17:36,858][root][INFO] - Step 56202240 @ 3581.1 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 56202240, mean_episode_return = 98.319, mean_episode_step = 1191.1, total_loss = -0.40364, pg_loss = -41.41, baseline_loss = 46.318, entropy_loss = -5.3122, learner_queue_size = 32, _tick = 14004, _time = 1.6548e+09, train_seconds = 1.4977e+04)
[2022-06-10 00:17:41,862][root][INFO] - Step 56222720 @ 4092.8 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 56222720, mean_episode_return = 9.8899, mean_episode_step = 1171.1, total_loss = 169.39, pg_loss = 101.16, baseline_loss = 73.568, entropy_loss = -5.3423, learner_queue_size = 32, _tick = 14010, _time = 1.6548e+09, train_seconds = 1.4982e+04)
[2022-06-10 00:17:46,866][root][INFO] - Step 56240640 @ 3581.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 56240640, mean_episode_return = 20.757, mean_episode_step = 1899.3, total_loss = 129.23, pg_loss = 66.082, baseline_loss = 68.399, entropy_loss = -5.254, learner_queue_size = 32, _tick = 14016, _time = 1.6548e+09, train_seconds = 1.4987e+04)
[2022-06-10 00:17:51,870][root][INFO] - Step 56261120 @ 4092.6 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 56261120, mean_episode_return = 24.513, mean_episode_step = 1161.7, total_loss = -147.21, pg_loss = -177.29, baseline_loss = 35.237, entropy_loss = -5.1575, learner_queue_size = 32, _tick = 14022, _time = 1.6548e+09, train_seconds = 1.4992e+04)
[2022-06-10 00:17:56,874][root][INFO] - Step 56279040 @ 3581.2 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 56279040, mean_episode_return = 19.11, mean_episode_step = 888.28, total_loss = 1.2675, pg_loss = -41.14, baseline_loss = 47.631, entropy_loss = -5.2236, learner_queue_size = 32, _tick = 14029, _time = 1.6548e+09, train_seconds = 1.4997e+04)
[2022-06-10 00:18:01,878][root][INFO] - Step 56299520 @ 4092.8 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 56299520, mean_episode_return = None, mean_episode_step = 832.41, total_loss = 261.46, pg_loss = 171.43, baseline_loss = 95.372, entropy_loss = -5.349, learner_queue_size = 32, _tick = 14035, _time = 1.6548e+09, train_seconds = 1.5002e+04)
[2022-06-10 00:18:06,882][root][INFO] - Step 56317440 @ 3581.0 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 56317440, mean_episode_return = 126.83, mean_episode_step = 1122.1, total_loss = 62.836, pg_loss = -16.213, baseline_loss = 84.386, entropy_loss = -5.3373, learner_queue_size = 32, _tick = 14040, _time = 1.6548e+09, train_seconds = 1.5007e+04)
[2022-06-10 00:18:11,886][root][INFO] - Step 56335360 @ 3581.3 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 56335360, mean_episode_return = None, mean_episode_step = 1025.1, total_loss = 202.56, pg_loss = 104.82, baseline_loss = 103.11, entropy_loss = -5.3634, learner_queue_size = 32, _tick = 14044, _time = 1.6548e+09, train_seconds = 1.5012e+04)
[2022-06-10 00:18:16,890][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 00:18:17,033][root][INFO] - Step 56355840 @ 4092.7 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 56355840, mean_episode_return = None, mean_episode_step = 984.25, total_loss = -57.499, pg_loss = -68.867, baseline_loss = 16.708, entropy_loss = -5.3395, learner_queue_size = 32, _tick = 14049, _time = 1.6548e+09, train_seconds = 1.5017e+04)
[2022-06-10 00:18:22,038][root][INFO] - Step 56373760 @ 3481.0 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 56373760, mean_episode_return = 106.19, mean_episode_step = 1777.2, total_loss = -39.153, pg_loss = -64.207, baseline_loss = 30.339, entropy_loss = -5.2849, learner_queue_size = 32, _tick = 14055, _time = 1.6548e+09, train_seconds = 1.5022e+04)
[2022-06-10 00:18:27,040][root][INFO] - Step 56391680 @ 3582.9 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 56391680, mean_episode_return = 63.391, mean_episode_step = 1108.7, total_loss = 279.69, pg_loss = 163.95, baseline_loss = 121.06, entropy_loss = -5.319, learner_queue_size = 32, _tick = 14060, _time = 1.6548e+09, train_seconds = 1.5027e+04)
[2022-06-10 00:18:32,042][root][INFO] - Step 56412160 @ 4093.9 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 56412160, mean_episode_return = 85.496, mean_episode_step = 1340.8, total_loss = 221.21, pg_loss = 98.487, baseline_loss = 128.02, entropy_loss = -5.2991, learner_queue_size = 32, _tick = 14067, _time = 1.6548e+09, train_seconds = 1.5032e+04)
[2022-06-10 00:18:37,046][root][INFO] - Step 56430080 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 56430080, mean_episode_return = -4.61, mean_episode_step = 1324.0, total_loss = 85.389, pg_loss = -0.30233, baseline_loss = 91.005, entropy_loss = -5.3142, learner_queue_size = 32, _tick = 14074, _time = 1.6548e+09, train_seconds = 1.5037e+04)
[2022-06-10 00:18:42,050][root][INFO] - Step 56450560 @ 4092.8 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 56450560, mean_episode_return = 54.991, mean_episode_step = 1608.6, total_loss = 161.49, pg_loss = 76.886, baseline_loss = 89.995, entropy_loss = -5.3954, learner_queue_size = 32, _tick = 14081, _time = 1.6548e+09, train_seconds = 1.5042e+04)
[2022-06-10 00:18:47,054][root][INFO] - Step 56468480 @ 3581.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 56468480, mean_episode_return = 29.827, mean_episode_step = 1299.9, total_loss = 151.97, pg_loss = 64.955, baseline_loss = 92.339, entropy_loss = -5.3229, learner_queue_size = 32, _tick = 14087, _time = 1.6548e+09, train_seconds = 1.5047e+04)
[2022-06-10 00:18:52,058][root][INFO] - Step 56488960 @ 4092.7 SPS. Inference batcher size: 73. Learner queue size: 32. Other stats: (step = 56488960, mean_episode_return = 89.091, mean_episode_step = 1023.8, total_loss = 106.72, pg_loss = 31.949, baseline_loss = 80.091, entropy_loss = -5.3243, learner_queue_size = 32, _tick = 14091, _time = 1.6548e+09, train_seconds = 1.5052e+04)
[2022-06-10 00:18:57,062][root][INFO] - Step 56506880 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 56506880, mean_episode_return = 58.86, mean_episode_step = 1127.3, total_loss = 280.15, pg_loss = 207.51, baseline_loss = 78.04, entropy_loss = -5.403, learner_queue_size = 32, _tick = 14098, _time = 1.6548e+09, train_seconds = 1.5057e+04)
[2022-06-10 00:19:02,066][root][INFO] - Step 56524800 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 56524800, mean_episode_return = None, mean_episode_step = 1871.2, total_loss = 24.537, pg_loss = -2.9527, baseline_loss = 32.877, entropy_loss = -5.3873, learner_queue_size = 32, _tick = 14103, _time = 1.6548e+09, train_seconds = 1.5062e+04)
[2022-06-10 00:19:07,070][root][INFO] - Step 56545280 @ 4092.8 SPS. Inference batcher size: 81. Learner queue size: 32. Other stats: (step = 56545280, mean_episode_return = 42.958, mean_episode_step = 1830.6, total_loss = 245.47, pg_loss = 161.73, baseline_loss = 89.055, entropy_loss = -5.3163, learner_queue_size = 32, _tick = 14110, _time = 1.6548e+09, train_seconds = 1.5067e+04)
[2022-06-10 00:19:12,074][root][INFO] - Step 56563200 @ 3581.0 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 56563200, mean_episode_return = None, mean_episode_step = 938.81, total_loss = 259.53, pg_loss = 201.9, baseline_loss = 62.934, entropy_loss = -5.2958, learner_queue_size = 32, _tick = 14116, _time = 1.6548e+09, train_seconds = 1.5072e+04)
[2022-06-10 00:19:17,078][root][INFO] - Step 56578560 @ 3069.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 56578560, mean_episode_return = -2.6158, mean_episode_step = 1230.1, total_loss = -68.837, pg_loss = -131.41, baseline_loss = 67.854, entropy_loss = -5.2808, learner_queue_size = 32, _tick = 14121, _time = 1.6548e+09, train_seconds = 1.5077e+04)
[2022-06-10 00:19:22,082][root][INFO] - Step 56596480 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 56596480, mean_episode_return = 30.11, mean_episode_step = 1005.1, total_loss = -21.813, pg_loss = -44.223, baseline_loss = 27.772, entropy_loss = -5.3627, learner_queue_size = 32, _tick = 14127, _time = 1.6548e+09, train_seconds = 1.5082e+04)
[2022-06-10 00:19:27,086][root][INFO] - Step 56614400 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 56614400, mean_episode_return = 52.88, mean_episode_step = 900.66, total_loss = 222.51, pg_loss = 169.2, baseline_loss = 58.611, entropy_loss = -5.301, learner_queue_size = 32, _tick = 14131, _time = 1.6548e+09, train_seconds = 1.5087e+04)
[2022-06-10 00:19:32,090][root][INFO] - Step 56634880 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 56634880, mean_episode_return = 5.8396, mean_episode_step = 1292.8, total_loss = 146.11, pg_loss = 82.557, baseline_loss = 68.657, entropy_loss = -5.1041, learner_queue_size = 32, _tick = 14138, _time = 1.6548e+09, train_seconds = 1.5092e+04)
[2022-06-10 00:19:37,094][root][INFO] - Step 56652800 @ 3581.2 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 56652800, mean_episode_return = 64.741, mean_episode_step = 1068.5, total_loss = 384.48, pg_loss = 263.64, baseline_loss = 126.02, entropy_loss = -5.1786, learner_queue_size = 32, _tick = 14144, _time = 1.6548e+09, train_seconds = 1.5097e+04)
[2022-06-10 00:19:42,098][root][INFO] - Step 56670720 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 56670720, mean_episode_return = 9.8698, mean_episode_step = 1620.1, total_loss = -113.27, pg_loss = -162.24, baseline_loss = 54.163, entropy_loss = -5.1881, learner_queue_size = 32, _tick = 14148, _time = 1.6548e+09, train_seconds = 1.5102e+04)
[2022-06-10 00:19:47,102][root][INFO] - Step 56691200 @ 4092.8 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 56691200, mean_episode_return = 26.67, mean_episode_step = 1021.1, total_loss = -134.91, pg_loss = -165.91, baseline_loss = 36.295, entropy_loss = -5.2911, learner_queue_size = 32, _tick = 14155, _time = 1.6548e+09, train_seconds = 1.5107e+04)
[2022-06-10 00:19:52,106][root][INFO] - Step 56709120 @ 3581.2 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 56709120, mean_episode_return = 38.001, mean_episode_step = 1011.9, total_loss = 180.04, pg_loss = 99.538, baseline_loss = 85.827, entropy_loss = -5.3262, learner_queue_size = 32, _tick = 14161, _time = 1.6548e+09, train_seconds = 1.5112e+04)
[2022-06-10 00:19:57,110][root][INFO] - Step 56727040 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 56727040, mean_episode_return = 35.213, mean_episode_step = 1005.5, total_loss = -33.865, pg_loss = -112.39, baseline_loss = 83.761, entropy_loss = -5.2402, learner_queue_size = 32, _tick = 14165, _time = 1.6548e+09, train_seconds = 1.5117e+04)
[2022-06-10 00:20:02,114][root][INFO] - Step 56747520 @ 4092.7 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (step = 56747520, mean_episode_return = None, mean_episode_step = 1540.0, total_loss = 489.72, pg_loss = 347.5, baseline_loss = 147.62, entropy_loss = -5.3997, learner_queue_size = 32, _tick = 14171, _time = 1.6548e+09, train_seconds = 1.5122e+04)
[2022-06-10 00:20:07,118][root][INFO] - Step 56765440 @ 3580.9 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 56765440, mean_episode_return = 48.511, mean_episode_step = 1304.4, total_loss = -119.54, pg_loss = -135.67, baseline_loss = 21.245, entropy_loss = -5.1177, learner_queue_size = 32, _tick = 14176, _time = 1.6548e+09, train_seconds = 1.5127e+04)
[2022-06-10 00:20:12,129][root][INFO] - Step 56783360 @ 3576.6 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 56783360, mean_episode_return = -4.0, mean_episode_step = 1070.1, total_loss = 258.44, pg_loss = 181.66, baseline_loss = 82.139, entropy_loss = -5.3589, learner_queue_size = 32, _tick = 14182, _time = 1.6548e+09, train_seconds = 1.5132e+04)
[2022-06-10 00:20:17,134][root][INFO] - Step 56801280 @ 3580.1 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 56801280, mean_episode_return = None, mean_episode_step = 1651.6, total_loss = 49.753, pg_loss = 21.325, baseline_loss = 33.683, entropy_loss = -5.2555, learner_queue_size = 32, _tick = 14187, _time = 1.6548e+09, train_seconds = 1.5137e+04)
[2022-06-10 00:20:22,138][root][INFO] - Step 56821760 @ 4092.8 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 56821760, mean_episode_return = -13.04, mean_episode_step = 1489.3, total_loss = 119.16, pg_loss = 60.824, baseline_loss = 63.467, entropy_loss = -5.1348, learner_queue_size = 32, _tick = 14194, _time = 1.6548e+09, train_seconds = 1.5142e+04)
[2022-06-10 00:20:27,142][root][INFO] - Step 56839680 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 56839680, mean_episode_return = 52.131, mean_episode_step = 1344.8, total_loss = 72.881, pg_loss = 22.556, baseline_loss = 55.445, entropy_loss = -5.1201, learner_queue_size = 32, _tick = 14199, _time = 1.6548e+09, train_seconds = 1.5147e+04)
[2022-06-10 00:20:32,146][root][INFO] - Step 56857600 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 56857600, mean_episode_return = 5.6396, mean_episode_step = 851.01, total_loss = 112.46, pg_loss = 83.983, baseline_loss = 33.852, entropy_loss = -5.3741, learner_queue_size = 32, _tick = 14205, _time = 1.6548e+09, train_seconds = 1.5152e+04)
[2022-06-10 00:20:37,150][root][INFO] - Step 56878080 @ 4092.7 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 56878080, mean_episode_return = 23.34, mean_episode_step = 1004.1, total_loss = 321.35, pg_loss = 240.64, baseline_loss = 86.076, entropy_loss = -5.368, learner_queue_size = 32, _tick = 14212, _time = 1.6548e+09, train_seconds = 1.5157e+04)
[2022-06-10 00:20:42,154][root][INFO] - Step 56896000 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 56896000, mean_episode_return = 81.641, mean_episode_step = 993.85, total_loss = -83.541, pg_loss = -95.09, baseline_loss = 16.768, entropy_loss = -5.2192, learner_queue_size = 32, _tick = 14219, _time = 1.6548e+09, train_seconds = 1.5162e+04)
[2022-06-10 00:20:47,158][root][INFO] - Step 56916480 @ 4092.7 SPS. Inference batcher size: 85. Learner queue size: 32. Other stats: (step = 56916480, mean_episode_return = 16.0, mean_episode_step = 816.89, total_loss = 41.113, pg_loss = -27.534, baseline_loss = 73.534, entropy_loss = -4.8871, learner_queue_size = 32, _tick = 14224, _time = 1.6548e+09, train_seconds = 1.5167e+04)
[2022-06-10 00:20:52,162][root][INFO] - Step 56934400 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 56934400, mean_episode_return = 68.862, mean_episode_step = 908.96, total_loss = -100.79, pg_loss = -134.87, baseline_loss = 39.096, entropy_loss = -5.0164, learner_queue_size = 32, _tick = 14229, _time = 1.6548e+09, train_seconds = 1.5172e+04)
[2022-06-10 00:20:57,166][root][INFO] - Step 56954880 @ 4092.7 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 56954880, mean_episode_return = 54.521, mean_episode_step = 1133.5, total_loss = -43.429, pg_loss = -52.5, baseline_loss = 14.431, entropy_loss = -5.3597, learner_queue_size = 32, _tick = 14236, _time = 1.6548e+09, train_seconds = 1.5177e+04)
[2022-06-10 00:21:02,170][root][INFO] - Step 56972800 @ 3581.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 56972800, mean_episode_return = -11.65, mean_episode_step = 1131.6, total_loss = 391.35, pg_loss = 314.49, baseline_loss = 82.247, entropy_loss = -5.3784, learner_queue_size = 32, _tick = 14242, _time = 1.6548e+09, train_seconds = 1.5182e+04)
[2022-06-10 00:21:07,174][root][INFO] - Step 56990720 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 56990720, mean_episode_return = 147.39, mean_episode_step = 1340.8, total_loss = 202.19, pg_loss = 131.85, baseline_loss = 75.716, entropy_loss = -5.3758, learner_queue_size = 32, _tick = 14249, _time = 1.6548e+09, train_seconds = 1.5187e+04)
[2022-06-10 00:21:12,178][root][INFO] - Step 57011200 @ 4092.7 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (step = 57011200, mean_episode_return = 38.696, mean_episode_step = 1201.4, total_loss = -170.13, pg_loss = -223.41, baseline_loss = 58.592, entropy_loss = -5.3104, learner_queue_size = 32, _tick = 14255, _time = 1.6548e+09, train_seconds = 1.5192e+04)
[2022-06-10 00:21:17,182][root][INFO] - Step 57029120 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 57029120, mean_episode_return = 101.33, mean_episode_step = 1033.2, total_loss = 237.91, pg_loss = 85.989, baseline_loss = 157.04, entropy_loss = -5.1216, learner_queue_size = 32, _tick = 14260, _time = 1.6548e+09, train_seconds = 1.5197e+04)
[2022-06-10 00:21:22,186][root][INFO] - Step 57047040 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 57047040, mean_episode_return = 58.53, mean_episode_step = 1305.8, total_loss = -231.16, pg_loss = -261.27, baseline_loss = 35.198, entropy_loss = -5.0845, learner_queue_size = 32, _tick = 14265, _time = 1.6548e+09, train_seconds = 1.5202e+04)
[2022-06-10 00:21:27,190][root][INFO] - Step 57067520 @ 4092.8 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 57067520, mean_episode_return = 78.808, mean_episode_step = 829.24, total_loss = -254.75, pg_loss = -342.04, baseline_loss = 92.154, entropy_loss = -4.8594, learner_queue_size = 32, _tick = 14272, _time = 1.6548e+09, train_seconds = 1.5207e+04)
[2022-06-10 00:21:32,194][root][INFO] - Step 57085440 @ 3581.2 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (step = 57085440, mean_episode_return = 144.04, mean_episode_step = 1058.2, total_loss = 88.111, pg_loss = 51.93, baseline_loss = 41.526, entropy_loss = -5.3452, learner_queue_size = 32, _tick = 14278, _time = 1.6548e+09, train_seconds = 1.5212e+04)
[2022-06-10 00:21:37,198][root][INFO] - Step 57103360 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 57103360, mean_episode_return = 19.1, mean_episode_step = 982.8, total_loss = 188.07, pg_loss = 108.8, baseline_loss = 84.632, entropy_loss = -5.3661, learner_queue_size = 32, _tick = 14285, _time = 1.6548e+09, train_seconds = 1.5217e+04)
[2022-06-10 00:21:42,202][root][INFO] - Step 57121280 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 57121280, mean_episode_return = 61.899, mean_episode_step = 1251.5, total_loss = -48.765, pg_loss = -115.42, baseline_loss = 72.01, entropy_loss = -5.36, learner_queue_size = 32, _tick = 14291, _time = 1.6548e+09, train_seconds = 1.5222e+04)
[2022-06-10 00:21:47,206][root][INFO] - Step 57139200 @ 3581.1 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (step = 57139200, mean_episode_return = 40.631, mean_episode_step = 919.45, total_loss = 9.1719, pg_loss = -61.31, baseline_loss = 75.822, entropy_loss = -5.3394, learner_queue_size = 32, _tick = 14296, _time = 1.6548e+09, train_seconds = 1.5227e+04)
[2022-06-10 00:21:52,210][root][INFO] - Step 57159680 @ 4092.6 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 57159680, mean_episode_return = None, mean_episode_step = 1963.9, total_loss = 21.99, pg_loss = 5.4831, baseline_loss = 21.813, entropy_loss = -5.306, learner_queue_size = 32, _tick = 14300, _time = 1.6548e+09, train_seconds = 1.5232e+04)
[2022-06-10 00:21:57,214][root][INFO] - Step 57177600 @ 3581.2 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 57177600, mean_episode_return = 94.437, mean_episode_step = 973.49, total_loss = -93.312, pg_loss = -150.74, baseline_loss = 62.552, entropy_loss = -5.1229, learner_queue_size = 32, _tick = 14305, _time = 1.6548e+09, train_seconds = 1.5237e+04)
[2022-06-10 00:22:02,218][root][INFO] - Step 57198080 @ 4092.7 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 57198080, mean_episode_return = 92.817, mean_episode_step = 921.02, total_loss = 61.722, pg_loss = 0.55587, baseline_loss = 66.507, entropy_loss = -5.3417, learner_queue_size = 32, _tick = 14313, _time = 1.6548e+09, train_seconds = 1.5242e+04)
[2022-06-10 00:22:07,222][root][INFO] - Step 57216000 @ 3581.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 57216000, mean_episode_return = 52.01, mean_episode_step = 1027.9, total_loss = 268.07, pg_loss = 191.24, baseline_loss = 82.147, entropy_loss = -5.3202, learner_queue_size = 32, _tick = 14318, _time = 1.6548e+09, train_seconds = 1.5247e+04)
[2022-06-10 00:22:12,226][root][INFO] - Step 57233920 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 57233920, mean_episode_return = 74.607, mean_episode_step = 1491.9, total_loss = 110.25, pg_loss = 19.693, baseline_loss = 95.894, entropy_loss = -5.3363, learner_queue_size = 32, _tick = 14325, _time = 1.6548e+09, train_seconds = 1.5252e+04)
[2022-06-10 00:22:17,230][root][INFO] - Step 57254400 @ 4092.6 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 57254400, mean_episode_return = None, mean_episode_step = 1025.4, total_loss = 19.121, pg_loss = -102.4, baseline_loss = 126.9, entropy_loss = -5.378, learner_queue_size = 32, _tick = 14332, _time = 1.6548e+09, train_seconds = 1.5257e+04)
[2022-06-10 00:22:22,234][root][INFO] - Step 57272320 @ 3581.2 SPS. Inference batcher size: 75. Learner queue size: 32. Other stats: (step = 57272320, mean_episode_return = 43.15, mean_episode_step = 1216.8, total_loss = 228.83, pg_loss = 164.44, baseline_loss = 69.676, entropy_loss = -5.2864, learner_queue_size = 32, _tick = 14339, _time = 1.6548e+09, train_seconds = 1.5262e+04)
[2022-06-10 00:22:27,238][root][INFO] - Step 57290240 @ 3581.2 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 57290240, mean_episode_return = None, mean_episode_step = 1030.9, total_loss = -14.096, pg_loss = -43.134, baseline_loss = 34.388, entropy_loss = -5.3496, learner_queue_size = 32, _tick = 14344, _time = 1.6548e+09, train_seconds = 1.5267e+04)
[2022-06-10 00:22:32,247][root][INFO] - Step 57310720 @ 4088.5 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 57310720, mean_episode_return = 44.741, mean_episode_step = 961.86, total_loss = 205.6, pg_loss = 95.62, baseline_loss = 115.28, entropy_loss = -5.3025, learner_queue_size = 32, _tick = 14350, _time = 1.6548e+09, train_seconds = 1.5272e+04)
[2022-06-10 00:22:37,250][root][INFO] - Step 57328640 @ 3582.0 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 57328640, mean_episode_return = 65.713, mean_episode_step = 1081.3, total_loss = -135.87, pg_loss = -161.12, baseline_loss = 30.483, entropy_loss = -5.2342, learner_queue_size = 32, _tick = 14355, _time = 1.6548e+09, train_seconds = 1.5277e+04)
[2022-06-10 00:22:42,254][root][INFO] - Step 57349120 @ 4092.7 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 57349120, mean_episode_return = 87.647, mean_episode_step = 1477.8, total_loss = 453.84, pg_loss = 357.9, baseline_loss = 101.27, entropy_loss = -5.3338, learner_queue_size = 32, _tick = 14362, _time = 1.6548e+09, train_seconds = 1.5282e+04)
[2022-06-10 00:22:47,259][root][INFO] - Step 57367040 @ 3580.6 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 57367040, mean_episode_return = 61.161, mean_episode_step = 1093.5, total_loss = 234.67, pg_loss = 155.9, baseline_loss = 84.055, entropy_loss = -5.284, learner_queue_size = 32, _tick = 14367, _time = 1.6548e+09, train_seconds = 1.5287e+04)
[2022-06-10 00:22:52,262][root][INFO] - Step 57387520 @ 4093.4 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 57387520, mean_episode_return = 18.08, mean_episode_step = 1406.0, total_loss = -152.7, pg_loss = -209.14, baseline_loss = 61.672, entropy_loss = -5.2359, learner_queue_size = 32, _tick = 14373, _time = 1.6548e+09, train_seconds = 1.5292e+04)
[2022-06-10 00:22:57,266][root][INFO] - Step 57405440 @ 3581.0 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 57405440, mean_episode_return = 38.899, mean_episode_step = 1737.9, total_loss = -120.64, pg_loss = -145.53, baseline_loss = 30.173, entropy_loss = -5.2831, learner_queue_size = 32, _tick = 14379, _time = 1.6548e+09, train_seconds = 1.5297e+04)
[2022-06-10 00:23:02,270][root][INFO] - Step 57420800 @ 3069.6 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 57420800, mean_episode_return = 12.631, mean_episode_step = 1042.2, total_loss = 86.267, pg_loss = 35.79, baseline_loss = 55.93, entropy_loss = -5.4529, learner_queue_size = 32, _tick = 14384, _time = 1.6548e+09, train_seconds = 1.5302e+04)
[2022-06-10 00:23:07,274][root][INFO] - Step 57441280 @ 4092.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 57441280, mean_episode_return = 110.99, mean_episode_step = 946.72, total_loss = 46.74, pg_loss = -18.598, baseline_loss = 70.782, entropy_loss = -5.4435, learner_queue_size = 32, _tick = 14389, _time = 1.6548e+09, train_seconds = 1.5307e+04)
[2022-06-10 00:23:12,280][root][INFO] - Step 57459200 @ 3579.8 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 57459200, mean_episode_return = 94.226, mean_episode_step = 1655.8, total_loss = 30.325, pg_loss = -18.392, baseline_loss = 54.124, entropy_loss = -5.4068, learner_queue_size = 32, _tick = 14395, _time = 1.6548e+09, train_seconds = 1.5312e+04)
[2022-06-10 00:23:17,282][root][INFO] - Step 57477120 @ 3582.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (step = 57477120, mean_episode_return = 27.68, mean_episode_step = 1022.8, total_loss = 188.35, pg_loss = 119.61, baseline_loss = 74.079, entropy_loss = -5.338, learner_queue_size = 32, _tick = 14402, _time = 1.6548e+09, train_seconds = 1.5317e+04)
[2022-06-10 00:23:22,286][root][INFO] - Step 57497600 @ 4092.5 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 57497600, mean_episode_return = 88.31, mean_episode_step = 790.0, total_loss = 194.42, pg_loss = 122.35, baseline_loss = 77.413, entropy_loss = -5.3352, learner_queue_size = 32, _tick = 14410, _time = 1.6548e+09, train_seconds = 1.5322e+04)
[2022-06-10 00:23:27,290][root][INFO] - Step 57515520 @ 3581.3 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 57515520, mean_episode_return = None, mean_episode_step = 769.62, total_loss = 182.51, pg_loss = 107.98, baseline_loss = 79.846, entropy_loss = -5.3191, learner_queue_size = 32, _tick = 14416, _time = 1.6548e+09, train_seconds = 1.5327e+04)
[2022-06-10 00:23:32,294][root][INFO] - Step 57536000 @ 4092.8 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 57536000, mean_episode_return = 36.362, mean_episode_step = 862.22, total_loss = -329.97, pg_loss = -343.59, baseline_loss = 18.996, entropy_loss = -5.3754, learner_queue_size = 32, _tick = 14420, _time = 1.6548e+09, train_seconds = 1.5332e+04)
[2022-06-10 00:23:37,298][root][INFO] - Step 57553920 @ 3581.1 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 57553920, mean_episode_return = 2.1299, mean_episode_step = 1492.1, total_loss = 56.769, pg_loss = 22.846, baseline_loss = 39.277, entropy_loss = -5.3541, learner_queue_size = 32, _tick = 14427, _time = 1.6548e+09, train_seconds = 1.5337e+04)
[2022-06-10 00:23:42,302][root][INFO] - Step 57571840 @ 3581.2 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 57571840, mean_episode_return = 171.91, mean_episode_step = 904.72, total_loss = 281.24, pg_loss = 210.67, baseline_loss = 75.898, entropy_loss = -5.3311, learner_queue_size = 32, _tick = 14433, _time = 1.6548e+09, train_seconds = 1.5342e+04)
[2022-06-10 00:23:47,306][root][INFO] - Step 57589760 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 57589760, mean_episode_return = 70.34, mean_episode_step = 926.34, total_loss = 658.47, pg_loss = 463.66, baseline_loss = 200.21, entropy_loss = -5.3999, learner_queue_size = 32, _tick = 14440, _time = 1.6548e+09, train_seconds = 1.5347e+04)
[2022-06-10 00:23:52,310][root][INFO] - Step 57610240 @ 4092.6 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 57610240, mean_episode_return = 29.03, mean_episode_step = 1141.8, total_loss = 119.59, pg_loss = 41.377, baseline_loss = 83.594, entropy_loss = -5.3826, learner_queue_size = 32, _tick = 14447, _time = 1.6548e+09, train_seconds = 1.5352e+04)
[2022-06-10 00:23:57,314][root][INFO] - Step 57628160 @ 3581.2 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 57628160, mean_episode_return = 14.06, mean_episode_step = 952.83, total_loss = 196.95, pg_loss = 137.21, baseline_loss = 65.106, entropy_loss = -5.3692, learner_queue_size = 32, _tick = 14451, _time = 1.6548e+09, train_seconds = 1.5357e+04)
[2022-06-10 00:24:02,318][root][INFO] - Step 57646080 @ 3581.1 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (step = 57646080, mean_episode_return = 95.249, mean_episode_step = 847.5, total_loss = 75.083, pg_loss = 22.724, baseline_loss = 57.608, entropy_loss = -5.2497, learner_queue_size = 32, _tick = 14457, _time = 1.6548e+09, train_seconds = 1.5362e+04)
[2022-06-10 00:24:07,322][root][INFO] - Step 57664000 @ 3581.1 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 57664000, mean_episode_return = 60.809, mean_episode_step = 1060.8, total_loss = 52.59, pg_loss = -14.497, baseline_loss = 72.385, entropy_loss = -5.2972, learner_queue_size = 32, _tick = 14462, _time = 1.6548e+09, train_seconds = 1.5367e+04)
[2022-06-10 00:24:12,326][root][INFO] - Step 57684480 @ 4092.7 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 57684480, mean_episode_return = 86.069, mean_episode_step = 1535.1, total_loss = -110.16, pg_loss = -134.84, baseline_loss = 29.954, entropy_loss = -5.274, learner_queue_size = 32, _tick = 14468, _time = 1.6548e+09, train_seconds = 1.5372e+04)
[2022-06-10 00:24:17,330][root][INFO] - Step 57702400 @ 3581.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 57702400, mean_episode_return = 8.4897, mean_episode_step = 917.18, total_loss = 107.67, pg_loss = 32.778, baseline_loss = 80.19, entropy_loss = -5.2973, learner_queue_size = 32, _tick = 14474, _time = 1.6548e+09, train_seconds = 1.5377e+04)
[2022-06-10 00:24:22,334][root][INFO] - Step 57720320 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 57720320, mean_episode_return = 71.654, mean_episode_step = 1143.4, total_loss = -82.143, pg_loss = -206.3, baseline_loss = 129.52, entropy_loss = -5.3627, learner_queue_size = 32, _tick = 14480, _time = 1.6548e+09, train_seconds = 1.5382e+04)
[2022-06-10 00:24:27,338][root][INFO] - Step 57740800 @ 4092.7 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 57740800, mean_episode_return = 14.89, mean_episode_step = 1084.2, total_loss = 370.76, pg_loss = 263.94, baseline_loss = 112.22, entropy_loss = -5.4037, learner_queue_size = 32, _tick = 14487, _time = 1.6548e+09, train_seconds = 1.5387e+04)
[2022-06-10 00:24:32,342][root][INFO] - Step 57758720 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 57758720, mean_episode_return = 140.94, mean_episode_step = 928.51, total_loss = 165.94, pg_loss = 109.2, baseline_loss = 62.178, entropy_loss = -5.4345, learner_queue_size = 32, _tick = 14493, _time = 1.6548e+09, train_seconds = 1.5392e+04)
[2022-06-10 00:24:37,346][root][INFO] - Step 57776640 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 57776640, mean_episode_return = 22.91, mean_episode_step = 990.29, total_loss = -47.065, pg_loss = -104.34, baseline_loss = 62.668, entropy_loss = -5.3965, learner_queue_size = 32, _tick = 14498, _time = 1.6548e+09, train_seconds = 1.5397e+04)
[2022-06-10 00:24:42,350][root][INFO] - Step 57794560 @ 3581.2 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 57794560, mean_episode_return = 5.2099, mean_episode_step = 1046.0, total_loss = 396.57, pg_loss = 296.44, baseline_loss = 105.56, entropy_loss = -5.4327, learner_queue_size = 32, _tick = 14505, _time = 1.6548e+09, train_seconds = 1.5402e+04)
[2022-06-10 00:24:47,354][root][INFO] - Step 57815040 @ 4092.7 SPS. Inference batcher size: 80. Learner queue size: 32. Other stats: (step = 57815040, mean_episode_return = 15.195, mean_episode_step = 1001.7, total_loss = -147.52, pg_loss = -166.35, baseline_loss = 24.162, entropy_loss = -5.3294, learner_queue_size = 32, _tick = 14510, _time = 1.6548e+09, train_seconds = 1.5407e+04)
[2022-06-10 00:24:52,358][root][INFO] - Step 57832960 @ 3581.2 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 57832960, mean_episode_return = 53.022, mean_episode_step = 1897.2, total_loss = 219.97, pg_loss = 82.221, baseline_loss = 143.03, entropy_loss = -5.2869, learner_queue_size = 32, _tick = 14517, _time = 1.6548e+09, train_seconds = 1.5412e+04)
[2022-06-10 00:24:57,362][root][INFO] - Step 57850880 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 57850880, mean_episode_return = None, mean_episode_step = 1072.8, total_loss = 91.633, pg_loss = 39.316, baseline_loss = 57.398, entropy_loss = -5.0816, learner_queue_size = 32, _tick = 14521, _time = 1.6548e+09, train_seconds = 1.5417e+04)
[2022-06-10 00:25:02,366][root][INFO] - Step 57871360 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 57871360, mean_episode_return = 158.43, mean_episode_step = 1050.5, total_loss = 285.96, pg_loss = 170.8, baseline_loss = 120.08, entropy_loss = -4.9254, learner_queue_size = 32, _tick = 14528, _time = 1.6548e+09, train_seconds = 1.5422e+04)
[2022-06-10 00:25:07,370][root][INFO] - Step 57889280 @ 3581.1 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 57889280, mean_episode_return = 65.469, mean_episode_step = 1001.6, total_loss = -154.99, pg_loss = -193.91, baseline_loss = 43.848, entropy_loss = -4.9275, learner_queue_size = 32, _tick = 14532, _time = 1.6548e+09, train_seconds = 1.5427e+04)
[2022-06-10 00:25:12,374][root][INFO] - Step 57907200 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 57907200, mean_episode_return = None, mean_episode_step = 971.88, total_loss = -22.067, pg_loss = -33.295, baseline_loss = 16.662, entropy_loss = -5.4349, learner_queue_size = 32, _tick = 14534, _time = 1.6548e+09, train_seconds = 1.5432e+04)
[2022-06-10 00:25:17,378][root][INFO] - Step 57925120 @ 3581.2 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 57925120, mean_episode_return = None, mean_episode_step = 961.25, total_loss = 216.25, pg_loss = 130.17, baseline_loss = 91.439, entropy_loss = -5.361, learner_queue_size = 32, _tick = 14539, _time = 1.6548e+09, train_seconds = 1.5437e+04)
[2022-06-10 00:25:22,382][root][INFO] - Step 57943040 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 57943040, mean_episode_return = 53.68, mean_episode_step = 1676.4, total_loss = 24.492, pg_loss = -25.399, baseline_loss = 55.309, entropy_loss = -5.4185, learner_queue_size = 32, _tick = 14546, _time = 1.6548e+09, train_seconds = 1.5442e+04)
[2022-06-10 00:25:27,387][root][INFO] - Step 57963520 @ 4092.0 SPS. Inference batcher size: 79. Learner queue size: 32. Other stats: (step = 57963520, mean_episode_return = 54.639, mean_episode_step = 982.02, total_loss = 41.616, pg_loss = 6.6944, baseline_loss = 40.257, entropy_loss = -5.3354, learner_queue_size = 32, _tick = 14553, _time = 1.6548e+09, train_seconds = 1.5447e+04)
[2022-06-10 00:25:32,390][root][INFO] - Step 57981440 @ 3581.6 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 57981440, mean_episode_return = 78.15, mean_episode_step = 976.53, total_loss = 88.147, pg_loss = 48.078, baseline_loss = 45.488, entropy_loss = -5.4181, learner_queue_size = 32, _tick = 14558, _time = 1.6548e+09, train_seconds = 1.5452e+04)
[2022-06-10 00:25:37,394][root][INFO] - Step 57999360 @ 3581.3 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 57999360, mean_episode_return = 81.621, mean_episode_step = 1019.3, total_loss = -98.832, pg_loss = -136.37, baseline_loss = 42.971, entropy_loss = -5.4279, learner_queue_size = 32, _tick = 14565, _time = 1.6548e+09, train_seconds = 1.5457e+04)
[2022-06-10 00:25:42,398][root][INFO] - Step 58019840 @ 4092.6 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (step = 58019840, mean_episode_return = 72.443, mean_episode_step = 1040.1, total_loss = 251.18, pg_loss = 142.55, baseline_loss = 114.02, entropy_loss = -5.3927, learner_queue_size = 32, _tick = 14572, _time = 1.6548e+09, train_seconds = 1.5462e+04)
[2022-06-10 00:25:47,402][root][INFO] - Step 58037760 @ 3581.2 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 58037760, mean_episode_return = 55.431, mean_episode_step = 980.28, total_loss = 84.088, pg_loss = 27.112, baseline_loss = 62.351, entropy_loss = -5.3748, learner_queue_size = 32, _tick = 14578, _time = 1.6548e+09, train_seconds = 1.5467e+04)
[2022-06-10 00:25:52,406][root][INFO] - Step 58055680 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 58055680, mean_episode_return = None, mean_episode_step = 1091.8, total_loss = 99.515, pg_loss = 65.093, baseline_loss = 39.653, entropy_loss = -5.2312, learner_queue_size = 32, _tick = 14583, _time = 1.6548e+09, train_seconds = 1.5472e+04)
[2022-06-10 00:25:57,410][root][INFO] - Step 58076160 @ 4092.8 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 58076160, mean_episode_return = 98.756, mean_episode_step = 833.98, total_loss = 434.03, pg_loss = 284.72, baseline_loss = 154.61, entropy_loss = -5.2947, learner_queue_size = 32, _tick = 14591, _time = 1.6548e+09, train_seconds = 1.5477e+04)
[2022-06-10 00:26:02,414][root][INFO] - Step 58094080 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 58094080, mean_episode_return = 14.55, mean_episode_step = 806.68, total_loss = 315.81, pg_loss = 199.5, baseline_loss = 121.54, entropy_loss = -5.2327, learner_queue_size = 32, _tick = 14596, _time = 1.6548e+09, train_seconds = 1.5482e+04)
[2022-06-10 00:26:07,418][root][INFO] - Step 58112000 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 58112000, mean_episode_return = None, mean_episode_step = 905.22, total_loss = 217.52, pg_loss = 124.55, baseline_loss = 98.101, entropy_loss = -5.1336, learner_queue_size = 32, _tick = 14601, _time = 1.6548e+09, train_seconds = 1.5487e+04)
[2022-06-10 00:26:12,422][root][INFO] - Step 58132480 @ 4092.7 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 58132480, mean_episode_return = 77.348, mean_episode_step = 1129.1, total_loss = -29.762, pg_loss = -80.274, baseline_loss = 55.745, entropy_loss = -5.2324, learner_queue_size = 32, _tick = 14607, _time = 1.6548e+09, train_seconds = 1.5492e+04)
[2022-06-10 00:26:17,426][root][INFO] - Step 58150400 @ 3581.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 58150400, mean_episode_return = 32.185, mean_episode_step = 1119.3, total_loss = 317.32, pg_loss = 110.6, baseline_loss = 211.93, entropy_loss = -5.2039, learner_queue_size = 32, _tick = 14612, _time = 1.6548e+09, train_seconds = 1.5497e+04)
[2022-06-10 00:26:22,430][root][INFO] - Step 58170880 @ 4092.8 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (step = 58170880, mean_episode_return = 133.82, mean_episode_step = 1027.7, total_loss = -60.746, pg_loss = -126.39, baseline_loss = 70.937, entropy_loss = -5.2956, learner_queue_size = 32, _tick = 14617, _time = 1.6548e+09, train_seconds = 1.5502e+04)
[2022-06-10 00:26:27,434][root][INFO] - Step 58188800 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 58188800, mean_episode_return = 80.48, mean_episode_step = 900.07, total_loss = 87.81, pg_loss = -93.852, baseline_loss = 186.75, entropy_loss = -5.0824, learner_queue_size = 32, _tick = 14623, _time = 1.6548e+09, train_seconds = 1.5507e+04)
[2022-06-10 00:26:32,438][root][INFO] - Step 58206720 @ 3581.1 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 58206720, mean_episode_return = 45.329, mean_episode_step = 1788.8, total_loss = -212.62, pg_loss = -221.88, baseline_loss = 14.603, entropy_loss = -5.3427, learner_queue_size = 32, _tick = 14629, _time = 1.6548e+09, train_seconds = 1.5512e+04)
[2022-06-10 00:26:37,442][root][INFO] - Step 58227200 @ 4092.8 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 58227200, mean_episode_return = 56.725, mean_episode_step = 928.23, total_loss = -112.76, pg_loss = -131.89, baseline_loss = 24.482, entropy_loss = -5.3556, learner_queue_size = 32, _tick = 14636, _time = 1.6548e+09, train_seconds = 1.5517e+04)
[2022-06-10 00:26:42,447][root][INFO] - Step 58245120 @ 3580.5 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 58245120, mean_episode_return = 78.82, mean_episode_step = 1016.4, total_loss = -68.184, pg_loss = -108.44, baseline_loss = 45.675, entropy_loss = -5.4225, learner_queue_size = 32, _tick = 14641, _time = 1.6548e+09, train_seconds = 1.5522e+04)
[2022-06-10 00:26:47,450][root][INFO] - Step 58263040 @ 3581.8 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 58263040, mean_episode_return = None, mean_episode_step = 1395.6, total_loss = -91.629, pg_loss = -105.28, baseline_loss = 19.081, entropy_loss = -5.4326, learner_queue_size = 32, _tick = 14646, _time = 1.6548e+09, train_seconds = 1.5527e+04)
[2022-06-10 00:26:52,454][root][INFO] - Step 58283520 @ 4092.7 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 58283520, mean_episode_return = 6.9398, mean_episode_step = 868.03, total_loss = 87.69, pg_loss = 53.544, baseline_loss = 39.42, entropy_loss = -5.2747, learner_queue_size = 32, _tick = 14653, _time = 1.6548e+09, train_seconds = 1.5532e+04)
[2022-06-10 00:26:57,458][root][INFO] - Step 58304000 @ 4092.6 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 58304000, mean_episode_return = 44.985, mean_episode_step = 1114.7, total_loss = 317.59, pg_loss = 201.42, baseline_loss = 121.4, entropy_loss = -5.2388, learner_queue_size = 32, _tick = 14659, _time = 1.6548e+09, train_seconds = 1.5537e+04)
[2022-06-10 00:27:02,462][root][INFO] - Step 58321920 @ 3581.2 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 58321920, mean_episode_return = None, mean_episode_step = 1096.9, total_loss = -136.36, pg_loss = -164.07, baseline_loss = 32.994, entropy_loss = -5.2888, learner_queue_size = 32, _tick = 14665, _time = 1.6548e+09, train_seconds = 1.5542e+04)
[2022-06-10 00:27:07,467][root][INFO] - Step 58339840 @ 3580.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 58339840, mean_episode_return = 117.41, mean_episode_step = 955.54, total_loss = 795.9, pg_loss = 492.51, baseline_loss = 308.73, entropy_loss = -5.3312, learner_queue_size = 32, _tick = 14671, _time = 1.6548e+09, train_seconds = 1.5547e+04)
[2022-06-10 00:27:12,470][root][INFO] - Step 58360320 @ 4094.0 SPS. Inference batcher size: 79. Learner queue size: 32. Other stats: (step = 58360320, mean_episode_return = 98.027, mean_episode_step = 1830.4, total_loss = -52.737, pg_loss = -86.2, baseline_loss = 38.766, entropy_loss = -5.3037, learner_queue_size = 32, _tick = 14677, _time = 1.6548e+09, train_seconds = 1.5552e+04)
[2022-06-10 00:27:17,474][root][INFO] - Step 58378240 @ 3581.1 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 58378240, mean_episode_return = None, mean_episode_step = 908.84, total_loss = 43.206, pg_loss = 4.0864, baseline_loss = 44.482, entropy_loss = -5.3623, learner_queue_size = 32, _tick = 14681, _time = 1.6548e+09, train_seconds = 1.5557e+04)
[2022-06-10 00:27:22,478][root][INFO] - Step 58396160 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 58396160, mean_episode_return = 58.07, mean_episode_step = 1004.7, total_loss = 23.685, pg_loss = 6.5102, baseline_loss = 22.511, entropy_loss = -5.3365, learner_queue_size = 32, _tick = 14685, _time = 1.6548e+09, train_seconds = 1.5562e+04)
[2022-06-10 00:27:27,482][root][INFO] - Step 58414080 @ 3581.2 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 58414080, mean_episode_return = 102.08, mean_episode_step = 996.19, total_loss = 128.52, pg_loss = 88.126, baseline_loss = 45.722, entropy_loss = -5.3302, learner_queue_size = 32, _tick = 14692, _time = 1.6548e+09, train_seconds = 1.5567e+04)
[2022-06-10 00:27:32,486][root][INFO] - Step 58432000 @ 3581.1 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 58432000, mean_episode_return = 96.839, mean_episode_step = 1195.0, total_loss = 333.76, pg_loss = 242.92, baseline_loss = 96.03, entropy_loss = -5.1998, learner_queue_size = 32, _tick = 14697, _time = 1.6548e+09, train_seconds = 1.5572e+04)
[2022-06-10 00:27:37,490][root][INFO] - Step 58452480 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 58452480, mean_episode_return = None, mean_episode_step = 1671.1, total_loss = -82.636, pg_loss = -98.548, baseline_loss = 21.159, entropy_loss = -5.2466, learner_queue_size = 32, _tick = 14703, _time = 1.6548e+09, train_seconds = 1.5577e+04)
[2022-06-10 00:27:42,494][root][INFO] - Step 58470400 @ 3581.1 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 58470400, mean_episode_return = None, mean_episode_step = 948.5, total_loss = 281.43, pg_loss = 187.41, baseline_loss = 99.295, entropy_loss = -5.2797, learner_queue_size = 32, _tick = 14709, _time = 1.6548e+09, train_seconds = 1.5582e+04)
[2022-06-10 00:27:47,499][root][INFO] - Step 58488320 @ 3580.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 58488320, mean_episode_return = 57.106, mean_episode_step = 1477.4, total_loss = -68.644, pg_loss = -115.75, baseline_loss = 52.349, entropy_loss = -5.2474, learner_queue_size = 32, _tick = 14715, _time = 1.6548e+09, train_seconds = 1.5587e+04)
[2022-06-10 00:27:52,502][root][INFO] - Step 58508800 @ 4093.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 58508800, mean_episode_return = 116.45, mean_episode_step = 920.36, total_loss = -155.24, pg_loss = -191.12, baseline_loss = 41.058, entropy_loss = -5.1836, learner_queue_size = 32, _tick = 14721, _time = 1.6548e+09, train_seconds = 1.5592e+04)
[2022-06-10 00:27:57,506][root][INFO] - Step 58526720 @ 3581.3 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 58526720, mean_episode_return = None, mean_episode_step = 883.16, total_loss = 241.36, pg_loss = 189.06, baseline_loss = 57.443, entropy_loss = -5.1426, learner_queue_size = 32, _tick = 14727, _time = 1.6548e+09, train_seconds = 1.5597e+04)
[2022-06-10 00:28:02,510][root][INFO] - Step 58544640 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 58544640, mean_episode_return = 57.228, mean_episode_step = 1324.5, total_loss = -242.7, pg_loss = -269.07, baseline_loss = 31.53, entropy_loss = -5.1597, learner_queue_size = 32, _tick = 14732, _time = 1.6548e+09, train_seconds = 1.5602e+04)
[2022-06-10 00:28:07,514][root][INFO] - Step 58565120 @ 4092.8 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 58565120, mean_episode_return = 32.4, mean_episode_step = 1044.8, total_loss = 200.08, pg_loss = 133.92, baseline_loss = 71.434, entropy_loss = -5.2715, learner_queue_size = 32, _tick = 14736, _time = 1.6548e+09, train_seconds = 1.5607e+04)
[2022-06-10 00:28:12,518][root][INFO] - Step 58583040 @ 3581.2 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 58583040, mean_episode_return = None, mean_episode_step = 1081.2, total_loss = -18.279, pg_loss = -55.516, baseline_loss = 42.537, entropy_loss = -5.2995, learner_queue_size = 32, _tick = 14741, _time = 1.6548e+09, train_seconds = 1.5612e+04)
[2022-06-10 00:28:17,522][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 00:28:17,723][root][INFO] - Step 58600960 @ 3581.1 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 58603520, mean_episode_return = None, mean_episode_step = 1117.8, total_loss = -84.155, pg_loss = -118.59, baseline_loss = 39.756, entropy_loss = -5.3252, learner_queue_size = 32, _tick = 14747, _time = 1.6548e+09, train_seconds = 1.5617e+04)
[2022-06-10 00:28:22,726][root][INFO] - Step 58621440 @ 3935.4 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 58621440, mean_episode_return = 59.363, mean_episode_step = 1054.7, total_loss = 267.9, pg_loss = 159.66, baseline_loss = 113.55, entropy_loss = -5.3098, learner_queue_size = 32, _tick = 14753, _time = 1.6548e+09, train_seconds = 1.5622e+04)
[2022-06-10 00:28:27,730][root][INFO] - Step 58639360 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 58639360, mean_episode_return = 51.76, mean_episode_step = 961.34, total_loss = 349.05, pg_loss = 217.23, baseline_loss = 137.07, entropy_loss = -5.2544, learner_queue_size = 32, _tick = 14760, _time = 1.6548e+09, train_seconds = 1.5628e+04)
[2022-06-10 00:28:32,734][root][INFO] - Step 58659840 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 58659840, mean_episode_return = 42.655, mean_episode_step = 1006.2, total_loss = 189.96, pg_loss = 120.56, baseline_loss = 74.676, entropy_loss = -5.27, learner_queue_size = 32, _tick = 14766, _time = 1.6548e+09, train_seconds = 1.5632e+04)
[2022-06-10 00:28:37,738][root][INFO] - Step 58677760 @ 3581.2 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 58677760, mean_episode_return = 113.81, mean_episode_step = 1134.0, total_loss = 219.01, pg_loss = 122.1, baseline_loss = 102.08, entropy_loss = -5.1663, learner_queue_size = 32, _tick = 14771, _time = 1.6548e+09, train_seconds = 1.5638e+04)
[2022-06-10 00:28:42,741][root][INFO] - Step 58695680 @ 3581.5 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 58695680, mean_episode_return = 50.815, mean_episode_step = 893.35, total_loss = 93.102, pg_loss = 34.699, baseline_loss = 63.604, entropy_loss = -5.2006, learner_queue_size = 32, _tick = 14777, _time = 1.6548e+09, train_seconds = 1.5642e+04)
[2022-06-10 00:28:47,746][root][INFO] - Step 58716160 @ 4092.3 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 58716160, mean_episode_return = 27.69, mean_episode_step = 959.44, total_loss = -15.501, pg_loss = -59.627, baseline_loss = 49.29, entropy_loss = -5.1635, learner_queue_size = 32, _tick = 14784, _time = 1.6548e+09, train_seconds = 1.5648e+04)
[2022-06-10 00:28:52,750][root][INFO] - Step 58734080 @ 3581.2 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (step = 58734080, mean_episode_return = 33.501, mean_episode_step = 790.89, total_loss = 102.59, pg_loss = 46.417, baseline_loss = 61.484, entropy_loss = -5.3127, learner_queue_size = 32, _tick = 14790, _time = 1.6548e+09, train_seconds = 1.5653e+04)
[2022-06-10 00:28:57,754][root][INFO] - Step 58752000 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 58752000, mean_episode_return = 84.38, mean_episode_step = 1305.0, total_loss = 74.194, pg_loss = 30.889, baseline_loss = 48.66, entropy_loss = -5.3551, learner_queue_size = 32, _tick = 14797, _time = 1.6548e+09, train_seconds = 1.5658e+04)
[2022-06-10 00:29:02,758][root][INFO] - Step 58772480 @ 4092.7 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 58772480, mean_episode_return = 54.028, mean_episode_step = 1067.9, total_loss = 111.81, pg_loss = 59.768, baseline_loss = 57.135, entropy_loss = -5.0907, learner_queue_size = 32, _tick = 14802, _time = 1.6548e+09, train_seconds = 1.5663e+04)
[2022-06-10 00:29:07,762][root][INFO] - Step 58790400 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 58790400, mean_episode_return = 26.595, mean_episode_step = 832.91, total_loss = 255.04, pg_loss = 147.39, baseline_loss = 112.75, entropy_loss = -5.108, learner_queue_size = 32, _tick = 14806, _time = 1.6548e+09, train_seconds = 1.5668e+04)
[2022-06-10 00:29:12,766][root][INFO] - Step 58810880 @ 4092.8 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 58810880, mean_episode_return = 42.958, mean_episode_step = 872.81, total_loss = 32.152, pg_loss = -30.15, baseline_loss = 67.394, entropy_loss = -5.0927, learner_queue_size = 32, _tick = 14813, _time = 1.6548e+09, train_seconds = 1.5673e+04)
[2022-06-10 00:29:17,771][root][INFO] - Step 58828800 @ 3580.0 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (step = 58828800, mean_episode_return = 57.761, mean_episode_step = 784.07, total_loss = -182.12, pg_loss = -221.23, baseline_loss = 44.051, entropy_loss = -4.9421, learner_queue_size = 32, _tick = 14818, _time = 1.6548e+09, train_seconds = 1.5678e+04)
[2022-06-10 00:29:22,774][root][INFO] - Step 58849280 @ 4093.6 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 58849280, mean_episode_return = 82.14, mean_episode_step = 957.26, total_loss = -4.175, pg_loss = -97.174, baseline_loss = 98.022, entropy_loss = -5.0223, learner_queue_size = 32, _tick = 14823, _time = 1.6548e+09, train_seconds = 1.5683e+04)
[2022-06-10 00:29:27,778][root][INFO] - Step 58867200 @ 3581.4 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 58867200, mean_episode_return = 87.136, mean_episode_step = 1157.0, total_loss = -88.468, pg_loss = -205.97, baseline_loss = 122.62, entropy_loss = -5.1242, learner_queue_size = 32, _tick = 14828, _time = 1.6548e+09, train_seconds = 1.5688e+04)
[2022-06-10 00:29:32,782][root][INFO] - Step 58885120 @ 3581.2 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 58885120, mean_episode_return = 10.72, mean_episode_step = 1138.8, total_loss = 36.126, pg_loss = -19.052, baseline_loss = 60.383, entropy_loss = -5.204, learner_queue_size = 32, _tick = 14834, _time = 1.6548e+09, train_seconds = 1.5693e+04)
[2022-06-10 00:29:37,786][root][INFO] - Step 58903040 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 58903040, mean_episode_return = None, mean_episode_step = 781.44, total_loss = 265.42, pg_loss = 183.64, baseline_loss = 86.895, entropy_loss = -5.1149, learner_queue_size = 32, _tick = 14839, _time = 1.6548e+09, train_seconds = 1.5698e+04)
[2022-06-10 00:29:42,790][root][INFO] - Step 58923520 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 58923520, mean_episode_return = 133.78, mean_episode_step = 899.92, total_loss = 38.04, pg_loss = 4.4525, baseline_loss = 38.909, entropy_loss = -5.3216, learner_queue_size = 32, _tick = 14846, _time = 1.6548e+09, train_seconds = 1.5703e+04)
[2022-06-10 00:29:47,794][root][INFO] - Step 58941440 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 58941440, mean_episode_return = None, mean_episode_step = 975.06, total_loss = 242.42, pg_loss = 191.1, baseline_loss = 56.44, entropy_loss = -5.1174, learner_queue_size = 32, _tick = 14852, _time = 1.6548e+09, train_seconds = 1.5708e+04)
[2022-06-10 00:29:52,798][root][INFO] - Step 58959360 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 58959360, mean_episode_return = 36.436, mean_episode_step = 723.15, total_loss = -120.45, pg_loss = -192.94, baseline_loss = 76.957, entropy_loss = -4.4666, learner_queue_size = 32, _tick = 14856, _time = 1.6548e+09, train_seconds = 1.5713e+04)
[2022-06-10 00:29:57,802][root][INFO] - Step 58974720 @ 3069.5 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 58974720, mean_episode_return = 56.545, mean_episode_step = 819.05, total_loss = -194.21, pg_loss = -258.23, baseline_loss = 68.86, entropy_loss = -4.8344, learner_queue_size = 32, _tick = 14861, _time = 1.6548e+09, train_seconds = 1.5718e+04)
[2022-06-10 00:30:02,806][root][INFO] - Step 58992640 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 58992640, mean_episode_return = 121.7, mean_episode_step = 1049.4, total_loss = 409.2, pg_loss = 275.67, baseline_loss = 138.49, entropy_loss = -4.9604, learner_queue_size = 32, _tick = 14866, _time = 1.6548e+09, train_seconds = 1.5723e+04)
[2022-06-10 00:30:07,811][root][INFO] - Step 59013120 @ 4092.2 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 59013120, mean_episode_return = 73.926, mean_episode_step = 833.87, total_loss = -119.59, pg_loss = -154.15, baseline_loss = 39.636, entropy_loss = -5.0767, learner_queue_size = 32, _tick = 14873, _time = 1.6548e+09, train_seconds = 1.5728e+04)
[2022-06-10 00:30:12,814][root][INFO] - Step 59031040 @ 3581.6 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 59031040, mean_episode_return = 73.389, mean_episode_step = 899.21, total_loss = 53.496, pg_loss = -37.636, baseline_loss = 96.146, entropy_loss = -5.0136, learner_queue_size = 32, _tick = 14880, _time = 1.6548e+09, train_seconds = 1.5733e+04)
[2022-06-10 00:30:17,818][root][INFO] - Step 59051520 @ 4092.6 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 59051520, mean_episode_return = 26.185, mean_episode_step = 815.92, total_loss = 15.938, pg_loss = -105.69, baseline_loss = 126.61, entropy_loss = -4.9784, learner_queue_size = 32, _tick = 14887, _time = 1.6548e+09, train_seconds = 1.5738e+04)
[2022-06-10 00:30:22,822][root][INFO] - Step 59069440 @ 3581.3 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 59069440, mean_episode_return = 87.919, mean_episode_step = 987.11, total_loss = 36.054, pg_loss = -4.5718, baseline_loss = 45.829, entropy_loss = -5.203, learner_queue_size = 32, _tick = 14891, _time = 1.6548e+09, train_seconds = 1.5743e+04)
[2022-06-10 00:30:27,826][root][INFO] - Step 59087360 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 59087360, mean_episode_return = 17.3, mean_episode_step = 1004.1, total_loss = 498.19, pg_loss = 363.57, baseline_loss = 139.73, entropy_loss = -5.1133, learner_queue_size = 32, _tick = 14898, _time = 1.6548e+09, train_seconds = 1.5748e+04)
[2022-06-10 00:30:32,830][root][INFO] - Step 59107840 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 59107840, mean_episode_return = 55.141, mean_episode_step = 1184.1, total_loss = 50.831, pg_loss = 8.7121, baseline_loss = 47.381, entropy_loss = -5.2626, learner_queue_size = 32, _tick = 14905, _time = 1.6548e+09, train_seconds = 1.5753e+04)
[2022-06-10 00:30:37,834][root][INFO] - Step 59125760 @ 3581.1 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 59125760, mean_episode_return = None, mean_episode_step = 1158.3, total_loss = 299.6, pg_loss = 230.36, baseline_loss = 74.412, entropy_loss = -5.1744, learner_queue_size = 32, _tick = 14911, _time = 1.6548e+09, train_seconds = 1.5758e+04)
[2022-06-10 00:30:42,838][root][INFO] - Step 59143680 @ 3581.2 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 59143680, mean_episode_return = 96.218, mean_episode_step = 1175.2, total_loss = -18.416, pg_loss = -86.985, baseline_loss = 73.796, entropy_loss = -5.2264, learner_queue_size = 32, _tick = 14918, _time = 1.6548e+09, train_seconds = 1.5763e+04)
[2022-06-10 00:30:47,842][root][INFO] - Step 59161600 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 59161600, mean_episode_return = 48.676, mean_episode_step = 949.37, total_loss = 414.23, pg_loss = 285.7, baseline_loss = 133.74, entropy_loss = -5.2145, learner_queue_size = 32, _tick = 14924, _time = 1.6548e+09, train_seconds = 1.5768e+04)
[2022-06-10 00:30:52,846][root][INFO] - Step 59182080 @ 4092.8 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 59182080, mean_episode_return = 73.239, mean_episode_step = 999.66, total_loss = 288.18, pg_loss = 211.07, baseline_loss = 82.463, entropy_loss = -5.3513, learner_queue_size = 32, _tick = 14932, _time = 1.6548e+09, train_seconds = 1.5773e+04)
[2022-06-10 00:30:57,850][root][INFO] - Step 59200000 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 59200000, mean_episode_return = 30.665, mean_episode_step = 937.62, total_loss = 345.92, pg_loss = 267.63, baseline_loss = 83.6, entropy_loss = -5.3066, learner_queue_size = 32, _tick = 14939, _time = 1.6548e+09, train_seconds = 1.5778e+04)
[2022-06-10 00:31:02,854][root][INFO] - Step 59220480 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 59220480, mean_episode_return = 110.28, mean_episode_step = 954.17, total_loss = 531.55, pg_loss = 401.43, baseline_loss = 135.33, entropy_loss = -5.214, learner_queue_size = 32, _tick = 14945, _time = 1.6548e+09, train_seconds = 1.5783e+04)
[2022-06-10 00:31:07,858][root][INFO] - Step 59238400 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 59238400, mean_episode_return = 89.275, mean_episode_step = 901.05, total_loss = 65.239, pg_loss = 24.202, baseline_loss = 46.111, entropy_loss = -5.0748, learner_queue_size = 32, _tick = 14951, _time = 1.6548e+09, train_seconds = 1.5788e+04)
[2022-06-10 00:31:12,862][root][INFO] - Step 59258880 @ 4092.8 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 59258880, mean_episode_return = 44.987, mean_episode_step = 1021.6, total_loss = -52.824, pg_loss = -134.85, baseline_loss = 87.116, entropy_loss = -5.092, learner_queue_size = 32, _tick = 14957, _time = 1.6548e+09, train_seconds = 1.5793e+04)
[2022-06-10 00:31:17,866][root][INFO] - Step 59276800 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 59276800, mean_episode_return = 81.935, mean_episode_step = 983.68, total_loss = -117.84, pg_loss = -148.44, baseline_loss = 35.797, entropy_loss = -5.1899, learner_queue_size = 32, _tick = 14963, _time = 1.6548e+09, train_seconds = 1.5798e+04)
[2022-06-10 00:31:22,870][root][INFO] - Step 59294720 @ 3581.2 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 59294720, mean_episode_return = 17.14, mean_episode_step = 937.71, total_loss = 97.431, pg_loss = 30.911, baseline_loss = 71.854, entropy_loss = -5.3339, learner_queue_size = 32, _tick = 14969, _time = 1.6548e+09, train_seconds = 1.5803e+04)
[2022-06-10 00:31:27,877][root][INFO] - Step 59312640 @ 3579.3 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 59312640, mean_episode_return = None, mean_episode_step = 793.84, total_loss = 224.85, pg_loss = 153.75, baseline_loss = 76.432, entropy_loss = -5.3388, learner_queue_size = 32, _tick = 14973, _time = 1.6548e+09, train_seconds = 1.5808e+04)
[2022-06-10 00:31:32,882][root][INFO] - Step 59333120 @ 4091.5 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 59333120, mean_episode_return = 140.93, mean_episode_step = 1306.5, total_loss = 377.68, pg_loss = 273.57, baseline_loss = 109.36, entropy_loss = -5.2533, learner_queue_size = 32, _tick = 14978, _time = 1.6548e+09, train_seconds = 1.5813e+04)
[2022-06-10 00:31:37,886][root][INFO] - Step 59351040 @ 3581.2 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 59351040, mean_episode_return = 139.49, mean_episode_step = 860.55, total_loss = 188.91, pg_loss = 121.38, baseline_loss = 72.785, entropy_loss = -5.2586, learner_queue_size = 32, _tick = 14984, _time = 1.6548e+09, train_seconds = 1.5818e+04)
[2022-06-10 00:31:42,890][root][INFO] - Step 59371520 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 59371520, mean_episode_return = 104.95, mean_episode_step = 1204.8, total_loss = 32.94, pg_loss = -2.3285, baseline_loss = 40.667, entropy_loss = -5.3992, learner_queue_size = 32, _tick = 14991, _time = 1.6548e+09, train_seconds = 1.5823e+04)
[2022-06-10 00:31:47,894][root][INFO] - Step 59389440 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 59389440, mean_episode_return = 100.46, mean_episode_step = 1169.5, total_loss = -126.03, pg_loss = -133.87, baseline_loss = 13.239, entropy_loss = -5.3954, learner_queue_size = 32, _tick = 14998, _time = 1.6548e+09, train_seconds = 1.5828e+04)
[2022-06-10 00:31:52,898][root][INFO] - Step 59407360 @ 3581.1 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 59407360, mean_episode_return = 72.65, mean_episode_step = 697.88, total_loss = 93.944, pg_loss = 48.043, baseline_loss = 51.082, entropy_loss = -5.1811, learner_queue_size = 32, _tick = 15005, _time = 1.6548e+09, train_seconds = 1.5833e+04)
[2022-06-10 00:31:57,902][root][INFO] - Step 59425280 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 59425280, mean_episode_return = None, mean_episode_step = 947.34, total_loss = -139.32, pg_loss = -156.73, baseline_loss = 22.734, entropy_loss = -5.3254, learner_queue_size = 32, _tick = 15009, _time = 1.6548e+09, train_seconds = 1.5838e+04)
[2022-06-10 00:32:02,906][root][INFO] - Step 59443200 @ 3581.1 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 59443200, mean_episode_return = 63.68, mean_episode_step = 827.18, total_loss = 4.1826, pg_loss = -36.627, baseline_loss = 46.164, entropy_loss = -5.355, learner_queue_size = 32, _tick = 15016, _time = 1.6548e+09, train_seconds = 1.5843e+04)
[2022-06-10 00:32:07,910][root][INFO] - Step 59463680 @ 4092.8 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 59463680, mean_episode_return = 90.57, mean_episode_step = 877.04, total_loss = -15.007, pg_loss = -58.791, baseline_loss = 49.049, entropy_loss = -5.2655, learner_queue_size = 32, _tick = 15021, _time = 1.6548e+09, train_seconds = 1.5848e+04)
[2022-06-10 00:32:12,914][root][INFO] - Step 59481600 @ 3581.2 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 59481600, mean_episode_return = None, mean_episode_step = 1067.7, total_loss = 168.79, pg_loss = 109.24, baseline_loss = 64.751, entropy_loss = -5.1976, learner_queue_size = 32, _tick = 15026, _time = 1.6548e+09, train_seconds = 1.5853e+04)
[2022-06-10 00:32:17,918][root][INFO] - Step 59502080 @ 4092.7 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 59502080, mean_episode_return = None, mean_episode_step = 1139.1, total_loss = 330.37, pg_loss = 215.39, baseline_loss = 120.17, entropy_loss = -5.1794, learner_queue_size = 32, _tick = 15031, _time = 1.6548e+09, train_seconds = 1.5858e+04)
[2022-06-10 00:32:22,922][root][INFO] - Step 59520000 @ 3581.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 59520000, mean_episode_return = None, mean_episode_step = 850.59, total_loss = 261.99, pg_loss = 185.56, baseline_loss = 81.673, entropy_loss = -5.2354, learner_queue_size = 32, _tick = 15037, _time = 1.6548e+09, train_seconds = 1.5863e+04)
[2022-06-10 00:32:27,926][root][INFO] - Step 59537920 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 59537920, mean_episode_return = None, mean_episode_step = 819.12, total_loss = 145.93, pg_loss = 85.34, baseline_loss = 65.867, entropy_loss = -5.273, learner_queue_size = 32, _tick = 15042, _time = 1.6548e+09, train_seconds = 1.5868e+04)
[2022-06-10 00:32:32,930][root][INFO] - Step 59555840 @ 3581.1 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (step = 59555840, mean_episode_return = 55.554, mean_episode_step = 1145.8, total_loss = 462.56, pg_loss = 304.12, baseline_loss = 163.58, entropy_loss = -5.1305, learner_queue_size = 32, _tick = 15048, _time = 1.6548e+09, train_seconds = 1.5873e+04)
[2022-06-10 00:32:37,934][root][INFO] - Step 59573760 @ 3581.2 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 59573760, mean_episode_return = 57.13, mean_episode_step = 1371.6, total_loss = 118.77, pg_loss = 59.655, baseline_loss = 64.395, entropy_loss = -5.2756, learner_queue_size = 32, _tick = 15053, _time = 1.6548e+09, train_seconds = 1.5878e+04)
[2022-06-10 00:32:42,938][root][INFO] - Step 59594240 @ 4092.7 SPS. Inference batcher size: 75. Learner queue size: 32. Other stats: (step = 59594240, mean_episode_return = 93.6, mean_episode_step = 1005.2, total_loss = -301.59, pg_loss = -360.22, baseline_loss = 63.897, entropy_loss = -5.2676, learner_queue_size = 32, _tick = 15060, _time = 1.6548e+09, train_seconds = 1.5883e+04)
[2022-06-10 00:32:47,942][root][INFO] - Step 59612160 @ 3581.1 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 59612160, mean_episode_return = None, mean_episode_step = 962.91, total_loss = -18.51, pg_loss = -47.463, baseline_loss = 34.229, entropy_loss = -5.276, learner_queue_size = 32, _tick = 15064, _time = 1.6548e+09, train_seconds = 1.5888e+04)
[2022-06-10 00:32:52,946][root][INFO] - Step 59630080 @ 3581.1 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 59630080, mean_episode_return = 34.335, mean_episode_step = 1122.8, total_loss = 307.34, pg_loss = 243.28, baseline_loss = 69.477, entropy_loss = -5.4143, learner_queue_size = 32, _tick = 15069, _time = 1.6548e+09, train_seconds = 1.5893e+04)
[2022-06-10 00:32:57,950][root][INFO] - Step 59648000 @ 3581.2 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 59648000, mean_episode_return = 50.78, mean_episode_step = 969.55, total_loss = -112.23, pg_loss = -147.64, baseline_loss = 40.746, entropy_loss = -5.3382, learner_queue_size = 32, _tick = 15076, _time = 1.6548e+09, train_seconds = 1.5898e+04)
[2022-06-10 00:33:02,954][root][INFO] - Step 59668480 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 59668480, mean_episode_return = None, mean_episode_step = 1342.1, total_loss = -215.08, pg_loss = -215.3, baseline_loss = 5.5049, entropy_loss = -5.2902, learner_queue_size = 32, _tick = 15083, _time = 1.6548e+09, train_seconds = 1.5903e+04)
[2022-06-10 00:33:07,958][root][INFO] - Step 59686400 @ 3581.1 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 59686400, mean_episode_return = 45.276, mean_episode_step = 1092.2, total_loss = -25.839, pg_loss = -124.57, baseline_loss = 103.93, entropy_loss = -5.2008, learner_queue_size = 32, _tick = 15088, _time = 1.6548e+09, train_seconds = 1.5908e+04)
[2022-06-10 00:33:12,962][root][INFO] - Step 59704320 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 59704320, mean_episode_return = 11.74, mean_episode_step = 1198.1, total_loss = -69.703, pg_loss = -98.343, baseline_loss = 33.747, entropy_loss = -5.1057, learner_queue_size = 32, _tick = 15094, _time = 1.6548e+09, train_seconds = 1.5913e+04)
[2022-06-10 00:33:17,966][root][INFO] - Step 59724800 @ 4092.7 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 59724800, mean_episode_return = None, mean_episode_step = 901.06, total_loss = 157.51, pg_loss = 87.169, baseline_loss = 75.582, entropy_loss = -5.242, learner_queue_size = 32, _tick = 15099, _time = 1.6548e+09, train_seconds = 1.5918e+04)
[2022-06-10 00:33:22,970][root][INFO] - Step 59742720 @ 3581.2 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 59742720, mean_episode_return = 42.43, mean_episode_step = 1100.1, total_loss = 312.21, pg_loss = 216.4, baseline_loss = 101.04, entropy_loss = -5.2232, learner_queue_size = 32, _tick = 15105, _time = 1.6548e+09, train_seconds = 1.5923e+04)
[2022-06-10 00:33:27,974][root][INFO] - Step 59763200 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 59763200, mean_episode_return = 44.861, mean_episode_step = 1397.3, total_loss = -68.651, pg_loss = -102.96, baseline_loss = 39.53, entropy_loss = -5.2211, learner_queue_size = 32, _tick = 15112, _time = 1.6548e+09, train_seconds = 1.5928e+04)
[2022-06-10 00:33:32,978][root][INFO] - Step 59781120 @ 3581.1 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 59781120, mean_episode_return = 112.54, mean_episode_step = 861.01, total_loss = 84.09, pg_loss = 0.45547, baseline_loss = 88.888, entropy_loss = -5.2531, learner_queue_size = 32, _tick = 15118, _time = 1.6548e+09, train_seconds = 1.5933e+04)
[2022-06-10 00:33:37,982][root][INFO] - Step 59799040 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 59799040, mean_episode_return = 100.19, mean_episode_step = 975.11, total_loss = -41.547, pg_loss = -51.313, baseline_loss = 15.077, entropy_loss = -5.3114, learner_queue_size = 32, _tick = 15123, _time = 1.6548e+09, train_seconds = 1.5938e+04)
[2022-06-10 00:33:42,986][root][INFO] - Step 59816960 @ 3581.1 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 59816960, mean_episode_return = None, mean_episode_step = 1261.8, total_loss = -73.878, pg_loss = -84.687, baseline_loss = 16.082, entropy_loss = -5.273, learner_queue_size = 32, _tick = 15128, _time = 1.6548e+09, train_seconds = 1.5943e+04)
[2022-06-10 00:33:47,990][root][INFO] - Step 59829760 @ 2557.9 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 59829760, mean_episode_return = 18.25, mean_episode_step = 1273.8, total_loss = -115.6, pg_loss = -139.82, baseline_loss = 29.438, entropy_loss = -5.2248, learner_queue_size = 32, _tick = 15133, _time = 1.6548e+09, train_seconds = 1.5948e+04)
[2022-06-10 00:33:52,994][root][INFO] - Step 59847680 @ 3581.2 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 59847680, mean_episode_return = 74.549, mean_episode_step = 815.95, total_loss = 466.85, pg_loss = 356.86, baseline_loss = 115.21, entropy_loss = -5.2196, learner_queue_size = 32, _tick = 15138, _time = 1.6548e+09, train_seconds = 1.5953e+04)
[2022-06-10 00:33:57,998][root][INFO] - Step 59868160 @ 4092.7 SPS. Inference batcher size: 73. Learner queue size: 32. Other stats: (step = 59868160, mean_episode_return = 55.321, mean_episode_step = 1190.8, total_loss = -9.3126, pg_loss = -42.712, baseline_loss = 38.521, entropy_loss = -5.1214, learner_queue_size = 32, _tick = 15144, _time = 1.6548e+09, train_seconds = 1.5958e+04)
[2022-06-10 00:34:03,002][root][INFO] - Step 59886080 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 59886080, mean_episode_return = None, mean_episode_step = 1241.1, total_loss = 174.99, pg_loss = 89.276, baseline_loss = 90.931, entropy_loss = -5.2221, learner_queue_size = 32, _tick = 15148, _time = 1.6548e+09, train_seconds = 1.5963e+04)
[2022-06-10 00:34:08,006][root][INFO] - Step 59906560 @ 4092.7 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 59906560, mean_episode_return = -11.08, mean_episode_step = 1426.2, total_loss = -65.651, pg_loss = -112.34, baseline_loss = 51.779, entropy_loss = -5.0939, learner_queue_size = 32, _tick = 15155, _time = 1.6548e+09, train_seconds = 1.5968e+04)
[2022-06-10 00:34:13,010][root][INFO] - Step 59924480 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 59924480, mean_episode_return = None, mean_episode_step = 1075.3, total_loss = 232.95, pg_loss = 149.41, baseline_loss = 88.688, entropy_loss = -5.1482, learner_queue_size = 32, _tick = 15160, _time = 1.6548e+09, train_seconds = 1.5973e+04)
[2022-06-10 00:34:18,016][root][INFO] - Step 59942400 @ 3579.9 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 59942400, mean_episode_return = 7.7297, mean_episode_step = 1600.3, total_loss = -67.777, pg_loss = -105.39, baseline_loss = 42.873, entropy_loss = -5.2602, learner_queue_size = 32, _tick = 15165, _time = 1.6548e+09, train_seconds = 1.5978e+04)
[2022-06-10 00:34:23,018][root][INFO] - Step 59960320 @ 3582.3 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 59960320, mean_episode_return = 77.385, mean_episode_step = 1391.4, total_loss = 546.15, pg_loss = 386.55, baseline_loss = 164.84, entropy_loss = -5.2419, learner_queue_size = 32, _tick = 15170, _time = 1.6548e+09, train_seconds = 1.5983e+04)
[2022-06-10 00:34:28,023][root][INFO] - Step 59978240 @ 3580.7 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 59978240, mean_episode_return = 87.897, mean_episode_step = 1189.7, total_loss = -153.07, pg_loss = -202.05, baseline_loss = 54.215, entropy_loss = -5.2294, learner_queue_size = 32, _tick = 15176, _time = 1.6548e+09, train_seconds = 1.5988e+04)
[2022-06-10 00:34:33,026][root][INFO] - Step 59998720 @ 4093.3 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 59998720, mean_episode_return = 61.235, mean_episode_step = 1071.1, total_loss = -91.051, pg_loss = -167.93, baseline_loss = 82.138, entropy_loss = -5.2567, learner_queue_size = 32, _tick = 15183, _time = 1.6548e+09, train_seconds = 1.5993e+04)
[2022-06-10 00:34:38,030][root][INFO] - Step 60016640 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 60016640, mean_episode_return = 76.4, mean_episode_step = 1575.7, total_loss = 91.391, pg_loss = 39.396, baseline_loss = 57.286, entropy_loss = -5.2908, learner_queue_size = 32, _tick = 15188, _time = 1.6548e+09, train_seconds = 1.5998e+04)
[2022-06-10 00:34:43,034][root][INFO] - Step 60037120 @ 4092.7 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 60037120, mean_episode_return = None, mean_episode_step = 1160.7, total_loss = 80.332, pg_loss = 12.737, baseline_loss = 72.917, entropy_loss = -5.3224, learner_queue_size = 32, _tick = 15194, _time = 1.6548e+09, train_seconds = 1.6003e+04)
[2022-06-10 00:34:48,038][root][INFO] - Step 60055040 @ 3580.8 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 60055040, mean_episode_return = 45.19, mean_episode_step = 1054.1, total_loss = -56.427, pg_loss = -86.942, baseline_loss = 35.577, entropy_loss = -5.0614, learner_queue_size = 32, _tick = 15200, _time = 1.6548e+09, train_seconds = 1.6008e+04)
[2022-06-10 00:34:53,042][root][INFO] - Step 60072960 @ 3581.2 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 60072960, mean_episode_return = 97.76, mean_episode_step = 990.56, total_loss = 74.338, pg_loss = 36.652, baseline_loss = 43.003, entropy_loss = -5.3168, learner_queue_size = 32, _tick = 15207, _time = 1.6548e+09, train_seconds = 1.6013e+04)
[2022-06-10 00:34:58,046][root][INFO] - Step 60093440 @ 4093.0 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 60093440, mean_episode_return = 44.175, mean_episode_step = 1173.9, total_loss = 62.211, pg_loss = -28.479, baseline_loss = 96.108, entropy_loss = -5.4177, learner_queue_size = 32, _tick = 15215, _time = 1.6548e+09, train_seconds = 1.6018e+04)
[2022-06-10 00:35:03,050][root][INFO] - Step 60111360 @ 3581.1 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 60111360, mean_episode_return = 69.965, mean_episode_step = 1081.7, total_loss = -182.02, pg_loss = -215.42, baseline_loss = 38.692, entropy_loss = -5.2903, learner_queue_size = 32, _tick = 15220, _time = 1.6548e+09, train_seconds = 1.6023e+04)
[2022-06-10 00:35:08,054][root][INFO] - Step 60131840 @ 4092.5 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 60131840, mean_episode_return = None, mean_episode_step = 694.28, total_loss = 145.4, pg_loss = 98.46, baseline_loss = 52.317, entropy_loss = -5.372, learner_queue_size = 32, _tick = 15224, _time = 1.6548e+09, train_seconds = 1.6028e+04)
[2022-06-10 00:35:13,058][root][INFO] - Step 60149760 @ 3581.2 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 60149760, mean_episode_return = 91.421, mean_episode_step = 1044.8, total_loss = 164.85, pg_loss = 87.49, baseline_loss = 82.748, entropy_loss = -5.3837, learner_queue_size = 32, _tick = 15231, _time = 1.6548e+09, train_seconds = 1.6033e+04)
[2022-06-10 00:35:18,062][root][INFO] - Step 60170240 @ 4092.8 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 60170240, mean_episode_return = 173.95, mean_episode_step = 977.56, total_loss = -26.196, pg_loss = -44.197, baseline_loss = 23.434, entropy_loss = -5.4332, learner_queue_size = 32, _tick = 15237, _time = 1.6548e+09, train_seconds = 1.6038e+04)
[2022-06-10 00:35:23,066][root][INFO] - Step 60188160 @ 3581.1 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 60188160, mean_episode_return = 38.171, mean_episode_step = 933.17, total_loss = 401.24, pg_loss = 287.54, baseline_loss = 119.1, entropy_loss = -5.4014, learner_queue_size = 32, _tick = 15242, _time = 1.6548e+09, train_seconds = 1.6043e+04)
[2022-06-10 00:35:28,070][root][INFO] - Step 60206080 @ 3581.1 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 60206080, mean_episode_return = 109.49, mean_episode_step = 912.16, total_loss = -4.6513, pg_loss = -17.984, baseline_loss = 18.684, entropy_loss = -5.3514, learner_queue_size = 32, _tick = 15248, _time = 1.6548e+09, train_seconds = 1.6048e+04)
[2022-06-10 00:35:33,074][root][INFO] - Step 60224000 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 60224000, mean_episode_return = 108.37, mean_episode_step = 1216.3, total_loss = 655.44, pg_loss = 542.67, baseline_loss = 118.11, entropy_loss = -5.3437, learner_queue_size = 32, _tick = 15253, _time = 1.6548e+09, train_seconds = 1.6053e+04)
[2022-06-10 00:35:38,078][root][INFO] - Step 60244480 @ 4092.6 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 60244480, mean_episode_return = 9.7399, mean_episode_step = 923.99, total_loss = 224.83, pg_loss = 106.65, baseline_loss = 123.46, entropy_loss = -5.2836, learner_queue_size = 32, _tick = 15260, _time = 1.6548e+09, train_seconds = 1.6058e+04)
[2022-06-10 00:35:43,082][root][INFO] - Step 60262400 @ 3581.3 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 60262400, mean_episode_return = 38.624, mean_episode_step = 1317.1, total_loss = -179.86, pg_loss = -191.6, baseline_loss = 17.083, entropy_loss = -5.3445, learner_queue_size = 32, _tick = 15266, _time = 1.6548e+09, train_seconds = 1.6063e+04)
[2022-06-10 00:35:48,086][root][INFO] - Step 60282880 @ 4092.7 SPS. Inference batcher size: 82. Learner queue size: 32. Other stats: (step = 60282880, mean_episode_return = 163.75, mean_episode_step = 1167.4, total_loss = 51.599, pg_loss = 16.491, baseline_loss = 40.39, entropy_loss = -5.2814, learner_queue_size = 32, _tick = 15272, _time = 1.6548e+09, train_seconds = 1.6068e+04)
[2022-06-10 00:35:53,090][root][INFO] - Step 60300800 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 60300800, mean_episode_return = 62.803, mean_episode_step = 1150.3, total_loss = 140.01, pg_loss = 76.075, baseline_loss = 69.27, entropy_loss = -5.3309, learner_queue_size = 32, _tick = 15278, _time = 1.6548e+09, train_seconds = 1.6073e+04)
[2022-06-10 00:35:58,096][root][INFO] - Step 60318720 @ 3579.7 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 60318720, mean_episode_return = None, mean_episode_step = 871.91, total_loss = 215.98, pg_loss = 153.35, baseline_loss = 67.748, entropy_loss = -5.1219, learner_queue_size = 32, _tick = 15282, _time = 1.6548e+09, train_seconds = 1.6078e+04)
[2022-06-10 00:36:03,098][root][INFO] - Step 60339200 @ 4094.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 60339200, mean_episode_return = None, mean_episode_step = 976.06, total_loss = -13.699, pg_loss = -76.611, baseline_loss = 68.202, entropy_loss = -5.29, learner_queue_size = 32, _tick = 15288, _time = 1.6548e+09, train_seconds = 1.6083e+04)
[2022-06-10 00:36:08,106][root][INFO] - Step 60357120 @ 3578.5 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 60357120, mean_episode_return = 29.33, mean_episode_step = 952.91, total_loss = 62.589, pg_loss = 21.288, baseline_loss = 46.685, entropy_loss = -5.3842, learner_queue_size = 32, _tick = 15295, _time = 1.6548e+09, train_seconds = 1.6088e+04)
[2022-06-10 00:36:13,110][root][INFO] - Step 60377600 @ 4092.8 SPS. Inference batcher size: 78. Learner queue size: 32. Other stats: (step = 60377600, mean_episode_return = None, mean_episode_step = 1257.6, total_loss = -10.319, pg_loss = -31.307, baseline_loss = 26.379, entropy_loss = -5.3906, learner_queue_size = 32, _tick = 15301, _time = 1.6548e+09, train_seconds = 1.6093e+04)
[2022-06-10 00:36:18,114][root][INFO] - Step 60395520 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 60395520, mean_episode_return = 44.05, mean_episode_step = 1079.2, total_loss = 194.94, pg_loss = 106.93, baseline_loss = 93.323, entropy_loss = -5.3112, learner_queue_size = 32, _tick = 15307, _time = 1.6548e+09, train_seconds = 1.6098e+04)
[2022-06-10 00:36:23,120][root][INFO] - Step 60416000 @ 4091.2 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 60416000, mean_episode_return = None, mean_episode_step = 1161.6, total_loss = 37.87, pg_loss = -11.494, baseline_loss = 54.701, entropy_loss = -5.3366, learner_queue_size = 32, _tick = 15313, _time = 1.6548e+09, train_seconds = 1.6103e+04)
[2022-06-10 00:36:28,122][root][INFO] - Step 60433920 @ 3582.4 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 60433920, mean_episode_return = 55.076, mean_episode_step = 1141.9, total_loss = -57.082, pg_loss = -81.724, baseline_loss = 29.924, entropy_loss = -5.2816, learner_queue_size = 32, _tick = 15320, _time = 1.6548e+09, train_seconds = 1.6108e+04)
[2022-06-10 00:36:33,126][root][INFO] - Step 60451840 @ 3581.2 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 60451840, mean_episode_return = 65.069, mean_episode_step = 1399.6, total_loss = 133.06, pg_loss = 60.379, baseline_loss = 77.92, entropy_loss = -5.2352, learner_queue_size = 32, _tick = 15327, _time = 1.6548e+09, train_seconds = 1.6113e+04)
[2022-06-10 00:36:38,132][root][INFO] - Step 60469760 @ 3579.8 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (step = 60469760, mean_episode_return = 30.821, mean_episode_step = 1098.7, total_loss = -226.98, pg_loss = -239.54, baseline_loss = 17.763, entropy_loss = -5.212, learner_queue_size = 32, _tick = 15333, _time = 1.6548e+09, train_seconds = 1.6118e+04)
[2022-06-10 00:36:43,138][root][INFO] - Step 60490240 @ 4091.0 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 60490240, mean_episode_return = None, mean_episode_step = 988.22, total_loss = 181.5, pg_loss = 124.99, baseline_loss = 61.765, entropy_loss = -5.253, learner_queue_size = 32, _tick = 15337, _time = 1.6548e+09, train_seconds = 1.6123e+04)
[2022-06-10 00:36:48,142][root][INFO] - Step 60508160 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 60508160, mean_episode_return = None, mean_episode_step = 1042.4, total_loss = 169.83, pg_loss = 98.481, baseline_loss = 76.606, entropy_loss = -5.2534, learner_queue_size = 32, _tick = 15341, _time = 1.6548e+09, train_seconds = 1.6128e+04)
[2022-06-10 00:36:53,147][root][INFO] - Step 60528640 @ 4092.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 60528640, mean_episode_return = 133.78, mean_episode_step = 1155.0, total_loss = 62.941, pg_loss = 26.26, baseline_loss = 41.682, entropy_loss = -5.0012, learner_queue_size = 32, _tick = 15348, _time = 1.6548e+09, train_seconds = 1.6133e+04)
[2022-06-10 00:36:58,150][root][INFO] - Step 60546560 @ 3581.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 60546560, mean_episode_return = 132.19, mean_episode_step = 994.83, total_loss = 199.91, pg_loss = 98.164, baseline_loss = 107.02, entropy_loss = -5.2715, learner_queue_size = 32, _tick = 15354, _time = 1.6548e+09, train_seconds = 1.6138e+04)
[2022-06-10 00:37:03,154][root][INFO] - Step 60564480 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 60564480, mean_episode_return = None, mean_episode_step = 1158.1, total_loss = 4.0582, pg_loss = -61.523, baseline_loss = 70.86, entropy_loss = -5.2782, learner_queue_size = 32, _tick = 15360, _time = 1.6548e+09, train_seconds = 1.6143e+04)
[2022-06-10 00:37:08,159][root][INFO] - Step 60584960 @ 4092.4 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 60584960, mean_episode_return = 24.707, mean_episode_step = 874.72, total_loss = 102.65, pg_loss = 9.0989, baseline_loss = 98.778, entropy_loss = -5.2255, learner_queue_size = 32, _tick = 15368, _time = 1.6548e+09, train_seconds = 1.6148e+04)
[2022-06-10 00:37:13,162][root][INFO] - Step 60602880 @ 3581.5 SPS. Inference batcher size: 79. Learner queue size: 32. Other stats: (step = 60602880, mean_episode_return = None, mean_episode_step = 957.38, total_loss = 269.33, pg_loss = 203.5, baseline_loss = 71.17, entropy_loss = -5.3381, learner_queue_size = 32, _tick = 15372, _time = 1.6548e+09, train_seconds = 1.6153e+04)
[2022-06-10 00:37:18,168][root][INFO] - Step 60620800 @ 3579.4 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 60620800, mean_episode_return = 39.628, mean_episode_step = 1251.6, total_loss = 74.873, pg_loss = 33.756, baseline_loss = 46.463, entropy_loss = -5.3464, learner_queue_size = 32, _tick = 15379, _time = 1.6548e+09, train_seconds = 1.6158e+04)
[2022-06-10 00:37:23,174][root][INFO] - Step 60641280 @ 4091.3 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 60641280, mean_episode_return = 77.988, mean_episode_step = 1151.6, total_loss = 67.704, pg_loss = 48.301, baseline_loss = 24.773, entropy_loss = -5.3707, learner_queue_size = 32, _tick = 15386, _time = 1.6548e+09, train_seconds = 1.6163e+04)
[2022-06-10 00:37:28,178][root][INFO] - Step 60659200 @ 3581.3 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 60659200, mean_episode_return = 10.21, mean_episode_step = 1273.7, total_loss = -99.803, pg_loss = -110.11, baseline_loss = 15.778, entropy_loss = -5.4696, learner_queue_size = 32, _tick = 15392, _time = 1.6548e+09, train_seconds = 1.6168e+04)
[2022-06-10 00:37:33,182][root][INFO] - Step 60677120 @ 3581.1 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 60677120, mean_episode_return = 55.526, mean_episode_step = 1209.3, total_loss = -7.9941, pg_loss = -34.141, baseline_loss = 31.577, entropy_loss = -5.4297, learner_queue_size = 32, _tick = 15398, _time = 1.6548e+09, train_seconds = 1.6173e+04)
[2022-06-10 00:37:38,186][root][INFO] - Step 60697600 @ 4092.7 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 60697600, mean_episode_return = 30.345, mean_episode_step = 1029.3, total_loss = -105.76, pg_loss = -142.21, baseline_loss = 41.706, entropy_loss = -5.2548, learner_queue_size = 32, _tick = 15405, _time = 1.6548e+09, train_seconds = 1.6178e+04)
[2022-06-10 00:37:43,190][root][INFO] - Step 60715520 @ 3581.2 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 60715520, mean_episode_return = 4.6093, mean_episode_step = 1175.0, total_loss = 225.22, pg_loss = 161.85, baseline_loss = 68.564, entropy_loss = -5.2006, learner_queue_size = 32, _tick = 15411, _time = 1.6548e+09, train_seconds = 1.6183e+04)
[2022-06-10 00:37:48,194][root][INFO] - Step 60733440 @ 3581.1 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 60733440, mean_episode_return = 168.61, mean_episode_step = 1212.8, total_loss = -79.669, pg_loss = -108.16, baseline_loss = 33.609, entropy_loss = -5.1181, learner_queue_size = 32, _tick = 15416, _time = 1.6548e+09, train_seconds = 1.6188e+04)
[2022-06-10 00:37:53,198][root][INFO] - Step 60753920 @ 4092.8 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 60753920, mean_episode_return = 20.97, mean_episode_step = 1076.1, total_loss = -9.855, pg_loss = -50.251, baseline_loss = 45.477, entropy_loss = -5.0806, learner_queue_size = 32, _tick = 15423, _time = 1.6548e+09, train_seconds = 1.6193e+04)
[2022-06-10 00:37:58,202][root][INFO] - Step 60771840 @ 3581.1 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 60771840, mean_episode_return = 13.78, mean_episode_step = 1018.5, total_loss = 106.45, pg_loss = 48.45, baseline_loss = 63.165, entropy_loss = -5.1671, learner_queue_size = 32, _tick = 15428, _time = 1.6548e+09, train_seconds = 1.6198e+04)
[2022-06-10 00:38:03,206][root][INFO] - Step 60789760 @ 3581.1 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 60789760, mean_episode_return = 14.96, mean_episode_step = 845.22, total_loss = 124.1, pg_loss = 66.122, baseline_loss = 63.202, entropy_loss = -5.2254, learner_queue_size = 32, _tick = 15434, _time = 1.6548e+09, train_seconds = 1.6203e+04)
[2022-06-10 00:38:08,210][root][INFO] - Step 60810240 @ 4092.7 SPS. Inference batcher size: 87. Learner queue size: 32. Other stats: (step = 60810240, mean_episode_return = 45.533, mean_episode_step = 1030.9, total_loss = 47.899, pg_loss = -34.357, baseline_loss = 87.242, entropy_loss = -4.9847, learner_queue_size = 32, _tick = 15442, _time = 1.6548e+09, train_seconds = 1.6208e+04)
[2022-06-10 00:38:13,214][root][INFO] - Step 60828160 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 60828160, mean_episode_return = None, mean_episode_step = 1044.7, total_loss = 370.29, pg_loss = 254.01, baseline_loss = 121.35, entropy_loss = -5.072, learner_queue_size = 32, _tick = 15447, _time = 1.6548e+09, train_seconds = 1.6213e+04)
[2022-06-10 00:38:18,218][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 00:38:18,420][root][INFO] - Step 60846080 @ 3581.1 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 60848640, mean_episode_return = 93.208, mean_episode_step = 939.47, total_loss = -9.1326, pg_loss = -48.827, baseline_loss = 44.778, entropy_loss = -5.0834, learner_queue_size = 32, _tick = 15454, _time = 1.6548e+09, train_seconds = 1.6218e+04)
[2022-06-10 00:38:23,422][root][INFO] - Step 60866560 @ 3935.3 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 60866560, mean_episode_return = 11.23, mean_episode_step = 937.99, total_loss = -54.396, pg_loss = -68.926, baseline_loss = 19.748, entropy_loss = -5.2179, learner_queue_size = 32, _tick = 15459, _time = 1.6548e+09, train_seconds = 1.6223e+04)
[2022-06-10 00:38:28,426][root][INFO] - Step 60884480 @ 3581.3 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 60884480, mean_episode_return = 83.044, mean_episode_step = 947.56, total_loss = 36.929, pg_loss = -0.42102, baseline_loss = 42.413, entropy_loss = -5.0629, learner_queue_size = 32, _tick = 15466, _time = 1.6548e+09, train_seconds = 1.6228e+04)
[2022-06-10 00:38:33,430][root][INFO] - Step 60902400 @ 3581.2 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 60902400, mean_episode_return = 62.9, mean_episode_step = 1085.7, total_loss = -29.532, pg_loss = -51.8, baseline_loss = 27.326, entropy_loss = -5.0578, learner_queue_size = 32, _tick = 15473, _time = 1.6548e+09, train_seconds = 1.6233e+04)
[2022-06-10 00:38:38,434][root][INFO] - Step 60922880 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 60922880, mean_episode_return = 8.6148, mean_episode_step = 953.56, total_loss = 83.182, pg_loss = 46.153, baseline_loss = 42.283, entropy_loss = -5.2542, learner_queue_size = 32, _tick = 15479, _time = 1.6548e+09, train_seconds = 1.6238e+04)
[2022-06-10 00:38:43,438][root][INFO] - Step 60940800 @ 3581.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 60940800, mean_episode_return = 88.821, mean_episode_step = 1032.4, total_loss = 118.51, pg_loss = 66.243, baseline_loss = 57.491, entropy_loss = -5.2225, learner_queue_size = 32, _tick = 15485, _time = 1.6548e+09, train_seconds = 1.6243e+04)
[2022-06-10 00:38:48,442][root][INFO] - Step 60958720 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 60958720, mean_episode_return = 73.759, mean_episode_step = 1295.4, total_loss = -93.772, pg_loss = -155.12, baseline_loss = 66.452, entropy_loss = -5.1015, learner_queue_size = 32, _tick = 15490, _time = 1.6548e+09, train_seconds = 1.6248e+04)
[2022-06-10 00:38:53,447][root][INFO] - Step 60979200 @ 4092.7 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 60979200, mean_episode_return = 144.23, mean_episode_step = 1100.2, total_loss = -12.305, pg_loss = -60.295, baseline_loss = 53.297, entropy_loss = -5.3062, learner_queue_size = 32, _tick = 15498, _time = 1.6548e+09, train_seconds = 1.6253e+04)
[2022-06-10 00:38:58,450][root][INFO] - Step 60997120 @ 3581.2 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 60997120, mean_episode_return = 56.567, mean_episode_step = 1245.4, total_loss = -118.28, pg_loss = -141.91, baseline_loss = 28.867, entropy_loss = -5.2353, learner_queue_size = 32, _tick = 15503, _time = 1.6548e+09, train_seconds = 1.6258e+04)
[2022-06-10 00:39:03,454][root][INFO] - Step 61017600 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 61017600, mean_episode_return = -3.0001, mean_episode_step = 869.43, total_loss = 149.55, pg_loss = 113.97, baseline_loss = 40.962, entropy_loss = -5.3845, learner_queue_size = 32, _tick = 15510, _time = 1.6548e+09, train_seconds = 1.6263e+04)
[2022-06-10 00:39:08,458][root][INFO] - Step 61035520 @ 3581.2 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 61035520, mean_episode_return = 46.283, mean_episode_step = 1084.9, total_loss = -21.538, pg_loss = -50.272, baseline_loss = 33.998, entropy_loss = -5.2639, learner_queue_size = 32, _tick = 15515, _time = 1.6548e+09, train_seconds = 1.6268e+04)
[2022-06-10 00:39:13,463][root][INFO] - Step 61053440 @ 3580.8 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 61053440, mean_episode_return = -16.13, mean_episode_step = 995.7, total_loss = 204.2, pg_loss = 130.77, baseline_loss = 78.709, entropy_loss = -5.2824, learner_queue_size = 32, _tick = 15520, _time = 1.6548e+09, train_seconds = 1.6273e+04)
[2022-06-10 00:39:18,466][root][INFO] - Step 61071360 @ 3581.5 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 61071360, mean_episode_return = 49.55, mean_episode_step = 1229.5, total_loss = 21.63, pg_loss = -30.425, baseline_loss = 57.125, entropy_loss = -5.0699, learner_queue_size = 32, _tick = 15526, _time = 1.6548e+09, train_seconds = 1.6278e+04)
[2022-06-10 00:39:23,470][root][INFO] - Step 61089280 @ 3581.2 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (step = 61089280, mean_episode_return = 40.7, mean_episode_step = 1397.4, total_loss = 12.039, pg_loss = -32.224, baseline_loss = 49.59, entropy_loss = -5.3265, learner_queue_size = 32, _tick = 15533, _time = 1.6548e+09, train_seconds = 1.6283e+04)
[2022-06-10 00:39:28,474][root][INFO] - Step 61109760 @ 4092.6 SPS. Inference batcher size: 83. Learner queue size: 32. Other stats: (step = 61109760, mean_episode_return = 44.066, mean_episode_step = 1323.6, total_loss = 127.5, pg_loss = 74.465, baseline_loss = 58.307, entropy_loss = -5.2676, learner_queue_size = 32, _tick = 15540, _time = 1.6548e+09, train_seconds = 1.6288e+04)
[2022-06-10 00:39:33,478][root][INFO] - Step 61127680 @ 3581.2 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 61127680, mean_episode_return = None, mean_episode_step = 1118.6, total_loss = 348.28, pg_loss = 253.22, baseline_loss = 100.27, entropy_loss = -5.2039, learner_queue_size = 32, _tick = 15544, _time = 1.6548e+09, train_seconds = 1.6293e+04)
[2022-06-10 00:39:38,482][root][INFO] - Step 61145600 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 61145600, mean_episode_return = 42.071, mean_episode_step = 961.33, total_loss = 421.62, pg_loss = 283.25, baseline_loss = 143.56, entropy_loss = -5.194, learner_queue_size = 32, _tick = 15549, _time = 1.6548e+09, train_seconds = 1.6298e+04)
[2022-06-10 00:39:43,486][root][INFO] - Step 61166080 @ 4092.8 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 61166080, mean_episode_return = 20.05, mean_episode_step = 1257.3, total_loss = -13.02, pg_loss = -54.514, baseline_loss = 46.627, entropy_loss = -5.1331, learner_queue_size = 32, _tick = 15556, _time = 1.6548e+09, train_seconds = 1.6303e+04)
[2022-06-10 00:39:48,490][root][INFO] - Step 61184000 @ 3581.2 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 61184000, mean_episode_return = 98.236, mean_episode_step = 1090.1, total_loss = 274.14, pg_loss = 169.96, baseline_loss = 109.14, entropy_loss = -4.9605, learner_queue_size = 32, _tick = 15562, _time = 1.6548e+09, train_seconds = 1.6308e+04)
[2022-06-10 00:39:53,494][root][INFO] - Step 61204480 @ 4092.8 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 61204480, mean_episode_return = 139.64, mean_episode_step = 1045.2, total_loss = -46.865, pg_loss = -82.279, baseline_loss = 40.568, entropy_loss = -5.1544, learner_queue_size = 32, _tick = 15568, _time = 1.6548e+09, train_seconds = 1.6313e+04)
[2022-06-10 00:39:58,498][root][INFO] - Step 61222400 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 61222400, mean_episode_return = 18.42, mean_episode_step = 1145.3, total_loss = 168.55, pg_loss = 86.171, baseline_loss = 87.554, entropy_loss = -5.1752, learner_queue_size = 32, _tick = 15573, _time = 1.6548e+09, train_seconds = 1.6318e+04)
[2022-06-10 00:40:03,502][root][INFO] - Step 61240320 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 61240320, mean_episode_return = 124.04, mean_episode_step = 919.9, total_loss = 221.99, pg_loss = 143.91, baseline_loss = 83.299, entropy_loss = -5.2246, learner_queue_size = 32, _tick = 15579, _time = 1.6548e+09, train_seconds = 1.6323e+04)
[2022-06-10 00:40:08,506][root][INFO] - Step 61260800 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 61260800, mean_episode_return = 62.865, mean_episode_step = 1305.4, total_loss = -95.617, pg_loss = -144.51, baseline_loss = 54.164, entropy_loss = -5.2674, learner_queue_size = 32, _tick = 15584, _time = 1.6548e+09, train_seconds = 1.6328e+04)
[2022-06-10 00:40:13,510][root][INFO] - Step 61278720 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 61278720, mean_episode_return = None, mean_episode_step = 1100.4, total_loss = 57.242, pg_loss = 32.36, baseline_loss = 30.108, entropy_loss = -5.2261, learner_queue_size = 32, _tick = 15588, _time = 1.6548e+09, train_seconds = 1.6333e+04)
[2022-06-10 00:40:18,514][root][INFO] - Step 61299200 @ 4092.7 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 61299200, mean_episode_return = 121.15, mean_episode_step = 733.64, total_loss = -103.04, pg_loss = -145.16, baseline_loss = 47.2, entropy_loss = -5.0788, learner_queue_size = 32, _tick = 15596, _time = 1.6548e+09, train_seconds = 1.6338e+04)
[2022-06-10 00:40:23,519][root][INFO] - Step 61317120 @ 3580.3 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 61317120, mean_episode_return = 62.44, mean_episode_step = 1114.9, total_loss = -43.929, pg_loss = -116.67, baseline_loss = 77.771, entropy_loss = -5.0254, learner_queue_size = 32, _tick = 15601, _time = 1.6548e+09, train_seconds = 1.6343e+04)
[2022-06-10 00:40:28,522][root][INFO] - Step 61335040 @ 3581.9 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 61335040, mean_episode_return = 62.484, mean_episode_step = 1195.2, total_loss = 353.17, pg_loss = 243.46, baseline_loss = 114.85, entropy_loss = -5.1458, learner_queue_size = 32, _tick = 15607, _time = 1.6548e+09, train_seconds = 1.6348e+04)
[2022-06-10 00:40:33,526][root][INFO] - Step 61355520 @ 4092.7 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 61355520, mean_episode_return = 43.93, mean_episode_step = 1222.3, total_loss = 166.51, pg_loss = 128.32, baseline_loss = 43.579, entropy_loss = -5.3812, learner_queue_size = 32, _tick = 15611, _time = 1.6548e+09, train_seconds = 1.6353e+04)
[2022-06-10 00:40:38,530][root][INFO] - Step 61373440 @ 3581.0 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 61373440, mean_episode_return = 37.487, mean_episode_step = 1546.1, total_loss = -31.579, pg_loss = -79.597, baseline_loss = 53.385, entropy_loss = -5.3672, learner_queue_size = 32, _tick = 15615, _time = 1.6548e+09, train_seconds = 1.6358e+04)
[2022-06-10 00:40:43,534][root][INFO] - Step 61393920 @ 4092.8 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 61393920, mean_episode_return = 42.906, mean_episode_step = 1067.1, total_loss = 446.74, pg_loss = 346.21, baseline_loss = 105.85, entropy_loss = -5.3192, learner_queue_size = 32, _tick = 15622, _time = 1.6548e+09, train_seconds = 1.6363e+04)
[2022-06-10 00:40:48,538][root][INFO] - Step 61411840 @ 3581.1 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (step = 61411840, mean_episode_return = 67.614, mean_episode_step = 1549.0, total_loss = 296.37, pg_loss = 247.46, baseline_loss = 54.324, entropy_loss = -5.4071, learner_queue_size = 32, _tick = 15629, _time = 1.6548e+09, train_seconds = 1.6368e+04)
[2022-06-10 00:40:53,542][root][INFO] - Step 61429760 @ 3580.8 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 61429760, mean_episode_return = None, mean_episode_step = 1290.9, total_loss = -100.82, pg_loss = -121.49, baseline_loss = 26.026, entropy_loss = -5.3625, learner_queue_size = 32, _tick = 15635, _time = 1.6548e+09, train_seconds = 1.6373e+04)
[2022-06-10 00:40:58,546][root][INFO] - Step 61450240 @ 4093.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 61450240, mean_episode_return = -1.3502, mean_episode_step = 1180.5, total_loss = -176.02, pg_loss = -179.84, baseline_loss = 9.0417, entropy_loss = -5.2246, learner_queue_size = 32, _tick = 15643, _time = 1.6548e+09, train_seconds = 1.6378e+04)
[2022-06-10 00:41:03,550][root][INFO] - Step 61468160 @ 3581.1 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 61468160, mean_episode_return = 49.242, mean_episode_step = 822.38, total_loss = 260.68, pg_loss = 174.37, baseline_loss = 91.541, entropy_loss = -5.2364, learner_queue_size = 32, _tick = 15649, _time = 1.6548e+09, train_seconds = 1.6383e+04)
[2022-06-10 00:41:08,554][root][INFO] - Step 61488640 @ 4092.7 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 61488640, mean_episode_return = 89.744, mean_episode_step = 1146.3, total_loss = -7.8764, pg_loss = -35.613, baseline_loss = 33.079, entropy_loss = -5.3423, learner_queue_size = 32, _tick = 15656, _time = 1.6548e+09, train_seconds = 1.6388e+04)
[2022-06-10 00:41:13,558][root][INFO] - Step 61506560 @ 3581.1 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 61506560, mean_episode_return = None, mean_episode_step = 957.31, total_loss = -20.401, pg_loss = -38.732, baseline_loss = 23.48, entropy_loss = -5.1496, learner_queue_size = 32, _tick = 15662, _time = 1.6548e+09, train_seconds = 1.6393e+04)
[2022-06-10 00:41:18,562][root][INFO] - Step 61524480 @ 3581.1 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 61524480, mean_episode_return = None, mean_episode_step = 1075.7, total_loss = -29.355, pg_loss = -49.628, baseline_loss = 25.451, entropy_loss = -5.1774, learner_queue_size = 32, _tick = 15667, _time = 1.6548e+09, train_seconds = 1.6398e+04)
[2022-06-10 00:41:23,566][root][INFO] - Step 61544960 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 61544960, mean_episode_return = 13.93, mean_episode_step = 1015.0, total_loss = -118.72, pg_loss = -134.94, baseline_loss = 21.441, entropy_loss = -5.221, learner_queue_size = 32, _tick = 15672, _time = 1.6548e+09, train_seconds = 1.6403e+04)
[2022-06-10 00:41:28,570][root][INFO] - Step 61562880 @ 3580.9 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 61562880, mean_episode_return = None, mean_episode_step = 1521.8, total_loss = 134.38, pg_loss = 78.631, baseline_loss = 61.131, entropy_loss = -5.3791, learner_queue_size = 32, _tick = 15677, _time = 1.6548e+09, train_seconds = 1.6408e+04)
[2022-06-10 00:41:33,574][root][INFO] - Step 61580800 @ 3581.3 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (step = 61580800, mean_episode_return = 59.437, mean_episode_step = 1184.4, total_loss = -248.19, pg_loss = -284.15, baseline_loss = 41.099, entropy_loss = -5.1349, learner_queue_size = 32, _tick = 15682, _time = 1.6548e+09, train_seconds = 1.6413e+04)
[2022-06-10 00:41:38,578][root][INFO] - Step 61601280 @ 4092.9 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 61601280, mean_episode_return = 12.53, mean_episode_step = 1163.7, total_loss = -92.122, pg_loss = -134.05, baseline_loss = 47.283, entropy_loss = -5.3578, learner_queue_size = 32, _tick = 15687, _time = 1.6548e+09, train_seconds = 1.6418e+04)
[2022-06-10 00:41:43,582][root][INFO] - Step 61619200 @ 3581.0 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 61619200, mean_episode_return = 144.47, mean_episode_step = 690.46, total_loss = 215.67, pg_loss = 159.63, baseline_loss = 61.377, entropy_loss = -5.3346, learner_queue_size = 32, _tick = 15692, _time = 1.6548e+09, train_seconds = 1.6423e+04)
[2022-06-10 00:41:48,586][root][INFO] - Step 61637120 @ 3581.2 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 61637120, mean_episode_return = 48.09, mean_episode_step = 986.8, total_loss = 288.52, pg_loss = 207.88, baseline_loss = 85.927, entropy_loss = -5.2884, learner_queue_size = 32, _tick = 15697, _time = 1.6548e+09, train_seconds = 1.6428e+04)
[2022-06-10 00:41:53,590][root][INFO] - Step 61657600 @ 4092.8 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 61657600, mean_episode_return = 98.129, mean_episode_step = 1273.6, total_loss = 246.44, pg_loss = 189.63, baseline_loss = 62.192, entropy_loss = -5.3868, learner_queue_size = 32, _tick = 15705, _time = 1.6548e+09, train_seconds = 1.6433e+04)
[2022-06-10 00:41:58,594][root][INFO] - Step 61675520 @ 3581.2 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 61675520, mean_episode_return = 89.735, mean_episode_step = 912.83, total_loss = -218.08, pg_loss = -247.18, baseline_loss = 34.201, entropy_loss = -5.1022, learner_queue_size = 32, _tick = 15710, _time = 1.6548e+09, train_seconds = 1.6438e+04)
[2022-06-10 00:42:03,598][root][INFO] - Step 61696000 @ 4092.7 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 61696000, mean_episode_return = 8.6498, mean_episode_step = 1064.7, total_loss = -137.01, pg_loss = -165.19, baseline_loss = 33.51, entropy_loss = -5.3276, learner_queue_size = 32, _tick = 15718, _time = 1.6548e+09, train_seconds = 1.6443e+04)
[2022-06-10 00:42:08,602][root][INFO] - Step 61713920 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 61713920, mean_episode_return = 11.71, mean_episode_step = 1056.3, total_loss = 146.46, pg_loss = 96.312, baseline_loss = 55.578, entropy_loss = -5.4324, learner_queue_size = 32, _tick = 15723, _time = 1.6548e+09, train_seconds = 1.6448e+04)
[2022-06-10 00:42:13,606][root][INFO] - Step 61731840 @ 3581.2 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 61731840, mean_episode_return = 57.621, mean_episode_step = 1313.4, total_loss = 2.9262, pg_loss = -52.746, baseline_loss = 61.034, entropy_loss = -5.3613, learner_queue_size = 32, _tick = 15729, _time = 1.6548e+09, train_seconds = 1.6453e+04)
[2022-06-10 00:42:18,610][root][INFO] - Step 61752320 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 61752320, mean_episode_return = 99.505, mean_episode_step = 919.66, total_loss = 27.626, pg_loss = -4.37, baseline_loss = 37.116, entropy_loss = -5.1203, learner_queue_size = 32, _tick = 15735, _time = 1.6548e+09, train_seconds = 1.6458e+04)
[2022-06-10 00:42:23,614][root][INFO] - Step 61770240 @ 3581.1 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 61770240, mean_episode_return = 46.025, mean_episode_step = 853.71, total_loss = 325.52, pg_loss = 105.35, baseline_loss = 225.36, entropy_loss = -5.1828, learner_queue_size = 32, _tick = 15741, _time = 1.6548e+09, train_seconds = 1.6463e+04)
[2022-06-10 00:42:28,618][root][INFO] - Step 61788160 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 61788160, mean_episode_return = 70.883, mean_episode_step = 1350.0, total_loss = 213.92, pg_loss = 108.2, baseline_loss = 110.93, entropy_loss = -5.2133, learner_queue_size = 32, _tick = 15746, _time = 1.6548e+09, train_seconds = 1.6468e+04)
[2022-06-10 00:42:33,623][root][INFO] - Step 61806080 @ 3580.2 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 61806080, mean_episode_return = 97.747, mean_episode_step = 1027.2, total_loss = -255.75, pg_loss = -281.04, baseline_loss = 30.527, entropy_loss = -5.2363, learner_queue_size = 32, _tick = 15753, _time = 1.6548e+09, train_seconds = 1.6473e+04)
[2022-06-10 00:42:38,626][root][INFO] - Step 61826560 @ 4093.8 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 61826560, mean_episode_return = None, mean_episode_step = 1124.0, total_loss = 66.056, pg_loss = 5.4699, baseline_loss = 65.809, entropy_loss = -5.2225, learner_queue_size = 32, _tick = 15759, _time = 1.6548e+09, train_seconds = 1.6478e+04)
[2022-06-10 00:42:43,630][root][INFO] - Step 61844480 @ 3581.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 61844480, mean_episode_return = 53.34, mean_episode_step = 841.04, total_loss = 309.93, pg_loss = 192.48, baseline_loss = 122.76, entropy_loss = -5.3142, learner_queue_size = 32, _tick = 15765, _time = 1.6548e+09, train_seconds = 1.6483e+04)
[2022-06-10 00:42:48,634][root][INFO] - Step 61862400 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 61862400, mean_episode_return = 77.52, mean_episode_step = 935.74, total_loss = 19.712, pg_loss = -26.741, baseline_loss = 51.598, entropy_loss = -5.1452, learner_queue_size = 32, _tick = 15771, _time = 1.6548e+09, train_seconds = 1.6488e+04)
[2022-06-10 00:42:53,638][root][INFO] - Step 61882880 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 61882880, mean_episode_return = 149.68, mean_episode_step = 827.52, total_loss = 117.14, pg_loss = 40.031, baseline_loss = 82.424, entropy_loss = -5.3124, learner_queue_size = 32, _tick = 15778, _time = 1.6548e+09, train_seconds = 1.6493e+04)
[2022-06-10 00:42:58,642][root][INFO] - Step 61900800 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 61900800, mean_episode_return = -1.03, mean_episode_step = 1034.2, total_loss = 244.94, pg_loss = 150.67, baseline_loss = 99.617, entropy_loss = -5.3508, learner_queue_size = 32, _tick = 15784, _time = 1.6548e+09, train_seconds = 1.6498e+04)
[2022-06-10 00:43:03,646][root][INFO] - Step 61918720 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 61918720, mean_episode_return = 112.23, mean_episode_step = 851.11, total_loss = 30.099, pg_loss = -1.1323, baseline_loss = 36.412, entropy_loss = -5.1805, learner_queue_size = 32, _tick = 15789, _time = 1.6548e+09, train_seconds = 1.6504e+04)
[2022-06-10 00:43:08,650][root][INFO] - Step 61939200 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 61939200, mean_episode_return = 64.68, mean_episode_step = 842.05, total_loss = 26.046, pg_loss = -65.056, baseline_loss = 96.193, entropy_loss = -5.0905, learner_queue_size = 32, _tick = 15793, _time = 1.6548e+09, train_seconds = 1.6508e+04)
[2022-06-10 00:43:13,654][root][INFO] - Step 61957120 @ 3581.2 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 61957120, mean_episode_return = 18.85, mean_episode_step = 900.37, total_loss = 91.68, pg_loss = 54.341, baseline_loss = 42.568, entropy_loss = -5.2292, learner_queue_size = 32, _tick = 15799, _time = 1.6548e+09, train_seconds = 1.6514e+04)
[2022-06-10 00:43:18,658][root][INFO] - Step 61975040 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 61975040, mean_episode_return = 71.944, mean_episode_step = 1013.1, total_loss = -219.24, pg_loss = -249.2, baseline_loss = 35.324, entropy_loss = -5.3666, learner_queue_size = 32, _tick = 15806, _time = 1.6548e+09, train_seconds = 1.6518e+04)
[2022-06-10 00:43:23,662][root][INFO] - Step 61995520 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 61995520, mean_episode_return = 116.96, mean_episode_step = 1000.1, total_loss = 35.558, pg_loss = 2.1549, baseline_loss = 38.65, entropy_loss = -5.2469, learner_queue_size = 32, _tick = 15814, _time = 1.6548e+09, train_seconds = 1.6524e+04)
[2022-06-10 00:43:28,666][root][INFO] - Step 62013440 @ 3581.1 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 62013440, mean_episode_return = 58.23, mean_episode_step = 972.74, total_loss = 220.14, pg_loss = 137.18, baseline_loss = 88.171, entropy_loss = -5.2158, learner_queue_size = 32, _tick = 15818, _time = 1.6548e+09, train_seconds = 1.6528e+04)
[2022-06-10 00:43:33,670][root][INFO] - Step 62031360 @ 3580.9 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 62031360, mean_episode_return = 54.154, mean_episode_step = 1020.5, total_loss = -78.314, pg_loss = -105.53, baseline_loss = 32.359, entropy_loss = -5.1393, learner_queue_size = 32, _tick = 15823, _time = 1.6548e+09, train_seconds = 1.6534e+04)
[2022-06-10 00:43:38,674][root][INFO] - Step 62051840 @ 4093.0 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 62051840, mean_episode_return = 26.56, mean_episode_step = 714.46, total_loss = 42.807, pg_loss = -12.773, baseline_loss = 60.462, entropy_loss = -4.8813, learner_queue_size = 32, _tick = 15831, _time = 1.6548e+09, train_seconds = 1.6538e+04)
[2022-06-10 00:43:43,680][root][INFO] - Step 62069760 @ 3580.0 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 62069760, mean_episode_return = None, mean_episode_step = 898.44, total_loss = -192.44, pg_loss = -198.49, baseline_loss = 11.44, entropy_loss = -5.3953, learner_queue_size = 32, _tick = 15835, _time = 1.6548e+09, train_seconds = 1.6544e+04)
[2022-06-10 00:43:48,683][root][INFO] - Step 62087680 @ 3582.3 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 62087680, mean_episode_return = 63.58, mean_episode_step = 1253.9, total_loss = 363.17, pg_loss = 260.9, baseline_loss = 107.68, entropy_loss = -5.4043, learner_queue_size = 32, _tick = 15840, _time = 1.6548e+09, train_seconds = 1.6548e+04)
[2022-06-10 00:43:53,687][root][INFO] - Step 62108160 @ 4091.8 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 62108160, mean_episode_return = 74.785, mean_episode_step = 886.92, total_loss = -54.657, pg_loss = -65.65, baseline_loss = 16.299, entropy_loss = -5.3063, learner_queue_size = 32, _tick = 15847, _time = 1.6548e+09, train_seconds = 1.6554e+04)
[2022-06-10 00:43:58,690][root][INFO] - Step 62126080 @ 3582.0 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (step = 62126080, mean_episode_return = None, mean_episode_step = 1484.3, total_loss = 84.316, pg_loss = 58.067, baseline_loss = 31.435, entropy_loss = -5.186, learner_queue_size = 32, _tick = 15851, _time = 1.6548e+09, train_seconds = 1.6558e+04)
[2022-06-10 00:44:03,694][root][INFO] - Step 62144000 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 62144000, mean_episode_return = None, mean_episode_step = 1181.8, total_loss = -142.43, pg_loss = -154.89, baseline_loss = 17.647, entropy_loss = -5.187, learner_queue_size = 32, _tick = 15856, _time = 1.6548e+09, train_seconds = 1.6564e+04)
[2022-06-10 00:44:08,698][root][INFO] - Step 62164480 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 62164480, mean_episode_return = None, mean_episode_step = 1114.3, total_loss = 31.609, pg_loss = -24.946, baseline_loss = 61.784, entropy_loss = -5.2297, learner_queue_size = 32, _tick = 15860, _time = 1.6548e+09, train_seconds = 1.6568e+04)
[2022-06-10 00:44:13,702][root][INFO] - Step 62182400 @ 3581.1 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 62182400, mean_episode_return = 27.87, mean_episode_step = 953.75, total_loss = 806.57, pg_loss = 555.83, baseline_loss = 255.97, entropy_loss = -5.2226, learner_queue_size = 32, _tick = 15867, _time = 1.6548e+09, train_seconds = 1.6574e+04)
[2022-06-10 00:44:18,706][root][INFO] - Step 62200320 @ 3581.1 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 62200320, mean_episode_return = None, mean_episode_step = 853.75, total_loss = -129.92, pg_loss = -169.26, baseline_loss = 44.507, entropy_loss = -5.1751, learner_queue_size = 32, _tick = 15872, _time = 1.6548e+09, train_seconds = 1.6578e+04)
[2022-06-10 00:44:23,710][root][INFO] - Step 62218240 @ 3581.1 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 62218240, mean_episode_return = None, mean_episode_step = 926.62, total_loss = 235.09, pg_loss = 184.66, baseline_loss = 55.548, entropy_loss = -5.1128, learner_queue_size = 32, _tick = 15878, _time = 1.6548e+09, train_seconds = 1.6584e+04)
[2022-06-10 00:44:28,714][root][INFO] - Step 62238720 @ 4092.7 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 62238720, mean_episode_return = 49.97, mean_episode_step = 1022.6, total_loss = -13.949, pg_loss = -61.626, baseline_loss = 52.862, entropy_loss = -5.1844, learner_queue_size = 32, _tick = 15885, _time = 1.6548e+09, train_seconds = 1.6588e+04)
[2022-06-10 00:44:33,718][root][INFO] - Step 62256640 @ 3581.0 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 62256640, mean_episode_return = None, mean_episode_step = 1442.2, total_loss = 211.83, pg_loss = 163.93, baseline_loss = 53.217, entropy_loss = -5.3223, learner_queue_size = 32, _tick = 15890, _time = 1.6548e+09, train_seconds = 1.6594e+04)
[2022-06-10 00:44:38,722][root][INFO] - Step 62277120 @ 4092.8 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 62277120, mean_episode_return = None, mean_episode_step = 1022.8, total_loss = 147.19, pg_loss = 97.87, baseline_loss = 54.567, entropy_loss = -5.2464, learner_queue_size = 32, _tick = 15897, _time = 1.6548e+09, train_seconds = 1.6598e+04)
[2022-06-10 00:44:43,726][root][INFO] - Step 62295040 @ 3581.2 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 62295040, mean_episode_return = 25.23, mean_episode_step = 1070.6, total_loss = -178.3, pg_loss = -189.68, baseline_loss = 16.565, entropy_loss = -5.1878, learner_queue_size = 32, _tick = 15903, _time = 1.6548e+09, train_seconds = 1.6604e+04)
[2022-06-10 00:44:48,731][root][INFO] - Step 62312960 @ 3581.2 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 62312960, mean_episode_return = 21.073, mean_episode_step = 1200.9, total_loss = -45.158, pg_loss = -135.08, baseline_loss = 95.055, entropy_loss = -5.1325, learner_queue_size = 32, _tick = 15909, _time = 1.6548e+09, train_seconds = 1.6608e+04)
[2022-06-10 00:44:53,734][root][INFO] - Step 62330880 @ 3581.1 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 62330880, mean_episode_return = 107.94, mean_episode_step = 1294.8, total_loss = 246.54, pg_loss = 179.57, baseline_loss = 72.043, entropy_loss = -5.0664, learner_queue_size = 32, _tick = 15914, _time = 1.6548e+09, train_seconds = 1.6614e+04)
[2022-06-10 00:44:58,738][root][INFO] - Step 62351360 @ 4092.7 SPS. Inference batcher size: 86. Learner queue size: 32. Other stats: (step = 62351360, mean_episode_return = 12.03, mean_episode_step = 1015.5, total_loss = 39.014, pg_loss = 6.1111, baseline_loss = 37.951, entropy_loss = -5.0485, learner_queue_size = 32, _tick = 15922, _time = 1.6548e+09, train_seconds = 1.6618e+04)
[2022-06-10 00:45:03,742][root][INFO] - Step 62369280 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 62369280, mean_episode_return = 76.589, mean_episode_step = 1052.5, total_loss = 36.917, pg_loss = 0.54906, baseline_loss = 41.392, entropy_loss = -5.0243, learner_queue_size = 32, _tick = 15928, _time = 1.6548e+09, train_seconds = 1.6624e+04)
[2022-06-10 00:45:08,746][root][INFO] - Step 62387200 @ 3581.1 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 62387200, mean_episode_return = None, mean_episode_step = 904.56, total_loss = 142.68, pg_loss = 47.405, baseline_loss = 100.31, entropy_loss = -5.0347, learner_queue_size = 32, _tick = 15932, _time = 1.6548e+09, train_seconds = 1.6629e+04)
[2022-06-10 00:45:13,750][root][INFO] - Step 62405120 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 62405120, mean_episode_return = None, mean_episode_step = 1222.5, total_loss = 383.07, pg_loss = 317.82, baseline_loss = 70.349, entropy_loss = -5.1059, learner_queue_size = 32, _tick = 15936, _time = 1.6548e+09, train_seconds = 1.6634e+04)
[2022-06-10 00:45:18,754][root][INFO] - Step 62425600 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 62425600, mean_episode_return = 42.683, mean_episode_step = 1203.6, total_loss = -90.123, pg_loss = -159.15, baseline_loss = 73.993, entropy_loss = -4.9647, learner_queue_size = 32, _tick = 15942, _time = 1.6548e+09, train_seconds = 1.6639e+04)
[2022-06-10 00:45:23,759][root][INFO] - Step 62443520 @ 3580.3 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 62443520, mean_episode_return = 62.889, mean_episode_step = 1000.2, total_loss = 169.86, pg_loss = 132.14, baseline_loss = 42.916, entropy_loss = -5.1909, learner_queue_size = 32, _tick = 15949, _time = 1.6548e+09, train_seconds = 1.6644e+04)
[2022-06-10 00:45:28,762][root][INFO] - Step 62461440 @ 3582.0 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 62461440, mean_episode_return = None, mean_episode_step = 1013.5, total_loss = 141.56, pg_loss = 78.891, baseline_loss = 67.752, entropy_loss = -5.0816, learner_queue_size = 32, _tick = 15954, _time = 1.6548e+09, train_seconds = 1.6649e+04)
[2022-06-10 00:45:33,767][root][INFO] - Step 62481920 @ 4091.8 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 62481920, mean_episode_return = -8.5704, mean_episode_step = 1316.6, total_loss = 117.7, pg_loss = 48.604, baseline_loss = 74.352, entropy_loss = -5.2577, learner_queue_size = 32, _tick = 15961, _time = 1.6548e+09, train_seconds = 1.6654e+04)
[2022-06-10 00:45:38,770][root][INFO] - Step 62499840 @ 3582.0 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 62499840, mean_episode_return = 143.31, mean_episode_step = 1209.0, total_loss = -17.403, pg_loss = -52.593, baseline_loss = 40.396, entropy_loss = -5.2062, learner_queue_size = 32, _tick = 15966, _time = 1.6548e+09, train_seconds = 1.6659e+04)
[2022-06-10 00:45:43,774][root][INFO] - Step 62517760 @ 3581.2 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 62517760, mean_episode_return = 69.041, mean_episode_step = 1255.2, total_loss = -72.728, pg_loss = -131.39, baseline_loss = 63.958, entropy_loss = -5.3007, learner_queue_size = 32, _tick = 15972, _time = 1.6548e+09, train_seconds = 1.6664e+04)
[2022-06-10 00:45:48,781][root][INFO] - Step 62538240 @ 4090.3 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 62538240, mean_episode_return = 81.755, mean_episode_step = 924.21, total_loss = 159.61, pg_loss = 77.789, baseline_loss = 86.87, entropy_loss = -5.0521, learner_queue_size = 32, _tick = 15978, _time = 1.6548e+09, train_seconds = 1.6669e+04)
[2022-06-10 00:45:53,786][root][INFO] - Step 62556160 @ 3580.4 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 62556160, mean_episode_return = 39.79, mean_episode_step = 1096.8, total_loss = 81.611, pg_loss = -99.043, baseline_loss = 185.97, entropy_loss = -5.3117, learner_queue_size = 32, _tick = 15986, _time = 1.6548e+09, train_seconds = 1.6674e+04)
[2022-06-10 00:45:58,790][root][INFO] - Step 62574080 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 62574080, mean_episode_return = None, mean_episode_step = 1451.7, total_loss = -49.78, pg_loss = -75.396, baseline_loss = 30.883, entropy_loss = -5.2675, learner_queue_size = 32, _tick = 15990, _time = 1.6548e+09, train_seconds = 1.6679e+04)
[2022-06-10 00:46:03,794][root][INFO] - Step 62592000 @ 3581.2 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 62592000, mean_episode_return = -0.1004, mean_episode_step = 948.97, total_loss = -62.778, pg_loss = -88.566, baseline_loss = 30.863, entropy_loss = -5.0757, learner_queue_size = 32, _tick = 15995, _time = 1.6548e+09, train_seconds = 1.6684e+04)
[2022-06-10 00:46:08,798][root][INFO] - Step 62612480 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 62612480, mean_episode_return = 33.375, mean_episode_step = 811.51, total_loss = 42.796, pg_loss = -27.335, baseline_loss = 75.324, entropy_loss = -5.1926, learner_queue_size = 32, _tick = 16003, _time = 1.6548e+09, train_seconds = 1.6689e+04)
[2022-06-10 00:46:13,802][root][INFO] - Step 62630400 @ 3581.1 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 62630400, mean_episode_return = 155.26, mean_episode_step = 1002.7, total_loss = -3.8454, pg_loss = -33.634, baseline_loss = 35.039, entropy_loss = -5.2509, learner_queue_size = 32, _tick = 16009, _time = 1.6548e+09, train_seconds = 1.6694e+04)
[2022-06-10 00:46:18,806][root][INFO] - Step 62648320 @ 3581.1 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 62648320, mean_episode_return = 36.932, mean_episode_step = 820.37, total_loss = -24.941, pg_loss = -56.239, baseline_loss = 36.577, entropy_loss = -5.2789, learner_queue_size = 32, _tick = 16016, _time = 1.6548e+09, train_seconds = 1.6699e+04)
[2022-06-10 00:46:23,810][root][INFO] - Step 62666240 @ 3581.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 62666240, mean_episode_return = 36.933, mean_episode_step = 947.2, total_loss = -288.17, pg_loss = -358.12, baseline_loss = 75.245, entropy_loss = -5.287, learner_queue_size = 32, _tick = 16022, _time = 1.6548e+09, train_seconds = 1.6704e+04)
[2022-06-10 00:46:28,814][root][INFO] - Step 62686720 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 62686720, mean_episode_return = 38.295, mean_episode_step = 813.85, total_loss = 264.33, pg_loss = 184.16, baseline_loss = 85.285, entropy_loss = -5.1132, learner_queue_size = 32, _tick = 16027, _time = 1.6548e+09, train_seconds = 1.6709e+04)
[2022-06-10 00:46:33,819][root][INFO] - Step 62704640 @ 3580.6 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 62704640, mean_episode_return = 65.91, mean_episode_step = 987.66, total_loss = -237.17, pg_loss = -259.21, baseline_loss = 27.197, entropy_loss = -5.1586, learner_queue_size = 32, _tick = 16032, _time = 1.6548e+09, train_seconds = 1.6714e+04)
[2022-06-10 00:46:38,823][root][INFO] - Step 62722560 @ 3581.3 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 62722560, mean_episode_return = None, mean_episode_step = 896.0, total_loss = 4.14, pg_loss = -21.015, baseline_loss = 30.502, entropy_loss = -5.3468, learner_queue_size = 32, _tick = 16037, _time = 1.6548e+09, train_seconds = 1.6719e+04)
[2022-06-10 00:46:43,826][root][INFO] - Step 62740480 @ 3581.5 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 62740480, mean_episode_return = 122.21, mean_episode_step = 1377.5, total_loss = -177.82, pg_loss = -201.33, baseline_loss = 28.84, entropy_loss = -5.3232, learner_queue_size = 32, _tick = 16043, _time = 1.6548e+09, train_seconds = 1.6724e+04)
[2022-06-10 00:46:48,830][root][INFO] - Step 62760960 @ 4092.8 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 62760960, mean_episode_return = 31.91, mean_episode_step = 985.96, total_loss = -49.842, pg_loss = -146.85, baseline_loss = 102.26, entropy_loss = -5.2489, learner_queue_size = 32, _tick = 16051, _time = 1.6548e+09, train_seconds = 1.6729e+04)
[2022-06-10 00:46:53,834][root][INFO] - Step 62778880 @ 3581.2 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 62778880, mean_episode_return = 36.41, mean_episode_step = 896.57, total_loss = -118.71, pg_loss = -149.7, baseline_loss = 36.285, entropy_loss = -5.2981, learner_queue_size = 32, _tick = 16056, _time = 1.6548e+09, train_seconds = 1.6734e+04)
[2022-06-10 00:46:58,838][root][INFO] - Step 62796800 @ 3581.2 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 62796800, mean_episode_return = None, mean_episode_step = 1070.4, total_loss = 308.78, pg_loss = 237.9, baseline_loss = 76.264, entropy_loss = -5.39, learner_queue_size = 32, _tick = 16059, _time = 1.6548e+09, train_seconds = 1.6739e+04)
[2022-06-10 00:47:03,842][root][INFO] - Step 62814720 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 62814720, mean_episode_return = 40.675, mean_episode_step = 983.94, total_loss = 151.59, pg_loss = 83.046, baseline_loss = 73.653, entropy_loss = -5.1088, learner_queue_size = 32, _tick = 16065, _time = 1.6548e+09, train_seconds = 1.6744e+04)
[2022-06-10 00:47:08,846][root][INFO] - Step 62832640 @ 3581.2 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 62832640, mean_episode_return = 10.1, mean_episode_step = 819.36, total_loss = 138.57, pg_loss = 24.266, baseline_loss = 119.26, entropy_loss = -4.9523, learner_queue_size = 32, _tick = 16069, _time = 1.6548e+09, train_seconds = 1.6749e+04)
[2022-06-10 00:47:13,850][root][INFO] - Step 62853120 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 62853120, mean_episode_return = 63.44, mean_episode_step = 1060.8, total_loss = 131.81, pg_loss = 77.984, baseline_loss = 59.178, entropy_loss = -5.3504, learner_queue_size = 32, _tick = 16076, _time = 1.6548e+09, train_seconds = 1.6754e+04)
[2022-06-10 00:47:18,854][root][INFO] - Step 62871040 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 62871040, mean_episode_return = 44.298, mean_episode_step = 875.55, total_loss = 374.41, pg_loss = 247.83, baseline_loss = 131.92, entropy_loss = -5.3379, learner_queue_size = 32, _tick = 16082, _time = 1.6548e+09, train_seconds = 1.6759e+04)
[2022-06-10 00:47:23,858][root][INFO] - Step 62891520 @ 4092.9 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 62891520, mean_episode_return = 19.3, mean_episode_step = 961.49, total_loss = -36.392, pg_loss = -58.913, baseline_loss = 27.953, entropy_loss = -5.4309, learner_queue_size = 32, _tick = 16088, _time = 1.6548e+09, train_seconds = 1.6764e+04)
[2022-06-10 00:47:28,862][root][INFO] - Step 62909440 @ 3581.1 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 62909440, mean_episode_return = 101.5, mean_episode_step = 930.33, total_loss = -6.2215, pg_loss = -31.885, baseline_loss = 31.074, entropy_loss = -5.4109, learner_queue_size = 32, _tick = 16095, _time = 1.6548e+09, train_seconds = 1.6769e+04)
[2022-06-10 00:47:33,866][root][INFO] - Step 62929920 @ 4092.5 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 62929920, mean_episode_return = 116.09, mean_episode_step = 894.13, total_loss = 47.417, pg_loss = 1.2735, baseline_loss = 51.484, entropy_loss = -5.3409, learner_queue_size = 32, _tick = 16103, _time = 1.6548e+09, train_seconds = 1.6774e+04)
[2022-06-10 00:47:38,870][root][INFO] - Step 62947840 @ 3581.3 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (step = 62947840, mean_episode_return = 74.155, mean_episode_step = 906.66, total_loss = 302.94, pg_loss = 230.3, baseline_loss = 77.943, entropy_loss = -5.3113, learner_queue_size = 32, _tick = 16109, _time = 1.6548e+09, train_seconds = 1.6779e+04)
[2022-06-10 00:47:43,874][root][INFO] - Step 62965760 @ 3581.1 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (step = 62965760, mean_episode_return = None, mean_episode_step = 922.84, total_loss = 10.773, pg_loss = -69.968, baseline_loss = 85.917, entropy_loss = -5.1759, learner_queue_size = 32, _tick = 16114, _time = 1.6548e+09, train_seconds = 1.6784e+04)
[2022-06-10 00:47:48,878][root][INFO] - Step 62983680 @ 3581.0 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 62983680, mean_episode_return = None, mean_episode_step = 961.16, total_loss = -151.27, pg_loss = -173.61, baseline_loss = 27.593, entropy_loss = -5.2488, learner_queue_size = 32, _tick = 16119, _time = 1.6548e+09, train_seconds = 1.6789e+04)
[2022-06-10 00:47:53,883][root][INFO] - Step 63004160 @ 4092.2 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 63004160, mean_episode_return = None, mean_episode_step = 889.56, total_loss = 106.84, pg_loss = 52.694, baseline_loss = 59.336, entropy_loss = -5.1927, learner_queue_size = 32, _tick = 16125, _time = 1.6548e+09, train_seconds = 1.6794e+04)
[2022-06-10 00:47:58,886][root][INFO] - Step 63022080 @ 3581.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 63022080, mean_episode_return = None, mean_episode_step = 798.5, total_loss = -48.074, pg_loss = -104.08, baseline_loss = 61.158, entropy_loss = -5.1558, learner_queue_size = 32, _tick = 16131, _time = 1.6548e+09, train_seconds = 1.6799e+04)
[2022-06-10 00:48:03,891][root][INFO] - Step 63040000 @ 3580.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 63040000, mean_episode_return = None, mean_episode_step = 921.44, total_loss = 502.35, pg_loss = 395.23, baseline_loss = 112.46, entropy_loss = -5.3455, learner_queue_size = 32, _tick = 16136, _time = 1.6548e+09, train_seconds = 1.6804e+04)
[2022-06-10 00:48:08,894][root][INFO] - Step 63060480 @ 4094.0 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 63060480, mean_episode_return = 129.69, mean_episode_step = 899.5, total_loss = -44.402, pg_loss = -99.536, baseline_loss = 60.468, entropy_loss = -5.3349, learner_queue_size = 32, _tick = 16143, _time = 1.6548e+09, train_seconds = 1.6809e+04)
[2022-06-10 00:48:13,898][root][INFO] - Step 63078400 @ 3581.0 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 63078400, mean_episode_return = 56.57, mean_episode_step = 1085.5, total_loss = -63.954, pg_loss = -102.02, baseline_loss = 43.411, entropy_loss = -5.3492, learner_queue_size = 32, _tick = 16148, _time = 1.6548e+09, train_seconds = 1.6814e+04)
[2022-06-10 00:48:18,902][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 00:48:19,080][root][INFO] - Step 63098880 @ 4092.8 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 63098880, mean_episode_return = None, mean_episode_step = 870.75, total_loss = 161.45, pg_loss = 133.28, baseline_loss = 33.418, entropy_loss = -5.2499, learner_queue_size = 32, _tick = 16154, _time = 1.6548e+09, train_seconds = 1.6819e+04)
[2022-06-10 00:48:24,083][root][INFO] - Step 63116800 @ 3458.6 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 63116800, mean_episode_return = 63.59, mean_episode_step = 1047.2, total_loss = 106.88, pg_loss = 58.153, baseline_loss = 53.969, entropy_loss = -5.2432, learner_queue_size = 32, _tick = 16161, _time = 1.6548e+09, train_seconds = 1.6824e+04)
[2022-06-10 00:48:29,086][root][INFO] - Step 63134720 @ 3582.0 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 63134720, mean_episode_return = None, mean_episode_step = 1079.5, total_loss = 31.81, pg_loss = -1.0298, baseline_loss = 38.163, entropy_loss = -5.3239, learner_queue_size = 32, _tick = 16167, _time = 1.6548e+09, train_seconds = 1.6829e+04)
[2022-06-10 00:48:34,090][root][INFO] - Step 63155200 @ 4092.7 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 63155200, mean_episode_return = 19.68, mean_episode_step = 1166.6, total_loss = -32.419, pg_loss = -59.869, baseline_loss = 32.938, entropy_loss = -5.4868, learner_queue_size = 32, _tick = 16173, _time = 1.6548e+09, train_seconds = 1.6834e+04)
[2022-06-10 00:48:39,094][root][INFO] - Step 63173120 @ 3581.1 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 63173120, mean_episode_return = None, mean_episode_step = 1012.0, total_loss = 588.04, pg_loss = 448.53, baseline_loss = 144.88, entropy_loss = -5.3739, learner_queue_size = 32, _tick = 16178, _time = 1.6548e+09, train_seconds = 1.6839e+04)
[2022-06-10 00:48:44,098][root][INFO] - Step 63191040 @ 3581.2 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 63191040, mean_episode_return = 79.68, mean_episode_step = 1072.7, total_loss = 224.57, pg_loss = 171.57, baseline_loss = 58.109, entropy_loss = -5.1008, learner_queue_size = 32, _tick = 16184, _time = 1.6548e+09, train_seconds = 1.6844e+04)
[2022-06-10 00:48:49,102][root][INFO] - Step 63211520 @ 4092.6 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 63211520, mean_episode_return = 4.0798, mean_episode_step = 933.61, total_loss = 232.01, pg_loss = 161.26, baseline_loss = 75.657, entropy_loss = -4.9105, learner_queue_size = 32, _tick = 16190, _time = 1.6548e+09, train_seconds = 1.6849e+04)
[2022-06-10 00:48:54,106][root][INFO] - Step 63229440 @ 3581.2 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 63229440, mean_episode_return = 31.101, mean_episode_step = 1209.7, total_loss = -66.208, pg_loss = -143.52, baseline_loss = 82.458, entropy_loss = -5.1411, learner_queue_size = 32, _tick = 16195, _time = 1.6548e+09, train_seconds = 1.6854e+04)
[2022-06-10 00:48:59,110][root][INFO] - Step 63247360 @ 3581.1 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 63247360, mean_episode_return = 9.4499, mean_episode_step = 1188.3, total_loss = -50.943, pg_loss = -63.108, baseline_loss = 17.648, entropy_loss = -5.4825, learner_queue_size = 32, _tick = 16202, _time = 1.6548e+09, train_seconds = 1.6859e+04)
[2022-06-10 00:49:04,114][root][INFO] - Step 63265280 @ 3581.0 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 63265280, mean_episode_return = None, mean_episode_step = 1426.7, total_loss = 85.354, pg_loss = 57.46, baseline_loss = 33.28, entropy_loss = -5.3865, learner_queue_size = 32, _tick = 16208, _time = 1.6548e+09, train_seconds = 1.6864e+04)
[2022-06-10 00:49:09,118][root][INFO] - Step 63285760 @ 4092.7 SPS. Inference batcher size: 88. Learner queue size: 32. Other stats: (step = 63285760, mean_episode_return = None, mean_episode_step = 1117.9, total_loss = 72.232, pg_loss = 47.845, baseline_loss = 29.548, entropy_loss = -5.161, learner_queue_size = 32, _tick = 16214, _time = 1.6548e+09, train_seconds = 1.6869e+04)
[2022-06-10 00:49:14,122][root][INFO] - Step 63303680 @ 3581.2 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 63303680, mean_episode_return = 48.655, mean_episode_step = 1242.2, total_loss = -115.91, pg_loss = -148.74, baseline_loss = 37.747, entropy_loss = -4.9225, learner_queue_size = 32, _tick = 16221, _time = 1.6548e+09, train_seconds = 1.6874e+04)
[2022-06-10 00:49:19,126][root][INFO] - Step 63321600 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 63321600, mean_episode_return = 26.195, mean_episode_step = 955.58, total_loss = 101.16, pg_loss = 35.204, baseline_loss = 71.052, entropy_loss = -5.0921, learner_queue_size = 32, _tick = 16225, _time = 1.6548e+09, train_seconds = 1.6879e+04)
[2022-06-10 00:49:24,130][root][INFO] - Step 63342080 @ 4092.7 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 63342080, mean_episode_return = 94.959, mean_episode_step = 989.33, total_loss = 106.02, pg_loss = 66.963, baseline_loss = 43.817, entropy_loss = -4.7617, learner_queue_size = 32, _tick = 16231, _time = 1.6548e+09, train_seconds = 1.6884e+04)
[2022-06-10 00:49:29,135][root][INFO] - Step 63360000 @ 3580.5 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 63360000, mean_episode_return = 112.08, mean_episode_step = 1277.6, total_loss = 37.819, pg_loss = -21.554, baseline_loss = 64.529, entropy_loss = -5.1555, learner_queue_size = 32, _tick = 16238, _time = 1.6548e+09, train_seconds = 1.6889e+04)
[2022-06-10 00:49:34,138][root][INFO] - Step 63377920 @ 3581.8 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 63377920, mean_episode_return = 39.232, mean_episode_step = 1097.5, total_loss = 169.8, pg_loss = 116.75, baseline_loss = 58.286, entropy_loss = -5.2414, learner_queue_size = 32, _tick = 16245, _time = 1.6548e+09, train_seconds = 1.6894e+04)
[2022-06-10 00:49:39,142][root][INFO] - Step 63398400 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 63398400, mean_episode_return = 81.685, mean_episode_step = 851.32, total_loss = -27.412, pg_loss = -53.92, baseline_loss = 31.525, entropy_loss = -5.0169, learner_queue_size = 32, _tick = 16250, _time = 1.6548e+09, train_seconds = 1.6899e+04)
[2022-06-10 00:49:44,146][root][INFO] - Step 63416320 @ 3581.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 63416320, mean_episode_return = 17.68, mean_episode_step = 944.66, total_loss = 331.22, pg_loss = 272.33, baseline_loss = 64.157, entropy_loss = -5.2642, learner_queue_size = 32, _tick = 16255, _time = 1.6548e+09, train_seconds = 1.6904e+04)
[2022-06-10 00:49:49,150][root][INFO] - Step 63436800 @ 4092.6 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 63436800, mean_episode_return = 84.14, mean_episode_step = 1149.0, total_loss = 322.28, pg_loss = 211.46, baseline_loss = 115.92, entropy_loss = -5.1038, learner_queue_size = 32, _tick = 16263, _time = 1.6548e+09, train_seconds = 1.6909e+04)
[2022-06-10 00:49:54,154][root][INFO] - Step 63454720 @ 3581.2 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 63454720, mean_episode_return = 112.06, mean_episode_step = 1225.5, total_loss = -94.454, pg_loss = -120.74, baseline_loss = 31.49, entropy_loss = -5.2086, learner_queue_size = 32, _tick = 16268, _time = 1.6548e+09, train_seconds = 1.6914e+04)
[2022-06-10 00:49:59,158][root][INFO] - Step 63472640 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 63472640, mean_episode_return = 86.23, mean_episode_step = 1092.1, total_loss = -363.0, pg_loss = -435.84, baseline_loss = 77.999, entropy_loss = -5.159, learner_queue_size = 32, _tick = 16273, _time = 1.6548e+09, train_seconds = 1.6919e+04)
[2022-06-10 00:50:04,162][root][INFO] - Step 63493120 @ 4092.7 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 63493120, mean_episode_return = None, mean_episode_step = 889.44, total_loss = 108.75, pg_loss = 45.023, baseline_loss = 68.944, entropy_loss = -5.2126, learner_queue_size = 32, _tick = 16278, _time = 1.6548e+09, train_seconds = 1.6924e+04)
[2022-06-10 00:50:09,166][root][INFO] - Step 63511040 @ 3581.1 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 63511040, mean_episode_return = 36.665, mean_episode_step = 1288.0, total_loss = -229.64, pg_loss = -238.14, baseline_loss = 13.604, entropy_loss = -5.1041, learner_queue_size = 32, _tick = 16285, _time = 1.6548e+09, train_seconds = 1.6929e+04)
[2022-06-10 00:50:14,170][root][INFO] - Step 63528960 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 63528960, mean_episode_return = 89.296, mean_episode_step = 952.64, total_loss = -52.56, pg_loss = -83.14, baseline_loss = 35.816, entropy_loss = -5.2358, learner_queue_size = 32, _tick = 16291, _time = 1.6548e+09, train_seconds = 1.6934e+04)
[2022-06-10 00:50:19,174][root][INFO] - Step 63546880 @ 3581.2 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 63546880, mean_episode_return = 44.923, mean_episode_step = 1668.9, total_loss = 143.36, pg_loss = 65.772, baseline_loss = 82.694, entropy_loss = -5.1092, learner_queue_size = 32, _tick = 16297, _time = 1.6548e+09, train_seconds = 1.6939e+04)
[2022-06-10 00:50:24,178][root][INFO] - Step 63564800 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 63564800, mean_episode_return = 19.675, mean_episode_step = 863.35, total_loss = 87.705, pg_loss = 45.45, baseline_loss = 47.116, entropy_loss = -4.8607, learner_queue_size = 32, _tick = 16302, _time = 1.6548e+09, train_seconds = 1.6944e+04)
[2022-06-10 00:50:29,182][root][INFO] - Step 63585280 @ 4092.7 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 63585280, mean_episode_return = 74.13, mean_episode_step = 925.49, total_loss = -221.24, pg_loss = -234.05, baseline_loss = 17.873, entropy_loss = -5.0628, learner_queue_size = 32, _tick = 16309, _time = 1.6548e+09, train_seconds = 1.6949e+04)
[2022-06-10 00:50:34,186][root][INFO] - Step 63603200 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 63603200, mean_episode_return = 39.68, mean_episode_step = 951.46, total_loss = 299.32, pg_loss = 235.06, baseline_loss = 69.247, entropy_loss = -4.9911, learner_queue_size = 32, _tick = 16316, _time = 1.6548e+09, train_seconds = 1.6954e+04)
[2022-06-10 00:50:39,190][root][INFO] - Step 63623680 @ 4092.8 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 63623680, mean_episode_return = 77.5, mean_episode_step = 1082.5, total_loss = 174.46, pg_loss = 101.44, baseline_loss = 78.177, entropy_loss = -5.1555, learner_queue_size = 32, _tick = 16324, _time = 1.6548e+09, train_seconds = 1.6959e+04)
[2022-06-10 00:50:44,194][root][INFO] - Step 63641600 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 63641600, mean_episode_return = 152.24, mean_episode_step = 1241.4, total_loss = -31.646, pg_loss = -98.219, baseline_loss = 71.647, entropy_loss = -5.074, learner_queue_size = 32, _tick = 16330, _time = 1.6548e+09, train_seconds = 1.6964e+04)
[2022-06-10 00:50:49,198][root][INFO] - Step 63659520 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 63659520, mean_episode_return = 67.44, mean_episode_step = 893.45, total_loss = -20.591, pg_loss = -82.251, baseline_loss = 66.145, entropy_loss = -4.4852, learner_queue_size = 32, _tick = 16337, _time = 1.6548e+09, train_seconds = 1.6969e+04)
[2022-06-10 00:50:54,202][root][INFO] - Step 63680000 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 63680000, mean_episode_return = None, mean_episode_step = 1453.0, total_loss = 38.92, pg_loss = 0.6828, baseline_loss = 43.336, entropy_loss = -5.0986, learner_queue_size = 32, _tick = 16340, _time = 1.6548e+09, train_seconds = 1.6974e+04)
[2022-06-10 00:50:59,206][root][INFO] - Step 63697920 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 63697920, mean_episode_return = 49.351, mean_episode_step = 1044.0, total_loss = 7.7755, pg_loss = -29.517, baseline_loss = 41.987, entropy_loss = -4.6946, learner_queue_size = 32, _tick = 16346, _time = 1.6548e+09, train_seconds = 1.6979e+04)
[2022-06-10 00:51:04,210][root][INFO] - Step 63715840 @ 3581.2 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (step = 63715840, mean_episode_return = None, mean_episode_step = 1125.1, total_loss = 338.6, pg_loss = 240.67, baseline_loss = 102.85, entropy_loss = -4.9199, learner_queue_size = 32, _tick = 16350, _time = 1.6548e+09, train_seconds = 1.6984e+04)
[2022-06-10 00:51:09,214][root][INFO] - Step 63736320 @ 4092.8 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 63736320, mean_episode_return = 79.661, mean_episode_step = 1208.2, total_loss = -183.27, pg_loss = -211.81, baseline_loss = 33.456, entropy_loss = -4.916, learner_queue_size = 32, _tick = 16356, _time = 1.6548e+09, train_seconds = 1.6989e+04)
[2022-06-10 00:51:14,218][root][INFO] - Step 63754240 @ 3580.9 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 63754240, mean_episode_return = 127.97, mean_episode_step = 1105.3, total_loss = 61.322, pg_loss = 22.421, baseline_loss = 43.997, entropy_loss = -5.0967, learner_queue_size = 32, _tick = 16363, _time = 1.6548e+09, train_seconds = 1.6994e+04)
[2022-06-10 00:51:19,222][root][INFO] - Step 63774720 @ 4093.0 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 63774720, mean_episode_return = None, mean_episode_step = 1308.2, total_loss = -84.789, pg_loss = -101.69, baseline_loss = 22.169, entropy_loss = -5.2658, learner_queue_size = 32, _tick = 16370, _time = 1.6548e+09, train_seconds = 1.6999e+04)
[2022-06-10 00:51:24,226][root][INFO] - Step 63792640 @ 3581.0 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 63792640, mean_episode_return = 93.57, mean_episode_step = 1171.2, total_loss = 186.81, pg_loss = 108.69, baseline_loss = 83.276, entropy_loss = -5.1501, learner_queue_size = 32, _tick = 16377, _time = 1.6548e+09, train_seconds = 1.7004e+04)
[2022-06-10 00:51:29,231][root][INFO] - Step 63813120 @ 4092.2 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 63813120, mean_episode_return = 106.45, mean_episode_step = 858.78, total_loss = -37.794, pg_loss = -79.584, baseline_loss = 46.948, entropy_loss = -5.1571, learner_queue_size = 32, _tick = 16385, _time = 1.6548e+09, train_seconds = 1.7009e+04)
[2022-06-10 00:51:34,234][root][INFO] - Step 63831040 @ 3581.6 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 63831040, mean_episode_return = 76.16, mean_episode_step = 984.23, total_loss = -33.452, pg_loss = -63.3, baseline_loss = 35.004, entropy_loss = -5.1559, learner_queue_size = 32, _tick = 16389, _time = 1.6548e+09, train_seconds = 1.7014e+04)
[2022-06-10 00:51:39,238][root][INFO] - Step 63848960 @ 3581.1 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 63848960, mean_episode_return = 40.76, mean_episode_step = 1216.6, total_loss = -156.21, pg_loss = -213.17, baseline_loss = 62.204, entropy_loss = -5.2359, learner_queue_size = 32, _tick = 16395, _time = 1.6548e+09, train_seconds = 1.7019e+04)
[2022-06-10 00:51:44,242][root][INFO] - Step 63869440 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 63869440, mean_episode_return = 113.24, mean_episode_step = 1320.9, total_loss = 386.0, pg_loss = 280.89, baseline_loss = 110.39, entropy_loss = -5.2757, learner_queue_size = 32, _tick = 16401, _time = 1.6548e+09, train_seconds = 1.7024e+04)
[2022-06-10 00:51:49,246][root][INFO] - Step 63887360 @ 3581.2 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 63887360, mean_episode_return = 227.04, mean_episode_step = 1336.1, total_loss = 268.91, pg_loss = 198.51, baseline_loss = 75.674, entropy_loss = -5.2748, learner_queue_size = 32, _tick = 16408, _time = 1.6548e+09, train_seconds = 1.7029e+04)
[2022-06-10 00:51:54,250][root][INFO] - Step 63905280 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 63905280, mean_episode_return = None, mean_episode_step = 1087.2, total_loss = 94.047, pg_loss = 44.608, baseline_loss = 54.57, entropy_loss = -5.131, learner_queue_size = 32, _tick = 16412, _time = 1.6548e+09, train_seconds = 1.7034e+04)
[2022-06-10 00:51:59,254][root][INFO] - Step 63925760 @ 4092.7 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 63925760, mean_episode_return = 125.05, mean_episode_step = 1025.6, total_loss = 125.47, pg_loss = 30.528, baseline_loss = 100.25, entropy_loss = -5.3066, learner_queue_size = 32, _tick = 16418, _time = 1.6548e+09, train_seconds = 1.7039e+04)
[2022-06-10 00:52:04,258][root][INFO] - Step 63943680 @ 3581.2 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 63943680, mean_episode_return = 16.53, mean_episode_step = 1705.6, total_loss = 396.32, pg_loss = 299.76, baseline_loss = 101.76, entropy_loss = -5.2026, learner_queue_size = 32, _tick = 16424, _time = 1.6548e+09, train_seconds = 1.7044e+04)
[2022-06-10 00:52:09,262][root][INFO] - Step 63961600 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 63961600, mean_episode_return = 58.02, mean_episode_step = 1411.7, total_loss = 159.2, pg_loss = 53.491, baseline_loss = 110.76, entropy_loss = -5.0495, learner_queue_size = 32, _tick = 16430, _time = 1.6548e+09, train_seconds = 1.7049e+04)
[2022-06-10 00:52:14,266][root][INFO] - Step 63982080 @ 4092.7 SPS. Inference batcher size: 76. Learner queue size: 32. Other stats: (step = 63982080, mean_episode_return = 43.36, mean_episode_step = 1806.7, total_loss = -84.389, pg_loss = -97.135, baseline_loss = 18.106, entropy_loss = -5.3606, learner_queue_size = 32, _tick = 16436, _time = 1.6548e+09, train_seconds = 1.7054e+04)
[2022-06-10 00:52:19,270][root][INFO] - Step 64000000 @ 3581.2 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 64000000, mean_episode_return = 50.698, mean_episode_step = 864.85, total_loss = -96.723, pg_loss = -146.51, baseline_loss = 55.076, entropy_loss = -5.2928, learner_queue_size = 32, _tick = 16440, _time = 1.6548e+09, train_seconds = 1.7059e+04)
[2022-06-10 00:52:24,274][root][INFO] - Step 64017920 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 64017920, mean_episode_return = 3.4999, mean_episode_step = 1209.6, total_loss = -116.24, pg_loss = -207.03, baseline_loss = 95.987, entropy_loss = -5.1886, learner_queue_size = 32, _tick = 16445, _time = 1.6548e+09, train_seconds = 1.7064e+04)
[2022-06-10 00:52:29,278][root][INFO] - Step 64038400 @ 4092.7 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 64038400, mean_episode_return = None, mean_episode_step = 937.28, total_loss = 190.67, pg_loss = 133.36, baseline_loss = 62.445, entropy_loss = -5.1359, learner_queue_size = 32, _tick = 16449, _time = 1.6548e+09, train_seconds = 1.7069e+04)
[2022-06-10 00:52:34,282][root][INFO] - Step 64056320 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 64056320, mean_episode_return = 49.676, mean_episode_step = 1473.1, total_loss = 96.515, pg_loss = 53.017, baseline_loss = 48.738, entropy_loss = -5.2393, learner_queue_size = 32, _tick = 16454, _time = 1.6548e+09, train_seconds = 1.7074e+04)
[2022-06-10 00:52:39,286][root][INFO] - Step 64074240 @ 3581.2 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 64074240, mean_episode_return = 53.775, mean_episode_step = 983.01, total_loss = 406.93, pg_loss = 305.92, baseline_loss = 106.32, entropy_loss = -5.318, learner_queue_size = 32, _tick = 16460, _time = 1.6548e+09, train_seconds = 1.7079e+04)
[2022-06-10 00:52:44,290][root][INFO] - Step 64094720 @ 4092.7 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 64094720, mean_episode_return = 66.471, mean_episode_step = 890.16, total_loss = 274.65, pg_loss = 192.66, baseline_loss = 87.194, entropy_loss = -5.2046, learner_queue_size = 32, _tick = 16467, _time = 1.6548e+09, train_seconds = 1.7084e+04)
[2022-06-10 00:52:49,296][root][INFO] - Step 64112640 @ 3579.7 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 64112640, mean_episode_return = None, mean_episode_step = 1487.3, total_loss = 368.26, pg_loss = 291.57, baseline_loss = 81.963, entropy_loss = -5.2661, learner_queue_size = 32, _tick = 16471, _time = 1.6548e+09, train_seconds = 1.7089e+04)
[2022-06-10 00:52:54,302][root][INFO] - Step 64130560 @ 3579.7 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 64130560, mean_episode_return = 207.35, mean_episode_step = 1321.3, total_loss = 65.028, pg_loss = 29.513, baseline_loss = 40.714, entropy_loss = -5.1983, learner_queue_size = 32, _tick = 16475, _time = 1.6548e+09, train_seconds = 1.7094e+04)
[2022-06-10 00:52:59,306][root][INFO] - Step 64151040 @ 4092.7 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 64151040, mean_episode_return = None, mean_episode_step = 1463.4, total_loss = 148.65, pg_loss = 66.423, baseline_loss = 87.44, entropy_loss = -5.2152, learner_queue_size = 32, _tick = 16478, _time = 1.6548e+09, train_seconds = 1.7099e+04)
[2022-06-10 00:53:04,310][root][INFO] - Step 64168960 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 64168960, mean_episode_return = 90.0, mean_episode_step = 1094.3, total_loss = 123.33, pg_loss = 52.108, baseline_loss = 76.474, entropy_loss = -5.2487, learner_queue_size = 32, _tick = 16485, _time = 1.6548e+09, train_seconds = 1.7104e+04)
[2022-06-10 00:53:09,314][root][INFO] - Step 64186880 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 64186880, mean_episode_return = 31.86, mean_episode_step = 1087.6, total_loss = -47.077, pg_loss = -73.727, baseline_loss = 31.859, entropy_loss = -5.2096, learner_queue_size = 32, _tick = 16490, _time = 1.6548e+09, train_seconds = 1.7109e+04)
[2022-06-10 00:53:14,318][root][INFO] - Step 64207360 @ 4092.6 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 64207360, mean_episode_return = None, mean_episode_step = 1055.5, total_loss = 97.195, pg_loss = 43.966, baseline_loss = 58.454, entropy_loss = -5.2256, learner_queue_size = 32, _tick = 16496, _time = 1.6548e+09, train_seconds = 1.7114e+04)
[2022-06-10 00:53:19,322][root][INFO] - Step 64225280 @ 3581.3 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 64225280, mean_episode_return = 64.579, mean_episode_step = 1110.9, total_loss = -93.172, pg_loss = -121.73, baseline_loss = 33.798, entropy_loss = -5.2355, learner_queue_size = 32, _tick = 16502, _time = 1.6548e+09, train_seconds = 1.7119e+04)
[2022-06-10 00:53:24,326][root][INFO] - Step 64245760 @ 4092.7 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 64245760, mean_episode_return = None, mean_episode_step = 1452.8, total_loss = 361.21, pg_loss = 262.83, baseline_loss = 103.61, entropy_loss = -5.2354, learner_queue_size = 32, _tick = 16508, _time = 1.6548e+09, train_seconds = 1.7124e+04)
[2022-06-10 00:53:29,330][root][INFO] - Step 64263680 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 64263680, mean_episode_return = None, mean_episode_step = 1576.8, total_loss = -115.51, pg_loss = -130.77, baseline_loss = 20.595, entropy_loss = -5.3274, learner_queue_size = 32, _tick = 16513, _time = 1.6548e+09, train_seconds = 1.7129e+04)
[2022-06-10 00:53:34,334][root][INFO] - Step 64281600 @ 3581.2 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 64281600, mean_episode_return = 60.82, mean_episode_step = 1125.8, total_loss = 150.43, pg_loss = 49.616, baseline_loss = 106.07, entropy_loss = -5.2557, learner_queue_size = 32, _tick = 16518, _time = 1.6548e+09, train_seconds = 1.7134e+04)
[2022-06-10 00:53:39,338][root][INFO] - Step 64299520 @ 3581.1 SPS. Inference batcher size: 75. Learner queue size: 32. Other stats: (step = 64299520, mean_episode_return = 90.845, mean_episode_step = 1238.9, total_loss = 346.08, pg_loss = 232.28, baseline_loss = 119.01, entropy_loss = -5.2154, learner_queue_size = 32, _tick = 16524, _time = 1.6548e+09, train_seconds = 1.7139e+04)
[2022-06-10 00:53:44,342][root][INFO] - Step 64317440 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 64317440, mean_episode_return = None, mean_episode_step = 1148.5, total_loss = 137.34, pg_loss = 73.298, baseline_loss = 69.324, entropy_loss = -5.2832, learner_queue_size = 32, _tick = 16529, _time = 1.6548e+09, train_seconds = 1.7144e+04)
[2022-06-10 00:53:49,346][root][INFO] - Step 64337920 @ 4092.5 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 64337920, mean_episode_return = 30.83, mean_episode_step = 948.63, total_loss = 85.068, pg_loss = 42.855, baseline_loss = 47.335, entropy_loss = -5.1218, learner_queue_size = 32, _tick = 16535, _time = 1.6548e+09, train_seconds = 1.7149e+04)
[2022-06-10 00:53:54,350][root][INFO] - Step 64355840 @ 3581.3 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 64355840, mean_episode_return = 76.113, mean_episode_step = 1030.6, total_loss = -92.533, pg_loss = -152.07, baseline_loss = 64.562, entropy_loss = -5.0228, learner_queue_size = 32, _tick = 16541, _time = 1.6548e+09, train_seconds = 1.7154e+04)
[2022-06-10 00:53:59,354][root][INFO] - Step 64376320 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 64376320, mean_episode_return = 58.691, mean_episode_step = 1352.7, total_loss = 128.83, pg_loss = 88.005, baseline_loss = 46.168, entropy_loss = -5.3385, learner_queue_size = 32, _tick = 16548, _time = 1.6548e+09, train_seconds = 1.7159e+04)
[2022-06-10 00:54:04,358][root][INFO] - Step 64394240 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 64394240, mean_episode_return = 25.481, mean_episode_step = 2173.0, total_loss = -121.16, pg_loss = -147.2, baseline_loss = 31.285, entropy_loss = -5.25, learner_queue_size = 32, _tick = 16553, _time = 1.6548e+09, train_seconds = 1.7164e+04)
[2022-06-10 00:54:09,362][root][INFO] - Step 64414720 @ 4092.8 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 64414720, mean_episode_return = 41.103, mean_episode_step = 1131.1, total_loss = 8.7324, pg_loss = -42.583, baseline_loss = 56.59, entropy_loss = -5.2743, learner_queue_size = 32, _tick = 16560, _time = 1.6548e+09, train_seconds = 1.7169e+04)
[2022-06-10 00:54:14,366][root][INFO] - Step 64432640 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 64432640, mean_episode_return = None, mean_episode_step = 1235.1, total_loss = -4.7579, pg_loss = -40.133, baseline_loss = 40.751, entropy_loss = -5.3758, learner_queue_size = 32, _tick = 16566, _time = 1.6548e+09, train_seconds = 1.7174e+04)
[2022-06-10 00:54:19,370][root][INFO] - Step 64450560 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 64450560, mean_episode_return = 86.039, mean_episode_step = 1081.3, total_loss = 301.99, pg_loss = 232.88, baseline_loss = 74.316, entropy_loss = -5.198, learner_queue_size = 32, _tick = 16573, _time = 1.6548e+09, train_seconds = 1.7179e+04)
[2022-06-10 00:54:24,374][root][INFO] - Step 64471040 @ 4092.7 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 64471040, mean_episode_return = 76.48, mean_episode_step = 1217.0, total_loss = 77.016, pg_loss = -26.716, baseline_loss = 108.98, entropy_loss = -5.2468, learner_queue_size = 32, _tick = 16580, _time = 1.6548e+09, train_seconds = 1.7184e+04)
[2022-06-10 00:54:29,379][root][INFO] - Step 64488960 @ 3580.6 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 64488960, mean_episode_return = 68.92, mean_episode_step = 1861.2, total_loss = -141.04, pg_loss = -225.37, baseline_loss = 89.404, entropy_loss = -5.0691, learner_queue_size = 32, _tick = 16587, _time = 1.6548e+09, train_seconds = 1.7189e+04)
[2022-06-10 00:54:34,382][root][INFO] - Step 64509440 @ 4093.3 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 64509440, mean_episode_return = 74.03, mean_episode_step = 813.97, total_loss = 116.86, pg_loss = 36.387, baseline_loss = 85.733, entropy_loss = -5.2584, learner_queue_size = 32, _tick = 16595, _time = 1.6548e+09, train_seconds = 1.7194e+04)
[2022-06-10 00:54:39,386][root][INFO] - Step 64527360 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 64527360, mean_episode_return = 20.919, mean_episode_step = 1008.7, total_loss = 118.57, pg_loss = 43.5, baseline_loss = 80.277, entropy_loss = -5.2101, learner_queue_size = 32, _tick = 16600, _time = 1.6548e+09, train_seconds = 1.7199e+04)
[2022-06-10 00:54:44,390][root][INFO] - Step 64545280 @ 3581.2 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 64545280, mean_episode_return = 132.5, mean_episode_step = 856.85, total_loss = -2.3137, pg_loss = -50.863, baseline_loss = 53.544, entropy_loss = -4.9943, learner_queue_size = 32, _tick = 16606, _time = 1.6548e+09, train_seconds = 1.7204e+04)
[2022-06-10 00:54:49,394][root][INFO] - Step 64563200 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 64563200, mean_episode_return = None, mean_episode_step = 997.25, total_loss = -174.47, pg_loss = -194.91, baseline_loss = 25.569, entropy_loss = -5.1324, learner_queue_size = 32, _tick = 16612, _time = 1.6548e+09, train_seconds = 1.7209e+04)
[2022-06-10 00:54:54,398][root][INFO] - Step 64583680 @ 4092.8 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 64583680, mean_episode_return = 51.197, mean_episode_step = 947.0, total_loss = -28.32, pg_loss = -64.029, baseline_loss = 40.957, entropy_loss = -5.2478, learner_queue_size = 32, _tick = 16619, _time = 1.6548e+09, train_seconds = 1.7214e+04)
[2022-06-10 00:54:59,402][root][INFO] - Step 64601600 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 64601600, mean_episode_return = None, mean_episode_step = 917.44, total_loss = 30.826, pg_loss = -1.9131, baseline_loss = 38.119, entropy_loss = -5.3799, learner_queue_size = 32, _tick = 16624, _time = 1.6548e+09, train_seconds = 1.7219e+04)
[2022-06-10 00:55:04,407][root][INFO] - Step 64619520 @ 3580.4 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 64619520, mean_episode_return = 82.299, mean_episode_step = 1068.7, total_loss = 355.58, pg_loss = 266.34, baseline_loss = 94.606, entropy_loss = -5.3678, learner_queue_size = 32, _tick = 16631, _time = 1.6548e+09, train_seconds = 1.7224e+04)
[2022-06-10 00:55:09,410][root][INFO] - Step 64640000 @ 4093.5 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 64640000, mean_episode_return = 101.38, mean_episode_step = 1424.1, total_loss = -111.67, pg_loss = -140.07, baseline_loss = 33.772, entropy_loss = -5.3727, learner_queue_size = 32, _tick = 16638, _time = 1.6548e+09, train_seconds = 1.7229e+04)
[2022-06-10 00:55:14,414][root][INFO] - Step 64657920 @ 3581.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 64657920, mean_episode_return = 65.699, mean_episode_step = 1380.4, total_loss = 323.39, pg_loss = 252.77, baseline_loss = 75.99, entropy_loss = -5.3767, learner_queue_size = 32, _tick = 16644, _time = 1.6548e+09, train_seconds = 1.7234e+04)
[2022-06-10 00:55:19,418][root][INFO] - Step 64675840 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 64675840, mean_episode_return = 20.225, mean_episode_step = 773.11, total_loss = -260.12, pg_loss = -276.81, baseline_loss = 21.945, entropy_loss = -5.2539, learner_queue_size = 32, _tick = 16649, _time = 1.6548e+09, train_seconds = 1.7239e+04)
[2022-06-10 00:55:24,422][root][INFO] - Step 64696320 @ 4092.8 SPS. Inference batcher size: 76. Learner queue size: 32. Other stats: (step = 64696320, mean_episode_return = None, mean_episode_step = 2120.7, total_loss = 204.88, pg_loss = 109.09, baseline_loss = 100.98, entropy_loss = -5.1919, learner_queue_size = 32, _tick = 16655, _time = 1.6548e+09, train_seconds = 1.7244e+04)
[2022-06-10 00:55:29,426][root][INFO] - Step 64714240 @ 3581.2 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (step = 64714240, mean_episode_return = 39.428, mean_episode_step = 810.08, total_loss = -156.81, pg_loss = -190.37, baseline_loss = 38.8, entropy_loss = -5.2378, learner_queue_size = 32, _tick = 16661, _time = 1.6548e+09, train_seconds = 1.7249e+04)
[2022-06-10 00:55:34,430][root][INFO] - Step 64732160 @ 3581.1 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 64732160, mean_episode_return = None, mean_episode_step = 1937.7, total_loss = 38.722, pg_loss = -19.103, baseline_loss = 63.159, entropy_loss = -5.3329, learner_queue_size = 32, _tick = 16664, _time = 1.6548e+09, train_seconds = 1.7254e+04)
[2022-06-10 00:55:39,434][root][INFO] - Step 64750080 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 64750080, mean_episode_return = 60.834, mean_episode_step = 1000.8, total_loss = -102.73, pg_loss = -129.28, baseline_loss = 31.931, entropy_loss = -5.3812, learner_queue_size = 32, _tick = 16671, _time = 1.6548e+09, train_seconds = 1.7259e+04)
[2022-06-10 00:55:44,438][root][INFO] - Step 64770560 @ 4092.5 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 64770560, mean_episode_return = 132.93, mean_episode_step = 973.5, total_loss = 99.978, pg_loss = 27.914, baseline_loss = 77.439, entropy_loss = -5.3759, learner_queue_size = 32, _tick = 16679, _time = 1.6548e+09, train_seconds = 1.7264e+04)
[2022-06-10 00:55:49,442][root][INFO] - Step 64788480 @ 3581.3 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 64788480, mean_episode_return = 80.24, mean_episode_step = 1064.6, total_loss = 63.286, pg_loss = 1.7011, baseline_loss = 66.906, entropy_loss = -5.321, learner_queue_size = 32, _tick = 16685, _time = 1.6548e+09, train_seconds = 1.7269e+04)
[2022-06-10 00:55:54,446][root][INFO] - Step 64806400 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 64806400, mean_episode_return = None, mean_episode_step = 1142.5, total_loss = 201.98, pg_loss = 113.97, baseline_loss = 93.318, entropy_loss = -5.3102, learner_queue_size = 32, _tick = 16691, _time = 1.6548e+09, train_seconds = 1.7274e+04)
[2022-06-10 00:55:59,453][root][INFO] - Step 64826880 @ 4090.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 64826880, mean_episode_return = None, mean_episode_step = 874.31, total_loss = 82.887, pg_loss = 34.171, baseline_loss = 54.082, entropy_loss = -5.3658, learner_queue_size = 32, _tick = 16697, _time = 1.6548e+09, train_seconds = 1.7279e+04)
[2022-06-10 00:56:04,458][root][INFO] - Step 64844800 @ 3580.1 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 64844800, mean_episode_return = -9.8501, mean_episode_step = 1109.9, total_loss = 177.55, pg_loss = 93.162, baseline_loss = 89.626, entropy_loss = -5.2388, learner_queue_size = 32, _tick = 16704, _time = 1.6548e+09, train_seconds = 1.7284e+04)
[2022-06-10 00:56:09,462][root][INFO] - Step 64862720 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 64862720, mean_episode_return = 72.193, mean_episode_step = 1681.4, total_loss = -82.336, pg_loss = -115.6, baseline_loss = 38.603, entropy_loss = -5.3405, learner_queue_size = 32, _tick = 16709, _time = 1.6548e+09, train_seconds = 1.7289e+04)
[2022-06-10 00:56:14,466][root][INFO] - Step 64880640 @ 3581.0 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 64880640, mean_episode_return = 44.74, mean_episode_step = 1629.1, total_loss = -34.396, pg_loss = -70.832, baseline_loss = 41.658, entropy_loss = -5.2218, learner_queue_size = 32, _tick = 16715, _time = 1.6548e+09, train_seconds = 1.7294e+04)
[2022-06-10 00:56:19,470][root][INFO] - Step 64901120 @ 4092.8 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 64901120, mean_episode_return = 84.701, mean_episode_step = 968.22, total_loss = -258.83, pg_loss = -285.89, baseline_loss = 32.301, entropy_loss = -5.2442, learner_queue_size = 32, _tick = 16723, _time = 1.6548e+09, train_seconds = 1.7299e+04)
[2022-06-10 00:56:24,474][root][INFO] - Step 64919040 @ 3581.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 64919040, mean_episode_return = 142.44, mean_episode_step = 897.2, total_loss = 1025.5, pg_loss = 770.29, baseline_loss = 260.54, entropy_loss = -5.3163, learner_queue_size = 32, _tick = 16730, _time = 1.6548e+09, train_seconds = 1.7304e+04)
[2022-06-10 00:56:29,478][root][INFO] - Step 64936960 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 64936960, mean_episode_return = 34.265, mean_episode_step = 801.32, total_loss = -44.532, pg_loss = -75.779, baseline_loss = 36.515, entropy_loss = -5.2678, learner_queue_size = 32, _tick = 16736, _time = 1.6548e+09, train_seconds = 1.7309e+04)
[2022-06-10 00:56:34,483][root][INFO] - Step 64957440 @ 4092.8 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 64957440, mean_episode_return = None, mean_episode_step = 943.44, total_loss = -98.021, pg_loss = -115.12, baseline_loss = 22.459, entropy_loss = -5.363, learner_queue_size = 32, _tick = 16742, _time = 1.6548e+09, train_seconds = 1.7314e+04)
[2022-06-10 00:56:39,486][root][INFO] - Step 64975360 @ 3580.8 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 64975360, mean_episode_return = 44.046, mean_episode_step = 843.19, total_loss = -34.576, pg_loss = -108.61, baseline_loss = 79.351, entropy_loss = -5.3158, learner_queue_size = 32, _tick = 16748, _time = 1.6548e+09, train_seconds = 1.7319e+04)
[2022-06-10 00:56:44,490][root][INFO] - Step 64993280 @ 3581.4 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 64993280, mean_episode_return = 127.63, mean_episode_step = 1011.3, total_loss = 184.76, pg_loss = 116.52, baseline_loss = 73.602, entropy_loss = -5.3637, learner_queue_size = 32, _tick = 16755, _time = 1.6548e+09, train_seconds = 1.7324e+04)
[2022-06-10 00:56:49,496][root][INFO] - Step 65011200 @ 3579.7 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 65011200, mean_episode_return = 45.703, mean_episode_step = 1481.2, total_loss = 138.3, pg_loss = 66.179, baseline_loss = 77.467, entropy_loss = -5.348, learner_queue_size = 32, _tick = 16761, _time = 1.6548e+09, train_seconds = 1.7329e+04)
[2022-06-10 00:56:54,499][root][INFO] - Step 65031680 @ 4094.5 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 65031680, mean_episode_return = 18.635, mean_episode_step = 1006.9, total_loss = -140.4, pg_loss = -166.91, baseline_loss = 31.851, entropy_loss = -5.3401, learner_queue_size = 32, _tick = 16769, _time = 1.6548e+09, train_seconds = 1.7334e+04)
[2022-06-10 00:56:59,502][root][INFO] - Step 65049600 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 65049600, mean_episode_return = 60.99, mean_episode_step = 876.57, total_loss = -70.535, pg_loss = -97.04, baseline_loss = 31.942, entropy_loss = -5.4363, learner_queue_size = 32, _tick = 16775, _time = 1.6548e+09, train_seconds = 1.7339e+04)
[2022-06-10 00:57:04,506][root][INFO] - Step 65070080 @ 4092.7 SPS. Inference batcher size: 80. Learner queue size: 32. Other stats: (step = 65070080, mean_episode_return = 92.798, mean_episode_step = 836.65, total_loss = -294.71, pg_loss = -297.78, baseline_loss = 8.4902, entropy_loss = -5.4238, learner_queue_size = 32, _tick = 16781, _time = 1.6548e+09, train_seconds = 1.7344e+04)
[2022-06-10 00:57:09,514][root][INFO] - Step 65088000 @ 3578.2 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 65088000, mean_episode_return = 48.515, mean_episode_step = 1329.2, total_loss = 399.92, pg_loss = 284.66, baseline_loss = 120.63, entropy_loss = -5.3572, learner_queue_size = 32, _tick = 16786, _time = 1.6548e+09, train_seconds = 1.7349e+04)
[2022-06-10 00:57:14,518][root][INFO] - Step 65105920 @ 3581.3 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 65105920, mean_episode_return = None, mean_episode_step = 806.5, total_loss = 69.173, pg_loss = 22.811, baseline_loss = 51.628, entropy_loss = -5.2662, learner_queue_size = 32, _tick = 16790, _time = 1.6548e+09, train_seconds = 1.7354e+04)
[2022-06-10 00:57:19,522][root][INFO] - Step 65123840 @ 3581.1 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (step = 65123840, mean_episode_return = 50.703, mean_episode_step = 999.36, total_loss = 16.493, pg_loss = -55.378, baseline_loss = 77.192, entropy_loss = -5.322, learner_queue_size = 32, _tick = 16796, _time = 1.6548e+09, train_seconds = 1.7359e+04)
[2022-06-10 00:57:24,526][root][INFO] - Step 65144320 @ 4092.7 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (step = 65144320, mean_episode_return = 47.54, mean_episode_step = 848.13, total_loss = 304.68, pg_loss = 237.28, baseline_loss = 72.731, entropy_loss = -5.3297, learner_queue_size = 32, _tick = 16803, _time = 1.6548e+09, train_seconds = 1.7364e+04)
[2022-06-10 00:57:29,530][root][INFO] - Step 65162240 @ 3581.2 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 65162240, mean_episode_return = 86.07, mean_episode_step = 1084.8, total_loss = 326.66, pg_loss = 231.57, baseline_loss = 100.42, entropy_loss = -5.326, learner_queue_size = 32, _tick = 16809, _time = 1.6548e+09, train_seconds = 1.7369e+04)
[2022-06-10 00:57:34,534][root][INFO] - Step 65180160 @ 3581.1 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (step = 65180160, mean_episode_return = None, mean_episode_step = 913.66, total_loss = -18.393, pg_loss = -66.36, baseline_loss = 53.319, entropy_loss = -5.3523, learner_queue_size = 32, _tick = 16813, _time = 1.6548e+09, train_seconds = 1.7374e+04)
[2022-06-10 00:57:39,538][root][INFO] - Step 65200640 @ 4092.7 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 65200640, mean_episode_return = -3.49, mean_episode_step = 796.7, total_loss = 128.28, pg_loss = 65.327, baseline_loss = 68.294, entropy_loss = -5.3394, learner_queue_size = 32, _tick = 16820, _time = 1.6548e+09, train_seconds = 1.7379e+04)
[2022-06-10 00:57:44,542][root][INFO] - Step 65218560 @ 3581.1 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 65218560, mean_episode_return = 30.72, mean_episode_step = 850.65, total_loss = 245.27, pg_loss = 177.97, baseline_loss = 72.581, entropy_loss = -5.283, learner_queue_size = 32, _tick = 16825, _time = 1.6548e+09, train_seconds = 1.7384e+04)
[2022-06-10 00:57:49,546][root][INFO] - Step 65236480 @ 3581.1 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 65236480, mean_episode_return = None, mean_episode_step = 724.75, total_loss = -12.707, pg_loss = -38.98, baseline_loss = 31.666, entropy_loss = -5.3935, learner_queue_size = 32, _tick = 16830, _time = 1.6548e+09, train_seconds = 1.7389e+04)
[2022-06-10 00:57:54,550][root][INFO] - Step 65256960 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 65256960, mean_episode_return = 72.56, mean_episode_step = 997.59, total_loss = -165.07, pg_loss = -170.33, baseline_loss = 10.676, entropy_loss = -5.4167, learner_queue_size = 32, _tick = 16838, _time = 1.6548e+09, train_seconds = 1.7394e+04)
[2022-06-10 00:57:59,554][root][INFO] - Step 65274880 @ 3581.2 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 65274880, mean_episode_return = 7.0697, mean_episode_step = 1455.8, total_loss = 370.44, pg_loss = 284.66, baseline_loss = 91.189, entropy_loss = -5.4041, learner_queue_size = 32, _tick = 16844, _time = 1.6548e+09, train_seconds = 1.7399e+04)
[2022-06-10 00:58:04,558][root][INFO] - Step 65292800 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 65292800, mean_episode_return = None, mean_episode_step = 1335.2, total_loss = -39.447, pg_loss = -57.182, baseline_loss = 22.993, entropy_loss = -5.258, learner_queue_size = 32, _tick = 16850, _time = 1.6548e+09, train_seconds = 1.7404e+04)
[2022-06-10 00:58:09,562][root][INFO] - Step 65310720 @ 3581.2 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 65310720, mean_episode_return = 42.1, mean_episode_step = 1245.0, total_loss = 123.28, pg_loss = 81.704, baseline_loss = 46.967, entropy_loss = -5.3901, learner_queue_size = 32, _tick = 16855, _time = 1.6548e+09, train_seconds = 1.7409e+04)
[2022-06-10 00:58:14,566][root][INFO] - Step 65331200 @ 4092.6 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 65331200, mean_episode_return = None, mean_episode_step = 1077.6, total_loss = 300.26, pg_loss = 218.02, baseline_loss = 87.668, entropy_loss = -5.4213, learner_queue_size = 32, _tick = 16859, _time = 1.6548e+09, train_seconds = 1.7414e+04)
[2022-06-10 00:58:19,570][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 00:58:19,781][root][INFO] - Step 65349120 @ 3581.3 SPS. Inference batcher size: 96. Learner queue size: 32. Other stats: (step = 65351680, mean_episode_return = 102.48, mean_episode_step = 1727.5, total_loss = 57.331, pg_loss = 23.963, baseline_loss = 38.765, entropy_loss = -5.3961, learner_queue_size = 32, _tick = 16866, _time = 1.6548e+09, train_seconds = 1.7419e+04)
[2022-06-10 00:58:24,786][root][INFO] - Step 65369600 @ 3926.3 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (step = 65369600, mean_episode_return = None, mean_episode_step = 1244.1, total_loss = -81.53, pg_loss = -98.75, baseline_loss = 22.347, entropy_loss = -5.1283, learner_queue_size = 32, _tick = 16872, _time = 1.6548e+09, train_seconds = 1.7425e+04)
[2022-06-10 00:58:29,790][root][INFO] - Step 65387520 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 65387520, mean_episode_return = 8.2099, mean_episode_step = 1106.7, total_loss = -114.9, pg_loss = -128.91, baseline_loss = 19.281, entropy_loss = -5.2705, learner_queue_size = 32, _tick = 16878, _time = 1.6548e+09, train_seconds = 1.743e+04)
[2022-06-10 00:58:34,794][root][INFO] - Step 65405440 @ 3581.2 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 65405440, mean_episode_return = 33.235, mean_episode_step = 922.47, total_loss = 42.627, pg_loss = -41.44, baseline_loss = 89.291, entropy_loss = -5.2238, learner_queue_size = 32, _tick = 16884, _time = 1.6548e+09, train_seconds = 1.7435e+04)
[2022-06-10 00:58:39,800][root][INFO] - Step 65425920 @ 4090.8 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 65425920, mean_episode_return = 32.323, mean_episode_step = 1317.5, total_loss = -238.09, pg_loss = -316.65, baseline_loss = 83.548, entropy_loss = -4.9876, learner_queue_size = 32, _tick = 16889, _time = 1.6548e+09, train_seconds = 1.744e+04)
[2022-06-10 00:58:44,806][root][INFO] - Step 65443840 @ 3579.9 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 65443840, mean_episode_return = 9.35, mean_episode_step = 1553.1, total_loss = 198.68, pg_loss = 133.13, baseline_loss = 70.966, entropy_loss = -5.4237, learner_queue_size = 32, _tick = 16896, _time = 1.6548e+09, train_seconds = 1.7445e+04)
[2022-06-10 00:58:49,810][root][INFO] - Step 65461760 @ 3581.2 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 65461760, mean_episode_return = 32.7, mean_episode_step = 892.17, total_loss = -82.882, pg_loss = -99.943, baseline_loss = 22.421, entropy_loss = -5.3596, learner_queue_size = 32, _tick = 16903, _time = 1.6548e+09, train_seconds = 1.745e+04)
[2022-06-10 00:58:54,814][root][INFO] - Step 65479680 @ 3581.0 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 65479680, mean_episode_return = 26.99, mean_episode_step = 932.24, total_loss = -21.997, pg_loss = -68.447, baseline_loss = 51.736, entropy_loss = -5.2862, learner_queue_size = 32, _tick = 16909, _time = 1.6548e+09, train_seconds = 1.7455e+04)
[2022-06-10 00:58:59,818][root][INFO] - Step 65500160 @ 4092.9 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 65500160, mean_episode_return = 35.25, mean_episode_step = 1312.8, total_loss = -190.46, pg_loss = -204.75, baseline_loss = 19.653, entropy_loss = -5.3617, learner_queue_size = 32, _tick = 16917, _time = 1.6548e+09, train_seconds = 1.746e+04)
[2022-06-10 00:59:04,822][root][INFO] - Step 65518080 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 65518080, mean_episode_return = None, mean_episode_step = 991.84, total_loss = 78.608, pg_loss = 42.591, baseline_loss = 41.343, entropy_loss = -5.3263, learner_queue_size = 32, _tick = 16922, _time = 1.6548e+09, train_seconds = 1.7465e+04)
[2022-06-10 00:59:09,826][root][INFO] - Step 65538560 @ 4092.8 SPS. Inference batcher size: 77. Learner queue size: 32. Other stats: (step = 65538560, mean_episode_return = 93.226, mean_episode_step = 856.21, total_loss = 193.58, pg_loss = 139.06, baseline_loss = 59.562, entropy_loss = -5.0425, learner_queue_size = 32, _tick = 16929, _time = 1.6548e+09, train_seconds = 1.747e+04)
[2022-06-10 00:59:14,830][root][INFO] - Step 65556480 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 65556480, mean_episode_return = 50.081, mean_episode_step = 993.83, total_loss = 204.36, pg_loss = 132.82, baseline_loss = 76.558, entropy_loss = -5.0224, learner_queue_size = 32, _tick = 16935, _time = 1.6548e+09, train_seconds = 1.7475e+04)
[2022-06-10 00:59:19,834][root][INFO] - Step 65574400 @ 3581.1 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 65574400, mean_episode_return = 76.824, mean_episode_step = 1331.1, total_loss = -157.19, pg_loss = -224.36, baseline_loss = 72.39, entropy_loss = -5.2271, learner_queue_size = 32, _tick = 16941, _time = 1.6548e+09, train_seconds = 1.748e+04)
[2022-06-10 00:59:24,840][root][INFO] - Step 65592320 @ 3579.7 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 65592320, mean_episode_return = None, mean_episode_step = 1635.0, total_loss = 99.988, pg_loss = 37.676, baseline_loss = 67.45, entropy_loss = -5.1381, learner_queue_size = 32, _tick = 16945, _time = 1.6548e+09, train_seconds = 1.7485e+04)
[2022-06-10 00:59:29,846][root][INFO] - Step 65612800 @ 4091.1 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 65612800, mean_episode_return = 84.27, mean_episode_step = 838.58, total_loss = -43.325, pg_loss = -92.005, baseline_loss = 53.889, entropy_loss = -5.2089, learner_queue_size = 32, _tick = 16952, _time = 1.6548e+09, train_seconds = 1.749e+04)
[2022-06-10 00:59:34,850][root][INFO] - Step 65630720 @ 3581.1 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 65630720, mean_episode_return = 127.99, mean_episode_step = 1368.6, total_loss = -100.52, pg_loss = -113.01, baseline_loss = 17.716, entropy_loss = -5.2225, learner_queue_size = 32, _tick = 16958, _time = 1.6548e+09, train_seconds = 1.7495e+04)
[2022-06-10 00:59:39,854][root][INFO] - Step 65651200 @ 4092.8 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (step = 65651200, mean_episode_return = 20.47, mean_episode_step = 1178.3, total_loss = -52.497, pg_loss = -78.905, baseline_loss = 31.696, entropy_loss = -5.2884, learner_queue_size = 32, _tick = 16966, _time = 1.6548e+09, train_seconds = 1.75e+04)
[2022-06-10 00:59:44,858][root][INFO] - Step 65669120 @ 3581.2 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 65669120, mean_episode_return = 31.4, mean_episode_step = 922.37, total_loss = 32.22, pg_loss = -28.401, baseline_loss = 65.604, entropy_loss = -4.9825, learner_queue_size = 32, _tick = 16971, _time = 1.6548e+09, train_seconds = 1.7505e+04)
[2022-06-10 00:59:49,862][root][INFO] - Step 65687040 @ 3581.1 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 65687040, mean_episode_return = 112.56, mean_episode_step = 958.69, total_loss = -129.28, pg_loss = -189.39, baseline_loss = 65.304, entropy_loss = -5.1914, learner_queue_size = 32, _tick = 16977, _time = 1.6548e+09, train_seconds = 1.751e+04)
[2022-06-10 00:59:54,867][root][INFO] - Step 65707520 @ 4092.4 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 65707520, mean_episode_return = None, mean_episode_step = 1000.5, total_loss = 205.14, pg_loss = 151.79, baseline_loss = 58.764, entropy_loss = -5.4157, learner_queue_size = 32, _tick = 16983, _time = 1.6548e+09, train_seconds = 1.7515e+04)
[2022-06-10 00:59:59,870][root][INFO] - Step 65725440 @ 3581.4 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 65725440, mean_episode_return = 25.465, mean_episode_step = 1036.5, total_loss = 184.28, pg_loss = 110.97, baseline_loss = 78.777, entropy_loss = -5.464, learner_queue_size = 32, _tick = 16987, _time = 1.6548e+09, train_seconds = 1.752e+04)
[2022-06-10 01:00:04,874][root][INFO] - Step 65743360 @ 3581.2 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 65743360, mean_episode_return = 71.409, mean_episode_step = 1143.5, total_loss = 36.051, pg_loss = 15.557, baseline_loss = 25.926, entropy_loss = -5.432, learner_queue_size = 32, _tick = 16994, _time = 1.6548e+09, train_seconds = 1.7525e+04)
[2022-06-10 01:00:09,878][root][INFO] - Step 65761280 @ 3581.0 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 65761280, mean_episode_return = 98.066, mean_episode_step = 1521.9, total_loss = 196.3, pg_loss = 136.71, baseline_loss = 64.975, entropy_loss = -5.3857, learner_queue_size = 32, _tick = 17000, _time = 1.6548e+09, train_seconds = 1.753e+04)
[2022-06-10 01:00:14,882][root][INFO] - Step 65781760 @ 4092.9 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 65781760, mean_episode_return = None, mean_episode_step = 1090.2, total_loss = 117.74, pg_loss = 84.002, baseline_loss = 39.065, entropy_loss = -5.3278, learner_queue_size = 32, _tick = 17004, _time = 1.6548e+09, train_seconds = 1.7535e+04)
[2022-06-10 01:00:19,886][root][INFO] - Step 65799680 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 65799680, mean_episode_return = 5.9299, mean_episode_step = 971.42, total_loss = -50.207, pg_loss = -93.351, baseline_loss = 48.429, entropy_loss = -5.2856, learner_queue_size = 32, _tick = 17011, _time = 1.6548e+09, train_seconds = 1.754e+04)
[2022-06-10 01:00:24,890][root][INFO] - Step 65820160 @ 4092.7 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 65820160, mean_episode_return = 32.45, mean_episode_step = 932.06, total_loss = -6.4771, pg_loss = -61.773, baseline_loss = 60.623, entropy_loss = -5.3272, learner_queue_size = 32, _tick = 17019, _time = 1.6548e+09, train_seconds = 1.7545e+04)
[2022-06-10 01:00:29,894][root][INFO] - Step 65838080 @ 3581.2 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 65838080, mean_episode_return = 32.091, mean_episode_step = 1213.5, total_loss = 98.919, pg_loss = 50.541, baseline_loss = 53.627, entropy_loss = -5.2486, learner_queue_size = 32, _tick = 17024, _time = 1.6548e+09, train_seconds = 1.755e+04)
[2022-06-10 01:00:34,898][root][INFO] - Step 65856000 @ 3581.0 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 65856000, mean_episode_return = 58.291, mean_episode_step = 1370.8, total_loss = 97.313, pg_loss = 43.14, baseline_loss = 59.517, entropy_loss = -5.345, learner_queue_size = 32, _tick = 17029, _time = 1.6548e+09, train_seconds = 1.7555e+04)
[2022-06-10 01:00:39,902][root][INFO] - Step 65876480 @ 4092.8 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 65876480, mean_episode_return = None, mean_episode_step = 888.16, total_loss = 308.32, pg_loss = 244.21, baseline_loss = 69.48, entropy_loss = -5.3618, learner_queue_size = 32, _tick = 17035, _time = 1.6548e+09, train_seconds = 1.756e+04)
[2022-06-10 01:00:44,906][root][INFO] - Step 65894400 @ 3581.3 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 65894400, mean_episode_return = 103.02, mean_episode_step = 927.28, total_loss = 97.831, pg_loss = 19.645, baseline_loss = 83.512, entropy_loss = -5.3259, learner_queue_size = 32, _tick = 17040, _time = 1.6548e+09, train_seconds = 1.7565e+04)
[2022-06-10 01:00:49,910][root][INFO] - Step 65912320 @ 3581.0 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 65912320, mean_episode_return = 34.72, mean_episode_step = 961.56, total_loss = 148.41, pg_loss = 103.88, baseline_loss = 49.929, entropy_loss = -5.3919, learner_queue_size = 32, _tick = 17046, _time = 1.6548e+09, train_seconds = 1.757e+04)
[2022-06-10 01:00:54,914][root][INFO] - Step 65932800 @ 4092.8 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 65932800, mean_episode_return = None, mean_episode_step = 1278.3, total_loss = 266.91, pg_loss = 224.59, baseline_loss = 47.817, entropy_loss = -5.4975, learner_queue_size = 32, _tick = 17051, _time = 1.6548e+09, train_seconds = 1.7575e+04)
[2022-06-10 01:00:59,918][root][INFO] - Step 65950720 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 65950720, mean_episode_return = 105.58, mean_episode_step = 1174.3, total_loss = 257.71, pg_loss = 186.28, baseline_loss = 76.859, entropy_loss = -5.4275, learner_queue_size = 32, _tick = 17057, _time = 1.6548e+09, train_seconds = 1.758e+04)
[2022-06-10 01:01:04,922][root][INFO] - Step 65968640 @ 3581.1 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 65968640, mean_episode_return = None, mean_episode_step = 1482.9, total_loss = 209.86, pg_loss = 140.09, baseline_loss = 75.174, entropy_loss = -5.4081, learner_queue_size = 32, _tick = 17061, _time = 1.6548e+09, train_seconds = 1.7585e+04)
[2022-06-10 01:01:09,926][root][INFO] - Step 65986560 @ 3581.2 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 65986560, mean_episode_return = 36.84, mean_episode_step = 1176.3, total_loss = 16.198, pg_loss = -34.925, baseline_loss = 56.549, entropy_loss = -5.4268, learner_queue_size = 32, _tick = 17067, _time = 1.6548e+09, train_seconds = 1.759e+04)
[2022-06-10 01:01:14,930][root][INFO] - Step 66007040 @ 4092.7 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 66007040, mean_episode_return = 22.38, mean_episode_step = 849.97, total_loss = 20.572, pg_loss = -13.241, baseline_loss = 39.232, entropy_loss = -5.4183, learner_queue_size = 32, _tick = 17074, _time = 1.6548e+09, train_seconds = 1.7595e+04)
[2022-06-10 01:01:19,934][root][INFO] - Step 66024960 @ 3581.1 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 66024960, mean_episode_return = 86.46, mean_episode_step = 1016.5, total_loss = -82.855, pg_loss = -139.84, baseline_loss = 62.373, entropy_loss = -5.3845, learner_queue_size = 32, _tick = 17077, _time = 1.6548e+09, train_seconds = 1.76e+04)
[2022-06-10 01:01:24,938][root][INFO] - Step 66045440 @ 4092.7 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 66045440, mean_episode_return = 152.37, mean_episode_step = 852.28, total_loss = -43.818, pg_loss = -87.771, baseline_loss = 49.319, entropy_loss = -5.3654, learner_queue_size = 32, _tick = 17085, _time = 1.6548e+09, train_seconds = 1.7605e+04)
[2022-06-10 01:01:29,942][root][INFO] - Step 66063360 @ 3581.0 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (step = 66063360, mean_episode_return = 39.4, mean_episode_step = 1084.0, total_loss = 64.063, pg_loss = -34.06, baseline_loss = 103.48, entropy_loss = -5.3558, learner_queue_size = 32, _tick = 17092, _time = 1.6548e+09, train_seconds = 1.761e+04)
[2022-06-10 01:01:34,946][root][INFO] - Step 66081280 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 66081280, mean_episode_return = 96.83, mean_episode_step = 951.15, total_loss = -56.933, pg_loss = -80.484, baseline_loss = 29.036, entropy_loss = -5.4855, learner_queue_size = 32, _tick = 17098, _time = 1.6548e+09, train_seconds = 1.7615e+04)
[2022-06-10 01:01:39,950][root][INFO] - Step 66099200 @ 3581.4 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 66099200, mean_episode_return = 98.566, mean_episode_step = 930.13, total_loss = 336.84, pg_loss = 192.08, baseline_loss = 150.13, entropy_loss = -5.3718, learner_queue_size = 32, _tick = 17104, _time = 1.6548e+09, train_seconds = 1.762e+04)
[2022-06-10 01:01:44,954][root][INFO] - Step 66119680 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 66119680, mean_episode_return = 128.48, mean_episode_step = 1360.2, total_loss = 141.41, pg_loss = 93.262, baseline_loss = 53.561, entropy_loss = -5.4131, learner_queue_size = 32, _tick = 17111, _time = 1.6548e+09, train_seconds = 1.7625e+04)
[2022-06-10 01:01:49,958][root][INFO] - Step 66140160 @ 4092.8 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 66140160, mean_episode_return = 105.24, mean_episode_step = 1706.7, total_loss = -7.3035, pg_loss = -52.831, baseline_loss = 50.89, entropy_loss = -5.3621, learner_queue_size = 32, _tick = 17118, _time = 1.6548e+09, train_seconds = 1.763e+04)
[2022-06-10 01:01:54,962][root][INFO] - Step 66158080 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 66158080, mean_episode_return = 57.8, mean_episode_step = 997.84, total_loss = 84.272, pg_loss = 27.122, baseline_loss = 62.547, entropy_loss = -5.3973, learner_queue_size = 32, _tick = 17121, _time = 1.6548e+09, train_seconds = 1.7635e+04)
[2022-06-10 01:01:59,966][root][INFO] - Step 66176000 @ 3581.0 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 66176000, mean_episode_return = 127.13, mean_episode_step = 938.36, total_loss = -116.99, pg_loss = -131.5, baseline_loss = 19.833, entropy_loss = -5.3228, learner_queue_size = 32, _tick = 17127, _time = 1.6548e+09, train_seconds = 1.764e+04)
[2022-06-10 01:02:04,970][root][INFO] - Step 66193920 @ 3581.2 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 66193920, mean_episode_return = None, mean_episode_step = 1068.6, total_loss = 28.803, pg_loss = -9.2811, baseline_loss = 43.411, entropy_loss = -5.3264, learner_queue_size = 32, _tick = 17131, _time = 1.6548e+09, train_seconds = 1.7645e+04)
[2022-06-10 01:02:09,974][root][INFO] - Step 66211840 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 66211840, mean_episode_return = None, mean_episode_step = 959.84, total_loss = 88.277, pg_loss = 33.902, baseline_loss = 59.656, entropy_loss = -5.2806, learner_queue_size = 32, _tick = 17137, _time = 1.6548e+09, train_seconds = 1.765e+04)
[2022-06-10 01:02:14,978][root][INFO] - Step 66232320 @ 4092.5 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (step = 66232320, mean_episode_return = None, mean_episode_step = 945.53, total_loss = 154.68, pg_loss = 87.615, baseline_loss = 72.411, entropy_loss = -5.3412, learner_queue_size = 32, _tick = 17144, _time = 1.6548e+09, train_seconds = 1.7655e+04)
[2022-06-10 01:02:19,982][root][INFO] - Step 66250240 @ 3581.4 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 66250240, mean_episode_return = 77.844, mean_episode_step = 1082.8, total_loss = 83.291, pg_loss = -17.159, baseline_loss = 105.76, entropy_loss = -5.307, learner_queue_size = 32, _tick = 17150, _time = 1.6548e+09, train_seconds = 1.766e+04)
[2022-06-10 01:02:24,986][root][INFO] - Step 66268160 @ 3581.1 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (step = 66268160, mean_episode_return = None, mean_episode_step = 1326.2, total_loss = -157.64, pg_loss = -171.13, baseline_loss = 18.751, entropy_loss = -5.2608, learner_queue_size = 32, _tick = 17152, _time = 1.6548e+09, train_seconds = 1.7665e+04)
[2022-06-10 01:02:29,990][root][INFO] - Step 66288640 @ 4092.8 SPS. Inference batcher size: 73. Learner queue size: 32. Other stats: (step = 66288640, mean_episode_return = 165.32, mean_episode_step = 1036.2, total_loss = 38.143, pg_loss = 1.1908, baseline_loss = 42.239, entropy_loss = -5.2864, learner_queue_size = 32, _tick = 17159, _time = 1.6548e+09, train_seconds = 1.767e+04)
[2022-06-10 01:02:34,994][root][INFO] - Step 66306560 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 66306560, mean_episode_return = None, mean_episode_step = 1149.0, total_loss = 25.666, pg_loss = -4.8328, baseline_loss = 35.584, entropy_loss = -5.0844, learner_queue_size = 32, _tick = 17164, _time = 1.6548e+09, train_seconds = 1.7675e+04)
[2022-06-10 01:02:39,998][root][INFO] - Step 66324480 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 66324480, mean_episode_return = 48.42, mean_episode_step = 1099.7, total_loss = -202.95, pg_loss = -275.82, baseline_loss = 78.247, entropy_loss = -5.3719, learner_queue_size = 32, _tick = 17170, _time = 1.6548e+09, train_seconds = 1.768e+04)
[2022-06-10 01:02:45,002][root][INFO] - Step 66342400 @ 3581.2 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 66342400, mean_episode_return = 35.015, mean_episode_step = 1235.3, total_loss = -286.94, pg_loss = -321.18, baseline_loss = 39.657, entropy_loss = -5.4151, learner_queue_size = 32, _tick = 17177, _time = 1.6548e+09, train_seconds = 1.7685e+04)
[2022-06-10 01:02:50,006][root][INFO] - Step 66362880 @ 4092.7 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 66362880, mean_episode_return = -156.44, mean_episode_step = 1116.5, total_loss = -81.643, pg_loss = -93.372, baseline_loss = 17.142, entropy_loss = -5.4125, learner_queue_size = 32, _tick = 17185, _time = 1.6548e+09, train_seconds = 1.769e+04)
[2022-06-10 01:02:55,010][root][INFO] - Step 66380800 @ 3581.1 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 66380800, mean_episode_return = 32.48, mean_episode_step = 1031.3, total_loss = 369.47, pg_loss = 298.75, baseline_loss = 76.019, entropy_loss = -5.301, learner_queue_size = 32, _tick = 17190, _time = 1.6548e+09, train_seconds = 1.7695e+04)
[2022-06-10 01:03:00,014][root][INFO] - Step 66398720 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 66398720, mean_episode_return = None, mean_episode_step = 763.44, total_loss = 133.14, pg_loss = 79.844, baseline_loss = 58.547, entropy_loss = -5.2475, learner_queue_size = 32, _tick = 17196, _time = 1.6548e+09, train_seconds = 1.77e+04)
[2022-06-10 01:03:05,018][root][INFO] - Step 66419200 @ 4092.8 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 66419200, mean_episode_return = 35.54, mean_episode_step = 1385.8, total_loss = -121.26, pg_loss = -140.4, baseline_loss = 24.361, entropy_loss = -5.2249, learner_queue_size = 32, _tick = 17203, _time = 1.6548e+09, train_seconds = 1.7705e+04)
[2022-06-10 01:03:10,022][root][INFO] - Step 66437120 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 66437120, mean_episode_return = 88.006, mean_episode_step = 1390.9, total_loss = -108.87, pg_loss = -121.57, baseline_loss = 17.923, entropy_loss = -5.2223, learner_queue_size = 32, _tick = 17207, _time = 1.6548e+09, train_seconds = 1.771e+04)
[2022-06-10 01:03:15,026][root][INFO] - Step 66455040 @ 3581.2 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 66455040, mean_episode_return = 59.51, mean_episode_step = 1050.6, total_loss = -306.45, pg_loss = -331.23, baseline_loss = 30.061, entropy_loss = -5.28, learner_queue_size = 32, _tick = 17214, _time = 1.6548e+09, train_seconds = 1.7715e+04)
[2022-06-10 01:03:20,030][root][INFO] - Step 66472960 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 66472960, mean_episode_return = 39.36, mean_episode_step = 1230.8, total_loss = -47.818, pg_loss = -108.61, baseline_loss = 66.096, entropy_loss = -5.3035, learner_queue_size = 32, _tick = 17221, _time = 1.6548e+09, train_seconds = 1.772e+04)
[2022-06-10 01:03:25,034][root][INFO] - Step 66493440 @ 4092.7 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 66493440, mean_episode_return = 120.52, mean_episode_step = 1057.0, total_loss = 254.61, pg_loss = 176.2, baseline_loss = 83.794, entropy_loss = -5.3798, learner_queue_size = 32, _tick = 17224, _time = 1.6548e+09, train_seconds = 1.7725e+04)
[2022-06-10 01:03:30,041][root][INFO] - Step 66511360 @ 3579.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 66511360, mean_episode_return = 66.759, mean_episode_step = 1131.5, total_loss = 157.78, pg_loss = 60.497, baseline_loss = 102.68, entropy_loss = -5.4002, learner_queue_size = 32, _tick = 17229, _time = 1.6548e+09, train_seconds = 1.773e+04)
[2022-06-10 01:03:35,046][root][INFO] - Step 66529280 @ 3580.3 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 66529280, mean_episode_return = 89.919, mean_episode_step = 926.92, total_loss = -52.562, pg_loss = -70.777, baseline_loss = 23.505, entropy_loss = -5.2905, learner_queue_size = 32, _tick = 17232, _time = 1.6548e+09, train_seconds = 1.7735e+04)
[2022-06-10 01:03:40,050][root][INFO] - Step 66549760 @ 4092.7 SPS. Inference batcher size: 80. Learner queue size: 32. Other stats: (step = 66549760, mean_episode_return = 95.435, mean_episode_step = 1158.8, total_loss = -50.577, pg_loss = -90.221, baseline_loss = 44.867, entropy_loss = -5.2232, learner_queue_size = 32, _tick = 17240, _time = 1.6548e+09, train_seconds = 1.774e+04)
[2022-06-10 01:03:45,054][root][INFO] - Step 66567680 @ 3581.1 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 66567680, mean_episode_return = 24.308, mean_episode_step = 1028.9, total_loss = 70.434, pg_loss = 13.192, baseline_loss = 62.457, entropy_loss = -5.215, learner_queue_size = 32, _tick = 17247, _time = 1.6548e+09, train_seconds = 1.7745e+04)
[2022-06-10 01:03:50,058][root][INFO] - Step 66585600 @ 3581.2 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 66585600, mean_episode_return = 42.121, mean_episode_step = 1277.2, total_loss = -164.55, pg_loss = -171.75, baseline_loss = 12.555, entropy_loss = -5.3619, learner_queue_size = 32, _tick = 17253, _time = 1.6548e+09, train_seconds = 1.775e+04)
[2022-06-10 01:03:55,062][root][INFO] - Step 66600960 @ 3069.5 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 66600960, mean_episode_return = 47.532, mean_episode_step = 1207.6, total_loss = -70.013, pg_loss = -87.432, baseline_loss = 22.786, entropy_loss = -5.3679, learner_queue_size = 32, _tick = 17258, _time = 1.6548e+09, train_seconds = 1.7755e+04)
[2022-06-10 01:04:00,066][root][INFO] - Step 66621440 @ 4092.7 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 66621440, mean_episode_return = None, mean_episode_step = 782.25, total_loss = 242.47, pg_loss = 190.39, baseline_loss = 57.463, entropy_loss = -5.3786, learner_queue_size = 32, _tick = 17264, _time = 1.6548e+09, train_seconds = 1.776e+04)
[2022-06-10 01:04:05,070][root][INFO] - Step 66639360 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 66639360, mean_episode_return = 47.31, mean_episode_step = 1253.8, total_loss = -58.745, pg_loss = -102.44, baseline_loss = 49.046, entropy_loss = -5.3529, learner_queue_size = 32, _tick = 17270, _time = 1.6548e+09, train_seconds = 1.7765e+04)
[2022-06-10 01:04:10,074][root][INFO] - Step 66657280 @ 3581.2 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 66657280, mean_episode_return = 18.915, mean_episode_step = 946.19, total_loss = -70.755, pg_loss = -95.093, baseline_loss = 29.719, entropy_loss = -5.38, learner_queue_size = 32, _tick = 17277, _time = 1.6548e+09, train_seconds = 1.777e+04)
[2022-06-10 01:04:15,079][root][INFO] - Step 66677760 @ 4091.9 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 66677760, mean_episode_return = None, mean_episode_step = 1031.3, total_loss = -68.381, pg_loss = -77.945, baseline_loss = 14.967, entropy_loss = -5.4033, learner_queue_size = 32, _tick = 17282, _time = 1.6548e+09, train_seconds = 1.7775e+04)
[2022-06-10 01:04:20,082][root][INFO] - Step 66695680 @ 3581.8 SPS. Inference batcher size: 73. Learner queue size: 32. Other stats: (step = 66695680, mean_episode_return = None, mean_episode_step = 897.34, total_loss = 371.59, pg_loss = 288.51, baseline_loss = 88.474, entropy_loss = -5.4027, learner_queue_size = 32, _tick = 17288, _time = 1.6548e+09, train_seconds = 1.778e+04)
[2022-06-10 01:04:25,086][root][INFO] - Step 66713600 @ 3581.2 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 66713600, mean_episode_return = 101.2, mean_episode_step = 1028.9, total_loss = 8.0083, pg_loss = -31.95, baseline_loss = 45.346, entropy_loss = -5.388, learner_queue_size = 32, _tick = 17294, _time = 1.6548e+09, train_seconds = 1.7785e+04)
[2022-06-10 01:04:30,090][root][INFO] - Step 66734080 @ 4092.7 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 66734080, mean_episode_return = 36.283, mean_episode_step = 957.7, total_loss = -17.401, pg_loss = -108.64, baseline_loss = 96.549, entropy_loss = -5.3136, learner_queue_size = 32, _tick = 17301, _time = 1.6548e+09, train_seconds = 1.779e+04)
[2022-06-10 01:04:35,095][root][INFO] - Step 66752000 @ 3580.8 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 66752000, mean_episode_return = 19.52, mean_episode_step = 719.94, total_loss = 205.81, pg_loss = 158.0, baseline_loss = 53.165, entropy_loss = -5.3499, learner_queue_size = 32, _tick = 17308, _time = 1.6548e+09, train_seconds = 1.7795e+04)
[2022-06-10 01:04:40,098][root][INFO] - Step 66769920 @ 3581.4 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 66769920, mean_episode_return = 44.321, mean_episode_step = 1149.2, total_loss = 159.94, pg_loss = 95.127, baseline_loss = 70.094, entropy_loss = -5.2824, learner_queue_size = 32, _tick = 17314, _time = 1.6548e+09, train_seconds = 1.78e+04)
[2022-06-10 01:04:45,102][root][INFO] - Step 66790400 @ 4092.8 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 66790400, mean_episode_return = 31.55, mean_episode_step = 970.69, total_loss = 126.9, pg_loss = 36.3, baseline_loss = 95.943, entropy_loss = -5.3404, learner_queue_size = 32, _tick = 17319, _time = 1.6548e+09, train_seconds = 1.7805e+04)
[2022-06-10 01:04:50,106][root][INFO] - Step 66808320 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 66808320, mean_episode_return = 49.979, mean_episode_step = 952.07, total_loss = -33.442, pg_loss = -81.073, baseline_loss = 52.989, entropy_loss = -5.3584, learner_queue_size = 32, _tick = 17324, _time = 1.6548e+09, train_seconds = 1.781e+04)
[2022-06-10 01:04:55,110][root][INFO] - Step 66828800 @ 4092.7 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 66828800, mean_episode_return = 99.179, mean_episode_step = 1260.0, total_loss = 487.65, pg_loss = 372.46, baseline_loss = 120.56, entropy_loss = -5.372, learner_queue_size = 32, _tick = 17331, _time = 1.6548e+09, train_seconds = 1.7815e+04)
[2022-06-10 01:05:00,114][root][INFO] - Step 66846720 @ 3581.1 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 66846720, mean_episode_return = None, mean_episode_step = 749.12, total_loss = 64.435, pg_loss = 34.759, baseline_loss = 34.953, entropy_loss = -5.2775, learner_queue_size = 32, _tick = 17335, _time = 1.6548e+09, train_seconds = 1.782e+04)
[2022-06-10 01:05:05,118][root][INFO] - Step 66864640 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 66864640, mean_episode_return = 55.03, mean_episode_step = 1012.3, total_loss = 99.034, pg_loss = 63.972, baseline_loss = 40.346, entropy_loss = -5.2845, learner_queue_size = 32, _tick = 17340, _time = 1.6548e+09, train_seconds = 1.7825e+04)
[2022-06-10 01:05:10,122][root][INFO] - Step 66885120 @ 4092.7 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 66885120, mean_episode_return = 53.86, mean_episode_step = 1255.0, total_loss = -174.88, pg_loss = -180.9, baseline_loss = 11.407, entropy_loss = -5.3946, learner_queue_size = 32, _tick = 17345, _time = 1.6548e+09, train_seconds = 1.783e+04)
[2022-06-10 01:05:15,126][root][INFO] - Step 66903040 @ 3581.1 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 66903040, mean_episode_return = 45.961, mean_episode_step = 1005.7, total_loss = -10.217, pg_loss = -40.692, baseline_loss = 35.866, entropy_loss = -5.3914, learner_queue_size = 32, _tick = 17349, _time = 1.6548e+09, train_seconds = 1.7835e+04)
[2022-06-10 01:05:20,130][root][INFO] - Step 66920960 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 66920960, mean_episode_return = 9.6397, mean_episode_step = 903.9, total_loss = 169.06, pg_loss = 85.367, baseline_loss = 88.995, entropy_loss = -5.2985, learner_queue_size = 32, _tick = 17355, _time = 1.6548e+09, train_seconds = 1.784e+04)
[2022-06-10 01:05:25,134][root][INFO] - Step 66941440 @ 4092.7 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 66941440, mean_episode_return = 42.427, mean_episode_step = 1137.1, total_loss = 45.011, pg_loss = -5.9328, baseline_loss = 56.257, entropy_loss = -5.3133, learner_queue_size = 32, _tick = 17362, _time = 1.6548e+09, train_seconds = 1.7845e+04)
[2022-06-10 01:05:30,138][root][INFO] - Step 66959360 @ 3581.1 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 66959360, mean_episode_return = 60.401, mean_episode_step = 1112.2, total_loss = -136.95, pg_loss = -150.55, baseline_loss = 18.884, entropy_loss = -5.2902, learner_queue_size = 32, _tick = 17366, _time = 1.6548e+09, train_seconds = 1.785e+04)
[2022-06-10 01:05:35,142][root][INFO] - Step 66977280 @ 3581.2 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 66977280, mean_episode_return = 166.53, mean_episode_step = 1043.4, total_loss = 341.92, pg_loss = 209.13, baseline_loss = 137.99, entropy_loss = -5.1985, learner_queue_size = 32, _tick = 17370, _time = 1.6548e+09, train_seconds = 1.7855e+04)
[2022-06-10 01:05:40,146][root][INFO] - Step 66997760 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 66997760, mean_episode_return = 69.8, mean_episode_step = 1085.6, total_loss = 47.83, pg_loss = 17.036, baseline_loss = 36.028, entropy_loss = -5.2333, learner_queue_size = 32, _tick = 17378, _time = 1.6548e+09, train_seconds = 1.786e+04)
[2022-06-10 01:05:45,150][root][INFO] - Step 67015680 @ 3581.0 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 67015680, mean_episode_return = 81.739, mean_episode_step = 1133.6, total_loss = -61.737, pg_loss = -82.075, baseline_loss = 25.57, entropy_loss = -5.2321, learner_queue_size = 32, _tick = 17383, _time = 1.6548e+09, train_seconds = 1.7865e+04)
[2022-06-10 01:05:50,154][root][INFO] - Step 67033600 @ 3581.3 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 67033600, mean_episode_return = 14.96, mean_episode_step = 1056.3, total_loss = 115.04, pg_loss = 60.133, baseline_loss = 60.272, entropy_loss = -5.3689, learner_queue_size = 32, _tick = 17389, _time = 1.6548e+09, train_seconds = 1.787e+04)
[2022-06-10 01:05:55,158][root][INFO] - Step 67051520 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 67051520, mean_episode_return = 97.1, mean_episode_step = 1259.0, total_loss = -107.82, pg_loss = -133.03, baseline_loss = 30.537, entropy_loss = -5.3329, learner_queue_size = 32, _tick = 17394, _time = 1.6548e+09, train_seconds = 1.7875e+04)
[2022-06-10 01:06:00,162][root][INFO] - Step 67072000 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 67072000, mean_episode_return = 56.222, mean_episode_step = 879.42, total_loss = 116.79, pg_loss = 75.023, baseline_loss = 47.118, entropy_loss = -5.3476, learner_queue_size = 32, _tick = 17400, _time = 1.6548e+09, train_seconds = 1.788e+04)
[2022-06-10 01:06:05,166][root][INFO] - Step 67089920 @ 3581.1 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 67089920, mean_episode_return = 41.711, mean_episode_step = 963.98, total_loss = 228.93, pg_loss = 175.71, baseline_loss = 58.472, entropy_loss = -5.2569, learner_queue_size = 32, _tick = 17406, _time = 1.6548e+09, train_seconds = 1.7885e+04)
[2022-06-10 01:06:10,170][root][INFO] - Step 67107840 @ 3581.1 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 67107840, mean_episode_return = None, mean_episode_step = 1025.2, total_loss = 501.65, pg_loss = 393.03, baseline_loss = 113.63, entropy_loss = -5.0005, learner_queue_size = 32, _tick = 17412, _time = 1.6548e+09, train_seconds = 1.789e+04)
[2022-06-10 01:06:15,174][root][INFO] - Step 67125760 @ 3581.2 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 67125760, mean_episode_return = 26.76, mean_episode_step = 985.92, total_loss = -69.718, pg_loss = -92.79, baseline_loss = 28.155, entropy_loss = -5.083, learner_queue_size = 32, _tick = 17418, _time = 1.6548e+09, train_seconds = 1.7895e+04)
[2022-06-10 01:06:20,178][root][INFO] - Step 67146240 @ 4092.7 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 67146240, mean_episode_return = 20.333, mean_episode_step = 1124.3, total_loss = -131.8, pg_loss = -148.55, baseline_loss = 22.045, entropy_loss = -5.2967, learner_queue_size = 32, _tick = 17426, _time = 1.6548e+09, train_seconds = 1.79e+04)
[2022-06-10 01:06:25,182][root][INFO] - Step 67164160 @ 3581.0 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 67164160, mean_episode_return = 29.975, mean_episode_step = 1209.3, total_loss = -77.805, pg_loss = -110.18, baseline_loss = 37.646, entropy_loss = -5.275, learner_queue_size = 32, _tick = 17430, _time = 1.6548e+09, train_seconds = 1.7905e+04)
[2022-06-10 01:06:30,186][root][INFO] - Step 67182080 @ 3581.2 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 67182080, mean_episode_return = None, mean_episode_step = 1205.3, total_loss = 85.015, pg_loss = 55.209, baseline_loss = 35.194, entropy_loss = -5.388, learner_queue_size = 32, _tick = 17436, _time = 1.6548e+09, train_seconds = 1.791e+04)
[2022-06-10 01:06:35,190][root][INFO] - Step 67202560 @ 4092.4 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 67202560, mean_episode_return = None, mean_episode_step = 1144.5, total_loss = 213.86, pg_loss = 128.99, baseline_loss = 90.221, entropy_loss = -5.3471, learner_queue_size = 32, _tick = 17441, _time = 1.6548e+09, train_seconds = 1.7915e+04)
[2022-06-10 01:06:40,194][root][INFO] - Step 67220480 @ 3581.5 SPS. Inference batcher size: 79. Learner queue size: 32. Other stats: (step = 67220480, mean_episode_return = 34.58, mean_episode_step = 1134.7, total_loss = -226.82, pg_loss = -252.71, baseline_loss = 31.132, entropy_loss = -5.2416, learner_queue_size = 32, _tick = 17448, _time = 1.6548e+09, train_seconds = 1.792e+04)
[2022-06-10 01:06:45,198][root][INFO] - Step 67238400 @ 3581.1 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 67238400, mean_episode_return = None, mean_episode_step = 1212.4, total_loss = 40.85, pg_loss = -16.616, baseline_loss = 62.759, entropy_loss = -5.2923, learner_queue_size = 32, _tick = 17452, _time = 1.6548e+09, train_seconds = 1.7925e+04)
[2022-06-10 01:06:50,202][root][INFO] - Step 67258880 @ 4092.7 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 67258880, mean_episode_return = 7.8298, mean_episode_step = 989.99, total_loss = -55.911, pg_loss = -83.854, baseline_loss = 33.18, entropy_loss = -5.2367, learner_queue_size = 32, _tick = 17456, _time = 1.6548e+09, train_seconds = 1.793e+04)
[2022-06-10 01:06:55,206][root][INFO] - Step 67276800 @ 3580.9 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 67276800, mean_episode_return = 59.466, mean_episode_step = 1150.9, total_loss = 154.62, pg_loss = 112.26, baseline_loss = 47.71, entropy_loss = -5.3471, learner_queue_size = 32, _tick = 17462, _time = 1.6548e+09, train_seconds = 1.7935e+04)
[2022-06-10 01:07:00,210][root][INFO] - Step 67294720 @ 3581.4 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 67294720, mean_episode_return = None, mean_episode_step = 970.38, total_loss = -134.45, pg_loss = -141.72, baseline_loss = 12.621, entropy_loss = -5.3526, learner_queue_size = 32, _tick = 17466, _time = 1.6548e+09, train_seconds = 1.794e+04)
[2022-06-10 01:07:05,214][root][INFO] - Step 67312640 @ 3581.0 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 67312640, mean_episode_return = 13.35, mean_episode_step = 1421.8, total_loss = 124.12, pg_loss = 96.143, baseline_loss = 33.327, entropy_loss = -5.3494, learner_queue_size = 32, _tick = 17472, _time = 1.6548e+09, train_seconds = 1.7945e+04)
[2022-06-10 01:07:10,218][root][INFO] - Step 67333120 @ 4092.8 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 67333120, mean_episode_return = 75.419, mean_episode_step = 1112.1, total_loss = -30.905, pg_loss = -59.702, baseline_loss = 34.073, entropy_loss = -5.2762, learner_queue_size = 32, _tick = 17477, _time = 1.6548e+09, train_seconds = 1.795e+04)
[2022-06-10 01:07:15,222][root][INFO] - Step 67351040 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 67351040, mean_episode_return = 61.881, mean_episode_step = 1381.5, total_loss = -37.325, pg_loss = -79.401, baseline_loss = 47.5, entropy_loss = -5.4239, learner_queue_size = 32, _tick = 17482, _time = 1.6548e+09, train_seconds = 1.7955e+04)
[2022-06-10 01:07:20,226][root][INFO] - Step 67368960 @ 3581.2 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 67368960, mean_episode_return = 20.557, mean_episode_step = 1110.8, total_loss = 75.068, pg_loss = 10.378, baseline_loss = 70.037, entropy_loss = -5.3466, learner_queue_size = 32, _tick = 17487, _time = 1.6548e+09, train_seconds = 1.796e+04)
[2022-06-10 01:07:25,230][root][INFO] - Step 67389440 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 67389440, mean_episode_return = 74.53, mean_episode_step = 1019.5, total_loss = 68.454, pg_loss = -2.2419, baseline_loss = 75.991, entropy_loss = -5.295, learner_queue_size = 32, _tick = 17492, _time = 1.6548e+09, train_seconds = 1.7965e+04)
[2022-06-10 01:07:30,234][root][INFO] - Step 67407360 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 67407360, mean_episode_return = 53.412, mean_episode_step = 1151.9, total_loss = 25.392, pg_loss = -4.9511, baseline_loss = 35.655, entropy_loss = -5.3114, learner_queue_size = 32, _tick = 17498, _time = 1.6548e+09, train_seconds = 1.797e+04)
[2022-06-10 01:07:35,238][root][INFO] - Step 67425280 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 67425280, mean_episode_return = 42.771, mean_episode_step = 909.74, total_loss = 13.935, pg_loss = -28.745, baseline_loss = 48.007, entropy_loss = -5.3265, learner_queue_size = 32, _tick = 17504, _time = 1.6548e+09, train_seconds = 1.7975e+04)
[2022-06-10 01:07:40,242][root][INFO] - Step 67445760 @ 4092.7 SPS. Inference batcher size: 73. Learner queue size: 32. Other stats: (step = 67445760, mean_episode_return = 13.1, mean_episode_step = 743.83, total_loss = 182.69, pg_loss = 124.22, baseline_loss = 63.815, entropy_loss = -5.3457, learner_queue_size = 32, _tick = 17512, _time = 1.6548e+09, train_seconds = 1.798e+04)
[2022-06-10 01:07:45,246][root][INFO] - Step 67463680 @ 3581.1 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (step = 67463680, mean_episode_return = 88.349, mean_episode_step = 1087.4, total_loss = 106.28, pg_loss = 47.811, baseline_loss = 63.837, entropy_loss = -5.3665, learner_queue_size = 32, _tick = 17518, _time = 1.6548e+09, train_seconds = 1.7985e+04)
[2022-06-10 01:07:50,250][root][INFO] - Step 67484160 @ 4092.5 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 67484160, mean_episode_return = 142.85, mean_episode_step = 1189.5, total_loss = 203.32, pg_loss = 110.0, baseline_loss = 98.664, entropy_loss = -5.3456, learner_queue_size = 32, _tick = 17524, _time = 1.6548e+09, train_seconds = 1.799e+04)
[2022-06-10 01:07:55,254][root][INFO] - Step 67502080 @ 3581.2 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 67502080, mean_episode_return = None, mean_episode_step = 943.88, total_loss = 136.8, pg_loss = 80.224, baseline_loss = 61.944, entropy_loss = -5.3696, learner_queue_size = 32, _tick = 17529, _time = 1.6548e+09, train_seconds = 1.7995e+04)
[2022-06-10 01:08:00,258][root][INFO] - Step 67522560 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 67522560, mean_episode_return = 50.735, mean_episode_step = 861.21, total_loss = 248.38, pg_loss = 183.26, baseline_loss = 70.447, entropy_loss = -5.3306, learner_queue_size = 32, _tick = 17536, _time = 1.6548e+09, train_seconds = 1.8e+04)
[2022-06-10 01:08:05,262][root][INFO] - Step 67540480 @ 3581.0 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 67540480, mean_episode_return = 45.291, mean_episode_step = 1116.2, total_loss = -112.95, pg_loss = -138.03, baseline_loss = 30.348, entropy_loss = -5.2763, learner_queue_size = 32, _tick = 17541, _time = 1.6548e+09, train_seconds = 1.8005e+04)
[2022-06-10 01:08:10,266][root][INFO] - Step 67560960 @ 4092.9 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 67560960, mean_episode_return = 44.288, mean_episode_step = 902.82, total_loss = 1.2839, pg_loss = -49.816, baseline_loss = 56.443, entropy_loss = -5.3429, learner_queue_size = 32, _tick = 17545, _time = 1.6548e+09, train_seconds = 1.801e+04)
[2022-06-10 01:08:15,270][root][INFO] - Step 67578880 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 67578880, mean_episode_return = 32.569, mean_episode_step = 797.49, total_loss = 366.29, pg_loss = 262.66, baseline_loss = 108.99, entropy_loss = -5.3602, learner_queue_size = 32, _tick = 17550, _time = 1.6548e+09, train_seconds = 1.8015e+04)
[2022-06-10 01:08:20,274][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 01:08:20,412][root][INFO] - Step 67596800 @ 3581.2 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 67596800, mean_episode_return = 130.18, mean_episode_step = 983.99, total_loss = 95.432, pg_loss = 63.592, baseline_loss = 37.154, entropy_loss = -5.3142, learner_queue_size = 32, _tick = 17557, _time = 1.6548e+09, train_seconds = 1.802e+04)
[2022-06-10 01:08:25,414][root][INFO] - Step 67614720 @ 3486.3 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 67614720, mean_episode_return = 30.96, mean_episode_step = 922.37, total_loss = 123.92, pg_loss = 84.972, baseline_loss = 44.244, entropy_loss = -5.2985, learner_queue_size = 32, _tick = 17562, _time = 1.6548e+09, train_seconds = 1.8025e+04)
[2022-06-10 01:08:30,418][root][INFO] - Step 67635200 @ 4092.8 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 67635200, mean_episode_return = 26.915, mean_episode_step = 862.84, total_loss = -64.937, pg_loss = -89.042, baseline_loss = 29.367, entropy_loss = -5.2617, learner_queue_size = 32, _tick = 17569, _time = 1.6548e+09, train_seconds = 1.803e+04)
[2022-06-10 01:08:35,422][root][INFO] - Step 67653120 @ 3581.1 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 67653120, mean_episode_return = 43.835, mean_episode_step = 848.43, total_loss = 90.525, pg_loss = 52.51, baseline_loss = 43.168, entropy_loss = -5.1528, learner_queue_size = 32, _tick = 17574, _time = 1.6548e+09, train_seconds = 1.8035e+04)
[2022-06-10 01:08:40,426][root][INFO] - Step 67671040 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 67671040, mean_episode_return = 86.4, mean_episode_step = 917.84, total_loss = 54.916, pg_loss = 17.15, baseline_loss = 42.952, entropy_loss = -5.1858, learner_queue_size = 32, _tick = 17580, _time = 1.6548e+09, train_seconds = 1.804e+04)
[2022-06-10 01:08:45,430][root][INFO] - Step 67691520 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 67691520, mean_episode_return = None, mean_episode_step = 869.47, total_loss = 176.92, pg_loss = 118.48, baseline_loss = 63.498, entropy_loss = -5.0556, learner_queue_size = 32, _tick = 17584, _time = 1.6548e+09, train_seconds = 1.8045e+04)
[2022-06-10 01:08:50,434][root][INFO] - Step 67709440 @ 3581.0 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 67709440, mean_episode_return = 88.824, mean_episode_step = 968.48, total_loss = 219.22, pg_loss = 130.44, baseline_loss = 93.809, entropy_loss = -5.0242, learner_queue_size = 32, _tick = 17588, _time = 1.6548e+09, train_seconds = 1.805e+04)
[2022-06-10 01:08:55,438][root][INFO] - Step 67727360 @ 3581.3 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 67727360, mean_episode_return = 34.107, mean_episode_step = 1041.1, total_loss = 250.87, pg_loss = 157.42, baseline_loss = 98.316, entropy_loss = -4.8618, learner_queue_size = 32, _tick = 17592, _time = 1.6548e+09, train_seconds = 1.8055e+04)
[2022-06-10 01:09:00,442][root][INFO] - Step 67747840 @ 4092.7 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 67747840, mean_episode_return = 43.093, mean_episode_step = 867.79, total_loss = 428.13, pg_loss = 229.21, baseline_loss = 203.88, entropy_loss = -4.9509, learner_queue_size = 32, _tick = 17599, _time = 1.6548e+09, train_seconds = 1.806e+04)
[2022-06-10 01:09:05,446][root][INFO] - Step 67765760 @ 3581.1 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (step = 67765760, mean_episode_return = 41.65, mean_episode_step = 1066.4, total_loss = -42.165, pg_loss = -104.69, baseline_loss = 67.609, entropy_loss = -5.0894, learner_queue_size = 32, _tick = 17606, _time = 1.6548e+09, train_seconds = 1.8065e+04)
[2022-06-10 01:09:10,450][root][INFO] - Step 67783680 @ 3581.1 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 67783680, mean_episode_return = 29.03, mean_episode_step = 1129.9, total_loss = 11.498, pg_loss = -30.185, baseline_loss = 46.856, entropy_loss = -5.1728, learner_queue_size = 32, _tick = 17610, _time = 1.6548e+09, train_seconds = 1.807e+04)
[2022-06-10 01:09:15,454][root][INFO] - Step 67804160 @ 4092.7 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 67804160, mean_episode_return = None, mean_episode_step = 1041.7, total_loss = -170.18, pg_loss = -193.61, baseline_loss = 28.413, entropy_loss = -4.9757, learner_queue_size = 32, _tick = 17615, _time = 1.6548e+09, train_seconds = 1.8075e+04)
[2022-06-10 01:09:20,458][root][INFO] - Step 67822080 @ 3581.2 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 67822080, mean_episode_return = 48.536, mean_episode_step = 1148.2, total_loss = 252.73, pg_loss = 129.05, baseline_loss = 128.86, entropy_loss = -5.1813, learner_queue_size = 32, _tick = 17621, _time = 1.6548e+09, train_seconds = 1.808e+04)
[2022-06-10 01:09:25,462][root][INFO] - Step 67840000 @ 3581.0 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 67840000, mean_episode_return = 34.226, mean_episode_step = 1080.9, total_loss = 212.12, pg_loss = 45.101, baseline_loss = 172.3, entropy_loss = -5.2741, learner_queue_size = 32, _tick = 17627, _time = 1.6548e+09, train_seconds = 1.8085e+04)
[2022-06-10 01:09:30,466][root][INFO] - Step 67857920 @ 3581.2 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 67857920, mean_episode_return = 61.74, mean_episode_step = 1201.0, total_loss = 293.28, pg_loss = 198.54, baseline_loss = 99.999, entropy_loss = -5.2588, learner_queue_size = 32, _tick = 17634, _time = 1.6548e+09, train_seconds = 1.809e+04)
[2022-06-10 01:09:35,470][root][INFO] - Step 67875840 @ 3581.2 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 67875840, mean_episode_return = 49.721, mean_episode_step = 980.53, total_loss = 50.271, pg_loss = 18.252, baseline_loss = 37.009, entropy_loss = -4.9898, learner_queue_size = 32, _tick = 17640, _time = 1.6548e+09, train_seconds = 1.8095e+04)
[2022-06-10 01:09:40,474][root][INFO] - Step 67896320 @ 4092.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 67896320, mean_episode_return = 56.35, mean_episode_step = 1098.2, total_loss = -141.13, pg_loss = -191.08, baseline_loss = 55.129, entropy_loss = -5.1806, learner_queue_size = 32, _tick = 17646, _time = 1.6548e+09, train_seconds = 1.81e+04)
[2022-06-10 01:09:45,478][root][INFO] - Step 67916800 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 67916800, mean_episode_return = 44.525, mean_episode_step = 1051.6, total_loss = 354.79, pg_loss = 243.97, baseline_loss = 116.02, entropy_loss = -5.2041, learner_queue_size = 32, _tick = 17652, _time = 1.6548e+09, train_seconds = 1.8105e+04)
[2022-06-10 01:09:50,482][root][INFO] - Step 67934720 @ 3581.2 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 67934720, mean_episode_return = None, mean_episode_step = 1218.7, total_loss = -13.326, pg_loss = -31.748, baseline_loss = 23.573, entropy_loss = -5.1508, learner_queue_size = 32, _tick = 17656, _time = 1.6548e+09, train_seconds = 1.811e+04)
[2022-06-10 01:09:55,486][root][INFO] - Step 67955200 @ 4092.7 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 67955200, mean_episode_return = 37.98, mean_episode_step = 1192.4, total_loss = -1.1992, pg_loss = -47.795, baseline_loss = 51.862, entropy_loss = -5.266, learner_queue_size = 32, _tick = 17662, _time = 1.6548e+09, train_seconds = 1.8115e+04)
[2022-06-10 01:10:00,490][root][INFO] - Step 67973120 @ 3581.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 67973120, mean_episode_return = 112.7, mean_episode_step = 1036.0, total_loss = 269.55, pg_loss = 182.29, baseline_loss = 92.363, entropy_loss = -5.1021, learner_queue_size = 32, _tick = 17669, _time = 1.6548e+09, train_seconds = 1.812e+04)
[2022-06-10 01:10:05,494][root][INFO] - Step 67993600 @ 4092.8 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 67993600, mean_episode_return = 15.48, mean_episode_step = 971.18, total_loss = 125.11, pg_loss = 35.409, baseline_loss = 94.806, entropy_loss = -5.1052, learner_queue_size = 32, _tick = 17677, _time = 1.6548e+09, train_seconds = 1.8125e+04)
[2022-06-10 01:10:10,500][root][INFO] - Step 68011520 @ 3579.8 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 68011520, mean_episode_return = None, mean_episode_step = 1019.2, total_loss = -50.732, pg_loss = -73.876, baseline_loss = 28.478, entropy_loss = -5.3339, learner_queue_size = 32, _tick = 17681, _time = 1.6548e+09, train_seconds = 1.813e+04)
[2022-06-10 01:10:15,502][root][INFO] - Step 68032000 @ 4094.2 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 68032000, mean_episode_return = None, mean_episode_step = 1052.2, total_loss = 323.38, pg_loss = 254.58, baseline_loss = 74.097, entropy_loss = -5.2935, learner_queue_size = 32, _tick = 17686, _time = 1.6548e+09, train_seconds = 1.8135e+04)
[2022-06-10 01:10:20,506][root][INFO] - Step 68052480 @ 4092.8 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 68052480, mean_episode_return = None, mean_episode_step = 938.94, total_loss = 178.37, pg_loss = 111.39, baseline_loss = 72.294, entropy_loss = -5.3125, learner_queue_size = 32, _tick = 17692, _time = 1.6548e+09, train_seconds = 1.814e+04)
[2022-06-10 01:10:25,510][root][INFO] - Step 68070400 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 68070400, mean_episode_return = -6.3301, mean_episode_step = 1200.5, total_loss = 66.259, pg_loss = 33.138, baseline_loss = 38.462, entropy_loss = -5.3416, learner_queue_size = 32, _tick = 17699, _time = 1.6548e+09, train_seconds = 1.8145e+04)
[2022-06-10 01:10:30,514][root][INFO] - Step 68090880 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 68090880, mean_episode_return = None, mean_episode_step = 1087.4, total_loss = -297.48, pg_loss = -309.0, baseline_loss = 16.878, entropy_loss = -5.3585, learner_queue_size = 32, _tick = 17706, _time = 1.6548e+09, train_seconds = 1.815e+04)
[2022-06-10 01:10:35,518][root][INFO] - Step 68111360 @ 4092.8 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 68111360, mean_episode_return = 91.312, mean_episode_step = 947.16, total_loss = -97.014, pg_loss = -151.2, baseline_loss = 59.487, entropy_loss = -5.2973, learner_queue_size = 32, _tick = 17711, _time = 1.6548e+09, train_seconds = 1.8155e+04)
[2022-06-10 01:10:40,522][root][INFO] - Step 68129280 @ 3581.1 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 68129280, mean_episode_return = 15.34, mean_episode_step = 1059.6, total_loss = -78.517, pg_loss = -110.95, baseline_loss = 37.712, entropy_loss = -5.2768, learner_queue_size = 32, _tick = 17717, _time = 1.6548e+09, train_seconds = 1.816e+04)
[2022-06-10 01:10:45,526][root][INFO] - Step 68149760 @ 4092.7 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 68149760, mean_episode_return = 61.056, mean_episode_step = 1026.7, total_loss = 230.71, pg_loss = 153.83, baseline_loss = 82.164, entropy_loss = -5.2829, learner_queue_size = 32, _tick = 17725, _time = 1.6548e+09, train_seconds = 1.8165e+04)
[2022-06-10 01:10:50,530][root][INFO] - Step 68167680 @ 3581.2 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 68167680, mean_episode_return = 50.803, mean_episode_step = 1067.3, total_loss = -131.61, pg_loss = -168.99, baseline_loss = 42.548, entropy_loss = -5.1644, learner_queue_size = 32, _tick = 17730, _time = 1.6548e+09, train_seconds = 1.817e+04)
[2022-06-10 01:10:55,534][root][INFO] - Step 68188160 @ 4092.6 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 68188160, mean_episode_return = 4.0597, mean_episode_step = 818.6, total_loss = 72.445, pg_loss = 60.34, baseline_loss = 17.124, entropy_loss = -5.0179, learner_queue_size = 32, _tick = 17737, _time = 1.6548e+09, train_seconds = 1.8175e+04)
[2022-06-10 01:11:00,538][root][INFO] - Step 68206080 @ 3581.2 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 68206080, mean_episode_return = None, mean_episode_step = 734.28, total_loss = 392.97, pg_loss = 283.8, baseline_loss = 114.29, entropy_loss = -5.1083, learner_queue_size = 32, _tick = 17743, _time = 1.6548e+09, train_seconds = 1.818e+04)
[2022-06-10 01:11:05,543][root][INFO] - Step 68226560 @ 4092.1 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 68226560, mean_episode_return = None, mean_episode_step = 931.16, total_loss = 278.12, pg_loss = 217.45, baseline_loss = 65.674, entropy_loss = -5.0022, learner_queue_size = 32, _tick = 17750, _time = 1.6548e+09, train_seconds = 1.8185e+04)
[2022-06-10 01:11:10,546][root][INFO] - Step 68244480 @ 3581.7 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 68244480, mean_episode_return = None, mean_episode_step = 764.59, total_loss = -66.917, pg_loss = -73.762, baseline_loss = 11.805, entropy_loss = -4.9599, learner_queue_size = 32, _tick = 17756, _time = 1.6548e+09, train_seconds = 1.819e+04)
[2022-06-10 01:11:15,550][root][INFO] - Step 68264960 @ 4092.6 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 68264960, mean_episode_return = 81.414, mean_episode_step = 1103.0, total_loss = -106.43, pg_loss = -120.48, baseline_loss = 19.197, entropy_loss = -5.1566, learner_queue_size = 32, _tick = 17761, _time = 1.6548e+09, train_seconds = 1.8195e+04)
[2022-06-10 01:11:20,554][root][INFO] - Step 68285440 @ 4092.8 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 68285440, mean_episode_return = 55.521, mean_episode_step = 921.3, total_loss = 64.576, pg_loss = 28.624, baseline_loss = 41.104, entropy_loss = -5.1516, learner_queue_size = 32, _tick = 17766, _time = 1.6548e+09, train_seconds = 1.82e+04)
[2022-06-10 01:11:25,558][root][INFO] - Step 68303360 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 68303360, mean_episode_return = None, mean_episode_step = 974.16, total_loss = 298.78, pg_loss = 225.94, baseline_loss = 78.041, entropy_loss = -5.2002, learner_queue_size = 32, _tick = 17770, _time = 1.6548e+09, train_seconds = 1.8205e+04)
[2022-06-10 01:11:30,562][root][INFO] - Step 68323840 @ 4092.8 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 68323840, mean_episode_return = 0.1, mean_episode_step = 1154.2, total_loss = 171.34, pg_loss = 83.167, baseline_loss = 93.16, entropy_loss = -4.9885, learner_queue_size = 32, _tick = 17778, _time = 1.6548e+09, train_seconds = 1.821e+04)
[2022-06-10 01:11:35,568][root][INFO] - Step 68341760 @ 3579.5 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 68341760, mean_episode_return = 40.015, mean_episode_step = 1024.9, total_loss = -166.73, pg_loss = -198.18, baseline_loss = 36.358, entropy_loss = -4.9125, learner_queue_size = 32, _tick = 17783, _time = 1.6548e+09, train_seconds = 1.8215e+04)
[2022-06-10 01:11:40,574][root][INFO] - Step 68362240 @ 4091.2 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 68362240, mean_episode_return = 101.72, mean_episode_step = 1006.5, total_loss = 37.224, pg_loss = 6.729, baseline_loss = 35.616, entropy_loss = -5.121, learner_queue_size = 32, _tick = 17789, _time = 1.6548e+09, train_seconds = 1.822e+04)
[2022-06-10 01:11:45,578][root][INFO] - Step 68382720 @ 4092.7 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 68382720, mean_episode_return = 93.39, mean_episode_step = 813.97, total_loss = -7.4727, pg_loss = -47.862, baseline_loss = 45.428, entropy_loss = -5.0394, learner_queue_size = 32, _tick = 17796, _time = 1.6548e+09, train_seconds = 1.8225e+04)
[2022-06-10 01:11:50,582][root][INFO] - Step 68400640 @ 3581.2 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 68400640, mean_episode_return = 26.48, mean_episode_step = 1175.4, total_loss = -53.294, pg_loss = -93.244, baseline_loss = 44.985, entropy_loss = -5.0345, learner_queue_size = 32, _tick = 17801, _time = 1.6548e+09, train_seconds = 1.823e+04)
[2022-06-10 01:11:55,586][root][INFO] - Step 68421120 @ 4092.7 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 68421120, mean_episode_return = None, mean_episode_step = 1088.0, total_loss = 287.52, pg_loss = 178.61, baseline_loss = 114.07, entropy_loss = -5.1597, learner_queue_size = 32, _tick = 17806, _time = 1.6548e+09, train_seconds = 1.8235e+04)
[2022-06-10 01:12:00,590][root][INFO] - Step 68439040 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 68439040, mean_episode_return = None, mean_episode_step = 1016.3, total_loss = 186.08, pg_loss = 128.63, baseline_loss = 62.497, entropy_loss = -5.0376, learner_queue_size = 32, _tick = 17809, _time = 1.6548e+09, train_seconds = 1.824e+04)
[2022-06-10 01:12:05,594][root][INFO] - Step 68459520 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 68459520, mean_episode_return = 40.58, mean_episode_step = 1037.7, total_loss = -200.32, pg_loss = -306.19, baseline_loss = 111.09, entropy_loss = -5.2137, learner_queue_size = 32, _tick = 17817, _time = 1.6548e+09, train_seconds = 1.8245e+04)
[2022-06-10 01:12:10,598][root][INFO] - Step 68477440 @ 3581.1 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (step = 68477440, mean_episode_return = 57.059, mean_episode_step = 1132.5, total_loss = 136.6, pg_loss = 91.228, baseline_loss = 50.62, entropy_loss = -5.2524, learner_queue_size = 32, _tick = 17822, _time = 1.6548e+09, train_seconds = 1.825e+04)
[2022-06-10 01:12:15,602][root][INFO] - Step 68497920 @ 4092.8 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 68497920, mean_episode_return = 69.055, mean_episode_step = 1320.1, total_loss = -109.26, pg_loss = -129.77, baseline_loss = 25.848, entropy_loss = -5.3345, learner_queue_size = 32, _tick = 17829, _time = 1.6548e+09, train_seconds = 1.8255e+04)
[2022-06-10 01:12:20,606][root][INFO] - Step 68518400 @ 4092.7 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 68518400, mean_episode_return = 5.2997, mean_episode_step = 1258.9, total_loss = 220.46, pg_loss = 135.63, baseline_loss = 90.098, entropy_loss = -5.2663, learner_queue_size = 32, _tick = 17836, _time = 1.6548e+09, train_seconds = 1.826e+04)
[2022-06-10 01:12:25,612][root][INFO] - Step 68536320 @ 3579.5 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 68536320, mean_episode_return = 61.506, mean_episode_step = 1107.5, total_loss = -193.32, pg_loss = -213.04, baseline_loss = 25.023, entropy_loss = -5.2966, learner_queue_size = 32, _tick = 17842, _time = 1.6548e+09, train_seconds = 1.8265e+04)
[2022-06-10 01:12:30,618][root][INFO] - Step 68556800 @ 4091.3 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 68556800, mean_episode_return = None, mean_episode_step = 1264.8, total_loss = 182.73, pg_loss = 125.46, baseline_loss = 62.558, entropy_loss = -5.2915, learner_queue_size = 32, _tick = 17847, _time = 1.6548e+09, train_seconds = 1.827e+04)
[2022-06-10 01:12:35,622][root][INFO] - Step 68577280 @ 4092.7 SPS. Inference batcher size: 78. Learner queue size: 32. Other stats: (step = 68577280, mean_episode_return = 40.732, mean_episode_step = 1182.8, total_loss = 37.743, pg_loss = -2.6093, baseline_loss = 45.576, entropy_loss = -5.2229, learner_queue_size = 32, _tick = 17853, _time = 1.6548e+09, train_seconds = 1.8275e+04)
[2022-06-10 01:12:40,626][root][INFO] - Step 68595200 @ 3581.2 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 68595200, mean_episode_return = 11.451, mean_episode_step = 1133.3, total_loss = 87.293, pg_loss = 50.636, baseline_loss = 41.785, entropy_loss = -5.1277, learner_queue_size = 32, _tick = 17857, _time = 1.6548e+09, train_seconds = 1.828e+04)
[2022-06-10 01:12:45,630][root][INFO] - Step 68615680 @ 4092.7 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (step = 68615680, mean_episode_return = 97.227, mean_episode_step = 835.88, total_loss = 226.91, pg_loss = 125.5, baseline_loss = 106.58, entropy_loss = -5.179, learner_queue_size = 32, _tick = 17862, _time = 1.6548e+09, train_seconds = 1.8285e+04)
[2022-06-10 01:12:50,634][root][INFO] - Step 68636160 @ 4092.7 SPS. Inference batcher size: 79. Learner queue size: 32. Other stats: (step = 68636160, mean_episode_return = 77.745, mean_episode_step = 906.0, total_loss = -135.79, pg_loss = -176.61, baseline_loss = 45.98, entropy_loss = -5.1641, learner_queue_size = 32, _tick = 17869, _time = 1.6548e+09, train_seconds = 1.829e+04)
[2022-06-10 01:12:55,638][root][INFO] - Step 68654080 @ 3580.9 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 68654080, mean_episode_return = 10.43, mean_episode_step = 984.33, total_loss = 178.77, pg_loss = 117.74, baseline_loss = 66.152, entropy_loss = -5.1203, learner_queue_size = 32, _tick = 17875, _time = 1.6548e+09, train_seconds = 1.8295e+04)
[2022-06-10 01:13:00,642][root][INFO] - Step 68674560 @ 4092.9 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 68674560, mean_episode_return = 56.797, mean_episode_step = 892.62, total_loss = 47.569, pg_loss = -20.133, baseline_loss = 72.874, entropy_loss = -5.1729, learner_queue_size = 32, _tick = 17883, _time = 1.6548e+09, train_seconds = 1.83e+04)
[2022-06-10 01:13:05,646][root][INFO] - Step 68695040 @ 4092.8 SPS. Inference batcher size: 80. Learner queue size: 32. Other stats: (step = 68695040, mean_episode_return = None, mean_episode_step = 885.34, total_loss = 170.88, pg_loss = 125.54, baseline_loss = 50.629, entropy_loss = -5.287, learner_queue_size = 32, _tick = 17888, _time = 1.6548e+09, train_seconds = 1.8306e+04)
[2022-06-10 01:13:10,650][root][INFO] - Step 68715520 @ 4092.6 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 68715520, mean_episode_return = 12.02, mean_episode_step = 865.23, total_loss = -210.79, pg_loss = -225.34, baseline_loss = 19.613, entropy_loss = -5.0644, learner_queue_size = 32, _tick = 17895, _time = 1.6548e+09, train_seconds = 1.831e+04)
[2022-06-10 01:13:15,654][root][INFO] - Step 68733440 @ 3581.0 SPS. Inference batcher size: 77. Learner queue size: 32. Other stats: (step = 68733440, mean_episode_return = 43.82, mean_episode_step = 951.67, total_loss = -169.11, pg_loss = -218.01, baseline_loss = 54.025, entropy_loss = -5.1296, learner_queue_size = 32, _tick = 17901, _time = 1.6548e+09, train_seconds = 1.8316e+04)
[2022-06-10 01:13:20,658][root][INFO] - Step 68753920 @ 4093.0 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 68753920, mean_episode_return = -12.01, mean_episode_step = 1197.9, total_loss = 166.04, pg_loss = 112.75, baseline_loss = 58.491, entropy_loss = -5.2055, learner_queue_size = 32, _tick = 17908, _time = 1.6548e+09, train_seconds = 1.832e+04)
[2022-06-10 01:13:25,662][root][INFO] - Step 68774400 @ 4092.7 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (step = 68774400, mean_episode_return = 73.49, mean_episode_step = 1188.8, total_loss = -2.3663, pg_loss = -44.967, baseline_loss = 47.858, entropy_loss = -5.2578, learner_queue_size = 32, _tick = 17915, _time = 1.6548e+09, train_seconds = 1.8326e+04)
[2022-06-10 01:13:30,666][root][INFO] - Step 68794880 @ 4092.7 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 68794880, mean_episode_return = None, mean_episode_step = 1058.3, total_loss = 430.16, pg_loss = 329.11, baseline_loss = 106.28, entropy_loss = -5.2276, learner_queue_size = 32, _tick = 17921, _time = 1.6548e+09, train_seconds = 1.833e+04)
[2022-06-10 01:13:35,670][root][INFO] - Step 68815360 @ 4092.7 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 68815360, mean_episode_return = 155.93, mean_episode_step = 741.15, total_loss = 190.93, pg_loss = 125.3, baseline_loss = 70.854, entropy_loss = -5.2173, learner_queue_size = 32, _tick = 17928, _time = 1.6548e+09, train_seconds = 1.8336e+04)
[2022-06-10 01:13:40,674][root][INFO] - Step 68833280 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 68833280, mean_episode_return = None, mean_episode_step = 996.0, total_loss = -3.3173, pg_loss = -24.662, baseline_loss = 26.585, entropy_loss = -5.2404, learner_queue_size = 32, _tick = 17932, _time = 1.6548e+09, train_seconds = 1.834e+04)
[2022-06-10 01:13:45,678][root][INFO] - Step 68853760 @ 4092.7 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 68853760, mean_episode_return = 61.89, mean_episode_step = 1058.1, total_loss = -9.6588, pg_loss = -95.678, baseline_loss = 91.2, entropy_loss = -5.1812, learner_queue_size = 32, _tick = 17938, _time = 1.6548e+09, train_seconds = 1.8346e+04)
[2022-06-10 01:13:50,682][root][INFO] - Step 68871680 @ 3581.1 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 68871680, mean_episode_return = 12.535, mean_episode_step = 1032.1, total_loss = -133.35, pg_loss = -150.03, baseline_loss = 21.906, entropy_loss = -5.2199, learner_queue_size = 32, _tick = 17944, _time = 1.6548e+09, train_seconds = 1.835e+04)
[2022-06-10 01:13:55,686][root][INFO] - Step 68892160 @ 4092.8 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (step = 68892160, mean_episode_return = None, mean_episode_step = 1049.4, total_loss = 312.15, pg_loss = 168.51, baseline_loss = 148.9, entropy_loss = -5.262, learner_queue_size = 32, _tick = 17946, _time = 1.6548e+09, train_seconds = 1.8356e+04)
[2022-06-10 01:14:00,690][root][INFO] - Step 68912640 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 68912640, mean_episode_return = 38.335, mean_episode_step = 968.81, total_loss = 67.58, pg_loss = -5.8502, baseline_loss = 78.598, entropy_loss = -5.1677, learner_queue_size = 32, _tick = 17952, _time = 1.6548e+09, train_seconds = 1.836e+04)
[2022-06-10 01:14:05,698][root][INFO] - Step 68930560 @ 3578.3 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 68930560, mean_episode_return = 86.72, mean_episode_step = 1037.1, total_loss = 306.09, pg_loss = 239.87, baseline_loss = 71.526, entropy_loss = -5.2992, learner_queue_size = 32, _tick = 17959, _time = 1.6548e+09, train_seconds = 1.8366e+04)
[2022-06-10 01:14:10,702][root][INFO] - Step 68951040 @ 4092.7 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 68951040, mean_episode_return = 30.09, mean_episode_step = 1077.4, total_loss = 127.54, pg_loss = 79.514, baseline_loss = 53.378, entropy_loss = -5.3567, learner_queue_size = 32, _tick = 17966, _time = 1.6548e+09, train_seconds = 1.837e+04)
[2022-06-10 01:14:15,708][root][INFO] - Step 68968960 @ 3579.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (step = 68968960, mean_episode_return = 58.53, mean_episode_step = 1106.3, total_loss = 287.54, pg_loss = 217.31, baseline_loss = 75.652, entropy_loss = -5.4182, learner_queue_size = 32, _tick = 17971, _time = 1.6548e+09, train_seconds = 1.8376e+04)
[2022-06-10 01:14:20,714][root][INFO] - Step 68989440 @ 4091.5 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 68989440, mean_episode_return = 36.977, mean_episode_step = 907.5, total_loss = 162.98, pg_loss = 107.45, baseline_loss = 60.855, entropy_loss = -5.3271, learner_queue_size = 32, _tick = 17978, _time = 1.6548e+09, train_seconds = 1.838e+04)
[2022-06-10 01:14:25,718][root][INFO] - Step 69009920 @ 4092.7 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 69009920, mean_episode_return = 50.194, mean_episode_step = 1043.3, total_loss = 80.796, pg_loss = 20.776, baseline_loss = 65.321, entropy_loss = -5.301, learner_queue_size = 32, _tick = 17984, _time = 1.6548e+09, train_seconds = 1.8386e+04)
[2022-06-10 01:14:30,722][root][INFO] - Step 69027840 @ 3581.1 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 69027840, mean_episode_return = 112.7, mean_episode_step = 655.3, total_loss = 486.84, pg_loss = 299.0, baseline_loss = 192.93, entropy_loss = -5.0923, learner_queue_size = 32, _tick = 17989, _time = 1.6548e+09, train_seconds = 1.839e+04)
[2022-06-10 01:14:35,726][root][INFO] - Step 69048320 @ 4092.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 69048320, mean_episode_return = 63.911, mean_episode_step = 1222.0, total_loss = 120.55, pg_loss = 34.645, baseline_loss = 91.237, entropy_loss = -5.3293, learner_queue_size = 32, _tick = 17995, _time = 1.6548e+09, train_seconds = 1.8396e+04)
[2022-06-10 01:14:40,730][root][INFO] - Step 69068800 @ 4092.6 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 69068800, mean_episode_return = 41.51, mean_episode_step = 904.7, total_loss = -68.233, pg_loss = -101.21, baseline_loss = 38.223, entropy_loss = -5.2454, learner_queue_size = 32, _tick = 18002, _time = 1.6548e+09, train_seconds = 1.84e+04)
[2022-06-10 01:14:45,734][root][INFO] - Step 69086720 @ 3581.3 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 69086720, mean_episode_return = 25.08, mean_episode_step = 817.59, total_loss = -107.28, pg_loss = -134.47, baseline_loss = 32.479, entropy_loss = -5.2795, learner_queue_size = 32, _tick = 18009, _time = 1.6548e+09, train_seconds = 1.8406e+04)
[2022-06-10 01:14:50,738][root][INFO] - Step 69107200 @ 4092.7 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 69107200, mean_episode_return = None, mean_episode_step = 738.25, total_loss = 22.065, pg_loss = 0.48519, baseline_loss = 26.962, entropy_loss = -5.3818, learner_queue_size = 32, _tick = 18011, _time = 1.6548e+09, train_seconds = 1.841e+04)
[2022-06-10 01:14:55,742][root][INFO] - Step 69125120 @ 3581.1 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (step = 69125120, mean_episode_return = 62.48, mean_episode_step = 919.73, total_loss = 97.04, pg_loss = 36.688, baseline_loss = 65.76, entropy_loss = -5.4076, learner_queue_size = 32, _tick = 18018, _time = 1.6548e+09, train_seconds = 1.8416e+04)
[2022-06-10 01:15:00,746][root][INFO] - Step 69145600 @ 4092.8 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 69145600, mean_episode_return = None, mean_episode_step = 1119.4, total_loss = -88.704, pg_loss = -103.45, baseline_loss = 20.076, entropy_loss = -5.3336, learner_queue_size = 32, _tick = 18023, _time = 1.6548e+09, train_seconds = 1.8421e+04)
[2022-06-10 01:15:05,750][root][INFO] - Step 69163520 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 69163520, mean_episode_return = 74.22, mean_episode_step = 1062.0, total_loss = 350.8, pg_loss = 262.76, baseline_loss = 93.392, entropy_loss = -5.357, learner_queue_size = 32, _tick = 18030, _time = 1.6548e+09, train_seconds = 1.8426e+04)
[2022-06-10 01:15:10,754][root][INFO] - Step 69184000 @ 4092.7 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 69184000, mean_episode_return = None, mean_episode_step = 1141.4, total_loss = -76.215, pg_loss = -92.544, baseline_loss = 21.642, entropy_loss = -5.3127, learner_queue_size = 32, _tick = 18035, _time = 1.6548e+09, train_seconds = 1.8431e+04)
[2022-06-10 01:15:15,758][root][INFO] - Step 69201920 @ 3581.1 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 69201920, mean_episode_return = 29.24, mean_episode_step = 998.67, total_loss = 122.16, pg_loss = 46.085, baseline_loss = 81.359, entropy_loss = -5.2854, learner_queue_size = 32, _tick = 18042, _time = 1.6548e+09, train_seconds = 1.8436e+04)
[2022-06-10 01:15:20,762][root][INFO] - Step 69222400 @ 4092.7 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 69222400, mean_episode_return = 76.7, mean_episode_step = 883.87, total_loss = 122.8, pg_loss = 70.798, baseline_loss = 57.289, entropy_loss = -5.2869, learner_queue_size = 32, _tick = 18047, _time = 1.6548e+09, train_seconds = 1.8441e+04)
[2022-06-10 01:15:25,766][root][INFO] - Step 69242880 @ 4092.7 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 69242880, mean_episode_return = 21.783, mean_episode_step = 765.16, total_loss = -156.17, pg_loss = -190.0, baseline_loss = 39.026, entropy_loss = -5.1988, learner_queue_size = 32, _tick = 18055, _time = 1.6548e+09, train_seconds = 1.8446e+04)
[2022-06-10 01:15:30,770][root][INFO] - Step 69260800 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 69260800, mean_episode_return = None, mean_episode_step = 1027.0, total_loss = -112.87, pg_loss = -150.38, baseline_loss = 42.751, entropy_loss = -5.2451, learner_queue_size = 32, _tick = 18060, _time = 1.6548e+09, train_seconds = 1.8451e+04)
[2022-06-10 01:15:35,774][root][INFO] - Step 69281280 @ 4092.6 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 69281280, mean_episode_return = 85.594, mean_episode_step = 925.55, total_loss = 239.81, pg_loss = 159.97, baseline_loss = 85.221, entropy_loss = -5.381, learner_queue_size = 32, _tick = 18065, _time = 1.6548e+09, train_seconds = 1.8456e+04)
[2022-06-10 01:15:40,778][root][INFO] - Step 69301760 @ 4092.8 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 69301760, mean_episode_return = 42.427, mean_episode_step = 871.37, total_loss = 38.5, pg_loss = -15.946, baseline_loss = 59.774, entropy_loss = -5.3281, learner_queue_size = 32, _tick = 18071, _time = 1.6548e+09, train_seconds = 1.8461e+04)
[2022-06-10 01:15:45,782][root][INFO] - Step 69319680 @ 3581.2 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 69319680, mean_episode_return = 14.73, mean_episode_step = 965.28, total_loss = 23.847, pg_loss = -84.343, baseline_loss = 113.54, entropy_loss = -5.3493, learner_queue_size = 32, _tick = 18076, _time = 1.6548e+09, train_seconds = 1.8466e+04)
[2022-06-10 01:15:50,786][root][INFO] - Step 69340160 @ 4092.8 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 69340160, mean_episode_return = 87.354, mean_episode_step = 791.83, total_loss = -213.91, pg_loss = -238.69, baseline_loss = 30.112, entropy_loss = -5.327, learner_queue_size = 32, _tick = 18082, _time = 1.6548e+09, train_seconds = 1.8471e+04)
[2022-06-10 01:15:55,790][root][INFO] - Step 69358080 @ 3581.2 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 69358080, mean_episode_return = 13.66, mean_episode_step = 864.38, total_loss = 164.44, pg_loss = 122.06, baseline_loss = 47.689, entropy_loss = -5.3053, learner_queue_size = 32, _tick = 18088, _time = 1.6548e+09, train_seconds = 1.8476e+04)
[2022-06-10 01:16:00,796][root][INFO] - Step 69378560 @ 4091.0 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 69378560, mean_episode_return = None, mean_episode_step = 1082.0, total_loss = 154.89, pg_loss = 115.0, baseline_loss = 45.241, entropy_loss = -5.3522, learner_queue_size = 32, _tick = 18093, _time = 1.6548e+09, train_seconds = 1.8481e+04)
[2022-06-10 01:16:05,802][root][INFO] - Step 69399040 @ 4091.2 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 69399040, mean_episode_return = 92.84, mean_episode_step = 1226.0, total_loss = -90.038, pg_loss = -129.55, baseline_loss = 44.865, entropy_loss = -5.3571, learner_queue_size = 32, _tick = 18101, _time = 1.6548e+09, train_seconds = 1.8486e+04)
[2022-06-10 01:16:10,806][root][INFO] - Step 69419520 @ 4092.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 69419520, mean_episode_return = None, mean_episode_step = 1070.3, total_loss = 80.405, pg_loss = 48.99, baseline_loss = 36.874, entropy_loss = -5.4593, learner_queue_size = 32, _tick = 18107, _time = 1.6548e+09, train_seconds = 1.8491e+04)
[2022-06-10 01:16:15,810][root][INFO] - Step 69437440 @ 3581.2 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 69437440, mean_episode_return = 94.412, mean_episode_step = 892.54, total_loss = -82.669, pg_loss = -107.26, baseline_loss = 29.965, entropy_loss = -5.3789, learner_queue_size = 32, _tick = 18113, _time = 1.6548e+09, train_seconds = 1.8496e+04)
[2022-06-10 01:16:20,814][root][INFO] - Step 69457920 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 69457920, mean_episode_return = 102.96, mean_episode_step = 911.85, total_loss = 187.63, pg_loss = 128.25, baseline_loss = 64.722, entropy_loss = -5.3359, learner_queue_size = 32, _tick = 18118, _time = 1.6548e+09, train_seconds = 1.8501e+04)
[2022-06-10 01:16:25,822][root][INFO] - Step 69475840 @ 3578.2 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 69475840, mean_episode_return = 28.755, mean_episode_step = 751.28, total_loss = 907.73, pg_loss = 448.53, baseline_loss = 464.57, entropy_loss = -5.3743, learner_queue_size = 32, _tick = 18122, _time = 1.6548e+09, train_seconds = 1.8506e+04)
[2022-06-10 01:16:30,826][root][INFO] - Step 69496320 @ 4092.8 SPS. Inference batcher size: 77. Learner queue size: 32. Other stats: (step = 69496320, mean_episode_return = 71.99, mean_episode_step = 802.16, total_loss = 85.626, pg_loss = 29.139, baseline_loss = 61.84, entropy_loss = -5.3526, learner_queue_size = 32, _tick = 18129, _time = 1.6548e+09, train_seconds = 1.8511e+04)
[2022-06-10 01:16:35,830][root][INFO] - Step 69516800 @ 4092.7 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 69516800, mean_episode_return = 33.35, mean_episode_step = 1001.3, total_loss = -36.24, pg_loss = -68.389, baseline_loss = 37.515, entropy_loss = -5.3655, learner_queue_size = 32, _tick = 18137, _time = 1.6548e+09, train_seconds = 1.8516e+04)
[2022-06-10 01:16:40,834][root][INFO] - Step 69534720 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 69534720, mean_episode_return = None, mean_episode_step = 870.69, total_loss = 247.58, pg_loss = 177.52, baseline_loss = 75.518, entropy_loss = -5.4628, learner_queue_size = 32, _tick = 18142, _time = 1.6548e+09, train_seconds = 1.8521e+04)
[2022-06-10 01:16:45,838][root][INFO] - Step 69555200 @ 4092.7 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 69555200, mean_episode_return = None, mean_episode_step = 931.66, total_loss = 451.59, pg_loss = 322.43, baseline_loss = 134.58, entropy_loss = -5.4248, learner_queue_size = 32, _tick = 18148, _time = 1.6548e+09, train_seconds = 1.8526e+04)
[2022-06-10 01:16:50,842][root][INFO] - Step 69573120 @ 3581.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 69573120, mean_episode_return = 123.06, mean_episode_step = 1037.6, total_loss = 575.05, pg_loss = 458.03, baseline_loss = 122.46, entropy_loss = -5.4374, learner_queue_size = 32, _tick = 18154, _time = 1.6548e+09, train_seconds = 1.8531e+04)
[2022-06-10 01:16:55,847][root][INFO] - Step 69591040 @ 3580.3 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 69591040, mean_episode_return = None, mean_episode_step = 1087.1, total_loss = -58.985, pg_loss = -82.096, baseline_loss = 28.558, entropy_loss = -5.4472, learner_queue_size = 32, _tick = 18158, _time = 1.6548e+09, train_seconds = 1.8536e+04)
[2022-06-10 01:17:00,850][root][INFO] - Step 69611520 @ 4093.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 69611520, mean_episode_return = 93.298, mean_episode_step = 1139.9, total_loss = 297.0, pg_loss = 202.18, baseline_loss = 100.33, entropy_loss = -5.5011, learner_queue_size = 32, _tick = 18165, _time = 1.6548e+09, train_seconds = 1.8541e+04)
[2022-06-10 01:17:05,854][root][INFO] - Step 69632000 @ 4092.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 69632000, mean_episode_return = 40.496, mean_episode_step = 1048.5, total_loss = 97.379, pg_loss = 65.518, baseline_loss = 37.341, entropy_loss = -5.4805, learner_queue_size = 32, _tick = 18172, _time = 1.6548e+09, train_seconds = 1.8546e+04)
[2022-06-10 01:17:10,858][root][INFO] - Step 69649920 @ 3581.1 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 69649920, mean_episode_return = 18.75, mean_episode_step = 985.4, total_loss = -32.123, pg_loss = -59.089, baseline_loss = 32.495, entropy_loss = -5.5294, learner_queue_size = 32, _tick = 18179, _time = 1.6548e+09, train_seconds = 1.8551e+04)
[2022-06-10 01:17:15,862][root][INFO] - Step 69670400 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 69670400, mean_episode_return = 26.17, mean_episode_step = 1090.3, total_loss = 5.8903, pg_loss = -45.7, baseline_loss = 57.071, entropy_loss = -5.4802, learner_queue_size = 32, _tick = 18187, _time = 1.6548e+09, train_seconds = 1.8556e+04)
[2022-06-10 01:17:20,866][root][INFO] - Step 69690880 @ 4092.8 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 69690880, mean_episode_return = None, mean_episode_step = 1134.3, total_loss = 274.41, pg_loss = 218.02, baseline_loss = 61.805, entropy_loss = -5.418, learner_queue_size = 32, _tick = 18192, _time = 1.6548e+09, train_seconds = 1.8561e+04)
[2022-06-10 01:17:25,871][root][INFO] - Step 69708800 @ 3580.4 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 69708800, mean_episode_return = 12.05, mean_episode_step = 1155.3, total_loss = 181.26, pg_loss = 131.11, baseline_loss = 55.566, entropy_loss = -5.4117, learner_queue_size = 32, _tick = 18196, _time = 1.6548e+09, train_seconds = 1.8566e+04)
[2022-06-10 01:17:30,874][root][INFO] - Step 69729280 @ 4093.6 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 69729280, mean_episode_return = 72.37, mean_episode_step = 1259.2, total_loss = -105.06, pg_loss = -132.07, baseline_loss = 32.375, entropy_loss = -5.3647, learner_queue_size = 32, _tick = 18201, _time = 1.6548e+09, train_seconds = 1.8571e+04)
[2022-06-10 01:17:35,878][root][INFO] - Step 69747200 @ 3581.1 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 69747200, mean_episode_return = 88.439, mean_episode_step = 1044.3, total_loss = -170.02, pg_loss = -195.91, baseline_loss = 31.22, entropy_loss = -5.3343, learner_queue_size = 32, _tick = 18206, _time = 1.6548e+09, train_seconds = 1.8576e+04)
[2022-06-10 01:17:40,882][root][INFO] - Step 69767680 @ 4092.7 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 69767680, mean_episode_return = 16.247, mean_episode_step = 902.23, total_loss = 98.505, pg_loss = 26.117, baseline_loss = 77.751, entropy_loss = -5.3622, learner_queue_size = 32, _tick = 18212, _time = 1.6548e+09, train_seconds = 1.8581e+04)
[2022-06-10 01:17:45,886][root][INFO] - Step 69785600 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 69785600, mean_episode_return = None, mean_episode_step = 1230.9, total_loss = 90.708, pg_loss = 35.956, baseline_loss = 60.2, entropy_loss = -5.4477, learner_queue_size = 32, _tick = 18217, _time = 1.6548e+09, train_seconds = 1.8586e+04)
[2022-06-10 01:17:50,891][root][INFO] - Step 69806080 @ 4091.9 SPS. Inference batcher size: 87. Learner queue size: 32. Other stats: (step = 69806080, mean_episode_return = 94.04, mean_episode_step = 1278.4, total_loss = 171.15, pg_loss = 117.89, baseline_loss = 58.682, entropy_loss = -5.4225, learner_queue_size = 32, _tick = 18221, _time = 1.6548e+09, train_seconds = 1.8591e+04)
[2022-06-10 01:17:55,894][root][INFO] - Step 69824000 @ 3581.8 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 69824000, mean_episode_return = None, mean_episode_step = 1200.2, total_loss = 46.251, pg_loss = 2.6754, baseline_loss = 49.031, entropy_loss = -5.4562, learner_queue_size = 32, _tick = 18227, _time = 1.6548e+09, train_seconds = 1.8596e+04)
[2022-06-10 01:18:00,898][root][INFO] - Step 69844480 @ 4092.8 SPS. Inference batcher size: 77. Learner queue size: 32. Other stats: (step = 69844480, mean_episode_return = None, mean_episode_step = 1160.0, total_loss = 235.63, pg_loss = 160.08, baseline_loss = 80.933, entropy_loss = -5.3894, learner_queue_size = 32, _tick = 18232, _time = 1.6548e+09, train_seconds = 1.8601e+04)
[2022-06-10 01:18:05,902][root][INFO] - Step 69862400 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 69862400, mean_episode_return = 33.17, mean_episode_step = 896.62, total_loss = 85.009, pg_loss = 54.875, baseline_loss = 35.639, entropy_loss = -5.5048, learner_queue_size = 32, _tick = 18239, _time = 1.6548e+09, train_seconds = 1.8606e+04)
[2022-06-10 01:18:10,908][root][INFO] - Step 69882880 @ 4091.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 69882880, mean_episode_return = None, mean_episode_step = 1236.2, total_loss = 174.58, pg_loss = 119.08, baseline_loss = 60.934, entropy_loss = -5.4319, learner_queue_size = 32, _tick = 18245, _time = 1.6548e+09, train_seconds = 1.8611e+04)
[2022-06-10 01:18:15,914][root][INFO] - Step 69900800 @ 3579.8 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 69900800, mean_episode_return = 61.301, mean_episode_step = 1061.1, total_loss = 389.87, pg_loss = 306.75, baseline_loss = 88.599, entropy_loss = -5.4794, learner_queue_size = 32, _tick = 18251, _time = 1.6548e+09, train_seconds = 1.8616e+04)
[2022-06-10 01:18:20,918][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 01:18:21,059][root][INFO] - Step 69921280 @ 4092.7 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 69921280, mean_episode_return = None, mean_episode_step = 1091.7, total_loss = 6.6663, pg_loss = -34.293, baseline_loss = 46.417, entropy_loss = -5.458, learner_queue_size = 32, _tick = 18258, _time = 1.6548e+09, train_seconds = 1.8621e+04)
[2022-06-10 01:18:26,062][root][INFO] - Step 69941760 @ 3981.4 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 69941760, mean_episode_return = 107.43, mean_episode_step = 1004.4, total_loss = 89.113, pg_loss = 51.742, baseline_loss = 42.693, entropy_loss = -5.3222, learner_queue_size = 32, _tick = 18265, _time = 1.6548e+09, train_seconds = 1.8626e+04)
[2022-06-10 01:18:31,066][root][INFO] - Step 69959680 @ 3581.1 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 69959680, mean_episode_return = None, mean_episode_step = 1220.1, total_loss = 0.16628, pg_loss = -55.273, baseline_loss = 61.006, entropy_loss = -5.5672, learner_queue_size = 32, _tick = 18269, _time = 1.6548e+09, train_seconds = 1.8631e+04)
[2022-06-10 01:18:36,072][root][INFO] - Step 69980160 @ 4091.3 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 69980160, mean_episode_return = 66.17, mean_episode_step = 854.9, total_loss = 52.921, pg_loss = 15.133, baseline_loss = 43.266, entropy_loss = -5.4779, learner_queue_size = 32, _tick = 18274, _time = 1.6548e+09, train_seconds = 1.8636e+04)
[2022-06-10 01:18:41,074][root][INFO] - Step 70000640 @ 4094.2 SPS. Inference batcher size: 84. Learner queue size: 32. Other stats: (step = 70000640, mean_episode_return = 5.61, mean_episode_step = 958.31, total_loss = -202.8, pg_loss = -213.2, baseline_loss = 15.876, entropy_loss = -5.4735, learner_queue_size = 32, _tick = 18282, _time = 1.6548e+09, train_seconds = 1.8641e+04)
[2022-06-10 01:18:46,078][root][INFO] - Step 70018560 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 70018560, mean_episode_return = 20.853, mean_episode_step = 1113.4, total_loss = 568.08, pg_loss = 428.98, baseline_loss = 144.52, entropy_loss = -5.4131, learner_queue_size = 32, _tick = 18288, _time = 1.6548e+09, train_seconds = 1.8646e+04)
[2022-06-10 01:18:51,082][root][INFO] - Step 70039040 @ 4092.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 70039040, mean_episode_return = 21.78, mean_episode_step = 786.72, total_loss = 42.671, pg_loss = 8.5292, baseline_loss = 39.455, entropy_loss = -5.3132, learner_queue_size = 32, _tick = 18294, _time = 1.6548e+09, train_seconds = 1.8651e+04)
[2022-06-10 01:18:56,086][root][INFO] - Step 70059520 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 70059520, mean_episode_return = 35.415, mean_episode_step = 911.27, total_loss = -212.76, pg_loss = -243.4, baseline_loss = 35.84, entropy_loss = -5.1937, learner_queue_size = 32, _tick = 18300, _time = 1.6548e+09, train_seconds = 1.8656e+04)
[2022-06-10 01:19:01,090][root][INFO] - Step 70077440 @ 3581.2 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 70077440, mean_episode_return = 60.053, mean_episode_step = 1024.0, total_loss = -82.018, pg_loss = -116.89, baseline_loss = 40.201, entropy_loss = -5.3258, learner_queue_size = 32, _tick = 18304, _time = 1.6548e+09, train_seconds = 1.8661e+04)
[2022-06-10 01:19:06,094][root][INFO] - Step 70097920 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 70097920, mean_episode_return = -2.79, mean_episode_step = 1276.7, total_loss = -96.556, pg_loss = -111.56, baseline_loss = 20.449, entropy_loss = -5.4409, learner_queue_size = 32, _tick = 18312, _time = 1.6548e+09, train_seconds = 1.8666e+04)
[2022-06-10 01:19:11,099][root][INFO] - Step 70118400 @ 4092.0 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 70118400, mean_episode_return = None, mean_episode_step = 1428.0, total_loss = 341.0, pg_loss = 261.74, baseline_loss = 84.718, entropy_loss = -5.4657, learner_queue_size = 32, _tick = 18318, _time = 1.6548e+09, train_seconds = 1.8671e+04)
[2022-06-10 01:19:16,102][root][INFO] - Step 70136320 @ 3581.8 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 70136320, mean_episode_return = None, mean_episode_step = 1101.8, total_loss = -89.36, pg_loss = -109.28, baseline_loss = 25.261, entropy_loss = -5.3359, learner_queue_size = 32, _tick = 18322, _time = 1.6548e+09, train_seconds = 1.8676e+04)
[2022-06-10 01:19:21,103][root][INFO] - Step 70156800 @ 4094.8 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 70156800, mean_episode_return = 55.28, mean_episode_step = 1032.2, total_loss = -79.86, pg_loss = -99.528, baseline_loss = 24.829, entropy_loss = -5.1608, learner_queue_size = 32, _tick = 18330, _time = 1.6548e+09, train_seconds = 1.8681e+04)
[2022-06-10 01:19:26,106][root][INFO] - Step 70177280 @ 4094.0 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 70177280, mean_episode_return = 47.235, mean_episode_step = 1106.7, total_loss = -155.7, pg_loss = -193.91, baseline_loss = 43.448, entropy_loss = -5.233, learner_queue_size = 32, _tick = 18337, _time = 1.6548e+09, train_seconds = 1.8686e+04)
[2022-06-10 01:19:31,110][root][INFO] - Step 70195200 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 70195200, mean_episode_return = 172.95, mean_episode_step = 897.09, total_loss = -68.852, pg_loss = -87.389, baseline_loss = 23.907, entropy_loss = -5.3703, learner_queue_size = 32, _tick = 18343, _time = 1.6548e+09, train_seconds = 1.8691e+04)
[2022-06-10 01:19:36,114][root][INFO] - Step 70215680 @ 4092.8 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 70215680, mean_episode_return = 4.5696, mean_episode_step = 1153.3, total_loss = -74.071, pg_loss = -99.257, baseline_loss = 30.615, entropy_loss = -5.4301, learner_queue_size = 32, _tick = 18348, _time = 1.6548e+09, train_seconds = 1.8696e+04)
[2022-06-10 01:19:41,118][root][INFO] - Step 70236160 @ 4092.7 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 70236160, mean_episode_return = 74.513, mean_episode_step = 925.85, total_loss = -134.37, pg_loss = -149.9, baseline_loss = 20.637, entropy_loss = -5.1105, learner_queue_size = 32, _tick = 18354, _time = 1.6548e+09, train_seconds = 1.8701e+04)
[2022-06-10 01:19:46,122][root][INFO] - Step 70254080 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 70254080, mean_episode_return = None, mean_episode_step = 993.0, total_loss = 62.116, pg_loss = 37.598, baseline_loss = 29.533, entropy_loss = -5.0162, learner_queue_size = 32, _tick = 18358, _time = 1.6548e+09, train_seconds = 1.8706e+04)
[2022-06-10 01:19:51,126][root][INFO] - Step 70272000 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 70272000, mean_episode_return = None, mean_episode_step = 1041.4, total_loss = 57.923, pg_loss = 6.5808, baseline_loss = 56.827, entropy_loss = -5.4841, learner_queue_size = 32, _tick = 18363, _time = 1.6548e+09, train_seconds = 1.8711e+04)
[2022-06-10 01:19:56,130][root][INFO] - Step 70292480 @ 4092.6 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 70292480, mean_episode_return = 47.753, mean_episode_step = 867.3, total_loss = -139.8, pg_loss = -153.68, baseline_loss = 19.334, entropy_loss = -5.4586, learner_queue_size = 32, _tick = 18369, _time = 1.6548e+09, train_seconds = 1.8716e+04)
[2022-06-10 01:20:01,134][root][INFO] - Step 70312960 @ 4092.8 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 70312960, mean_episode_return = 18.78, mean_episode_step = 971.35, total_loss = -71.868, pg_loss = -113.85, baseline_loss = 47.487, entropy_loss = -5.5047, learner_queue_size = 32, _tick = 18375, _time = 1.6548e+09, train_seconds = 1.8721e+04)
[2022-06-10 01:20:06,138][root][INFO] - Step 70330880 @ 3581.1 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 70330880, mean_episode_return = None, mean_episode_step = 1248.9, total_loss = 267.72, pg_loss = 219.26, baseline_loss = 53.885, entropy_loss = -5.4263, learner_queue_size = 32, _tick = 18380, _time = 1.6548e+09, train_seconds = 1.8726e+04)
[2022-06-10 01:20:11,142][root][INFO] - Step 70351360 @ 4092.5 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 70351360, mean_episode_return = 37.244, mean_episode_step = 844.9, total_loss = -22.353, pg_loss = -71.198, baseline_loss = 54.093, entropy_loss = -5.2487, learner_queue_size = 32, _tick = 18384, _time = 1.6548e+09, train_seconds = 1.8731e+04)
[2022-06-10 01:20:16,146][root][INFO] - Step 70369280 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 70369280, mean_episode_return = 56.07, mean_episode_step = 950.72, total_loss = -207.03, pg_loss = -252.08, baseline_loss = 50.31, entropy_loss = -5.2626, learner_queue_size = 32, _tick = 18389, _time = 1.6548e+09, train_seconds = 1.8736e+04)
[2022-06-10 01:20:21,152][root][INFO] - Step 70389760 @ 4091.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 70389760, mean_episode_return = 29.715, mean_episode_step = 993.75, total_loss = 209.94, pg_loss = 123.27, baseline_loss = 92.038, entropy_loss = -5.3712, learner_queue_size = 32, _tick = 18396, _time = 1.6548e+09, train_seconds = 1.8741e+04)
[2022-06-10 01:20:26,158][root][INFO] - Step 70410240 @ 4091.2 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 70410240, mean_episode_return = None, mean_episode_step = 1111.0, total_loss = 11.092, pg_loss = -32.79, baseline_loss = 49.284, entropy_loss = -5.4024, learner_queue_size = 32, _tick = 18403, _time = 1.6548e+09, train_seconds = 1.8746e+04)
[2022-06-10 01:20:31,162][root][INFO] - Step 70428160 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 70428160, mean_episode_return = 49.201, mean_episode_step = 834.02, total_loss = 421.16, pg_loss = 325.9, baseline_loss = 100.4, entropy_loss = -5.1375, learner_queue_size = 32, _tick = 18409, _time = 1.6548e+09, train_seconds = 1.8751e+04)
[2022-06-10 01:20:36,166][root][INFO] - Step 70448640 @ 4092.7 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 70448640, mean_episode_return = 50.88, mean_episode_step = 942.78, total_loss = -45.715, pg_loss = -105.81, baseline_loss = 65.159, entropy_loss = -5.0613, learner_queue_size = 32, _tick = 18417, _time = 1.6548e+09, train_seconds = 1.8756e+04)
[2022-06-10 01:20:41,170][root][INFO] - Step 70466560 @ 3581.1 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 70466560, mean_episode_return = None, mean_episode_step = 958.31, total_loss = 106.78, pg_loss = 50.333, baseline_loss = 61.573, entropy_loss = -5.1261, learner_queue_size = 32, _tick = 18422, _time = 1.6548e+09, train_seconds = 1.8761e+04)
[2022-06-10 01:20:46,174][root][INFO] - Step 70487040 @ 4092.8 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 70487040, mean_episode_return = 86.45, mean_episode_step = 1071.7, total_loss = 14.514, pg_loss = -14.072, baseline_loss = 34.102, entropy_loss = -5.5158, learner_queue_size = 32, _tick = 18428, _time = 1.6548e+09, train_seconds = 1.8766e+04)
[2022-06-10 01:20:51,178][root][INFO] - Step 70507520 @ 4092.8 SPS. Inference batcher size: 93. Learner queue size: 32. Other stats: (step = 70507520, mean_episode_return = 101.83, mean_episode_step = 811.14, total_loss = -15.55, pg_loss = -51.585, baseline_loss = 41.425, entropy_loss = -5.3906, learner_queue_size = 32, _tick = 18435, _time = 1.6548e+09, train_seconds = 1.8771e+04)
[2022-06-10 01:20:56,182][root][INFO] - Step 70525440 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 70525440, mean_episode_return = None, mean_episode_step = 945.19, total_loss = 297.2, pg_loss = 241.18, baseline_loss = 61.458, entropy_loss = -5.4307, learner_queue_size = 32, _tick = 18439, _time = 1.6548e+09, train_seconds = 1.8776e+04)
[2022-06-10 01:21:01,186][root][INFO] - Step 70545920 @ 4092.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 70545920, mean_episode_return = 58.87, mean_episode_step = 826.64, total_loss = 234.18, pg_loss = 143.57, baseline_loss = 95.936, entropy_loss = -5.3291, learner_queue_size = 32, _tick = 18447, _time = 1.6548e+09, train_seconds = 1.8781e+04)
[2022-06-10 01:21:06,190][root][INFO] - Step 70566400 @ 4092.7 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 70566400, mean_episode_return = 76.545, mean_episode_step = 974.75, total_loss = 483.68, pg_loss = 266.29, baseline_loss = 222.83, entropy_loss = -5.4377, learner_queue_size = 32, _tick = 18453, _time = 1.6548e+09, train_seconds = 1.8786e+04)
[2022-06-10 01:21:11,196][root][INFO] - Step 70584320 @ 3579.7 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (step = 70584320, mean_episode_return = None, mean_episode_step = 1155.4, total_loss = 20.006, pg_loss = -24.34, baseline_loss = 49.653, entropy_loss = -5.3066, learner_queue_size = 32, _tick = 18458, _time = 1.6548e+09, train_seconds = 1.8791e+04)
[2022-06-10 01:21:16,202][root][INFO] - Step 70604800 @ 4091.0 SPS. Inference batcher size: 75. Learner queue size: 32. Other stats: (step = 70604800, mean_episode_return = 93.748, mean_episode_step = 1014.8, total_loss = 11.578, pg_loss = -23.824, baseline_loss = 40.79, entropy_loss = -5.3883, learner_queue_size = 32, _tick = 18465, _time = 1.6548e+09, train_seconds = 1.8796e+04)
[2022-06-10 01:21:21,206][root][INFO] - Step 70622720 @ 3581.2 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 70622720, mean_episode_return = 58.571, mean_episode_step = 815.27, total_loss = 87.195, pg_loss = 35.586, baseline_loss = 56.866, entropy_loss = -5.2563, learner_queue_size = 32, _tick = 18471, _time = 1.6548e+09, train_seconds = 1.8801e+04)
[2022-06-10 01:21:26,210][root][INFO] - Step 70643200 @ 4092.7 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 70643200, mean_episode_return = 55.01, mean_episode_step = 873.55, total_loss = -244.96, pg_loss = -261.69, baseline_loss = 22.079, entropy_loss = -5.3508, learner_queue_size = 32, _tick = 18477, _time = 1.6548e+09, train_seconds = 1.8806e+04)
[2022-06-10 01:21:31,214][root][INFO] - Step 70663680 @ 4092.8 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 70663680, mean_episode_return = None, mean_episode_step = 823.78, total_loss = 61.765, pg_loss = 20.558, baseline_loss = 46.716, entropy_loss = -5.509, learner_queue_size = 32, _tick = 18481, _time = 1.6548e+09, train_seconds = 1.8811e+04)
[2022-06-10 01:21:36,224][root][INFO] - Step 70681600 @ 3576.6 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 70681600, mean_episode_return = None, mean_episode_step = 857.66, total_loss = 110.86, pg_loss = 58.977, baseline_loss = 57.316, entropy_loss = -5.4326, learner_queue_size = 32, _tick = 18487, _time = 1.6548e+09, train_seconds = 1.8816e+04)
[2022-06-10 01:21:41,230][root][INFO] - Step 70702080 @ 4091.3 SPS. Inference batcher size: 81. Learner queue size: 32. Other stats: (step = 70702080, mean_episode_return = 52.31, mean_episode_step = 1024.7, total_loss = 184.39, pg_loss = 127.05, baseline_loss = 62.697, entropy_loss = -5.3646, learner_queue_size = 32, _tick = 18494, _time = 1.6548e+09, train_seconds = 1.8821e+04)
[2022-06-10 01:21:46,235][root][INFO] - Step 70720000 @ 3580.7 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 70720000, mean_episode_return = 97.439, mean_episode_step = 1186.7, total_loss = 128.88, pg_loss = 80.633, baseline_loss = 53.602, entropy_loss = -5.354, learner_queue_size = 32, _tick = 18501, _time = 1.6548e+09, train_seconds = 1.8826e+04)
[2022-06-10 01:21:51,238][root][INFO] - Step 70740480 @ 4093.2 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 70740480, mean_episode_return = 6.7297, mean_episode_step = 983.71, total_loss = 143.81, pg_loss = 95.785, baseline_loss = 53.279, entropy_loss = -5.2505, learner_queue_size = 32, _tick = 18506, _time = 1.6548e+09, train_seconds = 1.8831e+04)
[2022-06-10 01:21:56,243][root][INFO] - Step 70758400 @ 3580.3 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 70758400, mean_episode_return = 33.493, mean_episode_step = 992.51, total_loss = 349.21, pg_loss = 225.55, baseline_loss = 129.11, entropy_loss = -5.4419, learner_queue_size = 32, _tick = 18513, _time = 1.6548e+09, train_seconds = 1.8836e+04)
[2022-06-10 01:22:01,246][root][INFO] - Step 70778880 @ 4093.8 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 70778880, mean_episode_return = None, mean_episode_step = 918.09, total_loss = -87.223, pg_loss = -128.13, baseline_loss = 46.387, entropy_loss = -5.4817, learner_queue_size = 32, _tick = 18520, _time = 1.6548e+09, train_seconds = 1.8841e+04)
[2022-06-10 01:22:06,250][root][INFO] - Step 70796800 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 70796800, mean_episode_return = 72.78, mean_episode_step = 748.96, total_loss = 150.06, pg_loss = 95.49, baseline_loss = 59.995, entropy_loss = -5.4272, learner_queue_size = 32, _tick = 18527, _time = 1.6548e+09, train_seconds = 1.8846e+04)
[2022-06-10 01:22:11,254][root][INFO] - Step 70817280 @ 4092.7 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 70817280, mean_episode_return = 111.8, mean_episode_step = 569.77, total_loss = 234.32, pg_loss = 150.23, baseline_loss = 89.504, entropy_loss = -5.4068, learner_queue_size = 32, _tick = 18533, _time = 1.6548e+09, train_seconds = 1.8851e+04)
[2022-06-10 01:22:16,258][root][INFO] - Step 70835200 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 70835200, mean_episode_return = 33.25, mean_episode_step = 953.79, total_loss = -161.7, pg_loss = -202.27, baseline_loss = 45.946, entropy_loss = -5.3734, learner_queue_size = 32, _tick = 18537, _time = 1.6548e+09, train_seconds = 1.8856e+04)
[2022-06-10 01:22:21,262][root][INFO] - Step 70855680 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 70855680, mean_episode_return = 32.901, mean_episode_step = 898.14, total_loss = -67.403, pg_loss = -99.832, baseline_loss = 37.85, entropy_loss = -5.4223, learner_queue_size = 32, _tick = 18542, _time = 1.6548e+09, train_seconds = 1.8861e+04)
[2022-06-10 01:22:26,268][root][INFO] - Step 70873600 @ 3579.8 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 70873600, mean_episode_return = 78.312, mean_episode_step = 944.8, total_loss = -149.52, pg_loss = -198.58, baseline_loss = 54.548, entropy_loss = -5.4892, learner_queue_size = 32, _tick = 18548, _time = 1.6548e+09, train_seconds = 1.8866e+04)
[2022-06-10 01:22:31,270][root][INFO] - Step 70894080 @ 4094.2 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 70894080, mean_episode_return = None, mean_episode_step = 940.53, total_loss = 310.02, pg_loss = 238.24, baseline_loss = 77.233, entropy_loss = -5.4501, learner_queue_size = 32, _tick = 18555, _time = 1.6548e+09, train_seconds = 1.8871e+04)
[2022-06-10 01:22:36,274][root][INFO] - Step 70914560 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 70914560, mean_episode_return = None, mean_episode_step = 1026.0, total_loss = 137.36, pg_loss = 72.781, baseline_loss = 69.991, entropy_loss = -5.412, learner_queue_size = 32, _tick = 18561, _time = 1.6548e+09, train_seconds = 1.8876e+04)
[2022-06-10 01:22:41,278][root][INFO] - Step 70932480 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 70932480, mean_episode_return = 74.92, mean_episode_step = 1065.1, total_loss = -44.204, pg_loss = -86.212, baseline_loss = 47.291, entropy_loss = -5.2835, learner_queue_size = 32, _tick = 18566, _time = 1.6548e+09, train_seconds = 1.8881e+04)
[2022-06-10 01:22:46,282][root][INFO] - Step 70952960 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 70952960, mean_episode_return = None, mean_episode_step = 845.81, total_loss = -30.744, pg_loss = -59.653, baseline_loss = 34.264, entropy_loss = -5.3538, learner_queue_size = 32, _tick = 18572, _time = 1.6548e+09, train_seconds = 1.8886e+04)
[2022-06-10 01:22:51,286][root][INFO] - Step 70970880 @ 3581.1 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 70970880, mean_episode_return = None, mean_episode_step = 962.97, total_loss = -109.28, pg_loss = -156.1, baseline_loss = 52.126, entropy_loss = -5.3004, learner_queue_size = 32, _tick = 18578, _time = 1.6548e+09, train_seconds = 1.8891e+04)
[2022-06-10 01:22:56,290][root][INFO] - Step 70991360 @ 4092.7 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 70991360, mean_episode_return = 46.865, mean_episode_step = 959.41, total_loss = -171.57, pg_loss = -199.59, baseline_loss = 33.465, entropy_loss = -5.4524, learner_queue_size = 32, _tick = 18583, _time = 1.6548e+09, train_seconds = 1.8896e+04)
[2022-06-10 01:23:01,294][root][INFO] - Step 71009280 @ 3581.2 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 71009280, mean_episode_return = None, mean_episode_step = 1101.8, total_loss = 348.76, pg_loss = 230.99, baseline_loss = 123.21, entropy_loss = -5.4465, learner_queue_size = 32, _tick = 18589, _time = 1.6548e+09, train_seconds = 1.8901e+04)
[2022-06-10 01:23:06,298][root][INFO] - Step 71029760 @ 4092.8 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 71029760, mean_episode_return = 20.595, mean_episode_step = 1212.6, total_loss = -148.04, pg_loss = -181.2, baseline_loss = 38.643, entropy_loss = -5.4822, learner_queue_size = 32, _tick = 18595, _time = 1.6548e+09, train_seconds = 1.8906e+04)
[2022-06-10 01:23:11,302][root][INFO] - Step 71050240 @ 4092.7 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 71050240, mean_episode_return = None, mean_episode_step = 1169.7, total_loss = 222.8, pg_loss = 130.86, baseline_loss = 97.383, entropy_loss = -5.4455, learner_queue_size = 32, _tick = 18602, _time = 1.6548e+09, train_seconds = 1.8911e+04)
[2022-06-10 01:23:16,306][root][INFO] - Step 71068160 @ 3581.1 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 71068160, mean_episode_return = 65.61, mean_episode_step = 993.73, total_loss = 106.12, pg_loss = 20.738, baseline_loss = 90.755, entropy_loss = -5.3707, learner_queue_size = 32, _tick = 18607, _time = 1.6548e+09, train_seconds = 1.8916e+04)
[2022-06-10 01:23:21,311][root][INFO] - Step 71088640 @ 4092.0 SPS. Inference batcher size: 90. Learner queue size: 32. Other stats: (step = 71088640, mean_episode_return = 60.75, mean_episode_step = 986.44, total_loss = 105.79, pg_loss = 28.958, baseline_loss = 82.428, entropy_loss = -5.5997, learner_queue_size = 32, _tick = 18614, _time = 1.6548e+09, train_seconds = 1.8921e+04)
[2022-06-10 01:23:26,314][root][INFO] - Step 71109120 @ 4093.4 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 71109120, mean_episode_return = 130.51, mean_episode_step = 1349.5, total_loss = -48.755, pg_loss = -75.986, baseline_loss = 32.685, entropy_loss = -5.454, learner_queue_size = 32, _tick = 18621, _time = 1.6548e+09, train_seconds = 1.8926e+04)
[2022-06-10 01:23:31,318][root][INFO] - Step 71129600 @ 4092.7 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 71129600, mean_episode_return = 30.24, mean_episode_step = 1065.8, total_loss = -124.76, pg_loss = -176.22, baseline_loss = 56.789, entropy_loss = -5.3278, learner_queue_size = 32, _tick = 18628, _time = 1.6548e+09, train_seconds = 1.8931e+04)
[2022-06-10 01:23:36,322][root][INFO] - Step 71147520 @ 3581.2 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 71147520, mean_episode_return = 66.553, mean_episode_step = 862.81, total_loss = 196.86, pg_loss = 94.522, baseline_loss = 107.51, entropy_loss = -5.1675, learner_queue_size = 32, _tick = 18634, _time = 1.6548e+09, train_seconds = 1.8936e+04)
[2022-06-10 01:23:41,326][root][INFO] - Step 71168000 @ 4092.7 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 71168000, mean_episode_return = 42.31, mean_episode_step = 840.02, total_loss = -66.468, pg_loss = -120.25, baseline_loss = 58.969, entropy_loss = -5.1834, learner_queue_size = 32, _tick = 18641, _time = 1.6548e+09, train_seconds = 1.8941e+04)
[2022-06-10 01:23:46,330][root][INFO] - Step 71185920 @ 3581.2 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 71185920, mean_episode_return = 85.768, mean_episode_step = 738.82, total_loss = 149.87, pg_loss = 81.335, baseline_loss = 73.751, entropy_loss = -5.2129, learner_queue_size = 32, _tick = 18646, _time = 1.6548e+09, train_seconds = 1.8946e+04)
[2022-06-10 01:23:51,335][root][INFO] - Step 71206400 @ 4092.0 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 71206400, mean_episode_return = 100.81, mean_episode_step = 1258.1, total_loss = -126.27, pg_loss = -146.97, baseline_loss = 26.006, entropy_loss = -5.3055, learner_queue_size = 32, _tick = 18652, _time = 1.6548e+09, train_seconds = 1.8951e+04)
[2022-06-10 01:23:56,338][root][INFO] - Step 71226880 @ 4093.4 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 71226880, mean_episode_return = 57.781, mean_episode_step = 1013.3, total_loss = -45.889, pg_loss = -100.78, baseline_loss = 60.32, entropy_loss = -5.4262, learner_queue_size = 32, _tick = 18658, _time = 1.6548e+09, train_seconds = 1.8956e+04)
[2022-06-10 01:24:01,342][root][INFO] - Step 71244800 @ 3581.2 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 71244800, mean_episode_return = 56.74, mean_episode_step = 967.45, total_loss = -156.73, pg_loss = -184.96, baseline_loss = 33.673, entropy_loss = -5.4424, learner_queue_size = 32, _tick = 18662, _time = 1.6548e+09, train_seconds = 1.8961e+04)
[2022-06-10 01:24:06,346][root][INFO] - Step 71265280 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 71265280, mean_episode_return = 74.497, mean_episode_step = 1197.4, total_loss = 251.53, pg_loss = 117.12, baseline_loss = 139.76, entropy_loss = -5.344, learner_queue_size = 32, _tick = 18670, _time = 1.6548e+09, train_seconds = 1.8966e+04)
[2022-06-10 01:24:11,350][root][INFO] - Step 71285760 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 71285760, mean_episode_return = None, mean_episode_step = 1222.7, total_loss = 376.78, pg_loss = 286.78, baseline_loss = 95.351, entropy_loss = -5.3485, learner_queue_size = 32, _tick = 18677, _time = 1.6548e+09, train_seconds = 1.8971e+04)
[2022-06-10 01:24:16,356][root][INFO] - Step 71303680 @ 3579.7 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 71303680, mean_episode_return = None, mean_episode_step = 1024.2, total_loss = 206.11, pg_loss = 128.49, baseline_loss = 82.955, entropy_loss = -5.3307, learner_queue_size = 32, _tick = 18681, _time = 1.6548e+09, train_seconds = 1.8976e+04)
[2022-06-10 01:24:21,362][root][INFO] - Step 71324160 @ 4091.2 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 71324160, mean_episode_return = 29.336, mean_episode_step = 926.9, total_loss = -64.904, pg_loss = -104.43, baseline_loss = 44.953, entropy_loss = -5.4244, learner_queue_size = 32, _tick = 18687, _time = 1.6548e+09, train_seconds = 1.8981e+04)
[2022-06-10 01:24:26,366][root][INFO] - Step 71344640 @ 4092.6 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 71344640, mean_episode_return = 49.051, mean_episode_step = 1023.1, total_loss = 328.73, pg_loss = 221.47, baseline_loss = 112.73, entropy_loss = -5.4665, learner_queue_size = 32, _tick = 18693, _time = 1.6548e+09, train_seconds = 1.8986e+04)
[2022-06-10 01:24:31,370][root][INFO] - Step 71362560 @ 3581.2 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 71362560, mean_episode_return = 79.09, mean_episode_step = 1345.5, total_loss = 359.7, pg_loss = 280.5, baseline_loss = 84.567, entropy_loss = -5.3697, learner_queue_size = 32, _tick = 18700, _time = 1.6548e+09, train_seconds = 1.8991e+04)
[2022-06-10 01:24:36,374][root][INFO] - Step 71383040 @ 4092.7 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 71383040, mean_episode_return = 46.22, mean_episode_step = 850.72, total_loss = -105.78, pg_loss = -159.5, baseline_loss = 59.077, entropy_loss = -5.3564, learner_queue_size = 32, _tick = 18707, _time = 1.6548e+09, train_seconds = 1.8996e+04)
[2022-06-10 01:24:41,378][root][INFO] - Step 71400960 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 71400960, mean_episode_return = None, mean_episode_step = 998.06, total_loss = -102.5, pg_loss = -113.23, baseline_loss = 16.127, entropy_loss = -5.3957, learner_queue_size = 32, _tick = 18712, _time = 1.6548e+09, train_seconds = 1.9001e+04)
[2022-06-10 01:24:46,382][root][INFO] - Step 71421440 @ 4092.5 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 71421440, mean_episode_return = 123.24, mean_episode_step = 1185.9, total_loss = 6.0127, pg_loss = -34.574, baseline_loss = 45.983, entropy_loss = -5.3958, learner_queue_size = 32, _tick = 18719, _time = 1.6548e+09, train_seconds = 1.9006e+04)
[2022-06-10 01:24:51,386][root][INFO] - Step 71441920 @ 4092.9 SPS. Inference batcher size: 73. Learner queue size: 32. Other stats: (step = 71441920, mean_episode_return = 75.209, mean_episode_step = 1214.3, total_loss = -139.95, pg_loss = -210.16, baseline_loss = 75.644, entropy_loss = -5.4359, learner_queue_size = 32, _tick = 18725, _time = 1.6548e+09, train_seconds = 1.9011e+04)
[2022-06-10 01:24:56,390][root][INFO] - Step 71462400 @ 4092.8 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 71462400, mean_episode_return = 70.29, mean_episode_step = 1186.9, total_loss = -84.936, pg_loss = -122.41, baseline_loss = 42.903, entropy_loss = -5.432, learner_queue_size = 32, _tick = 18733, _time = 1.6548e+09, train_seconds = 1.9016e+04)
[2022-06-10 01:25:01,394][root][INFO] - Step 71480320 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 71480320, mean_episode_return = 103.93, mean_episode_step = 1053.8, total_loss = 298.18, pg_loss = 227.61, baseline_loss = 76.073, entropy_loss = -5.5068, learner_queue_size = 32, _tick = 18740, _time = 1.6548e+09, train_seconds = 1.9021e+04)
[2022-06-10 01:25:06,398][root][INFO] - Step 71500800 @ 4092.7 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 71500800, mean_episode_return = 37.451, mean_episode_step = 969.44, total_loss = 422.17, pg_loss = 265.28, baseline_loss = 162.21, entropy_loss = -5.316, learner_queue_size = 32, _tick = 18747, _time = 1.6548e+09, train_seconds = 1.9026e+04)
[2022-06-10 01:25:11,404][root][INFO] - Step 71521280 @ 4091.0 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 71521280, mean_episode_return = 98.208, mean_episode_step = 1156.1, total_loss = 83.197, pg_loss = 53.813, baseline_loss = 34.819, entropy_loss = -5.4347, learner_queue_size = 32, _tick = 18755, _time = 1.6548e+09, train_seconds = 1.9031e+04)
[2022-06-10 01:25:16,410][root][INFO] - Step 71539200 @ 3579.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 71539200, mean_episode_return = 47.96, mean_episode_step = 1096.9, total_loss = 25.134, pg_loss = -23.653, baseline_loss = 54.166, entropy_loss = -5.3785, learner_queue_size = 32, _tick = 18762, _time = 1.6548e+09, train_seconds = 1.9036e+04)
[2022-06-10 01:25:21,414][root][INFO] - Step 71559680 @ 4092.9 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 71559680, mean_episode_return = 24.006, mean_episode_step = 969.06, total_loss = -173.19, pg_loss = -189.91, baseline_loss = 22.026, entropy_loss = -5.3051, learner_queue_size = 32, _tick = 18770, _time = 1.6548e+09, train_seconds = 1.9041e+04)
[2022-06-10 01:25:26,418][root][INFO] - Step 71580160 @ 4092.6 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 71580160, mean_episode_return = None, mean_episode_step = 1376.8, total_loss = 32.362, pg_loss = -14.258, baseline_loss = 51.962, entropy_loss = -5.3412, learner_queue_size = 32, _tick = 18773, _time = 1.6548e+09, train_seconds = 1.9046e+04)
[2022-06-10 01:25:31,421][root][INFO] - Step 71598080 @ 3582.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 71598080, mean_episode_return = 28.08, mean_episode_step = 1057.1, total_loss = 278.89, pg_loss = 211.24, baseline_loss = 73.013, entropy_loss = -5.3555, learner_queue_size = 32, _tick = 18780, _time = 1.6548e+09, train_seconds = 1.9051e+04)
[2022-06-10 01:25:36,426][root][INFO] - Step 71618560 @ 4091.8 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 71618560, mean_episode_return = None, mean_episode_step = 1041.2, total_loss = -44.071, pg_loss = -117.02, baseline_loss = 78.293, entropy_loss = -5.3432, learner_queue_size = 32, _tick = 18786, _time = 1.6548e+09, train_seconds = 1.9056e+04)
[2022-06-10 01:25:41,430][root][INFO] - Step 71639040 @ 4092.7 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 71639040, mean_episode_return = 24.12, mean_episode_step = 1095.0, total_loss = 14.114, pg_loss = -44.505, baseline_loss = 63.965, entropy_loss = -5.3465, learner_queue_size = 32, _tick = 18794, _time = 1.6548e+09, train_seconds = 1.9061e+04)
[2022-06-10 01:25:46,434][root][INFO] - Step 71659520 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 71659520, mean_episode_return = 26.299, mean_episode_step = 873.25, total_loss = 109.91, pg_loss = -1.5457, baseline_loss = 116.78, entropy_loss = -5.3223, learner_queue_size = 32, _tick = 18799, _time = 1.6548e+09, train_seconds = 1.9066e+04)
[2022-06-10 01:25:51,438][root][INFO] - Step 71677440 @ 3581.1 SPS. Inference batcher size: 73. Learner queue size: 32. Other stats: (step = 71677440, mean_episode_return = 84.209, mean_episode_step = 1106.0, total_loss = 528.8, pg_loss = 388.36, baseline_loss = 145.66, entropy_loss = -5.2228, learner_queue_size = 32, _tick = 18805, _time = 1.6548e+09, train_seconds = 1.9071e+04)
[2022-06-10 01:25:56,442][root][INFO] - Step 71697920 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 71697920, mean_episode_return = 50.01, mean_episode_step = 1506.3, total_loss = 20.455, pg_loss = -22.627, baseline_loss = 48.504, entropy_loss = -5.4217, learner_queue_size = 32, _tick = 18811, _time = 1.6548e+09, train_seconds = 1.9076e+04)
[2022-06-10 01:26:01,446][root][INFO] - Step 71715840 @ 3581.2 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 71715840, mean_episode_return = 14.67, mean_episode_step = 1280.2, total_loss = 262.28, pg_loss = 209.29, baseline_loss = 58.465, entropy_loss = -5.4769, learner_queue_size = 32, _tick = 18817, _time = 1.6548e+09, train_seconds = 1.9081e+04)
[2022-06-10 01:26:06,450][root][INFO] - Step 71736320 @ 4092.7 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 71736320, mean_episode_return = 48.697, mean_episode_step = 1019.3, total_loss = 96.39, pg_loss = 60.584, baseline_loss = 41.196, entropy_loss = -5.3903, learner_queue_size = 32, _tick = 18822, _time = 1.6548e+09, train_seconds = 1.9086e+04)
[2022-06-10 01:26:11,454][root][INFO] - Step 71756800 @ 4092.7 SPS. Inference batcher size: 96. Learner queue size: 32. Other stats: (step = 71756800, mean_episode_return = 83.835, mean_episode_step = 1140.6, total_loss = -138.4, pg_loss = -162.81, baseline_loss = 29.712, entropy_loss = -5.3019, learner_queue_size = 32, _tick = 18829, _time = 1.6548e+09, train_seconds = 1.9091e+04)
[2022-06-10 01:26:16,458][root][INFO] - Step 71774720 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 71774720, mean_episode_return = 27.981, mean_episode_step = 1167.3, total_loss = 281.25, pg_loss = 223.4, baseline_loss = 63.307, entropy_loss = -5.4599, learner_queue_size = 32, _tick = 18835, _time = 1.6548e+09, train_seconds = 1.9096e+04)
[2022-06-10 01:26:21,462][root][INFO] - Step 71795200 @ 4092.6 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 71795200, mean_episode_return = None, mean_episode_step = 977.06, total_loss = 82.268, pg_loss = 23.007, baseline_loss = 64.719, entropy_loss = -5.4577, learner_queue_size = 32, _tick = 18842, _time = 1.6548e+09, train_seconds = 1.9101e+04)
[2022-06-10 01:26:26,466][root][INFO] - Step 71813120 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 71813120, mean_episode_return = 198.11, mean_episode_step = 966.0, total_loss = 296.7, pg_loss = 92.06, baseline_loss = 210.16, entropy_loss = -5.5162, learner_queue_size = 32, _tick = 18849, _time = 1.6548e+09, train_seconds = 1.9106e+04)
[2022-06-10 01:26:31,470][root][INFO] - Step 71833600 @ 4092.8 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 71833600, mean_episode_return = 31.601, mean_episode_step = 1324.6, total_loss = -87.393, pg_loss = -99.164, baseline_loss = 17.282, entropy_loss = -5.5111, learner_queue_size = 32, _tick = 18856, _time = 1.6548e+09, train_seconds = 1.9111e+04)
[2022-06-10 01:26:36,474][root][INFO] - Step 71854080 @ 4092.7 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 71854080, mean_episode_return = 90.977, mean_episode_step = 1060.5, total_loss = 29.098, pg_loss = -16.376, baseline_loss = 50.963, entropy_loss = -5.4902, learner_queue_size = 32, _tick = 18862, _time = 1.6548e+09, train_seconds = 1.9116e+04)
[2022-06-10 01:26:41,529][root][INFO] - Step 71874560 @ 4051.3 SPS. Inference batcher size: 81. Learner queue size: 32. Other stats: (step = 71874560, mean_episode_return = None, mean_episode_step = 925.09, total_loss = 160.53, pg_loss = 115.87, baseline_loss = 50.07, entropy_loss = -5.4048, learner_queue_size = 32, _tick = 18865, _time = 1.6548e+09, train_seconds = 1.9121e+04)
[2022-06-10 01:26:46,534][root][INFO] - Step 71892480 @ 3580.5 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 71892480, mean_episode_return = 67.3, mean_episode_step = 994.01, total_loss = 394.96, pg_loss = 302.08, baseline_loss = 98.229, entropy_loss = -5.3454, learner_queue_size = 32, _tick = 18871, _time = 1.6548e+09, train_seconds = 1.9126e+04)
[2022-06-10 01:26:51,538][root][INFO] - Step 71912960 @ 4092.6 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 71912960, mean_episode_return = 89.29, mean_episode_step = 972.39, total_loss = 121.87, pg_loss = 56.318, baseline_loss = 70.962, entropy_loss = -5.4054, learner_queue_size = 32, _tick = 18877, _time = 1.6548e+09, train_seconds = 1.9131e+04)
[2022-06-10 01:26:56,542][root][INFO] - Step 71930880 @ 3581.3 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 71930880, mean_episode_return = 38.918, mean_episode_step = 1025.7, total_loss = 136.46, pg_loss = 62.757, baseline_loss = 79.119, entropy_loss = -5.4203, learner_queue_size = 32, _tick = 18882, _time = 1.6548e+09, train_seconds = 1.9136e+04)
[2022-06-10 01:27:01,546][root][INFO] - Step 71951360 @ 4092.7 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 71951360, mean_episode_return = 42.761, mean_episode_step = 1302.7, total_loss = -156.95, pg_loss = -196.01, baseline_loss = 44.44, entropy_loss = -5.3787, learner_queue_size = 32, _tick = 18887, _time = 1.6548e+09, train_seconds = 1.9141e+04)
[2022-06-10 01:27:06,550][root][INFO] - Step 71971840 @ 4092.8 SPS. Inference batcher size: 76. Learner queue size: 32. Other stats: (step = 71971840, mean_episode_return = 57.386, mean_episode_step = 1160.2, total_loss = -230.92, pg_loss = -249.0, baseline_loss = 23.513, entropy_loss = -5.4272, learner_queue_size = 32, _tick = 18894, _time = 1.6548e+09, train_seconds = 1.9146e+04)
[2022-06-10 01:27:11,554][root][INFO] - Step 71989760 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 71989760, mean_episode_return = 71.169, mean_episode_step = 934.46, total_loss = 216.98, pg_loss = 146.21, baseline_loss = 76.217, entropy_loss = -5.4487, learner_queue_size = 32, _tick = 18900, _time = 1.6548e+09, train_seconds = 1.9151e+04)
[2022-06-10 01:27:16,558][root][INFO] - Step 72007680 @ 3581.2 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 72007680, mean_episode_return = 11.53, mean_episode_step = 1323.4, total_loss = -42.301, pg_loss = -62.531, baseline_loss = 25.688, entropy_loss = -5.4584, learner_queue_size = 32, _tick = 18907, _time = 1.6548e+09, train_seconds = 1.9156e+04)
[2022-06-10 01:27:21,562][root][INFO] - Step 72028160 @ 4092.7 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 72028160, mean_episode_return = None, mean_episode_step = 1516.8, total_loss = 143.0, pg_loss = 122.39, baseline_loss = 25.98, entropy_loss = -5.3711, learner_queue_size = 32, _tick = 18914, _time = 1.6548e+09, train_seconds = 1.9161e+04)
[2022-06-10 01:27:26,566][root][INFO] - Step 72046080 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 72046080, mean_episode_return = None, mean_episode_step = 1269.4, total_loss = -141.77, pg_loss = -152.26, baseline_loss = 15.79, entropy_loss = -5.303, learner_queue_size = 32, _tick = 18919, _time = 1.6548e+09, train_seconds = 1.9166e+04)
[2022-06-10 01:27:31,570][root][INFO] - Step 72066560 @ 4092.8 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 72066560, mean_episode_return = None, mean_episode_step = 940.06, total_loss = -96.479, pg_loss = -116.5, baseline_loss = 25.296, entropy_loss = -5.2704, learner_queue_size = 32, _tick = 18925, _time = 1.6548e+09, train_seconds = 1.9171e+04)
[2022-06-10 01:27:36,574][root][INFO] - Step 72087040 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 72087040, mean_episode_return = None, mean_episode_step = 1061.4, total_loss = 172.64, pg_loss = 116.08, baseline_loss = 61.856, entropy_loss = -5.2972, learner_queue_size = 32, _tick = 18931, _time = 1.6548e+09, train_seconds = 1.9176e+04)
[2022-06-10 01:27:41,578][root][INFO] - Step 72107520 @ 4092.4 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (step = 72107520, mean_episode_return = 83.501, mean_episode_step = 865.01, total_loss = -66.977, pg_loss = -93.562, baseline_loss = 30.71, entropy_loss = -4.1258, learner_queue_size = 32, _tick = 18938, _time = 1.6548e+09, train_seconds = 1.9181e+04)
[2022-06-10 01:27:46,582][root][INFO] - Step 72125440 @ 3581.4 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 72125440, mean_episode_return = 54.444, mean_episode_step = 933.59, total_loss = -20.988, pg_loss = -22.701, baseline_loss = 7.2784, entropy_loss = -5.5652, learner_queue_size = 32, _tick = 18945, _time = 1.6548e+09, train_seconds = 1.9186e+04)
[2022-06-10 01:27:51,588][root][INFO] - Step 72143360 @ 3579.6 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 72143360, mean_episode_return = None, mean_episode_step = 1361.2, total_loss = -152.39, pg_loss = -150.87, baseline_loss = 3.9883, entropy_loss = -5.5117, learner_queue_size = 32, _tick = 18951, _time = 1.6548e+09, train_seconds = 1.9191e+04)
[2022-06-10 01:27:56,594][root][INFO] - Step 72163840 @ 4091.1 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 72163840, mean_episode_return = 59.17, mean_episode_step = 797.73, total_loss = 458.67, pg_loss = 374.98, baseline_loss = 89.198, entropy_loss = -5.5077, learner_queue_size = 32, _tick = 18956, _time = 1.6548e+09, train_seconds = 1.9196e+04)
[2022-06-10 01:28:01,600][root][INFO] - Step 72181760 @ 3579.6 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 72181760, mean_episode_return = 71.884, mean_episode_step = 1057.6, total_loss = -14.958, pg_loss = -53.196, baseline_loss = 43.692, entropy_loss = -5.4531, learner_queue_size = 32, _tick = 18962, _time = 1.6548e+09, train_seconds = 1.9201e+04)
[2022-06-10 01:28:06,606][root][INFO] - Step 72202240 @ 4091.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 72202240, mean_episode_return = 28.02, mean_episode_step = 1315.7, total_loss = -27.848, pg_loss = -42.138, baseline_loss = 19.232, entropy_loss = -4.9424, learner_queue_size = 32, _tick = 18969, _time = 1.6548e+09, train_seconds = 1.9206e+04)
[2022-06-10 01:28:11,610][root][INFO] - Step 72222720 @ 4092.9 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 72222720, mean_episode_return = None, mean_episode_step = 817.62, total_loss = -169.83, pg_loss = -182.43, baseline_loss = 17.42, entropy_loss = -4.8248, learner_queue_size = 32, _tick = 18975, _time = 1.6548e+09, train_seconds = 1.9211e+04)
[2022-06-10 01:28:16,614][root][INFO] - Step 72243200 @ 4092.8 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 72243200, mean_episode_return = 59.018, mean_episode_step = 1147.6, total_loss = -308.8, pg_loss = -320.48, baseline_loss = 16.679, entropy_loss = -4.9979, learner_queue_size = 32, _tick = 18982, _time = 1.6548e+09, train_seconds = 1.9216e+04)
[2022-06-10 01:28:21,618][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 01:28:21,771][root][INFO] - Step 72261120 @ 3581.1 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 72261120, mean_episode_return = 68.16, mean_episode_step = 858.05, total_loss = 232.9, pg_loss = 163.63, baseline_loss = 74.716, entropy_loss = -5.4432, learner_queue_size = 32, _tick = 18987, _time = 1.6548e+09, train_seconds = 1.9221e+04)
[2022-06-10 01:28:26,774][root][INFO] - Step 72281600 @ 3972.0 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 72281600, mean_episode_return = None, mean_episode_step = 975.19, total_loss = -12.609, pg_loss = -38.15, baseline_loss = 30.968, entropy_loss = -5.4274, learner_queue_size = 32, _tick = 18993, _time = 1.6548e+09, train_seconds = 1.9227e+04)
[2022-06-10 01:28:31,778][root][INFO] - Step 72302080 @ 4092.7 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (step = 72302080, mean_episode_return = 30.24, mean_episode_step = 830.84, total_loss = 335.02, pg_loss = 240.72, baseline_loss = 99.708, entropy_loss = -5.4064, learner_queue_size = 32, _tick = 18998, _time = 1.6548e+09, train_seconds = 1.9232e+04)
[2022-06-10 01:28:36,780][root][INFO] - Step 72320000 @ 3582.6 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 72320000, mean_episode_return = 41.776, mean_episode_step = 854.54, total_loss = 167.14, pg_loss = 71.298, baseline_loss = 101.14, entropy_loss = -5.3029, learner_queue_size = 32, _tick = 19005, _time = 1.6548e+09, train_seconds = 1.9237e+04)
[2022-06-10 01:28:41,790][root][INFO] - Step 72340480 @ 4087.9 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (step = 72340480, mean_episode_return = 5.1249, mean_episode_step = 904.43, total_loss = -194.73, pg_loss = -212.84, baseline_loss = 23.308, entropy_loss = -5.1971, learner_queue_size = 32, _tick = 19011, _time = 1.6548e+09, train_seconds = 1.9242e+04)
[2022-06-10 01:28:46,794][root][INFO] - Step 72358400 @ 3581.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 72358400, mean_episode_return = 75.989, mean_episode_step = 836.12, total_loss = 48.163, pg_loss = -2.6819, baseline_loss = 56.152, entropy_loss = -5.3075, learner_queue_size = 32, _tick = 19017, _time = 1.6548e+09, train_seconds = 1.9247e+04)
[2022-06-10 01:28:51,798][root][INFO] - Step 72378880 @ 4092.7 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 72378880, mean_episode_return = 35.5, mean_episode_step = 972.28, total_loss = 1.9182, pg_loss = -37.856, baseline_loss = 45.169, entropy_loss = -5.3949, learner_queue_size = 32, _tick = 19023, _time = 1.6548e+09, train_seconds = 1.9252e+04)
[2022-06-10 01:28:56,802][root][INFO] - Step 72399360 @ 4092.7 SPS. Inference batcher size: 86. Learner queue size: 32. Other stats: (step = 72399360, mean_episode_return = 74.539, mean_episode_step = 1056.1, total_loss = 320.53, pg_loss = 219.07, baseline_loss = 106.79, entropy_loss = -5.3265, learner_queue_size = 32, _tick = 19029, _time = 1.6548e+09, train_seconds = 1.9257e+04)
[2022-06-10 01:29:01,806][root][INFO] - Step 72417280 @ 3581.1 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (step = 72417280, mean_episode_return = 69.83, mean_episode_step = 1512.2, total_loss = 40.218, pg_loss = 10.796, baseline_loss = 34.822, entropy_loss = -5.3996, learner_queue_size = 32, _tick = 19036, _time = 1.6548e+09, train_seconds = 1.9262e+04)
[2022-06-10 01:29:06,810][root][INFO] - Step 72437760 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 72437760, mean_episode_return = None, mean_episode_step = 1094.6, total_loss = 235.25, pg_loss = 97.783, baseline_loss = 142.72, entropy_loss = -5.2495, learner_queue_size = 32, _tick = 19041, _time = 1.6548e+09, train_seconds = 1.9267e+04)
[2022-06-10 01:29:11,814][root][INFO] - Step 72458240 @ 4092.8 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 72458240, mean_episode_return = None, mean_episode_step = 1169.2, total_loss = -67.602, pg_loss = -78.343, baseline_loss = 16.143, entropy_loss = -5.4024, learner_queue_size = 32, _tick = 19045, _time = 1.6548e+09, train_seconds = 1.9272e+04)
[2022-06-10 01:29:16,818][root][INFO] - Step 72476160 @ 3581.1 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 72476160, mean_episode_return = 61.23, mean_episode_step = 1140.4, total_loss = 251.98, pg_loss = 187.61, baseline_loss = 69.739, entropy_loss = -5.3671, learner_queue_size = 32, _tick = 19050, _time = 1.6548e+09, train_seconds = 1.9277e+04)
[2022-06-10 01:29:21,822][root][INFO] - Step 72496640 @ 4092.8 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 72496640, mean_episode_return = 8.6297, mean_episode_step = 1301.1, total_loss = -5.2717, pg_loss = -26.377, baseline_loss = 26.303, entropy_loss = -5.1979, learner_queue_size = 32, _tick = 19056, _time = 1.6548e+09, train_seconds = 1.9282e+04)
[2022-06-10 01:29:26,826][root][INFO] - Step 72517120 @ 4092.6 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 72517120, mean_episode_return = 147.88, mean_episode_step = 1183.8, total_loss = -199.85, pg_loss = -257.39, baseline_loss = 62.746, entropy_loss = -5.2048, learner_queue_size = 32, _tick = 19063, _time = 1.6548e+09, train_seconds = 1.9287e+04)
[2022-06-10 01:29:31,830][root][INFO] - Step 72535040 @ 3581.2 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 72535040, mean_episode_return = 19.88, mean_episode_step = 1559.4, total_loss = -92.292, pg_loss = -162.51, baseline_loss = 75.536, entropy_loss = -5.32, learner_queue_size = 32, _tick = 19070, _time = 1.6548e+09, train_seconds = 1.9292e+04)
[2022-06-10 01:29:36,834][root][INFO] - Step 72555520 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 72555520, mean_episode_return = 53.732, mean_episode_step = 970.09, total_loss = 46.903, pg_loss = 27.181, baseline_loss = 25.28, entropy_loss = -5.5587, learner_queue_size = 32, _tick = 19077, _time = 1.6548e+09, train_seconds = 1.9297e+04)
[2022-06-10 01:29:41,838][root][INFO] - Step 72573440 @ 3581.2 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 72573440, mean_episode_return = 123.08, mean_episode_step = 929.26, total_loss = 337.07, pg_loss = 240.8, baseline_loss = 101.78, entropy_loss = -5.5064, learner_queue_size = 32, _tick = 19083, _time = 1.6548e+09, train_seconds = 1.9302e+04)
[2022-06-10 01:29:46,842][root][INFO] - Step 72593920 @ 4092.6 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 72593920, mean_episode_return = None, mean_episode_step = 1129.6, total_loss = 407.69, pg_loss = 333.76, baseline_loss = 79.441, entropy_loss = -5.5139, learner_queue_size = 32, _tick = 19088, _time = 1.6548e+09, train_seconds = 1.9307e+04)
[2022-06-10 01:29:51,846][root][INFO] - Step 72614400 @ 4092.6 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 72614400, mean_episode_return = 35.831, mean_episode_step = 1535.9, total_loss = 4.3906, pg_loss = -15.39, baseline_loss = 25.144, entropy_loss = -5.363, learner_queue_size = 32, _tick = 19094, _time = 1.6548e+09, train_seconds = 1.9312e+04)
[2022-06-10 01:29:56,852][root][INFO] - Step 72634880 @ 4091.0 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 72634880, mean_episode_return = 116.64, mean_episode_step = 1241.5, total_loss = -11.825, pg_loss = -60.431, baseline_loss = 53.898, entropy_loss = -5.292, learner_queue_size = 32, _tick = 19102, _time = 1.6548e+09, train_seconds = 1.9317e+04)
[2022-06-10 01:30:01,858][root][INFO] - Step 72655360 @ 4091.4 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (step = 72655360, mean_episode_return = 16.74, mean_episode_step = 941.2, total_loss = -34.306, pg_loss = -74.181, baseline_loss = 45.274, entropy_loss = -5.3984, learner_queue_size = 32, _tick = 19108, _time = 1.6548e+09, train_seconds = 1.9322e+04)
[2022-06-10 01:30:06,864][root][INFO] - Step 72673280 @ 3579.5 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 72673280, mean_episode_return = None, mean_episode_step = 1103.0, total_loss = 74.696, pg_loss = 31.323, baseline_loss = 48.806, entropy_loss = -5.4328, learner_queue_size = 32, _tick = 19111, _time = 1.6548e+09, train_seconds = 1.9327e+04)
[2022-06-10 01:30:11,870][root][INFO] - Step 72693760 @ 4091.3 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 72693760, mean_episode_return = None, mean_episode_step = 934.66, total_loss = 666.02, pg_loss = 534.06, baseline_loss = 137.32, entropy_loss = -5.3627, learner_queue_size = 32, _tick = 19117, _time = 1.6548e+09, train_seconds = 1.9332e+04)
[2022-06-10 01:30:16,874][root][INFO] - Step 72714240 @ 4092.7 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 72714240, mean_episode_return = 37.26, mean_episode_step = 923.03, total_loss = -79.469, pg_loss = -115.73, baseline_loss = 41.474, entropy_loss = -5.209, learner_queue_size = 32, _tick = 19120, _time = 1.6548e+09, train_seconds = 1.9337e+04)
[2022-06-10 01:30:21,878][root][INFO] - Step 72734720 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 72734720, mean_episode_return = None, mean_episode_step = 1254.5, total_loss = -78.038, pg_loss = -102.92, baseline_loss = 30.344, entropy_loss = -5.4632, learner_queue_size = 32, _tick = 19126, _time = 1.6548e+09, train_seconds = 1.9342e+04)
[2022-06-10 01:30:26,882][root][INFO] - Step 72752640 @ 3581.2 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 72752640, mean_episode_return = 100.87, mean_episode_step = 1125.7, total_loss = 103.63, pg_loss = 6.1711, baseline_loss = 102.97, entropy_loss = -5.518, learner_queue_size = 32, _tick = 19133, _time = 1.6548e+09, train_seconds = 1.9347e+04)
[2022-06-10 01:30:31,888][root][INFO] - Step 72773120 @ 4091.2 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 72773120, mean_episode_return = 63.963, mean_episode_step = 1215.8, total_loss = 374.76, pg_loss = 283.93, baseline_loss = 96.311, entropy_loss = -5.479, learner_queue_size = 32, _tick = 19141, _time = 1.6548e+09, train_seconds = 1.9352e+04)
[2022-06-10 01:30:36,890][root][INFO] - Step 72793600 @ 4094.2 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 72793600, mean_episode_return = 57.685, mean_episode_step = 1162.4, total_loss = 141.88, pg_loss = 21.239, baseline_loss = 126.03, entropy_loss = -5.3982, learner_queue_size = 32, _tick = 19149, _time = 1.6548e+09, train_seconds = 1.9357e+04)
[2022-06-10 01:30:41,894][root][INFO] - Step 72811520 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 72811520, mean_episode_return = 89.276, mean_episode_step = 776.17, total_loss = -196.67, pg_loss = -219.62, baseline_loss = 27.917, entropy_loss = -4.9686, learner_queue_size = 32, _tick = 19154, _time = 1.6548e+09, train_seconds = 1.9362e+04)
[2022-06-10 01:30:46,898][root][INFO] - Step 72832000 @ 4092.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 72832000, mean_episode_return = 52.831, mean_episode_step = 1294.2, total_loss = 127.53, pg_loss = 76.974, baseline_loss = 56.069, entropy_loss = -5.5078, learner_queue_size = 32, _tick = 19159, _time = 1.6548e+09, train_seconds = 1.9367e+04)
[2022-06-10 01:30:51,902][root][INFO] - Step 72852480 @ 4092.8 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 72852480, mean_episode_return = 30.28, mean_episode_step = 1636.0, total_loss = -0.016061, pg_loss = -49.11, baseline_loss = 54.559, entropy_loss = -5.4651, learner_queue_size = 32, _tick = 19167, _time = 1.6548e+09, train_seconds = 1.9372e+04)
[2022-06-10 01:30:56,906][root][INFO] - Step 72870400 @ 3581.0 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 72870400, mean_episode_return = 61.9, mean_episode_step = 1006.7, total_loss = -65.069, pg_loss = -89.186, baseline_loss = 29.63, entropy_loss = -5.5126, learner_queue_size = 32, _tick = 19174, _time = 1.6548e+09, train_seconds = 1.9377e+04)
[2022-06-10 01:31:01,910][root][INFO] - Step 72890880 @ 4092.8 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 72890880, mean_episode_return = 96.517, mean_episode_step = 881.08, total_loss = -87.669, pg_loss = -126.28, baseline_loss = 44.082, entropy_loss = -5.4712, learner_queue_size = 32, _tick = 19181, _time = 1.6548e+09, train_seconds = 1.9382e+04)
[2022-06-10 01:31:06,914][root][INFO] - Step 72908800 @ 3581.2 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 72908800, mean_episode_return = None, mean_episode_step = 828.19, total_loss = 186.88, pg_loss = 129.65, baseline_loss = 62.629, entropy_loss = -5.4039, learner_queue_size = 32, _tick = 19184, _time = 1.6548e+09, train_seconds = 1.9387e+04)
[2022-06-10 01:31:11,918][root][INFO] - Step 72929280 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 72929280, mean_episode_return = None, mean_episode_step = 1016.8, total_loss = -27.531, pg_loss = -34.235, baseline_loss = 11.966, entropy_loss = -5.2618, learner_queue_size = 32, _tick = 19190, _time = 1.6548e+09, train_seconds = 1.9392e+04)
[2022-06-10 01:31:16,922][root][INFO] - Step 72947200 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 72947200, mean_episode_return = 63.64, mean_episode_step = 940.34, total_loss = -170.94, pg_loss = -222.08, baseline_loss = 56.534, entropy_loss = -5.3969, learner_queue_size = 32, _tick = 19196, _time = 1.6548e+09, train_seconds = 1.9397e+04)
[2022-06-10 01:31:21,926][root][INFO] - Step 72967680 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 72967680, mean_episode_return = 39.4, mean_episode_step = 1063.4, total_loss = -54.206, pg_loss = -76.538, baseline_loss = 27.844, entropy_loss = -5.5118, learner_queue_size = 32, _tick = 19202, _time = 1.6548e+09, train_seconds = 1.9402e+04)
[2022-06-10 01:31:26,930][root][INFO] - Step 72988160 @ 4092.8 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (step = 72988160, mean_episode_return = None, mean_episode_step = 1254.8, total_loss = 187.2, pg_loss = 110.22, baseline_loss = 82.533, entropy_loss = -5.5505, learner_queue_size = 32, _tick = 19209, _time = 1.6548e+09, train_seconds = 1.9407e+04)
[2022-06-10 01:31:31,937][root][INFO] - Step 73008640 @ 4090.5 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 73008640, mean_episode_return = 44.036, mean_episode_step = 915.21, total_loss = -103.96, pg_loss = -155.8, baseline_loss = 57.366, entropy_loss = -5.5317, learner_queue_size = 32, _tick = 19217, _time = 1.6548e+09, train_seconds = 1.9412e+04)
[2022-06-10 01:31:36,942][root][INFO] - Step 73026560 @ 3580.2 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 73026560, mean_episode_return = 89.795, mean_episode_step = 832.15, total_loss = 522.67, pg_loss = 384.63, baseline_loss = 143.51, entropy_loss = -5.4665, learner_queue_size = 32, _tick = 19223, _time = 1.6548e+09, train_seconds = 1.9417e+04)
[2022-06-10 01:31:41,946][root][INFO] - Step 73047040 @ 4092.7 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 73047040, mean_episode_return = 114.96, mean_episode_step = 907.7, total_loss = -66.059, pg_loss = -105.18, baseline_loss = 44.441, entropy_loss = -5.3238, learner_queue_size = 32, _tick = 19229, _time = 1.6548e+09, train_seconds = 1.9422e+04)
[2022-06-10 01:31:46,950][root][INFO] - Step 73064960 @ 3581.2 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 73064960, mean_episode_return = 88.52, mean_episode_step = 886.74, total_loss = 711.36, pg_loss = 422.14, baseline_loss = 294.67, entropy_loss = -5.4623, learner_queue_size = 32, _tick = 19235, _time = 1.6548e+09, train_seconds = 1.9427e+04)
[2022-06-10 01:31:51,954][root][INFO] - Step 73085440 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 73085440, mean_episode_return = None, mean_episode_step = 841.84, total_loss = -39.468, pg_loss = -72.008, baseline_loss = 37.863, entropy_loss = -5.3234, learner_queue_size = 32, _tick = 19242, _time = 1.6548e+09, train_seconds = 1.9432e+04)
[2022-06-10 01:31:56,958][root][INFO] - Step 73105920 @ 4092.7 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 73105920, mean_episode_return = None, mean_episode_step = 1136.3, total_loss = -100.81, pg_loss = -126.67, baseline_loss = 31.262, entropy_loss = -5.3989, learner_queue_size = 32, _tick = 19246, _time = 1.6548e+09, train_seconds = 1.9437e+04)
[2022-06-10 01:32:01,962][root][INFO] - Step 73123840 @ 3581.0 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 73123840, mean_episode_return = None, mean_episode_step = 856.0, total_loss = -127.6, pg_loss = -142.98, baseline_loss = 20.813, entropy_loss = -5.4398, learner_queue_size = 32, _tick = 19250, _time = 1.6548e+09, train_seconds = 1.9442e+04)
[2022-06-10 01:32:06,966][root][INFO] - Step 73144320 @ 4092.9 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 73144320, mean_episode_return = None, mean_episode_step = 838.97, total_loss = -18.6, pg_loss = -54.849, baseline_loss = 41.611, entropy_loss = -5.3625, learner_queue_size = 32, _tick = 19256, _time = 1.6548e+09, train_seconds = 1.9447e+04)
[2022-06-10 01:32:11,970][root][INFO] - Step 73164800 @ 4092.6 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 73164800, mean_episode_return = 45.964, mean_episode_step = 1509.4, total_loss = 149.0, pg_loss = 65.52, baseline_loss = 88.728, entropy_loss = -5.2467, learner_queue_size = 32, _tick = 19263, _time = 1.6548e+09, train_seconds = 1.9452e+04)
[2022-06-10 01:32:16,974][root][INFO] - Step 73185280 @ 4092.8 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 73185280, mean_episode_return = 52.862, mean_episode_step = 1015.6, total_loss = -51.549, pg_loss = -80.046, baseline_loss = 33.713, entropy_loss = -5.2164, learner_queue_size = 32, _tick = 19267, _time = 1.6548e+09, train_seconds = 1.9457e+04)
[2022-06-10 01:32:21,978][root][INFO] - Step 73203200 @ 3581.1 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 73203200, mean_episode_return = 88.96, mean_episode_step = 999.59, total_loss = 100.27, pg_loss = 33.458, baseline_loss = 72.17, entropy_loss = -5.3592, learner_queue_size = 32, _tick = 19272, _time = 1.6548e+09, train_seconds = 1.9462e+04)
[2022-06-10 01:32:26,984][root][INFO] - Step 73223680 @ 4091.5 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 73223680, mean_episode_return = 58.439, mean_episode_step = 965.98, total_loss = 16.886, pg_loss = -34.632, baseline_loss = 56.659, entropy_loss = -5.1414, learner_queue_size = 32, _tick = 19279, _time = 1.6548e+09, train_seconds = 1.9467e+04)
[2022-06-10 01:32:31,990][root][INFO] - Step 73244160 @ 4090.7 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 73244160, mean_episode_return = 57.491, mean_episode_step = 942.63, total_loss = -99.631, pg_loss = -204.15, baseline_loss = 109.52, entropy_loss = -5.002, learner_queue_size = 32, _tick = 19286, _time = 1.6548e+09, train_seconds = 1.9472e+04)
[2022-06-10 01:32:36,996][root][INFO] - Step 73262080 @ 3579.8 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 73262080, mean_episode_return = 66.393, mean_episode_step = 1198.9, total_loss = 165.9, pg_loss = 78.506, baseline_loss = 92.649, entropy_loss = -5.2527, learner_queue_size = 32, _tick = 19292, _time = 1.6548e+09, train_seconds = 1.9477e+04)
[2022-06-10 01:32:42,002][root][INFO] - Step 73282560 @ 4091.0 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 73282560, mean_episode_return = 10.02, mean_episode_step = 977.05, total_loss = -133.45, pg_loss = -154.69, baseline_loss = 26.502, entropy_loss = -5.2617, learner_queue_size = 32, _tick = 19300, _time = 1.6548e+09, train_seconds = 1.9482e+04)
[2022-06-10 01:32:47,014][root][INFO] - Step 73303040 @ 4086.2 SPS. Inference batcher size: 83. Learner queue size: 32. Other stats: (step = 73303040, mean_episode_return = 101.2, mean_episode_step = 807.19, total_loss = 328.87, pg_loss = 269.37, baseline_loss = 64.759, entropy_loss = -5.2569, learner_queue_size = 32, _tick = 19307, _time = 1.6548e+09, train_seconds = 1.9487e+04)
[2022-06-10 01:32:52,018][root][INFO] - Step 73323520 @ 4092.7 SPS. Inference batcher size: 96. Learner queue size: 32. Other stats: (step = 73323520, mean_episode_return = 46.241, mean_episode_step = 1597.5, total_loss = 132.82, pg_loss = 66.333, baseline_loss = 71.8, entropy_loss = -5.3091, learner_queue_size = 32, _tick = 19313, _time = 1.6548e+09, train_seconds = 1.9492e+04)
[2022-06-10 01:32:57,022][root][INFO] - Step 73341440 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 73341440, mean_episode_return = 74.086, mean_episode_step = 1201.0, total_loss = -46.491, pg_loss = -114.12, baseline_loss = 72.937, entropy_loss = -5.3103, learner_queue_size = 32, _tick = 19319, _time = 1.6548e+09, train_seconds = 1.9497e+04)
[2022-06-10 01:33:02,026][root][INFO] - Step 73361920 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 73361920, mean_episode_return = 80.689, mean_episode_step = 1153.7, total_loss = 224.91, pg_loss = 68.571, baseline_loss = 161.35, entropy_loss = -5.0103, learner_queue_size = 32, _tick = 19324, _time = 1.6548e+09, train_seconds = 1.9502e+04)
[2022-06-10 01:33:07,032][root][INFO] - Step 73379840 @ 3579.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 73379840, mean_episode_return = 90.46, mean_episode_step = 1046.7, total_loss = -21.739, pg_loss = -63.103, baseline_loss = 46.247, entropy_loss = -4.8826, learner_queue_size = 32, _tick = 19329, _time = 1.6548e+09, train_seconds = 1.9507e+04)
[2022-06-10 01:33:12,038][root][INFO] - Step 73400320 @ 4091.3 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 73400320, mean_episode_return = 115.18, mean_episode_step = 1077.1, total_loss = -72.723, pg_loss = -140.99, baseline_loss = 73.479, entropy_loss = -5.2122, learner_queue_size = 32, _tick = 19335, _time = 1.6548e+09, train_seconds = 1.9512e+04)
[2022-06-10 01:33:17,042][root][INFO] - Step 73420800 @ 4092.7 SPS. Inference batcher size: 79. Learner queue size: 32. Other stats: (step = 73420800, mean_episode_return = 79.369, mean_episode_step = 1036.9, total_loss = 35.219, pg_loss = 1.7635, baseline_loss = 38.681, entropy_loss = -5.225, learner_queue_size = 32, _tick = 19341, _time = 1.6548e+09, train_seconds = 1.9517e+04)
[2022-06-10 01:33:22,046][root][INFO] - Step 73438720 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 73438720, mean_episode_return = 55.22, mean_episode_step = 1212.6, total_loss = -191.63, pg_loss = -233.56, baseline_loss = 47.167, entropy_loss = -5.236, learner_queue_size = 32, _tick = 19348, _time = 1.6548e+09, train_seconds = 1.9522e+04)
[2022-06-10 01:33:27,050][root][INFO] - Step 73459200 @ 4092.8 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 73459200, mean_episode_return = 58.651, mean_episode_step = 1159.8, total_loss = 27.375, pg_loss = -38.543, baseline_loss = 71.208, entropy_loss = -5.2905, learner_queue_size = 32, _tick = 19355, _time = 1.6548e+09, train_seconds = 1.9527e+04)
[2022-06-10 01:33:32,054][root][INFO] - Step 73477120 @ 3581.1 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 73477120, mean_episode_return = 82.323, mean_episode_step = 940.78, total_loss = 279.01, pg_loss = 192.6, baseline_loss = 91.732, entropy_loss = -5.3292, learner_queue_size = 32, _tick = 19361, _time = 1.6548e+09, train_seconds = 1.9532e+04)
[2022-06-10 01:33:37,058][root][INFO] - Step 73497600 @ 4092.6 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 73497600, mean_episode_return = 86.83, mean_episode_step = 867.89, total_loss = 74.838, pg_loss = 22.469, baseline_loss = 57.503, entropy_loss = -5.1349, learner_queue_size = 32, _tick = 19367, _time = 1.6548e+09, train_seconds = 1.9537e+04)
[2022-06-10 01:33:42,064][root][INFO] - Step 73515520 @ 3579.6 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 73515520, mean_episode_return = None, mean_episode_step = 1005.3, total_loss = -63.416, pg_loss = -96.823, baseline_loss = 38.696, entropy_loss = -5.2894, learner_queue_size = 32, _tick = 19372, _time = 1.6548e+09, train_seconds = 1.9542e+04)
[2022-06-10 01:33:47,070][root][INFO] - Step 73536000 @ 4090.9 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 73536000, mean_episode_return = 60.365, mean_episode_step = 1048.7, total_loss = -5.4814, pg_loss = -38.242, baseline_loss = 38.266, entropy_loss = -5.5058, learner_queue_size = 32, _tick = 19379, _time = 1.6548e+09, train_seconds = 1.9547e+04)
[2022-06-10 01:33:52,074][root][INFO] - Step 73556480 @ 4093.1 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 73556480, mean_episode_return = 71.791, mean_episode_step = 870.18, total_loss = 17.724, pg_loss = -31.007, baseline_loss = 53.836, entropy_loss = -5.1056, learner_queue_size = 32, _tick = 19387, _time = 1.6548e+09, train_seconds = 1.9552e+04)
[2022-06-10 01:33:57,078][root][INFO] - Step 73574400 @ 3581.2 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 73574400, mean_episode_return = 65.11, mean_episode_step = 1071.7, total_loss = 64.457, pg_loss = 8.2912, baseline_loss = 61.456, entropy_loss = -5.2904, learner_queue_size = 32, _tick = 19394, _time = 1.6548e+09, train_seconds = 1.9557e+04)
[2022-06-10 01:34:02,083][root][INFO] - Step 73594880 @ 4092.0 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 73594880, mean_episode_return = 83.839, mean_episode_step = 1458.2, total_loss = 458.46, pg_loss = 364.24, baseline_loss = 99.607, entropy_loss = -5.3803, learner_queue_size = 32, _tick = 19401, _time = 1.6548e+09, train_seconds = 1.9562e+04)
[2022-06-10 01:34:07,086][root][INFO] - Step 73615360 @ 4093.5 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 73615360, mean_episode_return = None, mean_episode_step = 916.84, total_loss = -68.66, pg_loss = -108.97, baseline_loss = 45.568, entropy_loss = -5.2626, learner_queue_size = 32, _tick = 19404, _time = 1.6548e+09, train_seconds = 1.9567e+04)
[2022-06-10 01:34:12,090][root][INFO] - Step 73633280 @ 3581.2 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 73633280, mean_episode_return = 18.75, mean_episode_step = 1302.8, total_loss = 105.14, pg_loss = -10.667, baseline_loss = 121.21, entropy_loss = -5.4015, learner_queue_size = 32, _tick = 19408, _time = 1.6548e+09, train_seconds = 1.9572e+04)
[2022-06-10 01:34:17,094][root][INFO] - Step 73653760 @ 4092.7 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (step = 73653760, mean_episode_return = 101.16, mean_episode_step = 1155.1, total_loss = 117.35, pg_loss = 59.658, baseline_loss = 63.091, entropy_loss = -5.4011, learner_queue_size = 32, _tick = 19412, _time = 1.6548e+09, train_seconds = 1.9577e+04)
[2022-06-10 01:34:22,099][root][INFO] - Step 73674240 @ 4091.9 SPS. Inference batcher size: 78. Learner queue size: 32. Other stats: (step = 73674240, mean_episode_return = None, mean_episode_step = 1035.6, total_loss = 202.84, pg_loss = 129.83, baseline_loss = 78.445, entropy_loss = -5.4372, learner_queue_size = 32, _tick = 19419, _time = 1.6548e+09, train_seconds = 1.9582e+04)
[2022-06-10 01:34:27,102][root][INFO] - Step 73694720 @ 4093.6 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 73694720, mean_episode_return = 56.134, mean_episode_step = 844.0, total_loss = 55.09, pg_loss = -15.411, baseline_loss = 75.822, entropy_loss = -5.3207, learner_queue_size = 32, _tick = 19425, _time = 1.6548e+09, train_seconds = 1.9587e+04)
[2022-06-10 01:34:32,106][root][INFO] - Step 73712640 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 73712640, mean_episode_return = None, mean_episode_step = 804.31, total_loss = -62.313, pg_loss = -126.03, baseline_loss = 69.028, entropy_loss = -5.3087, learner_queue_size = 32, _tick = 19431, _time = 1.6548e+09, train_seconds = 1.9592e+04)
[2022-06-10 01:34:37,110][root][INFO] - Step 73733120 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 73733120, mean_episode_return = 14.52, mean_episode_step = 981.48, total_loss = 37.776, pg_loss = -21.593, baseline_loss = 64.76, entropy_loss = -5.3912, learner_queue_size = 32, _tick = 19437, _time = 1.6548e+09, train_seconds = 1.9597e+04)
[2022-06-10 01:34:42,114][root][INFO] - Step 73751040 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 73751040, mean_episode_return = 61.09, mean_episode_step = 889.7, total_loss = -25.527, pg_loss = -71.952, baseline_loss = 51.739, entropy_loss = -5.3143, learner_queue_size = 32, _tick = 19444, _time = 1.6548e+09, train_seconds = 1.9602e+04)
[2022-06-10 01:34:47,118][root][INFO] - Step 73771520 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 73771520, mean_episode_return = 50.686, mean_episode_step = 827.92, total_loss = 391.91, pg_loss = 274.44, baseline_loss = 122.74, entropy_loss = -5.2691, learner_queue_size = 32, _tick = 19449, _time = 1.6548e+09, train_seconds = 1.9607e+04)
[2022-06-10 01:34:52,123][root][INFO] - Step 73789440 @ 3580.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 73789440, mean_episode_return = 18.04, mean_episode_step = 861.04, total_loss = -39.891, pg_loss = -93.405, baseline_loss = 58.924, entropy_loss = -5.4102, learner_queue_size = 32, _tick = 19455, _time = 1.6548e+09, train_seconds = 1.9612e+04)
[2022-06-10 01:34:57,126][root][INFO] - Step 73809920 @ 4093.3 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 73809920, mean_episode_return = 31.62, mean_episode_step = 963.56, total_loss = 182.67, pg_loss = 120.43, baseline_loss = 67.586, entropy_loss = -5.3503, learner_queue_size = 32, _tick = 19461, _time = 1.6548e+09, train_seconds = 1.9617e+04)
[2022-06-10 01:35:02,130][root][INFO] - Step 73830400 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 73830400, mean_episode_return = None, mean_episode_step = 1062.3, total_loss = 71.0, pg_loss = 25.934, baseline_loss = 50.547, entropy_loss = -5.4803, learner_queue_size = 32, _tick = 19467, _time = 1.6548e+09, train_seconds = 1.9622e+04)
[2022-06-10 01:35:07,134][root][INFO] - Step 73850880 @ 4092.7 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 73850880, mean_episode_return = 135.84, mean_episode_step = 1105.7, total_loss = 134.31, pg_loss = 93.299, baseline_loss = 46.491, entropy_loss = -5.4845, learner_queue_size = 32, _tick = 19474, _time = 1.6548e+09, train_seconds = 1.9627e+04)
[2022-06-10 01:35:12,138][root][INFO] - Step 73868800 @ 3581.2 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 73868800, mean_episode_return = None, mean_episode_step = 803.75, total_loss = 125.05, pg_loss = 67.167, baseline_loss = 63.352, entropy_loss = -5.4704, learner_queue_size = 32, _tick = 19480, _time = 1.6548e+09, train_seconds = 1.9632e+04)
[2022-06-10 01:35:17,142][root][INFO] - Step 73889280 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 73889280, mean_episode_return = 57.7, mean_episode_step = 799.0, total_loss = 96.398, pg_loss = 36.134, baseline_loss = 65.714, entropy_loss = -5.45, learner_queue_size = 32, _tick = 19487, _time = 1.6548e+09, train_seconds = 1.9637e+04)
[2022-06-10 01:35:22,146][root][INFO] - Step 73909760 @ 4092.8 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 73909760, mean_episode_return = None, mean_episode_step = 1401.2, total_loss = 413.27, pg_loss = 310.68, baseline_loss = 107.99, entropy_loss = -5.3964, learner_queue_size = 32, _tick = 19493, _time = 1.6548e+09, train_seconds = 1.9642e+04)
[2022-06-10 01:35:27,150][root][INFO] - Step 73930240 @ 4092.6 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 73930240, mean_episode_return = None, mean_episode_step = 902.03, total_loss = -60.169, pg_loss = -81.347, baseline_loss = 26.481, entropy_loss = -5.3028, learner_queue_size = 32, _tick = 19500, _time = 1.6548e+09, train_seconds = 1.9647e+04)
[2022-06-10 01:35:32,158][root][INFO] - Step 73950720 @ 4089.5 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 73950720, mean_episode_return = 45.99, mean_episode_step = 766.92, total_loss = 117.36, pg_loss = 22.063, baseline_loss = 100.62, entropy_loss = -5.3267, learner_queue_size = 32, _tick = 19504, _time = 1.6548e+09, train_seconds = 1.9652e+04)
[2022-06-10 01:35:37,162][root][INFO] - Step 73971200 @ 4092.8 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 73971200, mean_episode_return = 68.71, mean_episode_step = 1077.0, total_loss = 526.73, pg_loss = 371.07, baseline_loss = 161.18, entropy_loss = -5.5146, learner_queue_size = 32, _tick = 19512, _time = 1.6548e+09, train_seconds = 1.9657e+04)
[2022-06-10 01:35:42,166][root][INFO] - Step 73989120 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 73989120, mean_episode_return = 74.774, mean_episode_step = 786.12, total_loss = -101.41, pg_loss = -132.74, baseline_loss = 36.757, entropy_loss = -5.4211, learner_queue_size = 32, _tick = 19516, _time = 1.6548e+09, train_seconds = 1.9662e+04)
[2022-06-10 01:35:47,170][root][INFO] - Step 74009600 @ 4092.8 SPS. Inference batcher size: 91. Learner queue size: 32. Other stats: (step = 74009600, mean_episode_return = 24.355, mean_episode_step = 920.96, total_loss = 96.018, pg_loss = 18.154, baseline_loss = 83.192, entropy_loss = -5.3281, learner_queue_size = 32, _tick = 19523, _time = 1.6548e+09, train_seconds = 1.9667e+04)
[2022-06-10 01:35:52,174][root][INFO] - Step 74027520 @ 3581.1 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 74027520, mean_episode_return = None, mean_episode_step = 1598.8, total_loss = 67.838, pg_loss = 27.369, baseline_loss = 45.852, entropy_loss = -5.3825, learner_queue_size = 32, _tick = 19528, _time = 1.6548e+09, train_seconds = 1.9672e+04)
[2022-06-10 01:35:57,180][root][INFO] - Step 74048000 @ 4092.0 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 74048000, mean_episode_return = 42.476, mean_episode_step = 1325.7, total_loss = 317.73, pg_loss = 239.53, baseline_loss = 83.587, entropy_loss = -5.3906, learner_queue_size = 32, _tick = 19536, _time = 1.6548e+09, train_seconds = 1.9677e+04)
[2022-06-10 01:36:02,186][root][INFO] - Step 74068480 @ 4089.9 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (step = 74068480, mean_episode_return = 104.19, mean_episode_step = 840.71, total_loss = -101.45, pg_loss = -146.97, baseline_loss = 50.922, entropy_loss = -5.3972, learner_queue_size = 32, _tick = 19544, _time = 1.6548e+09, train_seconds = 1.9682e+04)
[2022-06-10 01:36:07,193][root][INFO] - Step 74086400 @ 3579.4 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 74086400, mean_episode_return = None, mean_episode_step = 1178.2, total_loss = -67.908, pg_loss = -93.964, baseline_loss = 31.59, entropy_loss = -5.5338, learner_queue_size = 32, _tick = 19549, _time = 1.6548e+09, train_seconds = 1.9687e+04)
[2022-06-10 01:36:12,198][root][INFO] - Step 74106880 @ 4091.7 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 74106880, mean_episode_return = 56.25, mean_episode_step = 1026.8, total_loss = 232.19, pg_loss = 154.61, baseline_loss = 82.945, entropy_loss = -5.3603, learner_queue_size = 32, _tick = 19555, _time = 1.6548e+09, train_seconds = 1.9692e+04)
[2022-06-10 01:36:17,204][root][INFO] - Step 74127360 @ 4091.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 74127360, mean_episode_return = 83.92, mean_episode_step = 1081.8, total_loss = 69.79, pg_loss = -9.4336, baseline_loss = 84.583, entropy_loss = -5.3598, learner_queue_size = 32, _tick = 19560, _time = 1.6548e+09, train_seconds = 1.9697e+04)
[2022-06-10 01:36:22,210][root][INFO] - Step 74145280 @ 3579.7 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 74145280, mean_episode_return = None, mean_episode_step = 975.31, total_loss = 546.51, pg_loss = 325.4, baseline_loss = 226.33, entropy_loss = -5.2221, learner_queue_size = 32, _tick = 19564, _time = 1.6548e+09, train_seconds = 1.9702e+04)
[2022-06-10 01:36:27,214][root][INFO] - Step 74165760 @ 4092.7 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 74165760, mean_episode_return = 67.6, mean_episode_step = 1004.5, total_loss = -124.12, pg_loss = -154.44, baseline_loss = 35.674, entropy_loss = -5.3554, learner_queue_size = 32, _tick = 19568, _time = 1.6548e+09, train_seconds = 1.9707e+04)
[2022-06-10 01:36:32,218][root][INFO] - Step 74183680 @ 3581.2 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 74183680, mean_episode_return = 16.69, mean_episode_step = 1334.1, total_loss = 36.5, pg_loss = -23.595, baseline_loss = 65.467, entropy_loss = -5.3716, learner_queue_size = 32, _tick = 19573, _time = 1.6548e+09, train_seconds = 1.9712e+04)
[2022-06-10 01:36:37,222][root][INFO] - Step 74204160 @ 4092.5 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 74204160, mean_episode_return = 33.15, mean_episode_step = 882.57, total_loss = 33.023, pg_loss = -56.787, baseline_loss = 94.974, entropy_loss = -5.1653, learner_queue_size = 32, _tick = 19577, _time = 1.6548e+09, train_seconds = 1.9717e+04)
[2022-06-10 01:36:42,228][root][INFO] - Step 74224640 @ 4091.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 74224640, mean_episode_return = 56.617, mean_episode_step = 958.82, total_loss = 87.72, pg_loss = -18.848, baseline_loss = 111.81, entropy_loss = -5.2435, learner_queue_size = 32, _tick = 19583, _time = 1.6548e+09, train_seconds = 1.9722e+04)
[2022-06-10 01:36:47,234][root][INFO] - Step 74242560 @ 3579.9 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 74242560, mean_episode_return = 61.993, mean_episode_step = 839.77, total_loss = -225.04, pg_loss = -281.07, baseline_loss = 61.305, entropy_loss = -5.2793, learner_queue_size = 32, _tick = 19589, _time = 1.6548e+09, train_seconds = 1.9727e+04)
[2022-06-10 01:36:52,238][root][INFO] - Step 74263040 @ 4092.7 SPS. Inference batcher size: 96. Learner queue size: 32. Other stats: (step = 74263040, mean_episode_return = 75.025, mean_episode_step = 832.49, total_loss = -211.5, pg_loss = -232.39, baseline_loss = 26.275, entropy_loss = -5.3885, learner_queue_size = 32, _tick = 19595, _time = 1.6548e+09, train_seconds = 1.9732e+04)
[2022-06-10 01:36:57,242][root][INFO] - Step 74283520 @ 4092.5 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 74283520, mean_episode_return = 66.201, mean_episode_step = 1142.6, total_loss = -149.94, pg_loss = -153.54, baseline_loss = 9.0678, entropy_loss = -5.47, learner_queue_size = 32, _tick = 19602, _time = 1.6548e+09, train_seconds = 1.9737e+04)
[2022-06-10 01:37:02,246][root][INFO] - Step 74301440 @ 3581.2 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 74301440, mean_episode_return = None, mean_episode_step = 1157.9, total_loss = 61.34, pg_loss = 18.499, baseline_loss = 48.324, entropy_loss = -5.4833, learner_queue_size = 32, _tick = 19607, _time = 1.6548e+09, train_seconds = 1.9742e+04)
[2022-06-10 01:37:07,250][root][INFO] - Step 74321920 @ 4092.8 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 74321920, mean_episode_return = 78.367, mean_episode_step = 1505.4, total_loss = -101.17, pg_loss = -119.14, baseline_loss = 23.427, entropy_loss = -5.4636, learner_queue_size = 32, _tick = 19614, _time = 1.6548e+09, train_seconds = 1.9747e+04)
[2022-06-10 01:37:12,254][root][INFO] - Step 74342400 @ 4092.8 SPS. Inference batcher size: 103. Learner queue size: 32. Other stats: (step = 74342400, mean_episode_return = 78.629, mean_episode_step = 781.27, total_loss = 252.91, pg_loss = 210.54, baseline_loss = 47.773, entropy_loss = -5.4021, learner_queue_size = 32, _tick = 19619, _time = 1.6548e+09, train_seconds = 1.9752e+04)
[2022-06-10 01:37:17,258][root][INFO] - Step 74360320 @ 3581.1 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (step = 74360320, mean_episode_return = None, mean_episode_step = 1086.2, total_loss = 147.06, pg_loss = 90.653, baseline_loss = 61.648, entropy_loss = -5.2408, learner_queue_size = 32, _tick = 19625, _time = 1.6548e+09, train_seconds = 1.9757e+04)
[2022-06-10 01:37:22,262][root][INFO] - Step 74380800 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 74380800, mean_episode_return = 17.3, mean_episode_step = 809.51, total_loss = 148.89, pg_loss = 101.07, baseline_loss = 52.841, entropy_loss = -5.0234, learner_queue_size = 32, _tick = 19633, _time = 1.6548e+09, train_seconds = 1.9762e+04)
[2022-06-10 01:37:27,266][root][INFO] - Step 74401280 @ 4092.7 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 74401280, mean_episode_return = 43.459, mean_episode_step = 1217.2, total_loss = 57.419, pg_loss = -14.491, baseline_loss = 77.088, entropy_loss = -5.1778, learner_queue_size = 32, _tick = 19641, _time = 1.6548e+09, train_seconds = 1.9767e+04)
[2022-06-10 01:37:32,270][root][INFO] - Step 74419200 @ 3581.2 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 74419200, mean_episode_return = None, mean_episode_step = 1112.5, total_loss = 92.849, pg_loss = 58.017, baseline_loss = 40.291, entropy_loss = -5.4588, learner_queue_size = 32, _tick = 19646, _time = 1.6548e+09, train_seconds = 1.9772e+04)
[2022-06-10 01:37:37,274][root][INFO] - Step 74439680 @ 4092.7 SPS. Inference batcher size: 80. Learner queue size: 32. Other stats: (step = 74439680, mean_episode_return = 5.5499, mean_episode_step = 1276.8, total_loss = -16.662, pg_loss = -51.616, baseline_loss = 40.476, entropy_loss = -5.522, learner_queue_size = 32, _tick = 19653, _time = 1.6548e+09, train_seconds = 1.9777e+04)
[2022-06-10 01:37:42,278][root][INFO] - Step 74457600 @ 3581.1 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 74457600, mean_episode_return = None, mean_episode_step = 1118.0, total_loss = 222.75, pg_loss = 164.89, baseline_loss = 63.205, entropy_loss = -5.344, learner_queue_size = 32, _tick = 19658, _time = 1.6548e+09, train_seconds = 1.9782e+04)
[2022-06-10 01:37:47,282][root][INFO] - Step 74478080 @ 4092.5 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 74478080, mean_episode_return = 80.159, mean_episode_step = 863.63, total_loss = 167.58, pg_loss = 127.8, baseline_loss = 45.19, entropy_loss = -5.4133, learner_queue_size = 32, _tick = 19666, _time = 1.6548e+09, train_seconds = 1.9787e+04)
[2022-06-10 01:37:52,286][root][INFO] - Step 74498560 @ 4093.0 SPS. Inference batcher size: 75. Learner queue size: 32. Other stats: (step = 74498560, mean_episode_return = 49.831, mean_episode_step = 873.83, total_loss = 307.45, pg_loss = 218.93, baseline_loss = 93.906, entropy_loss = -5.3805, learner_queue_size = 32, _tick = 19673, _time = 1.6548e+09, train_seconds = 1.9792e+04)
[2022-06-10 01:37:57,290][root][INFO] - Step 74516480 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 74516480, mean_episode_return = 55.78, mean_episode_step = 844.61, total_loss = 18.87, pg_loss = -18.512, baseline_loss = 42.842, entropy_loss = -5.4601, learner_queue_size = 32, _tick = 19678, _time = 1.6548e+09, train_seconds = 1.9797e+04)
[2022-06-10 01:38:02,294][root][INFO] - Step 74536960 @ 4092.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 74536960, mean_episode_return = None, mean_episode_step = 961.44, total_loss = 606.6, pg_loss = 456.72, baseline_loss = 155.39, entropy_loss = -5.5062, learner_queue_size = 32, _tick = 19684, _time = 1.6548e+09, train_seconds = 1.9802e+04)
[2022-06-10 01:38:07,298][root][INFO] - Step 74557440 @ 4092.8 SPS. Inference batcher size: 85. Learner queue size: 32. Other stats: (step = 74557440, mean_episode_return = 53.561, mean_episode_step = 1682.3, total_loss = 330.39, pg_loss = 242.28, baseline_loss = 93.596, entropy_loss = -5.4854, learner_queue_size = 32, _tick = 19692, _time = 1.6548e+09, train_seconds = 1.9807e+04)
[2022-06-10 01:38:12,302][root][INFO] - Step 74575360 @ 3581.1 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (step = 74575360, mean_episode_return = 161.86, mean_episode_step = 1008.0, total_loss = 138.82, pg_loss = 61.744, baseline_loss = 82.401, entropy_loss = -5.3274, learner_queue_size = 32, _tick = 19698, _time = 1.6548e+09, train_seconds = 1.9812e+04)
[2022-06-10 01:38:17,306][root][INFO] - Step 74595840 @ 4092.7 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 74595840, mean_episode_return = 54.92, mean_episode_step = 1041.8, total_loss = 38.616, pg_loss = -4.919, baseline_loss = 48.896, entropy_loss = -5.3616, learner_queue_size = 32, _tick = 19705, _time = 1.6548e+09, train_seconds = 1.9817e+04)
[2022-06-10 01:38:22,310][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 01:38:22,445][root][INFO] - Step 74616320 @ 4092.9 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 74616320, mean_episode_return = 55.711, mean_episode_step = 1387.9, total_loss = -10.363, pg_loss = -39.204, baseline_loss = 34.116, entropy_loss = -5.2753, learner_queue_size = 32, _tick = 19711, _time = 1.6548e+09, train_seconds = 1.9822e+04)
[2022-06-10 01:38:27,450][root][INFO] - Step 74636800 @ 3984.4 SPS. Inference batcher size: 101. Learner queue size: 32. Other stats: (step = 74636800, mean_episode_return = None, mean_episode_step = 1355.3, total_loss = 4.4455, pg_loss = -27.552, baseline_loss = 37.194, entropy_loss = -5.1962, learner_queue_size = 32, _tick = 19718, _time = 1.6548e+09, train_seconds = 1.9827e+04)
[2022-06-10 01:38:32,454][root][INFO] - Step 74654720 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 74654720, mean_episode_return = 52.915, mean_episode_step = 964.27, total_loss = -93.008, pg_loss = -119.15, baseline_loss = 31.484, entropy_loss = -5.3418, learner_queue_size = 32, _tick = 19724, _time = 1.6548e+09, train_seconds = 1.9832e+04)
[2022-06-10 01:38:37,458][root][INFO] - Step 74675200 @ 4092.8 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 74675200, mean_episode_return = 70.171, mean_episode_step = 1327.6, total_loss = 78.788, pg_loss = 30.251, baseline_loss = 53.975, entropy_loss = -5.4382, learner_queue_size = 32, _tick = 19728, _time = 1.6548e+09, train_seconds = 1.9837e+04)
[2022-06-10 01:38:42,462][root][INFO] - Step 74695680 @ 4092.6 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 74695680, mean_episode_return = 62.871, mean_episode_step = 1024.7, total_loss = -137.7, pg_loss = -154.39, baseline_loss = 22.208, entropy_loss = -5.5191, learner_queue_size = 32, _tick = 19735, _time = 1.6548e+09, train_seconds = 1.9842e+04)
[2022-06-10 01:38:47,468][root][INFO] - Step 74713600 @ 3579.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 74713600, mean_episode_return = 18.93, mean_episode_step = 1233.3, total_loss = 120.11, pg_loss = 80.353, baseline_loss = 45.274, entropy_loss = -5.5173, learner_queue_size = 32, _tick = 19742, _time = 1.6548e+09, train_seconds = 1.9847e+04)
[2022-06-10 01:38:52,474][root][INFO] - Step 74734080 @ 4091.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 74734080, mean_episode_return = 163.17, mean_episode_step = 931.87, total_loss = 115.36, pg_loss = 66.218, baseline_loss = 54.582, entropy_loss = -5.4358, learner_queue_size = 32, _tick = 19749, _time = 1.6548e+09, train_seconds = 1.9852e+04)
[2022-06-10 01:38:57,478][root][INFO] - Step 74754560 @ 4092.8 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 74754560, mean_episode_return = None, mean_episode_step = 941.66, total_loss = 241.16, pg_loss = 182.93, baseline_loss = 63.72, entropy_loss = -5.486, learner_queue_size = 32, _tick = 19753, _time = 1.6548e+09, train_seconds = 1.9857e+04)
[2022-06-10 01:39:02,482][root][INFO] - Step 74775040 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 74775040, mean_episode_return = 36.045, mean_episode_step = 1110.0, total_loss = -63.231, pg_loss = -97.298, baseline_loss = 39.461, entropy_loss = -5.3944, learner_queue_size = 32, _tick = 19759, _time = 1.6548e+09, train_seconds = 1.9862e+04)
[2022-06-10 01:39:07,486][root][INFO] - Step 74792960 @ 3581.2 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (step = 74792960, mean_episode_return = 27.416, mean_episode_step = 876.29, total_loss = 465.73, pg_loss = 315.3, baseline_loss = 155.8, entropy_loss = -5.3754, learner_queue_size = 32, _tick = 19766, _time = 1.6548e+09, train_seconds = 1.9867e+04)
[2022-06-10 01:39:12,494][root][INFO] - Step 74813440 @ 4089.2 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 74813440, mean_episode_return = 31.38, mean_episode_step = 1052.1, total_loss = 103.87, pg_loss = -17.36, baseline_loss = 126.7, entropy_loss = -5.4737, learner_queue_size = 32, _tick = 19771, _time = 1.6548e+09, train_seconds = 1.9872e+04)
[2022-06-10 01:39:17,498][root][INFO] - Step 74831360 @ 3581.3 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 74831360, mean_episode_return = 59.241, mean_episode_step = 1163.0, total_loss = 281.82, pg_loss = 181.49, baseline_loss = 105.78, entropy_loss = -5.4538, learner_queue_size = 32, _tick = 19777, _time = 1.6548e+09, train_seconds = 1.9877e+04)
[2022-06-10 01:39:22,502][root][INFO] - Step 74851840 @ 4092.8 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 74851840, mean_episode_return = 4.1, mean_episode_step = 1653.7, total_loss = -167.74, pg_loss = -190.65, baseline_loss = 28.338, entropy_loss = -5.4311, learner_queue_size = 32, _tick = 19783, _time = 1.6548e+09, train_seconds = 1.9882e+04)
[2022-06-10 01:39:27,506][root][INFO] - Step 74869760 @ 3581.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 74869760, mean_episode_return = None, mean_episode_step = 947.44, total_loss = 94.009, pg_loss = 56.993, baseline_loss = 42.257, entropy_loss = -5.2404, learner_queue_size = 32, _tick = 19786, _time = 1.6548e+09, train_seconds = 1.9887e+04)
[2022-06-10 01:39:32,510][root][INFO] - Step 74890240 @ 4092.8 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 74890240, mean_episode_return = 30.46, mean_episode_step = 1178.2, total_loss = 54.419, pg_loss = -19.008, baseline_loss = 78.501, entropy_loss = -5.0744, learner_queue_size = 32, _tick = 19791, _time = 1.6548e+09, train_seconds = 1.9892e+04)
[2022-06-10 01:39:37,514][root][INFO] - Step 74910720 @ 4092.7 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 74910720, mean_episode_return = 45.75, mean_episode_step = 1060.5, total_loss = 206.44, pg_loss = 110.13, baseline_loss = 101.57, entropy_loss = -5.2682, learner_queue_size = 32, _tick = 19798, _time = 1.6548e+09, train_seconds = 1.9897e+04)
[2022-06-10 01:39:42,518][root][INFO] - Step 74928640 @ 3581.2 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 74928640, mean_episode_return = 129.0, mean_episode_step = 752.31, total_loss = -110.64, pg_loss = -132.3, baseline_loss = 27.036, entropy_loss = -5.3703, learner_queue_size = 32, _tick = 19804, _time = 1.6548e+09, train_seconds = 1.9902e+04)
[2022-06-10 01:39:47,522][root][INFO] - Step 74949120 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 74949120, mean_episode_return = None, mean_episode_step = 1008.2, total_loss = -63.504, pg_loss = -77.81, baseline_loss = 19.685, entropy_loss = -5.3793, learner_queue_size = 32, _tick = 19809, _time = 1.6548e+09, train_seconds = 1.9907e+04)
[2022-06-10 01:39:52,526][root][INFO] - Step 74969600 @ 4092.6 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 74969600, mean_episode_return = 75.266, mean_episode_step = 1560.0, total_loss = -192.13, pg_loss = -205.81, baseline_loss = 19.248, entropy_loss = -5.5746, learner_queue_size = 32, _tick = 19817, _time = 1.6548e+09, train_seconds = 1.9912e+04)
[2022-06-10 01:39:57,530][root][INFO] - Step 74990080 @ 4092.8 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 74990080, mean_episode_return = 20.665, mean_episode_step = 1081.3, total_loss = 89.585, pg_loss = 12.563, baseline_loss = 82.507, entropy_loss = -5.4846, learner_queue_size = 32, _tick = 19822, _time = 1.6548e+09, train_seconds = 1.9917e+04)
[2022-06-10 01:40:02,534][root][INFO] - Step 75008000 @ 3581.0 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 75008000, mean_episode_return = 35.17, mean_episode_step = 1024.6, total_loss = -183.43, pg_loss = -197.54, baseline_loss = 19.531, entropy_loss = -5.4181, learner_queue_size = 32, _tick = 19827, _time = 1.6548e+09, train_seconds = 1.9922e+04)
[2022-06-10 01:40:07,539][root][INFO] - Step 75028480 @ 4092.5 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 75028480, mean_episode_return = 71.92, mean_episode_step = 1187.0, total_loss = -69.899, pg_loss = -89.473, baseline_loss = 24.789, entropy_loss = -5.2148, learner_queue_size = 32, _tick = 19834, _time = 1.6548e+09, train_seconds = 1.9927e+04)
[2022-06-10 01:40:12,543][root][INFO] - Step 75046400 @ 3581.1 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 75046400, mean_episode_return = 101.13, mean_episode_step = 1059.3, total_loss = -26.748, pg_loss = -62.928, baseline_loss = 41.541, entropy_loss = -5.3615, learner_queue_size = 32, _tick = 19840, _time = 1.6548e+09, train_seconds = 1.9932e+04)
[2022-06-10 01:40:17,546][root][INFO] - Step 75066880 @ 4093.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 75066880, mean_episode_return = 16.77, mean_episode_step = 1506.5, total_loss = -273.56, pg_loss = -286.2, baseline_loss = 18.164, entropy_loss = -5.5243, learner_queue_size = 32, _tick = 19847, _time = 1.6548e+09, train_seconds = 1.9937e+04)
[2022-06-10 01:40:22,550][root][INFO] - Step 75084800 @ 3581.5 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 75084800, mean_episode_return = 122.6, mean_episode_step = 1028.3, total_loss = -128.53, pg_loss = -154.87, baseline_loss = 31.745, entropy_loss = -5.4085, learner_queue_size = 32, _tick = 19853, _time = 1.6548e+09, train_seconds = 1.9942e+04)
[2022-06-10 01:40:27,554][root][INFO] - Step 75105280 @ 4092.4 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 75105280, mean_episode_return = 57.633, mean_episode_step = 1205.9, total_loss = -127.08, pg_loss = -185.49, baseline_loss = 63.645, entropy_loss = -5.2389, learner_queue_size = 32, _tick = 19860, _time = 1.6548e+09, train_seconds = 1.9947e+04)
[2022-06-10 01:40:32,558][root][INFO] - Step 75125760 @ 4092.7 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 75125760, mean_episode_return = 86.131, mean_episode_step = 943.41, total_loss = 222.07, pg_loss = 156.32, baseline_loss = 71.188, entropy_loss = -5.4341, learner_queue_size = 32, _tick = 19864, _time = 1.6548e+09, train_seconds = 1.9952e+04)
[2022-06-10 01:40:37,562][root][INFO] - Step 75143680 @ 3581.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 75143680, mean_episode_return = 5.0497, mean_episode_step = 1091.7, total_loss = 226.3, pg_loss = 122.25, baseline_loss = 109.47, entropy_loss = -5.414, learner_queue_size = 32, _tick = 19871, _time = 1.6548e+09, train_seconds = 1.9957e+04)
[2022-06-10 01:40:42,566][root][INFO] - Step 75164160 @ 4092.7 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 75164160, mean_episode_return = 35.716, mean_episode_step = 1303.7, total_loss = -38.38, pg_loss = -95.338, baseline_loss = 62.26, entropy_loss = -5.3012, learner_queue_size = 32, _tick = 19878, _time = 1.6548e+09, train_seconds = 1.9962e+04)
[2022-06-10 01:40:47,571][root][INFO] - Step 75184640 @ 4092.3 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 75184640, mean_episode_return = -1.49, mean_episode_step = 1245.0, total_loss = 37.274, pg_loss = -27.329, baseline_loss = 69.804, entropy_loss = -5.201, learner_queue_size = 32, _tick = 19886, _time = 1.6548e+09, train_seconds = 1.9967e+04)
[2022-06-10 01:40:52,574][root][INFO] - Step 75202560 @ 3581.6 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 75202560, mean_episode_return = 27.45, mean_episode_step = 1187.1, total_loss = 177.83, pg_loss = 93.399, baseline_loss = 89.806, entropy_loss = -5.3722, learner_queue_size = 32, _tick = 19892, _time = 1.6548e+09, train_seconds = 1.9972e+04)
[2022-06-10 01:40:57,578][root][INFO] - Step 75223040 @ 4092.7 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 75223040, mean_episode_return = 78.552, mean_episode_step = 1076.0, total_loss = 79.563, pg_loss = 15.424, baseline_loss = 69.673, entropy_loss = -5.5344, learner_queue_size = 32, _tick = 19898, _time = 1.6548e+09, train_seconds = 1.9977e+04)
[2022-06-10 01:41:02,582][root][INFO] - Step 75240960 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 75240960, mean_episode_return = None, mean_episode_step = 1494.4, total_loss = -113.75, pg_loss = -122.61, baseline_loss = 14.415, entropy_loss = -5.5562, learner_queue_size = 32, _tick = 19901, _time = 1.6548e+09, train_seconds = 1.9982e+04)
[2022-06-10 01:41:07,586][root][INFO] - Step 75261440 @ 4092.6 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 75261440, mean_episode_return = 61.672, mean_episode_step = 1062.6, total_loss = 148.23, pg_loss = 79.547, baseline_loss = 74.072, entropy_loss = -5.3854, learner_queue_size = 32, _tick = 19906, _time = 1.6548e+09, train_seconds = 1.9987e+04)
[2022-06-10 01:41:12,590][root][INFO] - Step 75281920 @ 4092.8 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 75281920, mean_episode_return = 97.185, mean_episode_step = 936.93, total_loss = 210.86, pg_loss = 134.59, baseline_loss = 81.76, entropy_loss = -5.4931, learner_queue_size = 32, _tick = 19911, _time = 1.6548e+09, train_seconds = 1.9992e+04)
[2022-06-10 01:41:17,594][root][INFO] - Step 75299840 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 75299840, mean_episode_return = None, mean_episode_step = 905.38, total_loss = 93.862, pg_loss = 44.687, baseline_loss = 54.603, entropy_loss = -5.4273, learner_queue_size = 32, _tick = 19915, _time = 1.6548e+09, train_seconds = 1.9997e+04)
[2022-06-10 01:41:22,598][root][INFO] - Step 75320320 @ 4092.8 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 75320320, mean_episode_return = 50.396, mean_episode_step = 1607.3, total_loss = 145.54, pg_loss = 83.55, baseline_loss = 67.459, entropy_loss = -5.4732, learner_queue_size = 32, _tick = 19922, _time = 1.6548e+09, train_seconds = 2.0002e+04)
[2022-06-10 01:41:27,602][root][INFO] - Step 75338240 @ 3580.9 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 75338240, mean_episode_return = 53.221, mean_episode_step = 1090.7, total_loss = 188.44, pg_loss = 133.91, baseline_loss = 59.9, entropy_loss = -5.3739, learner_queue_size = 32, _tick = 19927, _time = 1.6548e+09, train_seconds = 2.0007e+04)
[2022-06-10 01:41:32,606][root][INFO] - Step 75358720 @ 4093.1 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 75358720, mean_episode_return = 39.64, mean_episode_step = 1571.2, total_loss = 76.078, pg_loss = 21.851, baseline_loss = 59.519, entropy_loss = -5.2918, learner_queue_size = 32, _tick = 19934, _time = 1.6548e+09, train_seconds = 2.0012e+04)
[2022-06-10 01:41:37,610][root][INFO] - Step 75376640 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 75376640, mean_episode_return = 29.32, mean_episode_step = 993.91, total_loss = 219.24, pg_loss = 147.71, baseline_loss = 76.761, entropy_loss = -5.2335, learner_queue_size = 32, _tick = 19939, _time = 1.6548e+09, train_seconds = 2.0017e+04)
[2022-06-10 01:41:42,614][root][INFO] - Step 75397120 @ 4092.7 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 75397120, mean_episode_return = None, mean_episode_step = 1655.6, total_loss = 161.82, pg_loss = 109.44, baseline_loss = 57.727, entropy_loss = -5.348, learner_queue_size = 32, _tick = 19945, _time = 1.6548e+09, train_seconds = 2.0022e+04)
[2022-06-10 01:41:47,618][root][INFO] - Step 75415040 @ 3581.1 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 75415040, mean_episode_return = -2.73, mean_episode_step = 858.93, total_loss = 118.82, pg_loss = 24.576, baseline_loss = 99.535, entropy_loss = -5.2905, learner_queue_size = 32, _tick = 19951, _time = 1.6548e+09, train_seconds = 2.0027e+04)
[2022-06-10 01:41:52,622][root][INFO] - Step 75435520 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 75435520, mean_episode_return = 83.025, mean_episode_step = 1111.7, total_loss = -89.25, pg_loss = -132.9, baseline_loss = 49.021, entropy_loss = -5.3667, learner_queue_size = 32, _tick = 19956, _time = 1.6548e+09, train_seconds = 2.0032e+04)
[2022-06-10 01:41:57,626][root][INFO] - Step 75456000 @ 4092.6 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 75456000, mean_episode_return = None, mean_episode_step = 964.38, total_loss = 46.198, pg_loss = -34.225, baseline_loss = 85.706, entropy_loss = -5.2833, learner_queue_size = 32, _tick = 19962, _time = 1.6548e+09, train_seconds = 2.0037e+04)
[2022-06-10 01:42:02,630][root][INFO] - Step 75476480 @ 4092.9 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 75476480, mean_episode_return = 44.42, mean_episode_step = 927.6, total_loss = -133.35, pg_loss = -219.04, baseline_loss = 90.828, entropy_loss = -5.1417, learner_queue_size = 32, _tick = 19968, _time = 1.6548e+09, train_seconds = 2.0042e+04)
[2022-06-10 01:42:07,634][root][INFO] - Step 75494400 @ 3581.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 75494400, mean_episode_return = 20.557, mean_episode_step = 913.06, total_loss = -158.49, pg_loss = -208.44, baseline_loss = 55.23, entropy_loss = -5.2793, learner_queue_size = 32, _tick = 19974, _time = 1.6548e+09, train_seconds = 2.0047e+04)
[2022-06-10 01:42:12,638][root][INFO] - Step 75514880 @ 4092.6 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 75514880, mean_episode_return = 106.32, mean_episode_step = 815.07, total_loss = 295.47, pg_loss = 217.99, baseline_loss = 82.911, entropy_loss = -5.4237, learner_queue_size = 32, _tick = 19981, _time = 1.6548e+09, train_seconds = 2.0052e+04)
[2022-06-10 01:42:17,642][root][INFO] - Step 75532800 @ 3581.2 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 75532800, mean_episode_return = 62.075, mean_episode_step = 1021.1, total_loss = 157.98, pg_loss = 84.826, baseline_loss = 78.428, entropy_loss = -5.2761, learner_queue_size = 32, _tick = 19988, _time = 1.6548e+09, train_seconds = 2.0057e+04)
[2022-06-10 01:42:22,646][root][INFO] - Step 75553280 @ 4092.8 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 75553280, mean_episode_return = 54.419, mean_episode_step = 914.77, total_loss = 300.03, pg_loss = 207.47, baseline_loss = 98.05, entropy_loss = -5.4823, learner_queue_size = 32, _tick = 19996, _time = 1.6548e+09, train_seconds = 2.0062e+04)
[2022-06-10 01:42:27,650][root][INFO] - Step 75573760 @ 4092.6 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 75573760, mean_episode_return = 58.481, mean_episode_step = 770.75, total_loss = -47.146, pg_loss = -85.125, baseline_loss = 43.358, entropy_loss = -5.3791, learner_queue_size = 32, _tick = 20001, _time = 1.6548e+09, train_seconds = 2.0068e+04)
[2022-06-10 01:42:32,654][root][INFO] - Step 75594240 @ 4092.8 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 75594240, mean_episode_return = None, mean_episode_step = 773.88, total_loss = 220.56, pg_loss = 159.0, baseline_loss = 66.803, entropy_loss = -5.2439, learner_queue_size = 32, _tick = 20006, _time = 1.6548e+09, train_seconds = 2.0072e+04)
[2022-06-10 01:42:37,658][root][INFO] - Step 75612160 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 75612160, mean_episode_return = None, mean_episode_step = 752.34, total_loss = 908.35, pg_loss = 642.52, baseline_loss = 271.17, entropy_loss = -5.351, learner_queue_size = 32, _tick = 20011, _time = 1.6548e+09, train_seconds = 2.0078e+04)
[2022-06-10 01:42:42,662][root][INFO] - Step 75632640 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 75632640, mean_episode_return = 70.565, mean_episode_step = 827.24, total_loss = 63.343, pg_loss = 27.555, baseline_loss = 41.116, entropy_loss = -5.3279, learner_queue_size = 32, _tick = 20016, _time = 1.6548e+09, train_seconds = 2.0082e+04)
[2022-06-10 01:42:47,666][root][INFO] - Step 75653120 @ 4092.7 SPS. Inference batcher size: 83. Learner queue size: 32. Other stats: (step = 75653120, mean_episode_return = 69.046, mean_episode_step = 882.12, total_loss = -196.58, pg_loss = -219.42, baseline_loss = 28.3, entropy_loss = -5.4643, learner_queue_size = 32, _tick = 20023, _time = 1.6548e+09, train_seconds = 2.0088e+04)
[2022-06-10 01:42:52,670][root][INFO] - Step 75671040 @ 3581.1 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 75671040, mean_episode_return = 16.5, mean_episode_step = 1378.2, total_loss = -113.11, pg_loss = -140.84, baseline_loss = 33.208, entropy_loss = -5.4745, learner_queue_size = 32, _tick = 20030, _time = 1.6548e+09, train_seconds = 2.0092e+04)
[2022-06-10 01:42:57,674][root][INFO] - Step 75691520 @ 4092.6 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 75691520, mean_episode_return = None, mean_episode_step = 679.84, total_loss = -196.83, pg_loss = -227.24, baseline_loss = 35.823, entropy_loss = -5.4173, learner_queue_size = 32, _tick = 20036, _time = 1.6548e+09, train_seconds = 2.0098e+04)
[2022-06-10 01:43:02,678][root][INFO] - Step 75712000 @ 4092.8 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (step = 75712000, mean_episode_return = 165.45, mean_episode_step = 1151.1, total_loss = 218.88, pg_loss = 164.16, baseline_loss = 60.334, entropy_loss = -5.6106, learner_queue_size = 32, _tick = 20043, _time = 1.6548e+09, train_seconds = 2.0102e+04)
[2022-06-10 01:43:07,682][root][INFO] - Step 75729920 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 75729920, mean_episode_return = 53.321, mean_episode_step = 1037.2, total_loss = 374.42, pg_loss = 257.54, baseline_loss = 122.49, entropy_loss = -5.6051, learner_queue_size = 32, _tick = 20049, _time = 1.6548e+09, train_seconds = 2.0108e+04)
[2022-06-10 01:43:12,686][root][INFO] - Step 75750400 @ 4092.7 SPS. Inference batcher size: 77. Learner queue size: 32. Other stats: (step = 75750400, mean_episode_return = 69.145, mean_episode_step = 849.02, total_loss = 155.13, pg_loss = 79.976, baseline_loss = 80.656, entropy_loss = -5.5007, learner_queue_size = 32, _tick = 20056, _time = 1.6548e+09, train_seconds = 2.0112e+04)
[2022-06-10 01:43:17,690][root][INFO] - Step 75768320 @ 3581.0 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (step = 75768320, mean_episode_return = None, mean_episode_step = 652.75, total_loss = 133.22, pg_loss = 75.786, baseline_loss = 62.805, entropy_loss = -5.3709, learner_queue_size = 32, _tick = 20061, _time = 1.6548e+09, train_seconds = 2.0118e+04)
[2022-06-10 01:43:22,694][root][INFO] - Step 75788800 @ 4092.9 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 75788800, mean_episode_return = 43.987, mean_episode_step = 944.85, total_loss = 47.322, pg_loss = -66.285, baseline_loss = 119.01, entropy_loss = -5.4, learner_queue_size = 32, _tick = 20068, _time = 1.6548e+09, train_seconds = 2.0122e+04)
[2022-06-10 01:43:27,698][root][INFO] - Step 75809280 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 75809280, mean_episode_return = 70.66, mean_episode_step = 919.39, total_loss = -192.11, pg_loss = -209.68, baseline_loss = 23.111, entropy_loss = -5.5429, learner_queue_size = 32, _tick = 20074, _time = 1.6548e+09, train_seconds = 2.0128e+04)
[2022-06-10 01:43:32,702][root][INFO] - Step 75827200 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 75827200, mean_episode_return = 44.97, mean_episode_step = 977.06, total_loss = -182.37, pg_loss = -238.61, baseline_loss = 61.77, entropy_loss = -5.5333, learner_queue_size = 32, _tick = 20081, _time = 1.6548e+09, train_seconds = 2.0132e+04)
[2022-06-10 01:43:37,706][root][INFO] - Step 75847680 @ 4092.8 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 75847680, mean_episode_return = 25.94, mean_episode_step = 969.79, total_loss = 9.6851, pg_loss = -25.969, baseline_loss = 41.214, entropy_loss = -5.5602, learner_queue_size = 32, _tick = 20088, _time = 1.6548e+09, train_seconds = 2.0138e+04)
[2022-06-10 01:43:42,710][root][INFO] - Step 75868160 @ 4092.6 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 75868160, mean_episode_return = 55.21, mean_episode_step = 1042.8, total_loss = 276.12, pg_loss = 211.25, baseline_loss = 70.441, entropy_loss = -5.5726, learner_queue_size = 32, _tick = 20094, _time = 1.6548e+09, train_seconds = 2.0142e+04)
[2022-06-10 01:43:47,714][root][INFO] - Step 75886080 @ 3581.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 75886080, mean_episode_return = 44.33, mean_episode_step = 1017.8, total_loss = 126.06, pg_loss = 95.995, baseline_loss = 35.528, entropy_loss = -5.4596, learner_queue_size = 32, _tick = 20100, _time = 1.6548e+09, train_seconds = 2.0148e+04)
[2022-06-10 01:43:52,718][root][INFO] - Step 75906560 @ 4092.5 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 75906560, mean_episode_return = 1.75, mean_episode_step = 1051.9, total_loss = 80.485, pg_loss = 5.1158, baseline_loss = 80.881, entropy_loss = -5.5124, learner_queue_size = 32, _tick = 20107, _time = 1.6548e+09, train_seconds = 2.0152e+04)
[2022-06-10 01:43:57,722][root][INFO] - Step 75924480 @ 3581.3 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 75924480, mean_episode_return = 36.57, mean_episode_step = 1636.2, total_loss = 81.482, pg_loss = 16.0, baseline_loss = 71.007, entropy_loss = -5.5257, learner_queue_size = 32, _tick = 20114, _time = 1.6548e+09, train_seconds = 2.0158e+04)
[2022-06-10 01:44:02,726][root][INFO] - Step 75944960 @ 4092.8 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 75944960, mean_episode_return = None, mean_episode_step = 859.03, total_loss = 6.0704, pg_loss = -33.437, baseline_loss = 44.942, entropy_loss = -5.4351, learner_queue_size = 32, _tick = 20120, _time = 1.6548e+09, train_seconds = 2.0162e+04)
[2022-06-10 01:44:07,730][root][INFO] - Step 75962880 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 75962880, mean_episode_return = None, mean_episode_step = 937.59, total_loss = 389.92, pg_loss = 308.33, baseline_loss = 87.015, entropy_loss = -5.4253, learner_queue_size = 32, _tick = 20124, _time = 1.6548e+09, train_seconds = 2.0168e+04)
[2022-06-10 01:44:12,734][root][INFO] - Step 75983360 @ 4092.6 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 75983360, mean_episode_return = 83.363, mean_episode_step = 949.68, total_loss = -239.0, pg_loss = -291.82, baseline_loss = 58.317, entropy_loss = -5.4931, learner_queue_size = 32, _tick = 20131, _time = 1.6548e+09, train_seconds = 2.0172e+04)
[2022-06-10 01:44:17,738][root][INFO] - Step 76003840 @ 4092.8 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 76003840, mean_episode_return = 3.9549, mean_episode_step = 832.21, total_loss = 206.53, pg_loss = 162.7, baseline_loss = 49.305, entropy_loss = -5.4788, learner_queue_size = 32, _tick = 20138, _time = 1.6548e+09, train_seconds = 2.0178e+04)
[2022-06-10 01:44:22,743][root][INFO] - Step 76021760 @ 3580.3 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 76021760, mean_episode_return = 73.53, mean_episode_step = 1183.3, total_loss = 284.31, pg_loss = 211.88, baseline_loss = 77.954, entropy_loss = -5.5246, learner_queue_size = 32, _tick = 20144, _time = 1.6548e+09, train_seconds = 2.0183e+04)
[2022-06-10 01:44:27,749][root][INFO] - Step 76042240 @ 4091.0 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 76042240, mean_episode_return = 66.505, mean_episode_step = 1527.9, total_loss = 148.78, pg_loss = 79.889, baseline_loss = 74.368, entropy_loss = -5.4718, learner_queue_size = 32, _tick = 20152, _time = 1.6548e+09, train_seconds = 2.0188e+04)
[2022-06-10 01:44:32,754][root][INFO] - Step 76062720 @ 4092.1 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 76062720, mean_episode_return = 54.993, mean_episode_step = 1639.4, total_loss = -73.618, pg_loss = -126.85, baseline_loss = 58.788, entropy_loss = -5.5557, learner_queue_size = 32, _tick = 20158, _time = 1.6548e+09, train_seconds = 2.0193e+04)
[2022-06-10 01:44:37,758][root][INFO] - Step 76083200 @ 4092.8 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (step = 76083200, mean_episode_return = 82.371, mean_episode_step = 891.23, total_loss = -7.6635, pg_loss = -37.341, baseline_loss = 35.186, entropy_loss = -5.5083, learner_queue_size = 32, _tick = 20165, _time = 1.6548e+09, train_seconds = 2.0198e+04)
[2022-06-10 01:44:42,762][root][INFO] - Step 76101120 @ 3581.1 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (step = 76101120, mean_episode_return = 29.092, mean_episode_step = 978.61, total_loss = 82.699, pg_loss = 39.24, baseline_loss = 48.851, entropy_loss = -5.391, learner_queue_size = 32, _tick = 20170, _time = 1.6548e+09, train_seconds = 2.0203e+04)
[2022-06-10 01:44:47,767][root][INFO] - Step 76121600 @ 4092.2 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 76121600, mean_episode_return = 14.01, mean_episode_step = 864.91, total_loss = 249.54, pg_loss = 153.02, baseline_loss = 102.04, entropy_loss = -5.5216, learner_queue_size = 32, _tick = 20177, _time = 1.6548e+09, train_seconds = 2.0208e+04)
[2022-06-10 01:44:52,770][root][INFO] - Step 76139520 @ 3581.5 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 76139520, mean_episode_return = None, mean_episode_step = 1198.6, total_loss = 717.67, pg_loss = 485.93, baseline_loss = 237.23, entropy_loss = -5.5016, learner_queue_size = 32, _tick = 20182, _time = 1.6548e+09, train_seconds = 2.0213e+04)
[2022-06-10 01:44:57,774][root][INFO] - Step 76160000 @ 4092.7 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 76160000, mean_episode_return = 55.97, mean_episode_step = 1032.5, total_loss = -10.279, pg_loss = -39.144, baseline_loss = 34.309, entropy_loss = -5.4437, learner_queue_size = 32, _tick = 20190, _time = 1.6548e+09, train_seconds = 2.0218e+04)
[2022-06-10 01:45:02,778][root][INFO] - Step 76177920 @ 3581.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 76177920, mean_episode_return = 68.205, mean_episode_step = 957.23, total_loss = -9.1644, pg_loss = -41.163, baseline_loss = 37.388, entropy_loss = -5.3894, learner_queue_size = 32, _tick = 20197, _time = 1.6548e+09, train_seconds = 2.0223e+04)
[2022-06-10 01:45:07,782][root][INFO] - Step 76198400 @ 4092.8 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 76198400, mean_episode_return = 35.396, mean_episode_step = 1287.1, total_loss = -87.192, pg_loss = -126.76, baseline_loss = 45.099, entropy_loss = -5.5314, learner_queue_size = 32, _tick = 20203, _time = 1.6548e+09, train_seconds = 2.0228e+04)
[2022-06-10 01:45:12,786][root][INFO] - Step 76218880 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 76218880, mean_episode_return = 28.941, mean_episode_step = 1577.3, total_loss = -85.934, pg_loss = -110.45, baseline_loss = 29.891, entropy_loss = -5.3759, learner_queue_size = 32, _tick = 20211, _time = 1.6548e+09, train_seconds = 2.0233e+04)
[2022-06-10 01:45:17,791][root][INFO] - Step 76236800 @ 3580.5 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 76236800, mean_episode_return = -1.11, mean_episode_step = 977.57, total_loss = -15.634, pg_loss = -58.928, baseline_loss = 48.82, entropy_loss = -5.5271, learner_queue_size = 32, _tick = 20218, _time = 1.6548e+09, train_seconds = 2.0238e+04)
[2022-06-10 01:45:22,794][root][INFO] - Step 76257280 @ 4093.5 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 76257280, mean_episode_return = None, mean_episode_step = 724.69, total_loss = 63.807, pg_loss = 3.1815, baseline_loss = 65.932, entropy_loss = -5.3064, learner_queue_size = 32, _tick = 20225, _time = 1.6548e+09, train_seconds = 2.0243e+04)
[2022-06-10 01:45:27,798][root][INFO] - Step 76277760 @ 4092.8 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 76277760, mean_episode_return = 39.037, mean_episode_step = 825.87, total_loss = 375.2, pg_loss = 193.99, baseline_loss = 186.64, entropy_loss = -5.4291, learner_queue_size = 32, _tick = 20231, _time = 1.6548e+09, train_seconds = 2.0248e+04)
[2022-06-10 01:45:32,802][root][INFO] - Step 76295680 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 76295680, mean_episode_return = 67.409, mean_episode_step = 1074.9, total_loss = 139.93, pg_loss = 75.754, baseline_loss = 69.626, entropy_loss = -5.4476, learner_queue_size = 32, _tick = 20236, _time = 1.6548e+09, train_seconds = 2.0253e+04)
[2022-06-10 01:45:37,806][root][INFO] - Step 76316160 @ 4092.6 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 76316160, mean_episode_return = -97.525, mean_episode_step = 997.27, total_loss = -73.001, pg_loss = -94.097, baseline_loss = 26.648, entropy_loss = -5.5524, learner_queue_size = 32, _tick = 20242, _time = 1.6548e+09, train_seconds = 2.0258e+04)
[2022-06-10 01:45:42,810][root][INFO] - Step 76334080 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 76334080, mean_episode_return = 64.11, mean_episode_step = 865.12, total_loss = 32.486, pg_loss = -5.4538, baseline_loss = 43.394, entropy_loss = -5.4537, learner_queue_size = 32, _tick = 20248, _time = 1.6548e+09, train_seconds = 2.0263e+04)
[2022-06-10 01:45:47,814][root][INFO] - Step 76354560 @ 4092.8 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 76354560, mean_episode_return = 37.265, mean_episode_step = 895.09, total_loss = 266.69, pg_loss = 173.37, baseline_loss = 98.521, entropy_loss = -5.1977, learner_queue_size = 32, _tick = 20254, _time = 1.6548e+09, train_seconds = 2.0268e+04)
[2022-06-10 01:45:52,818][root][INFO] - Step 76372480 @ 3581.2 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 76372480, mean_episode_return = None, mean_episode_step = 963.31, total_loss = 218.13, pg_loss = 164.79, baseline_loss = 58.616, entropy_loss = -5.2756, learner_queue_size = 32, _tick = 20257, _time = 1.6548e+09, train_seconds = 2.0273e+04)
[2022-06-10 01:45:57,822][root][INFO] - Step 76392960 @ 4092.6 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 76392960, mean_episode_return = 159.63, mean_episode_step = 947.47, total_loss = -201.94, pg_loss = -225.58, baseline_loss = 28.834, entropy_loss = -5.1978, learner_queue_size = 32, _tick = 20262, _time = 1.6548e+09, train_seconds = 2.0278e+04)
[2022-06-10 01:46:02,826][root][INFO] - Step 76410880 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 76410880, mean_episode_return = 30.57, mean_episode_step = 1178.4, total_loss = 66.376, pg_loss = 26.943, baseline_loss = 44.853, entropy_loss = -5.4199, learner_queue_size = 32, _tick = 20268, _time = 1.6548e+09, train_seconds = 2.0283e+04)
[2022-06-10 01:46:07,830][root][INFO] - Step 76431360 @ 4092.8 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 76431360, mean_episode_return = 39.115, mean_episode_step = 1028.7, total_loss = 47.013, pg_loss = -26.612, baseline_loss = 79.087, entropy_loss = -5.4611, learner_queue_size = 32, _tick = 20274, _time = 1.6548e+09, train_seconds = 2.0288e+04)
[2022-06-10 01:46:12,834][root][INFO] - Step 76451840 @ 4092.7 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 76451840, mean_episode_return = 71.706, mean_episode_step = 1594.9, total_loss = -194.69, pg_loss = -207.68, baseline_loss = 18.606, entropy_loss = -5.6118, learner_queue_size = 32, _tick = 20281, _time = 1.6548e+09, train_seconds = 2.0293e+04)
[2022-06-10 01:46:17,838][root][INFO] - Step 76469760 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 76469760, mean_episode_return = 82.105, mean_episode_step = 946.46, total_loss = -22.862, pg_loss = -41.011, baseline_loss = 23.662, entropy_loss = -5.5127, learner_queue_size = 32, _tick = 20287, _time = 1.6548e+09, train_seconds = 2.0298e+04)
[2022-06-10 01:46:22,842][root][INFO] - Step 76490240 @ 4092.8 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 76490240, mean_episode_return = 19.28, mean_episode_step = 1390.2, total_loss = 226.9, pg_loss = 156.64, baseline_loss = 75.866, entropy_loss = -5.612, learner_queue_size = 32, _tick = 20295, _time = 1.6548e+09, train_seconds = 2.0303e+04)
[2022-06-10 01:46:27,846][root][INFO] - Step 76508160 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 76508160, mean_episode_return = 43.84, mean_episode_step = 963.93, total_loss = 117.72, pg_loss = 96.65, baseline_loss = 26.67, entropy_loss = -5.5953, learner_queue_size = 32, _tick = 20301, _time = 1.6548e+09, train_seconds = 2.0308e+04)
[2022-06-10 01:46:32,851][root][INFO] - Step 76528640 @ 4091.9 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 76528640, mean_episode_return = 51.817, mean_episode_step = 1070.8, total_loss = -37.194, pg_loss = -83.354, baseline_loss = 51.703, entropy_loss = -5.5438, learner_queue_size = 32, _tick = 20309, _time = 1.6548e+09, train_seconds = 2.0313e+04)
[2022-06-10 01:46:37,854][root][INFO] - Step 76549120 @ 4093.6 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 76549120, mean_episode_return = 58.826, mean_episode_step = 1226.6, total_loss = 3.3215, pg_loss = -45.06, baseline_loss = 53.936, entropy_loss = -5.5549, learner_queue_size = 32, _tick = 20313, _time = 1.6548e+09, train_seconds = 2.0318e+04)
[2022-06-10 01:46:42,858][root][INFO] - Step 76569600 @ 4092.7 SPS. Inference batcher size: 77. Learner queue size: 32. Other stats: (step = 76569600, mean_episode_return = 106.36, mean_episode_step = 929.62, total_loss = 114.46, pg_loss = 25.512, baseline_loss = 94.478, entropy_loss = -5.5311, learner_queue_size = 32, _tick = 20318, _time = 1.6548e+09, train_seconds = 2.0323e+04)
[2022-06-10 01:46:47,862][root][INFO] - Step 76587520 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 76587520, mean_episode_return = 70.255, mean_episode_step = 877.86, total_loss = 33.93, pg_loss = -7.1297, baseline_loss = 46.59, entropy_loss = -5.5303, learner_queue_size = 32, _tick = 20324, _time = 1.6548e+09, train_seconds = 2.0328e+04)
[2022-06-10 01:46:52,866][root][INFO] - Step 76608000 @ 4092.7 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 76608000, mean_episode_return = 95.439, mean_episode_step = 785.93, total_loss = -99.22, pg_loss = -116.77, baseline_loss = 23.066, entropy_loss = -5.5124, learner_queue_size = 32, _tick = 20330, _time = 1.6548e+09, train_seconds = 2.0333e+04)
[2022-06-10 01:46:57,872][root][INFO] - Step 76625920 @ 3579.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 76625920, mean_episode_return = 40.84, mean_episode_step = 1597.6, total_loss = -46.367, pg_loss = -72.906, baseline_loss = 32.074, entropy_loss = -5.5345, learner_queue_size = 32, _tick = 20337, _time = 1.6548e+09, train_seconds = 2.0338e+04)
[2022-06-10 01:47:02,878][root][INFO] - Step 76646400 @ 4091.2 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 76646400, mean_episode_return = 90.703, mean_episode_step = 1554.8, total_loss = -148.99, pg_loss = -164.47, baseline_loss = 21.049, entropy_loss = -5.5779, learner_queue_size = 32, _tick = 20343, _time = 1.6548e+09, train_seconds = 2.0343e+04)
[2022-06-10 01:47:07,882][root][INFO] - Step 76666880 @ 4092.7 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 76666880, mean_episode_return = 24.42, mean_episode_step = 830.92, total_loss = -116.97, pg_loss = -138.41, baseline_loss = 26.913, entropy_loss = -5.472, learner_queue_size = 32, _tick = 20350, _time = 1.6548e+09, train_seconds = 2.0348e+04)
[2022-06-10 01:47:12,886][root][INFO] - Step 76684800 @ 3581.2 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 76684800, mean_episode_return = 44.545, mean_episode_step = 998.61, total_loss = 194.83, pg_loss = 133.7, baseline_loss = 66.619, entropy_loss = -5.49, learner_queue_size = 32, _tick = 20357, _time = 1.6548e+09, train_seconds = 2.0353e+04)
[2022-06-10 01:47:17,890][root][INFO] - Step 76705280 @ 4092.6 SPS. Inference batcher size: 81. Learner queue size: 32. Other stats: (step = 76705280, mean_episode_return = None, mean_episode_step = 989.09, total_loss = 48.143, pg_loss = 2.8629, baseline_loss = 50.726, entropy_loss = -5.4455, learner_queue_size = 32, _tick = 20364, _time = 1.6548e+09, train_seconds = 2.0358e+04)
[2022-06-10 01:47:22,894][root][INFO] - Step 76725760 @ 4092.8 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 76725760, mean_episode_return = 56.221, mean_episode_step = 855.55, total_loss = 115.96, pg_loss = 23.908, baseline_loss = 97.431, entropy_loss = -5.377, learner_queue_size = 32, _tick = 20371, _time = 1.6548e+09, train_seconds = 2.0363e+04)
[2022-06-10 01:47:27,898][root][INFO] - Step 76743680 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 76743680, mean_episode_return = None, mean_episode_step = 997.56, total_loss = -136.91, pg_loss = -167.16, baseline_loss = 35.715, entropy_loss = -5.4721, learner_queue_size = 32, _tick = 20377, _time = 1.6548e+09, train_seconds = 2.0368e+04)
[2022-06-10 01:47:32,903][root][INFO] - Step 76764160 @ 4091.8 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 76764160, mean_episode_return = 158.92, mean_episode_step = 1324.9, total_loss = 289.04, pg_loss = 209.53, baseline_loss = 84.949, entropy_loss = -5.4377, learner_queue_size = 32, _tick = 20385, _time = 1.6548e+09, train_seconds = 2.0373e+04)
[2022-06-10 01:47:37,906][root][INFO] - Step 76782080 @ 3581.9 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 76782080, mean_episode_return = 53.97, mean_episode_step = 781.58, total_loss = -150.78, pg_loss = -180.16, baseline_loss = 34.746, entropy_loss = -5.3698, learner_queue_size = 32, _tick = 20391, _time = 1.6548e+09, train_seconds = 2.0378e+04)
[2022-06-10 01:47:42,910][root][INFO] - Step 76802560 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 76802560, mean_episode_return = None, mean_episode_step = 1131.8, total_loss = -120.89, pg_loss = -129.56, baseline_loss = 14.15, entropy_loss = -5.4843, learner_queue_size = 32, _tick = 20395, _time = 1.6548e+09, train_seconds = 2.0383e+04)
[2022-06-10 01:47:47,914][root][INFO] - Step 76823040 @ 4092.6 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 76823040, mean_episode_return = 100.24, mean_episode_step = 858.13, total_loss = 129.18, pg_loss = 77.567, baseline_loss = 57.013, entropy_loss = -5.4007, learner_queue_size = 32, _tick = 20400, _time = 1.6548e+09, train_seconds = 2.0388e+04)
[2022-06-10 01:47:52,918][root][INFO] - Step 76840960 @ 3581.2 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 76840960, mean_episode_return = 141.15, mean_episode_step = 901.8, total_loss = -71.509, pg_loss = -109.39, baseline_loss = 43.353, entropy_loss = -5.4683, learner_queue_size = 32, _tick = 20406, _time = 1.6548e+09, train_seconds = 2.0393e+04)
[2022-06-10 01:47:57,922][root][INFO] - Step 76861440 @ 4092.7 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 76861440, mean_episode_return = -8.8901, mean_episode_step = 1453.7, total_loss = -20.872, pg_loss = -42.535, baseline_loss = 27.09, entropy_loss = -5.4269, learner_queue_size = 32, _tick = 20412, _time = 1.6548e+09, train_seconds = 2.0398e+04)
[2022-06-10 01:48:02,928][root][INFO] - Step 76881920 @ 4091.0 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 76881920, mean_episode_return = None, mean_episode_step = 1141.7, total_loss = -58.947, pg_loss = -87.663, baseline_loss = 34.16, entropy_loss = -5.4434, learner_queue_size = 32, _tick = 20415, _time = 1.6548e+09, train_seconds = 2.0403e+04)
[2022-06-10 01:48:07,934][root][INFO] - Step 76899840 @ 3579.8 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 76899840, mean_episode_return = None, mean_episode_step = 1008.0, total_loss = 101.73, pg_loss = 52.92, baseline_loss = 54.268, entropy_loss = -5.4583, learner_queue_size = 32, _tick = 20421, _time = 1.6548e+09, train_seconds = 2.0408e+04)
[2022-06-10 01:48:12,938][root][INFO] - Step 76920320 @ 4092.8 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 76920320, mean_episode_return = 28.39, mean_episode_step = 1146.0, total_loss = -224.36, pg_loss = -263.98, baseline_loss = 45.075, entropy_loss = -5.4561, learner_queue_size = 32, _tick = 20428, _time = 1.6548e+09, train_seconds = 2.0413e+04)
[2022-06-10 01:48:17,942][root][INFO] - Step 76940800 @ 4092.6 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 76940800, mean_episode_return = 27.07, mean_episode_step = 843.15, total_loss = 489.12, pg_loss = 374.1, baseline_loss = 120.48, entropy_loss = -5.4597, learner_queue_size = 32, _tick = 20436, _time = 1.6548e+09, train_seconds = 2.0418e+04)
[2022-06-10 01:48:22,946][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 01:48:23,105][root][INFO] - Step 76958720 @ 3581.1 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 76958720, mean_episode_return = 38.57, mean_episode_step = 1165.0, total_loss = 116.09, pg_loss = 71.541, baseline_loss = 50.062, entropy_loss = -5.5083, learner_queue_size = 32, _tick = 20442, _time = 1.6548e+09, train_seconds = 2.0423e+04)
[2022-06-10 01:48:28,110][root][INFO] - Step 76979200 @ 3965.9 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 76979200, mean_episode_return = 38.35, mean_episode_step = 990.78, total_loss = -155.36, pg_loss = -193.45, baseline_loss = 43.559, entropy_loss = -5.4616, learner_queue_size = 32, _tick = 20449, _time = 1.6548e+09, train_seconds = 2.0428e+04)
[2022-06-10 01:48:33,114][root][INFO] - Step 76999680 @ 4092.8 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 76999680, mean_episode_return = 62.65, mean_episode_step = 1341.5, total_loss = -124.51, pg_loss = -138.01, baseline_loss = 18.96, entropy_loss = -5.4548, learner_queue_size = 32, _tick = 20456, _time = 1.6548e+09, train_seconds = 2.0433e+04)
[2022-06-10 01:48:38,118][root][INFO] - Step 77017600 @ 3581.2 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 77017600, mean_episode_return = 116.14, mean_episode_step = 1125.6, total_loss = 412.99, pg_loss = 339.73, baseline_loss = 78.734, entropy_loss = -5.4726, learner_queue_size = 32, _tick = 20462, _time = 1.6548e+09, train_seconds = 2.0438e+04)
[2022-06-10 01:48:43,122][root][INFO] - Step 77038080 @ 4092.7 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 77038080, mean_episode_return = 46.07, mean_episode_step = 1481.5, total_loss = -181.93, pg_loss = -211.81, baseline_loss = 35.236, entropy_loss = -5.3486, learner_queue_size = 32, _tick = 20470, _time = 1.6548e+09, train_seconds = 2.0443e+04)
[2022-06-10 01:48:48,127][root][INFO] - Step 77058560 @ 4091.9 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (step = 77058560, mean_episode_return = 31.5, mean_episode_step = 994.12, total_loss = 139.13, pg_loss = 90.449, baseline_loss = 54.08, entropy_loss = -5.4038, learner_queue_size = 32, _tick = 20476, _time = 1.6548e+09, train_seconds = 2.0448e+04)
[2022-06-10 01:48:53,130][root][INFO] - Step 77079040 @ 4093.4 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 77079040, mean_episode_return = 40.69, mean_episode_step = 1076.5, total_loss = 275.41, pg_loss = 191.02, baseline_loss = 89.751, entropy_loss = -5.3574, learner_queue_size = 32, _tick = 20481, _time = 1.6548e+09, train_seconds = 2.0453e+04)
[2022-06-10 01:48:58,134][root][INFO] - Step 77096960 @ 3581.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 77096960, mean_episode_return = None, mean_episode_step = 1033.7, total_loss = 174.3, pg_loss = 117.03, baseline_loss = 62.421, entropy_loss = -5.1472, learner_queue_size = 32, _tick = 20484, _time = 1.6548e+09, train_seconds = 2.0458e+04)
[2022-06-10 01:49:03,138][root][INFO] - Step 77114880 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 77114880, mean_episode_return = 112.14, mean_episode_step = 1058.8, total_loss = -194.95, pg_loss = -239.8, baseline_loss = 50.174, entropy_loss = -5.3236, learner_queue_size = 32, _tick = 20489, _time = 1.6548e+09, train_seconds = 2.0463e+04)
[2022-06-10 01:49:08,142][root][INFO] - Step 77135360 @ 4092.8 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 77135360, mean_episode_return = 67.253, mean_episode_step = 1256.8, total_loss = 68.07, pg_loss = -8.5981, baseline_loss = 81.787, entropy_loss = -5.1183, learner_queue_size = 32, _tick = 20497, _time = 1.6548e+09, train_seconds = 2.0468e+04)
[2022-06-10 01:49:13,146][root][INFO] - Step 77155840 @ 4092.6 SPS. Inference batcher size: 81. Learner queue size: 32. Other stats: (step = 77155840, mean_episode_return = 77.721, mean_episode_step = 1007.5, total_loss = 322.51, pg_loss = 246.57, baseline_loss = 81.367, entropy_loss = -5.4268, learner_queue_size = 32, _tick = 20501, _time = 1.6548e+09, train_seconds = 2.0473e+04)
[2022-06-10 01:49:18,150][root][INFO] - Step 77173760 @ 3581.2 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 77173760, mean_episode_return = 15.325, mean_episode_step = 863.48, total_loss = 283.52, pg_loss = 213.64, baseline_loss = 75.283, entropy_loss = -5.4003, learner_queue_size = 32, _tick = 20508, _time = 1.6548e+09, train_seconds = 2.0478e+04)
[2022-06-10 01:49:23,154][root][INFO] - Step 77194240 @ 4092.7 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 77194240, mean_episode_return = 45.754, mean_episode_step = 1035.9, total_loss = 134.58, pg_loss = 66.857, baseline_loss = 73.121, entropy_loss = -5.3979, learner_queue_size = 32, _tick = 20516, _time = 1.6548e+09, train_seconds = 2.0483e+04)
[2022-06-10 01:49:28,160][root][INFO] - Step 77212160 @ 3579.4 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 77212160, mean_episode_return = 52.897, mean_episode_step = 941.12, total_loss = -233.66, pg_loss = -316.15, baseline_loss = 87.896, entropy_loss = -5.4025, learner_queue_size = 32, _tick = 20521, _time = 1.6548e+09, train_seconds = 2.0488e+04)
[2022-06-10 01:49:33,166][root][INFO] - Step 77232640 @ 4091.4 SPS. Inference batcher size: 76. Learner queue size: 32. Other stats: (step = 77232640, mean_episode_return = 19.755, mean_episode_step = 1410.8, total_loss = 143.45, pg_loss = 93.859, baseline_loss = 54.876, entropy_loss = -5.2853, learner_queue_size = 32, _tick = 20528, _time = 1.6548e+09, train_seconds = 2.0493e+04)
[2022-06-10 01:49:38,170][root][INFO] - Step 77250560 @ 3581.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 77250560, mean_episode_return = 25.36, mean_episode_step = 1526.4, total_loss = 60.561, pg_loss = 12.044, baseline_loss = 53.922, entropy_loss = -5.4054, learner_queue_size = 32, _tick = 20535, _time = 1.6548e+09, train_seconds = 2.0498e+04)
[2022-06-10 01:49:43,174][root][INFO] - Step 77271040 @ 4092.7 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (step = 77271040, mean_episode_return = None, mean_episode_step = 1156.8, total_loss = 90.77, pg_loss = 37.228, baseline_loss = 58.921, entropy_loss = -5.3783, learner_queue_size = 32, _tick = 20542, _time = 1.6548e+09, train_seconds = 2.0503e+04)
[2022-06-10 01:49:48,178][root][INFO] - Step 77288960 @ 3581.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 77288960, mean_episode_return = 130.63, mean_episode_step = 1116.4, total_loss = -237.65, pg_loss = -244.66, baseline_loss = 12.468, entropy_loss = -5.4592, learner_queue_size = 32, _tick = 20548, _time = 1.6548e+09, train_seconds = 2.0508e+04)
[2022-06-10 01:49:53,182][root][INFO] - Step 77309440 @ 4092.7 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 77309440, mean_episode_return = 114.93, mean_episode_step = 1122.3, total_loss = 238.06, pg_loss = 164.51, baseline_loss = 78.992, entropy_loss = -5.4479, learner_queue_size = 32, _tick = 20554, _time = 1.6548e+09, train_seconds = 2.0513e+04)
[2022-06-10 01:49:58,186][root][INFO] - Step 77329920 @ 4092.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 77329920, mean_episode_return = 1.6998, mean_episode_step = 1712.9, total_loss = 70.475, pg_loss = 38.849, baseline_loss = 37.051, entropy_loss = -5.4253, learner_queue_size = 32, _tick = 20558, _time = 1.6548e+09, train_seconds = 2.0518e+04)
[2022-06-10 01:50:03,190][root][INFO] - Step 77347840 @ 3581.1 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 77347840, mean_episode_return = 45.81, mean_episode_step = 1445.7, total_loss = -210.69, pg_loss = -236.53, baseline_loss = 31.244, entropy_loss = -5.4115, learner_queue_size = 32, _tick = 20565, _time = 1.6548e+09, train_seconds = 2.0523e+04)
[2022-06-10 01:50:08,194][root][INFO] - Step 77368320 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 77368320, mean_episode_return = None, mean_episode_step = 958.75, total_loss = -12.714, pg_loss = -55.348, baseline_loss = 48.089, entropy_loss = -5.4548, learner_queue_size = 32, _tick = 20571, _time = 1.6548e+09, train_seconds = 2.0528e+04)
[2022-06-10 01:50:13,198][root][INFO] - Step 77386240 @ 3581.2 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 77386240, mean_episode_return = 6.6897, mean_episode_step = 1129.7, total_loss = 253.84, pg_loss = 155.44, baseline_loss = 103.75, entropy_loss = -5.344, learner_queue_size = 32, _tick = 20578, _time = 1.6548e+09, train_seconds = 2.0533e+04)
[2022-06-10 01:50:18,202][root][INFO] - Step 77406720 @ 4092.5 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 77406720, mean_episode_return = 51.995, mean_episode_step = 1114.1, total_loss = -85.884, pg_loss = -117.27, baseline_loss = 36.802, entropy_loss = -5.4144, learner_queue_size = 32, _tick = 20585, _time = 1.6548e+09, train_seconds = 2.0538e+04)
[2022-06-10 01:50:23,206][root][INFO] - Step 77427200 @ 4092.9 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 77427200, mean_episode_return = 102.64, mean_episode_step = 947.69, total_loss = 107.03, pg_loss = 47.424, baseline_loss = 65.009, entropy_loss = -5.4068, learner_queue_size = 32, _tick = 20592, _time = 1.6548e+09, train_seconds = 2.0543e+04)
[2022-06-10 01:50:28,210][root][INFO] - Step 77445120 @ 3581.1 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (step = 77445120, mean_episode_return = None, mean_episode_step = 1009.8, total_loss = 473.0, pg_loss = 339.0, baseline_loss = 139.42, entropy_loss = -5.4191, learner_queue_size = 32, _tick = 20597, _time = 1.6548e+09, train_seconds = 2.0548e+04)
[2022-06-10 01:50:33,214][root][INFO] - Step 77463040 @ 3581.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 77463040, mean_episode_return = 38.465, mean_episode_step = 1772.5, total_loss = 983.88, pg_loss = 501.04, baseline_loss = 488.03, entropy_loss = -5.1901, learner_queue_size = 32, _tick = 20603, _time = 1.6548e+09, train_seconds = 2.0553e+04)
[2022-06-10 01:50:38,218][root][INFO] - Step 77483520 @ 4092.8 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 77483520, mean_episode_return = 39.067, mean_episode_step = 954.09, total_loss = 131.57, pg_loss = 12.586, baseline_loss = 124.32, entropy_loss = -5.3421, learner_queue_size = 32, _tick = 20611, _time = 1.6548e+09, train_seconds = 2.0558e+04)
[2022-06-10 01:50:43,222][root][INFO] - Step 77501440 @ 3581.1 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (step = 77501440, mean_episode_return = 54.233, mean_episode_step = 1075.1, total_loss = -129.14, pg_loss = -145.14, baseline_loss = 21.451, entropy_loss = -5.4459, learner_queue_size = 32, _tick = 20617, _time = 1.6548e+09, train_seconds = 2.0563e+04)
[2022-06-10 01:50:48,226][root][INFO] - Step 77521920 @ 4092.6 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 77521920, mean_episode_return = 58.09, mean_episode_step = 979.33, total_loss = -70.017, pg_loss = -87.758, baseline_loss = 23.153, entropy_loss = -5.4116, learner_queue_size = 32, _tick = 20623, _time = 1.6548e+09, train_seconds = 2.0568e+04)
[2022-06-10 01:50:53,232][root][INFO] - Step 77539840 @ 3579.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 77539840, mean_episode_return = 66.217, mean_episode_step = 815.24, total_loss = 149.03, pg_loss = 86.006, baseline_loss = 68.21, entropy_loss = -5.1839, learner_queue_size = 32, _tick = 20629, _time = 1.6548e+09, train_seconds = 2.0573e+04)
[2022-06-10 01:50:58,238][root][INFO] - Step 77560320 @ 4091.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 77560320, mean_episode_return = 111.77, mean_episode_step = 869.26, total_loss = -141.23, pg_loss = -176.39, baseline_loss = 40.335, entropy_loss = -5.1788, learner_queue_size = 32, _tick = 20637, _time = 1.6548e+09, train_seconds = 2.0578e+04)
[2022-06-10 01:51:03,242][root][INFO] - Step 77578240 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 77578240, mean_episode_return = 51.615, mean_episode_step = 958.5, total_loss = 277.12, pg_loss = 198.6, baseline_loss = 83.931, entropy_loss = -5.4108, learner_queue_size = 32, _tick = 20643, _time = 1.6548e+09, train_seconds = 2.0583e+04)
[2022-06-10 01:51:08,246][root][INFO] - Step 77598720 @ 4092.7 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 77598720, mean_episode_return = 52.102, mean_episode_step = 939.9, total_loss = 586.41, pg_loss = 465.27, baseline_loss = 126.48, entropy_loss = -5.3485, learner_queue_size = 32, _tick = 20649, _time = 1.6548e+09, train_seconds = 2.0588e+04)
[2022-06-10 01:51:13,250][root][INFO] - Step 77619200 @ 4092.8 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 77619200, mean_episode_return = 23.06, mean_episode_step = 886.51, total_loss = -126.58, pg_loss = -152.46, baseline_loss = 31.292, entropy_loss = -5.4136, learner_queue_size = 32, _tick = 20656, _time = 1.6548e+09, train_seconds = 2.0593e+04)
[2022-06-10 01:51:18,254][root][INFO] - Step 77637120 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 77637120, mean_episode_return = 81.27, mean_episode_step = 874.4, total_loss = 263.29, pg_loss = 168.16, baseline_loss = 100.53, entropy_loss = -5.403, learner_queue_size = 32, _tick = 20663, _time = 1.6548e+09, train_seconds = 2.0598e+04)
[2022-06-10 01:51:23,258][root][INFO] - Step 77657600 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 77657600, mean_episode_return = 57.157, mean_episode_step = 817.54, total_loss = 56.037, pg_loss = -9.6823, baseline_loss = 71.15, entropy_loss = -5.4302, learner_queue_size = 32, _tick = 20669, _time = 1.6548e+09, train_seconds = 2.0603e+04)
[2022-06-10 01:51:28,262][root][INFO] - Step 77675520 @ 3581.1 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 77675520, mean_episode_return = 82.337, mean_episode_step = 803.69, total_loss = 514.54, pg_loss = 431.31, baseline_loss = 88.654, entropy_loss = -5.4232, learner_queue_size = 32, _tick = 20675, _time = 1.6548e+09, train_seconds = 2.0608e+04)
[2022-06-10 01:51:33,266][root][INFO] - Step 77696000 @ 4092.8 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 77696000, mean_episode_return = 226.59, mean_episode_step = 1225.1, total_loss = 45.991, pg_loss = 8.293, baseline_loss = 42.724, entropy_loss = -5.0262, learner_queue_size = 32, _tick = 20683, _time = 1.6548e+09, train_seconds = 2.0613e+04)
[2022-06-10 01:51:38,270][root][INFO] - Step 77713920 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 77713920, mean_episode_return = 121.22, mean_episode_step = 850.68, total_loss = 44.358, pg_loss = 5.5681, baseline_loss = 44.161, entropy_loss = -5.3716, learner_queue_size = 32, _tick = 20688, _time = 1.6548e+09, train_seconds = 2.0618e+04)
[2022-06-10 01:51:43,274][root][INFO] - Step 77734400 @ 4092.7 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 77734400, mean_episode_return = 125.33, mean_episode_step = 1075.8, total_loss = 15.542, pg_loss = -27.198, baseline_loss = 48.243, entropy_loss = -5.5024, learner_queue_size = 32, _tick = 20695, _time = 1.6548e+09, train_seconds = 2.0623e+04)
[2022-06-10 01:51:48,278][root][INFO] - Step 77754880 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 77754880, mean_episode_return = 32.617, mean_episode_step = 940.32, total_loss = -49.366, pg_loss = -84.557, baseline_loss = 40.543, entropy_loss = -5.3516, learner_queue_size = 32, _tick = 20703, _time = 1.6548e+09, train_seconds = 2.0628e+04)
[2022-06-10 01:51:53,282][root][INFO] - Step 77772800 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 77772800, mean_episode_return = 12.19, mean_episode_step = 935.78, total_loss = 47.137, pg_loss = 1.9376, baseline_loss = 50.507, entropy_loss = -5.3082, learner_queue_size = 32, _tick = 20708, _time = 1.6548e+09, train_seconds = 2.0633e+04)
[2022-06-10 01:51:58,286][root][INFO] - Step 77793280 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 77793280, mean_episode_return = 49.296, mean_episode_step = 985.38, total_loss = 15.529, pg_loss = -50.212, baseline_loss = 71.142, entropy_loss = -5.4009, learner_queue_size = 32, _tick = 20715, _time = 1.6548e+09, train_seconds = 2.0638e+04)
[2022-06-10 01:52:03,293][root][INFO] - Step 77811200 @ 3579.0 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 77811200, mean_episode_return = 69.09, mean_episode_step = 1011.1, total_loss = 466.12, pg_loss = 346.19, baseline_loss = 125.29, entropy_loss = -5.3597, learner_queue_size = 32, _tick = 20721, _time = 1.6548e+09, train_seconds = 2.0643e+04)
[2022-06-10 01:52:08,298][root][INFO] - Step 77831680 @ 4091.8 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 77831680, mean_episode_return = 60.49, mean_episode_step = 1078.0, total_loss = 336.75, pg_loss = 174.04, baseline_loss = 167.95, entropy_loss = -5.2438, learner_queue_size = 32, _tick = 20729, _time = 1.6548e+09, train_seconds = 2.0648e+04)
[2022-06-10 01:52:13,301][root][INFO] - Step 77849600 @ 3582.1 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 77849600, mean_episode_return = 29.986, mean_episode_step = 1092.0, total_loss = 92.077, pg_loss = 36.368, baseline_loss = 61.167, entropy_loss = -5.4582, learner_queue_size = 32, _tick = 20735, _time = 1.6548e+09, train_seconds = 2.0653e+04)
[2022-06-10 01:52:18,306][root][INFO] - Step 77870080 @ 4091.9 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (step = 77870080, mean_episode_return = 33.599, mean_episode_step = 1074.6, total_loss = -32.807, pg_loss = -73.111, baseline_loss = 45.79, entropy_loss = -5.4855, learner_queue_size = 32, _tick = 20741, _time = 1.6548e+09, train_seconds = 2.0658e+04)
[2022-06-10 01:52:23,310][root][INFO] - Step 77890560 @ 4092.6 SPS. Inference batcher size: 88. Learner queue size: 32. Other stats: (step = 77890560, mean_episode_return = -2.64, mean_episode_step = 697.82, total_loss = 15.478, pg_loss = -9.1668, baseline_loss = 30.021, entropy_loss = -5.3767, learner_queue_size = 32, _tick = 20747, _time = 1.6548e+09, train_seconds = 2.0663e+04)
[2022-06-10 01:52:28,314][root][INFO] - Step 77908480 @ 3581.2 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 77908480, mean_episode_return = -1.47, mean_episode_step = 866.53, total_loss = 18.05, pg_loss = -21.818, baseline_loss = 45.246, entropy_loss = -5.3776, learner_queue_size = 32, _tick = 20754, _time = 1.6548e+09, train_seconds = 2.0668e+04)
[2022-06-10 01:52:33,318][root][INFO] - Step 77928960 @ 4092.6 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 77928960, mean_episode_return = 119.76, mean_episode_step = 801.63, total_loss = -236.13, pg_loss = -256.99, baseline_loss = 26.3, entropy_loss = -5.4384, learner_queue_size = 32, _tick = 20762, _time = 1.6548e+09, train_seconds = 2.0673e+04)
[2022-06-10 01:52:38,322][root][INFO] - Step 77946880 @ 3581.3 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 77946880, mean_episode_return = None, mean_episode_step = 936.72, total_loss = 176.93, pg_loss = 121.33, baseline_loss = 61.072, entropy_loss = -5.4706, learner_queue_size = 32, _tick = 20766, _time = 1.6548e+09, train_seconds = 2.0678e+04)
[2022-06-10 01:52:43,326][root][INFO] - Step 77967360 @ 4092.6 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 77967360, mean_episode_return = 104.75, mean_episode_step = 905.35, total_loss = -128.53, pg_loss = -151.72, baseline_loss = 28.584, entropy_loss = -5.4011, learner_queue_size = 32, _tick = 20773, _time = 1.6548e+09, train_seconds = 2.0683e+04)
[2022-06-10 01:52:48,331][root][INFO] - Step 77987840 @ 4092.3 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (step = 77987840, mean_episode_return = 16.97, mean_episode_step = 1006.2, total_loss = 26.709, pg_loss = -22.495, baseline_loss = 54.682, entropy_loss = -5.4776, learner_queue_size = 32, _tick = 20780, _time = 1.6548e+09, train_seconds = 2.0688e+04)
[2022-06-10 01:52:53,334][root][INFO] - Step 78008320 @ 4093.3 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 78008320, mean_episode_return = 18.62, mean_episode_step = 961.2, total_loss = 377.35, pg_loss = 272.28, baseline_loss = 110.15, entropy_loss = -5.0863, learner_queue_size = 32, _tick = 20786, _time = 1.6548e+09, train_seconds = 2.0693e+04)
[2022-06-10 01:52:58,338][root][INFO] - Step 78028800 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 78028800, mean_episode_return = 83.765, mean_episode_step = 878.1, total_loss = 292.81, pg_loss = 201.34, baseline_loss = 96.902, entropy_loss = -5.4355, learner_queue_size = 32, _tick = 20792, _time = 1.6548e+09, train_seconds = 2.0698e+04)
[2022-06-10 01:53:03,342][root][INFO] - Step 78046720 @ 3581.2 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 78046720, mean_episode_return = 186.83, mean_episode_step = 1080.3, total_loss = 57.05, pg_loss = 21.588, baseline_loss = 40.979, entropy_loss = -5.5167, learner_queue_size = 32, _tick = 20798, _time = 1.6548e+09, train_seconds = 2.0703e+04)
[2022-06-10 01:53:08,346][root][INFO] - Step 78067200 @ 4092.7 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 78067200, mean_episode_return = 27.67, mean_episode_step = 827.16, total_loss = 82.088, pg_loss = 34.82, baseline_loss = 52.737, entropy_loss = -5.4695, learner_queue_size = 32, _tick = 20805, _time = 1.6548e+09, train_seconds = 2.0708e+04)
[2022-06-10 01:53:13,350][root][INFO] - Step 78087680 @ 4092.7 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 78087680, mean_episode_return = 104.23, mean_episode_step = 924.27, total_loss = -84.044, pg_loss = -197.75, baseline_loss = 119.18, entropy_loss = -5.4694, learner_queue_size = 32, _tick = 20813, _time = 1.6548e+09, train_seconds = 2.0713e+04)
[2022-06-10 01:53:18,354][root][INFO] - Step 78105600 @ 3581.1 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 78105600, mean_episode_return = 60.314, mean_episode_step = 1041.1, total_loss = -126.87, pg_loss = -149.24, baseline_loss = 27.844, entropy_loss = -5.4686, learner_queue_size = 32, _tick = 20818, _time = 1.6548e+09, train_seconds = 2.0718e+04)
[2022-06-10 01:53:23,360][root][INFO] - Step 78126080 @ 4091.0 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 78126080, mean_episode_return = None, mean_episode_step = 802.5, total_loss = -38.779, pg_loss = -54.019, baseline_loss = 20.752, entropy_loss = -5.512, learner_queue_size = 32, _tick = 20824, _time = 1.6548e+09, train_seconds = 2.0723e+04)
[2022-06-10 01:53:28,365][root][INFO] - Step 78144000 @ 3580.6 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 78144000, mean_episode_return = -3.73, mean_episode_step = 853.95, total_loss = 140.16, pg_loss = 79.966, baseline_loss = 65.655, entropy_loss = -5.4616, learner_queue_size = 32, _tick = 20829, _time = 1.6548e+09, train_seconds = 2.0728e+04)
[2022-06-10 01:53:33,370][root][INFO] - Step 78164480 @ 4091.8 SPS. Inference batcher size: 78. Learner queue size: 32. Other stats: (step = 78164480, mean_episode_return = 56.601, mean_episode_step = 844.81, total_loss = -193.55, pg_loss = -199.39, baseline_loss = 11.372, entropy_loss = -5.5279, learner_queue_size = 32, _tick = 20837, _time = 1.6548e+09, train_seconds = 2.0733e+04)
[2022-06-10 01:53:38,374][root][INFO] - Step 78182400 @ 3581.1 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (step = 78182400, mean_episode_return = 79.41, mean_episode_step = 759.27, total_loss = 204.61, pg_loss = 167.39, baseline_loss = 42.613, entropy_loss = -5.3899, learner_queue_size = 32, _tick = 20842, _time = 1.6548e+09, train_seconds = 2.0738e+04)
[2022-06-10 01:53:43,378][root][INFO] - Step 78202880 @ 4092.8 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 78202880, mean_episode_return = None, mean_episode_step = 904.53, total_loss = 367.64, pg_loss = 262.96, baseline_loss = 110.14, entropy_loss = -5.4642, learner_queue_size = 32, _tick = 20847, _time = 1.6548e+09, train_seconds = 2.0743e+04)
[2022-06-10 01:53:48,382][root][INFO] - Step 78223360 @ 4092.7 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 78223360, mean_episode_return = 79.412, mean_episode_step = 1041.7, total_loss = -167.82, pg_loss = -186.13, baseline_loss = 23.795, entropy_loss = -5.4814, learner_queue_size = 32, _tick = 20851, _time = 1.6548e+09, train_seconds = 2.0748e+04)
[2022-06-10 01:53:53,386][root][INFO] - Step 78243840 @ 4092.7 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 78243840, mean_episode_return = 94.893, mean_episode_step = 1007.0, total_loss = -52.616, pg_loss = -81.781, baseline_loss = 34.665, entropy_loss = -5.5002, learner_queue_size = 32, _tick = 20857, _time = 1.6548e+09, train_seconds = 2.0753e+04)
[2022-06-10 01:53:58,390][root][INFO] - Step 78264320 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 78264320, mean_episode_return = 75.891, mean_episode_step = 1109.8, total_loss = 130.82, pg_loss = 91.876, baseline_loss = 44.403, entropy_loss = -5.4564, learner_queue_size = 32, _tick = 20863, _time = 1.6548e+09, train_seconds = 2.0758e+04)
[2022-06-10 01:54:03,394][root][INFO] - Step 78282240 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 78282240, mean_episode_return = 27.451, mean_episode_step = 999.41, total_loss = 38.361, pg_loss = 5.7951, baseline_loss = 38.012, entropy_loss = -5.4468, learner_queue_size = 32, _tick = 20870, _time = 1.6548e+09, train_seconds = 2.0763e+04)
[2022-06-10 01:54:08,398][root][INFO] - Step 78302720 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 78302720, mean_episode_return = 67.27, mean_episode_step = 954.94, total_loss = -85.277, pg_loss = -102.21, baseline_loss = 22.28, entropy_loss = -5.3495, learner_queue_size = 32, _tick = 20877, _time = 1.6548e+09, train_seconds = 2.0768e+04)
[2022-06-10 01:54:13,402][root][INFO] - Step 78320640 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 78320640, mean_episode_return = 94.271, mean_episode_step = 1101.9, total_loss = 210.6, pg_loss = 128.59, baseline_loss = 87.432, entropy_loss = -5.4216, learner_queue_size = 32, _tick = 20884, _time = 1.6548e+09, train_seconds = 2.0773e+04)
[2022-06-10 01:54:18,406][root][INFO] - Step 78341120 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 78341120, mean_episode_return = 32.58, mean_episode_step = 1003.5, total_loss = -65.591, pg_loss = -91.806, baseline_loss = 31.536, entropy_loss = -5.321, learner_queue_size = 32, _tick = 20890, _time = 1.6548e+09, train_seconds = 2.0778e+04)
[2022-06-10 01:54:23,410][root][INFO] - Step 78361600 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 78361600, mean_episode_return = 189.55, mean_episode_step = 1164.5, total_loss = 179.22, pg_loss = 7.9625, baseline_loss = 41.473, entropy_loss = -5.3112, learner_queue_size = 32, _tick = 20896, _time = 1.6548e+09, train_seconds = 2.0783e+04)
[2022-06-10 01:54:28,414][root][INFO] - Step 78379520 @ 3581.0 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (step = 78379520, mean_episode_return = 40.901, mean_episode_step = 1092.0, total_loss = 43.877, pg_loss = -3.8892, baseline_loss = 53.115, entropy_loss = -5.3484, learner_queue_size = 32, _tick = 20902, _time = 1.6548e+09, train_seconds = 2.0788e+04)
[2022-06-10 01:54:33,418][root][INFO] - Step 78397440 @ 3581.0 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 78397440, mean_episode_return = 83.21, mean_episode_step = 1151.4, total_loss = 50.227, pg_loss = -0.90899, baseline_loss = 56.586, entropy_loss = -5.4504, learner_queue_size = 32, _tick = 20908, _time = 1.6548e+09, train_seconds = 2.0793e+04)
[2022-06-10 01:54:38,422][root][INFO] - Step 78417920 @ 4093.0 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 78417920, mean_episode_return = 72.476, mean_episode_step = 1210.2, total_loss = 316.37, pg_loss = 195.83, baseline_loss = 125.78, entropy_loss = -5.2464, learner_queue_size = 32, _tick = 20916, _time = 1.6548e+09, train_seconds = 2.0798e+04)
[2022-06-10 01:54:43,430][root][INFO] - Step 78438400 @ 4089.6 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 78438400, mean_episode_return = None, mean_episode_step = 895.81, total_loss = 97.218, pg_loss = 61.057, baseline_loss = 41.511, entropy_loss = -5.3504, learner_queue_size = 32, _tick = 20922, _time = 1.6548e+09, train_seconds = 2.0803e+04)
[2022-06-10 01:54:48,434][root][INFO] - Step 78456320 @ 3581.1 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 78456320, mean_episode_return = None, mean_episode_step = 994.16, total_loss = 89.357, pg_loss = 39.975, baseline_loss = 54.612, entropy_loss = -5.2303, learner_queue_size = 32, _tick = 20927, _time = 1.6548e+09, train_seconds = 2.0808e+04)
[2022-06-10 01:54:53,438][root][INFO] - Step 78476800 @ 4092.5 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 78476800, mean_episode_return = 21.44, mean_episode_step = 911.86, total_loss = 62.846, pg_loss = -13.299, baseline_loss = 81.561, entropy_loss = -5.416, learner_queue_size = 32, _tick = 20934, _time = 1.6548e+09, train_seconds = 2.0813e+04)
[2022-06-10 01:54:58,442][root][INFO] - Step 78497280 @ 4092.9 SPS. Inference batcher size: 88. Learner queue size: 32. Other stats: (step = 78497280, mean_episode_return = 57.483, mean_episode_step = 942.63, total_loss = 357.48, pg_loss = 244.78, baseline_loss = 118.18, entropy_loss = -5.4775, learner_queue_size = 32, _tick = 20941, _time = 1.6548e+09, train_seconds = 2.0818e+04)
[2022-06-10 01:55:03,446][root][INFO] - Step 78517760 @ 4092.8 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 78517760, mean_episode_return = 19.22, mean_episode_step = 1223.8, total_loss = 196.78, pg_loss = 153.4, baseline_loss = 48.841, entropy_loss = -5.4638, learner_queue_size = 32, _tick = 20947, _time = 1.6548e+09, train_seconds = 2.0823e+04)
[2022-06-10 01:55:08,450][root][INFO] - Step 78535680 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 78535680, mean_episode_return = 38.59, mean_episode_step = 838.51, total_loss = 25.795, pg_loss = -36.46, baseline_loss = 67.605, entropy_loss = -5.3496, learner_queue_size = 32, _tick = 20953, _time = 1.6548e+09, train_seconds = 2.0828e+04)
[2022-06-10 01:55:13,454][root][INFO] - Step 78556160 @ 4092.7 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 78556160, mean_episode_return = 42.9, mean_episode_step = 1025.5, total_loss = 56.255, pg_loss = -69.28, baseline_loss = 130.94, entropy_loss = -5.4074, learner_queue_size = 32, _tick = 20961, _time = 1.6548e+09, train_seconds = 2.0833e+04)
[2022-06-10 01:55:18,458][root][INFO] - Step 78576640 @ 4092.8 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 78576640, mean_episode_return = 48.525, mean_episode_step = 958.04, total_loss = 466.65, pg_loss = 369.62, baseline_loss = 102.47, entropy_loss = -5.4398, learner_queue_size = 32, _tick = 20969, _time = 1.6548e+09, train_seconds = 2.0838e+04)
[2022-06-10 01:55:23,462][root][INFO] - Step 78594560 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 78594560, mean_episode_return = 81.367, mean_episode_step = 853.74, total_loss = 127.53, pg_loss = -16.977, baseline_loss = 149.91, entropy_loss = -5.4051, learner_queue_size = 32, _tick = 20974, _time = 1.6548e+09, train_seconds = 2.0843e+04)
[2022-06-10 01:55:28,466][root][INFO] - Step 78615040 @ 4092.6 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 78615040, mean_episode_return = 68.315, mean_episode_step = 990.51, total_loss = -45.054, pg_loss = -106.82, baseline_loss = 67.18, entropy_loss = -5.4162, learner_queue_size = 32, _tick = 20980, _time = 1.6548e+09, train_seconds = 2.0848e+04)
[2022-06-10 01:55:33,470][root][INFO] - Step 78635520 @ 4092.8 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 78635520, mean_episode_return = 29.091, mean_episode_step = 966.14, total_loss = 102.27, pg_loss = 44.778, baseline_loss = 62.939, entropy_loss = -5.4513, learner_queue_size = 32, _tick = 20987, _time = 1.6548e+09, train_seconds = 2.0853e+04)
[2022-06-10 01:55:38,474][root][INFO] - Step 78656000 @ 4092.8 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 78656000, mean_episode_return = None, mean_episode_step = 1074.9, total_loss = 66.646, pg_loss = -6.1196, baseline_loss = 78.219, entropy_loss = -5.4533, learner_queue_size = 32, _tick = 20994, _time = 1.6548e+09, train_seconds = 2.0858e+04)
[2022-06-10 01:55:43,478][root][INFO] - Step 78676480 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 78676480, mean_episode_return = 41.623, mean_episode_step = 934.13, total_loss = 30.17, pg_loss = -2.5351, baseline_loss = 38.191, entropy_loss = -5.4856, learner_queue_size = 32, _tick = 21000, _time = 1.6548e+09, train_seconds = 2.0863e+04)
[2022-06-10 01:55:48,482][root][INFO] - Step 78694400 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 78694400, mean_episode_return = 27.27, mean_episode_step = 925.01, total_loss = -155.89, pg_loss = -184.73, baseline_loss = 34.381, entropy_loss = -5.534, learner_queue_size = 32, _tick = 21005, _time = 1.6548e+09, train_seconds = 2.0868e+04)
[2022-06-10 01:55:53,486][root][INFO] - Step 78714880 @ 4092.8 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (step = 78714880, mean_episode_return = 115.91, mean_episode_step = 1023.3, total_loss = -149.63, pg_loss = -166.84, baseline_loss = 22.777, entropy_loss = -5.5709, learner_queue_size = 32, _tick = 21012, _time = 1.6548e+09, train_seconds = 2.0873e+04)
[2022-06-10 01:55:58,490][root][INFO] - Step 78735360 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 78735360, mean_episode_return = None, mean_episode_step = 1003.3, total_loss = 229.02, pg_loss = 176.04, baseline_loss = 58.6, entropy_loss = -5.6222, learner_queue_size = 32, _tick = 21017, _time = 1.6548e+09, train_seconds = 2.0878e+04)
[2022-06-10 01:56:03,494][root][INFO] - Step 78753280 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 78753280, mean_episode_return = 65.484, mean_episode_step = 1100.0, total_loss = -195.58, pg_loss = -208.94, baseline_loss = 18.934, entropy_loss = -5.5715, learner_queue_size = 32, _tick = 21024, _time = 1.6548e+09, train_seconds = 2.0883e+04)
[2022-06-10 01:56:08,498][root][INFO] - Step 78773760 @ 4092.8 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 78773760, mean_episode_return = None, mean_episode_step = 840.62, total_loss = 37.874, pg_loss = -3.5567, baseline_loss = 46.836, entropy_loss = -5.4045, learner_queue_size = 32, _tick = 21029, _time = 1.6548e+09, train_seconds = 2.0888e+04)
[2022-06-10 01:56:13,502][root][INFO] - Step 78794240 @ 4092.7 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (step = 78794240, mean_episode_return = 80.55, mean_episode_step = 956.26, total_loss = 424.02, pg_loss = 293.94, baseline_loss = 135.58, entropy_loss = -5.5089, learner_queue_size = 32, _tick = 21036, _time = 1.6548e+09, train_seconds = 2.0893e+04)
[2022-06-10 01:56:18,506][root][INFO] - Step 78814720 @ 4092.8 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 78814720, mean_episode_return = 26.89, mean_episode_step = 831.77, total_loss = 204.24, pg_loss = 143.58, baseline_loss = 66.163, entropy_loss = -5.5042, learner_queue_size = 32, _tick = 21040, _time = 1.6548e+09, train_seconds = 2.0898e+04)
[2022-06-10 01:56:23,510][root][INFO] - Step 78832640 @ 3581.0 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 78832640, mean_episode_return = 0.95, mean_episode_step = 932.48, total_loss = 344.42, pg_loss = 254.68, baseline_loss = 95.247, entropy_loss = -5.5138, learner_queue_size = 32, _tick = 21045, _time = 1.6548e+09, train_seconds = 2.0903e+04)
[2022-06-10 01:56:28,514][root][INFO] - Step 78853120 @ 4092.8 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 78853120, mean_episode_return = 68.262, mean_episode_step = 1182.1, total_loss = 188.23, pg_loss = 117.03, baseline_loss = 76.695, entropy_loss = -5.4901, learner_queue_size = 32, _tick = 21052, _time = 1.6548e+09, train_seconds = 2.0908e+04)
[2022-06-10 01:56:33,518][root][INFO] - Step 78873600 @ 4092.8 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 78873600, mean_episode_return = 115.6, mean_episode_step = 966.63, total_loss = -226.38, pg_loss = -346.82, baseline_loss = 125.84, entropy_loss = -5.4042, learner_queue_size = 32, _tick = 21060, _time = 1.6548e+09, train_seconds = 2.0913e+04)
[2022-06-10 01:56:38,522][root][INFO] - Step 78894080 @ 4092.6 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 78894080, mean_episode_return = None, mean_episode_step = 829.97, total_loss = 173.93, pg_loss = 101.38, baseline_loss = 78.027, entropy_loss = -5.4802, learner_queue_size = 32, _tick = 21066, _time = 1.6548e+09, train_seconds = 2.0918e+04)
[2022-06-10 01:56:43,526][root][INFO] - Step 78912000 @ 3581.2 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 78912000, mean_episode_return = 17.115, mean_episode_step = 950.59, total_loss = -24.546, pg_loss = -59.184, baseline_loss = 40.157, entropy_loss = -5.5182, learner_queue_size = 32, _tick = 21073, _time = 1.6548e+09, train_seconds = 2.0923e+04)
[2022-06-10 01:56:48,530][root][INFO] - Step 78932480 @ 4092.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 78932480, mean_episode_return = 86.799, mean_episode_step = 1165.4, total_loss = 229.24, pg_loss = 185.57, baseline_loss = 49.221, entropy_loss = -5.5554, learner_queue_size = 32, _tick = 21080, _time = 1.6548e+09, train_seconds = 2.0928e+04)
[2022-06-10 01:56:53,534][root][INFO] - Step 78952960 @ 4092.7 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 78952960, mean_episode_return = 65.745, mean_episode_step = 978.74, total_loss = 216.07, pg_loss = 142.45, baseline_loss = 79.123, entropy_loss = -5.5032, learner_queue_size = 32, _tick = 21087, _time = 1.6548e+09, train_seconds = 2.0933e+04)
[2022-06-10 01:56:58,538][root][INFO] - Step 78973440 @ 4092.7 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 78973440, mean_episode_return = 19.2, mean_episode_step = 871.5, total_loss = -81.419, pg_loss = -189.11, baseline_loss = 113.07, entropy_loss = -5.376, learner_queue_size = 32, _tick = 21094, _time = 1.6548e+09, train_seconds = 2.0938e+04)
[2022-06-10 01:57:03,546][root][INFO] - Step 78993920 @ 4089.8 SPS. Inference batcher size: 84. Learner queue size: 32. Other stats: (step = 78993920, mean_episode_return = 30.81, mean_episode_step = 836.54, total_loss = 366.78, pg_loss = 285.01, baseline_loss = 87.206, entropy_loss = -5.4328, learner_queue_size = 32, _tick = 21101, _time = 1.6548e+09, train_seconds = 2.0943e+04)
[2022-06-10 01:57:08,550][root][INFO] - Step 79011840 @ 3580.9 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 79011840, mean_episode_return = None, mean_episode_step = 985.47, total_loss = 362.77, pg_loss = 156.54, baseline_loss = 211.72, entropy_loss = -5.4936, learner_queue_size = 32, _tick = 21107, _time = 1.6548e+09, train_seconds = 2.0948e+04)
[2022-06-10 01:57:13,555][root][INFO] - Step 79032320 @ 4092.2 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 79032320, mean_episode_return = 53.215, mean_episode_step = 728.44, total_loss = 83.586, pg_loss = 22.429, baseline_loss = 66.655, entropy_loss = -5.4978, learner_queue_size = 32, _tick = 21112, _time = 1.6548e+09, train_seconds = 2.0953e+04)
[2022-06-10 01:57:18,558][root][INFO] - Step 79052800 @ 4093.3 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 79052800, mean_episode_return = 68.99, mean_episode_step = 1174.3, total_loss = -35.204, pg_loss = -71.744, baseline_loss = 42.041, entropy_loss = -5.5019, learner_queue_size = 32, _tick = 21116, _time = 1.6548e+09, train_seconds = 2.0958e+04)
[2022-06-10 01:57:23,562][root][INFO] - Step 79070720 @ 3581.1 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 79070720, mean_episode_return = None, mean_episode_step = 913.03, total_loss = -123.47, pg_loss = -148.72, baseline_loss = 30.599, entropy_loss = -5.3426, learner_queue_size = 32, _tick = 21121, _time = 1.6548e+09, train_seconds = 2.0963e+04)
[2022-06-10 01:57:28,566][root][INFO] - Step 79091200 @ 4092.8 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 79091200, mean_episode_return = 70.274, mean_episode_step = 820.03, total_loss = 186.86, pg_loss = 93.169, baseline_loss = 98.912, entropy_loss = -5.2164, learner_queue_size = 32, _tick = 21127, _time = 1.6548e+09, train_seconds = 2.0968e+04)
[2022-06-10 01:57:33,570][root][INFO] - Step 79111680 @ 4092.7 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (step = 79111680, mean_episode_return = 49.741, mean_episode_step = 1279.4, total_loss = 300.59, pg_loss = 192.84, baseline_loss = 113.12, entropy_loss = -5.3622, learner_queue_size = 32, _tick = 21134, _time = 1.6548e+09, train_seconds = 2.0973e+04)
[2022-06-10 01:57:38,574][root][INFO] - Step 79132160 @ 4092.8 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 79132160, mean_episode_return = None, mean_episode_step = 1251.2, total_loss = 32.191, pg_loss = -36.967, baseline_loss = 74.623, entropy_loss = -5.4645, learner_queue_size = 32, _tick = 21139, _time = 1.6548e+09, train_seconds = 2.0978e+04)
[2022-06-10 01:57:43,578][root][INFO] - Step 79150080 @ 3581.1 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 79150080, mean_episode_return = 174.59, mean_episode_step = 1386.8, total_loss = -101.74, pg_loss = -114.97, baseline_loss = 18.687, entropy_loss = -5.4544, learner_queue_size = 32, _tick = 21145, _time = 1.6548e+09, train_seconds = 2.0983e+04)
[2022-06-10 01:57:48,582][root][INFO] - Step 79170560 @ 4092.7 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (step = 79170560, mean_episode_return = 95.886, mean_episode_step = 913.3, total_loss = 3.0305, pg_loss = -22.774, baseline_loss = 31.272, entropy_loss = -5.4681, learner_queue_size = 32, _tick = 21153, _time = 1.6548e+09, train_seconds = 2.0988e+04)
[2022-06-10 01:57:53,586][root][INFO] - Step 79191040 @ 4092.8 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 79191040, mean_episode_return = 35.62, mean_episode_step = 928.54, total_loss = -10.748, pg_loss = -36.781, baseline_loss = 31.46, entropy_loss = -5.4273, learner_queue_size = 32, _tick = 21160, _time = 1.6548e+09, train_seconds = 2.0993e+04)
[2022-06-10 01:57:58,590][root][INFO] - Step 79211520 @ 4092.7 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 79211520, mean_episode_return = 83.08, mean_episode_step = 1227.9, total_loss = -131.48, pg_loss = -172.07, baseline_loss = 45.932, entropy_loss = -5.3502, learner_queue_size = 32, _tick = 21167, _time = 1.6548e+09, train_seconds = 2.0998e+04)
[2022-06-10 01:58:03,594][root][INFO] - Step 79229440 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 79229440, mean_episode_return = None, mean_episode_step = 1203.2, total_loss = -27.149, pg_loss = -50.033, baseline_loss = 28.389, entropy_loss = -5.5046, learner_queue_size = 32, _tick = 21173, _time = 1.6548e+09, train_seconds = 2.1003e+04)
[2022-06-10 01:58:08,598][root][INFO] - Step 79249920 @ 4092.8 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 79249920, mean_episode_return = 37.501, mean_episode_step = 928.5, total_loss = 88.358, pg_loss = 40.166, baseline_loss = 53.727, entropy_loss = -5.534, learner_queue_size = 32, _tick = 21178, _time = 1.6548e+09, train_seconds = 2.1008e+04)
[2022-06-10 01:58:13,602][root][INFO] - Step 79270400 @ 4092.6 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 79270400, mean_episode_return = 41.701, mean_episode_step = 1117.6, total_loss = 140.42, pg_loss = 113.01, baseline_loss = 32.927, entropy_loss = -5.5172, learner_queue_size = 32, _tick = 21186, _time = 1.6548e+09, train_seconds = 2.1013e+04)
[2022-06-10 01:58:18,606][root][INFO] - Step 79290880 @ 4092.8 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (step = 79290880, mean_episode_return = None, mean_episode_step = 1068.3, total_loss = 193.33, pg_loss = 149.89, baseline_loss = 48.942, entropy_loss = -5.5032, learner_queue_size = 32, _tick = 21192, _time = 1.6548e+09, train_seconds = 2.1018e+04)
[2022-06-10 01:58:23,610][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 01:58:23,737][root][INFO] - Step 79308800 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 79308800, mean_episode_return = 56.16, mean_episode_step = 943.25, total_loss = 336.27, pg_loss = 232.42, baseline_loss = 109.31, entropy_loss = -5.4551, learner_queue_size = 32, _tick = 21198, _time = 1.6548e+09, train_seconds = 2.1023e+04)
[2022-06-10 01:58:28,742][root][INFO] - Step 79329280 @ 3990.6 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 79329280, mean_episode_return = 53.644, mean_episode_step = 793.94, total_loss = -33.447, pg_loss = -132.78, baseline_loss = 104.59, entropy_loss = -5.2593, learner_queue_size = 32, _tick = 21204, _time = 1.6548e+09, train_seconds = 2.1028e+04)
[2022-06-10 01:58:33,746][root][INFO] - Step 79349760 @ 4092.4 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (step = 79349760, mean_episode_return = 50.141, mean_episode_step = 932.59, total_loss = -0.7165, pg_loss = -38.054, baseline_loss = 42.784, entropy_loss = -5.4467, learner_queue_size = 32, _tick = 21210, _time = 1.6548e+09, train_seconds = 2.1034e+04)
[2022-06-10 01:58:38,750][root][INFO] - Step 79370240 @ 4092.9 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 79370240, mean_episode_return = 89.65, mean_episode_step = 834.51, total_loss = 176.77, pg_loss = 97.922, baseline_loss = 84.18, entropy_loss = -5.3297, learner_queue_size = 32, _tick = 21216, _time = 1.6548e+09, train_seconds = 2.1039e+04)
[2022-06-10 01:58:43,754][root][INFO] - Step 79388160 @ 3581.2 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 79388160, mean_episode_return = 35.43, mean_episode_step = 1266.4, total_loss = -25.22, pg_loss = -71.254, baseline_loss = 51.425, entropy_loss = -5.3923, learner_queue_size = 32, _tick = 21223, _time = 1.6548e+09, train_seconds = 2.1044e+04)
[2022-06-10 01:58:48,760][root][INFO] - Step 79408640 @ 4090.8 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (step = 79408640, mean_episode_return = 36.857, mean_episode_step = 856.3, total_loss = 173.54, pg_loss = 98.268, baseline_loss = 80.412, entropy_loss = -5.1382, learner_queue_size = 32, _tick = 21231, _time = 1.6548e+09, train_seconds = 2.1049e+04)
[2022-06-10 01:58:53,766][root][INFO] - Step 79426560 @ 3579.9 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 79426560, mean_episode_return = None, mean_episode_step = 879.31, total_loss = -23.581, pg_loss = -44.933, baseline_loss = 26.4, entropy_loss = -5.0481, learner_queue_size = 32, _tick = 21235, _time = 1.6548e+09, train_seconds = 2.1054e+04)
[2022-06-10 01:58:58,772][root][INFO] - Step 79444480 @ 3579.7 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 79444480, mean_episode_return = 10.07, mean_episode_step = 894.49, total_loss = 515.75, pg_loss = 313.76, baseline_loss = 207.14, entropy_loss = -5.1522, learner_queue_size = 32, _tick = 21241, _time = 1.6548e+09, train_seconds = 2.1059e+04)
[2022-06-10 01:59:03,778][root][INFO] - Step 79464960 @ 4091.1 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 79464960, mean_episode_return = 32.3, mean_episode_step = 989.62, total_loss = 328.76, pg_loss = 207.74, baseline_loss = 126.24, entropy_loss = -5.2217, learner_queue_size = 32, _tick = 21248, _time = 1.6548e+09, train_seconds = 2.1064e+04)
[2022-06-10 01:59:08,782][root][INFO] - Step 79485440 @ 4092.5 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 79485440, mean_episode_return = 46.192, mean_episode_step = 917.24, total_loss = 41.911, pg_loss = 10.341, baseline_loss = 36.893, entropy_loss = -5.3237, learner_queue_size = 32, _tick = 21254, _time = 1.6548e+09, train_seconds = 2.1069e+04)
[2022-06-10 01:59:13,786][root][INFO] - Step 79505920 @ 4092.9 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 79505920, mean_episode_return = None, mean_episode_step = 1138.7, total_loss = 363.93, pg_loss = 265.72, baseline_loss = 103.61, entropy_loss = -5.4008, learner_queue_size = 32, _tick = 21258, _time = 1.6548e+09, train_seconds = 2.1074e+04)
[2022-06-10 01:59:18,790][root][INFO] - Step 79523840 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 79523840, mean_episode_return = 49.103, mean_episode_step = 940.67, total_loss = 0.24865, pg_loss = -67.342, baseline_loss = 72.971, entropy_loss = -5.3808, learner_queue_size = 32, _tick = 21264, _time = 1.6548e+09, train_seconds = 2.1079e+04)
[2022-06-10 01:59:23,794][root][INFO] - Step 79544320 @ 4092.6 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 79544320, mean_episode_return = 47.33, mean_episode_step = 926.6, total_loss = -104.84, pg_loss = -130.2, baseline_loss = 30.82, entropy_loss = -5.4608, learner_queue_size = 32, _tick = 21270, _time = 1.6548e+09, train_seconds = 2.1084e+04)
[2022-06-10 01:59:28,798][root][INFO] - Step 79562240 @ 3581.3 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 79562240, mean_episode_return = 55.03, mean_episode_step = 876.82, total_loss = 14.312, pg_loss = -25.427, baseline_loss = 45.197, entropy_loss = -5.4584, learner_queue_size = 32, _tick = 21276, _time = 1.6548e+09, train_seconds = 2.1089e+04)
[2022-06-10 01:59:33,802][root][INFO] - Step 79582720 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 79582720, mean_episode_return = 40.656, mean_episode_step = 979.34, total_loss = 236.14, pg_loss = 174.27, baseline_loss = 67.178, entropy_loss = -5.3085, learner_queue_size = 32, _tick = 21283, _time = 1.6548e+09, train_seconds = 2.1094e+04)
[2022-06-10 01:59:38,806][root][INFO] - Step 79600640 @ 3581.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 79600640, mean_episode_return = 13.95, mean_episode_step = 1030.1, total_loss = 327.74, pg_loss = 225.07, baseline_loss = 108.05, entropy_loss = -5.379, learner_queue_size = 32, _tick = 21288, _time = 1.6548e+09, train_seconds = 2.1099e+04)
[2022-06-10 01:59:43,810][root][INFO] - Step 79621120 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 79621120, mean_episode_return = 99.87, mean_episode_step = 1037.7, total_loss = 339.94, pg_loss = 213.42, baseline_loss = 131.76, entropy_loss = -5.2386, learner_queue_size = 32, _tick = 21296, _time = 1.6548e+09, train_seconds = 2.1104e+04)
[2022-06-10 01:59:48,814][root][INFO] - Step 79639040 @ 3581.2 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 79639040, mean_episode_return = 46.01, mean_episode_step = 1069.0, total_loss = -139.26, pg_loss = -164.78, baseline_loss = 30.72, entropy_loss = -5.2005, learner_queue_size = 32, _tick = 21303, _time = 1.6548e+09, train_seconds = 2.1109e+04)
[2022-06-10 01:59:53,823][root][INFO] - Step 79659520 @ 4088.9 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 79659520, mean_episode_return = None, mean_episode_step = 1003.1, total_loss = 141.6, pg_loss = 87.846, baseline_loss = 59.097, entropy_loss = -5.346, learner_queue_size = 32, _tick = 21310, _time = 1.6548e+09, train_seconds = 2.1114e+04)
[2022-06-10 01:59:58,826][root][INFO] - Step 79677440 @ 3581.6 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 79677440, mean_episode_return = 57.515, mean_episode_step = 818.28, total_loss = 28.083, pg_loss = -34.116, baseline_loss = 67.418, entropy_loss = -5.2187, learner_queue_size = 32, _tick = 21316, _time = 1.6548e+09, train_seconds = 2.1119e+04)
[2022-06-10 02:00:03,830][root][INFO] - Step 79697920 @ 4092.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 79697920, mean_episode_return = 140.06, mean_episode_step = 888.43, total_loss = -60.547, pg_loss = -112.92, baseline_loss = 57.606, entropy_loss = -5.2359, learner_queue_size = 32, _tick = 21323, _time = 1.6548e+09, train_seconds = 2.1124e+04)
[2022-06-10 02:00:08,834][root][INFO] - Step 79715840 @ 3581.1 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 79715840, mean_episode_return = 71.654, mean_episode_step = 885.51, total_loss = 115.63, pg_loss = 73.942, baseline_loss = 46.877, entropy_loss = -5.192, learner_queue_size = 32, _tick = 21330, _time = 1.6548e+09, train_seconds = 2.1129e+04)
[2022-06-10 02:00:13,838][root][INFO] - Step 79736320 @ 4092.8 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 79736320, mean_episode_return = 28.79, mean_episode_step = 1238.7, total_loss = -60.206, pg_loss = -97.257, baseline_loss = 42.312, entropy_loss = -5.2607, learner_queue_size = 32, _tick = 21333, _time = 1.6548e+09, train_seconds = 2.1134e+04)
[2022-06-10 02:00:18,845][root][INFO] - Step 79756800 @ 4090.3 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 79756800, mean_episode_return = 79.539, mean_episode_step = 851.92, total_loss = 99.213, pg_loss = 40.799, baseline_loss = 63.604, entropy_loss = -5.1906, learner_queue_size = 32, _tick = 21338, _time = 1.6548e+09, train_seconds = 2.1139e+04)
[2022-06-10 02:00:23,846][root][INFO] - Step 79774720 @ 3582.9 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 79774720, mean_episode_return = None, mean_episode_step = 1001.9, total_loss = 102.21, pg_loss = 54.676, baseline_loss = 52.936, entropy_loss = -5.3975, learner_queue_size = 32, _tick = 21343, _time = 1.6548e+09, train_seconds = 2.1144e+04)
[2022-06-10 02:00:28,850][root][INFO] - Step 79795200 @ 4093.0 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 79795200, mean_episode_return = None, mean_episode_step = 996.0, total_loss = -8.7643, pg_loss = -35.832, baseline_loss = 32.522, entropy_loss = -5.4543, learner_queue_size = 32, _tick = 21350, _time = 1.6548e+09, train_seconds = 2.1149e+04)
[2022-06-10 02:00:33,854][root][INFO] - Step 79813120 @ 3581.2 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 79813120, mean_episode_return = 59.085, mean_episode_step = 978.57, total_loss = 206.29, pg_loss = 175.03, baseline_loss = 36.771, entropy_loss = -5.5176, learner_queue_size = 32, _tick = 21357, _time = 1.6548e+09, train_seconds = 2.1154e+04)
[2022-06-10 02:00:38,858][root][INFO] - Step 79833600 @ 4092.8 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 79833600, mean_episode_return = 57.333, mean_episode_step = 970.22, total_loss = -51.714, pg_loss = -103.14, baseline_loss = 56.787, entropy_loss = -5.363, learner_queue_size = 32, _tick = 21364, _time = 1.6548e+09, train_seconds = 2.1159e+04)
[2022-06-10 02:00:43,862][root][INFO] - Step 79851520 @ 3581.1 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 79851520, mean_episode_return = 30.211, mean_episode_step = 1035.3, total_loss = -64.885, pg_loss = -83.462, baseline_loss = 23.999, entropy_loss = -5.4219, learner_queue_size = 32, _tick = 21370, _time = 1.6548e+09, train_seconds = 2.1164e+04)
[2022-06-10 02:00:48,866][root][INFO] - Step 79872000 @ 4092.7 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 79872000, mean_episode_return = 78.438, mean_episode_step = 795.72, total_loss = 4.9874, pg_loss = -44.604, baseline_loss = 55.033, entropy_loss = -5.4412, learner_queue_size = 32, _tick = 21377, _time = 1.6548e+09, train_seconds = 2.1169e+04)
[2022-06-10 02:00:53,870][root][INFO] - Step 79892480 @ 4092.6 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 79892480, mean_episode_return = 19.47, mean_episode_step = 769.05, total_loss = 129.92, pg_loss = 64.749, baseline_loss = 70.575, entropy_loss = -5.4083, learner_queue_size = 32, _tick = 21385, _time = 1.6548e+09, train_seconds = 2.1174e+04)
[2022-06-10 02:00:58,874][root][INFO] - Step 79910400 @ 3581.2 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (step = 79910400, mean_episode_return = 136.82, mean_episode_step = 739.98, total_loss = -30.228, pg_loss = -77.801, baseline_loss = 52.96, entropy_loss = -5.3874, learner_queue_size = 32, _tick = 21391, _time = 1.6548e+09, train_seconds = 2.1179e+04)
[2022-06-10 02:01:03,878][root][INFO] - Step 79930880 @ 4092.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 79930880, mean_episode_return = 58.95, mean_episode_step = 713.4, total_loss = 80.014, pg_loss = 40.322, baseline_loss = 45.026, entropy_loss = -5.3337, learner_queue_size = 32, _tick = 21399, _time = 1.6548e+09, train_seconds = 2.1184e+04)
[2022-06-10 02:01:08,882][root][INFO] - Step 79948800 @ 3581.2 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 79948800, mean_episode_return = 56.39, mean_episode_step = 727.73, total_loss = 97.576, pg_loss = 36.109, baseline_loss = 66.822, entropy_loss = -5.3548, learner_queue_size = 32, _tick = 21405, _time = 1.6548e+09, train_seconds = 2.1189e+04)
[2022-06-10 02:01:13,886][root][INFO] - Step 79969280 @ 4092.7 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 79969280, mean_episode_return = 51.261, mean_episode_step = 903.96, total_loss = -55.865, pg_loss = -113.0, baseline_loss = 62.505, entropy_loss = -5.3655, learner_queue_size = 32, _tick = 21411, _time = 1.6548e+09, train_seconds = 2.1194e+04)
[2022-06-10 02:01:18,890][root][INFO] - Step 79987200 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 79987200, mean_episode_return = None, mean_episode_step = 619.75, total_loss = 187.66, pg_loss = 95.311, baseline_loss = 97.766, entropy_loss = -5.4191, learner_queue_size = 32, _tick = 21417, _time = 1.6548e+09, train_seconds = 2.1199e+04)
[2022-06-10 02:01:23,894][root][INFO] - Step 80007680 @ 4092.7 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 80007680, mean_episode_return = 13.546, mean_episode_step = 989.35, total_loss = -109.93, pg_loss = -135.47, baseline_loss = 30.958, entropy_loss = -5.4135, learner_queue_size = 32, _tick = 21424, _time = 1.6548e+09, train_seconds = 2.1204e+04)
[2022-06-10 02:01:28,898][root][INFO] - Step 80025600 @ 3581.1 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 80025600, mean_episode_return = 121.6, mean_episode_step = 1181.2, total_loss = 164.94, pg_loss = 115.93, baseline_loss = 54.492, entropy_loss = -5.4802, learner_queue_size = 32, _tick = 21429, _time = 1.6548e+09, train_seconds = 2.1209e+04)
[2022-06-10 02:01:33,902][root][INFO] - Step 80046080 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 80046080, mean_episode_return = 134.53, mean_episode_step = 821.06, total_loss = 165.82, pg_loss = 75.79, baseline_loss = 95.408, entropy_loss = -5.375, learner_queue_size = 32, _tick = 21435, _time = 1.6548e+09, train_seconds = 2.1214e+04)
[2022-06-10 02:01:38,906][root][INFO] - Step 80066560 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 80066560, mean_episode_return = 81.559, mean_episode_step = 817.77, total_loss = 184.05, pg_loss = 122.75, baseline_loss = 66.644, entropy_loss = -5.3478, learner_queue_size = 32, _tick = 21442, _time = 1.6548e+09, train_seconds = 2.1219e+04)
[2022-06-10 02:01:43,910][root][INFO] - Step 80084480 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 80084480, mean_episode_return = 76.381, mean_episode_step = 994.31, total_loss = 133.49, pg_loss = 84.409, baseline_loss = 54.502, entropy_loss = -5.4165, learner_queue_size = 32, _tick = 21449, _time = 1.6548e+09, train_seconds = 2.1224e+04)
[2022-06-10 02:01:48,914][root][INFO] - Step 80104960 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 80104960, mean_episode_return = 34.245, mean_episode_step = 889.49, total_loss = -225.27, pg_loss = -271.21, baseline_loss = 51.335, entropy_loss = -5.3944, learner_queue_size = 32, _tick = 21456, _time = 1.6548e+09, train_seconds = 2.1229e+04)
[2022-06-10 02:01:53,919][root][INFO] - Step 80125440 @ 4092.2 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (step = 80125440, mean_episode_return = 13.93, mean_episode_step = 871.63, total_loss = -43.143, pg_loss = -80.144, baseline_loss = 42.473, entropy_loss = -5.4723, learner_queue_size = 32, _tick = 21463, _time = 1.6548e+09, train_seconds = 2.1234e+04)
[2022-06-10 02:01:58,922][root][INFO] - Step 80143360 @ 3581.6 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 80143360, mean_episode_return = None, mean_episode_step = 835.06, total_loss = 138.69, pg_loss = 75.265, baseline_loss = 68.903, entropy_loss = -5.4797, learner_queue_size = 32, _tick = 21469, _time = 1.6548e+09, train_seconds = 2.1239e+04)
[2022-06-10 02:02:03,926][root][INFO] - Step 80163840 @ 4092.6 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 80163840, mean_episode_return = 45.73, mean_episode_step = 938.4, total_loss = 259.65, pg_loss = 183.54, baseline_loss = 81.542, entropy_loss = -5.4314, learner_queue_size = 32, _tick = 21476, _time = 1.6548e+09, train_seconds = 2.1244e+04)
[2022-06-10 02:02:08,930][root][INFO] - Step 80184320 @ 4092.9 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 80184320, mean_episode_return = 150.48, mean_episode_step = 905.69, total_loss = 477.22, pg_loss = 379.78, baseline_loss = 102.9, entropy_loss = -5.4614, learner_queue_size = 32, _tick = 21484, _time = 1.6548e+09, train_seconds = 2.1249e+04)
[2022-06-10 02:02:13,934][root][INFO] - Step 80202240 @ 3581.1 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 80202240, mean_episode_return = 80.7, mean_episode_step = 977.22, total_loss = -58.891, pg_loss = -92.083, baseline_loss = 38.619, entropy_loss = -5.4273, learner_queue_size = 32, _tick = 21488, _time = 1.6548e+09, train_seconds = 2.1254e+04)
[2022-06-10 02:02:18,938][root][INFO] - Step 80222720 @ 4092.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 80222720, mean_episode_return = 55.453, mean_episode_step = 851.15, total_loss = 42.663, pg_loss = -2.9254, baseline_loss = 50.993, entropy_loss = -5.4045, learner_queue_size = 32, _tick = 21494, _time = 1.6548e+09, train_seconds = 2.1259e+04)
[2022-06-10 02:02:23,943][root][INFO] - Step 80240640 @ 3580.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 80240640, mean_episode_return = None, mean_episode_step = 1023.9, total_loss = 263.31, pg_loss = 213.9, baseline_loss = 54.911, entropy_loss = -5.4961, learner_queue_size = 32, _tick = 21499, _time = 1.6548e+09, train_seconds = 2.1264e+04)
[2022-06-10 02:02:28,946][root][INFO] - Step 80261120 @ 4093.9 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 80261120, mean_episode_return = 58.774, mean_episode_step = 885.09, total_loss = 228.76, pg_loss = 146.56, baseline_loss = 87.663, entropy_loss = -5.465, learner_queue_size = 32, _tick = 21507, _time = 1.6548e+09, train_seconds = 2.1269e+04)
[2022-06-10 02:02:33,950][root][INFO] - Step 80281600 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 80281600, mean_episode_return = 28.14, mean_episode_step = 731.99, total_loss = -189.65, pg_loss = -203.07, baseline_loss = 18.885, entropy_loss = -5.4637, learner_queue_size = 32, _tick = 21513, _time = 1.6548e+09, train_seconds = 2.1274e+04)
[2022-06-10 02:02:38,954][root][INFO] - Step 80302080 @ 4092.6 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 80302080, mean_episode_return = 44.99, mean_episode_step = 857.2, total_loss = -190.31, pg_loss = -230.91, baseline_loss = 46.093, entropy_loss = -5.4948, learner_queue_size = 32, _tick = 21518, _time = 1.6548e+09, train_seconds = 2.1279e+04)
[2022-06-10 02:02:43,958][root][INFO] - Step 80320000 @ 3581.2 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 80320000, mean_episode_return = 59.072, mean_episode_step = 875.85, total_loss = -88.126, pg_loss = -126.72, baseline_loss = 44.139, entropy_loss = -5.5415, learner_queue_size = 32, _tick = 21524, _time = 1.6548e+09, train_seconds = 2.1284e+04)
[2022-06-10 02:02:48,962][root][INFO] - Step 80340480 @ 4092.8 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 80340480, mean_episode_return = None, mean_episode_step = 853.81, total_loss = 33.613, pg_loss = 17.343, baseline_loss = 21.79, entropy_loss = -5.5209, learner_queue_size = 32, _tick = 21529, _time = 1.6548e+09, train_seconds = 2.1289e+04)
[2022-06-10 02:02:53,966][root][INFO] - Step 80360960 @ 4092.7 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 80360960, mean_episode_return = None, mean_episode_step = 802.97, total_loss = 216.22, pg_loss = 158.17, baseline_loss = 63.53, entropy_loss = -5.4792, learner_queue_size = 32, _tick = 21536, _time = 1.6548e+09, train_seconds = 2.1294e+04)
[2022-06-10 02:02:58,970][root][INFO] - Step 80381440 @ 4092.7 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (step = 80381440, mean_episode_return = 9.8148, mean_episode_step = 873.62, total_loss = 159.73, pg_loss = 86.827, baseline_loss = 78.39, entropy_loss = -5.4895, learner_queue_size = 32, _tick = 21543, _time = 1.6548e+09, train_seconds = 2.1299e+04)
[2022-06-10 02:03:03,974][root][INFO] - Step 80399360 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 80399360, mean_episode_return = None, mean_episode_step = 839.53, total_loss = 454.15, pg_loss = 363.24, baseline_loss = 96.245, entropy_loss = -5.3287, learner_queue_size = 32, _tick = 21545, _time = 1.6548e+09, train_seconds = 2.1304e+04)
[2022-06-10 02:03:08,978][root][INFO] - Step 80419840 @ 4092.7 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 80419840, mean_episode_return = 50.095, mean_episode_step = 1128.2, total_loss = -190.15, pg_loss = -206.38, baseline_loss = 21.575, entropy_loss = -5.3478, learner_queue_size = 32, _tick = 21551, _time = 1.6548e+09, train_seconds = 2.1309e+04)
[2022-06-10 02:03:13,982][root][INFO] - Step 80440320 @ 4092.8 SPS. Inference batcher size: 80. Learner queue size: 32. Other stats: (step = 80440320, mean_episode_return = None, mean_episode_step = 994.06, total_loss = -189.15, pg_loss = -201.59, baseline_loss = 17.959, entropy_loss = -5.513, learner_queue_size = 32, _tick = 21557, _time = 1.6548e+09, train_seconds = 2.1314e+04)
[2022-06-10 02:03:18,986][root][INFO] - Step 80458240 @ 3581.1 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 80458240, mean_episode_return = 8.1298, mean_episode_step = 1010.3, total_loss = 138.3, pg_loss = 87.579, baseline_loss = 56.205, entropy_loss = -5.48, learner_queue_size = 32, _tick = 21563, _time = 1.6548e+09, train_seconds = 2.1319e+04)
[2022-06-10 02:03:23,990][root][INFO] - Step 80476160 @ 3581.2 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (step = 80476160, mean_episode_return = 53.687, mean_episode_step = 1064.6, total_loss = 138.62, pg_loss = 106.44, baseline_loss = 37.69, entropy_loss = -5.5073, learner_queue_size = 32, _tick = 21568, _time = 1.6548e+09, train_seconds = 2.1324e+04)
[2022-06-10 02:03:28,995][root][INFO] - Step 80496640 @ 4092.3 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 80496640, mean_episode_return = 95.709, mean_episode_step = 1067.3, total_loss = 117.02, pg_loss = 79.247, baseline_loss = 43.182, entropy_loss = -5.4067, learner_queue_size = 32, _tick = 21574, _time = 1.6548e+09, train_seconds = 2.1329e+04)
[2022-06-10 02:03:33,998][root][INFO] - Step 80517120 @ 4093.1 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 80517120, mean_episode_return = -23.37, mean_episode_step = 1064.1, total_loss = 317.29, pg_loss = 237.13, baseline_loss = 85.558, entropy_loss = -5.3919, learner_queue_size = 32, _tick = 21581, _time = 1.6548e+09, train_seconds = 2.1334e+04)
[2022-06-10 02:03:39,002][root][INFO] - Step 80537600 @ 4092.6 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 80537600, mean_episode_return = 76.99, mean_episode_step = 791.93, total_loss = 161.11, pg_loss = 88.184, baseline_loss = 78.177, entropy_loss = -5.2526, learner_queue_size = 32, _tick = 21588, _time = 1.6548e+09, train_seconds = 2.1339e+04)
[2022-06-10 02:03:44,006][root][INFO] - Step 80555520 @ 3581.3 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 80555520, mean_episode_return = 56.986, mean_episode_step = 1197.9, total_loss = 123.62, pg_loss = 74.509, baseline_loss = 54.563, entropy_loss = -5.4521, learner_queue_size = 32, _tick = 21595, _time = 1.6548e+09, train_seconds = 2.1344e+04)
[2022-06-10 02:03:49,010][root][INFO] - Step 80576000 @ 4092.7 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 80576000, mean_episode_return = 30.534, mean_episode_step = 1031.2, total_loss = 187.82, pg_loss = 132.9, baseline_loss = 60.231, entropy_loss = -5.3076, learner_queue_size = 32, _tick = 21601, _time = 1.6548e+09, train_seconds = 2.1349e+04)
[2022-06-10 02:03:54,014][root][INFO] - Step 80593920 @ 3581.0 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 80593920, mean_episode_return = None, mean_episode_step = 1054.1, total_loss = 184.35, pg_loss = 132.78, baseline_loss = 56.93, entropy_loss = -5.3567, learner_queue_size = 32, _tick = 21605, _time = 1.6548e+09, train_seconds = 2.1354e+04)
[2022-06-10 02:03:59,018][root][INFO] - Step 80614400 @ 4092.9 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 80614400, mean_episode_return = -1.67, mean_episode_step = 1172.4, total_loss = 56.867, pg_loss = 6.7009, baseline_loss = 55.407, entropy_loss = -5.2405, learner_queue_size = 32, _tick = 21610, _time = 1.6548e+09, train_seconds = 2.1359e+04)
[2022-06-10 02:04:04,022][root][INFO] - Step 80632320 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 80632320, mean_episode_return = 29.03, mean_episode_step = 1091.0, total_loss = -104.56, pg_loss = -116.19, baseline_loss = 17.064, entropy_loss = -5.4366, learner_queue_size = 32, _tick = 21616, _time = 1.6548e+09, train_seconds = 2.1364e+04)
[2022-06-10 02:04:09,026][root][INFO] - Step 80652800 @ 4092.8 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 80652800, mean_episode_return = 31.11, mean_episode_step = 915.18, total_loss = -193.73, pg_loss = -229.25, baseline_loss = 40.905, entropy_loss = -5.3862, learner_queue_size = 32, _tick = 21623, _time = 1.6548e+09, train_seconds = 2.1369e+04)
[2022-06-10 02:04:14,030][root][INFO] - Step 80673280 @ 4092.8 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 80673280, mean_episode_return = 10.815, mean_episode_step = 946.31, total_loss = 264.8, pg_loss = 205.24, baseline_loss = 64.883, entropy_loss = -5.3219, learner_queue_size = 32, _tick = 21629, _time = 1.6548e+09, train_seconds = 2.1374e+04)
[2022-06-10 02:04:19,034][root][INFO] - Step 80691200 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 80691200, mean_episode_return = None, mean_episode_step = 946.12, total_loss = 245.86, pg_loss = 199.53, baseline_loss = 51.764, entropy_loss = -5.4319, learner_queue_size = 32, _tick = 21635, _time = 1.6548e+09, train_seconds = 2.1379e+04)
[2022-06-10 02:04:24,038][root][INFO] - Step 80711680 @ 4092.7 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (step = 80711680, mean_episode_return = 46.593, mean_episode_step = 1019.0, total_loss = 14.294, pg_loss = -28.217, baseline_loss = 47.905, entropy_loss = -5.3949, learner_queue_size = 32, _tick = 21641, _time = 1.6548e+09, train_seconds = 2.1384e+04)
[2022-06-10 02:04:29,042][root][INFO] - Step 80729600 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 80729600, mean_episode_return = 43.673, mean_episode_step = 984.32, total_loss = -114.79, pg_loss = -147.58, baseline_loss = 38.222, entropy_loss = -5.4308, learner_queue_size = 32, _tick = 21647, _time = 1.6548e+09, train_seconds = 2.1389e+04)
[2022-06-10 02:04:34,046][root][INFO] - Step 80750080 @ 4092.7 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (step = 80750080, mean_episode_return = 42.557, mean_episode_step = 1020.8, total_loss = -24.55, pg_loss = -64.359, baseline_loss = 45.17, entropy_loss = -5.3607, learner_queue_size = 32, _tick = 21654, _time = 1.6548e+09, train_seconds = 2.1394e+04)
[2022-06-10 02:04:39,052][root][INFO] - Step 80768000 @ 3579.9 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 80768000, mean_episode_return = 37.81, mean_episode_step = 854.63, total_loss = 248.97, pg_loss = 185.87, baseline_loss = 68.401, entropy_loss = -5.3065, learner_queue_size = 32, _tick = 21660, _time = 1.6548e+09, train_seconds = 2.1399e+04)
[2022-06-10 02:04:44,054][root][INFO] - Step 80788480 @ 4094.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 80788480, mean_episode_return = 121.04, mean_episode_step = 1005.5, total_loss = 289.45, pg_loss = 224.74, baseline_loss = 70.085, entropy_loss = -5.3713, learner_queue_size = 32, _tick = 21665, _time = 1.6548e+09, train_seconds = 2.1404e+04)
[2022-06-10 02:04:49,058][root][INFO] - Step 80808960 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 80808960, mean_episode_return = 55.35, mean_episode_step = 934.78, total_loss = 47.264, pg_loss = -38.438, baseline_loss = 91.101, entropy_loss = -5.3991, learner_queue_size = 32, _tick = 21672, _time = 1.6548e+09, train_seconds = 2.1409e+04)
[2022-06-10 02:04:54,062][root][INFO] - Step 80826880 @ 3580.9 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 80826880, mean_episode_return = 37.441, mean_episode_step = 991.11, total_loss = 236.4, pg_loss = 173.89, baseline_loss = 67.826, entropy_loss = -5.3207, learner_queue_size = 32, _tick = 21679, _time = 1.6548e+09, train_seconds = 2.1414e+04)
[2022-06-10 02:04:59,066][root][INFO] - Step 80847360 @ 4092.9 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 80847360, mean_episode_return = None, mean_episode_step = 1054.3, total_loss = 18.626, pg_loss = -23.292, baseline_loss = 47.103, entropy_loss = -5.1848, learner_queue_size = 32, _tick = 21684, _time = 1.6548e+09, train_seconds = 2.1419e+04)
[2022-06-10 02:05:04,070][root][INFO] - Step 80867840 @ 4092.8 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 80867840, mean_episode_return = 25.84, mean_episode_step = 982.45, total_loss = 180.74, pg_loss = 90.281, baseline_loss = 95.691, entropy_loss = -5.2351, learner_queue_size = 32, _tick = 21691, _time = 1.6548e+09, train_seconds = 2.1424e+04)
[2022-06-10 02:05:09,074][root][INFO] - Step 80885760 @ 3581.1 SPS. Inference batcher size: 82. Learner queue size: 32. Other stats: (step = 80885760, mean_episode_return = 145.9, mean_episode_step = 1022.2, total_loss = 33.267, pg_loss = -40.729, baseline_loss = 79.322, entropy_loss = -5.3269, learner_queue_size = 32, _tick = 21696, _time = 1.6548e+09, train_seconds = 2.1429e+04)
[2022-06-10 02:05:14,079][root][INFO] - Step 80906240 @ 4092.2 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 80906240, mean_episode_return = None, mean_episode_step = 1128.6, total_loss = 411.52, pg_loss = 315.66, baseline_loss = 101.18, entropy_loss = -5.319, learner_queue_size = 32, _tick = 21700, _time = 1.6548e+09, train_seconds = 2.1434e+04)
[2022-06-10 02:05:19,082][root][INFO] - Step 80926720 @ 4093.2 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 80926720, mean_episode_return = 77.996, mean_episode_step = 935.89, total_loss = 29.135, pg_loss = -11.841, baseline_loss = 46.314, entropy_loss = -5.3385, learner_queue_size = 32, _tick = 21705, _time = 1.6548e+09, train_seconds = 2.1439e+04)
[2022-06-10 02:05:24,086][root][INFO] - Step 80944640 @ 3581.2 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 80944640, mean_episode_return = 26.471, mean_episode_step = 1034.6, total_loss = 89.308, pg_loss = 44.835, baseline_loss = 49.812, entropy_loss = -5.3391, learner_queue_size = 32, _tick = 21711, _time = 1.6548e+09, train_seconds = 2.1444e+04)
[2022-06-10 02:05:29,090][root][INFO] - Step 80965120 @ 4092.7 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 80965120, mean_episode_return = 66.315, mean_episode_step = 1012.7, total_loss = 282.02, pg_loss = 156.27, baseline_loss = 131.14, entropy_loss = -5.3868, learner_queue_size = 32, _tick = 21715, _time = 1.6548e+09, train_seconds = 2.1449e+04)
[2022-06-10 02:05:34,094][root][INFO] - Step 80985600 @ 4092.6 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 80985600, mean_episode_return = 60.571, mean_episode_step = 1045.9, total_loss = 173.44, pg_loss = 121.05, baseline_loss = 57.812, entropy_loss = -5.4159, learner_queue_size = 32, _tick = 21722, _time = 1.6548e+09, train_seconds = 2.1454e+04)
[2022-06-10 02:05:39,098][root][INFO] - Step 81006080 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 81006080, mean_episode_return = 51.445, mean_episode_step = 1067.6, total_loss = 418.76, pg_loss = 270.38, baseline_loss = 153.78, entropy_loss = -5.4018, learner_queue_size = 32, _tick = 21730, _time = 1.6548e+09, train_seconds = 2.1459e+04)
[2022-06-10 02:05:44,102][root][INFO] - Step 81024000 @ 3581.2 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 81024000, mean_episode_return = 46.1, mean_episode_step = 690.2, total_loss = 272.7, pg_loss = 211.59, baseline_loss = 66.487, entropy_loss = -5.37, learner_queue_size = 32, _tick = 21737, _time = 1.6548e+09, train_seconds = 2.1464e+04)
[2022-06-10 02:05:49,106][root][INFO] - Step 81044480 @ 4092.7 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 81044480, mean_episode_return = None, mean_episode_step = 982.19, total_loss = 221.73, pg_loss = 141.09, baseline_loss = 86.043, entropy_loss = -5.4016, learner_queue_size = 32, _tick = 21743, _time = 1.6548e+09, train_seconds = 2.1469e+04)
[2022-06-10 02:05:54,110][root][INFO] - Step 81062400 @ 3581.1 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 81062400, mean_episode_return = 27.21, mean_episode_step = 979.9, total_loss = 102.17, pg_loss = 24.338, baseline_loss = 83.168, entropy_loss = -5.3408, learner_queue_size = 32, _tick = 21750, _time = 1.6548e+09, train_seconds = 2.1474e+04)
[2022-06-10 02:05:59,114][root][INFO] - Step 81082880 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 81082880, mean_episode_return = 45.506, mean_episode_step = 913.99, total_loss = -184.9, pg_loss = -221.11, baseline_loss = 41.462, entropy_loss = -5.2543, learner_queue_size = 32, _tick = 21758, _time = 1.6548e+09, train_seconds = 2.1479e+04)
[2022-06-10 02:06:04,118][root][INFO] - Step 81103360 @ 4092.8 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 81103360, mean_episode_return = 35.77, mean_episode_step = 1179.5, total_loss = 29.655, pg_loss = -16.719, baseline_loss = 51.777, entropy_loss = -5.4027, learner_queue_size = 32, _tick = 21765, _time = 1.6548e+09, train_seconds = 2.1484e+04)
[2022-06-10 02:06:09,122][root][INFO] - Step 81123840 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 81123840, mean_episode_return = None, mean_episode_step = 883.03, total_loss = 149.01, pg_loss = 80.442, baseline_loss = 73.769, entropy_loss = -5.2012, learner_queue_size = 32, _tick = 21772, _time = 1.6548e+09, train_seconds = 2.1489e+04)
[2022-06-10 02:06:14,126][root][INFO] - Step 81144320 @ 4092.7 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 81144320, mean_episode_return = None, mean_episode_step = 940.59, total_loss = 148.82, pg_loss = 107.33, baseline_loss = 46.685, entropy_loss = -5.1989, learner_queue_size = 32, _tick = 21777, _time = 1.6548e+09, train_seconds = 2.1494e+04)
[2022-06-10 02:06:19,130][root][INFO] - Step 81162240 @ 3581.2 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 81162240, mean_episode_return = 128.7, mean_episode_step = 823.78, total_loss = -169.2, pg_loss = -186.34, baseline_loss = 22.452, entropy_loss = -5.3162, learner_queue_size = 32, _tick = 21782, _time = 1.6548e+09, train_seconds = 2.1499e+04)
[2022-06-10 02:06:24,134][root][INFO] - Step 81182720 @ 4092.7 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 81182720, mean_episode_return = 24.33, mean_episode_step = 1178.5, total_loss = -153.31, pg_loss = -157.13, baseline_loss = 9.1842, entropy_loss = -5.3607, learner_queue_size = 32, _tick = 21788, _time = 1.6548e+09, train_seconds = 2.1504e+04)
[2022-06-10 02:06:29,138][root][INFO] - Step 81200640 @ 3581.1 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 81200640, mean_episode_return = 70.405, mean_episode_step = 924.59, total_loss = -91.716, pg_loss = -143.03, baseline_loss = 56.707, entropy_loss = -5.3928, learner_queue_size = 32, _tick = 21793, _time = 1.6548e+09, train_seconds = 2.1509e+04)
[2022-06-10 02:06:34,142][root][INFO] - Step 81221120 @ 4092.8 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 81221120, mean_episode_return = 140.87, mean_episode_step = 947.48, total_loss = -188.71, pg_loss = -199.92, baseline_loss = 16.552, entropy_loss = -5.3446, learner_queue_size = 32, _tick = 21801, _time = 1.6548e+09, train_seconds = 2.1514e+04)
[2022-06-10 02:06:39,146][root][INFO] - Step 81241600 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 81241600, mean_episode_return = 40.635, mean_episode_step = 858.41, total_loss = 164.12, pg_loss = 112.4, baseline_loss = 57.079, entropy_loss = -5.3645, learner_queue_size = 32, _tick = 21808, _time = 1.6548e+09, train_seconds = 2.1519e+04)
[2022-06-10 02:06:44,150][root][INFO] - Step 81259520 @ 3581.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 81259520, mean_episode_return = 145.49, mean_episode_step = 871.71, total_loss = 261.53, pg_loss = 123.78, baseline_loss = 143.1, entropy_loss = -5.3407, learner_queue_size = 32, _tick = 21814, _time = 1.6548e+09, train_seconds = 2.1524e+04)
[2022-06-10 02:06:49,154][root][INFO] - Step 81280000 @ 4092.8 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 81280000, mean_episode_return = None, mean_episode_step = 962.06, total_loss = 164.49, pg_loss = 116.97, baseline_loss = 52.943, entropy_loss = -5.4204, learner_queue_size = 32, _tick = 21820, _time = 1.6548e+09, train_seconds = 2.1529e+04)
[2022-06-10 02:06:54,158][root][INFO] - Step 81297920 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 81297920, mean_episode_return = -14.87, mean_episode_step = 823.19, total_loss = 151.37, pg_loss = 92.936, baseline_loss = 63.794, entropy_loss = -5.3578, learner_queue_size = 32, _tick = 21826, _time = 1.6548e+09, train_seconds = 2.1534e+04)
[2022-06-10 02:06:59,162][root][INFO] - Step 81318400 @ 4092.8 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 81318400, mean_episode_return = None, mean_episode_step = 878.06, total_loss = 28.174, pg_loss = -1.4879, baseline_loss = 35.095, entropy_loss = -5.4328, learner_queue_size = 32, _tick = 21832, _time = 1.6548e+09, train_seconds = 2.1539e+04)
[2022-06-10 02:07:04,166][root][INFO] - Step 81338880 @ 4092.7 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 81338880, mean_episode_return = 43.971, mean_episode_step = 923.22, total_loss = 175.34, pg_loss = 111.04, baseline_loss = 69.773, entropy_loss = -5.4684, learner_queue_size = 32, _tick = 21840, _time = 1.6548e+09, train_seconds = 2.1544e+04)
[2022-06-10 02:07:09,170][root][INFO] - Step 81359360 @ 4092.6 SPS. Inference batcher size: 78. Learner queue size: 32. Other stats: (step = 81359360, mean_episode_return = None, mean_episode_step = 1047.3, total_loss = 333.3, pg_loss = 248.46, baseline_loss = 90.224, entropy_loss = -5.3859, learner_queue_size = 32, _tick = 21845, _time = 1.6548e+09, train_seconds = 2.1549e+04)
[2022-06-10 02:07:14,174][root][INFO] - Step 81377280 @ 3581.2 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (step = 81377280, mean_episode_return = None, mean_episode_step = 965.62, total_loss = 150.52, pg_loss = 92.328, baseline_loss = 63.463, entropy_loss = -5.2756, learner_queue_size = 32, _tick = 21850, _time = 1.6548e+09, train_seconds = 2.1554e+04)
[2022-06-10 02:07:19,179][root][INFO] - Step 81397760 @ 4092.2 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 81397760, mean_episode_return = None, mean_episode_step = 977.19, total_loss = -24.981, pg_loss = -60.733, baseline_loss = 41.13, entropy_loss = -5.3773, learner_queue_size = 32, _tick = 21855, _time = 1.6548e+09, train_seconds = 2.1559e+04)
[2022-06-10 02:07:24,183][root][INFO] - Step 81418240 @ 4093.3 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 81418240, mean_episode_return = 59.413, mean_episode_step = 963.91, total_loss = 95.277, pg_loss = 20.15, baseline_loss = 80.597, entropy_loss = -5.4708, learner_queue_size = 32, _tick = 21860, _time = 1.6548e+09, train_seconds = 2.1564e+04)
[2022-06-10 02:07:29,186][root][INFO] - Step 81436160 @ 3581.1 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 81436160, mean_episode_return = 63.96, mean_episode_step = 958.55, total_loss = 139.86, pg_loss = 80.875, baseline_loss = 64.441, entropy_loss = -5.4532, learner_queue_size = 32, _tick = 21867, _time = 1.6548e+09, train_seconds = 2.1569e+04)
[2022-06-10 02:07:34,190][root][INFO] - Step 81456640 @ 4092.7 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 81456640, mean_episode_return = 53.268, mean_episode_step = 957.56, total_loss = -42.36, pg_loss = -64.129, baseline_loss = 27.215, entropy_loss = -5.4464, learner_queue_size = 32, _tick = 21873, _time = 1.6548e+09, train_seconds = 2.1574e+04)
[2022-06-10 02:07:39,194][root][INFO] - Step 81477120 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 81477120, mean_episode_return = 52.875, mean_episode_step = 1025.2, total_loss = -49.111, pg_loss = -80.779, baseline_loss = 37.102, entropy_loss = -5.4346, learner_queue_size = 32, _tick = 21881, _time = 1.6548e+09, train_seconds = 2.1579e+04)
[2022-06-10 02:07:44,198][root][INFO] - Step 81495040 @ 3581.1 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 81495040, mean_episode_return = 77.969, mean_episode_step = 848.03, total_loss = 386.66, pg_loss = 311.76, baseline_loss = 80.246, entropy_loss = -5.3459, learner_queue_size = 32, _tick = 21888, _time = 1.6548e+09, train_seconds = 2.1584e+04)
[2022-06-10 02:07:49,203][root][INFO] - Step 81515520 @ 4092.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 81515520, mean_episode_return = 50.412, mean_episode_step = 1136.6, total_loss = -113.64, pg_loss = -123.92, baseline_loss = 15.75, entropy_loss = -5.4766, learner_queue_size = 32, _tick = 21895, _time = 1.6548e+09, train_seconds = 2.1589e+04)
[2022-06-10 02:07:54,206][root][INFO] - Step 81536000 @ 4093.4 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 81536000, mean_episode_return = 51.916, mean_episode_step = 946.89, total_loss = 5.87, pg_loss = -18.067, baseline_loss = 29.375, entropy_loss = -5.4382, learner_queue_size = 32, _tick = 21903, _time = 1.6548e+09, train_seconds = 2.1594e+04)
[2022-06-10 02:07:59,210][root][INFO] - Step 81556480 @ 4092.7 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 81556480, mean_episode_return = None, mean_episode_step = 782.84, total_loss = 94.8, pg_loss = 69.961, baseline_loss = 30.304, entropy_loss = -5.4655, learner_queue_size = 32, _tick = 21909, _time = 1.6548e+09, train_seconds = 2.1599e+04)
[2022-06-10 02:08:04,214][root][INFO] - Step 81574400 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 81574400, mean_episode_return = None, mean_episode_step = 856.62, total_loss = 201.32, pg_loss = 122.17, baseline_loss = 84.598, entropy_loss = -5.4417, learner_queue_size = 32, _tick = 21915, _time = 1.6548e+09, train_seconds = 2.1604e+04)
[2022-06-10 02:08:09,218][root][INFO] - Step 81594880 @ 4092.7 SPS. Inference batcher size: 79. Learner queue size: 32. Other stats: (step = 81594880, mean_episode_return = -5.1301, mean_episode_step = 870.86, total_loss = 10.131, pg_loss = -30.328, baseline_loss = 45.889, entropy_loss = -5.4296, learner_queue_size = 32, _tick = 21922, _time = 1.6548e+09, train_seconds = 2.1609e+04)
[2022-06-10 02:08:14,222][root][INFO] - Step 81615360 @ 4092.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 81615360, mean_episode_return = None, mean_episode_step = 1325.5, total_loss = 122.62, pg_loss = 85.903, baseline_loss = 42.236, entropy_loss = -5.5203, learner_queue_size = 32, _tick = 21929, _time = 1.6548e+09, train_seconds = 2.1614e+04)
[2022-06-10 02:08:19,226][root][INFO] - Step 81633280 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 81633280, mean_episode_return = None, mean_episode_step = 1261.7, total_loss = 399.33, pg_loss = 321.96, baseline_loss = 82.867, entropy_loss = -5.4988, learner_queue_size = 32, _tick = 21935, _time = 1.6548e+09, train_seconds = 2.1619e+04)
[2022-06-10 02:08:24,230][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 02:08:24,500][root][INFO] - Step 81651200 @ 3581.1 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (step = 81651200, mean_episode_return = 39.25, mean_episode_step = 973.1, total_loss = 58.596, pg_loss = -4.8062, baseline_loss = 68.833, entropy_loss = -5.4305, learner_queue_size = 32, _tick = 21940, _time = 1.6548e+09, train_seconds = 2.1624e+04)
[2022-06-10 02:08:29,506][root][INFO] - Step 81671680 @ 3881.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 81671680, mean_episode_return = 27.99, mean_episode_step = 970.89, total_loss = 269.14, pg_loss = 191.4, baseline_loss = 83.146, entropy_loss = -5.4055, learner_queue_size = 32, _tick = 21946, _time = 1.6548e+09, train_seconds = 2.1629e+04)
[2022-06-10 02:08:34,510][root][INFO] - Step 81692160 @ 4092.7 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 81692160, mean_episode_return = 96.789, mean_episode_step = 799.9, total_loss = 23.527, pg_loss = -14.802, baseline_loss = 43.529, entropy_loss = -5.1998, learner_queue_size = 32, _tick = 21951, _time = 1.6548e+09, train_seconds = 2.1634e+04)
[2022-06-10 02:08:39,514][root][INFO] - Step 81710080 @ 3581.2 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 81710080, mean_episode_return = 27.954, mean_episode_step = 986.16, total_loss = 218.0, pg_loss = 33.705, baseline_loss = 189.68, entropy_loss = -5.3902, learner_queue_size = 32, _tick = 21958, _time = 1.6548e+09, train_seconds = 2.1639e+04)
[2022-06-10 02:08:44,518][root][INFO] - Step 81730560 @ 4092.7 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 81730560, mean_episode_return = 29.133, mean_episode_step = 927.59, total_loss = 102.06, pg_loss = 62.316, baseline_loss = 45.18, entropy_loss = -5.4389, learner_queue_size = 32, _tick = 21964, _time = 1.6548e+09, train_seconds = 2.1644e+04)
[2022-06-10 02:08:49,522][root][INFO] - Step 81751040 @ 4092.8 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 81751040, mean_episode_return = None, mean_episode_step = 736.16, total_loss = -198.08, pg_loss = -205.91, baseline_loss = 13.219, entropy_loss = -5.3921, learner_queue_size = 32, _tick = 21969, _time = 1.6548e+09, train_seconds = 2.1649e+04)
[2022-06-10 02:08:54,526][root][INFO] - Step 81771520 @ 4092.6 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 81771520, mean_episode_return = 53.092, mean_episode_step = 867.39, total_loss = 220.87, pg_loss = 183.91, baseline_loss = 42.409, entropy_loss = -5.4495, learner_queue_size = 32, _tick = 21976, _time = 1.6548e+09, train_seconds = 2.1654e+04)
[2022-06-10 02:08:59,531][root][INFO] - Step 81792000 @ 4092.1 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 81792000, mean_episode_return = 55.481, mean_episode_step = 953.72, total_loss = -17.006, pg_loss = -46.615, baseline_loss = 35.052, entropy_loss = -5.4436, learner_queue_size = 32, _tick = 21982, _time = 1.6548e+09, train_seconds = 2.1659e+04)
[2022-06-10 02:09:04,534][root][INFO] - Step 81809920 @ 3581.8 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 81809920, mean_episode_return = 41.24, mean_episode_step = 1110.9, total_loss = 304.1, pg_loss = 218.76, baseline_loss = 90.88, entropy_loss = -5.538, learner_queue_size = 32, _tick = 21987, _time = 1.6548e+09, train_seconds = 2.1664e+04)
[2022-06-10 02:09:09,538][root][INFO] - Step 81830400 @ 4092.7 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 81830400, mean_episode_return = 83.669, mean_episode_step = 897.18, total_loss = 41.358, pg_loss = 16.714, baseline_loss = 29.988, entropy_loss = -5.3444, learner_queue_size = 32, _tick = 21992, _time = 1.6548e+09, train_seconds = 2.1669e+04)
[2022-06-10 02:09:14,542][root][INFO] - Step 81850880 @ 4092.8 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 81850880, mean_episode_return = 3.9499, mean_episode_step = 982.67, total_loss = 393.8, pg_loss = 315.23, baseline_loss = 83.934, entropy_loss = -5.3584, learner_queue_size = 32, _tick = 21999, _time = 1.6548e+09, train_seconds = 2.1674e+04)
[2022-06-10 02:09:19,546][root][INFO] - Step 81868800 @ 3581.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 81868800, mean_episode_return = 50.44, mean_episode_step = 1135.7, total_loss = -135.64, pg_loss = -145.96, baseline_loss = 15.706, entropy_loss = -5.3896, learner_queue_size = 32, _tick = 22006, _time = 1.6548e+09, train_seconds = 2.1679e+04)
[2022-06-10 02:09:24,550][root][INFO] - Step 81889280 @ 4092.6 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 81889280, mean_episode_return = 66.919, mean_episode_step = 1060.4, total_loss = 284.19, pg_loss = 206.87, baseline_loss = 82.62, entropy_loss = -5.2947, learner_queue_size = 32, _tick = 22013, _time = 1.6548e+09, train_seconds = 2.1684e+04)
[2022-06-10 02:09:29,554][root][INFO] - Step 81909760 @ 4092.8 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 81909760, mean_episode_return = 60.149, mean_episode_step = 987.87, total_loss = -16.878, pg_loss = -45.501, baseline_loss = 34.024, entropy_loss = -5.4004, learner_queue_size = 32, _tick = 22020, _time = 1.6548e+09, train_seconds = 2.1689e+04)
[2022-06-10 02:09:34,558][root][INFO] - Step 81927680 @ 3581.2 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 81927680, mean_episode_return = 70.713, mean_episode_step = 1200.9, total_loss = 51.209, pg_loss = 23.226, baseline_loss = 33.481, entropy_loss = -5.4976, learner_queue_size = 32, _tick = 22024, _time = 1.6548e+09, train_seconds = 2.1694e+04)
[2022-06-10 02:09:39,562][root][INFO] - Step 81948160 @ 4092.8 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 81948160, mean_episode_return = 37.17, mean_episode_step = 1049.7, total_loss = -142.02, pg_loss = -168.64, baseline_loss = 31.837, entropy_loss = -5.2174, learner_queue_size = 32, _tick = 22029, _time = 1.6548e+09, train_seconds = 2.1699e+04)
[2022-06-10 02:09:44,566][root][INFO] - Step 81968640 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 81968640, mean_episode_return = None, mean_episode_step = 898.91, total_loss = 218.4, pg_loss = 176.32, baseline_loss = 47.356, entropy_loss = -5.2794, learner_queue_size = 32, _tick = 22035, _time = 1.6548e+09, train_seconds = 2.1704e+04)
[2022-06-10 02:09:49,570][root][INFO] - Step 81986560 @ 3581.1 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 81986560, mean_episode_return = 68.805, mean_episode_step = 933.68, total_loss = 513.68, pg_loss = 444.21, baseline_loss = 74.912, entropy_loss = -5.4439, learner_queue_size = 32, _tick = 22042, _time = 1.6548e+09, train_seconds = 2.1709e+04)
[2022-06-10 02:09:54,600][root][INFO] - Step 82007040 @ 4071.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 82007040, mean_episode_return = 53.446, mean_episode_step = 991.72, total_loss = -23.092, pg_loss = -40.755, baseline_loss = 23.087, entropy_loss = -5.4241, learner_queue_size = 32, _tick = 22049, _time = 1.6548e+09, train_seconds = 2.1714e+04)
[2022-06-10 02:09:59,606][root][INFO] - Step 82027520 @ 4091.4 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 82027520, mean_episode_return = 46.85, mean_episode_step = 985.3, total_loss = 133.25, pg_loss = 108.53, baseline_loss = 29.944, entropy_loss = -5.221, learner_queue_size = 32, _tick = 22057, _time = 1.6548e+09, train_seconds = 2.1719e+04)
[2022-06-10 02:10:04,610][root][INFO] - Step 82045440 @ 3581.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 82045440, mean_episode_return = 103.79, mean_episode_step = 915.18, total_loss = -16.932, pg_loss = -54.88, baseline_loss = 42.787, entropy_loss = -4.8387, learner_queue_size = 32, _tick = 22060, _time = 1.6548e+09, train_seconds = 2.1724e+04)
[2022-06-10 02:10:09,614][root][INFO] - Step 82065920 @ 4092.7 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 82065920, mean_episode_return = 11.487, mean_episode_step = 914.09, total_loss = -102.84, pg_loss = -144.18, baseline_loss = 45.781, entropy_loss = -4.4392, learner_queue_size = 32, _tick = 22064, _time = 1.6548e+09, train_seconds = 2.1729e+04)
[2022-06-10 02:10:14,618][root][INFO] - Step 82086400 @ 4092.5 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 82086400, mean_episode_return = 62.21, mean_episode_step = 969.95, total_loss = -77.674, pg_loss = -93.95, baseline_loss = 21.479, entropy_loss = -5.2024, learner_queue_size = 32, _tick = 22072, _time = 1.6548e+09, train_seconds = 2.1734e+04)
[2022-06-10 02:10:19,622][root][INFO] - Step 82106880 @ 4092.9 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 82106880, mean_episode_return = 117.08, mean_episode_step = 1082.6, total_loss = -111.24, pg_loss = -127.62, baseline_loss = 21.817, entropy_loss = -5.4314, learner_queue_size = 32, _tick = 22079, _time = 1.6548e+09, train_seconds = 2.1739e+04)
[2022-06-10 02:10:24,626][root][INFO] - Step 82124800 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 82124800, mean_episode_return = None, mean_episode_step = 1079.0, total_loss = 76.363, pg_loss = 32.984, baseline_loss = 48.602, entropy_loss = -5.2228, learner_queue_size = 32, _tick = 22084, _time = 1.6548e+09, train_seconds = 2.1744e+04)
[2022-06-10 02:10:29,630][root][INFO] - Step 82145280 @ 4092.8 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 82145280, mean_episode_return = -0.21047, mean_episode_step = 837.54, total_loss = 118.04, pg_loss = 67.726, baseline_loss = 55.611, entropy_loss = -5.2939, learner_queue_size = 32, _tick = 22091, _time = 1.6548e+09, train_seconds = 2.1749e+04)
[2022-06-10 02:10:34,634][root][INFO] - Step 82165760 @ 4092.7 SPS. Inference batcher size: 80. Learner queue size: 32. Other stats: (step = 82165760, mean_episode_return = 41.405, mean_episode_step = 944.28, total_loss = -18.827, pg_loss = -33.79, baseline_loss = 20.396, entropy_loss = -5.4329, learner_queue_size = 32, _tick = 22096, _time = 1.6548e+09, train_seconds = 2.1754e+04)
[2022-06-10 02:10:39,638][root][INFO] - Step 82186240 @ 4092.7 SPS. Inference batcher size: 78. Learner queue size: 32. Other stats: (step = 82186240, mean_episode_return = 29.88, mean_episode_step = 839.2, total_loss = -259.29, pg_loss = -283.74, baseline_loss = 29.829, entropy_loss = -5.3783, learner_queue_size = 32, _tick = 22103, _time = 1.6548e+09, train_seconds = 2.1759e+04)
[2022-06-10 02:10:44,642][root][INFO] - Step 82206720 @ 4092.8 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 82206720, mean_episode_return = None, mean_episode_step = 886.78, total_loss = 168.09, pg_loss = 113.35, baseline_loss = 60.105, entropy_loss = -5.3724, learner_queue_size = 32, _tick = 22107, _time = 1.6548e+09, train_seconds = 2.1764e+04)
[2022-06-10 02:10:49,646][root][INFO] - Step 82224640 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 82224640, mean_episode_return = 69.049, mean_episode_step = 1068.0, total_loss = -17.886, pg_loss = -49.381, baseline_loss = 36.828, entropy_loss = -5.3336, learner_queue_size = 32, _tick = 22114, _time = 1.6548e+09, train_seconds = 2.177e+04)
[2022-06-10 02:10:54,650][root][INFO] - Step 82245120 @ 4092.4 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 82245120, mean_episode_return = 173.78, mean_episode_step = 928.47, total_loss = -25.148, pg_loss = -57.962, baseline_loss = 38.12, entropy_loss = -5.3058, learner_queue_size = 32, _tick = 22121, _time = 1.6548e+09, train_seconds = 2.1774e+04)
[2022-06-10 02:10:59,654][root][INFO] - Step 82263040 @ 3581.4 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 82263040, mean_episode_return = None, mean_episode_step = 1094.0, total_loss = 210.46, pg_loss = 137.27, baseline_loss = 78.484, entropy_loss = -5.2941, learner_queue_size = 32, _tick = 22125, _time = 1.6548e+09, train_seconds = 2.178e+04)
[2022-06-10 02:11:04,658][root][INFO] - Step 82283520 @ 4092.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 82283520, mean_episode_return = None, mean_episode_step = 1032.5, total_loss = -156.04, pg_loss = -169.7, baseline_loss = 19.025, entropy_loss = -5.3733, learner_queue_size = 32, _tick = 22129, _time = 1.6548e+09, train_seconds = 2.1784e+04)
[2022-06-10 02:11:09,662][root][INFO] - Step 82304000 @ 4093.0 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 82304000, mean_episode_return = 81.296, mean_episode_step = 949.21, total_loss = 23.389, pg_loss = -36.84, baseline_loss = 65.701, entropy_loss = -5.4722, learner_queue_size = 32, _tick = 22136, _time = 1.6548e+09, train_seconds = 2.179e+04)
[2022-06-10 02:11:14,666][root][INFO] - Step 82321920 @ 3581.1 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 82321920, mean_episode_return = 49.927, mean_episode_step = 984.91, total_loss = -24.546, pg_loss = -44.858, baseline_loss = 25.753, entropy_loss = -5.442, learner_queue_size = 32, _tick = 22143, _time = 1.6548e+09, train_seconds = 2.1794e+04)
[2022-06-10 02:11:19,670][root][INFO] - Step 82342400 @ 4092.7 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 82342400, mean_episode_return = None, mean_episode_step = 1157.4, total_loss = -106.57, pg_loss = -120.2, baseline_loss = 19.146, entropy_loss = -5.5089, learner_queue_size = 32, _tick = 22148, _time = 1.6548e+09, train_seconds = 2.18e+04)
[2022-06-10 02:11:24,674][root][INFO] - Step 82362880 @ 4092.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 82362880, mean_episode_return = 117.18, mean_episode_step = 937.89, total_loss = -64.834, pg_loss = -81.71, baseline_loss = 22.112, entropy_loss = -5.235, learner_queue_size = 32, _tick = 22154, _time = 1.6548e+09, train_seconds = 2.1804e+04)
[2022-06-10 02:11:29,678][root][INFO] - Step 82383360 @ 4092.7 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 82383360, mean_episode_return = None, mean_episode_step = 997.97, total_loss = 391.36, pg_loss = 316.65, baseline_loss = 80.134, entropy_loss = -5.4171, learner_queue_size = 32, _tick = 22160, _time = 1.6548e+09, train_seconds = 2.181e+04)
[2022-06-10 02:11:34,682][root][INFO] - Step 82401280 @ 3581.1 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 82401280, mean_episode_return = -5.33, mean_episode_step = 973.95, total_loss = 169.83, pg_loss = 117.27, baseline_loss = 57.819, entropy_loss = -5.2663, learner_queue_size = 32, _tick = 22165, _time = 1.6548e+09, train_seconds = 2.1814e+04)
[2022-06-10 02:11:39,686][root][INFO] - Step 82421760 @ 4092.7 SPS. Inference batcher size: 102. Learner queue size: 32. Other stats: (step = 82421760, mean_episode_return = 40.861, mean_episode_step = 999.49, total_loss = -65.179, pg_loss = -107.89, baseline_loss = 48.097, entropy_loss = -5.3871, learner_queue_size = 32, _tick = 22173, _time = 1.6548e+09, train_seconds = 2.182e+04)
[2022-06-10 02:11:44,690][root][INFO] - Step 82439680 @ 3581.1 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (step = 82439680, mean_episode_return = 27.79, mean_episode_step = 1291.2, total_loss = 143.22, pg_loss = 102.43, baseline_loss = 46.275, entropy_loss = -5.4813, learner_queue_size = 32, _tick = 22177, _time = 1.6548e+09, train_seconds = 2.1824e+04)
[2022-06-10 02:11:49,694][root][INFO] - Step 82460160 @ 4092.8 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 82460160, mean_episode_return = 212.03, mean_episode_step = 1206.9, total_loss = 222.0, pg_loss = 164.7, baseline_loss = 62.669, entropy_loss = -5.3645, learner_queue_size = 32, _tick = 22185, _time = 1.6548e+09, train_seconds = 2.183e+04)
[2022-06-10 02:11:54,698][root][INFO] - Step 82480640 @ 4092.7 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 82480640, mean_episode_return = 45.895, mean_episode_step = 961.57, total_loss = -95.331, pg_loss = -116.72, baseline_loss = 26.661, entropy_loss = -5.2676, learner_queue_size = 32, _tick = 22192, _time = 1.6548e+09, train_seconds = 2.1834e+04)
[2022-06-10 02:11:59,702][root][INFO] - Step 82498560 @ 3580.9 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 82498560, mean_episode_return = 73.959, mean_episode_step = 840.22, total_loss = 216.73, pg_loss = 157.56, baseline_loss = 64.534, entropy_loss = -5.3564, learner_queue_size = 32, _tick = 22196, _time = 1.6548e+09, train_seconds = 2.184e+04)
[2022-06-10 02:12:04,709][root][INFO] - Step 82516480 @ 3579.5 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 82516480, mean_episode_return = 97.98, mean_episode_step = 1061.2, total_loss = 273.77, pg_loss = 197.81, baseline_loss = 81.199, entropy_loss = -5.2349, learner_queue_size = 32, _tick = 22201, _time = 1.6548e+09, train_seconds = 2.1844e+04)
[2022-06-10 02:12:09,714][root][INFO] - Step 82536960 @ 4091.6 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 82536960, mean_episode_return = 152.11, mean_episode_step = 888.9, total_loss = 102.9, pg_loss = 49.65, baseline_loss = 58.455, entropy_loss = -5.21, learner_queue_size = 32, _tick = 22209, _time = 1.6548e+09, train_seconds = 2.185e+04)
[2022-06-10 02:12:14,718][root][INFO] - Step 82557440 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 82557440, mean_episode_return = 69.844, mean_episode_step = 1075.1, total_loss = -111.65, pg_loss = -166.63, baseline_loss = 60.285, entropy_loss = -5.3006, learner_queue_size = 32, _tick = 22216, _time = 1.6548e+09, train_seconds = 2.1854e+04)
[2022-06-10 02:12:19,722][root][INFO] - Step 82575360 @ 3581.2 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 82575360, mean_episode_return = 104.18, mean_episode_step = 1028.0, total_loss = 154.0, pg_loss = 91.511, baseline_loss = 67.889, entropy_loss = -5.3992, learner_queue_size = 32, _tick = 22222, _time = 1.6548e+09, train_seconds = 2.186e+04)
[2022-06-10 02:12:24,726][root][INFO] - Step 82593280 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 82593280, mean_episode_return = None, mean_episode_step = 855.38, total_loss = 111.54, pg_loss = 52.419, baseline_loss = 64.499, entropy_loss = -5.3724, learner_queue_size = 32, _tick = 22226, _time = 1.6548e+09, train_seconds = 2.1864e+04)
[2022-06-10 02:12:29,730][root][INFO] - Step 82613760 @ 4092.7 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (step = 82613760, mean_episode_return = 34.595, mean_episode_step = 1012.5, total_loss = 136.55, pg_loss = 56.964, baseline_loss = 84.868, entropy_loss = -5.28, learner_queue_size = 32, _tick = 22234, _time = 1.6548e+09, train_seconds = 2.187e+04)
[2022-06-10 02:12:34,734][root][INFO] - Step 82634240 @ 4092.7 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (step = 82634240, mean_episode_return = 39.8, mean_episode_step = 943.49, total_loss = 193.23, pg_loss = 121.59, baseline_loss = 76.837, entropy_loss = -5.1995, learner_queue_size = 32, _tick = 22240, _time = 1.6548e+09, train_seconds = 2.1874e+04)
[2022-06-10 02:12:39,738][root][INFO] - Step 82654720 @ 4092.7 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 82654720, mean_episode_return = 55.995, mean_episode_step = 925.52, total_loss = 50.344, pg_loss = -16.971, baseline_loss = 72.795, entropy_loss = -5.4798, learner_queue_size = 32, _tick = 22245, _time = 1.6548e+09, train_seconds = 2.188e+04)
[2022-06-10 02:12:44,742][root][INFO] - Step 82672640 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 82672640, mean_episode_return = 52.213, mean_episode_step = 958.69, total_loss = 284.9, pg_loss = 194.69, baseline_loss = 95.632, entropy_loss = -5.4261, learner_queue_size = 32, _tick = 22252, _time = 1.6548e+09, train_seconds = 2.1884e+04)
[2022-06-10 02:12:49,747][root][INFO] - Step 82693120 @ 4092.4 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (step = 82693120, mean_episode_return = 47.204, mean_episode_step = 807.84, total_loss = 223.53, pg_loss = 149.75, baseline_loss = 79.235, entropy_loss = -5.4605, learner_queue_size = 32, _tick = 22257, _time = 1.6548e+09, train_seconds = 2.189e+04)
[2022-06-10 02:12:54,750][root][INFO] - Step 82713600 @ 4093.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 82713600, mean_episode_return = 66.205, mean_episode_step = 831.29, total_loss = -74.204, pg_loss = -157.58, baseline_loss = 88.818, entropy_loss = -5.4373, learner_queue_size = 32, _tick = 22262, _time = 1.6548e+09, train_seconds = 2.1895e+04)
[2022-06-10 02:12:59,754][root][INFO] - Step 82731520 @ 3581.1 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 82731520, mean_episode_return = 25.22, mean_episode_step = 738.77, total_loss = 31.474, pg_loss = -21.681, baseline_loss = 58.63, entropy_loss = -5.4748, learner_queue_size = 32, _tick = 22269, _time = 1.6548e+09, train_seconds = 2.19e+04)
[2022-06-10 02:13:04,760][root][INFO] - Step 82752000 @ 4091.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 82752000, mean_episode_return = 96.589, mean_episode_step = 876.88, total_loss = 5.7801, pg_loss = -45.232, baseline_loss = 56.382, entropy_loss = -5.3704, learner_queue_size = 32, _tick = 22276, _time = 1.6548e+09, train_seconds = 2.1905e+04)
[2022-06-10 02:13:09,766][root][INFO] - Step 82769920 @ 3579.8 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 82769920, mean_episode_return = 78.917, mean_episode_step = 1164.4, total_loss = -108.89, pg_loss = -155.44, baseline_loss = 51.862, entropy_loss = -5.3165, learner_queue_size = 32, _tick = 22282, _time = 1.6548e+09, train_seconds = 2.191e+04)
[2022-06-10 02:13:14,770][root][INFO] - Step 82790400 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 82790400, mean_episode_return = 22.275, mean_episode_step = 988.03, total_loss = -9.7978, pg_loss = -66.989, baseline_loss = 62.73, entropy_loss = -5.5396, learner_queue_size = 32, _tick = 22289, _time = 1.6548e+09, train_seconds = 2.1915e+04)
[2022-06-10 02:13:19,774][root][INFO] - Step 82808320 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 82808320, mean_episode_return = 18.92, mean_episode_step = 1158.7, total_loss = -58.256, pg_loss = -91.603, baseline_loss = 38.703, entropy_loss = -5.3558, learner_queue_size = 32, _tick = 22295, _time = 1.6548e+09, train_seconds = 2.192e+04)
[2022-06-10 02:13:24,778][root][INFO] - Step 82828800 @ 4092.8 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 82828800, mean_episode_return = 95.891, mean_episode_step = 1004.3, total_loss = 148.09, pg_loss = 81.852, baseline_loss = 71.662, entropy_loss = -5.4194, learner_queue_size = 32, _tick = 22301, _time = 1.6548e+09, train_seconds = 2.1925e+04)
[2022-06-10 02:13:29,782][root][INFO] - Step 82849280 @ 4092.6 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 82849280, mean_episode_return = 86.435, mean_episode_step = 865.98, total_loss = -66.514, pg_loss = -86.202, baseline_loss = 25.261, entropy_loss = -5.5731, learner_queue_size = 32, _tick = 22308, _time = 1.6548e+09, train_seconds = 2.193e+04)
[2022-06-10 02:13:34,786][root][INFO] - Step 82867200 @ 3581.2 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 82867200, mean_episode_return = 50.965, mean_episode_step = 989.8, total_loss = 55.348, pg_loss = 16.757, baseline_loss = 44.255, entropy_loss = -5.6643, learner_queue_size = 32, _tick = 22315, _time = 1.6548e+09, train_seconds = 2.1935e+04)
[2022-06-10 02:13:39,790][root][INFO] - Step 82887680 @ 4092.7 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 82887680, mean_episode_return = 104.61, mean_episode_step = 845.58, total_loss = 104.58, pg_loss = 81.467, baseline_loss = 28.676, entropy_loss = -5.5672, learner_queue_size = 32, _tick = 22323, _time = 1.6548e+09, train_seconds = 2.194e+04)
[2022-06-10 02:13:44,794][root][INFO] - Step 82905600 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 82905600, mean_episode_return = 29.397, mean_episode_step = 944.81, total_loss = 40.448, pg_loss = -12.798, baseline_loss = 58.784, entropy_loss = -5.5381, learner_queue_size = 32, _tick = 22330, _time = 1.6548e+09, train_seconds = 2.1945e+04)
[2022-06-10 02:13:49,800][root][INFO] - Step 82926080 @ 4091.2 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 82926080, mean_episode_return = 40.93, mean_episode_step = 965.42, total_loss = 16.463, pg_loss = -26.596, baseline_loss = 48.622, entropy_loss = -5.5641, learner_queue_size = 32, _tick = 22338, _time = 1.6548e+09, train_seconds = 2.195e+04)
[2022-06-10 02:13:54,806][root][INFO] - Step 82944000 @ 3579.6 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 82944000, mean_episode_return = 42.9, mean_episode_step = 1176.4, total_loss = 482.98, pg_loss = 363.76, baseline_loss = 124.74, entropy_loss = -5.5227, learner_queue_size = 32, _tick = 22345, _time = 1.6548e+09, train_seconds = 2.1955e+04)
[2022-06-10 02:13:59,810][root][INFO] - Step 82964480 @ 4092.8 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 82964480, mean_episode_return = 39.695, mean_episode_step = 1165.0, total_loss = 433.91, pg_loss = 314.42, baseline_loss = 125.01, entropy_loss = -5.5124, learner_queue_size = 32, _tick = 22352, _time = 1.6548e+09, train_seconds = 2.196e+04)
[2022-06-10 02:14:04,814][root][INFO] - Step 82984960 @ 4092.7 SPS. Inference batcher size: 79. Learner queue size: 32. Other stats: (step = 82984960, mean_episode_return = 60.282, mean_episode_step = 1136.5, total_loss = 134.1, pg_loss = 61.446, baseline_loss = 78.16, entropy_loss = -5.5056, learner_queue_size = 32, _tick = 22360, _time = 1.6548e+09, train_seconds = 2.1965e+04)
[2022-06-10 02:14:09,818][root][INFO] - Step 83005440 @ 4092.6 SPS. Inference batcher size: 99. Learner queue size: 32. Other stats: (step = 83005440, mean_episode_return = 40.746, mean_episode_step = 843.52, total_loss = 31.949, pg_loss = -27.792, baseline_loss = 65.221, entropy_loss = -5.4804, learner_queue_size = 32, _tick = 22367, _time = 1.6548e+09, train_seconds = 2.197e+04)
[2022-06-10 02:14:14,822][root][INFO] - Step 83023360 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 83023360, mean_episode_return = 77.21, mean_episode_step = 896.89, total_loss = 127.57, pg_loss = 40.833, baseline_loss = 92.126, entropy_loss = -5.3883, learner_queue_size = 32, _tick = 22372, _time = 1.6548e+09, train_seconds = 2.1975e+04)
[2022-06-10 02:14:19,826][root][INFO] - Step 83043840 @ 4092.8 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 83043840, mean_episode_return = 59.251, mean_episode_step = 763.07, total_loss = -131.6, pg_loss = -165.95, baseline_loss = 39.821, entropy_loss = -5.4718, learner_queue_size = 32, _tick = 22377, _time = 1.6548e+09, train_seconds = 2.198e+04)
[2022-06-10 02:14:24,830][root][INFO] - Step 83061760 @ 3581.1 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 83061760, mean_episode_return = None, mean_episode_step = 912.56, total_loss = 93.365, pg_loss = 43.054, baseline_loss = 55.826, entropy_loss = -5.5147, learner_queue_size = 32, _tick = 22382, _time = 1.6548e+09, train_seconds = 2.1985e+04)
[2022-06-10 02:14:29,834][root][INFO] - Step 83082240 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 83082240, mean_episode_return = None, mean_episode_step = 978.75, total_loss = 349.67, pg_loss = 264.59, baseline_loss = 90.608, entropy_loss = -5.528, learner_queue_size = 32, _tick = 22387, _time = 1.6548e+09, train_seconds = 2.199e+04)
[2022-06-10 02:14:34,838][root][INFO] - Step 83100160 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 83100160, mean_episode_return = 108.88, mean_episode_step = 810.04, total_loss = -107.44, pg_loss = -137.59, baseline_loss = 35.597, entropy_loss = -5.448, learner_queue_size = 32, _tick = 22394, _time = 1.6548e+09, train_seconds = 2.1995e+04)
[2022-06-10 02:14:39,843][root][INFO] - Step 83120640 @ 4092.0 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 83120640, mean_episode_return = 66.73, mean_episode_step = 931.43, total_loss = 103.27, pg_loss = 48.775, baseline_loss = 60.047, entropy_loss = -5.5514, learner_queue_size = 32, _tick = 22401, _time = 1.6548e+09, train_seconds = 2.2e+04)
[2022-06-10 02:14:44,846][root][INFO] - Step 83141120 @ 4093.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (step = 83141120, mean_episode_return = 19.27, mean_episode_step = 993.61, total_loss = 232.17, pg_loss = 121.58, baseline_loss = 116.03, entropy_loss = -5.4287, learner_queue_size = 32, _tick = 22408, _time = 1.6548e+09, train_seconds = 2.2005e+04)
[2022-06-10 02:14:49,850][root][INFO] - Step 83161600 @ 4092.8 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 83161600, mean_episode_return = 97.769, mean_episode_step = 946.44, total_loss = 338.04, pg_loss = 264.83, baseline_loss = 78.647, entropy_loss = -5.444, learner_queue_size = 32, _tick = 22415, _time = 1.6548e+09, train_seconds = 2.201e+04)
[2022-06-10 02:14:54,854][root][INFO] - Step 83179520 @ 3581.1 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 83179520, mean_episode_return = 2.2948, mean_episode_step = 1332.4, total_loss = -102.68, pg_loss = -126.25, baseline_loss = 29.038, entropy_loss = -5.4703, learner_queue_size = 32, _tick = 22422, _time = 1.6548e+09, train_seconds = 2.2015e+04)
[2022-06-10 02:14:59,858][root][INFO] - Step 83200000 @ 4092.8 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 83200000, mean_episode_return = 60.725, mean_episode_step = 902.24, total_loss = -156.08, pg_loss = -218.62, baseline_loss = 68.015, entropy_loss = -5.4755, learner_queue_size = 32, _tick = 22429, _time = 1.6548e+09, train_seconds = 2.202e+04)
[2022-06-10 02:15:04,862][root][INFO] - Step 83217920 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 83217920, mean_episode_return = 88.471, mean_episode_step = 1119.0, total_loss = 205.71, pg_loss = 118.28, baseline_loss = 92.833, entropy_loss = -5.4034, learner_queue_size = 32, _tick = 22434, _time = 1.6548e+09, train_seconds = 2.2025e+04)
[2022-06-10 02:15:09,866][root][INFO] - Step 83238400 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 83238400, mean_episode_return = 61.341, mean_episode_step = 789.43, total_loss = 107.14, pg_loss = 50.176, baseline_loss = 62.428, entropy_loss = -5.4616, learner_queue_size = 32, _tick = 22442, _time = 1.6548e+09, train_seconds = 2.203e+04)
[2022-06-10 02:15:14,872][root][INFO] - Step 83256320 @ 3579.6 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 83256320, mean_episode_return = 31.947, mean_episode_step = 834.02, total_loss = 516.17, pg_loss = 249.24, baseline_loss = 272.41, entropy_loss = -5.4773, learner_queue_size = 32, _tick = 22447, _time = 1.6548e+09, train_seconds = 2.2035e+04)
[2022-06-10 02:15:19,878][root][INFO] - Step 83276800 @ 4091.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 83276800, mean_episode_return = 83.779, mean_episode_step = 669.82, total_loss = -141.13, pg_loss = -155.55, baseline_loss = 19.987, entropy_loss = -5.5677, learner_queue_size = 32, _tick = 22454, _time = 1.6548e+09, train_seconds = 2.204e+04)
[2022-06-10 02:15:24,882][root][INFO] - Step 83297280 @ 4092.8 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 83297280, mean_episode_return = 35.836, mean_episode_step = 803.94, total_loss = 144.73, pg_loss = 88.3, baseline_loss = 61.943, entropy_loss = -5.512, learner_queue_size = 32, _tick = 22461, _time = 1.6548e+09, train_seconds = 2.2045e+04)
[2022-06-10 02:15:29,886][root][INFO] - Step 83315200 @ 3581.1 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 83315200, mean_episode_return = 101.68, mean_episode_step = 935.99, total_loss = 274.51, pg_loss = 203.99, baseline_loss = 76.018, entropy_loss = -5.5016, learner_queue_size = 32, _tick = 22467, _time = 1.6548e+09, train_seconds = 2.205e+04)
[2022-06-10 02:15:34,890][root][INFO] - Step 83335680 @ 4092.6 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 83335680, mean_episode_return = 23.56, mean_episode_step = 1170.1, total_loss = 136.19, pg_loss = 90.834, baseline_loss = 50.803, entropy_loss = -5.4438, learner_queue_size = 32, _tick = 22472, _time = 1.6548e+09, train_seconds = 2.2055e+04)
[2022-06-10 02:15:39,894][root][INFO] - Step 83356160 @ 4092.7 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 83356160, mean_episode_return = None, mean_episode_step = 778.41, total_loss = -18.221, pg_loss = -44.241, baseline_loss = 31.501, entropy_loss = -5.4816, learner_queue_size = 32, _tick = 22477, _time = 1.6548e+09, train_seconds = 2.206e+04)
[2022-06-10 02:15:44,898][root][INFO] - Step 83374080 @ 3581.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 83374080, mean_episode_return = None, mean_episode_step = 951.88, total_loss = 3.4915, pg_loss = -25.196, baseline_loss = 34.212, entropy_loss = -5.5245, learner_queue_size = 32, _tick = 22483, _time = 1.6548e+09, train_seconds = 2.2065e+04)
[2022-06-10 02:15:49,902][root][INFO] - Step 83394560 @ 4092.9 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 83394560, mean_episode_return = 20.92, mean_episode_step = 926.27, total_loss = 367.85, pg_loss = 246.95, baseline_loss = 126.48, entropy_loss = -5.5804, learner_queue_size = 32, _tick = 22489, _time = 1.6548e+09, train_seconds = 2.207e+04)
[2022-06-10 02:15:54,906][root][INFO] - Step 83415040 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 83415040, mean_episode_return = 83.991, mean_episode_step = 889.77, total_loss = 2134.6, pg_loss = 764.84, baseline_loss = 1375.3, entropy_loss = -5.546, learner_queue_size = 32, _tick = 22497, _time = 1.6548e+09, train_seconds = 2.2075e+04)
[2022-06-10 02:15:59,910][root][INFO] - Step 83432960 @ 3581.1 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 83432960, mean_episode_return = 31.086, mean_episode_step = 1037.0, total_loss = -44.725, pg_loss = -111.99, baseline_loss = 72.757, entropy_loss = -5.493, learner_queue_size = 32, _tick = 22503, _time = 1.6548e+09, train_seconds = 2.208e+04)
[2022-06-10 02:16:04,914][root][INFO] - Step 83453440 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 83453440, mean_episode_return = 17.47, mean_episode_step = 821.93, total_loss = 32.918, pg_loss = -0.9811, baseline_loss = 39.379, entropy_loss = -5.4799, learner_queue_size = 32, _tick = 22510, _time = 1.6548e+09, train_seconds = 2.2085e+04)
[2022-06-10 02:16:09,918][root][INFO] - Step 83471360 @ 3581.2 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (step = 83471360, mean_episode_return = None, mean_episode_step = 1185.7, total_loss = 291.92, pg_loss = 219.23, baseline_loss = 78.101, entropy_loss = -5.4093, learner_queue_size = 32, _tick = 22516, _time = 1.6548e+09, train_seconds = 2.209e+04)
[2022-06-10 02:16:14,922][root][INFO] - Step 83491840 @ 4092.7 SPS. Inference batcher size: 77. Learner queue size: 32. Other stats: (step = 83491840, mean_episode_return = 82.617, mean_episode_step = 866.44, total_loss = 162.71, pg_loss = 76.285, baseline_loss = 91.914, entropy_loss = -5.4931, learner_queue_size = 32, _tick = 22523, _time = 1.6548e+09, train_seconds = 2.2095e+04)
[2022-06-10 02:16:19,926][root][INFO] - Step 83512320 @ 4092.7 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (step = 83512320, mean_episode_return = 23.03, mean_episode_step = 1152.7, total_loss = 161.34, pg_loss = 93.747, baseline_loss = 73.064, entropy_loss = -5.468, learner_queue_size = 32, _tick = 22530, _time = 1.6548e+09, train_seconds = 2.21e+04)
[2022-06-10 02:16:24,930][root][INFO] - Step 83530240 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 83530240, mean_episode_return = 132.11, mean_episode_step = 968.95, total_loss = 426.71, pg_loss = 323.09, baseline_loss = 109.19, entropy_loss = -5.5712, learner_queue_size = 32, _tick = 22536, _time = 1.6548e+09, train_seconds = 2.2105e+04)
[2022-06-10 02:16:29,934][root][INFO] - Step 83550720 @ 4092.7 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 83550720, mean_episode_return = 55.47, mean_episode_step = 815.33, total_loss = 100.42, pg_loss = 32.773, baseline_loss = 73.188, entropy_loss = -5.5417, learner_queue_size = 32, _tick = 22544, _time = 1.6548e+09, train_seconds = 2.211e+04)
[2022-06-10 02:16:34,938][root][INFO] - Step 83568640 @ 3581.1 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 83568640, mean_episode_return = 115.32, mean_episode_step = 1132.5, total_loss = -240.23, pg_loss = -248.59, baseline_loss = 13.929, entropy_loss = -5.5747, learner_queue_size = 32, _tick = 22550, _time = 1.6548e+09, train_seconds = 2.2115e+04)
[2022-06-10 02:16:39,942][root][INFO] - Step 83589120 @ 4092.7 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 83589120, mean_episode_return = 108.78, mean_episode_step = 944.03, total_loss = 77.591, pg_loss = 17.129, baseline_loss = 66.051, entropy_loss = -5.5892, learner_queue_size = 32, _tick = 22558, _time = 1.6548e+09, train_seconds = 2.212e+04)
[2022-06-10 02:16:44,946][root][INFO] - Step 83609600 @ 4092.6 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 83609600, mean_episode_return = 42.8, mean_episode_step = 898.28, total_loss = 533.2, pg_loss = 410.61, baseline_loss = 128.12, entropy_loss = -5.5286, learner_queue_size = 32, _tick = 22565, _time = 1.6548e+09, train_seconds = 2.2125e+04)
[2022-06-10 02:16:49,950][root][INFO] - Step 83630080 @ 4092.8 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 83630080, mean_episode_return = 53.635, mean_episode_step = 871.95, total_loss = -61.676, pg_loss = -110.19, baseline_loss = 54.043, entropy_loss = -5.5247, learner_queue_size = 32, _tick = 22571, _time = 1.6548e+09, train_seconds = 2.213e+04)
[2022-06-10 02:16:54,954][root][INFO] - Step 83648000 @ 3581.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 83648000, mean_episode_return = None, mean_episode_step = 850.81, total_loss = 157.88, pg_loss = 88.866, baseline_loss = 74.569, entropy_loss = -5.5596, learner_queue_size = 32, _tick = 22575, _time = 1.6548e+09, train_seconds = 2.2135e+04)
[2022-06-10 02:16:59,958][root][INFO] - Step 83668480 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 83668480, mean_episode_return = 14.77, mean_episode_step = 899.6, total_loss = -110.89, pg_loss = -137.93, baseline_loss = 32.535, entropy_loss = -5.4938, learner_queue_size = 32, _tick = 22581, _time = 1.6548e+09, train_seconds = 2.214e+04)
[2022-06-10 02:17:04,962][root][INFO] - Step 83688960 @ 4092.7 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 83688960, mean_episode_return = 28.01, mean_episode_step = 909.68, total_loss = -112.99, pg_loss = -155.8, baseline_loss = 48.414, entropy_loss = -5.5984, learner_queue_size = 32, _tick = 22589, _time = 1.6548e+09, train_seconds = 2.2145e+04)
[2022-06-10 02:17:09,966][root][INFO] - Step 83709440 @ 4092.8 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 83709440, mean_episode_return = 29.535, mean_episode_step = 953.45, total_loss = 255.58, pg_loss = 208.62, baseline_loss = 52.548, entropy_loss = -5.5792, learner_queue_size = 32, _tick = 22597, _time = 1.6548e+09, train_seconds = 2.215e+04)
[2022-06-10 02:17:14,970][root][INFO] - Step 83727360 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 83727360, mean_episode_return = 90.019, mean_episode_step = 1252.4, total_loss = 9.583, pg_loss = -36.551, baseline_loss = 51.691, entropy_loss = -5.5573, learner_queue_size = 32, _tick = 22604, _time = 1.6548e+09, train_seconds = 2.2155e+04)
[2022-06-10 02:17:19,974][root][INFO] - Step 83747840 @ 4092.7 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 83747840, mean_episode_return = None, mean_episode_step = 917.28, total_loss = 153.23, pg_loss = 73.981, baseline_loss = 84.787, entropy_loss = -5.5383, learner_queue_size = 32, _tick = 22610, _time = 1.6548e+09, train_seconds = 2.216e+04)
[2022-06-10 02:17:24,980][root][INFO] - Step 83765760 @ 3579.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 83765760, mean_episode_return = 92.339, mean_episode_step = 936.59, total_loss = 27.352, pg_loss = -19.39, baseline_loss = 52.322, entropy_loss = -5.5802, learner_queue_size = 32, _tick = 22616, _time = 1.6548e+09, train_seconds = 2.2165e+04)
[2022-06-10 02:17:29,986][root][INFO] - Step 83786240 @ 4091.2 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 83786240, mean_episode_return = 25.47, mean_episode_step = 948.81, total_loss = -213.36, pg_loss = -268.09, baseline_loss = 60.182, entropy_loss = -5.4597, learner_queue_size = 32, _tick = 22624, _time = 1.6548e+09, train_seconds = 2.217e+04)
[2022-06-10 02:17:34,990][root][INFO] - Step 83806720 @ 4092.8 SPS. Inference batcher size: 82. Learner queue size: 32. Other stats: (step = 83806720, mean_episode_return = None, mean_episode_step = 1041.0, total_loss = 108.27, pg_loss = 57.575, baseline_loss = 56.189, entropy_loss = -5.4915, learner_queue_size = 32, _tick = 22631, _time = 1.6548e+09, train_seconds = 2.2175e+04)
[2022-06-10 02:17:39,994][root][INFO] - Step 83824640 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 83824640, mean_episode_return = -0.99022, mean_episode_step = 1511.8, total_loss = 53.44, pg_loss = 10.28, baseline_loss = 48.751, entropy_loss = -5.5918, learner_queue_size = 32, _tick = 22637, _time = 1.6548e+09, train_seconds = 2.218e+04)
[2022-06-10 02:17:44,998][root][INFO] - Step 83845120 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 83845120, mean_episode_return = 61.318, mean_episode_step = 784.95, total_loss = 270.32, pg_loss = 158.33, baseline_loss = 117.55, entropy_loss = -5.5577, learner_queue_size = 32, _tick = 22645, _time = 1.6548e+09, train_seconds = 2.2185e+04)
[2022-06-10 02:17:50,002][root][INFO] - Step 83863040 @ 3581.2 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 83863040, mean_episode_return = 70.516, mean_episode_step = 977.43, total_loss = 173.7, pg_loss = 109.14, baseline_loss = 70.081, entropy_loss = -5.5284, learner_queue_size = 32, _tick = 22652, _time = 1.6548e+09, train_seconds = 2.219e+04)
[2022-06-10 02:17:55,006][root][INFO] - Step 83883520 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 83883520, mean_episode_return = 71.079, mean_episode_step = 874.42, total_loss = -129.91, pg_loss = -149.35, baseline_loss = 25.014, entropy_loss = -5.5675, learner_queue_size = 32, _tick = 22657, _time = 1.6548e+09, train_seconds = 2.2195e+04)
[2022-06-10 02:18:00,010][root][INFO] - Step 83904000 @ 4092.7 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 83904000, mean_episode_return = 34.465, mean_episode_step = 1042.8, total_loss = 119.45, pg_loss = 30.679, baseline_loss = 94.22, entropy_loss = -5.4464, learner_queue_size = 32, _tick = 22665, _time = 1.6548e+09, train_seconds = 2.22e+04)
[2022-06-10 02:18:05,014][root][INFO] - Step 83921920 @ 3581.1 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 83921920, mean_episode_return = None, mean_episode_step = 1202.4, total_loss = -199.17, pg_loss = -202.18, baseline_loss = 8.556, entropy_loss = -5.5506, learner_queue_size = 32, _tick = 22669, _time = 1.6548e+09, train_seconds = 2.2205e+04)
[2022-06-10 02:18:10,018][root][INFO] - Step 83942400 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 83942400, mean_episode_return = 57.88, mean_episode_step = 1174.1, total_loss = 223.52, pg_loss = 179.73, baseline_loss = 49.326, entropy_loss = -5.5348, learner_queue_size = 32, _tick = 22676, _time = 1.6548e+09, train_seconds = 2.221e+04)
[2022-06-10 02:18:15,022][root][INFO] - Step 83962880 @ 4092.7 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 83962880, mean_episode_return = 5.3549, mean_episode_step = 1177.5, total_loss = 155.07, pg_loss = 97.694, baseline_loss = 62.937, entropy_loss = -5.561, learner_queue_size = 32, _tick = 22682, _time = 1.6548e+09, train_seconds = 2.2215e+04)
[2022-06-10 02:18:20,028][root][INFO] - Step 83980800 @ 3579.7 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 83980800, mean_episode_return = 23.9, mean_episode_step = 819.27, total_loss = 111.56, pg_loss = 66.14, baseline_loss = 51.015, entropy_loss = -5.5949, learner_queue_size = 32, _tick = 22687, _time = 1.6548e+09, train_seconds = 2.222e+04)
[2022-06-10 02:18:25,034][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 02:18:25,226][root][INFO] - Step 84001280 @ 4091.1 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 84003840, mean_episode_return = 45.541, mean_episode_step = 994.73, total_loss = 49.732, pg_loss = 6.3361, baseline_loss = 48.946, entropy_loss = -5.55, learner_queue_size = 32, _tick = 22694, _time = 1.6548e+09, train_seconds = 2.2225e+04)
[2022-06-10 02:18:30,230][root][INFO] - Step 84024320 @ 4434.2 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 84024320, mean_episode_return = 103.75, mean_episode_step = 1105.2, total_loss = 345.85, pg_loss = 252.94, baseline_loss = 98.358, entropy_loss = -5.4493, learner_queue_size = 32, _tick = 22701, _time = 1.6548e+09, train_seconds = 2.223e+04)
[2022-06-10 02:18:35,235][root][INFO] - Step 84042240 @ 3580.4 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 84042240, mean_episode_return = 10.55, mean_episode_step = 1006.2, total_loss = 13.508, pg_loss = -14.937, baseline_loss = 33.802, entropy_loss = -5.3563, learner_queue_size = 32, _tick = 22708, _time = 1.6548e+09, train_seconds = 2.2235e+04)
[2022-06-10 02:18:40,238][root][INFO] - Step 84062720 @ 4093.5 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 84062720, mean_episode_return = 66.52, mean_episode_step = 1054.0, total_loss = 103.78, pg_loss = 64.213, baseline_loss = 45.102, entropy_loss = -5.5342, learner_queue_size = 32, _tick = 22714, _time = 1.6548e+09, train_seconds = 2.224e+04)
[2022-06-10 02:18:45,244][root][INFO] - Step 84083200 @ 4091.4 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 84083200, mean_episode_return = 21.015, mean_episode_step = 1162.4, total_loss = 100.03, pg_loss = 59.707, baseline_loss = 45.859, entropy_loss = -5.5343, learner_queue_size = 32, _tick = 22721, _time = 1.6548e+09, train_seconds = 2.2245e+04)
[2022-06-10 02:18:50,246][root][INFO] - Step 84101120 @ 3582.2 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 84101120, mean_episode_return = 19.87, mean_episode_step = 1042.5, total_loss = 222.78, pg_loss = 167.21, baseline_loss = 60.998, entropy_loss = -5.4296, learner_queue_size = 32, _tick = 22724, _time = 1.6548e+09, train_seconds = 2.225e+04)
[2022-06-10 02:18:55,250][root][INFO] - Step 84121600 @ 4092.8 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 84121600, mean_episode_return = 58.87, mean_episode_step = 1064.2, total_loss = -110.58, pg_loss = -143.52, baseline_loss = 38.111, entropy_loss = -5.1796, learner_queue_size = 32, _tick = 22729, _time = 1.6548e+09, train_seconds = 2.2255e+04)
[2022-06-10 02:19:00,255][root][INFO] - Step 84142080 @ 4091.6 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 84142080, mean_episode_return = 10.98, mean_episode_step = 953.0, total_loss = -125.21, pg_loss = -136.67, baseline_loss = 16.436, entropy_loss = -4.9778, learner_queue_size = 32, _tick = 22737, _time = 1.6548e+09, train_seconds = 2.226e+04)
[2022-06-10 02:19:05,258][root][INFO] - Step 84160000 @ 3582.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 84160000, mean_episode_return = 141.69, mean_episode_step = 1406.9, total_loss = -101.14, pg_loss = -117.8, baseline_loss = 22.125, entropy_loss = -5.4677, learner_queue_size = 32, _tick = 22743, _time = 1.6548e+09, train_seconds = 2.2265e+04)
[2022-06-10 02:19:10,262][root][INFO] - Step 84180480 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 84180480, mean_episode_return = 61.081, mean_episode_step = 1174.7, total_loss = -27.042, pg_loss = -26.935, baseline_loss = 5.538, entropy_loss = -5.6451, learner_queue_size = 32, _tick = 22749, _time = 1.6548e+09, train_seconds = 2.227e+04)
[2022-06-10 02:19:15,266][root][INFO] - Step 84198400 @ 3581.1 SPS. Inference batcher size: 82. Learner queue size: 32. Other stats: (step = 84198400, mean_episode_return = 47.725, mean_episode_step = 956.56, total_loss = 160.11, pg_loss = 126.95, baseline_loss = 38.674, entropy_loss = -5.5121, learner_queue_size = 32, _tick = 22755, _time = 1.6548e+09, train_seconds = 2.2275e+04)
[2022-06-10 02:19:20,270][root][INFO] - Step 84218880 @ 4092.8 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 84218880, mean_episode_return = 44.283, mean_episode_step = 1028.2, total_loss = -16.283, pg_loss = -34.529, baseline_loss = 23.746, entropy_loss = -5.5, learner_queue_size = 32, _tick = 22761, _time = 1.6548e+09, train_seconds = 2.228e+04)
[2022-06-10 02:19:25,274][root][INFO] - Step 84239360 @ 4092.6 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 84239360, mean_episode_return = 13.183, mean_episode_step = 930.14, total_loss = -188.75, pg_loss = -252.25, baseline_loss = 68.987, entropy_loss = -5.4836, learner_queue_size = 32, _tick = 22768, _time = 1.6548e+09, train_seconds = 2.2285e+04)
[2022-06-10 02:19:30,278][root][INFO] - Step 84259840 @ 4092.8 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 84259840, mean_episode_return = None, mean_episode_step = 1079.2, total_loss = 95.709, pg_loss = 35.146, baseline_loss = 65.966, entropy_loss = -5.4036, learner_queue_size = 32, _tick = 22772, _time = 1.6548e+09, train_seconds = 2.229e+04)
[2022-06-10 02:19:35,282][root][INFO] - Step 84277760 @ 3581.2 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 84277760, mean_episode_return = 134.25, mean_episode_step = 1248.6, total_loss = -173.88, pg_loss = -208.82, baseline_loss = 40.433, entropy_loss = -5.4935, learner_queue_size = 32, _tick = 22778, _time = 1.6548e+09, train_seconds = 2.2295e+04)
[2022-06-10 02:19:40,286][root][INFO] - Step 84298240 @ 4092.5 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 84298240, mean_episode_return = None, mean_episode_step = 1043.6, total_loss = -114.94, pg_loss = -145.23, baseline_loss = 35.74, entropy_loss = -5.4513, learner_queue_size = 32, _tick = 22783, _time = 1.6548e+09, train_seconds = 2.23e+04)
[2022-06-10 02:19:45,290][root][INFO] - Step 84316160 @ 3581.3 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 84316160, mean_episode_return = 28.19, mean_episode_step = 1463.2, total_loss = -180.87, pg_loss = -207.49, baseline_loss = 32.069, entropy_loss = -5.4461, learner_queue_size = 32, _tick = 22790, _time = 1.6548e+09, train_seconds = 2.2305e+04)
[2022-06-10 02:19:50,293][root][INFO] - Step 84336640 @ 4093.5 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 84336640, mean_episode_return = 9.6497, mean_episode_step = 980.14, total_loss = -118.49, pg_loss = -142.83, baseline_loss = 29.839, entropy_loss = -5.4995, learner_queue_size = 32, _tick = 22798, _time = 1.6548e+09, train_seconds = 2.231e+04)
[2022-06-10 02:19:55,300][root][INFO] - Step 84354560 @ 3578.8 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (step = 84354560, mean_episode_return = 145.16, mean_episode_step = 1047.6, total_loss = 220.41, pg_loss = 154.99, baseline_loss = 70.968, entropy_loss = -5.548, learner_queue_size = 32, _tick = 22804, _time = 1.6548e+09, train_seconds = 2.2315e+04)
[2022-06-10 02:20:00,306][root][INFO] - Step 84375040 @ 4091.3 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 84375040, mean_episode_return = 65.337, mean_episode_step = 1564.2, total_loss = -190.31, pg_loss = -231.55, baseline_loss = 46.719, entropy_loss = -5.4826, learner_queue_size = 32, _tick = 22811, _time = 1.6548e+09, train_seconds = 2.232e+04)
[2022-06-10 02:20:05,310][root][INFO] - Step 84392960 @ 3581.2 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 84392960, mean_episode_return = 80.94, mean_episode_step = 1911.8, total_loss = 54.834, pg_loss = 14.173, baseline_loss = 46.196, entropy_loss = -5.5349, learner_queue_size = 32, _tick = 22817, _time = 1.6548e+09, train_seconds = 2.2325e+04)
[2022-06-10 02:20:10,314][root][INFO] - Step 84413440 @ 4092.6 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 84413440, mean_episode_return = 19.915, mean_episode_step = 1073.3, total_loss = 58.792, pg_loss = 8.3542, baseline_loss = 55.951, entropy_loss = -5.513, learner_queue_size = 32, _tick = 22823, _time = 1.6548e+09, train_seconds = 2.233e+04)
[2022-06-10 02:20:15,319][root][INFO] - Step 84433920 @ 4092.1 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 84433920, mean_episode_return = 73.5, mean_episode_step = 1236.6, total_loss = 155.72, pg_loss = 100.04, baseline_loss = 61.244, entropy_loss = -5.5671, learner_queue_size = 32, _tick = 22830, _time = 1.6548e+09, train_seconds = 2.2335e+04)
[2022-06-10 02:20:20,322][root][INFO] - Step 84451840 @ 3581.7 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 84451840, mean_episode_return = 38.334, mean_episode_step = 988.07, total_loss = 282.22, pg_loss = 218.45, baseline_loss = 69.323, entropy_loss = -5.5495, learner_queue_size = 32, _tick = 22836, _time = 1.6548e+09, train_seconds = 2.234e+04)
[2022-06-10 02:20:25,328][root][INFO] - Step 84469760 @ 3579.7 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 84469760, mean_episode_return = 68.8, mean_episode_step = 1032.0, total_loss = 638.23, pg_loss = 266.83, baseline_loss = 376.94, entropy_loss = -5.5448, learner_queue_size = 32, _tick = 22843, _time = 1.6548e+09, train_seconds = 2.2345e+04)
[2022-06-10 02:20:30,330][root][INFO] - Step 84490240 @ 4094.5 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 84490240, mean_episode_return = 47.66, mean_episode_step = 1643.5, total_loss = 140.14, pg_loss = 93.281, baseline_loss = 52.394, entropy_loss = -5.53, learner_queue_size = 32, _tick = 22847, _time = 1.6548e+09, train_seconds = 2.235e+04)
[2022-06-10 02:20:35,334][root][INFO] - Step 84510720 @ 4092.7 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 84510720, mean_episode_return = 129.56, mean_episode_step = 1102.6, total_loss = 80.282, pg_loss = -11.216, baseline_loss = 96.942, entropy_loss = -5.444, learner_queue_size = 32, _tick = 22853, _time = 1.6548e+09, train_seconds = 2.2355e+04)
[2022-06-10 02:20:40,338][root][INFO] - Step 84531200 @ 4092.5 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 84531200, mean_episode_return = None, mean_episode_step = 1150.9, total_loss = 231.7, pg_loss = 129.87, baseline_loss = 107.34, entropy_loss = -5.5094, learner_queue_size = 32, _tick = 22858, _time = 1.6548e+09, train_seconds = 2.236e+04)
[2022-06-10 02:20:45,342][root][INFO] - Step 84551680 @ 4092.8 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 84551680, mean_episode_return = 108.92, mean_episode_step = 1201.2, total_loss = 255.31, pg_loss = 171.36, baseline_loss = 89.419, entropy_loss = -5.4696, learner_queue_size = 32, _tick = 22863, _time = 1.6548e+09, train_seconds = 2.2365e+04)
[2022-06-10 02:20:50,346][root][INFO] - Step 84569600 @ 3581.1 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 84569600, mean_episode_return = None, mean_episode_step = 1146.0, total_loss = -199.54, pg_loss = -227.03, baseline_loss = 32.981, entropy_loss = -5.4991, learner_queue_size = 32, _tick = 22868, _time = 1.6548e+09, train_seconds = 2.237e+04)
[2022-06-10 02:20:55,351][root][INFO] - Step 84590080 @ 4092.1 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 84590080, mean_episode_return = 36.77, mean_episode_step = 1059.3, total_loss = 16.452, pg_loss = -15.72, baseline_loss = 37.745, entropy_loss = -5.5723, learner_queue_size = 32, _tick = 22875, _time = 1.6548e+09, train_seconds = 2.2375e+04)
[2022-06-10 02:21:00,355][root][INFO] - Step 84610560 @ 4093.3 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 84610560, mean_episode_return = 79.45, mean_episode_step = 1060.5, total_loss = -79.436, pg_loss = -111.05, baseline_loss = 37.137, entropy_loss = -5.5242, learner_queue_size = 32, _tick = 22882, _time = 1.6548e+09, train_seconds = 2.238e+04)
[2022-06-10 02:21:05,358][root][INFO] - Step 84628480 @ 3581.2 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 84628480, mean_episode_return = 55.43, mean_episode_step = 840.46, total_loss = 89.961, pg_loss = 50.992, baseline_loss = 44.494, entropy_loss = -5.5252, learner_queue_size = 32, _tick = 22888, _time = 1.6548e+09, train_seconds = 2.2385e+04)
[2022-06-10 02:21:10,362][root][INFO] - Step 84648960 @ 4092.8 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 84648960, mean_episode_return = 21.35, mean_episode_step = 1035.8, total_loss = 157.62, pg_loss = 60.033, baseline_loss = 103.14, entropy_loss = -5.5514, learner_queue_size = 32, _tick = 22894, _time = 1.6548e+09, train_seconds = 2.239e+04)
[2022-06-10 02:21:15,366][root][INFO] - Step 84666880 @ 3581.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 84666880, mean_episode_return = 107.62, mean_episode_step = 1036.0, total_loss = 222.11, pg_loss = 169.67, baseline_loss = 57.974, entropy_loss = -5.5353, learner_queue_size = 32, _tick = 22899, _time = 1.6548e+09, train_seconds = 2.2395e+04)
[2022-06-10 02:21:20,370][root][INFO] - Step 84687360 @ 4092.7 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 84687360, mean_episode_return = 46.783, mean_episode_step = 1028.6, total_loss = -153.04, pg_loss = -178.29, baseline_loss = 30.755, entropy_loss = -5.4981, learner_queue_size = 32, _tick = 22905, _time = 1.6548e+09, train_seconds = 2.24e+04)
[2022-06-10 02:21:25,374][root][INFO] - Step 84705280 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 84705280, mean_episode_return = 55.249, mean_episode_step = 864.2, total_loss = -159.81, pg_loss = -171.27, baseline_loss = 16.976, entropy_loss = -5.5129, learner_queue_size = 32, _tick = 22911, _time = 1.6548e+09, train_seconds = 2.2405e+04)
[2022-06-10 02:21:30,378][root][INFO] - Step 84725760 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 84725760, mean_episode_return = 44.285, mean_episode_step = 1432.6, total_loss = 81.563, pg_loss = 14.294, baseline_loss = 72.804, entropy_loss = -5.5349, learner_queue_size = 32, _tick = 22919, _time = 1.6548e+09, train_seconds = 2.241e+04)
[2022-06-10 02:21:35,382][root][INFO] - Step 84746240 @ 4092.8 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 84746240, mean_episode_return = None, mean_episode_step = 1103.3, total_loss = 217.88, pg_loss = 168.04, baseline_loss = 55.416, entropy_loss = -5.575, learner_queue_size = 32, _tick = 22926, _time = 1.6548e+09, train_seconds = 2.2415e+04)
[2022-06-10 02:21:40,386][root][INFO] - Step 84766720 @ 4092.6 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 84766720, mean_episode_return = 22.5, mean_episode_step = 1395.8, total_loss = 114.6, pg_loss = 86.588, baseline_loss = 33.545, entropy_loss = -5.5331, learner_queue_size = 32, _tick = 22932, _time = 1.6548e+09, train_seconds = 2.242e+04)
[2022-06-10 02:21:45,393][root][INFO] - Step 84784640 @ 3579.2 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 84784640, mean_episode_return = None, mean_episode_step = 1547.8, total_loss = 149.21, pg_loss = 99.539, baseline_loss = 55.149, entropy_loss = -5.4747, learner_queue_size = 32, _tick = 22937, _time = 1.6548e+09, train_seconds = 2.2425e+04)
[2022-06-10 02:21:50,398][root][INFO] - Step 84805120 @ 4091.7 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 84805120, mean_episode_return = 33.13, mean_episode_step = 880.11, total_loss = 590.38, pg_loss = 460.73, baseline_loss = 135.09, entropy_loss = -5.4408, learner_queue_size = 32, _tick = 22942, _time = 1.6548e+09, train_seconds = 2.243e+04)
[2022-06-10 02:21:55,402][root][INFO] - Step 84825600 @ 4092.8 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 84825600, mean_episode_return = 44.164, mean_episode_step = 938.4, total_loss = 106.3, pg_loss = 45.256, baseline_loss = 66.409, entropy_loss = -5.3668, learner_queue_size = 32, _tick = 22949, _time = 1.6548e+09, train_seconds = 2.2435e+04)
[2022-06-10 02:22:00,406][root][INFO] - Step 84843520 @ 3581.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 84843520, mean_episode_return = 58.93, mean_episode_step = 1560.2, total_loss = -0.70812, pg_loss = -28.551, baseline_loss = 33.074, entropy_loss = -5.2308, learner_queue_size = 32, _tick = 22952, _time = 1.6548e+09, train_seconds = 2.244e+04)
[2022-06-10 02:22:05,410][root][INFO] - Step 84864000 @ 4092.7 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 84864000, mean_episode_return = 17.525, mean_episode_step = 1025.9, total_loss = 87.521, pg_loss = 44.859, baseline_loss = 48.252, entropy_loss = -5.5903, learner_queue_size = 32, _tick = 22959, _time = 1.6548e+09, train_seconds = 2.2445e+04)
[2022-06-10 02:22:10,414][root][INFO] - Step 84884480 @ 4092.8 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 84884480, mean_episode_return = 88.289, mean_episode_step = 1107.3, total_loss = 182.3, pg_loss = 108.49, baseline_loss = 79.406, entropy_loss = -5.5962, learner_queue_size = 32, _tick = 22966, _time = 1.6548e+09, train_seconds = 2.245e+04)
[2022-06-10 02:22:15,419][root][INFO] - Step 84902400 @ 3580.4 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 84902400, mean_episode_return = 67.487, mean_episode_step = 1063.2, total_loss = -117.09, pg_loss = -132.53, baseline_loss = 21.054, entropy_loss = -5.6136, learner_queue_size = 32, _tick = 22972, _time = 1.6548e+09, train_seconds = 2.2455e+04)
[2022-06-10 02:22:20,422][root][INFO] - Step 84922880 @ 4093.6 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 84922880, mean_episode_return = None, mean_episode_step = 1177.4, total_loss = 267.6, pg_loss = 214.48, baseline_loss = 58.696, entropy_loss = -5.5821, learner_queue_size = 32, _tick = 22979, _time = 1.6548e+09, train_seconds = 2.246e+04)
[2022-06-10 02:22:25,426][root][INFO] - Step 84943360 @ 4092.7 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 84943360, mean_episode_return = 67.381, mean_episode_step = 1026.9, total_loss = 256.42, pg_loss = 199.6, baseline_loss = 62.43, entropy_loss = -5.6139, learner_queue_size = 32, _tick = 22986, _time = 1.6548e+09, train_seconds = 2.2465e+04)
[2022-06-10 02:22:30,430][root][INFO] - Step 84961280 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 84961280, mean_episode_return = None, mean_episode_step = 1743.9, total_loss = -25.669, pg_loss = -49.301, baseline_loss = 29.268, entropy_loss = -5.6356, learner_queue_size = 32, _tick = 22991, _time = 1.6548e+09, train_seconds = 2.247e+04)
[2022-06-10 02:22:35,434][root][INFO] - Step 84981760 @ 4092.8 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 84981760, mean_episode_return = 26.355, mean_episode_step = 1354.7, total_loss = 444.94, pg_loss = 349.44, baseline_loss = 101.07, entropy_loss = -5.5718, learner_queue_size = 32, _tick = 22999, _time = 1.6548e+09, train_seconds = 2.2475e+04)
[2022-06-10 02:22:40,438][root][INFO] - Step 85002240 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 85002240, mean_episode_return = 105.44, mean_episode_step = 1426.6, total_loss = 39.538, pg_loss = -23.816, baseline_loss = 68.847, entropy_loss = -5.4934, learner_queue_size = 32, _tick = 23006, _time = 1.6548e+09, train_seconds = 2.248e+04)
[2022-06-10 02:22:45,442][root][INFO] - Step 85020160 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 85020160, mean_episode_return = None, mean_episode_step = 1184.9, total_loss = -39.793, pg_loss = -66.168, baseline_loss = 31.999, entropy_loss = -5.6239, learner_queue_size = 32, _tick = 23012, _time = 1.6548e+09, train_seconds = 2.2485e+04)
[2022-06-10 02:22:50,446][root][INFO] - Step 85038080 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 85038080, mean_episode_return = 2.21, mean_episode_step = 890.48, total_loss = 83.832, pg_loss = 25.583, baseline_loss = 63.888, entropy_loss = -5.64, learner_queue_size = 32, _tick = 23019, _time = 1.6548e+09, train_seconds = 2.249e+04)
[2022-06-10 02:22:55,450][root][INFO] - Step 85058560 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 85058560, mean_episode_return = 48.81, mean_episode_step = 942.38, total_loss = -152.08, pg_loss = -168.03, baseline_loss = 21.568, entropy_loss = -5.6238, learner_queue_size = 32, _tick = 23027, _time = 1.6548e+09, train_seconds = 2.2495e+04)
[2022-06-10 02:23:00,454][root][INFO] - Step 85076480 @ 3581.2 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 85076480, mean_episode_return = 115.68, mean_episode_step = 715.1, total_loss = 59.28, pg_loss = 25.626, baseline_loss = 39.297, entropy_loss = -5.6434, learner_queue_size = 32, _tick = 23032, _time = 1.6548e+09, train_seconds = 2.25e+04)
[2022-06-10 02:23:05,458][root][INFO] - Step 85094400 @ 3581.1 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 85094400, mean_episode_return = 88.019, mean_episode_step = 877.6, total_loss = 755.15, pg_loss = 584.07, baseline_loss = 176.7, entropy_loss = -5.6238, learner_queue_size = 32, _tick = 23038, _time = 1.6548e+09, train_seconds = 2.2505e+04)
[2022-06-10 02:23:10,462][root][INFO] - Step 85114880 @ 4092.9 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 85114880, mean_episode_return = 46.321, mean_episode_step = 1078.9, total_loss = -171.67, pg_loss = -176.22, baseline_loss = 10.218, entropy_loss = -5.666, learner_queue_size = 32, _tick = 23045, _time = 1.6548e+09, train_seconds = 2.251e+04)
[2022-06-10 02:23:15,466][root][INFO] - Step 85135360 @ 4092.6 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 85135360, mean_episode_return = 79.141, mean_episode_step = 1527.2, total_loss = -139.63, pg_loss = -150.0, baseline_loss = 15.991, entropy_loss = -5.6253, learner_queue_size = 32, _tick = 23049, _time = 1.6548e+09, train_seconds = 2.2515e+04)
[2022-06-10 02:23:20,470][root][INFO] - Step 85153280 @ 3581.2 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 85153280, mean_episode_return = 5.2099, mean_episode_step = 1105.2, total_loss = 64.983, pg_loss = 33.956, baseline_loss = 36.613, entropy_loss = -5.5861, learner_queue_size = 32, _tick = 23055, _time = 1.6548e+09, train_seconds = 2.252e+04)
[2022-06-10 02:23:25,474][root][INFO] - Step 85173760 @ 4092.7 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (step = 85173760, mean_episode_return = 18.585, mean_episode_step = 855.3, total_loss = -175.27, pg_loss = -189.59, baseline_loss = 19.869, entropy_loss = -5.5549, learner_queue_size = 32, _tick = 23062, _time = 1.6548e+09, train_seconds = 2.2525e+04)
[2022-06-10 02:23:30,478][root][INFO] - Step 85194240 @ 4092.7 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 85194240, mean_episode_return = 64.344, mean_episode_step = 1429.5, total_loss = 11.657, pg_loss = -2.2288, baseline_loss = 19.547, entropy_loss = -5.6616, learner_queue_size = 32, _tick = 23069, _time = 1.6548e+09, train_seconds = 2.253e+04)
[2022-06-10 02:23:35,482][root][INFO] - Step 85212160 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 85212160, mean_episode_return = 14.69, mean_episode_step = 1112.9, total_loss = 351.8, pg_loss = 287.72, baseline_loss = 69.798, entropy_loss = -5.7134, learner_queue_size = 32, _tick = 23074, _time = 1.6548e+09, train_seconds = 2.2535e+04)
[2022-06-10 02:23:40,486][root][INFO] - Step 85232640 @ 4092.3 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 85232640, mean_episode_return = 22.2, mean_episode_step = 796.07, total_loss = 256.54, pg_loss = 206.71, baseline_loss = 55.534, entropy_loss = -5.6998, learner_queue_size = 32, _tick = 23079, _time = 1.6548e+09, train_seconds = 2.254e+04)
[2022-06-10 02:23:45,490][root][INFO] - Step 85253120 @ 4093.0 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 85253120, mean_episode_return = 31.247, mean_episode_step = 774.8, total_loss = -14.569, pg_loss = -70.001, baseline_loss = 61.139, entropy_loss = -5.7062, learner_queue_size = 32, _tick = 23084, _time = 1.6548e+09, train_seconds = 2.2545e+04)
[2022-06-10 02:23:50,494][root][INFO] - Step 85271040 @ 3581.1 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 85271040, mean_episode_return = 64.949, mean_episode_step = 960.71, total_loss = 98.052, pg_loss = 60.36, baseline_loss = 43.351, entropy_loss = -5.6587, learner_queue_size = 32, _tick = 23088, _time = 1.6548e+09, train_seconds = 2.255e+04)
[2022-06-10 02:23:55,498][root][INFO] - Step 85291520 @ 4092.8 SPS. Inference batcher size: 85. Learner queue size: 32. Other stats: (step = 85291520, mean_episode_return = None, mean_episode_step = 959.5, total_loss = -6.0928, pg_loss = -98.141, baseline_loss = 97.671, entropy_loss = -5.6232, learner_queue_size = 32, _tick = 23091, _time = 1.6548e+09, train_seconds = 2.2555e+04)
[2022-06-10 02:24:00,502][root][INFO] - Step 85309440 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 85309440, mean_episode_return = 30.545, mean_episode_step = 900.12, total_loss = -285.15, pg_loss = -321.63, baseline_loss = 42.194, entropy_loss = -5.7123, learner_queue_size = 32, _tick = 23097, _time = 1.6548e+09, train_seconds = 2.256e+04)
[2022-06-10 02:24:05,506][root][INFO] - Step 85329920 @ 4092.8 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 85329920, mean_episode_return = 12.955, mean_episode_step = 962.59, total_loss = 171.05, pg_loss = 101.58, baseline_loss = 75.138, entropy_loss = -5.6693, learner_queue_size = 32, _tick = 23105, _time = 1.6548e+09, train_seconds = 2.2565e+04)
[2022-06-10 02:24:10,510][root][INFO] - Step 85350400 @ 4092.7 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 85350400, mean_episode_return = None, mean_episode_step = 765.72, total_loss = -46.557, pg_loss = -99.741, baseline_loss = 58.82, entropy_loss = -5.6361, learner_queue_size = 32, _tick = 23112, _time = 1.6548e+09, train_seconds = 2.257e+04)
[2022-06-10 02:24:15,514][root][INFO] - Step 85368320 @ 3581.2 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 85368320, mean_episode_return = 19.96, mean_episode_step = 1070.1, total_loss = 259.29, pg_loss = 202.25, baseline_loss = 62.7, entropy_loss = -5.6642, learner_queue_size = 32, _tick = 23117, _time = 1.6548e+09, train_seconds = 2.2575e+04)
[2022-06-10 02:24:20,518][root][INFO] - Step 85388800 @ 4092.7 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 85388800, mean_episode_return = 90.74, mean_episode_step = 1788.0, total_loss = 331.99, pg_loss = 260.68, baseline_loss = 76.919, entropy_loss = -5.6097, learner_queue_size = 32, _tick = 23124, _time = 1.6548e+09, train_seconds = 2.258e+04)
[2022-06-10 02:24:25,522][root][INFO] - Step 85409280 @ 4092.7 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 85409280, mean_episode_return = 40.35, mean_episode_step = 865.96, total_loss = -26.027, pg_loss = -93.289, baseline_loss = 72.861, entropy_loss = -5.5987, learner_queue_size = 32, _tick = 23131, _time = 1.6548e+09, train_seconds = 2.2585e+04)
[2022-06-10 02:24:30,526][root][INFO] - Step 85427200 @ 3581.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 85427200, mean_episode_return = 71.252, mean_episode_step = 1416.9, total_loss = -146.78, pg_loss = -182.0, baseline_loss = 40.724, entropy_loss = -5.5061, learner_queue_size = 32, _tick = 23137, _time = 1.6548e+09, train_seconds = 2.259e+04)
[2022-06-10 02:24:35,530][root][INFO] - Step 85447680 @ 4092.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 85447680, mean_episode_return = 54.098, mean_episode_step = 880.73, total_loss = -213.49, pg_loss = -298.14, baseline_loss = 89.962, entropy_loss = -5.3112, learner_queue_size = 32, _tick = 23142, _time = 1.6548e+09, train_seconds = 2.2595e+04)
[2022-06-10 02:24:40,534][root][INFO] - Step 85468160 @ 4092.6 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 85468160, mean_episode_return = 68.155, mean_episode_step = 867.41, total_loss = 123.88, pg_loss = 46.058, baseline_loss = 83.314, entropy_loss = -5.4876, learner_queue_size = 32, _tick = 23149, _time = 1.6548e+09, train_seconds = 2.26e+04)
[2022-06-10 02:24:45,538][root][INFO] - Step 85488640 @ 4092.6 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 85488640, mean_episode_return = 18.65, mean_episode_step = 954.31, total_loss = 87.741, pg_loss = 38.469, baseline_loss = 54.857, entropy_loss = -5.5856, learner_queue_size = 32, _tick = 23156, _time = 1.6548e+09, train_seconds = 2.2605e+04)
[2022-06-10 02:24:50,542][root][INFO] - Step 85506560 @ 3581.2 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 85506560, mean_episode_return = 16.127, mean_episode_step = 1239.3, total_loss = -23.421, pg_loss = -60.77, baseline_loss = 42.872, entropy_loss = -5.5234, learner_queue_size = 32, _tick = 23163, _time = 1.6548e+09, train_seconds = 2.261e+04)
[2022-06-10 02:24:55,546][root][INFO] - Step 85527040 @ 4092.8 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 85527040, mean_episode_return = 22.13, mean_episode_step = 892.73, total_loss = 78.448, pg_loss = 43.742, baseline_loss = 40.283, entropy_loss = -5.5771, learner_queue_size = 32, _tick = 23170, _time = 1.6548e+09, train_seconds = 2.2615e+04)
[2022-06-10 02:25:00,550][root][INFO] - Step 85544960 @ 3581.1 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 85544960, mean_episode_return = 59.854, mean_episode_step = 984.01, total_loss = -212.01, pg_loss = -237.64, baseline_loss = 31.227, entropy_loss = -5.5919, learner_queue_size = 32, _tick = 23176, _time = 1.6548e+09, train_seconds = 2.262e+04)
[2022-06-10 02:25:05,554][root][INFO] - Step 85565440 @ 4092.7 SPS. Inference batcher size: 85. Learner queue size: 32. Other stats: (step = 85565440, mean_episode_return = 50.66, mean_episode_step = 792.83, total_loss = 484.82, pg_loss = 392.86, baseline_loss = 97.515, entropy_loss = -5.5505, learner_queue_size = 32, _tick = 23183, _time = 1.6548e+09, train_seconds = 2.2625e+04)
[2022-06-10 02:25:10,558][root][INFO] - Step 85585920 @ 4092.8 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 85585920, mean_episode_return = 67.89, mean_episode_step = 832.94, total_loss = 224.8, pg_loss = 156.22, baseline_loss = 74.12, entropy_loss = -5.5361, learner_queue_size = 32, _tick = 23190, _time = 1.6548e+09, train_seconds = 2.263e+04)
[2022-06-10 02:25:15,562][root][INFO] - Step 85603840 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 85603840, mean_episode_return = 96.669, mean_episode_step = 808.63, total_loss = 172.67, pg_loss = 132.66, baseline_loss = 45.4, entropy_loss = -5.3946, learner_queue_size = 32, _tick = 23195, _time = 1.6548e+09, train_seconds = 2.2635e+04)
[2022-06-10 02:25:20,566][root][INFO] - Step 85624320 @ 4092.8 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 85624320, mean_episode_return = 6.875, mean_episode_step = 968.9, total_loss = -248.36, pg_loss = -287.21, baseline_loss = 44.391, entropy_loss = -5.5354, learner_queue_size = 32, _tick = 23201, _time = 1.6548e+09, train_seconds = 2.264e+04)
[2022-06-10 02:25:25,570][root][INFO] - Step 85644800 @ 4092.7 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 85644800, mean_episode_return = 164.32, mean_episode_step = 801.67, total_loss = 426.53, pg_loss = 313.56, baseline_loss = 118.39, entropy_loss = -5.423, learner_queue_size = 32, _tick = 23209, _time = 1.6548e+09, train_seconds = 2.2645e+04)
[2022-06-10 02:25:30,574][root][INFO] - Step 85665280 @ 4092.8 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 85665280, mean_episode_return = 87.9, mean_episode_step = 849.0, total_loss = 722.75, pg_loss = 512.1, baseline_loss = 216.14, entropy_loss = -5.4941, learner_queue_size = 32, _tick = 23215, _time = 1.6548e+09, train_seconds = 2.265e+04)
[2022-06-10 02:25:35,578][root][INFO] - Step 85683200 @ 3581.1 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 85683200, mean_episode_return = 83.339, mean_episode_step = 891.93, total_loss = 86.573, pg_loss = 36.863, baseline_loss = 55.179, entropy_loss = -5.469, learner_queue_size = 32, _tick = 23222, _time = 1.6548e+09, train_seconds = 2.2655e+04)
[2022-06-10 02:25:40,582][root][INFO] - Step 85703680 @ 4092.7 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 85703680, mean_episode_return = 94.169, mean_episode_step = 821.99, total_loss = -43.087, pg_loss = -71.569, baseline_loss = 34.052, entropy_loss = -5.5692, learner_queue_size = 32, _tick = 23230, _time = 1.6548e+09, train_seconds = 2.266e+04)
[2022-06-10 02:25:45,586][root][INFO] - Step 85721600 @ 3581.2 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 85721600, mean_episode_return = 56.88, mean_episode_step = 960.0, total_loss = -12.76, pg_loss = -51.029, baseline_loss = 43.866, entropy_loss = -5.5969, learner_queue_size = 32, _tick = 23236, _time = 1.6548e+09, train_seconds = 2.2665e+04)
[2022-06-10 02:25:50,590][root][INFO] - Step 85742080 @ 4092.7 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 85742080, mean_episode_return = 50.716, mean_episode_step = 1065.8, total_loss = 12.782, pg_loss = -18.663, baseline_loss = 37.009, entropy_loss = -5.5648, learner_queue_size = 32, _tick = 23242, _time = 1.6548e+09, train_seconds = 2.267e+04)
[2022-06-10 02:25:55,594][root][INFO] - Step 85762560 @ 4092.8 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 85762560, mean_episode_return = 46.823, mean_episode_step = 815.37, total_loss = 222.23, pg_loss = 149.77, baseline_loss = 77.93, entropy_loss = -5.4687, learner_queue_size = 32, _tick = 23248, _time = 1.6548e+09, train_seconds = 2.2675e+04)
[2022-06-10 02:26:00,598][root][INFO] - Step 85783040 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 85783040, mean_episode_return = 46.978, mean_episode_step = 841.57, total_loss = -282.53, pg_loss = -348.25, baseline_loss = 71.113, entropy_loss = -5.3954, learner_queue_size = 32, _tick = 23252, _time = 1.6548e+09, train_seconds = 2.268e+04)
[2022-06-10 02:26:05,602][root][INFO] - Step 85800960 @ 3581.1 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 85800960, mean_episode_return = None, mean_episode_step = 932.88, total_loss = 255.72, pg_loss = 147.75, baseline_loss = 113.55, entropy_loss = -5.5786, learner_queue_size = 32, _tick = 23256, _time = 1.6548e+09, train_seconds = 2.2685e+04)
[2022-06-10 02:26:10,606][root][INFO] - Step 85821440 @ 4092.7 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 85821440, mean_episode_return = 101.07, mean_episode_step = 875.11, total_loss = -80.949, pg_loss = -119.69, baseline_loss = 44.291, entropy_loss = -5.555, learner_queue_size = 32, _tick = 23264, _time = 1.6548e+09, train_seconds = 2.269e+04)
[2022-06-10 02:26:15,611][root][INFO] - Step 85841920 @ 4092.7 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 85841920, mean_episode_return = 29.957, mean_episode_step = 853.28, total_loss = 550.97, pg_loss = 393.46, baseline_loss = 163.09, entropy_loss = -5.5788, learner_queue_size = 32, _tick = 23270, _time = 1.6548e+09, train_seconds = 2.2695e+04)
[2022-06-10 02:26:20,614][root][INFO] - Step 85859840 @ 3581.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 85859840, mean_episode_return = 80.146, mean_episode_step = 1126.1, total_loss = 255.57, pg_loss = 192.18, baseline_loss = 68.968, entropy_loss = -5.5778, learner_queue_size = 32, _tick = 23275, _time = 1.6548e+09, train_seconds = 2.27e+04)
[2022-06-10 02:26:25,618][root][INFO] - Step 85880320 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 85880320, mean_episode_return = 98.324, mean_episode_step = 1069.3, total_loss = 131.45, pg_loss = 40.603, baseline_loss = 96.469, entropy_loss = -5.6209, learner_queue_size = 32, _tick = 23281, _time = 1.6548e+09, train_seconds = 2.2705e+04)
[2022-06-10 02:26:30,622][root][INFO] - Step 85900800 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 85900800, mean_episode_return = None, mean_episode_step = 1059.8, total_loss = -73.618, pg_loss = -100.57, baseline_loss = 32.503, entropy_loss = -5.547, learner_queue_size = 32, _tick = 23287, _time = 1.6548e+09, train_seconds = 2.271e+04)
[2022-06-10 02:26:35,626][root][INFO] - Step 85921280 @ 4092.6 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 85921280, mean_episode_return = 81.06, mean_episode_step = 1007.2, total_loss = 36.928, pg_loss = -28.579, baseline_loss = 71.008, entropy_loss = -5.501, learner_queue_size = 32, _tick = 23294, _time = 1.6548e+09, train_seconds = 2.2715e+04)
[2022-06-10 02:26:40,630][root][INFO] - Step 85939200 @ 3581.1 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 85939200, mean_episode_return = 82.76, mean_episode_step = 1025.8, total_loss = -203.45, pg_loss = -244.3, baseline_loss = 46.373, entropy_loss = -5.5176, learner_queue_size = 32, _tick = 23299, _time = 1.6548e+09, train_seconds = 2.272e+04)
[2022-06-10 02:26:45,634][root][INFO] - Step 85959680 @ 4092.8 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 85959680, mean_episode_return = 69.4, mean_episode_step = 1190.0, total_loss = 26.18, pg_loss = -9.6454, baseline_loss = 41.368, entropy_loss = -5.5419, learner_queue_size = 32, _tick = 23307, _time = 1.6548e+09, train_seconds = 2.2725e+04)
[2022-06-10 02:26:50,638][root][INFO] - Step 85977600 @ 3581.1 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 85977600, mean_episode_return = 97.69, mean_episode_step = 890.74, total_loss = 346.95, pg_loss = 134.55, baseline_loss = 217.99, entropy_loss = -5.5974, learner_queue_size = 32, _tick = 23312, _time = 1.6548e+09, train_seconds = 2.273e+04)
[2022-06-10 02:26:55,646][root][INFO] - Step 85998080 @ 4089.4 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 85998080, mean_episode_return = None, mean_episode_step = 823.84, total_loss = 172.69, pg_loss = 109.59, baseline_loss = 68.406, entropy_loss = -5.3041, learner_queue_size = 32, _tick = 23317, _time = 1.6548e+09, train_seconds = 2.2736e+04)
[2022-06-10 02:27:00,650][root][INFO] - Step 86018560 @ 4092.8 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 86018560, mean_episode_return = 36.46, mean_episode_step = 913.42, total_loss = 213.61, pg_loss = 121.11, baseline_loss = 97.693, entropy_loss = -5.1867, learner_queue_size = 32, _tick = 23324, _time = 1.6548e+09, train_seconds = 2.274e+04)
[2022-06-10 02:27:05,654][root][INFO] - Step 86039040 @ 4092.8 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 86039040, mean_episode_return = 14.87, mean_episode_step = 1106.6, total_loss = 4.6407, pg_loss = -38.877, baseline_loss = 49.014, entropy_loss = -5.4957, learner_queue_size = 32, _tick = 23329, _time = 1.6548e+09, train_seconds = 2.2746e+04)
[2022-06-10 02:27:10,658][root][INFO] - Step 86056960 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 86056960, mean_episode_return = 2.225, mean_episode_step = 862.74, total_loss = -12.309, pg_loss = -21.276, baseline_loss = 14.517, entropy_loss = -5.5512, learner_queue_size = 32, _tick = 23336, _time = 1.6548e+09, train_seconds = 2.275e+04)
[2022-06-10 02:27:15,662][root][INFO] - Step 86077440 @ 4092.8 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 86077440, mean_episode_return = 33.73, mean_episode_step = 1084.3, total_loss = 119.6, pg_loss = 85.647, baseline_loss = 39.529, entropy_loss = -5.5745, learner_queue_size = 32, _tick = 23341, _time = 1.6548e+09, train_seconds = 2.2756e+04)
[2022-06-10 02:27:20,666][root][INFO] - Step 86095360 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 86095360, mean_episode_return = 65.34, mean_episode_step = 941.33, total_loss = 136.46, pg_loss = 69.352, baseline_loss = 72.658, entropy_loss = -5.5483, learner_queue_size = 32, _tick = 23348, _time = 1.6548e+09, train_seconds = 2.276e+04)
[2022-06-10 02:27:25,674][root][INFO] - Step 86115840 @ 4089.3 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 86115840, mean_episode_return = None, mean_episode_step = 1131.1, total_loss = -58.821, pg_loss = -74.182, baseline_loss = 20.909, entropy_loss = -5.5485, learner_queue_size = 32, _tick = 23354, _time = 1.6548e+09, train_seconds = 2.2766e+04)
[2022-06-10 02:27:30,678][root][INFO] - Step 86136320 @ 4092.9 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 86136320, mean_episode_return = 64.396, mean_episode_step = 859.41, total_loss = -41.173, pg_loss = -81.28, baseline_loss = 45.622, entropy_loss = -5.514, learner_queue_size = 32, _tick = 23362, _time = 1.6548e+09, train_seconds = 2.277e+04)
[2022-06-10 02:27:35,682][root][INFO] - Step 86154240 @ 3581.2 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 86154240, mean_episode_return = 56.301, mean_episode_step = 830.31, total_loss = 7.3592, pg_loss = -27.521, baseline_loss = 40.334, entropy_loss = -5.4536, learner_queue_size = 32, _tick = 23369, _time = 1.6548e+09, train_seconds = 2.2776e+04)
[2022-06-10 02:27:40,687][root][INFO] - Step 86174720 @ 4092.3 SPS. Inference batcher size: 97. Learner queue size: 32. Other stats: (step = 86174720, mean_episode_return = -2.01, mean_episode_step = 882.19, total_loss = -104.84, pg_loss = -140.64, baseline_loss = 41.297, entropy_loss = -5.5016, learner_queue_size = 32, _tick = 23377, _time = 1.6548e+09, train_seconds = 2.278e+04)
[2022-06-10 02:27:45,690][root][INFO] - Step 86192640 @ 3581.5 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 86192640, mean_episode_return = -7.4701, mean_episode_step = 906.5, total_loss = 230.1, pg_loss = 154.88, baseline_loss = 80.763, entropy_loss = -5.5471, learner_queue_size = 32, _tick = 23383, _time = 1.6548e+09, train_seconds = 2.2786e+04)
[2022-06-10 02:27:50,694][root][INFO] - Step 86213120 @ 4092.8 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 86213120, mean_episode_return = 1.8398, mean_episode_step = 805.08, total_loss = 249.02, pg_loss = 188.49, baseline_loss = 66.019, entropy_loss = -5.4882, learner_queue_size = 32, _tick = 23388, _time = 1.6548e+09, train_seconds = 2.279e+04)
[2022-06-10 02:27:55,698][root][INFO] - Step 86233600 @ 4092.7 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 86233600, mean_episode_return = 50.58, mean_episode_step = 803.34, total_loss = -116.16, pg_loss = -149.03, baseline_loss = 38.346, entropy_loss = -5.4815, learner_queue_size = 32, _tick = 23393, _time = 1.6548e+09, train_seconds = 2.2796e+04)
[2022-06-10 02:28:00,702][root][INFO] - Step 86251520 @ 3581.2 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 86251520, mean_episode_return = 27.673, mean_episode_step = 873.92, total_loss = -54.226, pg_loss = -78.834, baseline_loss = 30.244, entropy_loss = -5.6361, learner_queue_size = 32, _tick = 23400, _time = 1.6548e+09, train_seconds = 2.28e+04)
[2022-06-10 02:28:05,706][root][INFO] - Step 86272000 @ 4092.7 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 86272000, mean_episode_return = 93.823, mean_episode_step = 856.63, total_loss = 110.25, pg_loss = 66.61, baseline_loss = 49.246, entropy_loss = -5.6067, learner_queue_size = 32, _tick = 23406, _time = 1.6548e+09, train_seconds = 2.2806e+04)
[2022-06-10 02:28:10,710][root][INFO] - Step 86292480 @ 4092.7 SPS. Inference batcher size: 78. Learner queue size: 32. Other stats: (step = 86292480, mean_episode_return = 26.34, mean_episode_step = 993.04, total_loss = 317.21, pg_loss = 255.3, baseline_loss = 67.447, entropy_loss = -5.5329, learner_queue_size = 32, _tick = 23412, _time = 1.6548e+09, train_seconds = 2.281e+04)
[2022-06-10 02:28:15,716][root][INFO] - Step 86310400 @ 3579.6 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 86310400, mean_episode_return = 81.19, mean_episode_step = 1083.3, total_loss = -114.98, pg_loss = -155.5, baseline_loss = 46.089, entropy_loss = -5.5655, learner_queue_size = 32, _tick = 23417, _time = 1.6548e+09, train_seconds = 2.2816e+04)
[2022-06-10 02:28:20,722][root][INFO] - Step 86330880 @ 4091.3 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 86330880, mean_episode_return = None, mean_episode_step = 783.31, total_loss = 234.54, pg_loss = 156.81, baseline_loss = 83.223, entropy_loss = -5.5007, learner_queue_size = 32, _tick = 23423, _time = 1.6548e+09, train_seconds = 2.282e+04)
[2022-06-10 02:28:25,726][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 02:28:25,926][root][INFO] - Step 86351360 @ 4092.7 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 86351360, mean_episode_return = 31.065, mean_episode_step = 906.06, total_loss = 2.2823, pg_loss = -49.131, baseline_loss = 57.017, entropy_loss = -5.6044, learner_queue_size = 32, _tick = 23430, _time = 1.6548e+09, train_seconds = 2.2826e+04)
[2022-06-10 02:28:30,930][root][INFO] - Step 86369280 @ 3443.4 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 86369280, mean_episode_return = 74.539, mean_episode_step = 797.3, total_loss = 6.2393, pg_loss = -25.238, baseline_loss = 37.091, entropy_loss = -5.6137, learner_queue_size = 32, _tick = 23437, _time = 1.6548e+09, train_seconds = 2.2831e+04)
[2022-06-10 02:28:35,934][root][INFO] - Step 86389760 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 86389760, mean_episode_return = 109.03, mean_episode_step = 848.27, total_loss = -97.878, pg_loss = -143.14, baseline_loss = 50.634, entropy_loss = -5.3704, learner_queue_size = 32, _tick = 23443, _time = 1.6548e+09, train_seconds = 2.2836e+04)
[2022-06-10 02:28:40,941][root][INFO] - Step 86407680 @ 3579.5 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 86407680, mean_episode_return = 99.569, mean_episode_step = 947.99, total_loss = 187.55, pg_loss = 126.85, baseline_loss = 66.188, entropy_loss = -5.494, learner_queue_size = 32, _tick = 23449, _time = 1.6548e+09, train_seconds = 2.2841e+04)
[2022-06-10 02:28:45,947][root][INFO] - Step 86428160 @ 4090.6 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (step = 86428160, mean_episode_return = 32.977, mean_episode_step = 899.01, total_loss = 176.2, pg_loss = 131.94, baseline_loss = 49.893, entropy_loss = -5.6333, learner_queue_size = 32, _tick = 23455, _time = 1.6548e+09, train_seconds = 2.2846e+04)
[2022-06-10 02:28:50,950][root][INFO] - Step 86448640 @ 4093.6 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 86448640, mean_episode_return = None, mean_episode_step = 1014.1, total_loss = -36.098, pg_loss = -81.372, baseline_loss = 50.874, entropy_loss = -5.6, learner_queue_size = 32, _tick = 23461, _time = 1.6548e+09, train_seconds = 2.2851e+04)
[2022-06-10 02:28:55,954][root][INFO] - Step 86466560 @ 3581.1 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 86466560, mean_episode_return = 51.891, mean_episode_step = 1022.5, total_loss = 277.53, pg_loss = 166.46, baseline_loss = 116.71, entropy_loss = -5.6434, learner_queue_size = 32, _tick = 23465, _time = 1.6548e+09, train_seconds = 2.2856e+04)
[2022-06-10 02:29:00,958][root][INFO] - Step 86487040 @ 4092.6 SPS. Inference batcher size: 73. Learner queue size: 32. Other stats: (step = 86487040, mean_episode_return = 56.931, mean_episode_step = 1026.1, total_loss = -49.886, pg_loss = -101.29, baseline_loss = 56.98, entropy_loss = -5.5718, learner_queue_size = 32, _tick = 23470, _time = 1.6548e+09, train_seconds = 2.2861e+04)
[2022-06-10 02:29:05,962][root][INFO] - Step 86504960 @ 3581.2 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 86504960, mean_episode_return = 35.947, mean_episode_step = 924.89, total_loss = 335.79, pg_loss = 249.34, baseline_loss = 92.139, entropy_loss = -5.6925, learner_queue_size = 32, _tick = 23477, _time = 1.6548e+09, train_seconds = 2.2866e+04)
[2022-06-10 02:29:10,966][root][INFO] - Step 86525440 @ 4092.5 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (step = 86525440, mean_episode_return = 41.59, mean_episode_step = 1146.8, total_loss = -69.465, pg_loss = -88.043, baseline_loss = 24.267, entropy_loss = -5.6887, learner_queue_size = 32, _tick = 23484, _time = 1.6548e+09, train_seconds = 2.2871e+04)
[2022-06-10 02:29:15,970][root][INFO] - Step 86545920 @ 4093.0 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 86545920, mean_episode_return = 142.4, mean_episode_step = 952.16, total_loss = 133.89, pg_loss = 87.384, baseline_loss = 52.166, entropy_loss = -5.6634, learner_queue_size = 32, _tick = 23490, _time = 1.6548e+09, train_seconds = 2.2876e+04)
[2022-06-10 02:29:20,974][root][INFO] - Step 86563840 @ 3581.2 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (step = 86563840, mean_episode_return = 16.82, mean_episode_step = 977.4, total_loss = -33.256, pg_loss = -51.879, baseline_loss = 24.297, entropy_loss = -5.6746, learner_queue_size = 32, _tick = 23495, _time = 1.6548e+09, train_seconds = 2.2881e+04)
[2022-06-10 02:29:25,978][root][INFO] - Step 86584320 @ 4092.6 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 86584320, mean_episode_return = 1.57, mean_episode_step = 863.17, total_loss = -22.583, pg_loss = -50.397, baseline_loss = 33.319, entropy_loss = -5.5052, learner_queue_size = 32, _tick = 23503, _time = 1.6548e+09, train_seconds = 2.2886e+04)
[2022-06-10 02:29:30,982][root][INFO] - Step 86602240 @ 3581.2 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 86602240, mean_episode_return = 61.766, mean_episode_step = 1144.8, total_loss = 83.431, pg_loss = 35.968, baseline_loss = 52.834, entropy_loss = -5.3709, learner_queue_size = 32, _tick = 23510, _time = 1.6548e+09, train_seconds = 2.2891e+04)
[2022-06-10 02:29:35,986][root][INFO] - Step 86622720 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 86622720, mean_episode_return = None, mean_episode_step = 905.84, total_loss = 218.48, pg_loss = 145.55, baseline_loss = 78.204, entropy_loss = -5.2752, learner_queue_size = 32, _tick = 23516, _time = 1.6548e+09, train_seconds = 2.2896e+04)
[2022-06-10 02:29:40,990][root][INFO] - Step 86643200 @ 4092.7 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 86643200, mean_episode_return = 18.75, mean_episode_step = 901.5, total_loss = 163.7, pg_loss = 80.677, baseline_loss = 88.487, entropy_loss = -5.4596, learner_queue_size = 32, _tick = 23523, _time = 1.6548e+09, train_seconds = 2.2901e+04)
[2022-06-10 02:29:45,994][root][INFO] - Step 86661120 @ 3581.1 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 86661120, mean_episode_return = 125.35, mean_episode_step = 804.43, total_loss = 151.22, pg_loss = 81.309, baseline_loss = 75.419, entropy_loss = -5.5126, learner_queue_size = 32, _tick = 23528, _time = 1.6548e+09, train_seconds = 2.2906e+04)
[2022-06-10 02:29:50,998][root][INFO] - Step 86681600 @ 4092.9 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 86681600, mean_episode_return = 23.449, mean_episode_step = 916.74, total_loss = 31.968, pg_loss = -2.8741, baseline_loss = 40.349, entropy_loss = -5.5073, learner_queue_size = 32, _tick = 23534, _time = 1.6548e+09, train_seconds = 2.2911e+04)
[2022-06-10 02:29:56,004][root][INFO] - Step 86699520 @ 3579.8 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 86699520, mean_episode_return = 37.155, mean_episode_step = 935.6, total_loss = 394.33, pg_loss = 204.27, baseline_loss = 195.41, entropy_loss = -5.3465, learner_queue_size = 32, _tick = 23541, _time = 1.6548e+09, train_seconds = 2.2916e+04)
[2022-06-10 02:30:01,006][root][INFO] - Step 86720000 @ 4094.3 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 86720000, mean_episode_return = 23.52, mean_episode_step = 944.65, total_loss = -86.053, pg_loss = -110.03, baseline_loss = 29.362, entropy_loss = -5.3833, learner_queue_size = 32, _tick = 23548, _time = 1.6548e+09, train_seconds = 2.2921e+04)
[2022-06-10 02:30:06,010][root][INFO] - Step 86740480 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 86740480, mean_episode_return = 96.609, mean_episode_step = 1122.4, total_loss = -96.294, pg_loss = -121.46, baseline_loss = 30.701, entropy_loss = -5.5322, learner_queue_size = 32, _tick = 23552, _time = 1.6548e+09, train_seconds = 2.2926e+04)
[2022-06-10 02:30:11,014][root][INFO] - Step 86758400 @ 3580.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 86758400, mean_episode_return = 18.12, mean_episode_step = 911.97, total_loss = 160.03, pg_loss = 105.78, baseline_loss = 59.678, entropy_loss = -5.4316, learner_queue_size = 32, _tick = 23559, _time = 1.6548e+09, train_seconds = 2.2931e+04)
[2022-06-10 02:30:16,019][root][INFO] - Step 86778880 @ 4092.5 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 86778880, mean_episode_return = None, mean_episode_step = 1232.0, total_loss = 31.87, pg_loss = 13.864, baseline_loss = 22.988, entropy_loss = -4.9828, learner_queue_size = 32, _tick = 23564, _time = 1.6548e+09, train_seconds = 2.2936e+04)
[2022-06-10 02:30:21,025][root][INFO] - Step 86796800 @ 3579.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 86796800, mean_episode_return = None, mean_episode_step = 1052.8, total_loss = 160.7, pg_loss = 93.859, baseline_loss = 71.123, entropy_loss = -4.2843, learner_queue_size = 32, _tick = 23568, _time = 1.6548e+09, train_seconds = 2.2941e+04)
[2022-06-10 02:30:26,030][root][INFO] - Step 86817280 @ 4091.8 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 86817280, mean_episode_return = 41.43, mean_episode_step = 1308.3, total_loss = -171.76, pg_loss = -197.87, baseline_loss = 30.724, entropy_loss = -4.618, learner_queue_size = 32, _tick = 23574, _time = 1.6548e+09, train_seconds = 2.2946e+04)
[2022-06-10 02:30:31,036][root][INFO] - Step 86835200 @ 3579.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 86835200, mean_episode_return = None, mean_episode_step = 985.0, total_loss = -73.928, pg_loss = -87.446, baseline_loss = 18.929, entropy_loss = -5.411, learner_queue_size = 32, _tick = 23579, _time = 1.6548e+09, train_seconds = 2.2951e+04)
[2022-06-10 02:30:36,038][root][INFO] - Step 86855680 @ 4094.4 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 86855680, mean_episode_return = 28.23, mean_episode_step = 1151.8, total_loss = -117.45, pg_loss = -128.53, baseline_loss = 16.638, entropy_loss = -5.5533, learner_queue_size = 32, _tick = 23587, _time = 1.6548e+09, train_seconds = 2.2956e+04)
[2022-06-10 02:30:41,042][root][INFO] - Step 86873600 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 86873600, mean_episode_return = 33.551, mean_episode_step = 1260.7, total_loss = -58.753, pg_loss = -73.406, baseline_loss = 20.266, entropy_loss = -5.6132, learner_queue_size = 32, _tick = 23594, _time = 1.6548e+09, train_seconds = 2.2961e+04)
[2022-06-10 02:30:46,046][root][INFO] - Step 86894080 @ 4092.7 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (step = 86894080, mean_episode_return = 51.04, mean_episode_step = 1043.7, total_loss = 75.811, pg_loss = 42.784, baseline_loss = 38.637, entropy_loss = -5.6111, learner_queue_size = 32, _tick = 23601, _time = 1.6548e+09, train_seconds = 2.2966e+04)
[2022-06-10 02:30:51,050][root][INFO] - Step 86912000 @ 3580.8 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 86912000, mean_episode_return = 8.9197, mean_episode_step = 967.17, total_loss = 48.787, pg_loss = 22.856, baseline_loss = 31.574, entropy_loss = -5.644, learner_queue_size = 32, _tick = 23607, _time = 1.6548e+09, train_seconds = 2.2971e+04)
[2022-06-10 02:30:56,054][root][INFO] - Step 86932480 @ 4093.2 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 86932480, mean_episode_return = 15.02, mean_episode_step = 889.17, total_loss = -58.369, pg_loss = -71.236, baseline_loss = 18.516, entropy_loss = -5.6484, learner_queue_size = 32, _tick = 23614, _time = 1.6548e+09, train_seconds = 2.2976e+04)
[2022-06-10 02:31:01,058][root][INFO] - Step 86950400 @ 3581.1 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 86950400, mean_episode_return = 26.327, mean_episode_step = 1009.6, total_loss = 84.207, pg_loss = 22.591, baseline_loss = 67.205, entropy_loss = -5.5894, learner_queue_size = 32, _tick = 23618, _time = 1.6548e+09, train_seconds = 2.2981e+04)
[2022-06-10 02:31:06,062][root][INFO] - Step 86970880 @ 4092.8 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (step = 86970880, mean_episode_return = 65.825, mean_episode_step = 937.3, total_loss = 504.91, pg_loss = 394.42, baseline_loss = 116.11, entropy_loss = -5.6117, learner_queue_size = 32, _tick = 23622, _time = 1.6548e+09, train_seconds = 2.2986e+04)
[2022-06-10 02:31:11,066][root][INFO] - Step 86991360 @ 4092.7 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (step = 86991360, mean_episode_return = 8.32, mean_episode_step = 985.11, total_loss = -64.302, pg_loss = -91.341, baseline_loss = 32.597, entropy_loss = -5.5576, learner_queue_size = 32, _tick = 23628, _time = 1.6548e+09, train_seconds = 2.2991e+04)
[2022-06-10 02:31:16,070][root][INFO] - Step 87011840 @ 4092.6 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 87011840, mean_episode_return = 20.85, mean_episode_step = 1051.6, total_loss = -52.669, pg_loss = -97.3, baseline_loss = 50.212, entropy_loss = -5.5809, learner_queue_size = 32, _tick = 23633, _time = 1.6548e+09, train_seconds = 2.2996e+04)
[2022-06-10 02:31:21,074][root][INFO] - Step 87029760 @ 3581.2 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 87029760, mean_episode_return = 80.118, mean_episode_step = 1126.3, total_loss = -209.93, pg_loss = -240.77, baseline_loss = 36.376, entropy_loss = -5.5353, learner_queue_size = 32, _tick = 23638, _time = 1.6548e+09, train_seconds = 2.3001e+04)
[2022-06-10 02:31:26,078][root][INFO] - Step 87047680 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 87047680, mean_episode_return = 131.6, mean_episode_step = 893.29, total_loss = -139.29, pg_loss = -157.03, baseline_loss = 23.317, entropy_loss = -5.5753, learner_queue_size = 32, _tick = 23643, _time = 1.6548e+09, train_seconds = 2.3006e+04)
[2022-06-10 02:31:31,082][root][INFO] - Step 87068160 @ 4092.7 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 87068160, mean_episode_return = 61.47, mean_episode_step = 1148.2, total_loss = 136.95, pg_loss = 84.272, baseline_loss = 58.302, entropy_loss = -5.6237, learner_queue_size = 32, _tick = 23650, _time = 1.6548e+09, train_seconds = 2.3011e+04)
[2022-06-10 02:31:36,086][root][INFO] - Step 87088640 @ 4092.5 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 87088640, mean_episode_return = 85.39, mean_episode_step = 1042.8, total_loss = -206.94, pg_loss = -240.59, baseline_loss = 39.175, entropy_loss = -5.5205, learner_queue_size = 32, _tick = 23656, _time = 1.6548e+09, train_seconds = 2.3016e+04)
[2022-06-10 02:31:41,090][root][INFO] - Step 87109120 @ 4093.0 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 87109120, mean_episode_return = 62.395, mean_episode_step = 1186.5, total_loss = -188.31, pg_loss = -196.14, baseline_loss = 13.372, entropy_loss = -5.5368, learner_queue_size = 32, _tick = 23663, _time = 1.6548e+09, train_seconds = 2.3021e+04)
[2022-06-10 02:31:46,094][root][INFO] - Step 87129600 @ 4092.7 SPS. Inference batcher size: 77. Learner queue size: 32. Other stats: (step = 87129600, mean_episode_return = None, mean_episode_step = 1279.6, total_loss = 238.11, pg_loss = 178.74, baseline_loss = 64.865, entropy_loss = -5.4985, learner_queue_size = 32, _tick = 23668, _time = 1.6548e+09, train_seconds = 2.3026e+04)
[2022-06-10 02:31:51,098][root][INFO] - Step 87147520 @ 3581.1 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 87147520, mean_episode_return = 81.771, mean_episode_step = 1348.5, total_loss = 21.561, pg_loss = -19.189, baseline_loss = 46.259, entropy_loss = -5.5092, learner_queue_size = 32, _tick = 23672, _time = 1.6548e+09, train_seconds = 2.3031e+04)
[2022-06-10 02:31:56,104][root][INFO] - Step 87168000 @ 4090.8 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 87168000, mean_episode_return = 54.78, mean_episode_step = 936.97, total_loss = 54.384, pg_loss = -0.50868, baseline_loss = 60.399, entropy_loss = -5.5067, learner_queue_size = 32, _tick = 23679, _time = 1.6548e+09, train_seconds = 2.3036e+04)
[2022-06-10 02:32:01,111][root][INFO] - Step 87188480 @ 4090.8 SPS. Inference batcher size: 79. Learner queue size: 32. Other stats: (step = 87188480, mean_episode_return = 149.96, mean_episode_step = 872.22, total_loss = -46.732, pg_loss = -58.32, baseline_loss = 17.074, entropy_loss = -5.4867, learner_queue_size = 32, _tick = 23687, _time = 1.6548e+09, train_seconds = 2.3041e+04)
[2022-06-10 02:32:06,114][root][INFO] - Step 87206400 @ 3581.6 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 87206400, mean_episode_return = 59.354, mean_episode_step = 889.21, total_loss = -3.7643, pg_loss = -31.666, baseline_loss = 33.113, entropy_loss = -5.2115, learner_queue_size = 32, _tick = 23693, _time = 1.6548e+09, train_seconds = 2.3046e+04)
[2022-06-10 02:32:11,118][root][INFO] - Step 87226880 @ 4092.8 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 87226880, mean_episode_return = 40.337, mean_episode_step = 849.44, total_loss = -163.23, pg_loss = -186.67, baseline_loss = 28.97, entropy_loss = -5.5315, learner_queue_size = 32, _tick = 23699, _time = 1.6548e+09, train_seconds = 2.3051e+04)
[2022-06-10 02:32:16,130][root][INFO] - Step 87244800 @ 3575.4 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 87244800, mean_episode_return = -1.3, mean_episode_step = 970.78, total_loss = -23.593, pg_loss = -74.969, baseline_loss = 56.871, entropy_loss = -5.4961, learner_queue_size = 32, _tick = 23704, _time = 1.6548e+09, train_seconds = 2.3056e+04)
[2022-06-10 02:32:21,134][root][INFO] - Step 87265280 @ 4092.8 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 87265280, mean_episode_return = 72.405, mean_episode_step = 853.84, total_loss = 28.946, pg_loss = -7.833, baseline_loss = 42.2, entropy_loss = -5.4212, learner_queue_size = 32, _tick = 23711, _time = 1.6548e+09, train_seconds = 2.3061e+04)
[2022-06-10 02:32:26,138][root][INFO] - Step 87283200 @ 3581.1 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 87283200, mean_episode_return = 22.54, mean_episode_step = 1178.3, total_loss = 615.95, pg_loss = 413.23, baseline_loss = 208.17, entropy_loss = -5.4415, learner_queue_size = 32, _tick = 23716, _time = 1.6548e+09, train_seconds = 2.3066e+04)
[2022-06-10 02:32:31,142][root][INFO] - Step 87303680 @ 4092.7 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 87303680, mean_episode_return = 68.86, mean_episode_step = 818.58, total_loss = -52.341, pg_loss = -81.643, baseline_loss = 34.332, entropy_loss = -5.0304, learner_queue_size = 32, _tick = 23721, _time = 1.6548e+09, train_seconds = 2.3071e+04)
[2022-06-10 02:32:36,146][root][INFO] - Step 87324160 @ 4092.8 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 87324160, mean_episode_return = 46.529, mean_episode_step = 1143.3, total_loss = 49.181, pg_loss = 7.9818, baseline_loss = 46.352, entropy_loss = -5.153, learner_queue_size = 32, _tick = 23727, _time = 1.6548e+09, train_seconds = 2.3076e+04)
[2022-06-10 02:32:41,150][root][INFO] - Step 87344640 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 87344640, mean_episode_return = 27.115, mean_episode_step = 999.3, total_loss = -96.929, pg_loss = -122.02, baseline_loss = 30.466, entropy_loss = -5.3789, learner_queue_size = 32, _tick = 23734, _time = 1.6548e+09, train_seconds = 2.3081e+04)
[2022-06-10 02:32:46,154][root][INFO] - Step 87365120 @ 4092.7 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 87365120, mean_episode_return = 60.76, mean_episode_step = 1181.8, total_loss = 172.35, pg_loss = 121.78, baseline_loss = 55.993, entropy_loss = -5.4249, learner_queue_size = 32, _tick = 23739, _time = 1.6548e+09, train_seconds = 2.3086e+04)
[2022-06-10 02:32:51,160][root][INFO] - Step 87383040 @ 3579.7 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 87383040, mean_episode_return = 60.955, mean_episode_step = 998.35, total_loss = -187.49, pg_loss = -245.39, baseline_loss = 63.222, entropy_loss = -5.3288, learner_queue_size = 32, _tick = 23745, _time = 1.6548e+09, train_seconds = 2.3091e+04)
[2022-06-10 02:32:56,166][root][INFO] - Step 87403520 @ 4091.0 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 87403520, mean_episode_return = None, mean_episode_step = 838.16, total_loss = -146.7, pg_loss = -161.15, baseline_loss = 19.893, entropy_loss = -5.4464, learner_queue_size = 32, _tick = 23750, _time = 1.6548e+09, train_seconds = 2.3096e+04)
[2022-06-10 02:33:01,170][root][INFO] - Step 87421440 @ 3581.2 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 87421440, mean_episode_return = 91.879, mean_episode_step = 951.66, total_loss = -19.777, pg_loss = -64.05, baseline_loss = 49.718, entropy_loss = -5.445, learner_queue_size = 32, _tick = 23755, _time = 1.6548e+09, train_seconds = 2.3101e+04)
[2022-06-10 02:33:06,174][root][INFO] - Step 87441920 @ 4092.7 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 87441920, mean_episode_return = 26.29, mean_episode_step = 1034.0, total_loss = 363.31, pg_loss = 270.11, baseline_loss = 98.594, entropy_loss = -5.3906, learner_queue_size = 32, _tick = 23760, _time = 1.6548e+09, train_seconds = 2.3106e+04)
[2022-06-10 02:33:11,178][root][INFO] - Step 87462400 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 87462400, mean_episode_return = None, mean_episode_step = 1086.0, total_loss = -88.656, pg_loss = -105.3, baseline_loss = 22.148, entropy_loss = -5.507, learner_queue_size = 32, _tick = 23767, _time = 1.6548e+09, train_seconds = 2.3111e+04)
[2022-06-10 02:33:16,182][root][INFO] - Step 87480320 @ 3581.1 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (step = 87480320, mean_episode_return = 94.59, mean_episode_step = 1143.7, total_loss = -122.35, pg_loss = -160.83, baseline_loss = 43.943, entropy_loss = -5.4629, learner_queue_size = 32, _tick = 23773, _time = 1.6548e+09, train_seconds = 2.3116e+04)
[2022-06-10 02:33:21,186][root][INFO] - Step 87500800 @ 4092.5 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (step = 87500800, mean_episode_return = 74.049, mean_episode_step = 891.85, total_loss = 68.968, pg_loss = 12.891, baseline_loss = 61.5, entropy_loss = -5.4228, learner_queue_size = 32, _tick = 23780, _time = 1.6548e+09, train_seconds = 2.3121e+04)
[2022-06-10 02:33:26,190][root][INFO] - Step 87518720 @ 3581.2 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 87518720, mean_episode_return = 123.74, mean_episode_step = 907.53, total_loss = 58.116, pg_loss = 24.187, baseline_loss = 39.457, entropy_loss = -5.5274, learner_queue_size = 32, _tick = 23786, _time = 1.6548e+09, train_seconds = 2.3126e+04)
[2022-06-10 02:33:31,194][root][INFO] - Step 87539200 @ 4092.8 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 87539200, mean_episode_return = 92.109, mean_episode_step = 1257.8, total_loss = 438.27, pg_loss = 356.13, baseline_loss = 87.777, entropy_loss = -5.6365, learner_queue_size = 32, _tick = 23793, _time = 1.6548e+09, train_seconds = 2.3131e+04)
[2022-06-10 02:33:36,198][root][INFO] - Step 87559680 @ 4092.7 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 87559680, mean_episode_return = None, mean_episode_step = 1005.8, total_loss = 266.75, pg_loss = 227.03, baseline_loss = 45.2, entropy_loss = -5.4842, learner_queue_size = 32, _tick = 23798, _time = 1.6548e+09, train_seconds = 2.3136e+04)
[2022-06-10 02:33:41,205][root][INFO] - Step 87577600 @ 3578.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 87577600, mean_episode_return = None, mean_episode_step = 965.19, total_loss = 15.9, pg_loss = -20.203, baseline_loss = 41.614, entropy_loss = -5.511, learner_queue_size = 32, _tick = 23803, _time = 1.6548e+09, train_seconds = 2.3141e+04)
[2022-06-10 02:33:46,210][root][INFO] - Step 87598080 @ 4092.2 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 87598080, mean_episode_return = 126.16, mean_episode_step = 1122.6, total_loss = 115.58, pg_loss = 63.363, baseline_loss = 57.6, entropy_loss = -5.3799, learner_queue_size = 32, _tick = 23809, _time = 1.6548e+09, train_seconds = 2.3146e+04)
[2022-06-10 02:33:51,215][root][INFO] - Step 87616000 @ 3580.2 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 87616000, mean_episode_return = 35.975, mean_episode_step = 932.08, total_loss = 153.62, pg_loss = 63.835, baseline_loss = 95.155, entropy_loss = -5.3737, learner_queue_size = 32, _tick = 23816, _time = 1.6548e+09, train_seconds = 2.3151e+04)
[2022-06-10 02:33:56,218][root][INFO] - Step 87636480 @ 4093.8 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 87636480, mean_episode_return = None, mean_episode_step = 851.53, total_loss = -51.244, pg_loss = -69.547, baseline_loss = 23.736, entropy_loss = -5.4323, learner_queue_size = 32, _tick = 23823, _time = 1.6548e+09, train_seconds = 2.3156e+04)
[2022-06-10 02:34:01,222][root][INFO] - Step 87656960 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 87656960, mean_episode_return = 66.244, mean_episode_step = 1093.9, total_loss = 131.81, pg_loss = 97.672, baseline_loss = 39.733, entropy_loss = -5.5935, learner_queue_size = 32, _tick = 23829, _time = 1.6548e+09, train_seconds = 2.3161e+04)
[2022-06-10 02:34:06,228][root][INFO] - Step 87677440 @ 4091.3 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 87677440, mean_episode_return = 62.409, mean_episode_step = 1067.0, total_loss = 59.843, pg_loss = 36.21, baseline_loss = 29.208, entropy_loss = -5.5742, learner_queue_size = 32, _tick = 23836, _time = 1.6548e+09, train_seconds = 2.3166e+04)
[2022-06-10 02:34:11,234][root][INFO] - Step 87695360 @ 3579.4 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 87695360, mean_episode_return = 114.3, mean_episode_step = 956.89, total_loss = -258.86, pg_loss = -303.37, baseline_loss = 50.128, entropy_loss = -5.6173, learner_queue_size = 32, _tick = 23843, _time = 1.6548e+09, train_seconds = 2.3171e+04)
[2022-06-10 02:34:16,238][root][INFO] - Step 87715840 @ 4092.8 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 87715840, mean_episode_return = 105.46, mean_episode_step = 914.96, total_loss = -163.61, pg_loss = -180.57, baseline_loss = 22.561, entropy_loss = -5.5971, learner_queue_size = 32, _tick = 23850, _time = 1.6548e+09, train_seconds = 2.3176e+04)
[2022-06-10 02:34:21,242][root][INFO] - Step 87733760 @ 3581.1 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 87733760, mean_episode_return = 66.998, mean_episode_step = 723.14, total_loss = -198.89, pg_loss = -205.81, baseline_loss = 12.56, entropy_loss = -5.642, learner_queue_size = 32, _tick = 23857, _time = 1.6548e+09, train_seconds = 2.3181e+04)
[2022-06-10 02:34:26,246][root][INFO] - Step 87754240 @ 4092.8 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 87754240, mean_episode_return = 87.655, mean_episode_step = 939.31, total_loss = 57.133, pg_loss = 30.002, baseline_loss = 32.769, entropy_loss = -5.6386, learner_queue_size = 32, _tick = 23864, _time = 1.6548e+09, train_seconds = 2.3186e+04)
[2022-06-10 02:34:31,252][root][INFO] - Step 87772160 @ 3579.6 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 87772160, mean_episode_return = None, mean_episode_step = 895.56, total_loss = -23.374, pg_loss = -50.842, baseline_loss = 33.128, entropy_loss = -5.6596, learner_queue_size = 32, _tick = 23866, _time = 1.6548e+09, train_seconds = 2.3191e+04)
[2022-06-10 02:34:36,258][root][INFO] - Step 87792640 @ 4091.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 87792640, mean_episode_return = 12.06, mean_episode_step = 964.16, total_loss = -118.97, pg_loss = -138.99, baseline_loss = 25.647, entropy_loss = -5.6181, learner_queue_size = 32, _tick = 23870, _time = 1.6548e+09, train_seconds = 2.3196e+04)
[2022-06-10 02:34:41,262][root][INFO] - Step 87813120 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 87813120, mean_episode_return = 55.879, mean_episode_step = 825.02, total_loss = -225.3, pg_loss = -245.2, baseline_loss = 25.57, entropy_loss = -5.6622, learner_queue_size = 32, _tick = 23877, _time = 1.6548e+09, train_seconds = 2.3201e+04)
[2022-06-10 02:34:46,266][root][INFO] - Step 87831040 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 87831040, mean_episode_return = -2.91, mean_episode_step = 827.37, total_loss = 253.84, pg_loss = 192.06, baseline_loss = 67.462, entropy_loss = -5.6804, learner_queue_size = 32, _tick = 23883, _time = 1.6548e+09, train_seconds = 2.3206e+04)
[2022-06-10 02:34:51,270][root][INFO] - Step 87851520 @ 4092.5 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 87851520, mean_episode_return = 29.59, mean_episode_step = 1102.9, total_loss = 43.461, pg_loss = 14.085, baseline_loss = 35.05, entropy_loss = -5.6732, learner_queue_size = 32, _tick = 23889, _time = 1.6548e+09, train_seconds = 2.3211e+04)
[2022-06-10 02:34:56,274][root][INFO] - Step 87872000 @ 4093.0 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 87872000, mean_episode_return = 46.768, mean_episode_step = 826.3, total_loss = 41.079, pg_loss = -31.68, baseline_loss = 78.359, entropy_loss = -5.6007, learner_queue_size = 32, _tick = 23895, _time = 1.6548e+09, train_seconds = 2.3216e+04)
[2022-06-10 02:35:01,278][root][INFO] - Step 87889920 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 87889920, mean_episode_return = 78.305, mean_episode_step = 934.99, total_loss = -67.288, pg_loss = -82.927, baseline_loss = 21.284, entropy_loss = -5.6447, learner_queue_size = 32, _tick = 23902, _time = 1.6548e+09, train_seconds = 2.3221e+04)
[2022-06-10 02:35:06,284][root][INFO] - Step 87910400 @ 4091.1 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 87910400, mean_episode_return = 76.61, mean_episode_step = 664.32, total_loss = 205.46, pg_loss = 140.24, baseline_loss = 70.826, entropy_loss = -5.6076, learner_queue_size = 32, _tick = 23909, _time = 1.6548e+09, train_seconds = 2.3226e+04)
[2022-06-10 02:35:11,290][root][INFO] - Step 87930880 @ 4091.1 SPS. Inference batcher size: 91. Learner queue size: 32. Other stats: (step = 87930880, mean_episode_return = None, mean_episode_step = 882.44, total_loss = -26.513, pg_loss = -53.593, baseline_loss = 32.729, entropy_loss = -5.6484, learner_queue_size = 32, _tick = 23915, _time = 1.6548e+09, train_seconds = 2.3231e+04)
[2022-06-10 02:35:16,294][root][INFO] - Step 87948800 @ 3581.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 87948800, mean_episode_return = 53.438, mean_episode_step = 918.93, total_loss = 253.57, pg_loss = 186.54, baseline_loss = 72.641, entropy_loss = -5.6129, learner_queue_size = 32, _tick = 23920, _time = 1.6548e+09, train_seconds = 2.3236e+04)
[2022-06-10 02:35:21,298][root][INFO] - Step 87969280 @ 4092.7 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 87969280, mean_episode_return = None, mean_episode_step = 1048.0, total_loss = 64.212, pg_loss = 22.055, baseline_loss = 47.797, entropy_loss = -5.6394, learner_queue_size = 32, _tick = 23926, _time = 1.6548e+09, train_seconds = 2.3241e+04)
[2022-06-10 02:35:26,302][root][INFO] - Step 87989760 @ 4092.7 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 87989760, mean_episode_return = None, mean_episode_step = 1023.2, total_loss = -21.086, pg_loss = -40.007, baseline_loss = 24.544, entropy_loss = -5.6243, learner_queue_size = 32, _tick = 23931, _time = 1.6548e+09, train_seconds = 2.3246e+04)
[2022-06-10 02:35:31,306][root][INFO] - Step 88010240 @ 4092.8 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 88010240, mean_episode_return = 23.16, mean_episode_step = 902.78, total_loss = -7.1145, pg_loss = -69.535, baseline_loss = 68.037, entropy_loss = -5.6167, learner_queue_size = 32, _tick = 23935, _time = 1.6548e+09, train_seconds = 2.3251e+04)
[2022-06-10 02:35:36,310][root][INFO] - Step 88028160 @ 3581.2 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (step = 88028160, mean_episode_return = 43.906, mean_episode_step = 1158.6, total_loss = 142.9, pg_loss = 64.009, baseline_loss = 84.555, entropy_loss = -5.6623, learner_queue_size = 32, _tick = 23941, _time = 1.6548e+09, train_seconds = 2.3256e+04)
[2022-06-10 02:35:41,314][root][INFO] - Step 88048640 @ 4092.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 88048640, mean_episode_return = 71.905, mean_episode_step = 1083.5, total_loss = 123.17, pg_loss = -0.089993, baseline_loss = 128.82, entropy_loss = -5.5549, learner_queue_size = 32, _tick = 23946, _time = 1.6548e+09, train_seconds = 2.3261e+04)
[2022-06-10 02:35:46,318][root][INFO] - Step 88066560 @ 3581.3 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 88066560, mean_episode_return = 47.54, mean_episode_step = 1187.9, total_loss = 275.44, pg_loss = 182.1, baseline_loss = 98.902, entropy_loss = -5.5534, learner_queue_size = 32, _tick = 23951, _time = 1.6548e+09, train_seconds = 2.3266e+04)
[2022-06-10 02:35:51,322][root][INFO] - Step 88087040 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 88087040, mean_episode_return = 65.92, mean_episode_step = 1189.9, total_loss = -25.717, pg_loss = -70.092, baseline_loss = 49.923, entropy_loss = -5.5483, learner_queue_size = 32, _tick = 23956, _time = 1.6548e+09, train_seconds = 2.3271e+04)
[2022-06-10 02:35:56,326][root][INFO] - Step 88104960 @ 3581.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 88104960, mean_episode_return = 130.12, mean_episode_step = 1086.4, total_loss = -132.11, pg_loss = -153.03, baseline_loss = 26.405, entropy_loss = -5.4819, learner_queue_size = 32, _tick = 23961, _time = 1.6548e+09, train_seconds = 2.3276e+04)
[2022-06-10 02:36:01,330][root][INFO] - Step 88125440 @ 4092.6 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 88125440, mean_episode_return = 301.0, mean_episode_step = 1065.6, total_loss = 54.656, pg_loss = -11.565, baseline_loss = 71.733, entropy_loss = -5.5119, learner_queue_size = 32, _tick = 23969, _time = 1.6548e+09, train_seconds = 2.3281e+04)
[2022-06-10 02:36:06,334][root][INFO] - Step 88143360 @ 3581.3 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 88143360, mean_episode_return = None, mean_episode_step = 1200.8, total_loss = 110.48, pg_loss = 67.885, baseline_loss = 48.2, entropy_loss = -5.6099, learner_queue_size = 32, _tick = 23974, _time = 1.6548e+09, train_seconds = 2.3286e+04)
[2022-06-10 02:36:11,338][root][INFO] - Step 88163840 @ 4092.8 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 88163840, mean_episode_return = 111.73, mean_episode_step = 1263.6, total_loss = 186.13, pg_loss = 136.89, baseline_loss = 54.818, entropy_loss = -5.5762, learner_queue_size = 32, _tick = 23982, _time = 1.6548e+09, train_seconds = 2.3291e+04)
[2022-06-10 02:36:16,342][root][INFO] - Step 88184320 @ 4092.6 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (step = 88184320, mean_episode_return = 92.755, mean_episode_step = 1132.7, total_loss = 286.67, pg_loss = 200.45, baseline_loss = 91.822, entropy_loss = -5.6027, learner_queue_size = 32, _tick = 23989, _time = 1.6548e+09, train_seconds = 2.3296e+04)
[2022-06-10 02:36:21,346][root][INFO] - Step 88202240 @ 3581.2 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 88202240, mean_episode_return = None, mean_episode_step = 1008.5, total_loss = 86.605, pg_loss = 36.159, baseline_loss = 55.899, entropy_loss = -5.4532, learner_queue_size = 32, _tick = 23995, _time = 1.6548e+09, train_seconds = 2.3301e+04)
[2022-06-10 02:36:26,352][root][INFO] - Step 88222720 @ 4091.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 88222720, mean_episode_return = 52.88, mean_episode_step = 889.56, total_loss = 54.952, pg_loss = 10.037, baseline_loss = 50.28, entropy_loss = -5.3647, learner_queue_size = 32, _tick = 24003, _time = 1.6548e+09, train_seconds = 2.3306e+04)
[2022-06-10 02:36:31,358][root][INFO] - Step 88240640 @ 3579.8 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 88240640, mean_episode_return = 20.847, mean_episode_step = 995.61, total_loss = 37.565, pg_loss = 6.9139, baseline_loss = 36.108, entropy_loss = -5.4568, learner_queue_size = 32, _tick = 24009, _time = 1.6548e+09, train_seconds = 2.3311e+04)
[2022-06-10 02:36:36,362][root][INFO] - Step 88261120 @ 4092.6 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 88261120, mean_episode_return = None, mean_episode_step = 825.34, total_loss = 18.031, pg_loss = -14.741, baseline_loss = 38.228, entropy_loss = -5.4563, learner_queue_size = 32, _tick = 24015, _time = 1.6548e+09, train_seconds = 2.3316e+04)
[2022-06-10 02:36:41,366][root][INFO] - Step 88281600 @ 4092.8 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 88281600, mean_episode_return = 36.71, mean_episode_step = 900.74, total_loss = 236.3, pg_loss = 141.03, baseline_loss = 100.57, entropy_loss = -5.3035, learner_queue_size = 32, _tick = 24022, _time = 1.6548e+09, train_seconds = 2.3321e+04)
[2022-06-10 02:36:46,370][root][INFO] - Step 88299520 @ 3580.9 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 88299520, mean_episode_return = 50.369, mean_episode_step = 885.94, total_loss = 54.645, pg_loss = 15.639, baseline_loss = 44.521, entropy_loss = -5.5149, learner_queue_size = 32, _tick = 24029, _time = 1.6548e+09, train_seconds = 2.3326e+04)
[2022-06-10 02:36:51,374][root][INFO] - Step 88320000 @ 4093.0 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 88320000, mean_episode_return = 28.355, mean_episode_step = 750.67, total_loss = -176.79, pg_loss = -214.55, baseline_loss = 43.229, entropy_loss = -5.47, learner_queue_size = 32, _tick = 24036, _time = 1.6548e+09, train_seconds = 2.3331e+04)
[2022-06-10 02:36:56,378][root][INFO] - Step 88340480 @ 4092.7 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 88340480, mean_episode_return = 54.351, mean_episode_step = 898.88, total_loss = -20.707, pg_loss = -63.778, baseline_loss = 48.557, entropy_loss = -5.4859, learner_queue_size = 32, _tick = 24043, _time = 1.6548e+09, train_seconds = 2.3336e+04)
[2022-06-10 02:37:01,382][root][INFO] - Step 88358400 @ 3581.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 88358400, mean_episode_return = None, mean_episode_step = 1018.1, total_loss = -14.23, pg_loss = -37.573, baseline_loss = 28.9, entropy_loss = -5.5566, learner_queue_size = 32, _tick = 24048, _time = 1.6548e+09, train_seconds = 2.3341e+04)
[2022-06-10 02:37:06,389][root][INFO] - Step 88378880 @ 4090.0 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 88378880, mean_episode_return = None, mean_episode_step = 882.75, total_loss = 107.17, pg_loss = 29.706, baseline_loss = 82.988, entropy_loss = -5.5285, learner_queue_size = 32, _tick = 24052, _time = 1.6548e+09, train_seconds = 2.3346e+04)
[2022-06-10 02:37:11,394][root][INFO] - Step 88399360 @ 4092.2 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 88399360, mean_episode_return = None, mean_episode_step = 1072.9, total_loss = 256.73, pg_loss = 184.55, baseline_loss = 77.785, entropy_loss = -5.602, learner_queue_size = 32, _tick = 24057, _time = 1.6548e+09, train_seconds = 2.3351e+04)
[2022-06-10 02:37:16,398][root][INFO] - Step 88417280 @ 3581.1 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 88417280, mean_episode_return = 74.85, mean_episode_step = 747.38, total_loss = 506.07, pg_loss = 356.08, baseline_loss = 155.47, entropy_loss = -5.4864, learner_queue_size = 32, _tick = 24061, _time = 1.6548e+09, train_seconds = 2.3356e+04)
[2022-06-10 02:37:21,402][root][INFO] - Step 88437760 @ 4092.7 SPS. Inference batcher size: 75. Learner queue size: 32. Other stats: (step = 88437760, mean_episode_return = 71.755, mean_episode_step = 908.42, total_loss = 182.98, pg_loss = 103.43, baseline_loss = 85.1, entropy_loss = -5.554, learner_queue_size = 32, _tick = 24069, _time = 1.6548e+09, train_seconds = 2.3361e+04)
[2022-06-10 02:37:26,406][root][INFO] - Step 88455680 @ 3581.1 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 88455680, mean_episode_return = 24.76, mean_episode_step = 999.08, total_loss = 137.85, pg_loss = 70.531, baseline_loss = 72.766, entropy_loss = -5.4468, learner_queue_size = 32, _tick = 24076, _time = 1.6548e+09, train_seconds = 2.3366e+04)
[2022-06-10 02:37:31,410][root][INFO] - Step 88476160 @ 4092.7 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 88476160, mean_episode_return = 43.435, mean_episode_step = 946.37, total_loss = 147.24, pg_loss = 67.749, baseline_loss = 85.084, entropy_loss = -5.5908, learner_queue_size = 32, _tick = 24084, _time = 1.6548e+09, train_seconds = 2.3371e+04)
[2022-06-10 02:37:36,414][root][INFO] - Step 88496640 @ 4092.8 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 88496640, mean_episode_return = 50.842, mean_episode_step = 823.9, total_loss = 283.62, pg_loss = 212.01, baseline_loss = 77.208, entropy_loss = -5.5989, learner_queue_size = 32, _tick = 24091, _time = 1.6548e+09, train_seconds = 2.3376e+04)
[2022-06-10 02:37:41,418][root][INFO] - Step 88517120 @ 4092.7 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 88517120, mean_episode_return = None, mean_episode_step = 1020.3, total_loss = 228.07, pg_loss = 179.92, baseline_loss = 53.617, entropy_loss = -5.4708, learner_queue_size = 32, _tick = 24098, _time = 1.6548e+09, train_seconds = 2.3381e+04)
[2022-06-10 02:37:46,422][root][INFO] - Step 88535040 @ 3581.1 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 88535040, mean_episode_return = 42.71, mean_episode_step = 1075.8, total_loss = -252.7, pg_loss = -286.26, baseline_loss = 39.028, entropy_loss = -5.4686, learner_queue_size = 32, _tick = 24105, _time = 1.6548e+09, train_seconds = 2.3386e+04)
[2022-06-10 02:37:51,426][root][INFO] - Step 88552960 @ 3581.2 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 88552960, mean_episode_return = None, mean_episode_step = 896.72, total_loss = 41.572, pg_loss = -34.022, baseline_loss = 81.142, entropy_loss = -5.5477, learner_queue_size = 32, _tick = 24109, _time = 1.6548e+09, train_seconds = 2.3391e+04)
[2022-06-10 02:37:56,430][root][INFO] - Step 88573440 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 88573440, mean_episode_return = 90.52, mean_episode_step = 927.23, total_loss = 584.61, pg_loss = 414.31, baseline_loss = 175.85, entropy_loss = -5.5411, learner_queue_size = 32, _tick = 24113, _time = 1.6548e+09, train_seconds = 2.3396e+04)
[2022-06-10 02:38:01,434][root][INFO] - Step 88593920 @ 4092.8 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 88593920, mean_episode_return = 60.523, mean_episode_step = 1142.2, total_loss = 184.99, pg_loss = 107.38, baseline_loss = 83.169, entropy_loss = -5.5632, learner_queue_size = 32, _tick = 24119, _time = 1.6548e+09, train_seconds = 2.3401e+04)
[2022-06-10 02:38:06,438][root][INFO] - Step 88611840 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 88611840, mean_episode_return = None, mean_episode_step = 1021.2, total_loss = 54.967, pg_loss = 12.786, baseline_loss = 47.758, entropy_loss = -5.577, learner_queue_size = 32, _tick = 24123, _time = 1.6548e+09, train_seconds = 2.3406e+04)
[2022-06-10 02:38:11,442][root][INFO] - Step 88632320 @ 4092.8 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 88632320, mean_episode_return = 34.91, mean_episode_step = 778.62, total_loss = 268.94, pg_loss = 132.54, baseline_loss = 141.77, entropy_loss = -5.3762, learner_queue_size = 32, _tick = 24130, _time = 1.6548e+09, train_seconds = 2.3411e+04)
[2022-06-10 02:38:16,446][root][INFO] - Step 88652800 @ 4092.6 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 88652800, mean_episode_return = 17.53, mean_episode_step = 836.02, total_loss = -102.33, pg_loss = -168.01, baseline_loss = 71.179, entropy_loss = -5.4956, learner_queue_size = 32, _tick = 24137, _time = 1.6548e+09, train_seconds = 2.3416e+04)
[2022-06-10 02:38:21,450][root][INFO] - Step 88670720 @ 3581.2 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 88670720, mean_episode_return = 43.925, mean_episode_step = 1017.0, total_loss = -243.25, pg_loss = -267.91, baseline_loss = 30.115, entropy_loss = -5.4503, learner_queue_size = 32, _tick = 24142, _time = 1.6548e+09, train_seconds = 2.3421e+04)
[2022-06-10 02:38:26,454][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 02:38:26,620][root][INFO] - Step 88691200 @ 4092.7 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 88691200, mean_episode_return = 73.328, mean_episode_step = 1115.8, total_loss = 166.06, pg_loss = 89.787, baseline_loss = 81.833, entropy_loss = -5.56, learner_queue_size = 32, _tick = 24149, _time = 1.6548e+09, train_seconds = 2.3426e+04)
[2022-06-10 02:38:31,626][root][INFO] - Step 88711680 @ 3959.6 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 88711680, mean_episode_return = None, mean_episode_step = 988.38, total_loss = 306.6, pg_loss = 219.01, baseline_loss = 93.116, entropy_loss = -5.5314, learner_queue_size = 32, _tick = 24155, _time = 1.6548e+09, train_seconds = 2.3431e+04)
[2022-06-10 02:38:36,630][root][INFO] - Step 88729600 @ 3581.3 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 88729600, mean_episode_return = 157.79, mean_episode_step = 1061.6, total_loss = -122.77, pg_loss = -157.15, baseline_loss = 39.903, entropy_loss = -5.5251, learner_queue_size = 32, _tick = 24160, _time = 1.6548e+09, train_seconds = 2.3436e+04)
[2022-06-10 02:38:41,634][root][INFO] - Step 88750080 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 88750080, mean_episode_return = 52.712, mean_episode_step = 953.48, total_loss = -26.944, pg_loss = -41.308, baseline_loss = 19.982, entropy_loss = -5.618, learner_queue_size = 32, _tick = 24166, _time = 1.6548e+09, train_seconds = 2.3441e+04)
[2022-06-10 02:38:46,638][root][INFO] - Step 88768000 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 88768000, mean_episode_return = 85.559, mean_episode_step = 927.47, total_loss = -78.028, pg_loss = -109.24, baseline_loss = 36.799, entropy_loss = -5.5921, learner_queue_size = 32, _tick = 24173, _time = 1.6548e+09, train_seconds = 2.3446e+04)
[2022-06-10 02:38:51,642][root][INFO] - Step 88788480 @ 4092.8 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 88788480, mean_episode_return = 30.23, mean_episode_step = 837.09, total_loss = 148.69, pg_loss = 114.25, baseline_loss = 39.878, entropy_loss = -5.4354, learner_queue_size = 32, _tick = 24181, _time = 1.6548e+09, train_seconds = 2.3451e+04)
[2022-06-10 02:38:56,646][root][INFO] - Step 88808960 @ 4092.7 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 88808960, mean_episode_return = 86.858, mean_episode_step = 992.21, total_loss = -125.14, pg_loss = -150.32, baseline_loss = 30.576, entropy_loss = -5.4022, learner_queue_size = 32, _tick = 24189, _time = 1.6548e+09, train_seconds = 2.3456e+04)
[2022-06-10 02:39:01,650][root][INFO] - Step 88826880 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 88826880, mean_episode_return = 208.14, mean_episode_step = 886.72, total_loss = -88.133, pg_loss = -117.0, baseline_loss = 34.486, entropy_loss = -5.6149, learner_queue_size = 32, _tick = 24195, _time = 1.6548e+09, train_seconds = 2.3462e+04)
[2022-06-10 02:39:06,654][root][INFO] - Step 88847360 @ 4092.8 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 88847360, mean_episode_return = 77.549, mean_episode_step = 956.01, total_loss = 236.45, pg_loss = 175.22, baseline_loss = 66.774, entropy_loss = -5.5451, learner_queue_size = 32, _tick = 24203, _time = 1.6548e+09, train_seconds = 2.3466e+04)
[2022-06-10 02:39:11,658][root][INFO] - Step 88867840 @ 4092.7 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 88867840, mean_episode_return = 53.854, mean_episode_step = 987.06, total_loss = -230.7, pg_loss = -242.69, baseline_loss = 17.519, entropy_loss = -5.5318, learner_queue_size = 32, _tick = 24210, _time = 1.6548e+09, train_seconds = 2.3472e+04)
[2022-06-10 02:39:16,662][root][INFO] - Step 88888320 @ 4092.8 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 88888320, mean_episode_return = 65.73, mean_episode_step = 970.88, total_loss = 246.41, pg_loss = 144.13, baseline_loss = 107.91, entropy_loss = -5.6387, learner_queue_size = 32, _tick = 24217, _time = 1.6548e+09, train_seconds = 2.3476e+04)
[2022-06-10 02:39:21,666][root][INFO] - Step 88906240 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 88906240, mean_episode_return = 6.1099, mean_episode_step = 846.66, total_loss = 186.61, pg_loss = 139.44, baseline_loss = 52.835, entropy_loss = -5.6629, learner_queue_size = 32, _tick = 24224, _time = 1.6548e+09, train_seconds = 2.3482e+04)
[2022-06-10 02:39:26,670][root][INFO] - Step 88926720 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 88926720, mean_episode_return = 144.06, mean_episode_step = 840.5, total_loss = 310.88, pg_loss = 236.9, baseline_loss = 79.639, entropy_loss = -5.6612, learner_queue_size = 32, _tick = 24230, _time = 1.6548e+09, train_seconds = 2.3486e+04)
[2022-06-10 02:39:31,674][root][INFO] - Step 88947200 @ 4092.7 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 88947200, mean_episode_return = 70.59, mean_episode_step = 802.45, total_loss = -242.96, pg_loss = -265.98, baseline_loss = 28.608, entropy_loss = -5.5904, learner_queue_size = 32, _tick = 24237, _time = 1.6548e+09, train_seconds = 2.3492e+04)
[2022-06-10 02:39:36,678][root][INFO] - Step 88965120 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 88965120, mean_episode_return = 52.83, mean_episode_step = 805.08, total_loss = 360.96, pg_loss = 280.18, baseline_loss = 86.421, entropy_loss = -5.6409, learner_queue_size = 32, _tick = 24242, _time = 1.6548e+09, train_seconds = 2.3496e+04)
[2022-06-10 02:39:41,682][root][INFO] - Step 88985600 @ 4092.6 SPS. Inference batcher size: 76. Learner queue size: 32. Other stats: (step = 88985600, mean_episode_return = 137.59, mean_episode_step = 858.05, total_loss = 110.03, pg_loss = 72.027, baseline_loss = 43.642, entropy_loss = -5.6441, learner_queue_size = 32, _tick = 24248, _time = 1.6548e+09, train_seconds = 2.3502e+04)
[2022-06-10 02:39:46,686][root][INFO] - Step 89006080 @ 4092.9 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 89006080, mean_episode_return = 66.1, mean_episode_step = 896.2, total_loss = 67.404, pg_loss = -29.491, baseline_loss = 102.41, entropy_loss = -5.5173, learner_queue_size = 32, _tick = 24255, _time = 1.6548e+09, train_seconds = 2.3506e+04)
[2022-06-10 02:39:51,690][root][INFO] - Step 89024000 @ 3581.1 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 89024000, mean_episode_return = 24.21, mean_episode_step = 729.08, total_loss = -241.06, pg_loss = -302.26, baseline_loss = 66.789, entropy_loss = -5.5822, learner_queue_size = 32, _tick = 24261, _time = 1.6548e+09, train_seconds = 2.3512e+04)
[2022-06-10 02:39:56,694][root][INFO] - Step 89044480 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 89044480, mean_episode_return = 101.5, mean_episode_step = 884.08, total_loss = -69.061, pg_loss = -88.521, baseline_loss = 25.063, entropy_loss = -5.6035, learner_queue_size = 32, _tick = 24268, _time = 1.6548e+09, train_seconds = 2.3516e+04)
[2022-06-10 02:40:01,698][root][INFO] - Step 89064960 @ 4092.8 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 89064960, mean_episode_return = 58.93, mean_episode_step = 1134.2, total_loss = 7.3364, pg_loss = -16.993, baseline_loss = 29.921, entropy_loss = -5.592, learner_queue_size = 32, _tick = 24273, _time = 1.6548e+09, train_seconds = 2.3522e+04)
[2022-06-10 02:40:06,702][root][INFO] - Step 89082880 @ 3581.2 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 89082880, mean_episode_return = 43.8, mean_episode_step = 911.8, total_loss = 306.3, pg_loss = 188.01, baseline_loss = 123.87, entropy_loss = -5.5831, learner_queue_size = 32, _tick = 24278, _time = 1.6548e+09, train_seconds = 2.3526e+04)
[2022-06-10 02:40:11,706][root][INFO] - Step 89103360 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 89103360, mean_episode_return = None, mean_episode_step = 863.09, total_loss = 416.61, pg_loss = 352.93, baseline_loss = 69.32, entropy_loss = -5.6369, learner_queue_size = 32, _tick = 24283, _time = 1.6548e+09, train_seconds = 2.3532e+04)
[2022-06-10 02:40:16,710][root][INFO] - Step 89123840 @ 4092.7 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (step = 89123840, mean_episode_return = 37.745, mean_episode_step = 1104.9, total_loss = 74.96, pg_loss = 27.207, baseline_loss = 53.467, entropy_loss = -5.7142, learner_queue_size = 32, _tick = 24289, _time = 1.6548e+09, train_seconds = 2.3536e+04)
[2022-06-10 02:40:21,714][root][INFO] - Step 89141760 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 89141760, mean_episode_return = 125.97, mean_episode_step = 830.01, total_loss = -123.26, pg_loss = -135.58, baseline_loss = 17.952, entropy_loss = -5.6315, learner_queue_size = 32, _tick = 24295, _time = 1.6548e+09, train_seconds = 2.3542e+04)
[2022-06-10 02:40:26,718][root][INFO] - Step 89162240 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 89162240, mean_episode_return = 106.12, mean_episode_step = 876.43, total_loss = 215.34, pg_loss = 154.73, baseline_loss = 66.249, entropy_loss = -5.646, learner_queue_size = 32, _tick = 24302, _time = 1.6548e+09, train_seconds = 2.3546e+04)
[2022-06-10 02:40:31,722][root][INFO] - Step 89182720 @ 4092.6 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 89182720, mean_episode_return = 23.23, mean_episode_step = 1152.8, total_loss = -67.486, pg_loss = -157.65, baseline_loss = 95.798, entropy_loss = -5.6361, learner_queue_size = 32, _tick = 24309, _time = 1.6548e+09, train_seconds = 2.3552e+04)
[2022-06-10 02:40:36,726][root][INFO] - Step 89200640 @ 3581.2 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 89200640, mean_episode_return = 20.863, mean_episode_step = 1086.8, total_loss = -42.142, pg_loss = -77.876, baseline_loss = 41.325, entropy_loss = -5.5907, learner_queue_size = 32, _tick = 24313, _time = 1.6548e+09, train_seconds = 2.3556e+04)
[2022-06-10 02:40:41,730][root][INFO] - Step 89221120 @ 4092.8 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 89221120, mean_episode_return = 53.922, mean_episode_step = 978.46, total_loss = 315.88, pg_loss = 164.12, baseline_loss = 157.39, entropy_loss = -5.6286, learner_queue_size = 32, _tick = 24320, _time = 1.6548e+09, train_seconds = 2.3562e+04)
[2022-06-10 02:40:46,737][root][INFO] - Step 89241600 @ 4090.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 89241600, mean_episode_return = None, mean_episode_step = 927.06, total_loss = 149.56, pg_loss = 101.38, baseline_loss = 53.745, entropy_loss = -5.5601, learner_queue_size = 32, _tick = 24325, _time = 1.6548e+09, train_seconds = 2.3566e+04)
[2022-06-10 02:40:51,742][root][INFO] - Step 89259520 @ 3580.5 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (step = 89259520, mean_episode_return = 51.41, mean_episode_step = 929.35, total_loss = -50.077, pg_loss = -86.965, baseline_loss = 42.509, entropy_loss = -5.62, learner_queue_size = 32, _tick = 24332, _time = 1.6548e+09, train_seconds = 2.3572e+04)
[2022-06-10 02:40:56,746][root][INFO] - Step 89280000 @ 4092.6 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 89280000, mean_episode_return = 23.444, mean_episode_step = 959.75, total_loss = -83.642, pg_loss = -105.49, baseline_loss = 27.314, entropy_loss = -5.469, learner_queue_size = 32, _tick = 24339, _time = 1.6548e+09, train_seconds = 2.3577e+04)
[2022-06-10 02:41:01,750][root][INFO] - Step 89297920 @ 3581.3 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 89297920, mean_episode_return = None, mean_episode_step = 830.91, total_loss = -101.54, pg_loss = -117.41, baseline_loss = 21.467, entropy_loss = -5.5932, learner_queue_size = 32, _tick = 24344, _time = 1.6548e+09, train_seconds = 2.3582e+04)
[2022-06-10 02:41:06,754][root][INFO] - Step 89318400 @ 4092.6 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 89318400, mean_episode_return = 32.98, mean_episode_step = 863.29, total_loss = -57.544, pg_loss = -74.473, baseline_loss = 22.42, entropy_loss = -5.4911, learner_queue_size = 32, _tick = 24351, _time = 1.6548e+09, train_seconds = 2.3587e+04)
[2022-06-10 02:41:11,758][root][INFO] - Step 89338880 @ 4092.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 89338880, mean_episode_return = None, mean_episode_step = 651.38, total_loss = 50.244, pg_loss = 4.5568, baseline_loss = 51.465, entropy_loss = -5.7781, learner_queue_size = 32, _tick = 24356, _time = 1.6548e+09, train_seconds = 2.3592e+04)
[2022-06-10 02:41:16,762][root][INFO] - Step 89356800 @ 3581.2 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 89356800, mean_episode_return = 63.016, mean_episode_step = 1047.6, total_loss = 132.61, pg_loss = 40.35, baseline_loss = 98.008, entropy_loss = -5.7501, learner_queue_size = 32, _tick = 24363, _time = 1.6548e+09, train_seconds = 2.3597e+04)
[2022-06-10 02:41:21,766][root][INFO] - Step 89377280 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 89377280, mean_episode_return = None, mean_episode_step = 910.69, total_loss = 119.72, pg_loss = 83.316, baseline_loss = 42.038, entropy_loss = -5.6341, learner_queue_size = 32, _tick = 24370, _time = 1.6548e+09, train_seconds = 2.3602e+04)
[2022-06-10 02:41:26,770][root][INFO] - Step 89397760 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 89397760, mean_episode_return = 42.225, mean_episode_step = 892.63, total_loss = 164.3, pg_loss = 75.72, baseline_loss = 94.316, entropy_loss = -5.739, learner_queue_size = 32, _tick = 24378, _time = 1.6548e+09, train_seconds = 2.3607e+04)
[2022-06-10 02:41:31,774][root][INFO] - Step 89415680 @ 3581.1 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 89415680, mean_episode_return = 68.799, mean_episode_step = 873.72, total_loss = 17.005, pg_loss = -16.005, baseline_loss = 38.666, entropy_loss = -5.656, learner_queue_size = 32, _tick = 24384, _time = 1.6548e+09, train_seconds = 2.3612e+04)
[2022-06-10 02:41:36,778][root][INFO] - Step 89436160 @ 4092.8 SPS. Inference batcher size: 77. Learner queue size: 32. Other stats: (step = 89436160, mean_episode_return = None, mean_episode_step = 991.03, total_loss = 210.98, pg_loss = 100.36, baseline_loss = 116.3, entropy_loss = -5.679, learner_queue_size = 32, _tick = 24388, _time = 1.6548e+09, train_seconds = 2.3617e+04)
[2022-06-10 02:41:41,784][root][INFO] - Step 89454080 @ 3579.7 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 89454080, mean_episode_return = 21.04, mean_episode_step = 1128.5, total_loss = 318.61, pg_loss = 243.69, baseline_loss = 80.38, entropy_loss = -5.4568, learner_queue_size = 32, _tick = 24393, _time = 1.6548e+09, train_seconds = 2.3622e+04)
[2022-06-10 02:41:46,790][root][INFO] - Step 89474560 @ 4091.2 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 89474560, mean_episode_return = 59.55, mean_episode_step = 837.13, total_loss = 104.48, pg_loss = 63.923, baseline_loss = 46.282, entropy_loss = -5.7297, learner_queue_size = 32, _tick = 24400, _time = 1.6548e+09, train_seconds = 2.3627e+04)
[2022-06-10 02:41:51,794][root][INFO] - Step 89492480 @ 3581.1 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 89492480, mean_episode_return = 61.74, mean_episode_step = 1026.2, total_loss = -3.0864, pg_loss = -13.528, baseline_loss = 16.2, entropy_loss = -5.7583, learner_queue_size = 32, _tick = 24406, _time = 1.6548e+09, train_seconds = 2.3632e+04)
[2022-06-10 02:41:56,798][root][INFO] - Step 89512960 @ 4092.8 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 89512960, mean_episode_return = None, mean_episode_step = 845.25, total_loss = 270.92, pg_loss = 203.15, baseline_loss = 73.373, entropy_loss = -5.5969, learner_queue_size = 32, _tick = 24413, _time = 1.6548e+09, train_seconds = 2.3637e+04)
[2022-06-10 02:42:01,802][root][INFO] - Step 89533440 @ 4092.6 SPS. Inference batcher size: 88. Learner queue size: 32. Other stats: (step = 89533440, mean_episode_return = None, mean_episode_step = 840.81, total_loss = 248.21, pg_loss = 188.35, baseline_loss = 65.265, entropy_loss = -5.4116, learner_queue_size = 32, _tick = 24420, _time = 1.6548e+09, train_seconds = 2.3642e+04)
[2022-06-10 02:42:06,806][root][INFO] - Step 89551360 @ 3581.2 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 89551360, mean_episode_return = None, mean_episode_step = 905.94, total_loss = -109.21, pg_loss = -134.58, baseline_loss = 30.915, entropy_loss = -5.5459, learner_queue_size = 32, _tick = 24423, _time = 1.6548e+09, train_seconds = 2.3647e+04)
[2022-06-10 02:42:11,810][root][INFO] - Step 89571840 @ 4092.8 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 89571840, mean_episode_return = 141.92, mean_episode_step = 852.11, total_loss = -63.839, pg_loss = -84.482, baseline_loss = 25.983, entropy_loss = -5.3401, learner_queue_size = 32, _tick = 24430, _time = 1.6548e+09, train_seconds = 2.3652e+04)
[2022-06-10 02:42:16,814][root][INFO] - Step 89592320 @ 4092.7 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 89592320, mean_episode_return = None, mean_episode_step = 950.62, total_loss = -53.481, pg_loss = -82.599, baseline_loss = 34.629, entropy_loss = -5.5114, learner_queue_size = 32, _tick = 24437, _time = 1.6548e+09, train_seconds = 2.3657e+04)
[2022-06-10 02:42:21,818][root][INFO] - Step 89610240 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 89610240, mean_episode_return = 69.165, mean_episode_step = 1035.2, total_loss = 23.578, pg_loss = -21.901, baseline_loss = 51.114, entropy_loss = -5.6358, learner_queue_size = 32, _tick = 24442, _time = 1.6548e+09, train_seconds = 2.3662e+04)
[2022-06-10 02:42:26,822][root][INFO] - Step 89630720 @ 4092.8 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 89630720, mean_episode_return = 141.6, mean_episode_step = 861.36, total_loss = 142.8, pg_loss = 88.337, baseline_loss = 60.119, entropy_loss = -5.6595, learner_queue_size = 32, _tick = 24449, _time = 1.6548e+09, train_seconds = 2.3667e+04)
[2022-06-10 02:42:31,828][root][INFO] - Step 89648640 @ 3579.6 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 89648640, mean_episode_return = 85.12, mean_episode_step = 937.23, total_loss = -10.011, pg_loss = -65.979, baseline_loss = 61.624, entropy_loss = -5.6571, learner_queue_size = 32, _tick = 24456, _time = 1.6548e+09, train_seconds = 2.3672e+04)
[2022-06-10 02:42:36,834][root][INFO] - Step 89669120 @ 4091.2 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 89669120, mean_episode_return = None, mean_episode_step = 1012.2, total_loss = 175.12, pg_loss = 137.41, baseline_loss = 43.343, entropy_loss = -5.6297, learner_queue_size = 32, _tick = 24460, _time = 1.6548e+09, train_seconds = 2.3677e+04)
[2022-06-10 02:42:41,838][root][INFO] - Step 89689600 @ 4092.7 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (step = 89689600, mean_episode_return = 52.36, mean_episode_step = 1035.4, total_loss = 112.23, pg_loss = 82.22, baseline_loss = 35.745, entropy_loss = -5.7379, learner_queue_size = 32, _tick = 24467, _time = 1.6548e+09, train_seconds = 2.3682e+04)
[2022-06-10 02:42:46,842][root][INFO] - Step 89707520 @ 3581.2 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 89707520, mean_episode_return = 97.18, mean_episode_step = 941.05, total_loss = 106.01, pg_loss = 49.267, baseline_loss = 62.392, entropy_loss = -5.6445, learner_queue_size = 32, _tick = 24473, _time = 1.6548e+09, train_seconds = 2.3687e+04)
[2022-06-10 02:42:51,846][root][INFO] - Step 89728000 @ 4092.7 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 89728000, mean_episode_return = -1.57, mean_episode_step = 1005.9, total_loss = -70.248, pg_loss = -94.475, baseline_loss = 29.869, entropy_loss = -5.6417, learner_queue_size = 32, _tick = 24480, _time = 1.6548e+09, train_seconds = 2.3692e+04)
[2022-06-10 02:42:56,850][root][INFO] - Step 89748480 @ 4092.6 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (step = 89748480, mean_episode_return = 77.56, mean_episode_step = 1131.0, total_loss = 163.36, pg_loss = 72.457, baseline_loss = 96.438, entropy_loss = -5.5326, learner_queue_size = 32, _tick = 24488, _time = 1.6548e+09, train_seconds = 2.3697e+04)
[2022-06-10 02:43:01,854][root][INFO] - Step 89768960 @ 4092.8 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 89768960, mean_episode_return = None, mean_episode_step = 863.28, total_loss = 70.855, pg_loss = 25.906, baseline_loss = 50.588, entropy_loss = -5.6388, learner_queue_size = 32, _tick = 24493, _time = 1.6548e+09, train_seconds = 2.3702e+04)
[2022-06-10 02:43:06,858][root][INFO] - Step 89786880 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 89786880, mean_episode_return = 42.96, mean_episode_step = 994.62, total_loss = -14.22, pg_loss = -54.669, baseline_loss = 46.081, entropy_loss = -5.6325, learner_queue_size = 32, _tick = 24500, _time = 1.6548e+09, train_seconds = 2.3707e+04)
[2022-06-10 02:43:11,862][root][INFO] - Step 89807360 @ 4092.7 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 89807360, mean_episode_return = 66.62, mean_episode_step = 980.01, total_loss = 84.863, pg_loss = 23.287, baseline_loss = 67.12, entropy_loss = -5.544, learner_queue_size = 32, _tick = 24507, _time = 1.6548e+09, train_seconds = 2.3712e+04)
[2022-06-10 02:43:16,866][root][INFO] - Step 89825280 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 89825280, mean_episode_return = -0.49, mean_episode_step = 1061.7, total_loss = 259.73, pg_loss = 201.38, baseline_loss = 64.009, entropy_loss = -5.6585, learner_queue_size = 32, _tick = 24514, _time = 1.6548e+09, train_seconds = 2.3717e+04)
[2022-06-10 02:43:21,870][root][INFO] - Step 89845760 @ 4092.7 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 89845760, mean_episode_return = 10.98, mean_episode_step = 1047.2, total_loss = 316.1, pg_loss = 238.4, baseline_loss = 83.348, entropy_loss = -5.6527, learner_queue_size = 32, _tick = 24521, _time = 1.6548e+09, train_seconds = 2.3722e+04)
[2022-06-10 02:43:26,874][root][INFO] - Step 89866240 @ 4092.6 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 89866240, mean_episode_return = 15.49, mean_episode_step = 794.81, total_loss = 315.18, pg_loss = 234.53, baseline_loss = 86.215, entropy_loss = -5.5664, learner_queue_size = 32, _tick = 24527, _time = 1.6548e+09, train_seconds = 2.3727e+04)
[2022-06-10 02:43:31,878][root][INFO] - Step 89884160 @ 3581.3 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 89884160, mean_episode_return = 104.54, mean_episode_step = 1074.3, total_loss = -120.48, pg_loss = -162.25, baseline_loss = 47.393, entropy_loss = -5.6204, learner_queue_size = 32, _tick = 24534, _time = 1.6548e+09, train_seconds = 2.3732e+04)
[2022-06-10 02:43:36,882][root][INFO] - Step 89904640 @ 4092.6 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 89904640, mean_episode_return = None, mean_episode_step = 991.28, total_loss = 27.462, pg_loss = -3.191, baseline_loss = 36.181, entropy_loss = -5.528, learner_queue_size = 32, _tick = 24540, _time = 1.6548e+09, train_seconds = 2.3737e+04)
[2022-06-10 02:43:41,886][root][INFO] - Step 89922560 @ 3581.3 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 89922560, mean_episode_return = 126.5, mean_episode_step = 758.91, total_loss = 73.124, pg_loss = 18.23, baseline_loss = 60.338, entropy_loss = -5.4438, learner_queue_size = 32, _tick = 24545, _time = 1.6548e+09, train_seconds = 2.3742e+04)
[2022-06-10 02:43:46,888][root][INFO] - Step 89943040 @ 4094.3 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 89943040, mean_episode_return = 32.51, mean_episode_step = 1100.1, total_loss = -32.488, pg_loss = -81.065, baseline_loss = 54.106, entropy_loss = -5.5285, learner_queue_size = 32, _tick = 24552, _time = 1.6548e+09, train_seconds = 2.3747e+04)
[2022-06-10 02:43:51,890][root][INFO] - Step 89963520 @ 4094.4 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 89963520, mean_episode_return = 77.25, mean_episode_step = 1193.7, total_loss = 63.213, pg_loss = 41.572, baseline_loss = 27.336, entropy_loss = -5.6962, learner_queue_size = 32, _tick = 24558, _time = 1.6548e+09, train_seconds = 2.3752e+04)
[2022-06-10 02:43:56,894][root][INFO] - Step 89981440 @ 3581.2 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 89981440, mean_episode_return = 59.821, mean_episode_step = 1013.7, total_loss = 519.49, pg_loss = 405.72, baseline_loss = 119.38, entropy_loss = -5.6112, learner_queue_size = 32, _tick = 24564, _time = 1.6548e+09, train_seconds = 2.3757e+04)
[2022-06-10 02:44:01,898][root][INFO] - Step 90001920 @ 4092.7 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 90001920, mean_episode_return = 11.67, mean_episode_step = 883.72, total_loss = -15.916, pg_loss = -51.489, baseline_loss = 41.259, entropy_loss = -5.6855, learner_queue_size = 32, _tick = 24572, _time = 1.6548e+09, train_seconds = 2.3762e+04)
[2022-06-10 02:44:06,902][root][INFO] - Step 90022400 @ 4092.8 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 90022400, mean_episode_return = None, mean_episode_step = 982.84, total_loss = 869.55, pg_loss = 650.3, baseline_loss = 224.94, entropy_loss = -5.6958, learner_queue_size = 32, _tick = 24578, _time = 1.6548e+09, train_seconds = 2.3767e+04)
[2022-06-10 02:44:11,906][root][INFO] - Step 90042880 @ 4092.6 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 90042880, mean_episode_return = 23.93, mean_episode_step = 1345.2, total_loss = 13.663, pg_loss = -18.36, baseline_loss = 37.652, entropy_loss = -5.6293, learner_queue_size = 32, _tick = 24583, _time = 1.6548e+09, train_seconds = 2.3772e+04)
[2022-06-10 02:44:16,912][root][INFO] - Step 90060800 @ 3579.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 90060800, mean_episode_return = 55.771, mean_episode_step = 1080.8, total_loss = -128.14, pg_loss = -151.94, baseline_loss = 29.502, entropy_loss = -5.7017, learner_queue_size = 32, _tick = 24586, _time = 1.6548e+09, train_seconds = 2.3777e+04)
[2022-06-10 02:44:21,918][root][INFO] - Step 90078720 @ 3579.8 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 90078720, mean_episode_return = 104.73, mean_episode_step = 1074.3, total_loss = 51.814, pg_loss = -5.533, baseline_loss = 62.985, entropy_loss = -5.6387, learner_queue_size = 32, _tick = 24593, _time = 1.6548e+09, train_seconds = 2.3782e+04)
[2022-06-10 02:44:26,922][root][INFO] - Step 90099200 @ 4092.8 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 90099200, mean_episode_return = 36.121, mean_episode_step = 1346.1, total_loss = -108.16, pg_loss = -129.26, baseline_loss = 26.73, entropy_loss = -5.6326, learner_queue_size = 32, _tick = 24599, _time = 1.6548e+09, train_seconds = 2.3787e+04)
[2022-06-10 02:44:31,926][root][INFO] - Step 90119680 @ 4092.7 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 90119680, mean_episode_return = -11.171, mean_episode_step = 1123.4, total_loss = -52.075, pg_loss = -68.505, baseline_loss = 22.085, entropy_loss = -5.6555, learner_queue_size = 32, _tick = 24607, _time = 1.6548e+09, train_seconds = 2.3792e+04)
[2022-06-10 02:44:36,932][root][INFO] - Step 90140160 @ 4091.0 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 90140160, mean_episode_return = 120.87, mean_episode_step = 1273.9, total_loss = 320.84, pg_loss = 263.04, baseline_loss = 63.375, entropy_loss = -5.5762, learner_queue_size = 32, _tick = 24613, _time = 1.6548e+09, train_seconds = 2.3797e+04)
[2022-06-10 02:44:41,940][root][INFO] - Step 90160640 @ 4091.2 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 90160640, mean_episode_return = 61.143, mean_episode_step = 932.81, total_loss = -121.77, pg_loss = -149.59, baseline_loss = 33.43, entropy_loss = -5.6181, learner_queue_size = 32, _tick = 24619, _time = 1.6548e+09, train_seconds = 2.3802e+04)
[2022-06-10 02:44:46,943][root][INFO] - Step 90178560 @ 3580.8 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 90178560, mean_episode_return = 66.78, mean_episode_step = 1143.3, total_loss = 47.52, pg_loss = -16.39, baseline_loss = 69.526, entropy_loss = -5.6159, learner_queue_size = 32, _tick = 24624, _time = 1.6548e+09, train_seconds = 2.3807e+04)
[2022-06-10 02:44:51,946][root][INFO] - Step 90199040 @ 4092.9 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 90199040, mean_episode_return = 44.922, mean_episode_step = 902.4, total_loss = -321.46, pg_loss = -385.21, baseline_loss = 69.271, entropy_loss = -5.5251, learner_queue_size = 32, _tick = 24631, _time = 1.6548e+09, train_seconds = 2.3812e+04)
[2022-06-10 02:44:56,950][root][INFO] - Step 90219520 @ 4092.8 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (step = 90219520, mean_episode_return = 64.339, mean_episode_step = 878.85, total_loss = -4.8143, pg_loss = -47.083, baseline_loss = 47.71, entropy_loss = -5.4414, learner_queue_size = 32, _tick = 24639, _time = 1.6548e+09, train_seconds = 2.3817e+04)
[2022-06-10 02:45:01,952][root][INFO] - Step 90237440 @ 3582.3 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 90237440, mean_episode_return = 0.060003, mean_episode_step = 778.41, total_loss = 177.25, pg_loss = 106.23, baseline_loss = 76.542, entropy_loss = -5.5303, learner_queue_size = 32, _tick = 24644, _time = 1.6548e+09, train_seconds = 2.3822e+04)
[2022-06-10 02:45:06,958][root][INFO] - Step 90257920 @ 4091.4 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 90257920, mean_episode_return = 63.69, mean_episode_step = 1006.9, total_loss = 81.36, pg_loss = 14.003, baseline_loss = 72.887, entropy_loss = -5.531, learner_queue_size = 32, _tick = 24650, _time = 1.6548e+09, train_seconds = 2.3827e+04)
[2022-06-10 02:45:11,962][root][INFO] - Step 90278400 @ 4092.7 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 90278400, mean_episode_return = None, mean_episode_step = 1234.9, total_loss = 9.9282, pg_loss = -9.6285, baseline_loss = 25.22, entropy_loss = -5.663, learner_queue_size = 32, _tick = 24656, _time = 1.6548e+09, train_seconds = 2.3832e+04)
[2022-06-10 02:45:16,966][root][INFO] - Step 90296320 @ 3581.2 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 90296320, mean_episode_return = 90.981, mean_episode_step = 906.28, total_loss = -60.145, pg_loss = -85.471, baseline_loss = 30.783, entropy_loss = -5.4563, learner_queue_size = 32, _tick = 24662, _time = 1.6548e+09, train_seconds = 2.3837e+04)
[2022-06-10 02:45:21,970][root][INFO] - Step 90316800 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 90316800, mean_episode_return = 26.487, mean_episode_step = 952.96, total_loss = 91.101, pg_loss = 50.443, baseline_loss = 46.172, entropy_loss = -5.5143, learner_queue_size = 32, _tick = 24668, _time = 1.6548e+09, train_seconds = 2.3842e+04)
[2022-06-10 02:45:26,974][root][INFO] - Step 90337280 @ 4092.7 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 90337280, mean_episode_return = None, mean_episode_step = 1061.9, total_loss = 80.488, pg_loss = 35.667, baseline_loss = 50.583, entropy_loss = -5.7616, learner_queue_size = 32, _tick = 24674, _time = 1.6548e+09, train_seconds = 2.3847e+04)
[2022-06-10 02:45:31,978][root][INFO] - Step 90355200 @ 3581.2 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 90355200, mean_episode_return = 52.88, mean_episode_step = 1019.5, total_loss = 425.42, pg_loss = 345.7, baseline_loss = 85.206, entropy_loss = -5.4823, learner_queue_size = 32, _tick = 24680, _time = 1.6548e+09, train_seconds = 2.3852e+04)
[2022-06-10 02:45:36,986][root][INFO] - Step 90375680 @ 4089.5 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 90375680, mean_episode_return = 4.7197, mean_episode_step = 1386.7, total_loss = 93.218, pg_loss = 40.463, baseline_loss = 58.473, entropy_loss = -5.7172, learner_queue_size = 32, _tick = 24687, _time = 1.6548e+09, train_seconds = 2.3857e+04)
[2022-06-10 02:45:41,990][root][INFO] - Step 90396160 @ 4092.7 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 90396160, mean_episode_return = 74.951, mean_episode_step = 925.45, total_loss = 45.13, pg_loss = 23.695, baseline_loss = 26.728, entropy_loss = -5.2929, learner_queue_size = 32, _tick = 24694, _time = 1.6548e+09, train_seconds = 2.3862e+04)
[2022-06-10 02:45:46,994][root][INFO] - Step 90414080 @ 3580.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 90414080, mean_episode_return = 34.91, mean_episode_step = 891.16, total_loss = 37.848, pg_loss = -21.534, baseline_loss = 64.492, entropy_loss = -5.1106, learner_queue_size = 32, _tick = 24700, _time = 1.6548e+09, train_seconds = 2.3867e+04)
[2022-06-10 02:45:51,998][root][INFO] - Step 90434560 @ 4093.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 90434560, mean_episode_return = 133.45, mean_episode_step = 988.79, total_loss = -85.013, pg_loss = -96.961, baseline_loss = 17.515, entropy_loss = -5.5669, learner_queue_size = 32, _tick = 24707, _time = 1.6548e+09, train_seconds = 2.3872e+04)
[2022-06-10 02:45:57,002][root][INFO] - Step 90452480 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 90452480, mean_episode_return = 50.935, mean_episode_step = 1017.6, total_loss = 244.67, pg_loss = 147.8, baseline_loss = 102.33, entropy_loss = -5.4596, learner_queue_size = 32, _tick = 24714, _time = 1.6548e+09, train_seconds = 2.3877e+04)
[2022-06-10 02:46:02,006][root][INFO] - Step 90472960 @ 4092.8 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 90472960, mean_episode_return = 57.957, mean_episode_step = 1003.4, total_loss = -97.217, pg_loss = -121.33, baseline_loss = 29.555, entropy_loss = -5.4433, learner_queue_size = 32, _tick = 24722, _time = 1.6548e+09, train_seconds = 2.3882e+04)
[2022-06-10 02:46:07,010][root][INFO] - Step 90493440 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 90493440, mean_episode_return = 87.902, mean_episode_step = 874.93, total_loss = -63.47, pg_loss = -85.621, baseline_loss = 27.642, entropy_loss = -5.4906, learner_queue_size = 32, _tick = 24729, _time = 1.6548e+09, train_seconds = 2.3887e+04)
[2022-06-10 02:46:12,014][root][INFO] - Step 90511360 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 90511360, mean_episode_return = 153.38, mean_episode_step = 799.63, total_loss = -58.94, pg_loss = -91.621, baseline_loss = 38.247, entropy_loss = -5.5658, learner_queue_size = 32, _tick = 24735, _time = 1.6548e+09, train_seconds = 2.3892e+04)
[2022-06-10 02:46:17,023][root][INFO] - Step 90531840 @ 4089.0 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 90531840, mean_episode_return = 104.36, mean_episode_step = 872.74, total_loss = 20.326, pg_loss = -24.183, baseline_loss = 50.054, entropy_loss = -5.5454, learner_queue_size = 32, _tick = 24742, _time = 1.6548e+09, train_seconds = 2.3897e+04)
[2022-06-10 02:46:22,026][root][INFO] - Step 90549760 @ 3581.6 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 90549760, mean_episode_return = 107.22, mean_episode_step = 846.04, total_loss = -77.129, pg_loss = -126.93, baseline_loss = 55.491, entropy_loss = -5.6885, learner_queue_size = 32, _tick = 24749, _time = 1.6548e+09, train_seconds = 2.3902e+04)
[2022-06-10 02:46:27,032][root][INFO] - Step 90570240 @ 4091.1 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (step = 90570240, mean_episode_return = 66.904, mean_episode_step = 880.12, total_loss = 13.342, pg_loss = -22.369, baseline_loss = 41.386, entropy_loss = -5.6755, learner_queue_size = 32, _tick = 24755, _time = 1.6548e+09, train_seconds = 2.3907e+04)
[2022-06-10 02:46:32,034][root][INFO] - Step 90590720 @ 4094.3 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 90590720, mean_episode_return = 88.435, mean_episode_step = 997.28, total_loss = -11.965, pg_loss = -31.175, baseline_loss = 24.942, entropy_loss = -5.7315, learner_queue_size = 32, _tick = 24762, _time = 1.6548e+09, train_seconds = 2.3912e+04)
[2022-06-10 02:46:37,038][root][INFO] - Step 90608640 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 90608640, mean_episode_return = 57.967, mean_episode_step = 947.11, total_loss = 179.26, pg_loss = 8.467, baseline_loss = 176.49, entropy_loss = -5.6967, learner_queue_size = 32, _tick = 24769, _time = 1.6548e+09, train_seconds = 2.3917e+04)
[2022-06-10 02:46:42,042][root][INFO] - Step 90629120 @ 4092.7 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (step = 90629120, mean_episode_return = 29.254, mean_episode_step = 892.92, total_loss = 172.38, pg_loss = 120.71, baseline_loss = 57.344, entropy_loss = -5.6725, learner_queue_size = 32, _tick = 24772, _time = 1.6548e+09, train_seconds = 2.3922e+04)
[2022-06-10 02:46:47,046][root][INFO] - Step 90649600 @ 4092.8 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 90649600, mean_episode_return = 41.815, mean_episode_step = 1116.2, total_loss = 46.349, pg_loss = 2.794, baseline_loss = 49.247, entropy_loss = -5.6925, learner_queue_size = 32, _tick = 24778, _time = 1.6548e+09, train_seconds = 2.3927e+04)
[2022-06-10 02:46:52,050][root][INFO] - Step 90667520 @ 3581.1 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (step = 90667520, mean_episode_return = 53.513, mean_episode_step = 1109.2, total_loss = 206.36, pg_loss = 11.922, baseline_loss = 200.03, entropy_loss = -5.5948, learner_queue_size = 32, _tick = 24784, _time = 1.6548e+09, train_seconds = 2.3932e+04)
[2022-06-10 02:46:57,054][root][INFO] - Step 90688000 @ 4092.6 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 90688000, mean_episode_return = 60.39, mean_episode_step = 954.32, total_loss = 171.35, pg_loss = 83.962, baseline_loss = 92.943, entropy_loss = -5.5582, learner_queue_size = 32, _tick = 24791, _time = 1.6548e+09, train_seconds = 2.3937e+04)
[2022-06-10 02:47:02,058][root][INFO] - Step 90708480 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 90708480, mean_episode_return = 85.78, mean_episode_step = 1095.2, total_loss = 51.675, pg_loss = 19.541, baseline_loss = 37.777, entropy_loss = -5.6429, learner_queue_size = 32, _tick = 24798, _time = 1.6548e+09, train_seconds = 2.3942e+04)
[2022-06-10 02:47:07,062][root][INFO] - Step 90726400 @ 3581.2 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 90726400, mean_episode_return = None, mean_episode_step = 956.22, total_loss = -29.147, pg_loss = -37.114, baseline_loss = 13.684, entropy_loss = -5.7167, learner_queue_size = 32, _tick = 24802, _time = 1.6548e+09, train_seconds = 2.3947e+04)
[2022-06-10 02:47:12,066][root][INFO] - Step 90746880 @ 4092.8 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 90746880, mean_episode_return = 95.184, mean_episode_step = 941.03, total_loss = -108.98, pg_loss = -128.85, baseline_loss = 25.612, entropy_loss = -5.7417, learner_queue_size = 32, _tick = 24809, _time = 1.6548e+09, train_seconds = 2.3952e+04)
[2022-06-10 02:47:17,070][root][INFO] - Step 90767360 @ 4092.7 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 90767360, mean_episode_return = None, mean_episode_step = 861.16, total_loss = -103.52, pg_loss = -139.03, baseline_loss = 41.244, entropy_loss = -5.7345, learner_queue_size = 32, _tick = 24814, _time = 1.6548e+09, train_seconds = 2.3957e+04)
[2022-06-10 02:47:22,074][root][INFO] - Step 90785280 @ 3581.1 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 90785280, mean_episode_return = None, mean_episode_step = 937.34, total_loss = 355.41, pg_loss = 248.88, baseline_loss = 112.24, entropy_loss = -5.707, learner_queue_size = 32, _tick = 24818, _time = 1.6548e+09, train_seconds = 2.3962e+04)
[2022-06-10 02:47:27,078][root][INFO] - Step 90805760 @ 4092.8 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 90805760, mean_episode_return = 82.23, mean_episode_step = 952.97, total_loss = 18.818, pg_loss = -32.869, baseline_loss = 57.373, entropy_loss = -5.6866, learner_queue_size = 32, _tick = 24825, _time = 1.6548e+09, train_seconds = 2.3967e+04)
[2022-06-10 02:47:32,082][root][INFO] - Step 90826240 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 90826240, mean_episode_return = None, mean_episode_step = 923.72, total_loss = 80.212, pg_loss = 50.249, baseline_loss = 35.709, entropy_loss = -5.7464, learner_queue_size = 32, _tick = 24831, _time = 1.6548e+09, train_seconds = 2.3972e+04)
[2022-06-10 02:47:37,086][root][INFO] - Step 90844160 @ 3581.0 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 90844160, mean_episode_return = 28.93, mean_episode_step = 1095.6, total_loss = 216.45, pg_loss = 151.63, baseline_loss = 70.48, entropy_loss = -5.6627, learner_queue_size = 32, _tick = 24836, _time = 1.6548e+09, train_seconds = 2.3977e+04)
[2022-06-10 02:47:42,091][root][INFO] - Step 90864640 @ 4092.7 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 90864640, mean_episode_return = 22.596, mean_episode_step = 840.4, total_loss = -14.294, pg_loss = -73.924, baseline_loss = 65.318, entropy_loss = -5.6883, learner_queue_size = 32, _tick = 24843, _time = 1.6548e+09, train_seconds = 2.3982e+04)
[2022-06-10 02:47:47,094][root][INFO] - Step 90885120 @ 4092.7 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 90885120, mean_episode_return = 30.259, mean_episode_step = 898.57, total_loss = -90.602, pg_loss = -106.21, baseline_loss = 21.262, entropy_loss = -5.6523, learner_queue_size = 32, _tick = 24851, _time = 1.6548e+09, train_seconds = 2.3987e+04)
[2022-06-10 02:47:52,098][root][INFO] - Step 90905600 @ 4092.8 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 90905600, mean_episode_return = None, mean_episode_step = 820.66, total_loss = 79.468, pg_loss = 29.256, baseline_loss = 55.822, entropy_loss = -5.6098, learner_queue_size = 32, _tick = 24855, _time = 1.6548e+09, train_seconds = 2.3992e+04)
[2022-06-10 02:47:57,103][root][INFO] - Step 90923520 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 90923520, mean_episode_return = 55.74, mean_episode_step = 1005.1, total_loss = -109.22, pg_loss = -141.47, baseline_loss = 37.864, entropy_loss = -5.6103, learner_queue_size = 32, _tick = 24860, _time = 1.6548e+09, train_seconds = 2.3997e+04)
[2022-06-10 02:48:02,106][root][INFO] - Step 90944000 @ 4092.8 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 90944000, mean_episode_return = 35.493, mean_episode_step = 1090.1, total_loss = 93.943, pg_loss = 28.75, baseline_loss = 70.899, entropy_loss = -5.7064, learner_queue_size = 32, _tick = 24865, _time = 1.6548e+09, train_seconds = 2.4002e+04)
[2022-06-10 02:48:07,110][root][INFO] - Step 90961920 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 90961920, mean_episode_return = 113.23, mean_episode_step = 1079.6, total_loss = -21.139, pg_loss = -67.425, baseline_loss = 51.992, entropy_loss = -5.7053, learner_queue_size = 32, _tick = 24871, _time = 1.6548e+09, train_seconds = 2.4007e+04)
[2022-06-10 02:48:12,114][root][INFO] - Step 90982400 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 90982400, mean_episode_return = None, mean_episode_step = 890.59, total_loss = 211.88, pg_loss = 154.11, baseline_loss = 63.401, entropy_loss = -5.6334, learner_queue_size = 32, _tick = 24876, _time = 1.6548e+09, train_seconds = 2.4012e+04)
[2022-06-10 02:48:17,118][root][INFO] - Step 91000320 @ 3581.2 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 91000320, mean_episode_return = 68.82, mean_episode_step = 1044.2, total_loss = -61.577, pg_loss = -102.24, baseline_loss = 46.329, entropy_loss = -5.6707, learner_queue_size = 32, _tick = 24882, _time = 1.6548e+09, train_seconds = 2.4017e+04)
[2022-06-10 02:48:22,122][root][INFO] - Step 91020800 @ 4092.7 SPS. Inference batcher size: 78. Learner queue size: 32. Other stats: (step = 91020800, mean_episode_return = None, mean_episode_step = 1148.1, total_loss = 249.83, pg_loss = 153.88, baseline_loss = 101.47, entropy_loss = -5.5245, learner_queue_size = 32, _tick = 24886, _time = 1.6548e+09, train_seconds = 2.4022e+04)
[2022-06-10 02:48:27,126][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 02:48:27,363][root][INFO] - Step 91038720 @ 3581.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 91041280, mean_episode_return = 76.365, mean_episode_step = 1040.1, total_loss = 368.11, pg_loss = 274.18, baseline_loss = 99.587, entropy_loss = -5.6653, learner_queue_size = 32, _tick = 24892, _time = 1.6548e+09, train_seconds = 2.4027e+04)
[2022-06-10 02:48:32,366][root][INFO] - Step 91059200 @ 3908.4 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 91059200, mean_episode_return = None, mean_episode_step = 1313.3, total_loss = 426.38, pg_loss = 330.73, baseline_loss = 101.39, entropy_loss = -5.7399, learner_queue_size = 32, _tick = 24896, _time = 1.6548e+09, train_seconds = 2.4032e+04)
[2022-06-10 02:48:37,370][root][INFO] - Step 91079680 @ 4092.8 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 91079680, mean_episode_return = None, mean_episode_step = 1282.0, total_loss = 278.26, pg_loss = 194.66, baseline_loss = 89.29, entropy_loss = -5.6913, learner_queue_size = 32, _tick = 24903, _time = 1.6548e+09, train_seconds = 2.4037e+04)
[2022-06-10 02:48:42,374][root][INFO] - Step 91100160 @ 4092.7 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 91100160, mean_episode_return = 59.084, mean_episode_step = 1174.5, total_loss = 322.06, pg_loss = 260.33, baseline_loss = 67.362, entropy_loss = -5.6311, learner_queue_size = 32, _tick = 24910, _time = 1.6548e+09, train_seconds = 2.4042e+04)
[2022-06-10 02:48:47,378][root][INFO] - Step 91118080 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 91118080, mean_episode_return = 14.53, mean_episode_step = 1095.0, total_loss = 129.16, pg_loss = 64.354, baseline_loss = 70.423, entropy_loss = -5.6154, learner_queue_size = 32, _tick = 24916, _time = 1.6548e+09, train_seconds = 2.4047e+04)
[2022-06-10 02:48:52,382][root][INFO] - Step 91138560 @ 4092.8 SPS. Inference batcher size: 80. Learner queue size: 32. Other stats: (step = 91138560, mean_episode_return = 80.553, mean_episode_step = 1156.2, total_loss = -189.22, pg_loss = -205.49, baseline_loss = 21.788, entropy_loss = -5.5112, learner_queue_size = 32, _tick = 24921, _time = 1.6548e+09, train_seconds = 2.4052e+04)
[2022-06-10 02:48:57,386][root][INFO] - Step 91156480 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 91156480, mean_episode_return = 58.211, mean_episode_step = 1023.3, total_loss = -46.127, pg_loss = -87.079, baseline_loss = 46.557, entropy_loss = -5.6057, learner_queue_size = 32, _tick = 24927, _time = 1.6548e+09, train_seconds = 2.4057e+04)
[2022-06-10 02:49:02,390][root][INFO] - Step 91176960 @ 4092.7 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 91176960, mean_episode_return = None, mean_episode_step = 1157.7, total_loss = 43.634, pg_loss = 9.637, baseline_loss = 39.703, entropy_loss = -5.7056, learner_queue_size = 32, _tick = 24933, _time = 1.6548e+09, train_seconds = 2.4062e+04)
[2022-06-10 02:49:07,394][root][INFO] - Step 91194880 @ 3581.3 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 91194880, mean_episode_return = 38.283, mean_episode_step = 1134.2, total_loss = 192.17, pg_loss = 143.13, baseline_loss = 54.644, entropy_loss = -5.6037, learner_queue_size = 32, _tick = 24939, _time = 1.6548e+09, train_seconds = 2.4067e+04)
[2022-06-10 02:49:12,398][root][INFO] - Step 91215360 @ 4092.5 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 91215360, mean_episode_return = 67.06, mean_episode_step = 1122.3, total_loss = -300.67, pg_loss = -319.78, baseline_loss = 24.795, entropy_loss = -5.6838, learner_queue_size = 32, _tick = 24945, _time = 1.6548e+09, train_seconds = 2.4072e+04)
[2022-06-10 02:49:17,402][root][INFO] - Step 91235840 @ 4092.7 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 91235840, mean_episode_return = 115.61, mean_episode_step = 954.58, total_loss = 136.66, pg_loss = 85.938, baseline_loss = 56.382, entropy_loss = -5.6584, learner_queue_size = 32, _tick = 24953, _time = 1.6548e+09, train_seconds = 2.4077e+04)
[2022-06-10 02:49:22,406][root][INFO] - Step 91253760 @ 3581.0 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 91253760, mean_episode_return = None, mean_episode_step = 1107.6, total_loss = -80.75, pg_loss = -110.05, baseline_loss = 34.951, entropy_loss = -5.6542, learner_queue_size = 32, _tick = 24958, _time = 1.6548e+09, train_seconds = 2.4082e+04)
[2022-06-10 02:49:27,410][root][INFO] - Step 91274240 @ 4092.9 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (step = 91274240, mean_episode_return = 43.546, mean_episode_step = 928.86, total_loss = 69.579, pg_loss = 12.278, baseline_loss = 63.045, entropy_loss = -5.7441, learner_queue_size = 32, _tick = 24965, _time = 1.6548e+09, train_seconds = 2.4087e+04)
[2022-06-10 02:49:32,414][root][INFO] - Step 91294720 @ 4092.6 SPS. Inference batcher size: 93. Learner queue size: 32. Other stats: (step = 91294720, mean_episode_return = 72.119, mean_episode_step = 911.88, total_loss = 198.7, pg_loss = 58.68, baseline_loss = 145.7, entropy_loss = -5.6874, learner_queue_size = 32, _tick = 24971, _time = 1.6548e+09, train_seconds = 2.4092e+04)
[2022-06-10 02:49:37,418][root][INFO] - Step 91312640 @ 3581.2 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 91312640, mean_episode_return = -7.3402, mean_episode_step = 897.59, total_loss = 239.78, pg_loss = 166.82, baseline_loss = 78.651, entropy_loss = -5.6968, learner_queue_size = 32, _tick = 24978, _time = 1.6548e+09, train_seconds = 2.4097e+04)
[2022-06-10 02:49:42,422][root][INFO] - Step 91333120 @ 4092.7 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 91333120, mean_episode_return = None, mean_episode_step = 1052.8, total_loss = 19.604, pg_loss = -5.2361, baseline_loss = 30.547, entropy_loss = -5.7064, learner_queue_size = 32, _tick = 24985, _time = 1.6548e+09, train_seconds = 2.4102e+04)
[2022-06-10 02:49:47,430][root][INFO] - Step 91353600 @ 4089.5 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 91353600, mean_episode_return = 66.14, mean_episode_step = 885.07, total_loss = -69.979, pg_loss = -116.8, baseline_loss = 52.425, entropy_loss = -5.6063, learner_queue_size = 32, _tick = 24991, _time = 1.6548e+09, train_seconds = 2.4107e+04)
[2022-06-10 02:49:52,434][root][INFO] - Step 91374080 @ 4092.8 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 91374080, mean_episode_return = 50.497, mean_episode_step = 800.0, total_loss = -29.577, pg_loss = -60.315, baseline_loss = 36.337, entropy_loss = -5.5986, learner_queue_size = 32, _tick = 24998, _time = 1.6548e+09, train_seconds = 2.4112e+04)
[2022-06-10 02:49:57,438][root][INFO] - Step 91392000 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 91392000, mean_episode_return = 79.56, mean_episode_step = 928.89, total_loss = 180.39, pg_loss = 82.916, baseline_loss = 103.01, entropy_loss = -5.5334, learner_queue_size = 32, _tick = 25005, _time = 1.6548e+09, train_seconds = 2.4117e+04)
[2022-06-10 02:50:02,442][root][INFO] - Step 91412480 @ 4092.7 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 91412480, mean_episode_return = 76.845, mean_episode_step = 696.83, total_loss = 3.2956, pg_loss = -208.57, baseline_loss = 217.49, entropy_loss = -5.6305, learner_queue_size = 32, _tick = 25013, _time = 1.6548e+09, train_seconds = 2.4122e+04)
[2022-06-10 02:50:07,446][root][INFO] - Step 91432960 @ 4092.5 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (step = 91432960, mean_episode_return = 51.564, mean_episode_step = 863.38, total_loss = 83.505, pg_loss = 30.185, baseline_loss = 58.913, entropy_loss = -5.5927, learner_queue_size = 32, _tick = 25020, _time = 1.6548e+09, train_seconds = 2.4127e+04)
[2022-06-10 02:50:12,450][root][INFO] - Step 91450880 @ 3581.4 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 91450880, mean_episode_return = None, mean_episode_step = 915.06, total_loss = -70.148, pg_loss = -109.99, baseline_loss = 45.501, entropy_loss = -5.6547, learner_queue_size = 32, _tick = 25025, _time = 1.6548e+09, train_seconds = 2.4132e+04)
[2022-06-10 02:50:17,454][root][INFO] - Step 91471360 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 91471360, mean_episode_return = None, mean_episode_step = 835.0, total_loss = 86.641, pg_loss = 46.413, baseline_loss = 45.86, entropy_loss = -5.632, learner_queue_size = 32, _tick = 25031, _time = 1.6548e+09, train_seconds = 2.4137e+04)
[2022-06-10 02:50:22,460][root][INFO] - Step 91491840 @ 4091.2 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 91491840, mean_episode_return = 9.5695, mean_episode_step = 1113.5, total_loss = 117.62, pg_loss = 72.978, baseline_loss = 50.241, entropy_loss = -5.5996, learner_queue_size = 32, _tick = 25039, _time = 1.6548e+09, train_seconds = 2.4142e+04)
[2022-06-10 02:50:27,462][root][INFO] - Step 91509760 @ 3582.3 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 91509760, mean_episode_return = 37.62, mean_episode_step = 1086.2, total_loss = 392.22, pg_loss = 276.82, baseline_loss = 120.98, entropy_loss = -5.5812, learner_queue_size = 32, _tick = 25045, _time = 1.6548e+09, train_seconds = 2.4147e+04)
[2022-06-10 02:50:32,468][root][INFO] - Step 91527680 @ 3579.9 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 91527680, mean_episode_return = 78.899, mean_episode_step = 965.09, total_loss = 58.08, pg_loss = 11.356, baseline_loss = 52.178, entropy_loss = -5.4537, learner_queue_size = 32, _tick = 25052, _time = 1.6548e+09, train_seconds = 2.4152e+04)
[2022-06-10 02:50:37,470][root][INFO] - Step 91548160 @ 4094.3 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 91548160, mean_episode_return = 82.87, mean_episode_step = 1099.7, total_loss = -7.0408, pg_loss = -57.499, baseline_loss = 55.906, entropy_loss = -5.4478, learner_queue_size = 32, _tick = 25059, _time = 1.6548e+09, train_seconds = 2.4157e+04)
[2022-06-10 02:50:42,474][root][INFO] - Step 91568640 @ 4092.6 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 91568640, mean_episode_return = 64.2, mean_episode_step = 1295.9, total_loss = 200.09, pg_loss = 134.23, baseline_loss = 71.52, entropy_loss = -5.6633, learner_queue_size = 32, _tick = 25066, _time = 1.6548e+09, train_seconds = 2.4162e+04)
[2022-06-10 02:50:47,479][root][INFO] - Step 91589120 @ 4092.0 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 91589120, mean_episode_return = 40.02, mean_episode_step = 1023.4, total_loss = -57.769, pg_loss = -68.351, baseline_loss = 16.297, entropy_loss = -5.7152, learner_queue_size = 32, _tick = 25072, _time = 1.6548e+09, train_seconds = 2.4167e+04)
[2022-06-10 02:50:52,482][root][INFO] - Step 91609600 @ 4093.5 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 91609600, mean_episode_return = 105.08, mean_episode_step = 915.32, total_loss = 263.98, pg_loss = 200.89, baseline_loss = 68.737, entropy_loss = -5.6419, learner_queue_size = 32, _tick = 25080, _time = 1.6548e+09, train_seconds = 2.4172e+04)
[2022-06-10 02:50:57,486][root][INFO] - Step 91627520 @ 3581.2 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 91627520, mean_episode_return = 37.151, mean_episode_step = 1011.3, total_loss = -17.161, pg_loss = -43.863, baseline_loss = 32.178, entropy_loss = -5.4764, learner_queue_size = 32, _tick = 25086, _time = 1.6548e+09, train_seconds = 2.4177e+04)
[2022-06-10 02:51:02,490][root][INFO] - Step 91648000 @ 4092.6 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 91648000, mean_episode_return = None, mean_episode_step = 866.09, total_loss = 288.57, pg_loss = 200.11, baseline_loss = 93.849, entropy_loss = -5.3871, learner_queue_size = 32, _tick = 25092, _time = 1.6548e+09, train_seconds = 2.4182e+04)
[2022-06-10 02:51:07,494][root][INFO] - Step 91668480 @ 4092.9 SPS. Inference batcher size: 80. Learner queue size: 32. Other stats: (step = 91668480, mean_episode_return = 125.26, mean_episode_step = 766.63, total_loss = 61.235, pg_loss = 19.859, baseline_loss = 46.906, entropy_loss = -5.5298, learner_queue_size = 32, _tick = 25100, _time = 1.6548e+09, train_seconds = 2.4187e+04)
[2022-06-10 02:51:12,498][root][INFO] - Step 91686400 @ 3581.1 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 91686400, mean_episode_return = 50.84, mean_episode_step = 872.59, total_loss = 81.857, pg_loss = 47.406, baseline_loss = 39.969, entropy_loss = -5.5185, learner_queue_size = 32, _tick = 25107, _time = 1.6548e+09, train_seconds = 2.4192e+04)
[2022-06-10 02:51:17,504][root][INFO] - Step 91706880 @ 4090.9 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 91706880, mean_episode_return = 27.61, mean_episode_step = 802.24, total_loss = -148.34, pg_loss = -182.22, baseline_loss = 39.304, entropy_loss = -5.4245, learner_queue_size = 32, _tick = 25114, _time = 1.6548e+09, train_seconds = 2.4197e+04)
[2022-06-10 02:51:22,510][root][INFO] - Step 91724800 @ 3579.9 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 91724800, mean_episode_return = 87.204, mean_episode_step = 943.06, total_loss = 220.18, pg_loss = 141.62, baseline_loss = 84.027, entropy_loss = -5.4663, learner_queue_size = 32, _tick = 25120, _time = 1.6548e+09, train_seconds = 2.4202e+04)
[2022-06-10 02:51:27,514][root][INFO] - Step 91745280 @ 4092.6 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 91745280, mean_episode_return = 105.62, mean_episode_step = 787.16, total_loss = 117.73, pg_loss = 43.728, baseline_loss = 79.635, entropy_loss = -5.6338, learner_queue_size = 32, _tick = 25127, _time = 1.6548e+09, train_seconds = 2.4207e+04)
[2022-06-10 02:51:32,518][root][INFO] - Step 91765760 @ 4092.8 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 91765760, mean_episode_return = 17.945, mean_episode_step = 901.38, total_loss = 33.547, pg_loss = -6.6684, baseline_loss = 45.706, entropy_loss = -5.4897, learner_queue_size = 32, _tick = 25134, _time = 1.6548e+09, train_seconds = 2.4212e+04)
[2022-06-10 02:51:37,522][root][INFO] - Step 91783680 @ 3581.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 91783680, mean_episode_return = 55.976, mean_episode_step = 1135.1, total_loss = 155.08, pg_loss = 92.936, baseline_loss = 67.769, entropy_loss = -5.6266, learner_queue_size = 32, _tick = 25141, _time = 1.6548e+09, train_seconds = 2.4217e+04)
[2022-06-10 02:51:42,526][root][INFO] - Step 91804160 @ 4092.7 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 91804160, mean_episode_return = 127.74, mean_episode_step = 884.54, total_loss = 98.494, pg_loss = 64.468, baseline_loss = 39.644, entropy_loss = -5.6177, learner_queue_size = 32, _tick = 25149, _time = 1.6548e+09, train_seconds = 2.4222e+04)
[2022-06-10 02:51:47,530][root][INFO] - Step 91824640 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 91824640, mean_episode_return = None, mean_episode_step = 885.41, total_loss = -121.87, pg_loss = -143.33, baseline_loss = 27.096, entropy_loss = -5.6356, learner_queue_size = 32, _tick = 25155, _time = 1.6548e+09, train_seconds = 2.4227e+04)
[2022-06-10 02:51:52,536][root][INFO] - Step 91842560 @ 3579.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 91842560, mean_episode_return = 75.373, mean_episode_step = 941.93, total_loss = 181.59, pg_loss = 108.96, baseline_loss = 78.133, entropy_loss = -5.5011, learner_queue_size = 32, _tick = 25160, _time = 1.6548e+09, train_seconds = 2.4232e+04)
[2022-06-10 02:51:57,543][root][INFO] - Step 91860480 @ 3579.4 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 91860480, mean_episode_return = None, mean_episode_step = 904.84, total_loss = 120.16, pg_loss = 58.482, baseline_loss = 67.34, entropy_loss = -5.6649, learner_queue_size = 32, _tick = 25165, _time = 1.6548e+09, train_seconds = 2.4237e+04)
[2022-06-10 02:52:02,546][root][INFO] - Step 91880960 @ 4093.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 91880960, mean_episode_return = 106.88, mean_episode_step = 880.05, total_loss = 161.88, pg_loss = 106.84, baseline_loss = 60.59, entropy_loss = -5.5558, learner_queue_size = 32, _tick = 25173, _time = 1.6548e+09, train_seconds = 2.4242e+04)
[2022-06-10 02:52:07,550][root][INFO] - Step 91901440 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 91901440, mean_episode_return = None, mean_episode_step = 953.59, total_loss = 76.385, pg_loss = 51.597, baseline_loss = 30.46, entropy_loss = -5.6727, learner_queue_size = 32, _tick = 25180, _time = 1.6548e+09, train_seconds = 2.4247e+04)
[2022-06-10 02:52:12,556][root][INFO] - Step 91919360 @ 3579.6 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 91919360, mean_episode_return = None, mean_episode_step = 833.75, total_loss = 336.47, pg_loss = 273.2, baseline_loss = 68.903, entropy_loss = -5.6336, learner_queue_size = 32, _tick = 25186, _time = 1.6548e+09, train_seconds = 2.4252e+04)
[2022-06-10 02:52:17,562][root][INFO] - Step 91939840 @ 4091.1 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 91939840, mean_episode_return = 183.5, mean_episode_step = 1002.4, total_loss = 266.22, pg_loss = 191.44, baseline_loss = 80.396, entropy_loss = -5.6215, learner_queue_size = 32, _tick = 25193, _time = 1.6548e+09, train_seconds = 2.4257e+04)
[2022-06-10 02:52:22,566][root][INFO] - Step 91957760 @ 3581.2 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 91957760, mean_episode_return = None, mean_episode_step = 808.78, total_loss = -69.003, pg_loss = -86.198, baseline_loss = 22.826, entropy_loss = -5.6315, learner_queue_size = 32, _tick = 25198, _time = 1.6548e+09, train_seconds = 2.4262e+04)
[2022-06-10 02:52:27,570][root][INFO] - Step 91978240 @ 4092.8 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 91978240, mean_episode_return = None, mean_episode_step = 913.34, total_loss = 84.828, pg_loss = 61.267, baseline_loss = 29.075, entropy_loss = -5.5132, learner_queue_size = 32, _tick = 25202, _time = 1.6548e+09, train_seconds = 2.4267e+04)
[2022-06-10 02:52:32,574][root][INFO] - Step 91998720 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 91998720, mean_episode_return = 63.794, mean_episode_step = 1280.3, total_loss = -88.524, pg_loss = -105.69, baseline_loss = 22.752, entropy_loss = -5.5815, learner_queue_size = 32, _tick = 25210, _time = 1.6548e+09, train_seconds = 2.4272e+04)
[2022-06-10 02:52:37,578][root][INFO] - Step 92016640 @ 3581.1 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 92016640, mean_episode_return = 43.374, mean_episode_step = 1205.8, total_loss = -107.92, pg_loss = -138.73, baseline_loss = 36.366, entropy_loss = -5.5519, learner_queue_size = 32, _tick = 25216, _time = 1.6548e+09, train_seconds = 2.4277e+04)
[2022-06-10 02:52:42,582][root][INFO] - Step 92037120 @ 4092.8 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 92037120, mean_episode_return = 37.063, mean_episode_step = 905.5, total_loss = -112.78, pg_loss = -144.29, baseline_loss = 37.118, entropy_loss = -5.6002, learner_queue_size = 32, _tick = 25224, _time = 1.6548e+09, train_seconds = 2.4282e+04)
[2022-06-10 02:52:47,586][root][INFO] - Step 92055040 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 92055040, mean_episode_return = 41.375, mean_episode_step = 680.76, total_loss = 54.267, pg_loss = 10.207, baseline_loss = 49.599, entropy_loss = -5.5388, learner_queue_size = 32, _tick = 25229, _time = 1.6548e+09, train_seconds = 2.4287e+04)
[2022-06-10 02:52:52,592][root][INFO] - Step 92075520 @ 4091.0 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 92075520, mean_episode_return = 15.47, mean_episode_step = 1015.8, total_loss = 91.639, pg_loss = 46.113, baseline_loss = 51.213, entropy_loss = -5.6873, learner_queue_size = 32, _tick = 25236, _time = 1.6548e+09, train_seconds = 2.4292e+04)
[2022-06-10 02:52:57,598][root][INFO] - Step 92096000 @ 4091.2 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 92096000, mean_episode_return = None, mean_episode_step = 702.75, total_loss = -37.098, pg_loss = -65.771, baseline_loss = 34.186, entropy_loss = -5.5126, learner_queue_size = 32, _tick = 25241, _time = 1.6548e+09, train_seconds = 2.4297e+04)
[2022-06-10 02:53:02,602][root][INFO] - Step 92113920 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 92113920, mean_episode_return = 61.396, mean_episode_step = 823.57, total_loss = 251.63, pg_loss = 196.91, baseline_loss = 60.253, entropy_loss = -5.5364, learner_queue_size = 32, _tick = 25246, _time = 1.6548e+09, train_seconds = 2.4302e+04)
[2022-06-10 02:53:07,606][root][INFO] - Step 92134400 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 92134400, mean_episode_return = 56.083, mean_episode_step = 853.97, total_loss = -299.91, pg_loss = -363.34, baseline_loss = 69.003, entropy_loss = -5.569, learner_queue_size = 32, _tick = 25254, _time = 1.6548e+09, train_seconds = 2.4307e+04)
[2022-06-10 02:53:12,610][root][INFO] - Step 92152320 @ 3581.2 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 92152320, mean_episode_return = None, mean_episode_step = 722.66, total_loss = 133.38, pg_loss = 69.889, baseline_loss = 69.018, entropy_loss = -5.5286, learner_queue_size = 32, _tick = 25257, _time = 1.6548e+09, train_seconds = 2.4312e+04)
[2022-06-10 02:53:17,614][root][INFO] - Step 92172800 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 92172800, mean_episode_return = 26.36, mean_episode_step = 1086.5, total_loss = 162.16, pg_loss = 116.64, baseline_loss = 51.162, entropy_loss = -5.6482, learner_queue_size = 32, _tick = 25263, _time = 1.6548e+09, train_seconds = 2.4317e+04)
[2022-06-10 02:53:22,618][root][INFO] - Step 92193280 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 92193280, mean_episode_return = 93.64, mean_episode_step = 924.88, total_loss = 9.6452, pg_loss = -19.845, baseline_loss = 35.072, entropy_loss = -5.5824, learner_queue_size = 32, _tick = 25269, _time = 1.6548e+09, train_seconds = 2.4322e+04)
[2022-06-10 02:53:27,624][root][INFO] - Step 92213760 @ 4090.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 92213760, mean_episode_return = 105.44, mean_episode_step = 1009.4, total_loss = -142.56, pg_loss = -172.85, baseline_loss = 35.87, entropy_loss = -5.5857, learner_queue_size = 32, _tick = 25277, _time = 1.6548e+09, train_seconds = 2.4327e+04)
[2022-06-10 02:53:32,630][root][INFO] - Step 92231680 @ 3580.0 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 92231680, mean_episode_return = 109.94, mean_episode_step = 1027.0, total_loss = 78.35, pg_loss = 31.866, baseline_loss = 51.876, entropy_loss = -5.3918, learner_queue_size = 32, _tick = 25282, _time = 1.6548e+09, train_seconds = 2.4332e+04)
[2022-06-10 02:53:37,634][root][INFO] - Step 92252160 @ 4092.6 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 92252160, mean_episode_return = 38.001, mean_episode_step = 863.06, total_loss = -199.33, pg_loss = -206.88, baseline_loss = 12.976, entropy_loss = -5.4302, learner_queue_size = 32, _tick = 25290, _time = 1.6548e+09, train_seconds = 2.4337e+04)
[2022-06-10 02:53:42,638][root][INFO] - Step 92270080 @ 3581.3 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 92270080, mean_episode_return = 104.36, mean_episode_step = 908.05, total_loss = 57.393, pg_loss = 26.335, baseline_loss = 36.509, entropy_loss = -5.4505, learner_queue_size = 32, _tick = 25297, _time = 1.6548e+09, train_seconds = 2.4342e+04)
[2022-06-10 02:53:47,642][root][INFO] - Step 92290560 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 92290560, mean_episode_return = 75.805, mean_episode_step = 772.65, total_loss = 359.02, pg_loss = 273.58, baseline_loss = 88.662, entropy_loss = -3.2181, learner_queue_size = 32, _tick = 25304, _time = 1.6548e+09, train_seconds = 2.4347e+04)
[2022-06-10 02:53:52,646][root][INFO] - Step 92311040 @ 4092.8 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 92311040, mean_episode_return = 62.561, mean_episode_step = 854.47, total_loss = 338.5, pg_loss = 248.83, baseline_loss = 98.861, entropy_loss = -9.1892, learner_queue_size = 32, _tick = 25312, _time = 1.6548e+09, train_seconds = 2.4352e+04)
[2022-06-10 02:53:57,650][root][INFO] - Step 92328960 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 92328960, mean_episode_return = None, mean_episode_step = 954.69, total_loss = -106.23, pg_loss = -106.69, baseline_loss = 10.254, entropy_loss = -9.7967, learner_queue_size = 32, _tick = 25313, _time = 1.6548e+09, train_seconds = 2.4358e+04)
[2022-06-10 02:54:02,654][root][INFO] - Step 92349440 @ 4092.7 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 92349440, mean_episode_return = None, mean_episode_step = 923.28, total_loss = -99.814, pg_loss = -99.975, baseline_loss = 8.6047, entropy_loss = -8.444, learner_queue_size = 32, _tick = 25313, _time = 1.6548e+09, train_seconds = 2.4362e+04)
[2022-06-10 02:54:07,660][root][INFO] - Step 92369920 @ 4091.4 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 92369920, mean_episode_return = None, mean_episode_step = 1036.8, total_loss = -65.779, pg_loss = -63.511, baseline_loss = 6.3269, entropy_loss = -8.5945, learner_queue_size = 32, _tick = 25313, _time = 1.6548e+09, train_seconds = 2.4368e+04)
[2022-06-10 02:54:12,662][root][INFO] - Step 92390400 @ 4094.2 SPS. Inference batcher size: 90. Learner queue size: 32. Other stats: (step = 92390400, mean_episode_return = None, mean_episode_step = 1092.6, total_loss = -23.385, pg_loss = -18.199, baseline_loss = 5.026, entropy_loss = -10.212, learner_queue_size = 32, _tick = 25313, _time = 1.6548e+09, train_seconds = 2.4372e+04)
[2022-06-10 02:54:17,666][root][INFO] - Step 92408320 @ 3581.1 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 92408320, mean_episode_return = 31.95, mean_episode_step = 1047.8, total_loss = 36.129, pg_loss = 40.599, baseline_loss = 5.8728, entropy_loss = -10.343, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4378e+04)
[2022-06-10 02:54:22,670][root][INFO] - Step 92428800 @ 4092.8 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 92428800, mean_episode_return = None, mean_episode_step = 1222.6, total_loss = 13.446, pg_loss = 20.704, baseline_loss = 3.1125, entropy_loss = -10.37, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4382e+04)
[2022-06-10 02:54:27,674][root][INFO] - Step 92449280 @ 4092.8 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (step = 92449280, mean_episode_return = None, mean_episode_step = 1274.5, total_loss = -16.56, pg_loss = -8.6435, baseline_loss = 2.4453, entropy_loss = -10.362, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4388e+04)
[2022-06-10 02:54:32,679][root][INFO] - Step 92469760 @ 4091.6 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 92469760, mean_episode_return = None, mean_episode_step = 1381.6, total_loss = -25.435, pg_loss = -17.076, baseline_loss = 1.9883, entropy_loss = -10.348, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4392e+04)
[2022-06-10 02:54:37,682][root][INFO] - Step 92490240 @ 4093.7 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 92490240, mean_episode_return = None, mean_episode_step = 1383.8, total_loss = -35.943, pg_loss = -27.22, baseline_loss = 1.6853, entropy_loss = -10.409, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4398e+04)
[2022-06-10 02:54:42,686][root][INFO] - Step 92508160 @ 3581.2 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 92508160, mean_episode_return = None, mean_episode_step = 1459.4, total_loss = 6.6282, pg_loss = 15.536, baseline_loss = 1.5118, entropy_loss = -10.42, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4402e+04)
[2022-06-10 02:54:47,691][root][INFO] - Step 92528640 @ 4091.9 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 92528640, mean_episode_return = None, mean_episode_step = 1570.5, total_loss = 1.9042, pg_loss = 11.155, baseline_loss = 1.3071, entropy_loss = -10.558, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4408e+04)
[2022-06-10 02:54:52,694][root][INFO] - Step 92549120 @ 4093.6 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 92549120, mean_episode_return = None, mean_episode_step = 1661.0, total_loss = -35.306, pg_loss = -25.781, baseline_loss = 1.0671, entropy_loss = -10.592, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4412e+04)
[2022-06-10 02:54:57,698][root][INFO] - Step 92569600 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 92569600, mean_episode_return = None, mean_episode_step = 1826.4, total_loss = -18.686, pg_loss = -9.0199, baseline_loss = 0.9472, entropy_loss = -10.614, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4418e+04)
[2022-06-10 02:55:02,702][root][INFO] - Step 92587520 @ 3581.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 92587520, mean_episode_return = None, mean_episode_step = 1831.9, total_loss = -19.158, pg_loss = -9.3421, baseline_loss = 0.8143, entropy_loss = -10.63, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4422e+04)
[2022-06-10 02:55:07,706][root][INFO] - Step 92608000 @ 4092.7 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 92608000, mean_episode_return = None, mean_episode_step = 2003.4, total_loss = 13.216, pg_loss = 23.174, baseline_loss = 0.74815, entropy_loss = -10.706, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4428e+04)
[2022-06-10 02:55:12,710][root][INFO] - Step 92625920 @ 3581.1 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 92625920, mean_episode_return = None, mean_episode_step = 1959.0, total_loss = -17.791, pg_loss = -7.7085, baseline_loss = 0.66333, entropy_loss = -10.746, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4432e+04)
[2022-06-10 02:55:17,714][root][INFO] - Step 92646400 @ 4092.7 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 92646400, mean_episode_return = None, mean_episode_step = 2184.3, total_loss = -26.41, pg_loss = -16.239, baseline_loss = 0.61267, entropy_loss = -10.783, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4438e+04)
[2022-06-10 02:55:22,720][root][INFO] - Step 92666880 @ 4091.2 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 92666880, mean_episode_return = None, mean_episode_step = 2095.4, total_loss = -13.49, pg_loss = -3.2303, baseline_loss = 0.54396, entropy_loss = -10.803, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4442e+04)
[2022-06-10 02:55:27,726][root][INFO] - Step 92684800 @ 3579.6 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 92684800, mean_episode_return = None, mean_episode_step = 2260.5, total_loss = -31.488, pg_loss = -21.17, baseline_loss = 0.49199, entropy_loss = -10.81, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4448e+04)
[2022-06-10 02:55:32,730][root][INFO] - Step 92705280 @ 4092.8 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 92705280, mean_episode_return = None, mean_episode_step = 2479.1, total_loss = -18.742, pg_loss = -8.3808, baseline_loss = 0.45093, entropy_loss = -10.812, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4452e+04)
[2022-06-10 02:55:37,734][root][INFO] - Step 92725760 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 92725760, mean_episode_return = None, mean_episode_step = 2242.8, total_loss = -27.62, pg_loss = -17.265, baseline_loss = 0.46897, entropy_loss = -10.824, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4458e+04)
[2022-06-10 02:55:42,738][root][INFO] - Step 92746240 @ 4092.7 SPS. Inference batcher size: 79. Learner queue size: 32. Other stats: (step = 92746240, mean_episode_return = None, mean_episode_step = 2484.2, total_loss = -12.697, pg_loss = -2.2752, baseline_loss = 0.4047, entropy_loss = -10.826, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4462e+04)
[2022-06-10 02:55:47,742][root][INFO] - Step 92764160 @ 3581.2 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 92764160, mean_episode_return = None, mean_episode_step = 2376.1, total_loss = -26.58, pg_loss = -16.122, baseline_loss = 0.39422, entropy_loss = -10.852, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4468e+04)
[2022-06-10 02:55:52,746][root][INFO] - Step 92784640 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 92784640, mean_episode_return = None, mean_episode_step = 2753.0, total_loss = 12.37, pg_loss = 22.865, baseline_loss = 0.37788, entropy_loss = -10.873, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4473e+04)
[2022-06-10 02:55:57,750][root][INFO] - Step 92805120 @ 4092.7 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 92805120, mean_episode_return = None, mean_episode_step = 2824.9, total_loss = 11.824, pg_loss = 22.382, baseline_loss = 0.33182, entropy_loss = -10.89, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4478e+04)
[2022-06-10 02:56:02,754][root][INFO] - Step 92825600 @ 4092.7 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 92825600, mean_episode_return = None, mean_episode_step = 2634.0, total_loss = -8.7323, pg_loss = 1.8282, baseline_loss = 0.33967, entropy_loss = -10.9, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4483e+04)
[2022-06-10 02:56:07,758][root][INFO] - Step 92843520 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 92843520, mean_episode_return = None, mean_episode_step = 2843.4, total_loss = 5.6406, pg_loss = 16.215, baseline_loss = 0.33231, entropy_loss = -10.906, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4488e+04)
[2022-06-10 02:56:12,762][root][INFO] - Step 92864000 @ 4092.8 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 92864000, mean_episode_return = None, mean_episode_step = 2924.2, total_loss = -29.69, pg_loss = -19.048, baseline_loss = 0.2803, entropy_loss = -10.922, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4493e+04)
[2022-06-10 02:56:17,766][root][INFO] - Step 92884480 @ 4092.7 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 92884480, mean_episode_return = None, mean_episode_step = 2926.3, total_loss = -12.37, pg_loss = -1.7187, baseline_loss = 0.27601, entropy_loss = -10.927, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4498e+04)
[2022-06-10 02:56:22,770][root][INFO] - Step 92902400 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 92902400, mean_episode_return = None, mean_episode_step = 2951.2, total_loss = -21.047, pg_loss = -10.393, baseline_loss = 0.27762, entropy_loss = -10.931, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4503e+04)
[2022-06-10 02:56:27,774][root][INFO] - Step 92922880 @ 4092.7 SPS. Inference batcher size: 81. Learner queue size: 32. Other stats: (step = 92922880, mean_episode_return = None, mean_episode_step = 3491.5, total_loss = -9.8936, pg_loss = 0.76016, baseline_loss = 0.28868, entropy_loss = -10.942, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4508e+04)
[2022-06-10 02:56:32,778][root][INFO] - Step 92940800 @ 3581.1 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 92940800, mean_episode_return = None, mean_episode_step = 3193.0, total_loss = -29.386, pg_loss = -18.708, baseline_loss = 0.25776, entropy_loss = -10.936, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4513e+04)
[2022-06-10 02:56:37,782][root][INFO] - Step 92961280 @ 4092.8 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 92961280, mean_episode_return = None, mean_episode_step = 3325.5, total_loss = -11.925, pg_loss = -1.2347, baseline_loss = 0.25034, entropy_loss = -10.941, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4518e+04)
[2022-06-10 02:56:42,786][root][INFO] - Step 92981760 @ 4092.3 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 92981760, mean_episode_return = None, mean_episode_step = 3620.9, total_loss = -10.906, pg_loss = -0.16716, baseline_loss = 0.21165, entropy_loss = -10.95, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4523e+04)
[2022-06-10 02:56:47,790][root][INFO] - Step 93002240 @ 4093.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 93002240, mean_episode_return = None, mean_episode_step = 3469.4, total_loss = -25.469, pg_loss = -14.743, baseline_loss = 0.23658, entropy_loss = -10.962, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4528e+04)
[2022-06-10 02:56:52,794][root][INFO] - Step 93020160 @ 3581.0 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 93020160, mean_episode_return = None, mean_episode_step = 3535.6, total_loss = -10.474, pg_loss = 0.2329, baseline_loss = 0.25314, entropy_loss = -10.96, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4533e+04)
[2022-06-10 02:56:57,798][root][INFO] - Step 93040640 @ 4092.8 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 93040640, mean_episode_return = None, mean_episode_step = 3868.7, total_loss = -18.874, pg_loss = -8.1244, baseline_loss = 0.22042, entropy_loss = -10.97, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4538e+04)
[2022-06-10 02:57:02,802][root][INFO] - Step 93061120 @ 4092.8 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 93061120, mean_episode_return = None, mean_episode_step = 3667.1, total_loss = -9.0706, pg_loss = 1.6765, baseline_loss = 0.23534, entropy_loss = -10.983, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4543e+04)
[2022-06-10 02:57:07,808][root][INFO] - Step 93079040 @ 3579.6 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 93079040, mean_episode_return = None, mean_episode_step = 3886.0, total_loss = -9.6667, pg_loss = 1.1122, baseline_loss = 0.21019, entropy_loss = -10.989, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4548e+04)
[2022-06-10 02:57:12,814][root][INFO] - Step 93099520 @ 4091.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 93099520, mean_episode_return = None, mean_episode_step = 4053.9, total_loss = -18.716, pg_loss = -7.927, baseline_loss = 0.20555, entropy_loss = -10.995, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4553e+04)
[2022-06-10 02:57:17,818][root][INFO] - Step 93120000 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 93120000, mean_episode_return = None, mean_episode_step = 3961.1, total_loss = -11.6, pg_loss = -0.80821, baseline_loss = 0.20554, entropy_loss = -10.998, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4558e+04)
[2022-06-10 02:57:22,822][root][INFO] - Step 93140480 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 93140480, mean_episode_return = None, mean_episode_step = 4237.7, total_loss = -2.3274, pg_loss = 8.468, baseline_loss = 0.21006, entropy_loss = -11.005, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4563e+04)
[2022-06-10 02:57:27,826][root][INFO] - Step 93158400 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 93158400, mean_episode_return = None, mean_episode_step = 4308.2, total_loss = -5.9998, pg_loss = 4.7725, baseline_loss = 0.22339, entropy_loss = -10.996, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4568e+04)
[2022-06-10 02:57:32,830][root][INFO] - Step 93178880 @ 4092.8 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (step = 93178880, mean_episode_return = None, mean_episode_step = 4273.5, total_loss = -25.75, pg_loss = -14.936, baseline_loss = 0.18845, entropy_loss = -11.003, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4573e+04)
[2022-06-10 02:57:37,834][root][INFO] - Step 93199360 @ 4092.5 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 93199360, mean_episode_return = None, mean_episode_step = 4075.7, total_loss = -19.544, pg_loss = -8.7283, baseline_loss = 0.19312, entropy_loss = -11.009, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4578e+04)
[2022-06-10 02:57:42,838][root][INFO] - Step 93219840 @ 4092.9 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 93219840, mean_episode_return = None, mean_episode_step = 4468.9, total_loss = -9.0215, pg_loss = 1.7907, baseline_loss = 0.19919, entropy_loss = -11.011, learner_queue_size = 32, _tick = 25314, _time = 1.6548e+09, train_seconds = 2.4583e+04)
[2022-06-10 02:57:47,842][root][INFO] - Step 93240320 @ 4092.8 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 93240320, mean_episode_return = None, mean_episode_step = 4275.7, total_loss = -22.676, pg_loss = -11.847, baseline_loss = 0.1859, entropy_loss = -11.015, learner_queue_size = 32, _tick = 25315, _time = 1.6548e+09, train_seconds = 2.4588e+04)
[2022-06-10 02:57:52,846][root][INFO] - Step 93258240 @ 3581.1 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 93258240, mean_episode_return = None, mean_episode_step = 4096.7, total_loss = -15.066, pg_loss = -4.2333, baseline_loss = 0.18489, entropy_loss = -11.017, learner_queue_size = 32, _tick = 25315, _time = 1.6548e+09, train_seconds = 2.4593e+04)
[2022-06-10 02:57:57,850][root][INFO] - Step 93278720 @ 4092.8 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 93278720, mean_episode_return = None, mean_episode_step = 4709.2, total_loss = -7.669, pg_loss = 3.1758, baseline_loss = 0.18675, entropy_loss = -11.032, learner_queue_size = 32, _tick = 25315, _time = 1.6548e+09, train_seconds = 2.4598e+04)
[2022-06-10 02:58:02,854][root][INFO] - Step 93299200 @ 4092.6 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 93299200, mean_episode_return = None, mean_episode_step = 4609.1, total_loss = -18.044, pg_loss = -7.2021, baseline_loss = 0.19001, entropy_loss = -11.032, learner_queue_size = 32, _tick = 25315, _time = 1.6548e+09, train_seconds = 2.4603e+04)
[2022-06-10 02:58:07,858][root][INFO] - Step 93317120 @ 3581.2 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 93317120, mean_episode_return = None, mean_episode_step = 4697.0, total_loss = -12.863, pg_loss = -2.0171, baseline_loss = 0.18638, entropy_loss = -11.032, learner_queue_size = 32, _tick = 25316, _time = 1.6548e+09, train_seconds = 2.4608e+04)
[2022-06-10 02:58:12,862][root][INFO] - Step 93337600 @ 4092.8 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 93337600, mean_episode_return = None, mean_episode_step = 4657.7, total_loss = -19.439, pg_loss = -8.5751, baseline_loss = 0.17175, entropy_loss = -11.035, learner_queue_size = 32, _tick = 25316, _time = 1.6548e+09, train_seconds = 2.4613e+04)
[2022-06-10 02:58:17,868][root][INFO] - Step 93358080 @ 4090.7 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 93358080, mean_episode_return = None, mean_episode_step = 4928.5, total_loss = 2.1001, pg_loss = 12.946, baseline_loss = 0.19104, entropy_loss = -11.037, learner_queue_size = 32, _tick = 25316, _time = 1.6548e+09, train_seconds = 2.4618e+04)
[2022-06-10 02:58:22,874][root][INFO] - Step 93376000 @ 3579.8 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 93376000, mean_episode_return = None, mean_episode_step = 4781.9, total_loss = -15.472, pg_loss = -4.6035, baseline_loss = 0.17277, entropy_loss = -11.041, learner_queue_size = 32, _tick = 25316, _time = 1.6548e+09, train_seconds = 2.4623e+04)
[2022-06-10 02:58:27,878][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 02:58:28,174][root][INFO] - Step 93396480 @ 4092.8 SPS. Inference batcher size: 76. Learner queue size: 32. Other stats: (step = 93399040, mean_episode_return = None, mean_episode_step = 5141.4, total_loss = -7.1392, pg_loss = 3.7267, baseline_loss = 0.17957, entropy_loss = -11.045, learner_queue_size = 32, _tick = 25316, _time = 1.6548e+09, train_seconds = 2.4628e+04)
[2022-06-10 02:58:33,178][root][INFO] - Step 93416960 @ 3864.2 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 93416960, mean_episode_return = None, mean_episode_step = 4934.2, total_loss = -18.102, pg_loss = -7.2143, baseline_loss = 0.16, entropy_loss = -11.047, learner_queue_size = 32, _tick = 25316, _time = 1.6548e+09, train_seconds = 2.4633e+04)
[2022-06-10 02:58:38,182][root][INFO] - Step 93437440 @ 4092.6 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 93437440, mean_episode_return = None, mean_episode_step = 5037.2, total_loss = -12.057, pg_loss = -1.1856, baseline_loss = 0.1822, entropy_loss = -11.053, learner_queue_size = 32, _tick = 25316, _time = 1.6548e+09, train_seconds = 2.4638e+04)
[2022-06-10 02:58:43,188][root][INFO] - Step 93455360 @ 3579.6 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 93455360, mean_episode_return = None, mean_episode_step = 5405.9, total_loss = -23.154, pg_loss = -12.27, baseline_loss = 0.17013, entropy_loss = -11.054, learner_queue_size = 32, _tick = 25316, _time = 1.6548e+09, train_seconds = 2.4643e+04)
[2022-06-10 02:58:48,194][root][INFO] - Step 93475840 @ 4091.3 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 93475840, mean_episode_return = None, mean_episode_step = 5375.6, total_loss = -13.685, pg_loss = -2.8158, baseline_loss = 0.18387, entropy_loss = -11.053, learner_queue_size = 32, _tick = 25316, _time = 1.6548e+09, train_seconds = 2.4648e+04)
[2022-06-10 02:58:53,198][root][INFO] - Step 93496320 @ 4092.7 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 93496320, mean_episode_return = None, mean_episode_step = 5425.6, total_loss = -17.403, pg_loss = -6.5227, baseline_loss = 0.17144, entropy_loss = -11.052, learner_queue_size = 32, _tick = 25316, _time = 1.6548e+09, train_seconds = 2.4653e+04)
[2022-06-10 02:58:58,202][root][INFO] - Step 93516800 @ 4092.7 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 93516800, mean_episode_return = None, mean_episode_step = 5411.1, total_loss = -13.291, pg_loss = -2.4066, baseline_loss = 0.16501, entropy_loss = -11.05, learner_queue_size = 32, _tick = 25316, _time = 1.6548e+09, train_seconds = 2.4658e+04)
[2022-06-10 02:59:03,206][root][INFO] - Step 93537280 @ 4092.8 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 93537280, mean_episode_return = None, mean_episode_step = 5645.4, total_loss = -16.926, pg_loss = -6.0486, baseline_loss = 0.17216, entropy_loss = -11.05, learner_queue_size = 32, _tick = 25316, _time = 1.6548e+09, train_seconds = 2.4663e+04)
[2022-06-10 02:59:08,210][root][INFO] - Step 93555200 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 93555200, mean_episode_return = None, mean_episode_step = 5719.3, total_loss = -18.678, pg_loss = -7.7908, baseline_loss = 0.1663, entropy_loss = -11.053, learner_queue_size = 32, _tick = 25316, _time = 1.6548e+09, train_seconds = 2.4668e+04)
[2022-06-10 02:59:13,214][root][INFO] - Step 93575680 @ 4092.7 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 93575680, mean_episode_return = None, mean_episode_step = 5796.0, total_loss = -5.1273, pg_loss = 5.7631, baseline_loss = 0.16326, entropy_loss = -11.054, learner_queue_size = 32, _tick = 25316, _time = 1.6548e+09, train_seconds = 2.4673e+04)
[2022-06-10 02:59:18,222][root][INFO] - Step 93596160 @ 4089.3 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 93596160, mean_episode_return = None, mean_episode_step = 5633.9, total_loss = -14.805, pg_loss = -3.9179, baseline_loss = 0.17635, entropy_loss = -11.064, learner_queue_size = 32, _tick = 25316, _time = 1.6548e+09, train_seconds = 2.4678e+04)
[2022-06-10 02:59:23,226][root][INFO] - Step 93616640 @ 4092.9 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (step = 93616640, mean_episode_return = None, mean_episode_step = 5556.5, total_loss = -5.4045, pg_loss = 5.5003, baseline_loss = 0.15392, entropy_loss = -11.059, learner_queue_size = 32, _tick = 25316, _time = 1.6548e+09, train_seconds = 2.4683e+04)
[2022-06-10 02:59:28,230][root][INFO] - Step 93634560 @ 3581.1 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 93634560, mean_episode_return = None, mean_episode_step = 5750.2, total_loss = -11.342, pg_loss = -0.45467, baseline_loss = 0.16874, entropy_loss = -11.056, learner_queue_size = 32, _tick = 25316, _time = 1.6548e+09, train_seconds = 2.4688e+04)
[2022-06-10 02:59:33,234][root][INFO] - Step 93655040 @ 4092.7 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 93655040, mean_episode_return = None, mean_episode_step = 5686.2, total_loss = -8.247, pg_loss = 2.6323, baseline_loss = 0.17576, entropy_loss = -11.055, learner_queue_size = 32, _tick = 25317, _time = 1.6548e+09, train_seconds = 2.4693e+04)
[2022-06-10 02:59:38,238][root][INFO] - Step 93675520 @ 4092.7 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 93675520, mean_episode_return = None, mean_episode_step = 5994.2, total_loss = -24.196, pg_loss = -13.291, baseline_loss = 0.15188, entropy_loss = -11.056, learner_queue_size = 32, _tick = 25317, _time = 1.6548e+09, train_seconds = 2.4698e+04)
[2022-06-10 02:59:43,242][root][INFO] - Step 93696000 @ 4092.7 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 93696000, mean_episode_return = None, mean_episode_step = 6196.5, total_loss = -6.8483, pg_loss = 4.0599, baseline_loss = 0.15717, entropy_loss = -11.065, learner_queue_size = 32, _tick = 25317, _time = 1.6548e+09, train_seconds = 2.4703e+04)
[2022-06-10 02:59:48,246][root][INFO] - Step 93716480 @ 4092.4 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 93716480, mean_episode_return = None, mean_episode_step = 6096.9, total_loss = 105.78, pg_loss = 105.81, baseline_loss = 10.9, entropy_loss = -10.93, learner_queue_size = 32, _tick = 25318, _time = 1.6548e+09, train_seconds = 2.4708e+04)
[2022-06-10 02:59:53,250][root][INFO] - Step 93734400 @ 3581.4 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 93734400, mean_episode_return = None, mean_episode_step = 6355.0, total_loss = -13.274, pg_loss = -2.3517, baseline_loss = 0.14639, entropy_loss = -11.068, learner_queue_size = 32, _tick = 25318, _time = 1.6548e+09, train_seconds = 2.4713e+04)
[2022-06-10 02:59:58,254][root][INFO] - Step 93754880 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 93754880, mean_episode_return = None, mean_episode_step = 6344.2, total_loss = -6.9695, pg_loss = 3.9559, baseline_loss = 0.14348, entropy_loss = -11.069, learner_queue_size = 32, _tick = 25318, _time = 1.6548e+09, train_seconds = 2.4718e+04)
[2022-06-10 03:00:03,259][root][INFO] - Step 93775360 @ 4092.1 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 93775360, mean_episode_return = None, mean_episode_step = 6221.8, total_loss = -10.845, pg_loss = 0.075841, baseline_loss = 0.14517, entropy_loss = -11.066, learner_queue_size = 32, _tick = 25318, _time = 1.6548e+09, train_seconds = 2.4723e+04)
[2022-06-10 03:00:08,262][root][INFO] - Step 93795840 @ 4093.4 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 93795840, mean_episode_return = None, mean_episode_step = 6512.8, total_loss = -18.257, pg_loss = -7.3444, baseline_loss = 0.15383, entropy_loss = -11.067, learner_queue_size = 32, _tick = 25318, _time = 1.6548e+09, train_seconds = 2.4728e+04)
[2022-06-10 03:00:13,264][root][INFO] - Step 93813760 @ 3582.6 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 93813760, mean_episode_return = None, mean_episode_step = 6547.0, total_loss = -13.296, pg_loss = -2.6512, baseline_loss = 0.20882, entropy_loss = -10.853, learner_queue_size = 32, _tick = 25318, _time = 1.6548e+09, train_seconds = 2.4733e+04)
[2022-06-10 03:00:18,266][root][INFO] - Step 93834240 @ 4094.3 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 93834240, mean_episode_return = None, mean_episode_step = 6744.1, total_loss = 2.3296, pg_loss = 13.207, baseline_loss = 0.17802, entropy_loss = -11.055, learner_queue_size = 32, _tick = 25318, _time = 1.6548e+09, train_seconds = 2.4738e+04)
[2022-06-10 03:00:23,270][root][INFO] - Step 93854720 @ 4092.6 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 93854720, mean_episode_return = None, mean_episode_step = 6819.4, total_loss = -22.56, pg_loss = -11.655, baseline_loss = 0.16037, entropy_loss = -11.065, learner_queue_size = 32, _tick = 25318, _time = 1.6548e+09, train_seconds = 2.4743e+04)
[2022-06-10 03:00:28,274][root][INFO] - Step 93875200 @ 4092.8 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 93875200, mean_episode_return = None, mean_episode_step = 6575.3, total_loss = -1.1563, pg_loss = 9.7424, baseline_loss = 0.17277, entropy_loss = -11.071, learner_queue_size = 32, _tick = 25318, _time = 1.6548e+09, train_seconds = 2.4748e+04)
[2022-06-10 03:00:33,278][root][INFO] - Step 93893120 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 93893120, mean_episode_return = None, mean_episode_step = 6916.1, total_loss = -7.9321, pg_loss = 2.9939, baseline_loss = 0.15372, entropy_loss = -11.08, learner_queue_size = 32, _tick = 25318, _time = 1.6548e+09, train_seconds = 2.4753e+04)
[2022-06-10 03:00:38,282][root][INFO] - Step 93913600 @ 4092.5 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 93913600, mean_episode_return = None, mean_episode_step = 7012.8, total_loss = -28.091, pg_loss = -17.159, baseline_loss = 0.14935, entropy_loss = -11.081, learner_queue_size = 32, _tick = 25318, _time = 1.6548e+09, train_seconds = 2.4758e+04)
[2022-06-10 03:00:43,286][root][INFO] - Step 93934080 @ 4093.0 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (step = 93934080, mean_episode_return = None, mean_episode_step = 6797.9, total_loss = -13.0, pg_loss = -2.0565, baseline_loss = 0.13606, entropy_loss = -11.079, learner_queue_size = 32, _tick = 25319, _time = 1.6548e+09, train_seconds = 2.4763e+04)
[2022-06-10 03:00:48,290][root][INFO] - Step 93954560 @ 4092.6 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 93954560, mean_episode_return = None, mean_episode_step = 7218.0, total_loss = -16.784, pg_loss = -5.86, baseline_loss = 0.15109, entropy_loss = -11.075, learner_queue_size = 32, _tick = 25319, _time = 1.6548e+09, train_seconds = 2.4768e+04)
[2022-06-10 03:00:53,294][root][INFO] - Step 93975040 @ 4092.9 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 93975040, mean_episode_return = None, mean_episode_step = 6961.4, total_loss = -11.242, pg_loss = -0.33824, baseline_loss = 0.1652, entropy_loss = -11.069, learner_queue_size = 32, _tick = 25319, _time = 1.6548e+09, train_seconds = 2.4773e+04)
[2022-06-10 03:00:58,298][root][INFO] - Step 93992960 @ 3581.1 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 93992960, mean_episode_return = None, mean_episode_step = 7280.7, total_loss = -11.052, pg_loss = -0.13804, baseline_loss = 0.15889, entropy_loss = -11.073, learner_queue_size = 32, _tick = 25319, _time = 1.6548e+09, train_seconds = 2.4778e+04)
[2022-06-10 03:01:03,302][root][INFO] - Step 94013440 @ 4092.8 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 94013440, mean_episode_return = None, mean_episode_step = 7591.0, total_loss = -21.346, pg_loss = -10.41, baseline_loss = 0.14233, entropy_loss = -11.079, learner_queue_size = 32, _tick = 25319, _time = 1.6548e+09, train_seconds = 2.4783e+04)
[2022-06-10 03:01:08,306][root][INFO] - Step 94033920 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 94033920, mean_episode_return = None, mean_episode_step = 7707.5, total_loss = -7.6956, pg_loss = 3.2432, baseline_loss = 0.13502, entropy_loss = -11.074, learner_queue_size = 32, _tick = 25320, _time = 1.6548e+09, train_seconds = 2.4788e+04)
[2022-06-10 03:01:13,310][root][INFO] - Step 94054400 @ 4092.6 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (step = 94054400, mean_episode_return = None, mean_episode_step = 7383.2, total_loss = -14.545, pg_loss = -3.6288, baseline_loss = 0.15682, entropy_loss = -11.073, learner_queue_size = 32, _tick = 25320, _time = 1.6548e+09, train_seconds = 2.4793e+04)
[2022-06-10 03:01:18,314][root][INFO] - Step 94072320 @ 3581.2 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 94072320, mean_episode_return = None, mean_episode_step = 7601.0, total_loss = -6.9015, pg_loss = 4.0233, baseline_loss = 0.14194, entropy_loss = -11.067, learner_queue_size = 32, _tick = 25320, _time = 1.6548e+09, train_seconds = 2.4798e+04)
[2022-06-10 03:01:23,318][root][INFO] - Step 94092800 @ 4092.8 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (step = 94092800, mean_episode_return = None, mean_episode_step = 7205.4, total_loss = -8.6274, pg_loss = 2.2873, baseline_loss = 0.15599, entropy_loss = -11.071, learner_queue_size = 32, _tick = 25320, _time = 1.6548e+09, train_seconds = 2.4803e+04)
[2022-06-10 03:01:28,322][root][INFO] - Step 94113280 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 94113280, mean_episode_return = None, mean_episode_step = 7314.1, total_loss = -12.082, pg_loss = -1.1624, baseline_loss = 0.14569, entropy_loss = -11.065, learner_queue_size = 32, _tick = 25320, _time = 1.6548e+09, train_seconds = 2.4808e+04)
[2022-06-10 03:01:33,328][root][INFO] - Step 94131200 @ 3579.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 94131200, mean_episode_return = None, mean_episode_step = 7674.7, total_loss = -12.246, pg_loss = -1.3273, baseline_loss = 0.14438, entropy_loss = -11.063, learner_queue_size = 32, _tick = 25320, _time = 1.6548e+09, train_seconds = 2.4813e+04)
[2022-06-10 03:01:38,334][root][INFO] - Step 94151680 @ 4091.1 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 94151680, mean_episode_return = None, mean_episode_step = 7691.3, total_loss = -17.434, pg_loss = -6.5111, baseline_loss = 0.14625, entropy_loss = -11.069, learner_queue_size = 32, _tick = 25320, _time = 1.6548e+09, train_seconds = 2.4818e+04)
[2022-06-10 03:01:43,338][root][INFO] - Step 94172160 @ 4092.8 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 94172160, mean_episode_return = None, mean_episode_step = 7970.8, total_loss = -15.373, pg_loss = -4.4486, baseline_loss = 0.14068, entropy_loss = -11.065, learner_queue_size = 32, _tick = 25320, _time = 1.6548e+09, train_seconds = 2.4823e+04)
[2022-06-10 03:01:48,342][root][INFO] - Step 94192640 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 94192640, mean_episode_return = None, mean_episode_step = 7857.0, total_loss = -9.8032, pg_loss = 1.134, baseline_loss = 0.1363, entropy_loss = -11.073, learner_queue_size = 32, _tick = 25320, _time = 1.6548e+09, train_seconds = 2.4828e+04)
[2022-06-10 03:01:53,346][root][INFO] - Step 94213120 @ 4092.7 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 94213120, mean_episode_return = None, mean_episode_step = 8339.1, total_loss = -7.0613, pg_loss = 3.8693, baseline_loss = 0.14993, entropy_loss = -11.081, learner_queue_size = 32, _tick = 25320, _time = 1.6548e+09, train_seconds = 2.4833e+04)
[2022-06-10 03:01:58,350][root][INFO] - Step 94233600 @ 4092.7 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (step = 94233600, mean_episode_return = None, mean_episode_step = 8401.4, total_loss = -18.252, pg_loss = -7.3212, baseline_loss = 0.14622, entropy_loss = -11.077, learner_queue_size = 32, _tick = 25320, _time = 1.6548e+09, train_seconds = 2.4838e+04)
[2022-06-10 03:02:03,354][root][INFO] - Step 94254080 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 94254080, mean_episode_return = None, mean_episode_step = 8072.4, total_loss = -9.947, pg_loss = 0.95891, baseline_loss = 0.16899, entropy_loss = -11.075, learner_queue_size = 32, _tick = 25320, _time = 1.6548e+09, train_seconds = 2.4843e+04)
[2022-06-10 03:02:08,358][root][INFO] - Step 94272000 @ 3581.2 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 94272000, mean_episode_return = None, mean_episode_step = 8226.7, total_loss = -19.572, pg_loss = -8.626, baseline_loss = 0.13038, entropy_loss = -11.076, learner_queue_size = 32, _tick = 25320, _time = 1.6548e+09, train_seconds = 2.4848e+04)
[2022-06-10 03:02:13,362][root][INFO] - Step 94292480 @ 4092.7 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 94292480, mean_episode_return = None, mean_episode_step = 8111.2, total_loss = -19.212, pg_loss = -8.2844, baseline_loss = 0.1525, entropy_loss = -11.08, learner_queue_size = 32, _tick = 25320, _time = 1.6548e+09, train_seconds = 2.4853e+04)
[2022-06-10 03:02:18,366][root][INFO] - Step 94312960 @ 4092.8 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (step = 94312960, mean_episode_return = None, mean_episode_step = 8297.7, total_loss = -15.195, pg_loss = -4.2763, baseline_loss = 0.15789, entropy_loss = -11.076, learner_queue_size = 32, _tick = 25320, _time = 1.6548e+09, train_seconds = 2.4858e+04)
[2022-06-10 03:02:23,370][root][INFO] - Step 94330880 @ 3581.1 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 94330880, mean_episode_return = None, mean_episode_step = 8713.1, total_loss = -14.612, pg_loss = -3.6763, baseline_loss = 0.13752, entropy_loss = -11.073, learner_queue_size = 32, _tick = 25320, _time = 1.6548e+09, train_seconds = 2.4863e+04)
[2022-06-10 03:02:28,374][root][INFO] - Step 94351360 @ 4092.6 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 94351360, mean_episode_return = None, mean_episode_step = 8401.2, total_loss = -13.44, pg_loss = -2.527, baseline_loss = 0.15583, entropy_loss = -11.069, learner_queue_size = 32, _tick = 25320, _time = 1.6548e+09, train_seconds = 2.4868e+04)
[2022-06-10 03:02:33,378][root][INFO] - Step 94371840 @ 4092.8 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 94371840, mean_episode_return = None, mean_episode_step = 8073.2, total_loss = -16.762, pg_loss = -5.826, baseline_loss = 0.1345, entropy_loss = -11.071, learner_queue_size = 32, _tick = 25320, _time = 1.6548e+09, train_seconds = 2.4873e+04)
[2022-06-10 03:02:38,382][root][INFO] - Step 94392320 @ 4092.6 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 94392320, mean_episode_return = None, mean_episode_step = 8586.4, total_loss = -2.142, pg_loss = 8.7889, baseline_loss = 0.14636, entropy_loss = -11.077, learner_queue_size = 32, _tick = 25320, _time = 1.6548e+09, train_seconds = 2.4878e+04)
[2022-06-10 03:02:43,387][root][INFO] - Step 94410240 @ 3580.5 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 94410240, mean_episode_return = None, mean_episode_step = 9074.4, total_loss = -6.3509, pg_loss = 4.585, baseline_loss = 0.14293, entropy_loss = -11.079, learner_queue_size = 32, _tick = 25320, _time = 1.6548e+09, train_seconds = 2.4883e+04)
[2022-06-10 03:02:48,390][root][INFO] - Step 94430720 @ 4093.5 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 94430720, mean_episode_return = None, mean_episode_step = 8925.0, total_loss = -6.2989, pg_loss = 4.6292, baseline_loss = 0.14288, entropy_loss = -11.071, learner_queue_size = 32, _tick = 25320, _time = 1.6548e+09, train_seconds = 2.4888e+04)
[2022-06-10 03:02:53,394][root][INFO] - Step 94451200 @ 4092.5 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 94451200, mean_episode_return = None, mean_episode_step = 8515.6, total_loss = -8.7168, pg_loss = 2.2035, baseline_loss = 0.14821, entropy_loss = -11.069, learner_queue_size = 32, _tick = 25320, _time = 1.6548e+09, train_seconds = 2.4893e+04)
[2022-06-10 03:02:58,402][root][INFO] - Step 94471680 @ 4089.5 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 94471680, mean_episode_return = None, mean_episode_step = 8960.8, total_loss = -7.876, pg_loss = 3.0348, baseline_loss = 0.14083, entropy_loss = -11.052, learner_queue_size = 32, _tick = 25320, _time = 1.6548e+09, train_seconds = 2.4898e+04)
[2022-06-10 03:03:03,406][root][INFO] - Step 94492160 @ 4093.0 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 94492160, mean_episode_return = None, mean_episode_step = 8717.2, total_loss = -31.325, pg_loss = -20.967, baseline_loss = 0.69354, entropy_loss = -11.052, learner_queue_size = 32, _tick = 25320, _time = 1.6548e+09, train_seconds = 2.4903e+04)
[2022-06-10 03:03:08,410][root][INFO] - Step 94512640 @ 4092.7 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 94512640, mean_episode_return = None, mean_episode_step = 9299.4, total_loss = -10.455, pg_loss = 0.46967, baseline_loss = 0.13177, entropy_loss = -11.056, learner_queue_size = 32, _tick = 25320, _time = 1.6548e+09, train_seconds = 2.4908e+04)
[2022-06-10 03:03:13,417][root][INFO] - Step 94530560 @ 3579.0 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 94530560, mean_episode_return = None, mean_episode_step = 9550.9, total_loss = -17.839, pg_loss = -6.923, baseline_loss = 0.13734, entropy_loss = -11.053, learner_queue_size = 32, _tick = 25320, _time = 1.6548e+09, train_seconds = 2.4913e+04)
[2022-06-10 03:03:18,422][root][INFO] - Step 94551040 @ 4091.8 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (step = 94551040, mean_episode_return = None, mean_episode_step = 9238.5, total_loss = -27.214, pg_loss = -16.291, baseline_loss = 0.13065, entropy_loss = -11.054, learner_queue_size = 32, _tick = 25321, _time = 1.6548e+09, train_seconds = 2.4918e+04)
[2022-06-10 03:03:23,426][root][INFO] - Step 94571520 @ 4092.7 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 94571520, mean_episode_return = None, mean_episode_step = 9467.0, total_loss = -16.684, pg_loss = -5.7637, baseline_loss = 0.13786, entropy_loss = -11.058, learner_queue_size = 32, _tick = 25321, _time = 1.6548e+09, train_seconds = 2.4923e+04)
[2022-06-10 03:03:28,430][root][INFO] - Step 94592000 @ 4092.7 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 94592000, mean_episode_return = None, mean_episode_step = 9585.0, total_loss = -13.698, pg_loss = -2.7785, baseline_loss = 0.14303, entropy_loss = -11.063, learner_queue_size = 32, _tick = 25321, _time = 1.6548e+09, train_seconds = 2.4928e+04)
[2022-06-10 03:03:33,434][root][INFO] - Step 94609920 @ 3581.1 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (step = 94609920, mean_episode_return = None, mean_episode_step = 9813.9, total_loss = -11.142, pg_loss = -0.20968, baseline_loss = 0.1297, entropy_loss = -11.062, learner_queue_size = 32, _tick = 25321, _time = 1.6548e+09, train_seconds = 2.4933e+04)
[2022-06-10 03:03:38,438][root][INFO] - Step 94630400 @ 4092.7 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 94630400, mean_episode_return = None, mean_episode_step = 9541.3, total_loss = -19.241, pg_loss = -8.3131, baseline_loss = 0.13724, entropy_loss = -11.065, learner_queue_size = 32, _tick = 25321, _time = 1.6548e+09, train_seconds = 2.4938e+04)
[2022-06-10 03:03:43,442][root][INFO] - Step 94648320 @ 3581.1 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 94648320, mean_episode_return = None, mean_episode_step = 1.0167e+04, total_loss = -13.725, pg_loss = -2.7955, baseline_loss = 0.13917, entropy_loss = -11.069, learner_queue_size = 32, _tick = 25321, _time = 1.6548e+09, train_seconds = 2.4943e+04)
[2022-06-10 03:03:48,446][root][INFO] - Step 94668800 @ 4092.8 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 94668800, mean_episode_return = None, mean_episode_step = 9790.3, total_loss = -3.1237, pg_loss = 7.8172, baseline_loss = 0.1349, entropy_loss = -11.076, learner_queue_size = 32, _tick = 25321, _time = 1.6548e+09, train_seconds = 2.4948e+04)
[2022-06-10 03:03:53,450][root][INFO] - Step 94689280 @ 4092.7 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 94689280, mean_episode_return = None, mean_episode_step = 9947.6, total_loss = -19.041, pg_loss = -8.1021, baseline_loss = 0.13724, entropy_loss = -11.076, learner_queue_size = 32, _tick = 25321, _time = 1.6548e+09, train_seconds = 2.4953e+04)
[2022-06-10 03:03:58,454][root][INFO] - Step 94709760 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 94709760, mean_episode_return = None, mean_episode_step = 9830.9, total_loss = -10.14, pg_loss = 0.80057, baseline_loss = 0.13932, entropy_loss = -11.08, learner_queue_size = 32, _tick = 25321, _time = 1.6548e+09, train_seconds = 2.4958e+04)
[2022-06-10 03:04:03,458][root][INFO] - Step 94727680 @ 3581.2 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 94727680, mean_episode_return = None, mean_episode_step = 1.0055e+04, total_loss = -10.199, pg_loss = 0.73715, baseline_loss = 0.13688, entropy_loss = -11.073, learner_queue_size = 32, _tick = 25322, _time = 1.6548e+09, train_seconds = 2.4963e+04)
[2022-06-10 03:04:08,462][root][INFO] - Step 94748160 @ 4092.7 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (step = 94748160, mean_episode_return = None, mean_episode_step = 1.0159e+04, total_loss = -9.7768, pg_loss = 1.1606, baseline_loss = 0.13289, entropy_loss = -11.07, learner_queue_size = 32, _tick = 25322, _time = 1.6548e+09, train_seconds = 2.4968e+04)
[2022-06-10 03:04:13,466][root][INFO] - Step 94768640 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 94768640, mean_episode_return = None, mean_episode_step = 1.0235e+04, total_loss = -19.713, pg_loss = -8.7883, baseline_loss = 0.1185, entropy_loss = -11.044, learner_queue_size = 32, _tick = 25324, _time = 1.6548e+09, train_seconds = 2.4973e+04)
[2022-06-10 03:04:18,470][root][INFO] - Step 94789120 @ 4092.7 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 94789120, mean_episode_return = -3.3675, mean_episode_step = 1.0315e+04, total_loss = 23.848, pg_loss = 33.212, baseline_loss = 1.6886, entropy_loss = -11.052, learner_queue_size = 32, _tick = 25326, _time = 1.6548e+09, train_seconds = 2.4978e+04)
[2022-06-10 03:04:23,475][root][INFO] - Step 94809600 @ 4091.9 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 94809600, mean_episode_return = None, mean_episode_step = 9732.2, total_loss = -14.913, pg_loss = -3.992, baseline_loss = 0.11804, entropy_loss = -11.039, learner_queue_size = 32, _tick = 25328, _time = 1.6548e+09, train_seconds = 2.4983e+04)
[2022-06-10 03:04:28,478][root][INFO] - Step 94827520 @ 3581.9 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (step = 94827520, mean_episode_return = -100.54, mean_episode_step = 1.0093e+04, total_loss = 10.125, pg_loss = 20.33, baseline_loss = 0.84748, entropy_loss = -11.052, learner_queue_size = 32, _tick = 25331, _time = 1.6548e+09, train_seconds = 2.4988e+04)
[2022-06-10 03:04:33,482][root][INFO] - Step 94848000 @ 4092.7 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 94848000, mean_episode_return = None, mean_episode_step = 9728.7, total_loss = -24.482, pg_loss = -13.547, baseline_loss = 0.1057, entropy_loss = -11.04, learner_queue_size = 32, _tick = 25333, _time = 1.6548e+09, train_seconds = 2.4993e+04)
[2022-06-10 03:04:38,487][root][INFO] - Step 94868480 @ 4092.0 SPS. Inference batcher size: 90. Learner queue size: 32. Other stats: (step = 94868480, mean_episode_return = None, mean_episode_step = 1.0197e+04, total_loss = -14.326, pg_loss = -3.4212, baseline_loss = 0.1352, entropy_loss = -11.04, learner_queue_size = 32, _tick = 25334, _time = 1.6548e+09, train_seconds = 2.4998e+04)
[2022-06-10 03:04:43,490][root][INFO] - Step 94886400 @ 3581.8 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 94886400, mean_episode_return = None, mean_episode_step = 1.0768e+04, total_loss = -7.375, pg_loss = 3.5399, baseline_loss = 0.13532, entropy_loss = -11.05, learner_queue_size = 32, _tick = 25334, _time = 1.6548e+09, train_seconds = 2.5003e+04)
[2022-06-10 03:04:48,494][root][INFO] - Step 94906880 @ 4092.7 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 94906880, mean_episode_return = None, mean_episode_step = 9765.8, total_loss = -6.2469, pg_loss = 4.688, baseline_loss = 0.12558, entropy_loss = -11.06, learner_queue_size = 32, _tick = 25336, _time = 1.6548e+09, train_seconds = 2.5008e+04)
[2022-06-10 03:04:53,498][root][INFO] - Step 94927360 @ 4092.7 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 94927360, mean_episode_return = None, mean_episode_step = 1.0181e+04, total_loss = -21.433, pg_loss = -10.508, baseline_loss = 0.13322, entropy_loss = -11.058, learner_queue_size = 32, _tick = 25338, _time = 1.6548e+09, train_seconds = 2.5013e+04)
[2022-06-10 03:04:58,502][root][INFO] - Step 94945280 @ 3581.2 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 94945280, mean_episode_return = None, mean_episode_step = 1.0231e+04, total_loss = -5.4801, pg_loss = 5.4324, baseline_loss = 0.15266, entropy_loss = -11.065, learner_queue_size = 32, _tick = 25338, _time = 1.6548e+09, train_seconds = 2.5018e+04)
[2022-06-10 03:05:03,510][root][INFO] - Step 94965760 @ 4089.5 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 94965760, mean_episode_return = None, mean_episode_step = 1.0893e+04, total_loss = -9.8898, pg_loss = 1.0355, baseline_loss = 0.13691, entropy_loss = -11.062, learner_queue_size = 32, _tick = 25339, _time = 1.6548e+09, train_seconds = 2.5023e+04)
[2022-06-10 03:05:08,514][root][INFO] - Step 94986240 @ 4092.6 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 94986240, mean_episode_return = None, mean_episode_step = 9570.9, total_loss = -8.8675, pg_loss = 2.0649, baseline_loss = 0.129, entropy_loss = -11.061, learner_queue_size = 32, _tick = 25340, _time = 1.6548e+09, train_seconds = 2.5028e+04)
[2022-06-10 03:05:13,518][root][INFO] - Step 95006720 @ 4092.8 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 95006720, mean_episode_return = None, mean_episode_step = 1.096e+04, total_loss = -12.76, pg_loss = -1.8183, baseline_loss = 0.12179, entropy_loss = -11.063, learner_queue_size = 32, _tick = 25342, _time = 1.6548e+09, train_seconds = 2.5033e+04)
[2022-06-10 03:05:18,522][root][INFO] - Step 95024640 @ 3581.1 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 95024640, mean_episode_return = None, mean_episode_step = 1.0587e+04, total_loss = -17.366, pg_loss = -6.4106, baseline_loss = 0.11111, entropy_loss = -11.066, learner_queue_size = 32, _tick = 25343, _time = 1.6548e+09, train_seconds = 2.5038e+04)
[2022-06-10 03:05:23,526][root][INFO] - Step 95045120 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 95045120, mean_episode_return = None, mean_episode_step = 9255.8, total_loss = -14.361, pg_loss = -3.4218, baseline_loss = 0.11864, entropy_loss = -11.058, learner_queue_size = 32, _tick = 25345, _time = 1.6548e+09, train_seconds = 2.5043e+04)
[2022-06-10 03:05:28,530][root][INFO] - Step 95065600 @ 4092.7 SPS. Inference batcher size: 93. Learner queue size: 32. Other stats: (step = 95065600, mean_episode_return = None, mean_episode_step = 9423.3, total_loss = -5.5954, pg_loss = 5.3119, baseline_loss = 0.14496, entropy_loss = -11.052, learner_queue_size = 32, _tick = 25345, _time = 1.6548e+09, train_seconds = 2.5048e+04)
[2022-06-10 03:05:33,542][root][INFO] - Step 95083520 @ 3575.4 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 95083520, mean_episode_return = None, mean_episode_step = 1.0493e+04, total_loss = -13.855, pg_loss = -2.9275, baseline_loss = 0.13209, entropy_loss = -11.06, learner_queue_size = 32, _tick = 25346, _time = 1.6548e+09, train_seconds = 2.5053e+04)
[2022-06-10 03:05:38,546][root][INFO] - Step 95104000 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 95104000, mean_episode_return = None, mean_episode_step = 1.0129e+04, total_loss = -13.657, pg_loss = -2.713, baseline_loss = 0.12414, entropy_loss = -11.068, learner_queue_size = 32, _tick = 25346, _time = 1.6548e+09, train_seconds = 2.5058e+04)
[2022-06-10 03:05:43,550][root][INFO] - Step 95124480 @ 4092.8 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 95124480, mean_episode_return = None, mean_episode_step = 1.0964e+04, total_loss = -17.084, pg_loss = -6.1433, baseline_loss = 0.13216, entropy_loss = -11.073, learner_queue_size = 32, _tick = 25347, _time = 1.6548e+09, train_seconds = 2.5063e+04)
[2022-06-10 03:05:48,554][root][INFO] - Step 95144960 @ 4092.7 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 95144960, mean_episode_return = None, mean_episode_step = 1.0676e+04, total_loss = -7.8535, pg_loss = 3.0839, baseline_loss = 0.13373, entropy_loss = -11.071, learner_queue_size = 32, _tick = 25348, _time = 1.6548e+09, train_seconds = 2.5068e+04)
[2022-06-10 03:05:53,558][root][INFO] - Step 95165440 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 95165440, mean_episode_return = None, mean_episode_step = 1.0874e+04, total_loss = -15.513, pg_loss = -4.5752, baseline_loss = 0.13094, entropy_loss = -11.069, learner_queue_size = 32, _tick = 25349, _time = 1.6548e+09, train_seconds = 2.5073e+04)
[2022-06-10 03:05:58,562][root][INFO] - Step 95185920 @ 4092.6 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 95185920, mean_episode_return = None, mean_episode_step = 1.0879e+04, total_loss = -11.038, pg_loss = -0.093099, baseline_loss = 0.12914, entropy_loss = -11.074, learner_queue_size = 32, _tick = 25349, _time = 1.6548e+09, train_seconds = 2.5078e+04)
[2022-06-10 03:06:03,566][root][INFO] - Step 95206400 @ 4092.9 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 95206400, mean_episode_return = None, mean_episode_step = 1.0362e+04, total_loss = 53.14, pg_loss = 62.411, baseline_loss = 1.802, entropy_loss = -11.073, learner_queue_size = 32, _tick = 25349, _time = 1.6548e+09, train_seconds = 2.5083e+04)
[2022-06-10 03:06:08,570][root][INFO] - Step 95226880 @ 4092.7 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 95226880, mean_episode_return = -73.377, mean_episode_step = 1.1592e+04, total_loss = 15.073, pg_loss = 25.05, baseline_loss = 1.1046, entropy_loss = -11.081, learner_queue_size = 32, _tick = 25350, _time = 1.6548e+09, train_seconds = 2.5088e+04)
[2022-06-10 03:06:13,574][root][INFO] - Step 95244800 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 95244800, mean_episode_return = None, mean_episode_step = 1.2091e+04, total_loss = -26.034, pg_loss = -15.083, baseline_loss = 0.1245, entropy_loss = -11.076, learner_queue_size = 32, _tick = 25350, _time = 1.6548e+09, train_seconds = 2.5093e+04)
[2022-06-10 03:06:18,578][root][INFO] - Step 95265280 @ 4092.7 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 95265280, mean_episode_return = None, mean_episode_step = 9871.4, total_loss = -9.7654, pg_loss = 1.1753, baseline_loss = 0.13147, entropy_loss = -11.072, learner_queue_size = 32, _tick = 25350, _time = 1.6548e+09, train_seconds = 2.5098e+04)
[2022-06-10 03:06:23,582][root][INFO] - Step 95285760 @ 4092.6 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 95285760, mean_episode_return = None, mean_episode_step = 1.131e+04, total_loss = -11.487, pg_loss = -0.53352, baseline_loss = 0.13055, entropy_loss = -11.084, learner_queue_size = 32, _tick = 25350, _time = 1.6548e+09, train_seconds = 2.5103e+04)
[2022-06-10 03:06:28,586][root][INFO] - Step 95303680 @ 3581.2 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 95303680, mean_episode_return = None, mean_episode_step = 1.0108e+04, total_loss = -13.787, pg_loss = -2.839, baseline_loss = 0.13474, entropy_loss = -11.083, learner_queue_size = 32, _tick = 25350, _time = 1.6548e+09, train_seconds = 2.5108e+04)
[2022-06-10 03:06:33,591][root][INFO] - Step 95324160 @ 4092.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 95324160, mean_episode_return = None, mean_episode_step = 1.1709e+04, total_loss = -10.042, pg_loss = 0.91716, baseline_loss = 0.12325, entropy_loss = -11.083, learner_queue_size = 32, _tick = 25350, _time = 1.6548e+09, train_seconds = 2.5113e+04)
[2022-06-10 03:06:38,594][root][INFO] - Step 95344640 @ 4093.4 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 95344640, mean_episode_return = None, mean_episode_step = 1.1232e+04, total_loss = -10.161, pg_loss = 0.77337, baseline_loss = 0.14335, entropy_loss = -11.077, learner_queue_size = 32, _tick = 25350, _time = 1.6548e+09, train_seconds = 2.5118e+04)
[2022-06-10 03:06:43,598][root][INFO] - Step 95362560 @ 3581.1 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 95362560, mean_episode_return = None, mean_episode_step = 1.1311e+04, total_loss = -13.803, pg_loss = -2.8493, baseline_loss = 0.12954, entropy_loss = -11.083, learner_queue_size = 32, _tick = 25350, _time = 1.6548e+09, train_seconds = 2.5123e+04)
[2022-06-10 03:06:48,602][root][INFO] - Step 95383040 @ 4092.8 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 95383040, mean_episode_return = None, mean_episode_step = 1.1335e+04, total_loss = -15.942, pg_loss = -5.0047, baseline_loss = 0.14666, entropy_loss = -11.084, learner_queue_size = 32, _tick = 25350, _time = 1.6548e+09, train_seconds = 2.5128e+04)
[2022-06-10 03:06:53,608][root][INFO] - Step 95403520 @ 4091.5 SPS. Inference batcher size: 82. Learner queue size: 32. Other stats: (step = 95403520, mean_episode_return = None, mean_episode_step = 1.0784e+04, total_loss = -67.491, pg_loss = -59.01, baseline_loss = 2.6113, entropy_loss = -11.092, learner_queue_size = 32, _tick = 25350, _time = 1.6548e+09, train_seconds = 2.5133e+04)
[2022-06-10 03:06:58,610][root][INFO] - Step 95424000 @ 4094.0 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 95424000, mean_episode_return = None, mean_episode_step = 1.1652e+04, total_loss = -11.307, pg_loss = -0.35113, baseline_loss = 0.12325, entropy_loss = -11.079, learner_queue_size = 32, _tick = 25351, _time = 1.6548e+09, train_seconds = 2.5138e+04)
[2022-06-10 03:07:03,614][root][INFO] - Step 95441920 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 95441920, mean_episode_return = None, mean_episode_step = 1.1211e+04, total_loss = -10.09, pg_loss = 0.85397, baseline_loss = 0.1343, entropy_loss = -11.078, learner_queue_size = 32, _tick = 25351, _time = 1.6548e+09, train_seconds = 2.5143e+04)
[2022-06-10 03:07:08,618][root][INFO] - Step 95462400 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 95462400, mean_episode_return = None, mean_episode_step = 1.215e+04, total_loss = -25.34, pg_loss = -14.388, baseline_loss = 0.12499, entropy_loss = -11.077, learner_queue_size = 32, _tick = 25352, _time = 1.6548e+09, train_seconds = 2.5148e+04)
[2022-06-10 03:07:13,622][root][INFO] - Step 95480320 @ 3581.1 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 95480320, mean_episode_return = None, mean_episode_step = 1.2112e+04, total_loss = -15.542, pg_loss = -4.5827, baseline_loss = 0.11995, entropy_loss = -11.079, learner_queue_size = 32, _tick = 25353, _time = 1.6548e+09, train_seconds = 2.5153e+04)
[2022-06-10 03:07:18,626][root][INFO] - Step 95500800 @ 4092.7 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 95500800, mean_episode_return = None, mean_episode_step = 1.0852e+04, total_loss = -6.6693, pg_loss = 4.2786, baseline_loss = 0.12962, entropy_loss = -11.078, learner_queue_size = 32, _tick = 25353, _time = 1.6548e+09, train_seconds = 2.5158e+04)
[2022-06-10 03:07:23,630][root][INFO] - Step 95523840 @ 4604.2 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 95523840, mean_episode_return = -140.14, mean_episode_step = 1.1707e+04, total_loss = 44.678, pg_loss = 53.388, baseline_loss = 2.3679, entropy_loss = -11.078, learner_queue_size = 32, _tick = 25354, _time = 1.6548e+09, train_seconds = 2.5163e+04)
[2022-06-10 03:07:28,634][root][INFO] - Step 95541760 @ 3581.2 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 95541760, mean_episode_return = None, mean_episode_step = 1.1931e+04, total_loss = -9.5995, pg_loss = 1.3521, baseline_loss = 0.12209, entropy_loss = -11.074, learner_queue_size = 32, _tick = 25354, _time = 1.6548e+09, train_seconds = 2.5168e+04)
[2022-06-10 03:07:33,638][root][INFO] - Step 95562240 @ 4092.7 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 95562240, mean_episode_return = None, mean_episode_step = 1.0692e+04, total_loss = -2.6047, pg_loss = 8.3439, baseline_loss = 0.12197, entropy_loss = -11.071, learner_queue_size = 32, _tick = 25354, _time = 1.6548e+09, train_seconds = 2.5173e+04)
[2022-06-10 03:07:38,642][root][INFO] - Step 95582720 @ 4092.8 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 95582720, mean_episode_return = None, mean_episode_step = 1.1443e+04, total_loss = -10.833, pg_loss = 0.11972, baseline_loss = 0.12096, entropy_loss = -11.074, learner_queue_size = 32, _tick = 25354, _time = 1.6548e+09, train_seconds = 2.5178e+04)
[2022-06-10 03:07:43,646][root][INFO] - Step 95603200 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 95603200, mean_episode_return = None, mean_episode_step = 1.1392e+04, total_loss = -17.54, pg_loss = -6.5793, baseline_loss = 0.11396, entropy_loss = -11.074, learner_queue_size = 32, _tick = 25355, _time = 1.6548e+09, train_seconds = 2.5184e+04)
[2022-06-10 03:07:48,650][root][INFO] - Step 95623680 @ 4092.7 SPS. Inference batcher size: 91. Learner queue size: 32. Other stats: (step = 95623680, mean_episode_return = -67.462, mean_episode_step = 1.2124e+04, total_loss = 52.16, pg_loss = 60.709, baseline_loss = 2.5309, entropy_loss = -11.08, learner_queue_size = 32, _tick = 25356, _time = 1.6548e+09, train_seconds = 2.5188e+04)
[2022-06-10 03:07:53,654][root][INFO] - Step 95644160 @ 4092.7 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 95644160, mean_episode_return = None, mean_episode_step = 1.148e+04, total_loss = -19.367, pg_loss = -8.4072, baseline_loss = 0.12022, entropy_loss = -11.08, learner_queue_size = 32, _tick = 25356, _time = 1.6548e+09, train_seconds = 2.5194e+04)
[2022-06-10 03:07:58,658][root][INFO] - Step 95662080 @ 3581.2 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 95662080, mean_episode_return = None, mean_episode_step = 1.2083e+04, total_loss = -16.357, pg_loss = -5.4115, baseline_loss = 0.12935, entropy_loss = -11.075, learner_queue_size = 32, _tick = 25357, _time = 1.6548e+09, train_seconds = 2.5198e+04)
[2022-06-10 03:08:03,662][root][INFO] - Step 95682560 @ 4092.7 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 95682560, mean_episode_return = None, mean_episode_step = 1.3151e+04, total_loss = -5.1592, pg_loss = 5.8059, baseline_loss = 0.12462, entropy_loss = -11.09, learner_queue_size = 32, _tick = 25357, _time = 1.6548e+09, train_seconds = 2.5204e+04)
[2022-06-10 03:08:08,666][root][INFO] - Step 95703040 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 95703040, mean_episode_return = None, mean_episode_step = 1.1555e+04, total_loss = -2.8697, pg_loss = 8.095, baseline_loss = 0.1255, entropy_loss = -11.09, learner_queue_size = 32, _tick = 25358, _time = 1.6548e+09, train_seconds = 2.5208e+04)
[2022-06-10 03:08:13,670][root][INFO] - Step 95723520 @ 4092.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 95723520, mean_episode_return = None, mean_episode_step = 1.2235e+04, total_loss = -4.0916, pg_loss = 6.8776, baseline_loss = 0.12805, entropy_loss = -11.097, learner_queue_size = 32, _tick = 25358, _time = 1.6548e+09, train_seconds = 2.5214e+04)
[2022-06-10 03:08:18,674][root][INFO] - Step 95744000 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 95744000, mean_episode_return = None, mean_episode_step = 1.2348e+04, total_loss = -13.015, pg_loss = -2.0395, baseline_loss = 0.12095, entropy_loss = -11.096, learner_queue_size = 32, _tick = 25359, _time = 1.6548e+09, train_seconds = 2.5218e+04)
[2022-06-10 03:08:23,678][root][INFO] - Step 95761920 @ 3581.1 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 95761920, mean_episode_return = -90.428, mean_episode_step = 1.1516e+04, total_loss = 42.011, pg_loss = 51.053, baseline_loss = 2.0488, entropy_loss = -11.091, learner_queue_size = 32, _tick = 25360, _time = 1.6548e+09, train_seconds = 2.5224e+04)
[2022-06-10 03:08:28,682][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 03:08:28,838][root][INFO] - Step 95782400 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 95782400, mean_episode_return = None, mean_episode_step = 1.2357e+04, total_loss = -18.612, pg_loss = -7.6557, baseline_loss = 0.12727, entropy_loss = -11.084, learner_queue_size = 32, _tick = 25360, _time = 1.6548e+09, train_seconds = 2.5228e+04)
[2022-06-10 03:08:33,842][root][INFO] - Step 95802880 @ 3969.0 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 95802880, mean_episode_return = None, mean_episode_step = 1.207e+04, total_loss = -15.222, pg_loss = -4.2578, baseline_loss = 0.12211, entropy_loss = -11.086, learner_queue_size = 32, _tick = 25360, _time = 1.6548e+09, train_seconds = 2.5234e+04)
[2022-06-10 03:08:38,846][root][INFO] - Step 95823360 @ 4092.6 SPS. Inference batcher size: 76. Learner queue size: 32. Other stats: (step = 95823360, mean_episode_return = -139.04, mean_episode_step = 1.2926e+04, total_loss = 47.915, pg_loss = 56.431, baseline_loss = 2.576, entropy_loss = -11.092, learner_queue_size = 32, _tick = 25362, _time = 1.6548e+09, train_seconds = 2.5239e+04)
[2022-06-10 03:08:43,850][root][INFO] - Step 95841280 @ 3581.2 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 95841280, mean_episode_return = None, mean_episode_step = 1.259e+04, total_loss = -10.279, pg_loss = 0.67616, baseline_loss = 0.12871, entropy_loss = -11.084, learner_queue_size = 32, _tick = 25362, _time = 1.6548e+09, train_seconds = 2.5244e+04)
[2022-06-10 03:08:48,854][root][INFO] - Step 95861760 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 95861760, mean_episode_return = None, mean_episode_step = 1.2913e+04, total_loss = -9.0662, pg_loss = 1.8921, baseline_loss = 0.12326, entropy_loss = -11.082, learner_queue_size = 32, _tick = 25364, _time = 1.6548e+09, train_seconds = 2.5249e+04)
[2022-06-10 03:08:53,860][root][INFO] - Step 95882240 @ 4090.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 95882240, mean_episode_return = None, mean_episode_step = 1.2113e+04, total_loss = -11.514, pg_loss = -0.55597, baseline_loss = 0.12021, entropy_loss = -11.078, learner_queue_size = 32, _tick = 25364, _time = 1.6548e+09, train_seconds = 2.5254e+04)
[2022-06-10 03:08:58,866][root][INFO] - Step 95902720 @ 4091.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 95902720, mean_episode_return = None, mean_episode_step = 1.1946e+04, total_loss = -17.703, pg_loss = -6.7377, baseline_loss = 0.12098, entropy_loss = -11.086, learner_queue_size = 32, _tick = 25365, _time = 1.6548e+09, train_seconds = 2.5259e+04)
[2022-06-10 03:09:03,877][root][INFO] - Step 95923200 @ 4086.9 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 95923200, mean_episode_return = None, mean_episode_step = 1.2596e+04, total_loss = -10.071, pg_loss = 0.88152, baseline_loss = 0.13121, entropy_loss = -11.084, learner_queue_size = 32, _tick = 25365, _time = 1.6548e+09, train_seconds = 2.5264e+04)
[2022-06-10 03:09:08,882][root][INFO] - Step 95943680 @ 4092.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 95943680, mean_episode_return = None, mean_episode_step = 1.2567e+04, total_loss = -19.869, pg_loss = -8.8984, baseline_loss = 0.11355, entropy_loss = -11.084, learner_queue_size = 32, _tick = 25366, _time = 1.6548e+09, train_seconds = 2.5269e+04)
[2022-06-10 03:09:13,886][root][INFO] - Step 95961600 @ 3581.1 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 95961600, mean_episode_return = None, mean_episode_step = 1.3373e+04, total_loss = -16.402, pg_loss = -5.8761, baseline_loss = 0.55372, entropy_loss = -11.08, learner_queue_size = 32, _tick = 25367, _time = 1.6548e+09, train_seconds = 2.5274e+04)
[2022-06-10 03:09:18,890][root][INFO] - Step 95982080 @ 4092.8 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 95982080, mean_episode_return = None, mean_episode_step = 1.2158e+04, total_loss = -15.317, pg_loss = -4.3492, baseline_loss = 0.11809, entropy_loss = -11.086, learner_queue_size = 32, _tick = 25368, _time = 1.6548e+09, train_seconds = 2.5279e+04)
[2022-06-10 03:09:23,894][root][INFO] - Step 96002560 @ 4092.6 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 96002560, mean_episode_return = None, mean_episode_step = 1.2615e+04, total_loss = -3.8351, pg_loss = 7.1409, baseline_loss = 0.11432, entropy_loss = -11.09, learner_queue_size = 32, _tick = 25368, _time = 1.6548e+09, train_seconds = 2.5284e+04)
[2022-06-10 03:09:28,898][root][INFO] - Step 96023040 @ 4092.8 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 96023040, mean_episode_return = None, mean_episode_step = 1.1932e+04, total_loss = -35.932, pg_loss = -24.962, baseline_loss = 0.11222, entropy_loss = -11.082, learner_queue_size = 32, _tick = 25369, _time = 1.6548e+09, train_seconds = 2.5289e+04)
[2022-06-10 03:09:33,902][root][INFO] - Step 96043520 @ 4092.8 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 96043520, mean_episode_return = None, mean_episode_step = 1.3552e+04, total_loss = -9.3293, pg_loss = 1.6165, baseline_loss = 0.13148, entropy_loss = -11.077, learner_queue_size = 32, _tick = 25369, _time = 1.6548e+09, train_seconds = 2.5294e+04)
[2022-06-10 03:09:38,906][root][INFO] - Step 96064000 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 96064000, mean_episode_return = None, mean_episode_step = 1.3445e+04, total_loss = -16.048, pg_loss = -5.0858, baseline_loss = 0.12209, entropy_loss = -11.084, learner_queue_size = 32, _tick = 25370, _time = 1.6548e+09, train_seconds = 2.5299e+04)
[2022-06-10 03:09:43,910][root][INFO] - Step 96084480 @ 4092.8 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 96084480, mean_episode_return = None, mean_episode_step = 1.2284e+04, total_loss = -10.171, pg_loss = 0.79813, baseline_loss = 0.11331, entropy_loss = -11.083, learner_queue_size = 32, _tick = 25370, _time = 1.6548e+09, train_seconds = 2.5304e+04)
[2022-06-10 03:09:48,916][root][INFO] - Step 96102400 @ 3579.9 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 96102400, mean_episode_return = None, mean_episode_step = 1.2356e+04, total_loss = -17.065, pg_loss = -6.0992, baseline_loss = 0.12143, entropy_loss = -11.087, learner_queue_size = 32, _tick = 25370, _time = 1.6548e+09, train_seconds = 2.5309e+04)
[2022-06-10 03:09:53,918][root][INFO] - Step 96122880 @ 4094.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 96122880, mean_episode_return = None, mean_episode_step = 1.3452e+04, total_loss = -15.057, pg_loss = -4.0987, baseline_loss = 0.12908, entropy_loss = -11.087, learner_queue_size = 32, _tick = 25370, _time = 1.6548e+09, train_seconds = 2.5314e+04)
[2022-06-10 03:09:58,922][root][INFO] - Step 96143360 @ 4092.5 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 96143360, mean_episode_return = None, mean_episode_step = 1.425e+04, total_loss = -22.653, pg_loss = -11.681, baseline_loss = 0.10747, entropy_loss = -11.079, learner_queue_size = 32, _tick = 25371, _time = 1.6548e+09, train_seconds = 2.5319e+04)
[2022-06-10 03:10:03,926][root][INFO] - Step 96163840 @ 4092.9 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 96163840, mean_episode_return = None, mean_episode_step = 1.3735e+04, total_loss = -20.768, pg_loss = -9.7985, baseline_loss = 0.10252, entropy_loss = -11.072, learner_queue_size = 32, _tick = 25373, _time = 1.6548e+09, train_seconds = 2.5324e+04)
[2022-06-10 03:10:08,930][root][INFO] - Step 96184320 @ 4092.8 SPS. Inference batcher size: 78. Learner queue size: 32. Other stats: (step = 96184320, mean_episode_return = None, mean_episode_step = 1.2085e+04, total_loss = -10.698, pg_loss = 0.25962, baseline_loss = 0.1148, entropy_loss = -11.072, learner_queue_size = 32, _tick = 25373, _time = 1.6548e+09, train_seconds = 2.5329e+04)
[2022-06-10 03:10:13,934][root][INFO] - Step 96204800 @ 4092.8 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 96204800, mean_episode_return = None, mean_episode_step = 1.225e+04, total_loss = -9.9204, pg_loss = 1.0258, baseline_loss = 0.12253, entropy_loss = -11.069, learner_queue_size = 32, _tick = 25373, _time = 1.6548e+09, train_seconds = 2.5334e+04)
[2022-06-10 03:10:18,938][root][INFO] - Step 96222720 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 96222720, mean_episode_return = None, mean_episode_step = 1.1185e+04, total_loss = -14.45, pg_loss = -3.4874, baseline_loss = 0.11377, entropy_loss = -11.077, learner_queue_size = 32, _tick = 25373, _time = 1.6548e+09, train_seconds = 2.5339e+04)
[2022-06-10 03:10:23,942][root][INFO] - Step 96243200 @ 4092.8 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 96243200, mean_episode_return = None, mean_episode_step = 1.248e+04, total_loss = -21.471, pg_loss = -10.514, baseline_loss = 0.098095, entropy_loss = -11.055, learner_queue_size = 32, _tick = 25376, _time = 1.6548e+09, train_seconds = 2.5344e+04)
[2022-06-10 03:10:28,946][root][INFO] - Step 96263680 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 96263680, mean_episode_return = None, mean_episode_step = 1.2067e+04, total_loss = -13.412, pg_loss = -2.4762, baseline_loss = 0.11735, entropy_loss = -11.053, learner_queue_size = 32, _tick = 25376, _time = 1.6548e+09, train_seconds = 2.5349e+04)
[2022-06-10 03:10:33,950][root][INFO] - Step 96284160 @ 4092.6 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 96284160, mean_episode_return = None, mean_episode_step = 1.4053e+04, total_loss = -12.143, pg_loss = -1.1958, baseline_loss = 0.12041, entropy_loss = -11.067, learner_queue_size = 32, _tick = 25376, _time = 1.6548e+09, train_seconds = 2.5354e+04)
[2022-06-10 03:10:38,954][root][INFO] - Step 96302080 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 96302080, mean_episode_return = -142.94, mean_episode_step = 1.3453e+04, total_loss = 39.484, pg_loss = 48.765, baseline_loss = 1.7848, entropy_loss = -11.066, learner_queue_size = 32, _tick = 25377, _time = 1.6548e+09, train_seconds = 2.5359e+04)
[2022-06-10 03:10:43,958][root][INFO] - Step 96322560 @ 4092.8 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 96322560, mean_episode_return = None, mean_episode_step = 1.4476e+04, total_loss = -10.718, pg_loss = 0.23023, baseline_loss = 0.11982, entropy_loss = -11.068, learner_queue_size = 32, _tick = 25377, _time = 1.6548e+09, train_seconds = 2.5364e+04)
[2022-06-10 03:10:48,962][root][INFO] - Step 96343040 @ 4092.7 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 96343040, mean_episode_return = None, mean_episode_step = 1.4886e+04, total_loss = -8.3321, pg_loss = 2.6283, baseline_loss = 0.11805, entropy_loss = -11.079, learner_queue_size = 32, _tick = 25377, _time = 1.6548e+09, train_seconds = 2.5369e+04)
[2022-06-10 03:10:53,965][root][INFO] - Step 96360960 @ 3581.8 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 96360960, mean_episode_return = None, mean_episode_step = 1.3989e+04, total_loss = -20.468, pg_loss = -9.5001, baseline_loss = 0.10445, entropy_loss = -11.072, learner_queue_size = 32, _tick = 25377, _time = 1.6548e+09, train_seconds = 2.5374e+04)
[2022-06-10 03:10:58,970][root][INFO] - Step 96381440 @ 4091.9 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 96381440, mean_episode_return = None, mean_episode_step = 1.3816e+04, total_loss = -12.084, pg_loss = -1.12, baseline_loss = 0.10422, entropy_loss = -11.068, learner_queue_size = 32, _tick = 25379, _time = 1.6548e+09, train_seconds = 2.5379e+04)
[2022-06-10 03:11:03,974][root][INFO] - Step 96401920 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 96401920, mean_episode_return = None, mean_episode_step = 1.3015e+04, total_loss = -10.269, pg_loss = 0.68634, baseline_loss = 0.11402, entropy_loss = -11.069, learner_queue_size = 32, _tick = 25380, _time = 1.6548e+09, train_seconds = 2.5384e+04)
[2022-06-10 03:11:08,978][root][INFO] - Step 96419840 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 96419840, mean_episode_return = None, mean_episode_step = 1.359e+04, total_loss = -18.832, pg_loss = -7.8643, baseline_loss = 0.11556, entropy_loss = -11.084, learner_queue_size = 32, _tick = 25381, _time = 1.6548e+09, train_seconds = 2.5389e+04)
[2022-06-10 03:11:13,982][root][INFO] - Step 96440320 @ 4092.7 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 96440320, mean_episode_return = None, mean_episode_step = 1.3816e+04, total_loss = -18.478, pg_loss = -7.4942, baseline_loss = 0.10158, entropy_loss = -11.085, learner_queue_size = 32, _tick = 25383, _time = 1.6548e+09, train_seconds = 2.5394e+04)
[2022-06-10 03:11:18,986][root][INFO] - Step 96460800 @ 4092.8 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 96460800, mean_episode_return = None, mean_episode_step = 1.3308e+04, total_loss = -14.332, pg_loss = -3.3559, baseline_loss = 0.10571, entropy_loss = -11.081, learner_queue_size = 32, _tick = 25385, _time = 1.6548e+09, train_seconds = 2.5399e+04)
[2022-06-10 03:11:23,990][root][INFO] - Step 96481280 @ 4092.6 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 96481280, mean_episode_return = None, mean_episode_step = 1.4498e+04, total_loss = -5.5246, pg_loss = 5.4497, baseline_loss = 0.11775, entropy_loss = -11.092, learner_queue_size = 32, _tick = 25385, _time = 1.6548e+09, train_seconds = 2.5404e+04)
[2022-06-10 03:11:28,994][root][INFO] - Step 96499200 @ 3581.2 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 96499200, mean_episode_return = None, mean_episode_step = 1.4778e+04, total_loss = -11.495, pg_loss = -0.512, baseline_loss = 0.10898, entropy_loss = -11.092, learner_queue_size = 32, _tick = 25385, _time = 1.6548e+09, train_seconds = 2.5409e+04)
[2022-06-10 03:11:33,998][root][INFO] - Step 96519680 @ 4092.7 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 96519680, mean_episode_return = None, mean_episode_step = 1.1824e+04, total_loss = -24.488, pg_loss = -13.509, baseline_loss = 0.11369, entropy_loss = -11.093, learner_queue_size = 32, _tick = 25385, _time = 1.6548e+09, train_seconds = 2.5414e+04)
[2022-06-10 03:11:39,002][root][INFO] - Step 96540160 @ 4092.8 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 96540160, mean_episode_return = None, mean_episode_step = 1.2091e+04, total_loss = -17.958, pg_loss = -6.9754, baseline_loss = 0.10497, entropy_loss = -11.087, learner_queue_size = 32, _tick = 25385, _time = 1.6548e+09, train_seconds = 2.5419e+04)
[2022-06-10 03:11:44,006][root][INFO] - Step 96560640 @ 4092.7 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 96560640, mean_episode_return = None, mean_episode_step = 1.4476e+04, total_loss = -6.1611, pg_loss = 4.8213, baseline_loss = 0.10943, entropy_loss = -11.092, learner_queue_size = 32, _tick = 25385, _time = 1.6548e+09, train_seconds = 2.5424e+04)
[2022-06-10 03:11:49,010][root][INFO] - Step 96578560 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 96578560, mean_episode_return = None, mean_episode_step = 1.4497e+04, total_loss = -12.124, pg_loss = -1.134, baseline_loss = 0.11018, entropy_loss = -11.1, learner_queue_size = 32, _tick = 25385, _time = 1.6548e+09, train_seconds = 2.5429e+04)
[2022-06-10 03:11:54,014][root][INFO] - Step 96599040 @ 4092.8 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 96599040, mean_episode_return = None, mean_episode_step = 1.5082e+04, total_loss = -17.511, pg_loss = -6.5206, baseline_loss = 0.11435, entropy_loss = -11.105, learner_queue_size = 32, _tick = 25385, _time = 1.6548e+09, train_seconds = 2.5434e+04)
[2022-06-10 03:11:59,018][root][INFO] - Step 96619520 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 96619520, mean_episode_return = None, mean_episode_step = 1.2451e+04, total_loss = -21.709, pg_loss = -10.72, baseline_loss = 0.11012, entropy_loss = -11.099, learner_queue_size = 32, _tick = 25386, _time = 1.6548e+09, train_seconds = 2.5439e+04)
[2022-06-10 03:12:04,022][root][INFO] - Step 96640000 @ 4092.8 SPS. Inference batcher size: 91. Learner queue size: 32. Other stats: (step = 96640000, mean_episode_return = None, mean_episode_step = 1.5356e+04, total_loss = -16.104, pg_loss = -5.119, baseline_loss = 0.11765, entropy_loss = -11.103, learner_queue_size = 32, _tick = 25387, _time = 1.6548e+09, train_seconds = 2.5444e+04)
[2022-06-10 03:12:09,026][root][INFO] - Step 96660480 @ 4092.4 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 96660480, mean_episode_return = None, mean_episode_step = 1.548e+04, total_loss = -23.823, pg_loss = -12.828, baseline_loss = 0.10451, entropy_loss = -11.099, learner_queue_size = 32, _tick = 25388, _time = 1.6548e+09, train_seconds = 2.5449e+04)
[2022-06-10 03:12:14,030][root][INFO] - Step 96678400 @ 3581.4 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 96678400, mean_episode_return = -128.46, mean_episode_step = 1.3603e+04, total_loss = 63.649, pg_loss = 69.652, baseline_loss = 5.0984, entropy_loss = -11.101, learner_queue_size = 32, _tick = 25389, _time = 1.6548e+09, train_seconds = 2.5454e+04)
[2022-06-10 03:12:19,035][root][INFO] - Step 96698880 @ 4091.9 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 96698880, mean_episode_return = None, mean_episode_step = 1.3328e+04, total_loss = -18.098, pg_loss = -7.1048, baseline_loss = 0.10942, entropy_loss = -11.103, learner_queue_size = 32, _tick = 25389, _time = 1.6548e+09, train_seconds = 2.5459e+04)
[2022-06-10 03:12:24,041][root][INFO] - Step 96719360 @ 4090.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 96719360, mean_episode_return = None, mean_episode_step = 1.401e+04, total_loss = -7.1233, pg_loss = 3.8748, baseline_loss = 0.11102, entropy_loss = -11.109, learner_queue_size = 32, _tick = 25391, _time = 1.6548e+09, train_seconds = 2.5464e+04)
[2022-06-10 03:12:29,046][root][INFO] - Step 96739840 @ 4092.2 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 96739840, mean_episode_return = None, mean_episode_step = 1.3904e+04, total_loss = -11.318, pg_loss = -0.31852, baseline_loss = 0.11343, entropy_loss = -11.113, learner_queue_size = 32, _tick = 25391, _time = 1.6548e+09, train_seconds = 2.5469e+04)
[2022-06-10 03:12:34,050][root][INFO] - Step 96760320 @ 4092.8 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 96760320, mean_episode_return = None, mean_episode_step = 1.2213e+04, total_loss = -5.691, pg_loss = 5.3066, baseline_loss = 0.11939, entropy_loss = -11.117, learner_queue_size = 32, _tick = 25391, _time = 1.6548e+09, train_seconds = 2.5474e+04)
[2022-06-10 03:12:39,054][root][INFO] - Step 96778240 @ 3580.8 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 96778240, mean_episode_return = None, mean_episode_step = 1.6213e+04, total_loss = -16.011, pg_loss = -4.9941, baseline_loss = 0.10563, entropy_loss = -11.123, learner_queue_size = 32, _tick = 25392, _time = 1.6548e+09, train_seconds = 2.5479e+04)
[2022-06-10 03:12:44,058][root][INFO] - Step 96798720 @ 4093.1 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 96798720, mean_episode_return = None, mean_episode_step = 1.4421e+04, total_loss = -9.5791, pg_loss = 1.4428, baseline_loss = 0.11123, entropy_loss = -11.133, learner_queue_size = 32, _tick = 25392, _time = 1.6548e+09, train_seconds = 2.5484e+04)
[2022-06-10 03:12:49,062][root][INFO] - Step 96819200 @ 4092.8 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 96819200, mean_episode_return = None, mean_episode_step = 1.4989e+04, total_loss = -10.447, pg_loss = 0.58278, baseline_loss = 0.10603, entropy_loss = -11.136, learner_queue_size = 32, _tick = 25392, _time = 1.6548e+09, train_seconds = 2.5489e+04)
[2022-06-10 03:12:54,068][root][INFO] - Step 96837120 @ 3579.8 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 96837120, mean_episode_return = -164.78, mean_episode_step = 1.3663e+04, total_loss = 75.421, pg_loss = 82.991, baseline_loss = 3.5658, entropy_loss = -11.136, learner_queue_size = 32, _tick = 25394, _time = 1.6548e+09, train_seconds = 2.5494e+04)
[2022-06-10 03:12:59,070][root][INFO] - Step 96857600 @ 4094.2 SPS. Inference batcher size: 82. Learner queue size: 32. Other stats: (step = 96857600, mean_episode_return = None, mean_episode_step = 1.5058e+04, total_loss = -17.722, pg_loss = -6.6788, baseline_loss = 0.10104, entropy_loss = -11.145, learner_queue_size = 32, _tick = 25394, _time = 1.6548e+09, train_seconds = 2.5499e+04)
[2022-06-10 03:13:04,074][root][INFO] - Step 96875520 @ 3581.0 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 96875520, mean_episode_return = None, mean_episode_step = 1.4687e+04, total_loss = -14.243, pg_loss = -3.202, baseline_loss = 0.10553, entropy_loss = -11.146, learner_queue_size = 32, _tick = 25394, _time = 1.6548e+09, train_seconds = 2.5504e+04)
[2022-06-10 03:13:09,078][root][INFO] - Step 96896000 @ 4092.8 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 96896000, mean_episode_return = None, mean_episode_step = 1.3927e+04, total_loss = -23.35, pg_loss = -12.291, baseline_loss = 0.087171, entropy_loss = -11.146, learner_queue_size = 32, _tick = 25395, _time = 1.6548e+09, train_seconds = 2.5509e+04)
[2022-06-10 03:13:14,082][root][INFO] - Step 96916480 @ 4092.7 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 96916480, mean_episode_return = None, mean_episode_step = 1.6682e+04, total_loss = -11.536, pg_loss = -0.49943, baseline_loss = 0.10714, entropy_loss = -11.144, learner_queue_size = 32, _tick = 25395, _time = 1.6548e+09, train_seconds = 2.5514e+04)
[2022-06-10 03:13:19,086][root][INFO] - Step 96934400 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 96934400, mean_episode_return = None, mean_episode_step = 1.4302e+04, total_loss = -23.905, pg_loss = -12.861, baseline_loss = 0.094209, entropy_loss = -11.138, learner_queue_size = 32, _tick = 25397, _time = 1.6548e+09, train_seconds = 2.5519e+04)
[2022-06-10 03:13:24,090][root][INFO] - Step 96954880 @ 4092.8 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 96954880, mean_episode_return = None, mean_episode_step = 1.4277e+04, total_loss = -13.039, pg_loss = -2.0105, baseline_loss = 0.11197, entropy_loss = -11.14, learner_queue_size = 32, _tick = 25397, _time = 1.6548e+09, train_seconds = 2.5524e+04)
[2022-06-10 03:13:29,094][root][INFO] - Step 96975360 @ 4092.7 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 96975360, mean_episode_return = None, mean_episode_step = 1.5194e+04, total_loss = -9.4628, pg_loss = 1.555, baseline_loss = 0.1213, entropy_loss = -11.139, learner_queue_size = 32, _tick = 25397, _time = 1.6548e+09, train_seconds = 2.5529e+04)
[2022-06-10 03:13:34,098][root][INFO] - Step 96995840 @ 4092.7 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 96995840, mean_episode_return = None, mean_episode_step = 1.2817e+04, total_loss = -6.6266, pg_loss = 4.4178, baseline_loss = 0.10218, entropy_loss = -11.147, learner_queue_size = 32, _tick = 25398, _time = 1.6548e+09, train_seconds = 2.5534e+04)
[2022-06-10 03:13:39,102][root][INFO] - Step 97016320 @ 4092.8 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 97016320, mean_episode_return = None, mean_episode_step = 1.3846e+04, total_loss = -22.134, pg_loss = -11.073, baseline_loss = 0.09244, entropy_loss = -11.153, learner_queue_size = 32, _tick = 25399, _time = 1.6548e+09, train_seconds = 2.5539e+04)
[2022-06-10 03:13:44,106][root][INFO] - Step 97036800 @ 4092.7 SPS. Inference batcher size: 95. Learner queue size: 32. Other stats: (step = 97036800, mean_episode_return = None, mean_episode_step = 1.4049e+04, total_loss = -7.9212, pg_loss = 3.1252, baseline_loss = 0.10516, entropy_loss = -11.152, learner_queue_size = 32, _tick = 25399, _time = 1.6548e+09, train_seconds = 2.5544e+04)
[2022-06-10 03:13:49,110][root][INFO] - Step 97057280 @ 4092.8 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 97057280, mean_episode_return = nan, mean_episode_step = 1.4287e+04, total_loss = 31.887, pg_loss = 40.88, baseline_loss = 2.1544, entropy_loss = -11.148, learner_queue_size = 32, _tick = 25401, _time = 1.6548e+09, train_seconds = 2.5549e+04)
[2022-06-10 03:13:54,114][root][INFO] - Step 97075200 @ 3581.2 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 97075200, mean_episode_return = None, mean_episode_step = 1.4458e+04, total_loss = -8.4937, pg_loss = 2.5434, baseline_loss = 0.10723, entropy_loss = -11.144, learner_queue_size = 32, _tick = 25401, _time = 1.6548e+09, train_seconds = 2.5554e+04)
[2022-06-10 03:13:59,118][root][INFO] - Step 97095680 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 97095680, mean_episode_return = -184.84, mean_episode_step = 1.5653e+04, total_loss = 45.98, pg_loss = 55.578, baseline_loss = 1.5555, entropy_loss = -11.154, learner_queue_size = 32, _tick = 25403, _time = 1.6548e+09, train_seconds = 2.5559e+04)
[2022-06-10 03:14:04,124][root][INFO] - Step 97116160 @ 4091.4 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 97116160, mean_episode_return = None, mean_episode_step = 1.5597e+04, total_loss = -4.8518, pg_loss = 6.187, baseline_loss = 0.1173, entropy_loss = -11.156, learner_queue_size = 32, _tick = 25403, _time = 1.6548e+09, train_seconds = 2.5564e+04)
[2022-06-10 03:14:09,126][root][INFO] - Step 97136640 @ 4094.0 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 97136640, mean_episode_return = None, mean_episode_step = 1.3968e+04, total_loss = -6.7894, pg_loss = 4.2766, baseline_loss = 0.094438, entropy_loss = -11.161, learner_queue_size = 32, _tick = 25404, _time = 1.6548e+09, train_seconds = 2.5569e+04)
[2022-06-10 03:14:14,130][root][INFO] - Step 97157120 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 97157120, mean_episode_return = -169.48, mean_episode_step = 1.4975e+04, total_loss = 52.242, pg_loss = 60.973, baseline_loss = 2.4304, entropy_loss = -11.161, learner_queue_size = 32, _tick = 25405, _time = 1.6548e+09, train_seconds = 2.5574e+04)
[2022-06-10 03:14:19,134][root][INFO] - Step 97175040 @ 3580.8 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 97175040, mean_episode_return = -90.921, mean_episode_step = 1.3158e+04, total_loss = 54.78, pg_loss = 63.34, baseline_loss = 2.5994, entropy_loss = -11.159, learner_queue_size = 32, _tick = 25406, _time = 1.6548e+09, train_seconds = 2.5579e+04)
[2022-06-10 03:14:24,138][root][INFO] - Step 97195520 @ 4093.0 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 97195520, mean_episode_return = None, mean_episode_step = 1.4914e+04, total_loss = -10.923, pg_loss = 0.1434, baseline_loss = 0.098724, entropy_loss = -11.166, learner_queue_size = 32, _tick = 25406, _time = 1.6548e+09, train_seconds = 2.5584e+04)
[2022-06-10 03:14:29,142][root][INFO] - Step 97216000 @ 4092.8 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 97216000, mean_episode_return = None, mean_episode_step = 1.4877e+04, total_loss = -18.281, pg_loss = -7.2511, baseline_loss = 0.097397, entropy_loss = -11.127, learner_queue_size = 32, _tick = 25409, _time = 1.6548e+09, train_seconds = 2.5589e+04)
[2022-06-10 03:14:34,146][root][INFO] - Step 97236480 @ 4092.7 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (step = 97236480, mean_episode_return = None, mean_episode_step = 1.466e+04, total_loss = -12.956, pg_loss = -1.8849, baseline_loss = 0.095531, entropy_loss = -11.166, learner_queue_size = 32, _tick = 25409, _time = 1.6548e+09, train_seconds = 2.5594e+04)
[2022-06-10 03:14:39,151][root][INFO] - Step 97254400 @ 3580.6 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 97254400, mean_episode_return = None, mean_episode_step = 1.4707e+04, total_loss = -13.894, pg_loss = -2.8128, baseline_loss = 0.098954, entropy_loss = -11.18, learner_queue_size = 32, _tick = 25409, _time = 1.6548e+09, train_seconds = 2.5599e+04)
[2022-06-10 03:14:44,155][root][INFO] - Step 97274880 @ 4092.9 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 97274880, mean_episode_return = None, mean_episode_step = 1.1555e+04, total_loss = -26.562, pg_loss = -15.492, baseline_loss = 0.11437, entropy_loss = -11.185, learner_queue_size = 32, _tick = 25410, _time = 1.6548e+09, train_seconds = 2.5604e+04)
[2022-06-10 03:14:49,162][root][INFO] - Step 97295360 @ 4089.9 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 97295360, mean_episode_return = None, mean_episode_step = 1.417e+04, total_loss = -14.082, pg_loss = -2.9899, baseline_loss = 0.095098, entropy_loss = -11.187, learner_queue_size = 32, _tick = 25410, _time = 1.6548e+09, train_seconds = 2.5609e+04)
[2022-06-10 03:14:54,171][root][INFO] - Step 97313280 @ 3577.9 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (step = 97313280, mean_episode_return = None, mean_episode_step = 1.3736e+04, total_loss = -20.258, pg_loss = -9.1619, baseline_loss = 0.093039, entropy_loss = -11.189, learner_queue_size = 32, _tick = 25411, _time = 1.6548e+09, train_seconds = 2.5614e+04)
[2022-06-10 03:14:59,174][root][INFO] - Step 97333760 @ 4093.0 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 97333760, mean_episode_return = None, mean_episode_step = 1.5454e+04, total_loss = -5.24, pg_loss = 5.8658, baseline_loss = 0.098385, entropy_loss = -11.204, learner_queue_size = 32, _tick = 25411, _time = 1.6548e+09, train_seconds = 2.5619e+04)
[2022-06-10 03:15:04,178][root][INFO] - Step 97351680 @ 3581.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 97351680, mean_episode_return = None, mean_episode_step = 1.5142e+04, total_loss = -15.047, pg_loss = -3.9476, baseline_loss = 0.10372, entropy_loss = -11.203, learner_queue_size = 32, _tick = 25411, _time = 1.6548e+09, train_seconds = 2.5624e+04)
[2022-06-10 03:15:09,182][root][INFO] - Step 97372160 @ 4092.8 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 97372160, mean_episode_return = None, mean_episode_step = 1.4623e+04, total_loss = -11.83, pg_loss = -0.71129, baseline_loss = 0.088543, entropy_loss = -11.207, learner_queue_size = 32, _tick = 25412, _time = 1.6548e+09, train_seconds = 2.5629e+04)
[2022-06-10 03:15:14,186][root][INFO] - Step 97392640 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 97392640, mean_episode_return = None, mean_episode_step = 1.7099e+04, total_loss = -14.936, pg_loss = -3.8244, baseline_loss = 0.090319, entropy_loss = -11.202, learner_queue_size = 32, _tick = 25413, _time = 1.6548e+09, train_seconds = 2.5634e+04)
[2022-06-10 03:15:19,190][root][INFO] - Step 97413120 @ 4092.7 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 97413120, mean_episode_return = None, mean_episode_step = 1.3492e+04, total_loss = 13.027, pg_loss = 23.781, baseline_loss = 0.44868, entropy_loss = -11.203, learner_queue_size = 32, _tick = 25413, _time = 1.6548e+09, train_seconds = 2.5639e+04)
[2022-06-10 03:15:24,194][root][INFO] - Step 97431040 @ 3581.2 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 97431040, mean_episode_return = None, mean_episode_step = 1.5663e+04, total_loss = -14.207, pg_loss = -3.0985, baseline_loss = 0.097211, entropy_loss = -11.205, learner_queue_size = 32, _tick = 25413, _time = 1.6548e+09, train_seconds = 2.5644e+04)
[2022-06-10 03:15:29,197][root][INFO] - Step 97451520 @ 4093.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 97451520, mean_episode_return = None, mean_episode_step = 1.4293e+04, total_loss = -11.737, pg_loss = -0.64134, baseline_loss = 0.10955, entropy_loss = -11.205, learner_queue_size = 32, _tick = 25413, _time = 1.6548e+09, train_seconds = 2.5649e+04)
[2022-06-10 03:15:34,202][root][INFO] - Step 97472000 @ 4092.3 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 97472000, mean_episode_return = None, mean_episode_step = 1.4195e+04, total_loss = -20.972, pg_loss = -9.851, baseline_loss = 0.09268, entropy_loss = -11.214, learner_queue_size = 32, _tick = 25413, _time = 1.6548e+09, train_seconds = 2.5654e+04)
[2022-06-10 03:15:39,206][root][INFO] - Step 97492480 @ 4092.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (step = 97492480, mean_episode_return = None, mean_episode_step = 1.4071e+04, total_loss = -15.394, pg_loss = -4.297, baseline_loss = 0.10143, entropy_loss = -11.198, learner_queue_size = 32, _tick = 25413, _time = 1.6548e+09, train_seconds = 2.5659e+04)
[2022-06-10 03:15:44,210][root][INFO] - Step 97512960 @ 4092.9 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 97512960, mean_episode_return = None, mean_episode_step = 1.6473e+04, total_loss = -9.4831, pg_loss = 1.5629, baseline_loss = 0.13925, entropy_loss = -11.185, learner_queue_size = 32, _tick = 25413, _time = 1.6548e+09, train_seconds = 2.5664e+04)
[2022-06-10 03:15:49,214][root][INFO] - Step 97530880 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 97530880, mean_episode_return = None, mean_episode_step = 1.4067e+04, total_loss = 2.6802, pg_loss = 13.6, baseline_loss = 0.28685, entropy_loss = -11.207, learner_queue_size = 32, _tick = 25414, _time = 1.6548e+09, train_seconds = 2.5669e+04)
[2022-06-10 03:15:54,218][root][INFO] - Step 97551360 @ 4092.6 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (step = 97551360, mean_episode_return = None, mean_episode_step = 1.5042e+04, total_loss = -9.6282, pg_loss = 1.4974, baseline_loss = 0.1093, entropy_loss = -11.235, learner_queue_size = 32, _tick = 25414, _time = 1.6548e+09, train_seconds = 2.5674e+04)
[2022-06-10 03:15:59,224][root][INFO] - Step 97571840 @ 4091.3 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 97571840, mean_episode_return = nan, mean_episode_step = 1.5922e+04, total_loss = -15.31, pg_loss = -4.1694, baseline_loss = 0.10296, entropy_loss = -11.244, learner_queue_size = 32, _tick = 25415, _time = 1.6548e+09, train_seconds = 2.5679e+04)
[2022-06-10 03:16:04,226][root][INFO] - Step 97589760 @ 3582.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 97589760, mean_episode_return = None, mean_episode_step = 1.4228e+04, total_loss = -16.138, pg_loss = -5.0291, baseline_loss = 0.13762, entropy_loss = -11.247, learner_queue_size = 32, _tick = 25415, _time = 1.6548e+09, train_seconds = 2.5684e+04)
[2022-06-10 03:16:09,230][root][INFO] - Step 97610240 @ 4092.7 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (step = 97610240, mean_episode_return = None, mean_episode_step = 1.3411e+04, total_loss = -3.319, pg_loss = 7.8242, baseline_loss = 0.097049, entropy_loss = -11.24, learner_queue_size = 32, _tick = 25415, _time = 1.6548e+09, train_seconds = 2.5689e+04)
[2022-06-10 03:16:14,234][root][INFO] - Step 97630720 @ 4092.6 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 97630720, mean_episode_return = -21.76, mean_episode_step = 1.7612e+04, total_loss = 12.184, pg_loss = 22.39, baseline_loss = 1.0414, entropy_loss = -11.248, learner_queue_size = 32, _tick = 25416, _time = 1.6548e+09, train_seconds = 2.5694e+04)
[2022-06-10 03:16:19,238][root][INFO] - Step 97651200 @ 4092.8 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 97651200, mean_episode_return = None, mean_episode_step = 1.3728e+04, total_loss = -17.831, pg_loss = -6.677, baseline_loss = 0.088751, entropy_loss = -11.243, learner_queue_size = 32, _tick = 25416, _time = 1.6548e+09, train_seconds = 2.5699e+04)
[2022-06-10 03:16:24,242][root][INFO] - Step 97669120 @ 3581.1 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 97669120, mean_episode_return = None, mean_episode_step = 1.425e+04, total_loss = -16.586, pg_loss = -5.4565, baseline_loss = 0.087516, entropy_loss = -11.217, learner_queue_size = 32, _tick = 25416, _time = 1.6548e+09, train_seconds = 2.5704e+04)
[2022-06-10 03:16:29,246][root][INFO] - Step 97689600 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 97689600, mean_episode_return = None, mean_episode_step = 1.5452e+04, total_loss = -8.055, pg_loss = 3.0963, baseline_loss = 0.094366, entropy_loss = -11.246, learner_queue_size = 32, _tick = 25416, _time = 1.6548e+09, train_seconds = 2.5709e+04)
[2022-06-10 03:16:34,251][root][INFO] - Step 97710080 @ 4091.8 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 97710080, mean_episode_return = None, mean_episode_step = 1.5586e+04, total_loss = -9.1765, pg_loss = 1.974, baseline_loss = 0.10394, entropy_loss = -11.254, learner_queue_size = 32, _tick = 25416, _time = 1.6548e+09, train_seconds = 2.5714e+04)
[2022-06-10 03:16:39,254][root][INFO] - Step 97728000 @ 3582.0 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 97728000, mean_episode_return = None, mean_episode_step = 1.7379e+04, total_loss = -17.87, pg_loss = -6.7727, baseline_loss = 0.15464, entropy_loss = -11.252, learner_queue_size = 32, _tick = 25416, _time = 1.6548e+09, train_seconds = 2.5719e+04)
[2022-06-10 03:16:44,258][root][INFO] - Step 97748480 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 97748480, mean_episode_return = None, mean_episode_step = 1.6389e+04, total_loss = -15.139, pg_loss = -3.9753, baseline_loss = 0.094533, entropy_loss = -11.258, learner_queue_size = 32, _tick = 25416, _time = 1.6548e+09, train_seconds = 2.5724e+04)
[2022-06-10 03:16:49,262][root][INFO] - Step 97768960 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 97768960, mean_episode_return = None, mean_episode_step = 1.6939e+04, total_loss = -13.753, pg_loss = -2.6183, baseline_loss = 0.091787, entropy_loss = -11.226, learner_queue_size = 32, _tick = 25418, _time = 1.6548e+09, train_seconds = 2.5729e+04)
[2022-06-10 03:16:54,266][root][INFO] - Step 97789440 @ 4092.8 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 97789440, mean_episode_return = None, mean_episode_step = 1.6339e+04, total_loss = 39.268, pg_loss = 45.673, baseline_loss = 4.8094, entropy_loss = -11.215, learner_queue_size = 32, _tick = 25419, _time = 1.6548e+09, train_seconds = 2.5734e+04)
[2022-06-10 03:16:59,270][root][INFO] - Step 97809920 @ 4092.6 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 97809920, mean_episode_return = None, mean_episode_step = 1.588e+04, total_loss = -7.0651, pg_loss = 4.1, baseline_loss = 0.091452, entropy_loss = -11.256, learner_queue_size = 32, _tick = 25420, _time = 1.6548e+09, train_seconds = 2.5739e+04)
[2022-06-10 03:17:04,274][root][INFO] - Step 97830400 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 97830400, mean_episode_return = None, mean_episode_step = 1.5209e+04, total_loss = -6.0505, pg_loss = 5.1154, baseline_loss = 0.094492, entropy_loss = -11.26, learner_queue_size = 32, _tick = 25420, _time = 1.6548e+09, train_seconds = 2.5744e+04)
[2022-06-10 03:17:09,278][root][INFO] - Step 97848320 @ 3581.2 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 97848320, mean_episode_return = None, mean_episode_step = 1.8655e+04, total_loss = -22.861, pg_loss = -11.681, baseline_loss = 0.087783, entropy_loss = -11.268, learner_queue_size = 32, _tick = 25420, _time = 1.6548e+09, train_seconds = 2.5749e+04)
[2022-06-10 03:17:14,282][root][INFO] - Step 97868800 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 97868800, mean_episode_return = None, mean_episode_step = 1.2444e+04, total_loss = -13.066, pg_loss = -1.9023, baseline_loss = 0.086966, entropy_loss = -11.251, learner_queue_size = 32, _tick = 25420, _time = 1.6548e+09, train_seconds = 2.5754e+04)
[2022-06-10 03:17:19,286][root][INFO] - Step 97889280 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 97889280, mean_episode_return = None, mean_episode_step = 1.819e+04, total_loss = -10.869, pg_loss = 0.28209, baseline_loss = 0.090933, entropy_loss = -11.242, learner_queue_size = 32, _tick = 25420, _time = 1.6548e+09, train_seconds = 2.5759e+04)
[2022-06-10 03:17:24,290][root][INFO] - Step 97907200 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 97907200, mean_episode_return = None, mean_episode_step = 1.5143e+04, total_loss = -23.696, pg_loss = -12.506, baseline_loss = 0.088314, entropy_loss = -11.278, learner_queue_size = 32, _tick = 25420, _time = 1.6548e+09, train_seconds = 2.5764e+04)
[2022-06-10 03:17:29,294][root][INFO] - Step 97927680 @ 4092.7 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 97927680, mean_episode_return = None, mean_episode_step = 1.7412e+04, total_loss = -9.0249, pg_loss = 2.1588, baseline_loss = 0.091702, entropy_loss = -11.275, learner_queue_size = 32, _tick = 25421, _time = 1.6548e+09, train_seconds = 2.5769e+04)
[2022-06-10 03:17:34,298][root][INFO] - Step 97948160 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 97948160, mean_episode_return = None, mean_episode_step = 1.3961e+04, total_loss = -7.6914, pg_loss = 3.4873, baseline_loss = 0.10859, entropy_loss = -11.287, learner_queue_size = 32, _tick = 25421, _time = 1.6548e+09, train_seconds = 2.5774e+04)
[2022-06-10 03:17:39,302][root][INFO] - Step 97968640 @ 4092.6 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 97968640, mean_episode_return = None, mean_episode_step = 1.6549e+04, total_loss = 5.0286, pg_loss = 15.943, baseline_loss = 0.37354, entropy_loss = -11.288, learner_queue_size = 32, _tick = 25421, _time = 1.6548e+09, train_seconds = 2.5779e+04)
[2022-06-10 03:17:44,309][root][INFO] - Step 97986560 @ 3579.2 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 97986560, mean_episode_return = None, mean_episode_step = 1.3916e+04, total_loss = -15.74, pg_loss = -4.5438, baseline_loss = 0.08394, entropy_loss = -11.281, learner_queue_size = 32, _tick = 25422, _time = 1.6548e+09, train_seconds = 2.5784e+04)
[2022-06-10 03:17:49,314][root][INFO] - Step 98007040 @ 4091.8 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 98007040, mean_episode_return = None, mean_episode_step = 1.673e+04, total_loss = -9.5283, pg_loss = 1.6379, baseline_loss = 0.10837, entropy_loss = -11.275, learner_queue_size = 32, _tick = 25423, _time = 1.6548e+09, train_seconds = 2.5789e+04)
[2022-06-10 03:17:54,320][root][INFO] - Step 98027520 @ 4091.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 98027520, mean_episode_return = None, mean_episode_step = 1.8226e+04, total_loss = -15.79, pg_loss = -4.6159, baseline_loss = 0.09158, entropy_loss = -11.265, learner_queue_size = 32, _tick = 25424, _time = 1.6548e+09, train_seconds = 2.5794e+04)
[2022-06-10 03:17:59,326][root][INFO] - Step 98048000 @ 4090.6 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 98048000, mean_episode_return = -168.65, mean_episode_step = 1.5582e+04, total_loss = -4.3906, pg_loss = 6.6273, baseline_loss = 0.25101, entropy_loss = -11.269, learner_queue_size = 32, _tick = 25426, _time = 1.6548e+09, train_seconds = 2.5799e+04)
[2022-06-10 03:18:04,330][root][INFO] - Step 98068480 @ 4092.8 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 98068480, mean_episode_return = None, mean_episode_step = 1.4634e+04, total_loss = -16.328, pg_loss = -5.1455, baseline_loss = 0.084123, entropy_loss = -11.267, learner_queue_size = 32, _tick = 25427, _time = 1.6548e+09, train_seconds = 2.5804e+04)
[2022-06-10 03:18:09,334][root][INFO] - Step 98086400 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 98086400, mean_episode_return = None, mean_episode_step = 1.7274e+04, total_loss = -16.081, pg_loss = -4.8888, baseline_loss = 0.084157, entropy_loss = -11.276, learner_queue_size = 32, _tick = 25427, _time = 1.6548e+09, train_seconds = 2.5809e+04)
[2022-06-10 03:18:14,346][root][INFO] - Step 98106880 @ 4086.2 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 98106880, mean_episode_return = None, mean_episode_step = 1.6103e+04, total_loss = -2.6568, pg_loss = 8.5114, baseline_loss = 0.10024, entropy_loss = -11.268, learner_queue_size = 32, _tick = 25427, _time = 1.6548e+09, train_seconds = 2.5814e+04)
[2022-06-10 03:18:19,352][root][INFO] - Step 98127360 @ 4091.3 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 98127360, mean_episode_return = None, mean_episode_step = 1.685e+04, total_loss = -15.385, pg_loss = -4.2218, baseline_loss = 0.09054, entropy_loss = -11.253, learner_queue_size = 32, _tick = 25427, _time = 1.6548e+09, train_seconds = 2.5819e+04)
[2022-06-10 03:18:24,358][root][INFO] - Step 98145280 @ 3579.6 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 98145280, mean_episode_return = None, mean_episode_step = 1.5891e+04, total_loss = -18.894, pg_loss = -7.6996, baseline_loss = 0.088513, entropy_loss = -11.283, learner_queue_size = 32, _tick = 25427, _time = 1.6548e+09, train_seconds = 2.5824e+04)
[2022-06-10 03:18:29,362][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 03:18:29,605][root][INFO] - Step 98165760 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 98165760, mean_episode_return = None, mean_episode_step = 1.5272e+04, total_loss = 12.456, pg_loss = 23.457, baseline_loss = 0.28815, entropy_loss = -11.289, learner_queue_size = 32, _tick = 25427, _time = 1.6548e+09, train_seconds = 2.5829e+04)
[2022-06-10 03:18:34,610][root][INFO] - Step 98186240 @ 3902.4 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 98186240, mean_episode_return = None, mean_episode_step = 1.7917e+04, total_loss = -48.136, pg_loss = -36.948, baseline_loss = 0.092564, entropy_loss = -11.28, learner_queue_size = 32, _tick = 25428, _time = 1.6548e+09, train_seconds = 2.5834e+04)
[2022-06-10 03:18:39,614][root][INFO] - Step 98206720 @ 4092.7 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 98206720, mean_episode_return = None, mean_episode_step = 1.601e+04, total_loss = -14.9, pg_loss = -3.6983, baseline_loss = 0.082066, entropy_loss = -11.284, learner_queue_size = 32, _tick = 25428, _time = 1.6548e+09, train_seconds = 2.5839e+04)
[2022-06-10 03:18:44,618][root][INFO] - Step 98227200 @ 4092.8 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 98227200, mean_episode_return = None, mean_episode_step = 1.8689e+04, total_loss = -14.217, pg_loss = -3.0249, baseline_loss = 0.091079, entropy_loss = -11.284, learner_queue_size = 32, _tick = 25428, _time = 1.6548e+09, train_seconds = 2.5844e+04)
[2022-06-10 03:18:49,622][root][INFO] - Step 98245120 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 98245120, mean_episode_return = None, mean_episode_step = 1.5721e+04, total_loss = -21.437, pg_loss = -10.238, baseline_loss = 0.078997, entropy_loss = -11.277, learner_queue_size = 32, _tick = 25429, _time = 1.6548e+09, train_seconds = 2.5849e+04)
[2022-06-10 03:18:54,626][root][INFO] - Step 98265600 @ 4092.7 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 98265600, mean_episode_return = None, mean_episode_step = 1.529e+04, total_loss = -20.407, pg_loss = -9.2666, baseline_loss = 0.089255, entropy_loss = -11.229, learner_queue_size = 32, _tick = 25429, _time = 1.6548e+09, train_seconds = 2.5854e+04)
[2022-06-10 03:18:59,630][root][INFO] - Step 98283520 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 98283520, mean_episode_return = None, mean_episode_step = 1.7389e+04, total_loss = 18.15, pg_loss = 28.783, baseline_loss = 0.60925, entropy_loss = -11.242, learner_queue_size = 32, _tick = 25429, _time = 1.6548e+09, train_seconds = 2.5859e+04)
[2022-06-10 03:19:04,634][root][INFO] - Step 98304000 @ 4092.7 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 98304000, mean_episode_return = None, mean_episode_step = 1.7361e+04, total_loss = -16.601, pg_loss = -5.4652, baseline_loss = 0.077838, entropy_loss = -11.214, learner_queue_size = 32, _tick = 25429, _time = 1.6548e+09, train_seconds = 2.5864e+04)
[2022-06-10 03:19:09,638][root][INFO] - Step 98324480 @ 4092.7 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 98324480, mean_episode_return = None, mean_episode_step = 1.7766e+04, total_loss = 2.7157, pg_loss = 13.862, baseline_loss = 0.10755, entropy_loss = -11.254, learner_queue_size = 32, _tick = 25429, _time = 1.6548e+09, train_seconds = 2.5869e+04)
[2022-06-10 03:19:14,642][root][INFO] - Step 98344960 @ 4092.7 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 98344960, mean_episode_return = None, mean_episode_step = 1.4608e+04, total_loss = -12.77, pg_loss = -1.574, baseline_loss = 0.08966, entropy_loss = -11.285, learner_queue_size = 32, _tick = 25429, _time = 1.6548e+09, train_seconds = 2.5874e+04)
[2022-06-10 03:19:19,646][root][INFO] - Step 98365440 @ 4092.7 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 98365440, mean_episode_return = None, mean_episode_step = 1.8153e+04, total_loss = 18.042, pg_loss = 28.367, baseline_loss = 0.9649, entropy_loss = -11.289, learner_queue_size = 32, _tick = 25429, _time = 1.6548e+09, train_seconds = 2.588e+04)
[2022-06-10 03:19:24,650][root][INFO] - Step 98383360 @ 3581.2 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 98383360, mean_episode_return = None, mean_episode_step = 1.7264e+04, total_loss = -1.9843, pg_loss = 9.2058, baseline_loss = 0.1049, entropy_loss = -11.295, learner_queue_size = 32, _tick = 25429, _time = 1.6548e+09, train_seconds = 2.5884e+04)
[2022-06-10 03:19:29,655][root][INFO] - Step 98403840 @ 4092.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 98403840, mean_episode_return = None, mean_episode_step = 1.9854e+04, total_loss = -12.355, pg_loss = -1.8708, baseline_loss = 0.80614, entropy_loss = -11.291, learner_queue_size = 32, _tick = 25429, _time = 1.6548e+09, train_seconds = 2.589e+04)
[2022-06-10 03:19:34,658][root][INFO] - Step 98421760 @ 3581.2 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 98421760, mean_episode_return = None, mean_episode_step = 2.0699e+04, total_loss = -10.23, pg_loss = 0.9759, baseline_loss = 0.09722, entropy_loss = -11.303, learner_queue_size = 32, _tick = 25429, _time = 1.6548e+09, train_seconds = 2.5894e+04)
[2022-06-10 03:19:39,664][root][INFO] - Step 98442240 @ 4091.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 98442240, mean_episode_return = None, mean_episode_step = 1.6267e+04, total_loss = -19.195, pg_loss = -7.9867, baseline_loss = 0.085241, entropy_loss = -11.293, learner_queue_size = 32, _tick = 25430, _time = 1.6548e+09, train_seconds = 2.59e+04)
[2022-06-10 03:19:44,670][root][INFO] - Step 98462720 @ 4091.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 98462720, mean_episode_return = None, mean_episode_step = 1.67e+04, total_loss = -2.2558, pg_loss = 8.9494, baseline_loss = 0.090622, entropy_loss = -11.296, learner_queue_size = 32, _tick = 25430, _time = 1.6548e+09, train_seconds = 2.5904e+04)
[2022-06-10 03:19:49,674][root][INFO] - Step 98483200 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 98483200, mean_episode_return = None, mean_episode_step = 1.5805e+04, total_loss = -14.422, pg_loss = -3.2162, baseline_loss = 0.087894, entropy_loss = -11.294, learner_queue_size = 32, _tick = 25431, _time = 1.6548e+09, train_seconds = 2.591e+04)
[2022-06-10 03:19:54,678][root][INFO] - Step 98501120 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 98501120, mean_episode_return = None, mean_episode_step = 1.9758e+04, total_loss = -14.652, pg_loss = -3.4513, baseline_loss = 0.08512, entropy_loss = -11.285, learner_queue_size = 32, _tick = 25432, _time = 1.6548e+09, train_seconds = 2.5914e+04)
[2022-06-10 03:19:59,682][root][INFO] - Step 98521600 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 98521600, mean_episode_return = None, mean_episode_step = 1.8526e+04, total_loss = -18.743, pg_loss = -7.5524, baseline_loss = 0.090672, entropy_loss = -11.281, learner_queue_size = 32, _tick = 25432, _time = 1.6548e+09, train_seconds = 2.592e+04)
[2022-06-10 03:20:04,686][root][INFO] - Step 98542080 @ 4092.7 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 98542080, mean_episode_return = None, mean_episode_step = 1.7542e+04, total_loss = -22.211, pg_loss = -11.005, baseline_loss = 0.073189, entropy_loss = -11.279, learner_queue_size = 32, _tick = 25433, _time = 1.6548e+09, train_seconds = 2.5924e+04)
[2022-06-10 03:20:09,690][root][INFO] - Step 98562560 @ 4092.8 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 98562560, mean_episode_return = -223.0, mean_episode_step = 1.8449e+04, total_loss = 24.79, pg_loss = 33.831, baseline_loss = 2.2451, entropy_loss = -11.286, learner_queue_size = 32, _tick = 25434, _time = 1.6548e+09, train_seconds = 2.593e+04)
[2022-06-10 03:20:14,694][root][INFO] - Step 98580480 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 98580480, mean_episode_return = None, mean_episode_step = 1.5889e+04, total_loss = -12.194, pg_loss = -1.0043, baseline_loss = 0.082695, entropy_loss = -11.272, learner_queue_size = 32, _tick = 25434, _time = 1.6548e+09, train_seconds = 2.5934e+04)
[2022-06-10 03:20:19,698][root][INFO] - Step 98600960 @ 4092.7 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 98600960, mean_episode_return = None, mean_episode_step = 2.2253e+04, total_loss = -2.571, pg_loss = 8.4423, baseline_loss = 0.28846, entropy_loss = -11.302, learner_queue_size = 32, _tick = 25434, _time = 1.6548e+09, train_seconds = 2.594e+04)
[2022-06-10 03:20:24,702][root][INFO] - Step 98621440 @ 4092.8 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 98621440, mean_episode_return = None, mean_episode_step = 1.9763e+04, total_loss = -16.27, pg_loss = -5.0794, baseline_loss = 0.080059, entropy_loss = -11.27, learner_queue_size = 32, _tick = 25434, _time = 1.6548e+09, train_seconds = 2.5944e+04)
[2022-06-10 03:20:29,706][root][INFO] - Step 98639360 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 98639360, mean_episode_return = None, mean_episode_step = 1.7227e+04, total_loss = -6.6052, pg_loss = 4.4638, baseline_loss = 0.076447, entropy_loss = -11.145, learner_queue_size = 32, _tick = 25434, _time = 1.6548e+09, train_seconds = 2.595e+04)
[2022-06-10 03:20:34,710][root][INFO] - Step 98659840 @ 4092.6 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 98659840, mean_episode_return = None, mean_episode_step = 1.7531e+04, total_loss = 0.51003, pg_loss = 11.364, baseline_loss = 0.37424, entropy_loss = -11.228, learner_queue_size = 32, _tick = 25436, _time = 1.6548e+09, train_seconds = 2.5954e+04)
[2022-06-10 03:20:39,714][root][INFO] - Step 98680320 @ 4092.8 SPS. Inference batcher size: 84. Learner queue size: 32. Other stats: (step = 98680320, mean_episode_return = None, mean_episode_step = 1.8019e+04, total_loss = -17.114, pg_loss = -5.9414, baseline_loss = 0.077373, entropy_loss = -11.25, learner_queue_size = 32, _tick = 25437, _time = 1.6548e+09, train_seconds = 2.596e+04)
[2022-06-10 03:20:44,718][root][INFO] - Step 98700800 @ 4092.8 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 98700800, mean_episode_return = None, mean_episode_step = 1.9429e+04, total_loss = -16.918, pg_loss = -5.737, baseline_loss = 0.073199, entropy_loss = -11.254, learner_queue_size = 32, _tick = 25437, _time = 1.6548e+09, train_seconds = 2.5964e+04)
[2022-06-10 03:20:49,722][root][INFO] - Step 98718720 @ 3581.1 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 98718720, mean_episode_return = None, mean_episode_step = 1.9027e+04, total_loss = -12.524, pg_loss = -1.3449, baseline_loss = 0.089502, entropy_loss = -11.269, learner_queue_size = 32, _tick = 25437, _time = 1.6548e+09, train_seconds = 2.597e+04)
[2022-06-10 03:20:54,726][root][INFO] - Step 98739200 @ 4092.6 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 98739200, mean_episode_return = None, mean_episode_step = 1.9088e+04, total_loss = -12.071, pg_loss = -1.193, baseline_loss = 0.37909, entropy_loss = -11.257, learner_queue_size = 32, _tick = 25439, _time = 1.6548e+09, train_seconds = 2.5974e+04)
[2022-06-10 03:20:59,730][root][INFO] - Step 98759680 @ 4092.8 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 98759680, mean_episode_return = None, mean_episode_step = 1.842e+04, total_loss = -18.615, pg_loss = -7.4232, baseline_loss = 0.07706, entropy_loss = -11.269, learner_queue_size = 32, _tick = 25440, _time = 1.6548e+09, train_seconds = 2.598e+04)
[2022-06-10 03:21:04,734][root][INFO] - Step 98780160 @ 4092.8 SPS. Inference batcher size: 73. Learner queue size: 32. Other stats: (step = 98780160, mean_episode_return = None, mean_episode_step = 1.7056e+04, total_loss = -22.119, pg_loss = -10.922, baseline_loss = 0.081185, entropy_loss = -11.278, learner_queue_size = 32, _tick = 25440, _time = 1.6548e+09, train_seconds = 2.5984e+04)
[2022-06-10 03:21:09,738][root][INFO] - Step 98798080 @ 3581.1 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 98798080, mean_episode_return = None, mean_episode_step = 1.8167e+04, total_loss = -20.087, pg_loss = -8.9111, baseline_loss = 0.077474, entropy_loss = -11.253, learner_queue_size = 32, _tick = 25441, _time = 1.6548e+09, train_seconds = 2.599e+04)
[2022-06-10 03:21:14,742][root][INFO] - Step 98818560 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 98818560, mean_episode_return = None, mean_episode_step = 1.8387e+04, total_loss = -1.1099, pg_loss = 9.2533, baseline_loss = 0.90235, entropy_loss = -11.266, learner_queue_size = 32, _tick = 25442, _time = 1.6548e+09, train_seconds = 2.5994e+04)
[2022-06-10 03:21:19,746][root][INFO] - Step 98839040 @ 4092.7 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 98839040, mean_episode_return = None, mean_episode_step = 1.8425e+04, total_loss = -10.586, pg_loss = 0.59998, baseline_loss = 0.082772, entropy_loss = -11.269, learner_queue_size = 32, _tick = 25442, _time = 1.6548e+09, train_seconds = 2.6e+04)
[2022-06-10 03:21:24,750][root][INFO] - Step 98856960 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 98856960, mean_episode_return = None, mean_episode_step = 1.8681e+04, total_loss = -12.839, pg_loss = -1.646, baseline_loss = 0.081414, entropy_loss = -11.275, learner_queue_size = 32, _tick = 25443, _time = 1.6548e+09, train_seconds = 2.6005e+04)
[2022-06-10 03:21:29,754][root][INFO] - Step 98877440 @ 4092.8 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 98877440, mean_episode_return = None, mean_episode_step = 1.7487e+04, total_loss = -20.324, pg_loss = -9.1509, baseline_loss = 0.070576, entropy_loss = -11.243, learner_queue_size = 32, _tick = 25445, _time = 1.6548e+09, train_seconds = 2.601e+04)
[2022-06-10 03:21:34,758][root][INFO] - Step 98897920 @ 4092.7 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 98897920, mean_episode_return = None, mean_episode_step = 2.0425e+04, total_loss = 0.26021, pg_loss = 11.062, baseline_loss = 0.4619, entropy_loss = -11.263, learner_queue_size = 32, _tick = 25446, _time = 1.6548e+09, train_seconds = 2.6015e+04)
[2022-06-10 03:21:39,762][root][INFO] - Step 98918400 @ 4092.7 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 98918400, mean_episode_return = None, mean_episode_step = 1.8945e+04, total_loss = -24.292, pg_loss = -13.148, baseline_loss = 0.081446, entropy_loss = -11.226, learner_queue_size = 32, _tick = 25448, _time = 1.6548e+09, train_seconds = 2.602e+04)
[2022-06-10 03:21:44,766][root][INFO] - Step 98938880 @ 4092.8 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 98938880, mean_episode_return = None, mean_episode_step = 1.7829e+04, total_loss = -19.977, pg_loss = -8.8719, baseline_loss = 0.080327, entropy_loss = -11.185, learner_queue_size = 32, _tick = 25448, _time = 1.6548e+09, train_seconds = 2.6025e+04)
[2022-06-10 03:21:49,770][root][INFO] - Step 98959360 @ 4092.6 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 98959360, mean_episode_return = None, mean_episode_step = 2.1819e+04, total_loss = -16.15, pg_loss = -4.9788, baseline_loss = 0.10065, entropy_loss = -11.272, learner_queue_size = 32, _tick = 25448, _time = 1.6548e+09, train_seconds = 2.603e+04)
[2022-06-10 03:21:54,774][root][INFO] - Step 98979840 @ 4092.7 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 98979840, mean_episode_return = None, mean_episode_step = 1.5159e+04, total_loss = -17.742, pg_loss = -6.5569, baseline_loss = 0.069537, entropy_loss = -11.254, learner_queue_size = 32, _tick = 25449, _time = 1.6548e+09, train_seconds = 2.6035e+04)
[2022-06-10 03:21:59,778][root][INFO] - Step 98997760 @ 3581.2 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 98997760, mean_episode_return = -232.5, mean_episode_step = 2.0217e+04, total_loss = 52.776, pg_loss = 61.429, baseline_loss = 2.6185, entropy_loss = -11.271, learner_queue_size = 32, _tick = 25450, _time = 1.6548e+09, train_seconds = 2.604e+04)
[2022-06-10 03:22:04,782][root][INFO] - Step 99018240 @ 4092.8 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 99018240, mean_episode_return = None, mean_episode_step = 1.9026e+04, total_loss = -8.6048, pg_loss = 2.5906, baseline_loss = 0.10955, entropy_loss = -11.305, learner_queue_size = 32, _tick = 25450, _time = 1.6548e+09, train_seconds = 2.6045e+04)
[2022-06-10 03:22:09,786][root][INFO] - Step 99038720 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 99038720, mean_episode_return = None, mean_episode_step = 1.8613e+04, total_loss = -10.294, pg_loss = 0.92539, baseline_loss = 0.086695, entropy_loss = -11.306, learner_queue_size = 32, _tick = 25451, _time = 1.6548e+09, train_seconds = 2.605e+04)
[2022-06-10 03:22:14,790][root][INFO] - Step 99059200 @ 4092.6 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 99059200, mean_episode_return = None, mean_episode_step = 2.0525e+04, total_loss = 45.153, pg_loss = 53.663, baseline_loss = 2.7898, entropy_loss = -11.3, learner_queue_size = 32, _tick = 25452, _time = 1.6548e+09, train_seconds = 2.6055e+04)
[2022-06-10 03:22:19,794][root][INFO] - Step 99079680 @ 4092.7 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 99079680, mean_episode_return = None, mean_episode_step = 1.685e+04, total_loss = -11.05, pg_loss = 0.049892, baseline_loss = 0.069271, entropy_loss = -11.169, learner_queue_size = 32, _tick = 25452, _time = 1.6548e+09, train_seconds = 2.606e+04)
[2022-06-10 03:22:24,798][root][INFO] - Step 99097600 @ 3581.2 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 99097600, mean_episode_return = None, mean_episode_step = 2.0462e+04, total_loss = -18.055, pg_loss = -6.9183, baseline_loss = 0.069381, entropy_loss = -11.206, learner_queue_size = 32, _tick = 25452, _time = 1.6548e+09, train_seconds = 2.6065e+04)
[2022-06-10 03:22:29,802][root][INFO] - Step 99118080 @ 4092.6 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 99118080, mean_episode_return = None, mean_episode_step = 1.5846e+04, total_loss = -14.765, pg_loss = -3.6214, baseline_loss = 0.14827, entropy_loss = -11.291, learner_queue_size = 32, _tick = 25453, _time = 1.6548e+09, train_seconds = 2.607e+04)
[2022-06-10 03:22:34,806][root][INFO] - Step 99138560 @ 4092.9 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 99138560, mean_episode_return = None, mean_episode_step = 1.7307e+04, total_loss = -12.328, pg_loss = -1.1114, baseline_loss = 0.092061, entropy_loss = -11.308, learner_queue_size = 32, _tick = 25453, _time = 1.6548e+09, train_seconds = 2.6075e+04)
[2022-06-10 03:22:39,810][root][INFO] - Step 99159040 @ 4092.7 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 99159040, mean_episode_return = None, mean_episode_step = 1.8424e+04, total_loss = -27.089, pg_loss = -15.864, baseline_loss = 0.073039, entropy_loss = -11.298, learner_queue_size = 32, _tick = 25454, _time = 1.6548e+09, train_seconds = 2.608e+04)
[2022-06-10 03:22:44,816][root][INFO] - Step 99176960 @ 3579.5 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 99176960, mean_episode_return = None, mean_episode_step = 2.0454e+04, total_loss = -13.499, pg_loss = -2.3473, baseline_loss = 0.10971, entropy_loss = -11.261, learner_queue_size = 32, _tick = 25456, _time = 1.6548e+09, train_seconds = 2.6085e+04)
[2022-06-10 03:22:49,822][root][INFO] - Step 99197440 @ 4091.2 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 99197440, mean_episode_return = None, mean_episode_step = 2.1142e+04, total_loss = -4.4291, pg_loss = 6.4154, baseline_loss = 0.41939, entropy_loss = -11.264, learner_queue_size = 32, _tick = 25458, _time = 1.6548e+09, train_seconds = 2.609e+04)
[2022-06-10 03:22:54,826][root][INFO] - Step 99217920 @ 4092.8 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 99217920, mean_episode_return = None, mean_episode_step = 1.8238e+04, total_loss = -25.502, pg_loss = -14.326, baseline_loss = 0.087569, entropy_loss = -11.264, learner_queue_size = 32, _tick = 25459, _time = 1.6548e+09, train_seconds = 2.6095e+04)
[2022-06-10 03:22:59,830][root][INFO] - Step 99238400 @ 4092.5 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 99238400, mean_episode_return = None, mean_episode_step = 1.9489e+04, total_loss = -17.741, pg_loss = -6.5588, baseline_loss = 0.073392, entropy_loss = -11.256, learner_queue_size = 32, _tick = 25459, _time = 1.6548e+09, train_seconds = 2.61e+04)
[2022-06-10 03:23:04,834][root][INFO] - Step 99258880 @ 4092.9 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 99258880, mean_episode_return = None, mean_episode_step = 1.9027e+04, total_loss = -13.247, pg_loss = -2.1219, baseline_loss = 0.081026, entropy_loss = -11.206, learner_queue_size = 32, _tick = 25459, _time = 1.6548e+09, train_seconds = 2.6105e+04)
[2022-06-10 03:23:09,838][root][INFO] - Step 99279360 @ 4092.6 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 99279360, mean_episode_return = None, mean_episode_step = 1.8709e+04, total_loss = -26.333, pg_loss = -15.31, baseline_loss = 0.2359, entropy_loss = -11.259, learner_queue_size = 32, _tick = 25461, _time = 1.6548e+09, train_seconds = 2.611e+04)
[2022-06-10 03:23:14,842][root][INFO] - Step 99297280 @ 3581.2 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 99297280, mean_episode_return = None, mean_episode_step = 1.754e+04, total_loss = -13.879, pg_loss = -2.6947, baseline_loss = 0.092317, entropy_loss = -11.277, learner_queue_size = 32, _tick = 25461, _time = 1.6548e+09, train_seconds = 2.6115e+04)
[2022-06-10 03:23:19,846][root][INFO] - Step 99317760 @ 4092.9 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 99317760, mean_episode_return = -163.89, mean_episode_step = 2.0186e+04, total_loss = -11.92, pg_loss = -0.82535, baseline_loss = 0.17612, entropy_loss = -11.271, learner_queue_size = 32, _tick = 25463, _time = 1.6548e+09, train_seconds = 2.612e+04)
[2022-06-10 03:23:24,850][root][INFO] - Step 99338240 @ 4092.7 SPS. Inference batcher size: 84. Learner queue size: 32. Other stats: (step = 99338240, mean_episode_return = None, mean_episode_step = 1.5736e+04, total_loss = -25.281, pg_loss = -14.26, baseline_loss = 0.071503, entropy_loss = -11.093, learner_queue_size = 32, _tick = 25464, _time = 1.6548e+09, train_seconds = 2.6125e+04)
[2022-06-10 03:23:29,854][root][INFO] - Step 99358720 @ 4092.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 99358720, mean_episode_return = None, mean_episode_step = 1.7449e+04, total_loss = -8.7872, pg_loss = 1.9561, baseline_loss = 0.068993, entropy_loss = -10.812, learner_queue_size = 32, _tick = 25466, _time = 1.6548e+09, train_seconds = 2.613e+04)
[2022-06-10 03:23:34,858][root][INFO] - Step 99376640 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 99376640, mean_episode_return = None, mean_episode_step = 1.9883e+04, total_loss = -15.406, pg_loss = -4.3816, baseline_loss = 0.18029, entropy_loss = -11.204, learner_queue_size = 32, _tick = 25467, _time = 1.6548e+09, train_seconds = 2.6135e+04)
[2022-06-10 03:23:39,862][root][INFO] - Step 99397120 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 99397120, mean_episode_return = None, mean_episode_step = 1.8788e+04, total_loss = -26.772, pg_loss = -15.719, baseline_loss = 0.065968, entropy_loss = -11.119, learner_queue_size = 32, _tick = 25469, _time = 1.6548e+09, train_seconds = 2.614e+04)
[2022-06-10 03:23:44,866][root][INFO] - Step 99417600 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 99417600, mean_episode_return = -120.6, mean_episode_step = 2.0107e+04, total_loss = 1.9655, pg_loss = 12.468, baseline_loss = 0.71963, entropy_loss = -11.223, learner_queue_size = 32, _tick = 25470, _time = 1.6548e+09, train_seconds = 2.6145e+04)
[2022-06-10 03:23:49,870][root][INFO] - Step 99435520 @ 3581.1 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 99435520, mean_episode_return = None, mean_episode_step = 1.6849e+04, total_loss = -21.902, pg_loss = -10.716, baseline_loss = 0.074586, entropy_loss = -11.261, learner_queue_size = 32, _tick = 25471, _time = 1.6548e+09, train_seconds = 2.615e+04)
[2022-06-10 03:23:54,874][root][INFO] - Step 99456000 @ 4092.8 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (step = 99456000, mean_episode_return = None, mean_episode_step = 1.7556e+04, total_loss = -16.473, pg_loss = -5.3002, baseline_loss = 0.094618, entropy_loss = -11.268, learner_queue_size = 32, _tick = 25472, _time = 1.6548e+09, train_seconds = 2.6155e+04)
[2022-06-10 03:23:59,897][root][INFO] - Step 99476480 @ 4077.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 99476480, mean_episode_return = -126.32, mean_episode_step = 1.7593e+04, total_loss = -1.9403, pg_loss = 8.4265, baseline_loss = 0.88111, entropy_loss = -11.248, learner_queue_size = 32, _tick = 25474, _time = 1.6548e+09, train_seconds = 2.616e+04)
[2022-06-10 03:24:04,902][root][INFO] - Step 99496960 @ 4092.0 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 99496960, mean_episode_return = None, mean_episode_step = 1.7233e+04, total_loss = -11.111, pg_loss = 0.043145, baseline_loss = 0.074133, entropy_loss = -11.228, learner_queue_size = 32, _tick = 25476, _time = 1.6548e+09, train_seconds = 2.6165e+04)
[2022-06-10 03:24:09,908][root][INFO] - Step 99514880 @ 3579.7 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 99514880, mean_episode_return = None, mean_episode_step = 1.7257e+04, total_loss = -10.188, pg_loss = 0.97912, baseline_loss = 0.088893, entropy_loss = -11.256, learner_queue_size = 32, _tick = 25476, _time = 1.6548e+09, train_seconds = 2.617e+04)
[2022-06-10 03:24:14,914][root][INFO] - Step 99535360 @ 4091.1 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 99535360, mean_episode_return = None, mean_episode_step = 1.8865e+04, total_loss = -24.333, pg_loss = -13.168, baseline_loss = 0.070377, entropy_loss = -11.236, learner_queue_size = 32, _tick = 25478, _time = 1.6548e+09, train_seconds = 2.6175e+04)
[2022-06-10 03:24:19,918][root][INFO] - Step 99555840 @ 4092.8 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 99555840, mean_episode_return = None, mean_episode_step = 1.6953e+04, total_loss = -22.596, pg_loss = -11.614, baseline_loss = 0.2554, entropy_loss = -11.237, learner_queue_size = 32, _tick = 25479, _time = 1.6548e+09, train_seconds = 2.618e+04)
[2022-06-10 03:24:24,922][root][INFO] - Step 99576320 @ 4092.7 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 99576320, mean_episode_return = None, mean_episode_step = 1.8089e+04, total_loss = -16.647, pg_loss = -5.4752, baseline_loss = 0.084782, entropy_loss = -11.257, learner_queue_size = 32, _tick = 25479, _time = 1.6548e+09, train_seconds = 2.6185e+04)
[2022-06-10 03:24:29,926][root][INFO] - Step 99594240 @ 3581.1 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 99594240, mean_episode_return = None, mean_episode_step = 1.7094e+04, total_loss = -9.2797, pg_loss = 1.9039, baseline_loss = 0.087481, entropy_loss = -11.271, learner_queue_size = 32, _tick = 25479, _time = 1.6548e+09, train_seconds = 2.619e+04)
[2022-06-10 03:24:34,930][root][INFO] - Step 99614720 @ 4092.7 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 99614720, mean_episode_return = None, mean_episode_step = 2.0802e+04, total_loss = -24.506, pg_loss = -13.306, baseline_loss = 0.079738, entropy_loss = -11.279, learner_queue_size = 32, _tick = 25480, _time = 1.6548e+09, train_seconds = 2.6195e+04)
[2022-06-10 03:24:39,934][root][INFO] - Step 99635200 @ 4092.7 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 99635200, mean_episode_return = None, mean_episode_step = 2e+04, total_loss = -9.3312, pg_loss = 1.8708, baseline_loss = 0.072958, entropy_loss = -11.275, learner_queue_size = 32, _tick = 25480, _time = 1.6548e+09, train_seconds = 2.62e+04)
[2022-06-10 03:24:44,940][root][INFO] - Step 99655680 @ 4091.1 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 99655680, mean_episode_return = None, mean_episode_step = 1.8204e+04, total_loss = -14.69, pg_loss = -3.5106, baseline_loss = 0.083375, entropy_loss = -11.263, learner_queue_size = 32, _tick = 25482, _time = 1.6548e+09, train_seconds = 2.6205e+04)
[2022-06-10 03:24:49,946][root][INFO] - Step 99676160 @ 4091.0 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 99676160, mean_episode_return = None, mean_episode_step = 1.6646e+04, total_loss = -10.853, pg_loss = 0.36584, baseline_loss = 0.078869, entropy_loss = -11.298, learner_queue_size = 32, _tick = 25483, _time = 1.6548e+09, train_seconds = 2.621e+04)
[2022-06-10 03:24:54,950][root][INFO] - Step 99696640 @ 4092.8 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (step = 99696640, mean_episode_return = None, mean_episode_step = 1.7894e+04, total_loss = -18.654, pg_loss = -7.5499, baseline_loss = 0.065053, entropy_loss = -11.17, learner_queue_size = 32, _tick = 25486, _time = 1.6548e+09, train_seconds = 2.6215e+04)
[2022-06-10 03:24:59,954][root][INFO] - Step 99714560 @ 3581.2 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 99714560, mean_episode_return = None, mean_episode_step = 1.9957e+04, total_loss = -15.921, pg_loss = -4.7337, baseline_loss = 0.079616, entropy_loss = -11.267, learner_queue_size = 32, _tick = 25486, _time = 1.6548e+09, train_seconds = 2.622e+04)
[2022-06-10 03:25:04,958][root][INFO] - Step 99735040 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 99735040, mean_episode_return = None, mean_episode_step = 1.8122e+04, total_loss = -14.147, pg_loss = -2.9757, baseline_loss = 0.081752, entropy_loss = -11.253, learner_queue_size = 32, _tick = 25487, _time = 1.6548e+09, train_seconds = 2.6225e+04)
[2022-06-10 03:25:09,962][root][INFO] - Step 99755520 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 99755520, mean_episode_return = None, mean_episode_step = 1.6562e+04, total_loss = 18.289, pg_loss = 28.862, baseline_loss = 0.71624, entropy_loss = -11.289, learner_queue_size = 32, _tick = 25487, _time = 1.6548e+09, train_seconds = 2.623e+04)
[2022-06-10 03:25:14,966][root][INFO] - Step 99776000 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 99776000, mean_episode_return = -0.62, mean_episode_step = 1.6481e+04, total_loss = 8.9174, pg_loss = 18.835, baseline_loss = 1.3042, entropy_loss = -11.222, learner_queue_size = 32, _tick = 25490, _time = 1.6548e+09, train_seconds = 2.6235e+04)
[2022-06-10 03:25:19,970][root][INFO] - Step 99796480 @ 4092.8 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 99796480, mean_episode_return = None, mean_episode_step = 1.7339e+04, total_loss = -23.212, pg_loss = -12.041, baseline_loss = 0.068918, entropy_loss = -11.24, learner_queue_size = 32, _tick = 25490, _time = 1.6548e+09, train_seconds = 2.624e+04)
[2022-06-10 03:25:24,974][root][INFO] - Step 99816960 @ 4092.6 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 99816960, mean_episode_return = -295.37, mean_episode_step = 1.5361e+04, total_loss = -0.26124, pg_loss = 9.9354, baseline_loss = 0.98468, entropy_loss = -11.181, learner_queue_size = 32, _tick = 25493, _time = 1.6548e+09, train_seconds = 2.6245e+04)
[2022-06-10 03:25:29,978][root][INFO] - Step 99837440 @ 4092.8 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 99837440, mean_episode_return = -259.33, mean_episode_step = 1.8006e+04, total_loss = 44.007, pg_loss = 52.865, baseline_loss = 0.64809, entropy_loss = -9.5062, learner_queue_size = 32, _tick = 25495, _time = 1.6548e+09, train_seconds = 2.625e+04)
[2022-06-10 03:25:34,982][root][INFO] - Step 99857920 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 99857920, mean_episode_return = None, mean_episode_step = 1.6723e+04, total_loss = 166.85, pg_loss = 168.23, baseline_loss = 5.9985, entropy_loss = -7.3714, learner_queue_size = 32, _tick = 25498, _time = 1.6548e+09, train_seconds = 2.6255e+04)
[2022-06-10 03:25:39,986][root][INFO] - Step 99875840 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 99875840, mean_episode_return = -43.498, mean_episode_step = 1.8777e+04, total_loss = 211.9, pg_loss = 208.3, baseline_loss = 8.063, entropy_loss = -4.4703, learner_queue_size = 32, _tick = 25505, _time = 1.6548e+09, train_seconds = 2.626e+04)
[2022-06-10 03:25:44,990][root][INFO] - Step 99896320 @ 4092.8 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 99896320, mean_episode_return = None, mean_episode_step = 1.6831e+04, total_loss = -7.6479, pg_loss = -2.862, baseline_loss = 0.51352, entropy_loss = -5.2994, learner_queue_size = 32, _tick = 25508, _time = 1.6548e+09, train_seconds = 2.6265e+04)
[2022-06-10 03:25:49,994][root][INFO] - Step 99914240 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 99914240, mean_episode_return = -152.26, mean_episode_step = 1.5802e+04, total_loss = 52.74, pg_loss = 45.916, baseline_loss = 12.315, entropy_loss = -5.4901, learner_queue_size = 32, _tick = 25513, _time = 1.6548e+09, train_seconds = 2.627e+04)
[2022-06-10 03:25:54,998][root][INFO] - Step 99934720 @ 4092.8 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 99934720, mean_episode_return = -285.51, mean_episode_step = 1.6991e+04, total_loss = 161.86, pg_loss = 138.3, baseline_loss = 29.126, entropy_loss = -5.5725, learner_queue_size = 32, _tick = 25518, _time = 1.6548e+09, train_seconds = 2.6275e+04)
[2022-06-10 03:26:00,002][root][INFO] - Step 99955200 @ 4092.6 SPS. Inference batcher size: 91. Learner queue size: 32. Other stats: (step = 99955200, mean_episode_return = -161.52, mean_episode_step = 1.881e+04, total_loss = 145.86, pg_loss = 111.68, baseline_loss = 39.765, entropy_loss = -5.5923, learner_queue_size = 32, _tick = 25523, _time = 1.6548e+09, train_seconds = 2.628e+04)
[2022-06-10 03:26:05,006][root][INFO] - Step 99973120 @ 3581.2 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 99973120, mean_episode_return = -80.437, mean_episode_step = 1.5555e+04, total_loss = 95.658, pg_loss = 64.343, baseline_loss = 36.79, entropy_loss = -5.4759, learner_queue_size = 32, _tick = 25528, _time = 1.6548e+09, train_seconds = 2.6285e+04)
[2022-06-10 03:26:10,010][root][INFO] - Step 99993600 @ 4092.6 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 99993600, mean_episode_return = -252.11, mean_episode_step = 1.3218e+04, total_loss = 22.376, pg_loss = 5.9601, baseline_loss = 21.89, entropy_loss = -5.4742, learner_queue_size = 32, _tick = 25533, _time = 1.6548e+09, train_seconds = 2.629e+04)
[2022-06-10 03:26:15,014][root][INFO] - Step 100011520 @ 3581.3 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 100011520, mean_episode_return = None, mean_episode_step = 1.409e+04, total_loss = 92.955, pg_loss = 72.276, baseline_loss = 25.924, entropy_loss = -5.2437, learner_queue_size = 32, _tick = 25535, _time = 1.6548e+09, train_seconds = 2.6295e+04)
[2022-06-10 03:26:20,018][root][INFO] - Step 100032000 @ 4092.7 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 100032000, mean_episode_return = None, mean_episode_step = 1.5698e+04, total_loss = -122.41, pg_loss = -119.89, baseline_loss = 2.7841, entropy_loss = -5.3002, learner_queue_size = 32, _tick = 25536, _time = 1.6548e+09, train_seconds = 2.63e+04)
[2022-06-10 03:26:25,024][root][INFO] - Step 100049920 @ 3579.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 100049920, mean_episode_return = -197.37, mean_episode_step = 1.1585e+04, total_loss = -42.342, pg_loss = -49.877, baseline_loss = 13.092, entropy_loss = -5.5573, learner_queue_size = 32, _tick = 25538, _time = 1.6548e+09, train_seconds = 2.6305e+04)
[2022-06-10 03:26:30,031][root][INFO] - Step 100072960 @ 4601.9 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 100072960, mean_episode_return = -243.0, mean_episode_step = 1.2868e+04, total_loss = 28.727, pg_loss = -21.608, baseline_loss = 55.853, entropy_loss = -5.517, learner_queue_size = 32, _tick = 25542, _time = 1.6548e+09, train_seconds = 2.631e+04)
[2022-06-10 03:26:35,034][root][INFO] - Step 100090880 @ 3581.6 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (step = 100090880, mean_episode_return = 14.08, mean_episode_step = 1.5023e+04, total_loss = 195.11, pg_loss = 154.67, baseline_loss = 46.033, entropy_loss = -5.5877, learner_queue_size = 32, _tick = 25548, _time = 1.6548e+09, train_seconds = 2.6315e+04)
[2022-06-10 03:26:40,038][root][INFO] - Step 100111360 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 100111360, mean_episode_return = 20.851, mean_episode_step = 1.1017e+04, total_loss = 82.081, pg_loss = 36.046, baseline_loss = 51.747, entropy_loss = -5.712, learner_queue_size = 32, _tick = 25553, _time = 1.6548e+09, train_seconds = 2.632e+04)
[2022-06-10 03:26:45,042][root][INFO] - Step 100131840 @ 4092.6 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 100131840, mean_episode_return = 26.84, mean_episode_step = 6468.8, total_loss = 418.33, pg_loss = 300.43, baseline_loss = 123.57, entropy_loss = -5.6664, learner_queue_size = 32, _tick = 25560, _time = 1.6548e+09, train_seconds = 2.6325e+04)
[2022-06-10 03:26:50,047][root][INFO] - Step 100149760 @ 3580.6 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 100149760, mean_episode_return = None, mean_episode_step = 1.1946e+04, total_loss = 205.12, pg_loss = 149.2, baseline_loss = 61.587, entropy_loss = -5.6643, learner_queue_size = 32, _tick = 25564, _time = 1.6548e+09, train_seconds = 2.633e+04)
[2022-06-10 03:26:55,050][root][INFO] - Step 100170240 @ 4093.5 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 100170240, mean_episode_return = None, mean_episode_step = 1.097e+04, total_loss = 198.62, pg_loss = 154.17, baseline_loss = 49.903, entropy_loss = -5.4582, learner_queue_size = 32, _tick = 25565, _time = 1.6548e+09, train_seconds = 2.6335e+04)
[2022-06-10 03:27:00,054][root][INFO] - Step 100188160 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 100188160, mean_episode_return = 30.02, mean_episode_step = 1.2048e+04, total_loss = -43.103, pg_loss = -57.348, baseline_loss = 19.848, entropy_loss = -5.6033, learner_queue_size = 32, _tick = 25570, _time = 1.6548e+09, train_seconds = 2.634e+04)
[2022-06-10 03:27:05,058][root][INFO] - Step 100208640 @ 4092.7 SPS. Inference batcher size: 73. Learner queue size: 32. Other stats: (step = 100208640, mean_episode_return = None, mean_episode_step = 8019.8, total_loss = 58.868, pg_loss = 41.425, baseline_loss = 23.094, entropy_loss = -5.651, learner_queue_size = 32, _tick = 25573, _time = 1.6548e+09, train_seconds = 2.6345e+04)
[2022-06-10 03:27:10,062][root][INFO] - Step 100226560 @ 3581.2 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 100226560, mean_episode_return = None, mean_episode_step = 1.1405e+04, total_loss = 119.63, pg_loss = 95.496, baseline_loss = 29.662, entropy_loss = -5.5261, learner_queue_size = 32, _tick = 25576, _time = 1.6548e+09, train_seconds = 2.635e+04)
[2022-06-10 03:27:15,066][root][INFO] - Step 100247040 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 100247040, mean_episode_return = -209.16, mean_episode_step = 1.1332e+04, total_loss = 139.67, pg_loss = 94.197, baseline_loss = 51.129, entropy_loss = -5.6533, learner_queue_size = 32, _tick = 25580, _time = 1.6548e+09, train_seconds = 2.6355e+04)
[2022-06-10 03:27:20,071][root][INFO] - Step 100264960 @ 3580.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 100264960, mean_episode_return = None, mean_episode_step = 6040.4, total_loss = 146.38, pg_loss = 112.61, baseline_loss = 39.394, entropy_loss = -5.6249, learner_queue_size = 32, _tick = 25582, _time = 1.6548e+09, train_seconds = 2.636e+04)
[2022-06-10 03:27:25,074][root][INFO] - Step 100285440 @ 4093.9 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 100285440, mean_episode_return = -54.647, mean_episode_step = 7848.1, total_loss = 17.189, pg_loss = -15.085, baseline_loss = 37.915, entropy_loss = -5.6416, learner_queue_size = 32, _tick = 25587, _time = 1.6548e+09, train_seconds = 2.6365e+04)
[2022-06-10 03:27:30,078][root][INFO] - Step 100305920 @ 4092.6 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 100305920, mean_episode_return = 75.96, mean_episode_step = 8922.5, total_loss = -155.83, pg_loss = -188.59, baseline_loss = 38.431, entropy_loss = -5.6674, learner_queue_size = 32, _tick = 25593, _time = 1.6548e+09, train_seconds = 2.637e+04)
[2022-06-10 03:27:35,082][root][INFO] - Step 100326400 @ 4092.8 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 100326400, mean_episode_return = None, mean_episode_step = 9649.2, total_loss = 154.15, pg_loss = 117.36, baseline_loss = 42.614, entropy_loss = -5.8207, learner_queue_size = 32, _tick = 25598, _time = 1.6548e+09, train_seconds = 2.6375e+04)
[2022-06-10 03:27:40,086][root][INFO] - Step 100346880 @ 4092.6 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 100346880, mean_episode_return = None, mean_episode_step = 6103.4, total_loss = -40.736, pg_loss = -42.055, baseline_loss = 7.2166, entropy_loss = -5.8984, learner_queue_size = 32, _tick = 25605, _time = 1.6548e+09, train_seconds = 2.638e+04)
[2022-06-10 03:27:45,090][root][INFO] - Step 100367360 @ 4092.8 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 100367360, mean_episode_return = None, mean_episode_step = 8719.7, total_loss = 257.15, pg_loss = 214.7, baseline_loss = 48.372, entropy_loss = -5.9253, learner_queue_size = 32, _tick = 25610, _time = 1.6548e+09, train_seconds = 2.6385e+04)
[2022-06-10 03:27:50,094][root][INFO] - Step 100385280 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 100385280, mean_episode_return = -33.863, mean_episode_step = 8804.8, total_loss = -67.424, pg_loss = -100.39, baseline_loss = 38.578, entropy_loss = -5.615, learner_queue_size = 32, _tick = 25615, _time = 1.6548e+09, train_seconds = 2.639e+04)
[2022-06-10 03:27:55,100][root][INFO] - Step 100405760 @ 4091.1 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 100405760, mean_episode_return = -135.97, mean_episode_step = 4586.3, total_loss = 203.46, pg_loss = 161.32, baseline_loss = 47.737, entropy_loss = -5.5989, learner_queue_size = 32, _tick = 25619, _time = 1.6548e+09, train_seconds = 2.6395e+04)
[2022-06-10 03:28:00,106][root][INFO] - Step 100423680 @ 3579.7 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 100423680, mean_episode_return = -70.978, mean_episode_step = 7910.5, total_loss = 8.0073, pg_loss = -10.426, baseline_loss = 22.274, entropy_loss = -3.8407, learner_queue_size = 32, _tick = 25623, _time = 1.6548e+09, train_seconds = 2.64e+04)
[2022-06-10 03:28:05,110][root][INFO] - Step 100444160 @ 4092.7 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 100444160, mean_episode_return = None, mean_episode_step = 5485.5, total_loss = 33.113, pg_loss = 21.842, baseline_loss = 15.375, entropy_loss = -4.104, learner_queue_size = 32, _tick = 25626, _time = 1.6548e+09, train_seconds = 2.6405e+04)
[2022-06-10 03:28:10,114][root][INFO] - Step 100464640 @ 4092.7 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 100464640, mean_episode_return = -54.913, mean_episode_step = 7617.2, total_loss = 61.359, pg_loss = 47.167, baseline_loss = 19.53, entropy_loss = -5.3383, learner_queue_size = 32, _tick = 25630, _time = 1.6548e+09, train_seconds = 2.641e+04)
[2022-06-10 03:28:15,118][root][INFO] - Step 100482560 @ 3581.2 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 100482560, mean_episode_return = 35.521, mean_episode_step = 5800.7, total_loss = 0.62333, pg_loss = -30.876, baseline_loss = 36.852, entropy_loss = -5.3531, learner_queue_size = 32, _tick = 25632, _time = 1.6548e+09, train_seconds = 2.6415e+04)
[2022-06-10 03:28:20,122][root][INFO] - Step 100503040 @ 4092.7 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 100503040, mean_episode_return = -67.957, mean_episode_step = 6538.1, total_loss = 0.86166, pg_loss = -17.866, baseline_loss = 23.114, entropy_loss = -4.386, learner_queue_size = 32, _tick = 25639, _time = 1.6548e+09, train_seconds = 2.642e+04)
[2022-06-10 03:28:25,126][root][INFO] - Step 100523520 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 100523520, mean_episode_return = None, mean_episode_step = 7642.2, total_loss = -49.201, pg_loss = -47.9, baseline_loss = 3.6596, entropy_loss = -4.9612, learner_queue_size = 32, _tick = 25644, _time = 1.6548e+09, train_seconds = 2.6425e+04)
[2022-06-10 03:28:30,130][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 03:28:30,267][root][INFO] - Step 100544000 @ 4092.8 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 100544000, mean_episode_return = 8.41, mean_episode_step = 3933.7, total_loss = 5.0492, pg_loss = -28.114, baseline_loss = 38.179, entropy_loss = -5.0158, learner_queue_size = 32, _tick = 25647, _time = 1.6548e+09, train_seconds = 2.643e+04)
[2022-06-10 03:28:35,270][root][INFO] - Step 100564480 @ 3984.4 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 100564480, mean_episode_return = None, mean_episode_step = 3716.7, total_loss = 40.65, pg_loss = 24.918, baseline_loss = 20.353, entropy_loss = -4.6216, learner_queue_size = 32, _tick = 25652, _time = 1.6548e+09, train_seconds = 2.6435e+04)
[2022-06-10 03:28:40,274][root][INFO] - Step 100582400 @ 3581.2 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 100582400, mean_episode_return = None, mean_episode_step = 4667.9, total_loss = -32.444, pg_loss = -40.067, baseline_loss = 13.087, entropy_loss = -5.464, learner_queue_size = 32, _tick = 25656, _time = 1.6548e+09, train_seconds = 2.644e+04)
[2022-06-10 03:28:45,278][root][INFO] - Step 100602880 @ 4092.8 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 100602880, mean_episode_return = None, mean_episode_step = 6488.9, total_loss = 104.83, pg_loss = 83.715, baseline_loss = 26.584, entropy_loss = -5.4708, learner_queue_size = 32, _tick = 25659, _time = 1.6548e+09, train_seconds = 2.6445e+04)
[2022-06-10 03:28:50,282][root][INFO] - Step 100623360 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 100623360, mean_episode_return = None, mean_episode_step = 4490.2, total_loss = 135.99, pg_loss = 106.07, baseline_loss = 35.518, entropy_loss = -5.6011, learner_queue_size = 32, _tick = 25666, _time = 1.6548e+09, train_seconds = 2.645e+04)
[2022-06-10 03:28:55,286][root][INFO] - Step 100641280 @ 3581.1 SPS. Inference batcher size: 82. Learner queue size: 32. Other stats: (step = 100641280, mean_episode_return = None, mean_episode_step = 4493.8, total_loss = -66.602, pg_loss = -68.926, baseline_loss = 8.0749, entropy_loss = -5.7504, learner_queue_size = 32, _tick = 25670, _time = 1.6548e+09, train_seconds = 2.6455e+04)
[2022-06-10 03:29:00,290][root][INFO] - Step 100661760 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 100661760, mean_episode_return = 13.295, mean_episode_step = 6726.5, total_loss = 28.343, pg_loss = 10.582, baseline_loss = 23.494, entropy_loss = -5.733, learner_queue_size = 32, _tick = 25677, _time = 1.6548e+09, train_seconds = 2.646e+04)
[2022-06-10 03:29:05,294][root][INFO] - Step 100682240 @ 4092.8 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 100682240, mean_episode_return = -89.313, mean_episode_step = 4002.7, total_loss = 131.41, pg_loss = 106.39, baseline_loss = 30.667, entropy_loss = -5.6391, learner_queue_size = 32, _tick = 25682, _time = 1.6548e+09, train_seconds = 2.6465e+04)
[2022-06-10 03:29:10,298][root][INFO] - Step 100702720 @ 4092.7 SPS. Inference batcher size: 84. Learner queue size: 32. Other stats: (step = 100702720, mean_episode_return = None, mean_episode_step = 5117.3, total_loss = 80.328, pg_loss = 48.088, baseline_loss = 37.838, entropy_loss = -5.5977, learner_queue_size = 32, _tick = 25687, _time = 1.6548e+09, train_seconds = 2.647e+04)
[2022-06-10 03:29:15,302][root][INFO] - Step 100720640 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 100720640, mean_episode_return = 94.925, mean_episode_step = 3371.0, total_loss = 218.08, pg_loss = 129.27, baseline_loss = 94.147, entropy_loss = -5.3391, learner_queue_size = 32, _tick = 25691, _time = 1.6548e+09, train_seconds = 2.6475e+04)
[2022-06-10 03:29:20,306][root][INFO] - Step 100741120 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 100741120, mean_episode_return = 65.937, mean_episode_step = 8794.7, total_loss = 126.23, pg_loss = 94.629, baseline_loss = 36.681, entropy_loss = -5.0846, learner_queue_size = 32, _tick = 25696, _time = 1.6548e+09, train_seconds = 2.648e+04)
[2022-06-10 03:29:25,310][root][INFO] - Step 100759040 @ 3581.2 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 100759040, mean_episode_return = -27.374, mean_episode_step = 6273.3, total_loss = -21.192, pg_loss = -32.641, baseline_loss = 16.828, entropy_loss = -5.3786, learner_queue_size = 32, _tick = 25700, _time = 1.6548e+09, train_seconds = 2.6485e+04)
[2022-06-10 03:29:30,314][root][INFO] - Step 100779520 @ 4092.6 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 100779520, mean_episode_return = None, mean_episode_step = 5139.3, total_loss = 19.281, pg_loss = 6.4152, baseline_loss = 18.565, entropy_loss = -5.6984, learner_queue_size = 32, _tick = 25703, _time = 1.6548e+09, train_seconds = 2.649e+04)
[2022-06-10 03:29:35,318][root][INFO] - Step 100800000 @ 4092.7 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 100800000, mean_episode_return = 2.0897, mean_episode_step = 7596.7, total_loss = 7.3879, pg_loss = -0.68038, baseline_loss = 13.67, entropy_loss = -5.6021, learner_queue_size = 32, _tick = 25707, _time = 1.6548e+09, train_seconds = 2.6495e+04)
[2022-06-10 03:29:40,324][root][INFO] - Step 100817920 @ 3579.4 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 100817920, mean_episode_return = 67.99, mean_episode_step = 6184.4, total_loss = 62.846, pg_loss = 40.245, baseline_loss = 28.323, entropy_loss = -5.7208, learner_queue_size = 32, _tick = 25712, _time = 1.6548e+09, train_seconds = 2.65e+04)
[2022-06-10 03:29:45,330][root][INFO] - Step 100838400 @ 4091.5 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 100838400, mean_episode_return = 51.473, mean_episode_step = 5395.8, total_loss = 84.541, pg_loss = 64.574, baseline_loss = 25.516, entropy_loss = -5.5499, learner_queue_size = 32, _tick = 25718, _time = 1.6548e+09, train_seconds = 2.6505e+04)
[2022-06-10 03:29:50,334][root][INFO] - Step 100858880 @ 4092.8 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 100858880, mean_episode_return = 103.07, mean_episode_step = 5760.1, total_loss = 187.31, pg_loss = 143.54, baseline_loss = 49.262, entropy_loss = -5.4908, learner_queue_size = 32, _tick = 25723, _time = 1.6548e+09, train_seconds = 2.651e+04)
[2022-06-10 03:29:55,339][root][INFO] - Step 100876800 @ 3580.2 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 100876800, mean_episode_return = 27.46, mean_episode_step = 6808.7, total_loss = -36.384, pg_loss = -48.082, baseline_loss = 17.074, entropy_loss = -5.3761, learner_queue_size = 32, _tick = 25730, _time = 1.6548e+09, train_seconds = 2.6515e+04)
[2022-06-10 03:30:00,342][root][INFO] - Step 100897280 @ 4093.8 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 100897280, mean_episode_return = 35.872, mean_episode_step = 2893.2, total_loss = 77.831, pg_loss = 53.4, baseline_loss = 29.271, entropy_loss = -4.8397, learner_queue_size = 32, _tick = 25734, _time = 1.6548e+09, train_seconds = 2.652e+04)
[2022-06-10 03:30:05,346][root][INFO] - Step 100915200 @ 3580.7 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (step = 100915200, mean_episode_return = 55.881, mean_episode_step = 3487.2, total_loss = -83.43, pg_loss = -94.152, baseline_loss = 16.105, entropy_loss = -5.3841, learner_queue_size = 32, _tick = 25738, _time = 1.6548e+09, train_seconds = 2.6525e+04)
[2022-06-10 03:30:10,350][root][INFO] - Step 100935680 @ 4093.2 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 100935680, mean_episode_return = -50.49, mean_episode_step = 4124.5, total_loss = -72.542, pg_loss = -75.82, baseline_loss = 8.7034, entropy_loss = -5.425, learner_queue_size = 32, _tick = 25743, _time = 1.6548e+09, train_seconds = 2.653e+04)
[2022-06-10 03:30:15,354][root][INFO] - Step 100953600 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 100953600, mean_episode_return = 14.59, mean_episode_step = 5781.6, total_loss = -60.388, pg_loss = -76.092, baseline_loss = 21.123, entropy_loss = -5.4194, learner_queue_size = 32, _tick = 25750, _time = 1.6548e+09, train_seconds = 2.6535e+04)
[2022-06-10 03:30:20,358][root][INFO] - Step 100974080 @ 4092.6 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 100974080, mean_episode_return = 39.34, mean_episode_step = 5825.0, total_loss = 290.64, pg_loss = 232.62, baseline_loss = 63.362, entropy_loss = -5.3436, learner_queue_size = 32, _tick = 25755, _time = 1.6548e+09, train_seconds = 2.654e+04)
[2022-06-10 03:30:25,362][root][INFO] - Step 100994560 @ 4092.9 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 100994560, mean_episode_return = 60.569, mean_episode_step = 2896.7, total_loss = 263.82, pg_loss = 185.88, baseline_loss = 83.379, entropy_loss = -5.4309, learner_queue_size = 32, _tick = 25762, _time = 1.6548e+09, train_seconds = 2.6545e+04)
[2022-06-10 03:30:30,366][root][INFO] - Step 101015040 @ 4092.7 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 101015040, mean_episode_return = 59.481, mean_episode_step = 1822.0, total_loss = 40.262, pg_loss = 2.3618, baseline_loss = 43.426, entropy_loss = -5.5253, learner_queue_size = 32, _tick = 25768, _time = 1.6548e+09, train_seconds = 2.655e+04)
[2022-06-10 03:30:35,370][root][INFO] - Step 101032960 @ 3581.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 101032960, mean_episode_return = 78.319, mean_episode_step = 3731.9, total_loss = 19.856, pg_loss = -10.957, baseline_loss = 36.14, entropy_loss = -5.3279, learner_queue_size = 32, _tick = 25775, _time = 1.6548e+09, train_seconds = 2.6555e+04)
[2022-06-10 03:30:40,374][root][INFO] - Step 101053440 @ 4092.7 SPS. Inference batcher size: 81. Learner queue size: 32. Other stats: (step = 101053440, mean_episode_return = 169.72, mean_episode_step = 3848.5, total_loss = -6.1537, pg_loss = -16.593, baseline_loss = 15.579, entropy_loss = -5.1398, learner_queue_size = 32, _tick = 25782, _time = 1.6548e+09, train_seconds = 2.656e+04)
[2022-06-10 03:30:45,378][root][INFO] - Step 101071360 @ 3581.2 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 101071360, mean_episode_return = 23.047, mean_episode_step = 2589.2, total_loss = -98.403, pg_loss = -122.55, baseline_loss = 29.489, entropy_loss = -5.3375, learner_queue_size = 32, _tick = 25788, _time = 1.6548e+09, train_seconds = 2.6565e+04)
[2022-06-10 03:30:50,382][root][INFO] - Step 101091840 @ 4092.7 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 101091840, mean_episode_return = None, mean_episode_step = 6540.0, total_loss = -53.48, pg_loss = -66.885, baseline_loss = 18.89, entropy_loss = -5.4843, learner_queue_size = 32, _tick = 25794, _time = 1.6548e+09, train_seconds = 2.657e+04)
[2022-06-10 03:30:55,386][root][INFO] - Step 101112320 @ 4092.6 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 101112320, mean_episode_return = 25.32, mean_episode_step = 1805.6, total_loss = 57.815, pg_loss = 21.834, baseline_loss = 41.194, entropy_loss = -5.213, learner_queue_size = 32, _tick = 25800, _time = 1.6548e+09, train_seconds = 2.6575e+04)
[2022-06-10 03:31:00,390][root][INFO] - Step 101132800 @ 4092.8 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 101132800, mean_episode_return = 137.78, mean_episode_step = 2698.5, total_loss = 98.569, pg_loss = 73.144, baseline_loss = 30.657, entropy_loss = -5.2319, learner_queue_size = 32, _tick = 25807, _time = 1.6548e+09, train_seconds = 2.658e+04)
[2022-06-10 03:31:05,394][root][INFO] - Step 101150720 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 101150720, mean_episode_return = -12.42, mean_episode_step = 2645.5, total_loss = -36.14, pg_loss = -36.763, baseline_loss = 6.1792, entropy_loss = -5.5558, learner_queue_size = 32, _tick = 25814, _time = 1.6548e+09, train_seconds = 2.6585e+04)
[2022-06-10 03:31:10,398][root][INFO] - Step 101171200 @ 4092.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 101171200, mean_episode_return = 173.45, mean_episode_step = 5115.8, total_loss = 157.17, pg_loss = 116.43, baseline_loss = 46.236, entropy_loss = -5.4971, learner_queue_size = 32, _tick = 25820, _time = 1.6548e+09, train_seconds = 2.659e+04)
[2022-06-10 03:31:15,402][root][INFO] - Step 101189120 @ 3581.1 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 101189120, mean_episode_return = None, mean_episode_step = 6036.5, total_loss = -31.238, pg_loss = -41.907, baseline_loss = 16.024, entropy_loss = -5.3548, learner_queue_size = 32, _tick = 25825, _time = 1.6548e+09, train_seconds = 2.6595e+04)
[2022-06-10 03:31:20,406][root][INFO] - Step 101209600 @ 4092.8 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 101209600, mean_episode_return = 128.01, mean_episode_step = 2974.1, total_loss = 42.104, pg_loss = 26.635, baseline_loss = 21.072, entropy_loss = -5.6034, learner_queue_size = 32, _tick = 25833, _time = 1.6548e+09, train_seconds = 2.66e+04)
[2022-06-10 03:31:25,410][root][INFO] - Step 101230080 @ 4092.7 SPS. Inference batcher size: 123. Learner queue size: 32. Other stats: (step = 101230080, mean_episode_return = 11.86, mean_episode_step = 2258.6, total_loss = 40.193, pg_loss = 14.082, baseline_loss = 31.411, entropy_loss = -5.2995, learner_queue_size = 32, _tick = 25838, _time = 1.6548e+09, train_seconds = 2.6605e+04)
[2022-06-10 03:31:30,415][root][INFO] - Step 101248000 @ 3580.6 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 101248000, mean_episode_return = None, mean_episode_step = 3877.3, total_loss = 137.17, pg_loss = 100.72, baseline_loss = 41.623, entropy_loss = -5.1664, learner_queue_size = 32, _tick = 25842, _time = 1.6548e+09, train_seconds = 2.661e+04)
[2022-06-10 03:31:35,421][root][INFO] - Step 101268480 @ 4091.0 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 101268480, mean_episode_return = 10.6, mean_episode_step = 4469.3, total_loss = -10.671, pg_loss = -36.926, baseline_loss = 31.051, entropy_loss = -4.796, learner_queue_size = 32, _tick = 25848, _time = 1.6548e+09, train_seconds = 2.6615e+04)
[2022-06-10 03:31:40,427][root][INFO] - Step 101288960 @ 4091.4 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (step = 101288960, mean_episode_return = 70.249, mean_episode_step = 5310.1, total_loss = -81.368, pg_loss = -93.806, baseline_loss = 17.569, entropy_loss = -5.1316, learner_queue_size = 32, _tick = 25852, _time = 1.6548e+09, train_seconds = 2.662e+04)
[2022-06-10 03:31:45,430][root][INFO] - Step 101306880 @ 3581.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 101306880, mean_episode_return = 28.495, mean_episode_step = 3021.3, total_loss = -47.189, pg_loss = -52.732, baseline_loss = 11.114, entropy_loss = -5.5713, learner_queue_size = 32, _tick = 25858, _time = 1.6548e+09, train_seconds = 2.6625e+04)
[2022-06-10 03:31:50,434][root][INFO] - Step 101327360 @ 4092.7 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 101327360, mean_episode_return = None, mean_episode_step = 3467.3, total_loss = 35.146, pg_loss = 22.252, baseline_loss = 18.363, entropy_loss = -5.4692, learner_queue_size = 32, _tick = 25864, _time = 1.6548e+09, train_seconds = 2.663e+04)
[2022-06-10 03:31:55,438][root][INFO] - Step 101347840 @ 4092.7 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 101347840, mean_episode_return = 46.37, mean_episode_step = 2426.0, total_loss = 53.775, pg_loss = 27.481, baseline_loss = 31.964, entropy_loss = -5.6705, learner_queue_size = 32, _tick = 25872, _time = 1.6548e+09, train_seconds = 2.6635e+04)
[2022-06-10 03:32:00,442][root][INFO] - Step 101365760 @ 3581.2 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 101365760, mean_episode_return = 27.56, mean_episode_step = 3743.7, total_loss = 133.46, pg_loss = 106.95, baseline_loss = 31.839, entropy_loss = -5.3337, learner_queue_size = 32, _tick = 25877, _time = 1.6548e+09, train_seconds = 2.664e+04)
[2022-06-10 03:32:05,447][root][INFO] - Step 101386240 @ 4092.0 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 101386240, mean_episode_return = 63.804, mean_episode_step = 2458.5, total_loss = -52.842, pg_loss = -72.5, baseline_loss = 25.191, entropy_loss = -5.533, learner_queue_size = 32, _tick = 25883, _time = 1.6548e+09, train_seconds = 2.6645e+04)
[2022-06-10 03:32:10,450][root][INFO] - Step 101404160 @ 3581.8 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 101404160, mean_episode_return = 36.01, mean_episode_step = 1625.0, total_loss = 174.76, pg_loss = 89.735, baseline_loss = 90.233, entropy_loss = -5.2121, learner_queue_size = 32, _tick = 25888, _time = 1.6548e+09, train_seconds = 2.665e+04)
[2022-06-10 03:32:15,454][root][INFO] - Step 101424640 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 101424640, mean_episode_return = 20.025, mean_episode_step = 3937.7, total_loss = -46.88, pg_loss = -58.975, baseline_loss = 17.117, entropy_loss = -5.0225, learner_queue_size = 32, _tick = 25892, _time = 1.6548e+09, train_seconds = 2.6655e+04)
[2022-06-10 03:32:20,458][root][INFO] - Step 101445120 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 101445120, mean_episode_return = 45.661, mean_episode_step = 1213.6, total_loss = -21.533, pg_loss = -45.984, baseline_loss = 29.431, entropy_loss = -4.9797, learner_queue_size = 32, _tick = 25900, _time = 1.6548e+09, train_seconds = 2.666e+04)
[2022-06-10 03:32:25,462][root][INFO] - Step 101465600 @ 4092.8 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 101465600, mean_episode_return = 153.9, mean_episode_step = 2252.0, total_loss = -131.44, pg_loss = -148.32, baseline_loss = 22.2, entropy_loss = -5.3157, learner_queue_size = 32, _tick = 25907, _time = 1.6548e+09, train_seconds = 2.6665e+04)
[2022-06-10 03:32:30,466][root][INFO] - Step 101483520 @ 3581.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 101483520, mean_episode_return = None, mean_episode_step = 2183.8, total_loss = 124.43, pg_loss = 90.25, baseline_loss = 39.461, entropy_loss = -5.2764, learner_queue_size = 32, _tick = 25911, _time = 1.6548e+09, train_seconds = 2.667e+04)
[2022-06-10 03:32:35,470][root][INFO] - Step 101504000 @ 4092.7 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 101504000, mean_episode_return = None, mean_episode_step = 2359.3, total_loss = 115.16, pg_loss = 87.107, baseline_loss = 33.369, entropy_loss = -5.3214, learner_queue_size = 32, _tick = 25917, _time = 1.6548e+09, train_seconds = 2.6675e+04)
[2022-06-10 03:32:40,475][root][INFO] - Step 101521920 @ 3580.7 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 101521920, mean_episode_return = 76.614, mean_episode_step = 1160.1, total_loss = 104.18, pg_loss = 44.645, baseline_loss = 64.832, entropy_loss = -5.297, learner_queue_size = 32, _tick = 25921, _time = 1.6548e+09, train_seconds = 2.668e+04)
[2022-06-10 03:32:45,478][root][INFO] - Step 101542400 @ 4093.3 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 101542400, mean_episode_return = 48.441, mean_episode_step = 2878.7, total_loss = 121.69, pg_loss = 87.175, baseline_loss = 40.113, entropy_loss = -5.5957, learner_queue_size = 32, _tick = 25926, _time = 1.6548e+09, train_seconds = 2.6685e+04)
[2022-06-10 03:32:50,482][root][INFO] - Step 101562880 @ 4092.8 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 101562880, mean_episode_return = 70.06, mean_episode_step = 3804.2, total_loss = -96.863, pg_loss = -119.36, baseline_loss = 27.984, entropy_loss = -5.4837, learner_queue_size = 32, _tick = 25934, _time = 1.6548e+09, train_seconds = 2.669e+04)
[2022-06-10 03:32:55,486][root][INFO] - Step 101580800 @ 3581.1 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 101580800, mean_episode_return = -285.17, mean_episode_step = 5417.3, total_loss = 106.6, pg_loss = 58.945, baseline_loss = 53.175, entropy_loss = -5.5166, learner_queue_size = 32, _tick = 25940, _time = 1.6548e+09, train_seconds = 2.6695e+04)
[2022-06-10 03:33:00,490][root][INFO] - Step 101601280 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 101601280, mean_episode_return = 90.509, mean_episode_step = 2216.7, total_loss = 47.759, pg_loss = 7.5775, baseline_loss = 45.255, entropy_loss = -5.0729, learner_queue_size = 32, _tick = 25948, _time = 1.6548e+09, train_seconds = 2.67e+04)
[2022-06-10 03:33:05,494][root][INFO] - Step 101621760 @ 4092.7 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 101621760, mean_episode_return = 40.83, mean_episode_step = 1543.7, total_loss = -20.26, pg_loss = -75.033, baseline_loss = 60.109, entropy_loss = -5.3362, learner_queue_size = 32, _tick = 25955, _time = 1.6548e+09, train_seconds = 2.6705e+04)
[2022-06-10 03:33:10,498][root][INFO] - Step 101639680 @ 3581.2 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 101639680, mean_episode_return = None, mean_episode_step = 941.56, total_loss = 12.925, pg_loss = -5.6415, baseline_loss = 23.96, entropy_loss = -5.3934, learner_queue_size = 32, _tick = 25960, _time = 1.6548e+09, train_seconds = 2.671e+04)
[2022-06-10 03:33:15,502][root][INFO] - Step 101660160 @ 4092.7 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 101660160, mean_episode_return = 66.007, mean_episode_step = 2693.6, total_loss = 778.87, pg_loss = 394.38, baseline_loss = 389.73, entropy_loss = -5.2369, learner_queue_size = 32, _tick = 25968, _time = 1.6548e+09, train_seconds = 2.6715e+04)
[2022-06-10 03:33:20,507][root][INFO] - Step 101678080 @ 3580.5 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 101678080, mean_episode_return = 74.208, mean_episode_step = 2216.5, total_loss = 274.21, pg_loss = 216.07, baseline_loss = 63.482, entropy_loss = -5.339, learner_queue_size = 32, _tick = 25972, _time = 1.6548e+09, train_seconds = 2.672e+04)
[2022-06-10 03:33:25,510][root][INFO] - Step 101698560 @ 4093.5 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 101698560, mean_episode_return = None, mean_episode_step = 1279.5, total_loss = -58.992, pg_loss = -75.464, baseline_loss = 21.668, entropy_loss = -5.1959, learner_queue_size = 32, _tick = 25979, _time = 1.6548e+09, train_seconds = 2.6725e+04)
[2022-06-10 03:33:30,514][root][INFO] - Step 101719040 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 101719040, mean_episode_return = 10.865, mean_episode_step = 2251.0, total_loss = 204.99, pg_loss = 153.71, baseline_loss = 56.906, entropy_loss = -5.6274, learner_queue_size = 32, _tick = 25985, _time = 1.6548e+09, train_seconds = 2.673e+04)
[2022-06-10 03:33:35,518][root][INFO] - Step 101736960 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 101736960, mean_episode_return = None, mean_episode_step = 1170.8, total_loss = 202.65, pg_loss = 164.7, baseline_loss = 43.452, entropy_loss = -5.4941, learner_queue_size = 32, _tick = 25990, _time = 1.6548e+09, train_seconds = 2.6735e+04)
[2022-06-10 03:33:40,522][root][INFO] - Step 101757440 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 101757440, mean_episode_return = None, mean_episode_step = 1054.9, total_loss = 51.582, pg_loss = 36.142, baseline_loss = 20.787, entropy_loss = -5.3473, learner_queue_size = 32, _tick = 25996, _time = 1.6548e+09, train_seconds = 2.674e+04)
[2022-06-10 03:33:45,526][root][INFO] - Step 101775360 @ 3581.1 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (step = 101775360, mean_episode_return = 87.427, mean_episode_step = 1081.3, total_loss = 321.0, pg_loss = 266.75, baseline_loss = 59.554, entropy_loss = -5.3027, learner_queue_size = 32, _tick = 26002, _time = 1.6548e+09, train_seconds = 2.6745e+04)
[2022-06-10 03:33:50,530][root][INFO] - Step 101795840 @ 4092.8 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 101795840, mean_episode_return = 7.9497, mean_episode_step = 1865.4, total_loss = 5.6288, pg_loss = -39.756, baseline_loss = 50.593, entropy_loss = -5.2082, learner_queue_size = 32, _tick = 26009, _time = 1.6548e+09, train_seconds = 2.675e+04)
[2022-06-10 03:33:55,534][root][INFO] - Step 101816320 @ 4092.4 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (step = 101816320, mean_episode_return = 22.36, mean_episode_step = 1712.0, total_loss = 121.64, pg_loss = 75.674, baseline_loss = 50.667, entropy_loss = -4.7004, learner_queue_size = 32, _tick = 26013, _time = 1.6548e+09, train_seconds = 2.6755e+04)
[2022-06-10 03:34:00,538][root][INFO] - Step 101836800 @ 4092.9 SPS. Inference batcher size: 75. Learner queue size: 32. Other stats: (step = 101836800, mean_episode_return = 69.957, mean_episode_step = 2280.3, total_loss = -99.49, pg_loss = -112.87, baseline_loss = 18.512, entropy_loss = -5.1268, learner_queue_size = 32, _tick = 26019, _time = 1.6548e+09, train_seconds = 2.676e+04)
[2022-06-10 03:34:05,542][root][INFO] - Step 101857280 @ 4092.9 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 101857280, mean_episode_return = 78.7, mean_episode_step = 823.39, total_loss = 464.2, pg_loss = 354.43, baseline_loss = 115.09, entropy_loss = -5.3166, learner_queue_size = 32, _tick = 26026, _time = 1.6548e+09, train_seconds = 2.6765e+04)
[2022-06-10 03:34:10,546][root][INFO] - Step 101875200 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 101875200, mean_episode_return = 30.48, mean_episode_step = 1169.5, total_loss = 666.26, pg_loss = 501.69, baseline_loss = 170.02, entropy_loss = -5.4517, learner_queue_size = 32, _tick = 26031, _time = 1.6548e+09, train_seconds = 2.677e+04)
[2022-06-10 03:34:15,550][root][INFO] - Step 101895680 @ 4092.7 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 101895680, mean_episode_return = 59.24, mean_episode_step = 1500.1, total_loss = -106.35, pg_loss = -115.82, baseline_loss = 14.882, entropy_loss = -5.4129, learner_queue_size = 32, _tick = 26037, _time = 1.6548e+09, train_seconds = 2.6775e+04)
[2022-06-10 03:34:20,555][root][INFO] - Step 101913600 @ 3580.4 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 101913600, mean_episode_return = 82.537, mean_episode_step = 1026.6, total_loss = 305.15, pg_loss = 235.48, baseline_loss = 75.057, entropy_loss = -5.382, learner_queue_size = 32, _tick = 26044, _time = 1.6548e+09, train_seconds = 2.678e+04)
[2022-06-10 03:34:25,558][root][INFO] - Step 101934080 @ 4093.6 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (step = 101934080, mean_episode_return = None, mean_episode_step = 927.09, total_loss = 16.378, pg_loss = -9.4257, baseline_loss = 31.106, entropy_loss = -5.3021, learner_queue_size = 32, _tick = 26047, _time = 1.6548e+09, train_seconds = 2.6785e+04)
[2022-06-10 03:34:30,570][root][INFO] - Step 101954560 @ 4086.2 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 101954560, mean_episode_return = 53.531, mean_episode_step = 2205.1, total_loss = 21.428, pg_loss = -10.843, baseline_loss = 37.658, entropy_loss = -5.3868, learner_queue_size = 32, _tick = 26055, _time = 1.6548e+09, train_seconds = 2.679e+04)
[2022-06-10 03:34:35,574][root][INFO] - Step 101975040 @ 4092.7 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 101975040, mean_episode_return = 15.1, mean_episode_step = 2371.5, total_loss = -21.648, pg_loss = -50.547, baseline_loss = 33.935, entropy_loss = -5.0365, learner_queue_size = 32, _tick = 26063, _time = 1.6548e+09, train_seconds = 2.6795e+04)
[2022-06-10 03:34:40,578][root][INFO] - Step 101992960 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 101992960, mean_episode_return = 84.036, mean_episode_step = 3438.5, total_loss = 156.4, pg_loss = 92.808, baseline_loss = 69.012, entropy_loss = -5.421, learner_queue_size = 32, _tick = 26068, _time = 1.6548e+09, train_seconds = 2.68e+04)
[2022-06-10 03:34:45,582][root][INFO] - Step 102013440 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 102013440, mean_episode_return = 47.01, mean_episode_step = 1984.1, total_loss = 70.655, pg_loss = 22.671, baseline_loss = 53.408, entropy_loss = -5.424, learner_queue_size = 32, _tick = 26072, _time = 1.6548e+09, train_seconds = 2.6805e+04)
[2022-06-10 03:34:50,586][root][INFO] - Step 102033920 @ 4092.6 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 102033920, mean_episode_return = None, mean_episode_step = 1187.0, total_loss = -246.99, pg_loss = -262.8, baseline_loss = 21.117, entropy_loss = -5.307, learner_queue_size = 32, _tick = 26078, _time = 1.6548e+09, train_seconds = 2.681e+04)
[2022-06-10 03:34:55,591][root][INFO] - Step 102051840 @ 3581.0 SPS. Inference batcher size: 79. Learner queue size: 32. Other stats: (step = 102051840, mean_episode_return = 71.4, mean_episode_step = 1852.5, total_loss = -101.42, pg_loss = -149.79, baseline_loss = 53.704, entropy_loss = -5.3376, learner_queue_size = 32, _tick = 26083, _time = 1.6548e+09, train_seconds = 2.6815e+04)
[2022-06-10 03:35:00,594][root][INFO] - Step 102072320 @ 4093.1 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (step = 102072320, mean_episode_return = 63.98, mean_episode_step = 2523.1, total_loss = 188.42, pg_loss = 126.74, baseline_loss = 67.216, entropy_loss = -5.5367, learner_queue_size = 32, _tick = 26089, _time = 1.6548e+09, train_seconds = 2.682e+04)
[2022-06-10 03:35:05,598][root][INFO] - Step 102092800 @ 4092.7 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 102092800, mean_episode_return = 179.16, mean_episode_step = 1157.0, total_loss = 252.67, pg_loss = 191.06, baseline_loss = 66.962, entropy_loss = -5.3506, learner_queue_size = 32, _tick = 26097, _time = 1.6548e+09, train_seconds = 2.6825e+04)
[2022-06-10 03:35:10,602][root][INFO] - Step 102110720 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 102110720, mean_episode_return = 75.795, mean_episode_step = 3205.8, total_loss = -3.7741, pg_loss = -19.82, baseline_loss = 21.559, entropy_loss = -5.513, learner_queue_size = 32, _tick = 26102, _time = 1.6548e+09, train_seconds = 2.683e+04)
[2022-06-10 03:35:15,608][root][INFO] - Step 102131200 @ 4090.9 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 102131200, mean_episode_return = 45.845, mean_episode_step = 891.29, total_loss = 101.48, pg_loss = 54.563, baseline_loss = 52.374, entropy_loss = -5.4588, learner_queue_size = 32, _tick = 26106, _time = 1.6548e+09, train_seconds = 2.6835e+04)
[2022-06-10 03:35:20,614][root][INFO] - Step 102151680 @ 4091.2 SPS. Inference batcher size: 73. Learner queue size: 32. Other stats: (step = 102151680, mean_episode_return = 66.54, mean_episode_step = 1310.0, total_loss = 19.484, pg_loss = 0.52185, baseline_loss = 24.219, entropy_loss = -5.2562, learner_queue_size = 32, _tick = 26112, _time = 1.6548e+09, train_seconds = 2.684e+04)
[2022-06-10 03:35:25,618][root][INFO] - Step 102169600 @ 3581.2 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 102169600, mean_episode_return = None, mean_episode_step = 1008.4, total_loss = 177.48, pg_loss = 123.94, baseline_loss = 58.842, entropy_loss = -5.3042, learner_queue_size = 32, _tick = 26118, _time = 1.6548e+09, train_seconds = 2.6845e+04)
[2022-06-10 03:35:30,622][root][INFO] - Step 102190080 @ 4092.7 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 102190080, mean_episode_return = 64.841, mean_episode_step = 1208.3, total_loss = 22.104, pg_loss = -22.522, baseline_loss = 49.981, entropy_loss = -5.3555, learner_queue_size = 32, _tick = 26125, _time = 1.6548e+09, train_seconds = 2.685e+04)
[2022-06-10 03:35:35,623][root][INFO] - Step 102210560 @ 4094.8 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 102210560, mean_episode_return = 29.023, mean_episode_step = 1696.9, total_loss = -17.15, pg_loss = -37.875, baseline_loss = 26.208, entropy_loss = -5.4822, learner_queue_size = 32, _tick = 26131, _time = 1.6548e+09, train_seconds = 2.6855e+04)
[2022-06-10 03:35:40,626][root][INFO] - Step 102228480 @ 3582.1 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (step = 102228480, mean_episode_return = 59.662, mean_episode_step = 1025.8, total_loss = 49.472, pg_loss = -11.069, baseline_loss = 65.998, entropy_loss = -5.4568, learner_queue_size = 32, _tick = 26137, _time = 1.6548e+09, train_seconds = 2.686e+04)
[2022-06-10 03:35:45,630][root][INFO] - Step 102248960 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 102248960, mean_episode_return = 41.46, mean_episode_step = 1640.8, total_loss = -119.86, pg_loss = -128.27, baseline_loss = 13.926, entropy_loss = -5.5128, learner_queue_size = 32, _tick = 26144, _time = 1.6548e+09, train_seconds = 2.6865e+04)
[2022-06-10 03:35:50,634][root][INFO] - Step 102269440 @ 4092.6 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 102269440, mean_episode_return = None, mean_episode_step = 1156.4, total_loss = 39.119, pg_loss = 23.68, baseline_loss = 20.798, entropy_loss = -5.3584, learner_queue_size = 32, _tick = 26150, _time = 1.6548e+09, train_seconds = 2.687e+04)
[2022-06-10 03:35:55,638][root][INFO] - Step 102287360 @ 3581.2 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 102287360, mean_episode_return = 31.712, mean_episode_step = 1878.0, total_loss = 284.06, pg_loss = 175.85, baseline_loss = 113.58, entropy_loss = -5.372, learner_queue_size = 32, _tick = 26156, _time = 1.6548e+09, train_seconds = 2.6875e+04)
[2022-06-10 03:36:00,642][root][INFO] - Step 102307840 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 102307840, mean_episode_return = 78.015, mean_episode_step = 1240.6, total_loss = 175.52, pg_loss = 105.2, baseline_loss = 75.653, entropy_loss = -5.339, learner_queue_size = 32, _tick = 26162, _time = 1.6548e+09, train_seconds = 2.688e+04)
[2022-06-10 03:36:05,646][root][INFO] - Step 102328320 @ 4092.8 SPS. Inference batcher size: 89. Learner queue size: 32. Other stats: (step = 102328320, mean_episode_return = 25.92, mean_episode_step = 982.1, total_loss = 51.526, pg_loss = -2.0795, baseline_loss = 58.873, entropy_loss = -5.2674, learner_queue_size = 32, _tick = 26169, _time = 1.6548e+09, train_seconds = 2.6886e+04)
[2022-06-10 03:36:10,652][root][INFO] - Step 102346240 @ 3579.4 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 102346240, mean_episode_return = 46.763, mean_episode_step = 1426.1, total_loss = 65.211, pg_loss = 6.4945, baseline_loss = 63.956, entropy_loss = -5.2396, learner_queue_size = 32, _tick = 26173, _time = 1.6548e+09, train_seconds = 2.689e+04)
[2022-06-10 03:36:15,658][root][INFO] - Step 102366720 @ 4091.4 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 102366720, mean_episode_return = 107.75, mean_episode_step = 2327.5, total_loss = 17.668, pg_loss = -9.2368, baseline_loss = 32.033, entropy_loss = -5.1274, learner_queue_size = 32, _tick = 26181, _time = 1.6548e+09, train_seconds = 2.6896e+04)
[2022-06-10 03:36:20,662][root][INFO] - Step 102387200 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 102387200, mean_episode_return = 24.376, mean_episode_step = 941.48, total_loss = -53.622, pg_loss = -76.743, baseline_loss = 28.483, entropy_loss = -5.3621, learner_queue_size = 32, _tick = 26188, _time = 1.6548e+09, train_seconds = 2.69e+04)
[2022-06-10 03:36:25,666][root][INFO] - Step 102405120 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 102405120, mean_episode_return = 43.141, mean_episode_step = 1144.1, total_loss = 581.12, pg_loss = 396.69, baseline_loss = 190.01, entropy_loss = -5.5751, learner_queue_size = 32, _tick = 26194, _time = 1.6548e+09, train_seconds = 2.6906e+04)
[2022-06-10 03:36:30,670][root][INFO] - Step 102425600 @ 4092.8 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 102425600, mean_episode_return = 20.705, mean_episode_step = 1094.7, total_loss = 220.1, pg_loss = 135.09, baseline_loss = 90.585, entropy_loss = -5.5768, learner_queue_size = 32, _tick = 26201, _time = 1.6548e+09, train_seconds = 2.691e+04)
[2022-06-10 03:36:35,676][root][INFO] - Step 102443520 @ 3579.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 102443520, mean_episode_return = 60.446, mean_episode_step = 1896.7, total_loss = 49.646, pg_loss = 18.642, baseline_loss = 36.645, entropy_loss = -5.6415, learner_queue_size = 32, _tick = 26208, _time = 1.6548e+09, train_seconds = 2.6916e+04)
[2022-06-10 03:36:40,682][root][INFO] - Step 102464000 @ 4091.1 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (step = 102464000, mean_episode_return = 67.367, mean_episode_step = 952.5, total_loss = -68.933, pg_loss = -79.007, baseline_loss = 15.872, entropy_loss = -5.7982, learner_queue_size = 32, _tick = 26216, _time = 1.6548e+09, train_seconds = 2.692e+04)
[2022-06-10 03:36:45,686][root][INFO] - Step 102484480 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 102484480, mean_episode_return = None, mean_episode_step = 1706.6, total_loss = 597.87, pg_loss = 473.87, baseline_loss = 129.68, entropy_loss = -5.6761, learner_queue_size = 32, _tick = 26222, _time = 1.6548e+09, train_seconds = 2.6926e+04)
[2022-06-10 03:36:50,690][root][INFO] - Step 102504960 @ 4092.7 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 102504960, mean_episode_return = 63.55, mean_episode_step = 2080.8, total_loss = 126.55, pg_loss = 77.942, baseline_loss = 53.732, entropy_loss = -5.1288, learner_queue_size = 32, _tick = 26228, _time = 1.6548e+09, train_seconds = 2.693e+04)
[2022-06-10 03:36:55,695][root][INFO] - Step 102522880 @ 3580.8 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 102522880, mean_episode_return = 37.53, mean_episode_step = 2190.9, total_loss = -16.807, pg_loss = -49.966, baseline_loss = 38.427, entropy_loss = -5.2683, learner_queue_size = 32, _tick = 26232, _time = 1.6548e+09, train_seconds = 2.6936e+04)
[2022-06-10 03:37:00,698][root][INFO] - Step 102543360 @ 4093.2 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 102543360, mean_episode_return = 35.88, mean_episode_step = 905.37, total_loss = 58.403, pg_loss = -15.646, baseline_loss = 78.677, entropy_loss = -4.6282, learner_queue_size = 32, _tick = 26239, _time = 1.6548e+09, train_seconds = 2.694e+04)
[2022-06-10 03:37:05,702][root][INFO] - Step 102563840 @ 4092.7 SPS. Inference batcher size: 77. Learner queue size: 32. Other stats: (step = 102563840, mean_episode_return = 146.31, mean_episode_step = 861.48, total_loss = 19.577, pg_loss = -7.8858, baseline_loss = 32.967, entropy_loss = -5.5046, learner_queue_size = 32, _tick = 26244, _time = 1.6548e+09, train_seconds = 2.6946e+04)
[2022-06-10 03:37:10,707][root][INFO] - Step 102581760 @ 3580.7 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (step = 102581760, mean_episode_return = None, mean_episode_step = 973.47, total_loss = 103.47, pg_loss = 82.083, baseline_loss = 27.412, entropy_loss = -6.0246, learner_queue_size = 32, _tick = 26250, _time = 1.6548e+09, train_seconds = 2.695e+04)
[2022-06-10 03:37:15,711][root][INFO] - Step 102602240 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 102602240, mean_episode_return = 39.995, mean_episode_step = 835.62, total_loss = 16.083, pg_loss = 2.4293, baseline_loss = 19.405, entropy_loss = -5.7506, learner_queue_size = 32, _tick = 26257, _time = 1.6548e+09, train_seconds = 2.6956e+04)
[2022-06-10 03:37:20,714][root][INFO] - Step 102622720 @ 4093.4 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 102622720, mean_episode_return = 29.62, mean_episode_step = 2144.9, total_loss = 78.399, pg_loss = 53.092, baseline_loss = 30.787, entropy_loss = -5.4807, learner_queue_size = 32, _tick = 26262, _time = 1.6548e+09, train_seconds = 2.696e+04)
[2022-06-10 03:37:25,718][root][INFO] - Step 102640640 @ 3581.1 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (step = 102640640, mean_episode_return = 11.46, mean_episode_step = 1593.4, total_loss = 71.271, pg_loss = 29.018, baseline_loss = 47.832, entropy_loss = -5.5791, learner_queue_size = 32, _tick = 26268, _time = 1.6548e+09, train_seconds = 2.6966e+04)
[2022-06-10 03:37:30,722][root][INFO] - Step 102661120 @ 4092.7 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 102661120, mean_episode_return = 17.955, mean_episode_step = 868.76, total_loss = 33.04, pg_loss = -27.75, baseline_loss = 66.387, entropy_loss = -5.5976, learner_queue_size = 32, _tick = 26274, _time = 1.6548e+09, train_seconds = 2.697e+04)
[2022-06-10 03:37:35,726][root][INFO] - Step 102681600 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 102681600, mean_episode_return = 77.095, mean_episode_step = 796.53, total_loss = -32.688, pg_loss = -67.16, baseline_loss = 39.825, entropy_loss = -5.3537, learner_queue_size = 32, _tick = 26279, _time = 1.6548e+09, train_seconds = 2.6976e+04)
[2022-06-10 03:37:40,730][root][INFO] - Step 102702080 @ 4092.7 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 102702080, mean_episode_return = 70.319, mean_episode_step = 954.24, total_loss = 219.64, pg_loss = 127.63, baseline_loss = 97.279, entropy_loss = -5.2707, learner_queue_size = 32, _tick = 26285, _time = 1.6548e+09, train_seconds = 2.698e+04)
[2022-06-10 03:37:45,734][root][INFO] - Step 102722560 @ 4092.8 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 102722560, mean_episode_return = 27.47, mean_episode_step = 969.48, total_loss = 95.793, pg_loss = 41.226, baseline_loss = 59.727, entropy_loss = -5.1605, learner_queue_size = 32, _tick = 26290, _time = 1.6548e+09, train_seconds = 2.6986e+04)
[2022-06-10 03:37:50,740][root][INFO] - Step 102740480 @ 3579.6 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 102740480, mean_episode_return = None, mean_episode_step = 858.88, total_loss = 133.71, pg_loss = 108.0, baseline_loss = 31.363, entropy_loss = -5.6555, learner_queue_size = 32, _tick = 26293, _time = 1.6548e+09, train_seconds = 2.699e+04)
[2022-06-10 03:37:55,746][root][INFO] - Step 102758400 @ 3579.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 102758400, mean_episode_return = None, mean_episode_step = 2373.0, total_loss = 223.26, pg_loss = 186.1, baseline_loss = 42.774, entropy_loss = -5.6096, learner_queue_size = 32, _tick = 26297, _time = 1.6548e+09, train_seconds = 2.6996e+04)
[2022-06-10 03:38:00,750][root][INFO] - Step 102778880 @ 4092.9 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 102778880, mean_episode_return = 78.58, mean_episode_step = 918.73, total_loss = -21.261, pg_loss = -52.026, baseline_loss = 36.267, entropy_loss = -5.5014, learner_queue_size = 32, _tick = 26305, _time = 1.6548e+09, train_seconds = 2.7001e+04)
[2022-06-10 03:38:05,754][root][INFO] - Step 102799360 @ 4092.7 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 102799360, mean_episode_return = 30.13, mean_episode_step = 960.42, total_loss = -163.86, pg_loss = -211.51, baseline_loss = 53.08, entropy_loss = -5.4289, learner_queue_size = 32, _tick = 26312, _time = 1.6548e+09, train_seconds = 2.7006e+04)
[2022-06-10 03:38:10,762][root][INFO] - Step 102817280 @ 3578.3 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 102817280, mean_episode_return = None, mean_episode_step = 2404.9, total_loss = 267.48, pg_loss = 216.46, baseline_loss = 56.478, entropy_loss = -5.4628, learner_queue_size = 32, _tick = 26317, _time = 1.6548e+09, train_seconds = 2.7011e+04)
[2022-06-10 03:38:15,766][root][INFO] - Step 102837760 @ 4092.6 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 102837760, mean_episode_return = 60.308, mean_episode_step = 1079.1, total_loss = 142.38, pg_loss = 83.047, baseline_loss = 64.7, entropy_loss = -5.3694, learner_queue_size = 32, _tick = 26323, _time = 1.6548e+09, train_seconds = 2.7016e+04)
[2022-06-10 03:38:20,771][root][INFO] - Step 102858240 @ 4092.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 102858240, mean_episode_return = 67.496, mean_episode_step = 1929.1, total_loss = 320.51, pg_loss = 252.66, baseline_loss = 73.439, entropy_loss = -5.5851, learner_queue_size = 32, _tick = 26329, _time = 1.6548e+09, train_seconds = 2.7021e+04)
[2022-06-10 03:38:25,774][root][INFO] - Step 102878720 @ 4093.5 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 102878720, mean_episode_return = None, mean_episode_step = 1585.4, total_loss = 96.567, pg_loss = 74.789, baseline_loss = 27.198, entropy_loss = -5.4195, learner_queue_size = 32, _tick = 26335, _time = 1.6548e+09, train_seconds = 2.7026e+04)
[2022-06-10 03:38:30,778][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 03:38:30,972][root][INFO] - Step 102899200 @ 4092.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 102899200, mean_episode_return = 18.12, mean_episode_step = 1727.2, total_loss = -55.964, pg_loss = -66.476, baseline_loss = 15.615, entropy_loss = -5.1026, learner_queue_size = 32, _tick = 26342, _time = 1.6548e+09, train_seconds = 2.7031e+04)
[2022-06-10 03:38:35,974][root][INFO] - Step 102917120 @ 3448.8 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 102917120, mean_episode_return = 40.121, mean_episode_step = 1161.8, total_loss = 98.737, pg_loss = 60.239, baseline_loss = 43.905, entropy_loss = -5.4065, learner_queue_size = 32, _tick = 26346, _time = 1.6548e+09, train_seconds = 2.7036e+04)
[2022-06-10 03:38:40,978][root][INFO] - Step 102937600 @ 4092.7 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 102937600, mean_episode_return = 104.07, mean_episode_step = 1172.0, total_loss = -11.187, pg_loss = -11.593, baseline_loss = 6.0286, entropy_loss = -5.6219, learner_queue_size = 32, _tick = 26352, _time = 1.6548e+09, train_seconds = 2.7041e+04)
[2022-06-10 03:38:45,982][root][INFO] - Step 102955520 @ 3581.2 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 102955520, mean_episode_return = 7.2597, mean_episode_step = 910.75, total_loss = 59.582, pg_loss = 30.622, baseline_loss = 34.393, entropy_loss = -5.4336, learner_queue_size = 32, _tick = 26358, _time = 1.6548e+09, train_seconds = 2.7046e+04)
[2022-06-10 03:38:50,986][root][INFO] - Step 102976000 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 102976000, mean_episode_return = 101.69, mean_episode_step = 1254.2, total_loss = 132.16, pg_loss = 34.793, baseline_loss = 102.71, entropy_loss = -5.3419, learner_queue_size = 32, _tick = 26366, _time = 1.6548e+09, train_seconds = 2.7051e+04)
[2022-06-10 03:38:55,990][root][INFO] - Step 102996480 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 102996480, mean_episode_return = None, mean_episode_step = 1283.3, total_loss = -7.3515, pg_loss = -34.955, baseline_loss = 32.794, entropy_loss = -5.1901, learner_queue_size = 32, _tick = 26373, _time = 1.6548e+09, train_seconds = 2.7056e+04)
[2022-06-10 03:39:00,998][root][INFO] - Step 103014400 @ 3578.4 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 103014400, mean_episode_return = 72.407, mean_episode_step = 1068.2, total_loss = -19.904, pg_loss = -35.017, baseline_loss = 20.634, entropy_loss = -5.5204, learner_queue_size = 32, _tick = 26379, _time = 1.6548e+09, train_seconds = 2.7061e+04)
[2022-06-10 03:39:06,002][root][INFO] - Step 103034880 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 103034880, mean_episode_return = 86.82, mean_episode_step = 1107.4, total_loss = -58.011, pg_loss = -76.852, baseline_loss = 24.418, entropy_loss = -5.5763, learner_queue_size = 32, _tick = 26385, _time = 1.6548e+09, train_seconds = 2.7066e+04)
[2022-06-10 03:39:11,006][root][INFO] - Step 103055360 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 103055360, mean_episode_return = 41.885, mean_episode_step = 1081.8, total_loss = -20.715, pg_loss = -43.981, baseline_loss = 28.915, entropy_loss = -5.6487, learner_queue_size = 32, _tick = 26391, _time = 1.6548e+09, train_seconds = 2.7071e+04)
[2022-06-10 03:39:16,010][root][INFO] - Step 103073280 @ 3581.1 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (step = 103073280, mean_episode_return = 2.8998, mean_episode_step = 836.61, total_loss = -136.19, pg_loss = -164.24, baseline_loss = 33.411, entropy_loss = -5.3669, learner_queue_size = 32, _tick = 26397, _time = 1.6548e+09, train_seconds = 2.7076e+04)
[2022-06-10 03:39:21,014][root][INFO] - Step 103093760 @ 4092.7 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 103093760, mean_episode_return = 76.86, mean_episode_step = 924.08, total_loss = 142.59, pg_loss = 95.677, baseline_loss = 52.185, entropy_loss = -5.2752, learner_queue_size = 32, _tick = 26404, _time = 1.6548e+09, train_seconds = 2.7081e+04)
[2022-06-10 03:39:26,018][root][INFO] - Step 103114240 @ 4092.7 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 103114240, mean_episode_return = 27.63, mean_episode_step = 834.61, total_loss = 204.17, pg_loss = 114.2, baseline_loss = 95.14, entropy_loss = -5.1695, learner_queue_size = 32, _tick = 26409, _time = 1.6548e+09, train_seconds = 2.7086e+04)
[2022-06-10 03:39:31,022][root][INFO] - Step 103132160 @ 3581.1 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (step = 103132160, mean_episode_return = 38.41, mean_episode_step = 808.89, total_loss = 253.49, pg_loss = 197.9, baseline_loss = 60.827, entropy_loss = -5.2399, learner_queue_size = 32, _tick = 26416, _time = 1.6548e+09, train_seconds = 2.7091e+04)
[2022-06-10 03:39:36,026][root][INFO] - Step 103152640 @ 4092.8 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 103152640, mean_episode_return = None, mean_episode_step = 1135.9, total_loss = 19.503, pg_loss = -1.5234, baseline_loss = 26.598, entropy_loss = -5.5716, learner_queue_size = 32, _tick = 26422, _time = 1.6548e+09, train_seconds = 2.7096e+04)
[2022-06-10 03:39:41,030][root][INFO] - Step 103170560 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 103170560, mean_episode_return = 15.55, mean_episode_step = 1072.8, total_loss = 10.853, pg_loss = -18.942, baseline_loss = 35.29, entropy_loss = -5.4955, learner_queue_size = 32, _tick = 26426, _time = 1.6548e+09, train_seconds = 2.7101e+04)
[2022-06-10 03:39:46,034][root][INFO] - Step 103191040 @ 4092.8 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 103191040, mean_episode_return = 65.953, mean_episode_step = 1057.1, total_loss = 71.173, pg_loss = 30.004, baseline_loss = 46.699, entropy_loss = -5.5297, learner_queue_size = 32, _tick = 26433, _time = 1.6548e+09, train_seconds = 2.7106e+04)
[2022-06-10 03:39:51,038][root][INFO] - Step 103211520 @ 4092.7 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 103211520, mean_episode_return = 52.44, mean_episode_step = 1061.2, total_loss = -69.77, pg_loss = -95.037, baseline_loss = 30.465, entropy_loss = -5.1984, learner_queue_size = 32, _tick = 26438, _time = 1.6548e+09, train_seconds = 2.7111e+04)
[2022-06-10 03:39:56,042][root][INFO] - Step 103232000 @ 4092.7 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 103232000, mean_episode_return = None, mean_episode_step = 808.72, total_loss = -8.1976, pg_loss = -35.539, baseline_loss = 32.588, entropy_loss = -5.2461, learner_queue_size = 32, _tick = 26444, _time = 1.6548e+09, train_seconds = 2.7116e+04)
[2022-06-10 03:40:01,046][root][INFO] - Step 103249920 @ 3581.1 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 103249920, mean_episode_return = -5.9803, mean_episode_step = 1186.3, total_loss = 220.35, pg_loss = 176.55, baseline_loss = 49.299, entropy_loss = -5.4982, learner_queue_size = 32, _tick = 26450, _time = 1.6548e+09, train_seconds = 2.7121e+04)
[2022-06-10 03:40:06,050][root][INFO] - Step 103270400 @ 4092.8 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 103270400, mean_episode_return = 96.417, mean_episode_step = 1048.9, total_loss = -225.03, pg_loss = -277.09, baseline_loss = 57.348, entropy_loss = -5.2903, learner_queue_size = 32, _tick = 26457, _time = 1.6548e+09, train_seconds = 2.7126e+04)
[2022-06-10 03:40:11,054][root][INFO] - Step 103288320 @ 3581.1 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 103288320, mean_episode_return = None, mean_episode_step = 986.94, total_loss = 287.2, pg_loss = 224.75, baseline_loss = 67.911, entropy_loss = -5.4548, learner_queue_size = 32, _tick = 26462, _time = 1.6548e+09, train_seconds = 2.7131e+04)
[2022-06-10 03:40:16,058][root][INFO] - Step 103308800 @ 4092.8 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 103308800, mean_episode_return = 2.9195, mean_episode_step = 936.02, total_loss = 28.264, pg_loss = -11.091, baseline_loss = 44.705, entropy_loss = -5.35, learner_queue_size = 32, _tick = 26468, _time = 1.6548e+09, train_seconds = 2.7136e+04)
[2022-06-10 03:40:21,064][root][INFO] - Step 103329280 @ 4091.2 SPS. Inference batcher size: 75. Learner queue size: 32. Other stats: (step = 103329280, mean_episode_return = 59.331, mean_episode_step = 788.6, total_loss = -131.19, pg_loss = -147.45, baseline_loss = 21.341, entropy_loss = -5.082, learner_queue_size = 32, _tick = 26475, _time = 1.6548e+09, train_seconds = 2.7141e+04)
[2022-06-10 03:40:26,066][root][INFO] - Step 103347200 @ 3582.5 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 103347200, mean_episode_return = 69.876, mean_episode_step = 1073.5, total_loss = 115.67, pg_loss = 49.926, baseline_loss = 71.07, entropy_loss = -5.3316, learner_queue_size = 32, _tick = 26481, _time = 1.6548e+09, train_seconds = 2.7146e+04)
[2022-06-10 03:40:31,070][root][INFO] - Step 103367680 @ 4092.6 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 103367680, mean_episode_return = 43.46, mean_episode_step = 1159.6, total_loss = -19.932, pg_loss = -63.116, baseline_loss = 48.354, entropy_loss = -5.17, learner_queue_size = 32, _tick = 26488, _time = 1.6548e+09, train_seconds = 2.7151e+04)
[2022-06-10 03:40:36,074][root][INFO] - Step 103385600 @ 3581.2 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 103385600, mean_episode_return = 14.62, mean_episode_step = 761.65, total_loss = -6.9449, pg_loss = -30.701, baseline_loss = 29.281, entropy_loss = -5.5251, learner_queue_size = 32, _tick = 26494, _time = 1.6548e+09, train_seconds = 2.7156e+04)
[2022-06-10 03:40:41,078][root][INFO] - Step 103406080 @ 4092.7 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 103406080, mean_episode_return = 21.975, mean_episode_step = 1086.1, total_loss = 133.49, pg_loss = 89.121, baseline_loss = 49.875, entropy_loss = -5.5071, learner_queue_size = 32, _tick = 26500, _time = 1.6548e+09, train_seconds = 2.7161e+04)
[2022-06-10 03:40:46,082][root][INFO] - Step 103426560 @ 4092.7 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 103426560, mean_episode_return = None, mean_episode_step = 947.44, total_loss = 123.99, pg_loss = 73.189, baseline_loss = 56.412, entropy_loss = -5.6111, learner_queue_size = 32, _tick = 26504, _time = 1.6548e+09, train_seconds = 2.7166e+04)
[2022-06-10 03:40:51,086][root][INFO] - Step 103447040 @ 4092.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 103447040, mean_episode_return = 74.78, mean_episode_step = 1133.5, total_loss = 354.42, pg_loss = 272.73, baseline_loss = 87.44, entropy_loss = -5.7567, learner_queue_size = 32, _tick = 26512, _time = 1.6548e+09, train_seconds = 2.7171e+04)
[2022-06-10 03:40:56,090][root][INFO] - Step 103467520 @ 4092.8 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 103467520, mean_episode_return = None, mean_episode_step = 955.22, total_loss = 180.82, pg_loss = 149.66, baseline_loss = 36.709, entropy_loss = -5.5461, learner_queue_size = 32, _tick = 26516, _time = 1.6548e+09, train_seconds = 2.7176e+04)
[2022-06-10 03:41:01,094][root][INFO] - Step 103485440 @ 3580.7 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 103485440, mean_episode_return = 35.731, mean_episode_step = 861.5, total_loss = 243.11, pg_loss = 159.94, baseline_loss = 88.66, entropy_loss = -5.4864, learner_queue_size = 32, _tick = 26520, _time = 1.6548e+09, train_seconds = 2.7181e+04)
[2022-06-10 03:41:06,098][root][INFO] - Step 103503360 @ 3581.5 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 103503360, mean_episode_return = 50.765, mean_episode_step = 1096.9, total_loss = 105.31, pg_loss = 36.36, baseline_loss = 74.514, entropy_loss = -5.5598, learner_queue_size = 32, _tick = 26526, _time = 1.6548e+09, train_seconds = 2.7186e+04)
[2022-06-10 03:41:11,102][root][INFO] - Step 103523840 @ 4092.6 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 103523840, mean_episode_return = -12.78, mean_episode_step = 1016.0, total_loss = 15.712, pg_loss = -14.738, baseline_loss = 35.962, entropy_loss = -5.5124, learner_queue_size = 32, _tick = 26533, _time = 1.6548e+09, train_seconds = 2.7191e+04)
[2022-06-10 03:41:16,106][root][INFO] - Step 103541760 @ 3581.0 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 103541760, mean_episode_return = None, mean_episode_step = 1074.7, total_loss = -5.2179, pg_loss = -17.318, baseline_loss = 17.906, entropy_loss = -5.8063, learner_queue_size = 32, _tick = 26537, _time = 1.6548e+09, train_seconds = 2.7196e+04)
[2022-06-10 03:41:21,110][root][INFO] - Step 103562240 @ 4093.0 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 103562240, mean_episode_return = None, mean_episode_step = 1065.5, total_loss = 335.58, pg_loss = 266.45, baseline_loss = 74.663, entropy_loss = -5.5264, learner_queue_size = 32, _tick = 26544, _time = 1.6548e+09, train_seconds = 2.7201e+04)
[2022-06-10 03:41:26,114][root][INFO] - Step 103582720 @ 4092.7 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 103582720, mean_episode_return = 64.379, mean_episode_step = 976.38, total_loss = 248.86, pg_loss = 207.58, baseline_loss = 46.811, entropy_loss = -5.5256, learner_queue_size = 32, _tick = 26549, _time = 1.6548e+09, train_seconds = 2.7206e+04)
[2022-06-10 03:41:31,118][root][INFO] - Step 103600640 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 103600640, mean_episode_return = 11.85, mean_episode_step = 1175.4, total_loss = 196.63, pg_loss = 131.93, baseline_loss = 70.178, entropy_loss = -5.476, learner_queue_size = 32, _tick = 26556, _time = 1.6548e+09, train_seconds = 2.7211e+04)
[2022-06-10 03:41:36,124][root][INFO] - Step 103621120 @ 4091.4 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 103621120, mean_episode_return = 73.71, mean_episode_step = 1198.5, total_loss = 101.72, pg_loss = 34.975, baseline_loss = 72.224, entropy_loss = -5.481, learner_queue_size = 32, _tick = 26561, _time = 1.6548e+09, train_seconds = 2.7216e+04)
[2022-06-10 03:41:41,126][root][INFO] - Step 103639040 @ 3582.3 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 103639040, mean_episode_return = 18.98, mean_episode_step = 1178.7, total_loss = -115.91, pg_loss = -118.42, baseline_loss = 7.8872, entropy_loss = -5.3832, learner_queue_size = 32, _tick = 26567, _time = 1.6548e+09, train_seconds = 2.7221e+04)
[2022-06-10 03:41:46,130][root][INFO] - Step 103659520 @ 4092.7 SPS. Inference batcher size: 75. Learner queue size: 32. Other stats: (step = 103659520, mean_episode_return = 21.275, mean_episode_step = 958.55, total_loss = 130.65, pg_loss = 59.802, baseline_loss = 76.322, entropy_loss = -5.4721, learner_queue_size = 32, _tick = 26571, _time = 1.6548e+09, train_seconds = 2.7226e+04)
[2022-06-10 03:41:51,134][root][INFO] - Step 103677440 @ 3581.2 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 103677440, mean_episode_return = 103.25, mean_episode_step = 996.3, total_loss = 101.47, pg_loss = 38.012, baseline_loss = 68.851, entropy_loss = -5.3953, learner_queue_size = 32, _tick = 26576, _time = 1.6548e+09, train_seconds = 2.7231e+04)
[2022-06-10 03:41:56,138][root][INFO] - Step 103697920 @ 4092.8 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 103697920, mean_episode_return = 19.58, mean_episode_step = 1127.6, total_loss = -38.472, pg_loss = -51.133, baseline_loss = 18.144, entropy_loss = -5.4837, learner_queue_size = 32, _tick = 26583, _time = 1.6548e+09, train_seconds = 2.7236e+04)
[2022-06-10 03:42:01,142][root][INFO] - Step 103718400 @ 4092.7 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 103718400, mean_episode_return = 8.5598, mean_episode_step = 1290.4, total_loss = 45.962, pg_loss = 17.004, baseline_loss = 34.484, entropy_loss = -5.5264, learner_queue_size = 32, _tick = 26588, _time = 1.6548e+09, train_seconds = 2.7241e+04)
[2022-06-10 03:42:06,146][root][INFO] - Step 103736320 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 103736320, mean_episode_return = 47.55, mean_episode_step = 1156.8, total_loss = 88.063, pg_loss = 57.975, baseline_loss = 35.678, entropy_loss = -5.5896, learner_queue_size = 32, _tick = 26594, _time = 1.6548e+09, train_seconds = 2.7246e+04)
[2022-06-10 03:42:11,150][root][INFO] - Step 103756800 @ 4092.8 SPS. Inference batcher size: 85. Learner queue size: 32. Other stats: (step = 103756800, mean_episode_return = None, mean_episode_step = 1264.2, total_loss = 123.54, pg_loss = 86.669, baseline_loss = 42.428, entropy_loss = -5.5621, learner_queue_size = 32, _tick = 26599, _time = 1.6548e+09, train_seconds = 2.7251e+04)
[2022-06-10 03:42:16,155][root][INFO] - Step 103774720 @ 3580.6 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 103774720, mean_episode_return = None, mean_episode_step = 1260.6, total_loss = -37.408, pg_loss = -53.128, baseline_loss = 21.282, entropy_loss = -5.5623, learner_queue_size = 32, _tick = 26604, _time = 1.6548e+09, train_seconds = 2.7256e+04)
[2022-06-10 03:42:21,158][root][INFO] - Step 103795200 @ 4093.3 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 103795200, mean_episode_return = None, mean_episode_step = 1155.9, total_loss = 25.226, pg_loss = -4.6002, baseline_loss = 35.399, entropy_loss = -5.5727, learner_queue_size = 32, _tick = 26609, _time = 1.6548e+09, train_seconds = 2.7261e+04)
[2022-06-10 03:42:26,162][root][INFO] - Step 103815680 @ 4092.7 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 103815680, mean_episode_return = 76.563, mean_episode_step = 1145.8, total_loss = -102.09, pg_loss = -137.65, baseline_loss = 40.946, entropy_loss = -5.3855, learner_queue_size = 32, _tick = 26615, _time = 1.6548e+09, train_seconds = 2.7266e+04)
[2022-06-10 03:42:31,168][root][INFO] - Step 103836160 @ 4090.9 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 103836160, mean_episode_return = 86.999, mean_episode_step = 1445.1, total_loss = 219.09, pg_loss = 144.57, baseline_loss = 80.057, entropy_loss = -5.539, learner_queue_size = 32, _tick = 26621, _time = 1.6548e+09, train_seconds = 2.7271e+04)
[2022-06-10 03:42:36,174][root][INFO] - Step 103854080 @ 3579.8 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 103854080, mean_episode_return = 71.738, mean_episode_step = 975.19, total_loss = 383.02, pg_loss = 118.64, baseline_loss = 269.76, entropy_loss = -5.3781, learner_queue_size = 32, _tick = 26626, _time = 1.6548e+09, train_seconds = 2.7276e+04)
[2022-06-10 03:42:41,178][root][INFO] - Step 103874560 @ 4092.7 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 103874560, mean_episode_return = 24.24, mean_episode_step = 1212.5, total_loss = 65.265, pg_loss = 9.3617, baseline_loss = 61.414, entropy_loss = -5.5098, learner_queue_size = 32, _tick = 26630, _time = 1.6548e+09, train_seconds = 2.7281e+04)
[2022-06-10 03:42:46,182][root][INFO] - Step 103892480 @ 3581.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 103892480, mean_episode_return = 52.21, mean_episode_step = 1270.3, total_loss = 79.933, pg_loss = 48.406, baseline_loss = 37.078, entropy_loss = -5.5519, learner_queue_size = 32, _tick = 26634, _time = 1.6548e+09, train_seconds = 2.7286e+04)
[2022-06-10 03:42:51,186][root][INFO] - Step 103912960 @ 4092.7 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 103912960, mean_episode_return = 46.968, mean_episode_step = 1378.5, total_loss = -4.1424, pg_loss = -38.993, baseline_loss = 40.272, entropy_loss = -5.4216, learner_queue_size = 32, _tick = 26639, _time = 1.6548e+09, train_seconds = 2.7291e+04)
[2022-06-10 03:42:56,190][root][INFO] - Step 103930880 @ 3581.1 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 103930880, mean_episode_return = 88.21, mean_episode_step = 1200.7, total_loss = 154.86, pg_loss = 114.97, baseline_loss = 45.316, entropy_loss = -5.4286, learner_queue_size = 32, _tick = 26645, _time = 1.6548e+09, train_seconds = 2.7296e+04)
[2022-06-10 03:43:01,194][root][INFO] - Step 103951360 @ 4092.7 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (step = 103951360, mean_episode_return = 55.093, mean_episode_step = 1449.0, total_loss = 97.923, pg_loss = 1.7453, baseline_loss = 101.55, entropy_loss = -5.3719, learner_queue_size = 32, _tick = 26652, _time = 1.6548e+09, train_seconds = 2.7301e+04)
[2022-06-10 03:43:06,198][root][INFO] - Step 103971840 @ 4092.8 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 103971840, mean_episode_return = 15.651, mean_episode_step = 1256.5, total_loss = 11.156, pg_loss = -18.136, baseline_loss = 34.826, entropy_loss = -5.5344, learner_queue_size = 32, _tick = 26659, _time = 1.6548e+09, train_seconds = 2.7306e+04)
[2022-06-10 03:43:11,203][root][INFO] - Step 103992320 @ 4091.8 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 103992320, mean_episode_return = 51.039, mean_episode_step = 946.47, total_loss = 431.74, pg_loss = 260.55, baseline_loss = 176.72, entropy_loss = -5.526, learner_queue_size = 32, _tick = 26666, _time = 1.6548e+09, train_seconds = 2.7311e+04)
[2022-06-10 03:43:16,206][root][INFO] - Step 104010240 @ 3581.9 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 104010240, mean_episode_return = -3.17, mean_episode_step = 1170.9, total_loss = 340.67, pg_loss = 278.83, baseline_loss = 67.203, entropy_loss = -5.3674, learner_queue_size = 32, _tick = 26672, _time = 1.6548e+09, train_seconds = 2.7316e+04)
[2022-06-10 03:43:21,210][root][INFO] - Step 104030720 @ 4092.7 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 104030720, mean_episode_return = 74.251, mean_episode_step = 838.04, total_loss = 339.79, pg_loss = 227.75, baseline_loss = 117.23, entropy_loss = -5.1889, learner_queue_size = 32, _tick = 26678, _time = 1.6548e+09, train_seconds = 2.7321e+04)
[2022-06-10 03:43:26,215][root][INFO] - Step 104051200 @ 4092.0 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 104051200, mean_episode_return = 6.66, mean_episode_step = 1336.9, total_loss = -30.516, pg_loss = -48.98, baseline_loss = 23.951, entropy_loss = -5.4871, learner_queue_size = 32, _tick = 26685, _time = 1.6548e+09, train_seconds = 2.7326e+04)
[2022-06-10 03:43:31,218][root][INFO] - Step 104069120 @ 3581.8 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 104069120, mean_episode_return = 42.63, mean_episode_step = 1014.8, total_loss = 32.899, pg_loss = -0.68613, baseline_loss = 39.106, entropy_loss = -5.5212, learner_queue_size = 32, _tick = 26690, _time = 1.6548e+09, train_seconds = 2.7331e+04)
[2022-06-10 03:43:36,222][root][INFO] - Step 104089600 @ 4092.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 104089600, mean_episode_return = 72.56, mean_episode_step = 806.48, total_loss = -87.793, pg_loss = -109.09, baseline_loss = 26.616, entropy_loss = -5.3185, learner_queue_size = 32, _tick = 26698, _time = 1.6548e+09, train_seconds = 2.7336e+04)
[2022-06-10 03:43:41,226][root][INFO] - Step 104110080 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 104110080, mean_episode_return = 15.585, mean_episode_step = 1015.5, total_loss = -90.291, pg_loss = -119.0, baseline_loss = 34.226, entropy_loss = -5.5137, learner_queue_size = 32, _tick = 26703, _time = 1.6548e+09, train_seconds = 2.7341e+04)
[2022-06-10 03:43:46,230][root][INFO] - Step 104128000 @ 3581.2 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 104128000, mean_episode_return = -18.4, mean_episode_step = 1014.6, total_loss = 8.4098, pg_loss = -11.182, baseline_loss = 24.616, entropy_loss = -5.0242, learner_queue_size = 32, _tick = 26709, _time = 1.6548e+09, train_seconds = 2.7346e+04)
[2022-06-10 03:43:51,236][root][INFO] - Step 104148480 @ 4091.0 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 104148480, mean_episode_return = -0.040267, mean_episode_step = 1107.5, total_loss = 3.3124, pg_loss = -17.335, baseline_loss = 26.038, entropy_loss = -5.3902, learner_queue_size = 32, _tick = 26716, _time = 1.6548e+09, train_seconds = 2.7351e+04)
[2022-06-10 03:43:56,242][root][INFO] - Step 104166400 @ 3579.7 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 104166400, mean_episode_return = 25.54, mean_episode_step = 969.3, total_loss = 46.123, pg_loss = 21.028, baseline_loss = 30.832, entropy_loss = -5.7374, learner_queue_size = 32, _tick = 26721, _time = 1.6548e+09, train_seconds = 2.7356e+04)
[2022-06-10 03:44:01,246][root][INFO] - Step 104186880 @ 4092.8 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (step = 104186880, mean_episode_return = 18.56, mean_episode_step = 1102.8, total_loss = -92.687, pg_loss = -120.02, baseline_loss = 32.883, entropy_loss = -5.5517, learner_queue_size = 32, _tick = 26726, _time = 1.6548e+09, train_seconds = 2.7361e+04)
[2022-06-10 03:44:06,250][root][INFO] - Step 104204800 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 104204800, mean_episode_return = 44.235, mean_episode_step = 1049.5, total_loss = 282.02, pg_loss = 220.81, baseline_loss = 66.831, entropy_loss = -5.6147, learner_queue_size = 32, _tick = 26732, _time = 1.6548e+09, train_seconds = 2.7366e+04)
[2022-06-10 03:44:11,254][root][INFO] - Step 104225280 @ 4092.7 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 104225280, mean_episode_return = None, mean_episode_step = 1181.4, total_loss = 201.36, pg_loss = 143.55, baseline_loss = 63.383, entropy_loss = -5.577, learner_queue_size = 32, _tick = 26737, _time = 1.6548e+09, train_seconds = 2.7371e+04)
[2022-06-10 03:44:16,258][root][INFO] - Step 104243200 @ 3581.2 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 104243200, mean_episode_return = 194.98, mean_episode_step = 1068.1, total_loss = 289.8, pg_loss = 226.27, baseline_loss = 69.031, entropy_loss = -5.5006, learner_queue_size = 32, _tick = 26743, _time = 1.6548e+09, train_seconds = 2.7376e+04)
[2022-06-10 03:44:21,262][root][INFO] - Step 104263680 @ 4092.8 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 104263680, mean_episode_return = 44.125, mean_episode_step = 1197.5, total_loss = 7.5067, pg_loss = -24.163, baseline_loss = 37.109, entropy_loss = -5.4396, learner_queue_size = 32, _tick = 26749, _time = 1.6548e+09, train_seconds = 2.7381e+04)
[2022-06-10 03:44:26,266][root][INFO] - Step 104281600 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 104281600, mean_episode_return = 70.33, mean_episode_step = 1061.6, total_loss = 146.2, pg_loss = 107.64, baseline_loss = 44.238, entropy_loss = -5.6797, learner_queue_size = 32, _tick = 26755, _time = 1.6548e+09, train_seconds = 2.7386e+04)
[2022-06-10 03:44:31,270][root][INFO] - Step 104302080 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 104302080, mean_episode_return = 126.75, mean_episode_step = 1009.0, total_loss = 137.16, pg_loss = 62.765, baseline_loss = 79.93, entropy_loss = -5.5328, learner_queue_size = 32, _tick = 26762, _time = 1.6548e+09, train_seconds = 2.7391e+04)
[2022-06-10 03:44:36,274][root][INFO] - Step 104320000 @ 3581.1 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 104320000, mean_episode_return = 256.84, mean_episode_step = 1081.4, total_loss = 13.823, pg_loss = -21.723, baseline_loss = 41.134, entropy_loss = -5.5874, learner_queue_size = 32, _tick = 26768, _time = 1.6548e+09, train_seconds = 2.7396e+04)
[2022-06-10 03:44:41,278][root][INFO] - Step 104340480 @ 4092.6 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 104340480, mean_episode_return = 151.35, mean_episode_step = 1092.7, total_loss = 40.726, pg_loss = -2.8778, baseline_loss = 49.053, entropy_loss = -5.4487, learner_queue_size = 32, _tick = 26775, _time = 1.6548e+09, train_seconds = 2.7401e+04)
[2022-06-10 03:44:46,282][root][INFO] - Step 104360960 @ 4092.9 SPS. Inference batcher size: 89. Learner queue size: 32. Other stats: (step = 104360960, mean_episode_return = None, mean_episode_step = 1243.5, total_loss = 163.77, pg_loss = 97.282, baseline_loss = 72.179, entropy_loss = -5.6914, learner_queue_size = 32, _tick = 26781, _time = 1.6548e+09, train_seconds = 2.7406e+04)
[2022-06-10 03:44:51,286][root][INFO] - Step 104378880 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 104378880, mean_episode_return = 9.1198, mean_episode_step = 1103.6, total_loss = 383.68, pg_loss = 189.57, baseline_loss = 199.78, entropy_loss = -5.6649, learner_queue_size = 32, _tick = 26786, _time = 1.6548e+09, train_seconds = 2.7411e+04)
[2022-06-10 03:44:56,290][root][INFO] - Step 104399360 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 104399360, mean_episode_return = 32.015, mean_episode_step = 940.22, total_loss = -57.367, pg_loss = -77.901, baseline_loss = 25.734, entropy_loss = -5.2, learner_queue_size = 32, _tick = 26791, _time = 1.6548e+09, train_seconds = 2.7416e+04)
[2022-06-10 03:45:01,294][root][INFO] - Step 104419840 @ 4092.7 SPS. Inference batcher size: 73. Learner queue size: 32. Other stats: (step = 104419840, mean_episode_return = 83.079, mean_episode_step = 960.66, total_loss = 342.76, pg_loss = 271.2, baseline_loss = 76.795, entropy_loss = -5.2262, learner_queue_size = 32, _tick = 26798, _time = 1.6548e+09, train_seconds = 2.7421e+04)
[2022-06-10 03:45:06,298][root][INFO] - Step 104437760 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 104437760, mean_episode_return = 55.81, mean_episode_step = 882.97, total_loss = -127.75, pg_loss = -176.48, baseline_loss = 53.979, entropy_loss = -5.2485, learner_queue_size = 32, _tick = 26805, _time = 1.6548e+09, train_seconds = 2.7426e+04)
[2022-06-10 03:45:11,302][root][INFO] - Step 104458240 @ 4092.6 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 104458240, mean_episode_return = 62.163, mean_episode_step = 931.22, total_loss = 26.045, pg_loss = -12.756, baseline_loss = 43.902, entropy_loss = -5.1009, learner_queue_size = 32, _tick = 26812, _time = 1.6548e+09, train_seconds = 2.7431e+04)
[2022-06-10 03:45:16,306][root][INFO] - Step 104476160 @ 3581.3 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 104476160, mean_episode_return = 70.294, mean_episode_step = 915.74, total_loss = 174.89, pg_loss = 136.63, baseline_loss = 43.827, entropy_loss = -5.5721, learner_queue_size = 32, _tick = 26819, _time = 1.6548e+09, train_seconds = 2.7436e+04)
[2022-06-10 03:45:21,310][root][INFO] - Step 104496640 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 104496640, mean_episode_return = 48.46, mean_episode_step = 930.38, total_loss = 77.732, pg_loss = 40.456, baseline_loss = 42.859, entropy_loss = -5.583, learner_queue_size = 32, _tick = 26827, _time = 1.6548e+09, train_seconds = 2.7441e+04)
[2022-06-10 03:45:26,317][root][INFO] - Step 104517120 @ 4090.7 SPS. Inference batcher size: 80. Learner queue size: 32. Other stats: (step = 104517120, mean_episode_return = -1.03, mean_episode_step = 764.26, total_loss = -90.546, pg_loss = -102.87, baseline_loss = 17.667, entropy_loss = -5.3476, learner_queue_size = 32, _tick = 26835, _time = 1.6548e+09, train_seconds = 2.7446e+04)
[2022-06-10 03:45:31,319][root][INFO] - Step 104535040 @ 3582.0 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 104535040, mean_episode_return = 19.42, mean_episode_step = 888.65, total_loss = 108.87, pg_loss = 69.566, baseline_loss = 44.736, entropy_loss = -5.4362, learner_queue_size = 32, _tick = 26841, _time = 1.6548e+09, train_seconds = 2.7451e+04)
[2022-06-10 03:45:36,322][root][INFO] - Step 104555520 @ 4093.8 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 104555520, mean_episode_return = 76.595, mean_episode_step = 839.64, total_loss = 30.48, pg_loss = -22.768, baseline_loss = 58.373, entropy_loss = -5.1251, learner_queue_size = 32, _tick = 26849, _time = 1.6548e+09, train_seconds = 2.7456e+04)
[2022-06-10 03:45:41,326][root][INFO] - Step 104576000 @ 4092.6 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 104576000, mean_episode_return = 6.6565, mean_episode_step = 923.08, total_loss = -94.752, pg_loss = -138.61, baseline_loss = 49.164, entropy_loss = -5.3067, learner_queue_size = 32, _tick = 26855, _time = 1.6548e+09, train_seconds = 2.7461e+04)
[2022-06-10 03:45:46,330][root][INFO] - Step 104593920 @ 3581.2 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 104593920, mean_episode_return = 36.746, mean_episode_step = 879.31, total_loss = 60.436, pg_loss = 15.937, baseline_loss = 49.86, entropy_loss = -5.3617, learner_queue_size = 32, _tick = 26861, _time = 1.6548e+09, train_seconds = 2.7466e+04)
[2022-06-10 03:45:51,334][root][INFO] - Step 104614400 @ 4092.8 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 104614400, mean_episode_return = 58.236, mean_episode_step = 915.35, total_loss = -32.819, pg_loss = -63.818, baseline_loss = 36.535, entropy_loss = -5.5356, learner_queue_size = 32, _tick = 26868, _time = 1.6548e+09, train_seconds = 2.7471e+04)
[2022-06-10 03:45:56,338][root][INFO] - Step 104634880 @ 4092.7 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 104634880, mean_episode_return = None, mean_episode_step = 810.62, total_loss = -10.053, pg_loss = -52.192, baseline_loss = 47.56, entropy_loss = -5.4214, learner_queue_size = 32, _tick = 26873, _time = 1.6548e+09, train_seconds = 2.7476e+04)
[2022-06-10 03:46:01,342][root][INFO] - Step 104652800 @ 3581.2 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 104652800, mean_episode_return = 52.031, mean_episode_step = 766.73, total_loss = -46.64, pg_loss = -76.433, baseline_loss = 35.001, entropy_loss = -5.2077, learner_queue_size = 32, _tick = 26879, _time = 1.6548e+09, train_seconds = 2.7481e+04)
[2022-06-10 03:46:06,346][root][INFO] - Step 104673280 @ 4092.7 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 104673280, mean_episode_return = 39.405, mean_episode_step = 911.42, total_loss = 195.33, pg_loss = 111.62, baseline_loss = 88.941, entropy_loss = -5.2332, learner_queue_size = 32, _tick = 26887, _time = 1.6548e+09, train_seconds = 2.7486e+04)
[2022-06-10 03:46:11,350][root][INFO] - Step 104691200 @ 3581.2 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (step = 104691200, mean_episode_return = None, mean_episode_step = 1064.7, total_loss = 115.41, pg_loss = 58.864, baseline_loss = 61.231, entropy_loss = -4.6895, learner_queue_size = 32, _tick = 26893, _time = 1.6548e+09, train_seconds = 2.7491e+04)
[2022-06-10 03:46:16,355][root][INFO] - Step 104711680 @ 4091.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 104711680, mean_episode_return = None, mean_episode_step = 1092.2, total_loss = 69.464, pg_loss = 13.622, baseline_loss = 60.593, entropy_loss = -4.7511, learner_queue_size = 32, _tick = 26896, _time = 1.6548e+09, train_seconds = 2.7496e+04)
[2022-06-10 03:46:21,358][root][INFO] - Step 104732160 @ 4093.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 104732160, mean_episode_return = 38.94, mean_episode_step = 1053.1, total_loss = -126.9, pg_loss = -133.19, baseline_loss = 11.528, entropy_loss = -5.2377, learner_queue_size = 32, _tick = 26904, _time = 1.6548e+09, train_seconds = 2.7501e+04)
[2022-06-10 03:46:26,366][root][INFO] - Step 104750080 @ 3578.4 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 104750080, mean_episode_return = 18.76, mean_episode_step = 1142.4, total_loss = -83.818, pg_loss = -87.096, baseline_loss = 9.0036, entropy_loss = -5.726, learner_queue_size = 32, _tick = 26911, _time = 1.6548e+09, train_seconds = 2.7506e+04)
[2022-06-10 03:46:31,370][root][INFO] - Step 104770560 @ 4092.6 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 104770560, mean_episode_return = 45.826, mean_episode_step = 768.97, total_loss = 222.28, pg_loss = 177.22, baseline_loss = 50.52, entropy_loss = -5.4575, learner_queue_size = 32, _tick = 26918, _time = 1.6548e+09, train_seconds = 2.7511e+04)
[2022-06-10 03:46:36,374][root][INFO] - Step 104791040 @ 4092.7 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 104791040, mean_episode_return = 43.02, mean_episode_step = 888.91, total_loss = 360.25, pg_loss = 208.81, baseline_loss = 156.85, entropy_loss = -5.4091, learner_queue_size = 32, _tick = 26925, _time = 1.6548e+09, train_seconds = 2.7516e+04)
[2022-06-10 03:46:41,378][root][INFO] - Step 104808960 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 104808960, mean_episode_return = 85.789, mean_episode_step = 993.52, total_loss = 49.186, pg_loss = -3.5723, baseline_loss = 58.026, entropy_loss = -5.268, learner_queue_size = 32, _tick = 26930, _time = 1.6548e+09, train_seconds = 2.7521e+04)
[2022-06-10 03:46:46,382][root][INFO] - Step 104829440 @ 4092.8 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 104829440, mean_episode_return = 44.851, mean_episode_step = 1393.3, total_loss = -27.103, pg_loss = -50.01, baseline_loss = 28.335, entropy_loss = -5.4279, learner_queue_size = 32, _tick = 26936, _time = 1.6548e+09, train_seconds = 2.7526e+04)
[2022-06-10 03:46:51,386][root][INFO] - Step 104849920 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 104849920, mean_episode_return = 90.786, mean_episode_step = 1361.2, total_loss = -25.9, pg_loss = -61.712, baseline_loss = 41.454, entropy_loss = -5.6411, learner_queue_size = 32, _tick = 26943, _time = 1.6548e+09, train_seconds = 2.7531e+04)
[2022-06-10 03:46:56,390][root][INFO] - Step 104867840 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 104867840, mean_episode_return = None, mean_episode_step = 1121.1, total_loss = 53.143, pg_loss = 23.877, baseline_loss = 35.099, entropy_loss = -5.8322, learner_queue_size = 32, _tick = 26947, _time = 1.6548e+09, train_seconds = 2.7536e+04)
[2022-06-10 03:47:01,394][root][INFO] - Step 104888320 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 104888320, mean_episode_return = None, mean_episode_step = 981.78, total_loss = 122.91, pg_loss = 83.606, baseline_loss = 45.169, entropy_loss = -5.8617, learner_queue_size = 32, _tick = 26952, _time = 1.6548e+09, train_seconds = 2.7541e+04)
[2022-06-10 03:47:06,398][root][INFO] - Step 104908800 @ 4092.8 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 104908800, mean_episode_return = 60.27, mean_episode_step = 1146.2, total_loss = 66.616, pg_loss = 25.74, baseline_loss = 46.523, entropy_loss = -5.6474, learner_queue_size = 32, _tick = 26958, _time = 1.6548e+09, train_seconds = 2.7546e+04)
[2022-06-10 03:47:11,402][root][INFO] - Step 104929280 @ 4092.4 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 104929280, mean_episode_return = 106.94, mean_episode_step = 887.11, total_loss = 252.54, pg_loss = 154.68, baseline_loss = 103.41, entropy_loss = -5.5414, learner_queue_size = 32, _tick = 26964, _time = 1.6548e+09, train_seconds = 2.7551e+04)
[2022-06-10 03:47:16,406][root][INFO] - Step 104947200 @ 3581.4 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 104947200, mean_episode_return = 62.371, mean_episode_step = 1137.7, total_loss = -23.822, pg_loss = -54.387, baseline_loss = 36.139, entropy_loss = -5.5738, learner_queue_size = 32, _tick = 26970, _time = 1.6548e+09, train_seconds = 2.7556e+04)
[2022-06-10 03:47:21,410][root][INFO] - Step 104967680 @ 4092.7 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 104967680, mean_episode_return = 26.983, mean_episode_step = 939.1, total_loss = 71.131, pg_loss = 49.681, baseline_loss = 27.021, entropy_loss = -5.5709, learner_queue_size = 32, _tick = 26977, _time = 1.6548e+09, train_seconds = 2.7561e+04)
[2022-06-10 03:47:26,414][root][INFO] - Step 104988160 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 104988160, mean_episode_return = 48.48, mean_episode_step = 1095.7, total_loss = 197.62, pg_loss = 149.08, baseline_loss = 53.987, entropy_loss = -5.4393, learner_queue_size = 32, _tick = 26984, _time = 1.6548e+09, train_seconds = 2.7566e+04)
[2022-06-10 03:47:31,418][root][INFO] - Step 105006080 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 105006080, mean_episode_return = 98.258, mean_episode_step = 1388.0, total_loss = -63.871, pg_loss = -78.535, baseline_loss = 20.057, entropy_loss = -5.3937, learner_queue_size = 32, _tick = 26990, _time = 1.6548e+09, train_seconds = 2.7571e+04)
[2022-06-10 03:47:36,422][root][INFO] - Step 105026560 @ 4092.7 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 105026560, mean_episode_return = 106.74, mean_episode_step = 1128.2, total_loss = 100.49, pg_loss = -13.575, baseline_loss = 119.52, entropy_loss = -5.4515, learner_queue_size = 32, _tick = 26996, _time = 1.6548e+09, train_seconds = 2.7576e+04)
[2022-06-10 03:47:41,426][root][INFO] - Step 105044480 @ 3581.1 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 105044480, mean_episode_return = 10.89, mean_episode_step = 1108.1, total_loss = 294.48, pg_loss = 219.85, baseline_loss = 80.371, entropy_loss = -5.7409, learner_queue_size = 32, _tick = 27002, _time = 1.6548e+09, train_seconds = 2.7581e+04)
[2022-06-10 03:47:46,430][root][INFO] - Step 105064960 @ 4092.8 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 105064960, mean_episode_return = 80.476, mean_episode_step = 1261.4, total_loss = -80.703, pg_loss = -110.07, baseline_loss = 34.883, entropy_loss = -5.5155, learner_queue_size = 32, _tick = 27008, _time = 1.6548e+09, train_seconds = 2.7586e+04)
[2022-06-10 03:47:51,434][root][INFO] - Step 105085440 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 105085440, mean_episode_return = None, mean_episode_step = 1048.8, total_loss = 59.853, pg_loss = 26.568, baseline_loss = 38.663, entropy_loss = -5.3781, learner_queue_size = 32, _tick = 27013, _time = 1.6548e+09, train_seconds = 2.7591e+04)
[2022-06-10 03:47:56,438][root][INFO] - Step 105103360 @ 3581.1 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 105103360, mean_episode_return = 78.164, mean_episode_step = 960.59, total_loss = -52.273, pg_loss = -100.66, baseline_loss = 53.941, entropy_loss = -5.5539, learner_queue_size = 32, _tick = 27020, _time = 1.6548e+09, train_seconds = 2.7596e+04)
[2022-06-10 03:48:01,442][root][INFO] - Step 105123840 @ 4092.8 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 105123840, mean_episode_return = None, mean_episode_step = 1136.3, total_loss = -141.64, pg_loss = -147.49, baseline_loss = 11.576, entropy_loss = -5.7277, learner_queue_size = 32, _tick = 27025, _time = 1.6548e+09, train_seconds = 2.7601e+04)
[2022-06-10 03:48:06,446][root][INFO] - Step 105144320 @ 4092.7 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 105144320, mean_episode_return = None, mean_episode_step = 1517.1, total_loss = 48.489, pg_loss = 13.278, baseline_loss = 40.802, entropy_loss = -5.5919, learner_queue_size = 32, _tick = 27030, _time = 1.6548e+09, train_seconds = 2.7606e+04)
[2022-06-10 03:48:11,450][root][INFO] - Step 105162240 @ 3581.2 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 105162240, mean_episode_return = 112.61, mean_episode_step = 950.56, total_loss = 64.405, pg_loss = -8.2097, baseline_loss = 78.353, entropy_loss = -5.7378, learner_queue_size = 32, _tick = 27037, _time = 1.6548e+09, train_seconds = 2.7611e+04)
[2022-06-10 03:48:16,454][root][INFO] - Step 105182720 @ 4092.5 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 105182720, mean_episode_return = 98.63, mean_episode_step = 863.99, total_loss = 243.95, pg_loss = 167.37, baseline_loss = 82.005, entropy_loss = -5.4178, learner_queue_size = 32, _tick = 27045, _time = 1.6548e+09, train_seconds = 2.7616e+04)
[2022-06-10 03:48:21,458][root][INFO] - Step 105200640 @ 3581.3 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 105200640, mean_episode_return = 101.89, mean_episode_step = 900.53, total_loss = 80.923, pg_loss = 13.717, baseline_loss = 72.593, entropy_loss = -5.3877, learner_queue_size = 32, _tick = 27050, _time = 1.6548e+09, train_seconds = 2.7621e+04)
[2022-06-10 03:48:26,462][root][INFO] - Step 105221120 @ 4092.7 SPS. Inference batcher size: 73. Learner queue size: 32. Other stats: (step = 105221120, mean_episode_return = 30.453, mean_episode_step = 1225.8, total_loss = 413.46, pg_loss = 287.53, baseline_loss = 131.48, entropy_loss = -5.555, learner_queue_size = 32, _tick = 27057, _time = 1.6548e+09, train_seconds = 2.7626e+04)
[2022-06-10 03:48:31,466][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 03:48:31,601][root][INFO] - Step 105241600 @ 4092.8 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 105241600, mean_episode_return = -2.04, mean_episode_step = 1337.7, total_loss = -46.556, pg_loss = -82.02, baseline_loss = 40.996, entropy_loss = -5.5327, learner_queue_size = 32, _tick = 27065, _time = 1.6548e+09, train_seconds = 2.7631e+04)
[2022-06-10 03:48:36,606][root][INFO] - Step 105259520 @ 3486.4 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 105259520, mean_episode_return = 83.389, mean_episode_step = 1356.4, total_loss = -49.966, pg_loss = -87.762, baseline_loss = 43.471, entropy_loss = -5.6748, learner_queue_size = 32, _tick = 27072, _time = 1.6548e+09, train_seconds = 2.7636e+04)
[2022-06-10 03:48:41,610][root][INFO] - Step 105280000 @ 4092.8 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 105280000, mean_episode_return = 63.45, mean_episode_step = 743.19, total_loss = 12.959, pg_loss = -15.985, baseline_loss = 34.628, entropy_loss = -5.6843, learner_queue_size = 32, _tick = 27077, _time = 1.6548e+09, train_seconds = 2.7641e+04)
[2022-06-10 03:48:46,614][root][INFO] - Step 105297920 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 105297920, mean_episode_return = 88.305, mean_episode_step = 894.6, total_loss = 197.14, pg_loss = 145.98, baseline_loss = 57.141, entropy_loss = -5.9802, learner_queue_size = 32, _tick = 27082, _time = 1.6548e+09, train_seconds = 2.7646e+04)
[2022-06-10 03:48:51,618][root][INFO] - Step 105318400 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 105318400, mean_episode_return = -3.73, mean_episode_step = 1104.2, total_loss = 72.872, pg_loss = 30.772, baseline_loss = 47.837, entropy_loss = -5.736, learner_queue_size = 32, _tick = 27090, _time = 1.6548e+09, train_seconds = 2.7651e+04)
[2022-06-10 03:48:56,622][root][INFO] - Step 105336320 @ 3581.1 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 105336320, mean_episode_return = 79.351, mean_episode_step = 1041.7, total_loss = -31.965, pg_loss = -41.01, baseline_loss = 14.844, entropy_loss = -5.7991, learner_queue_size = 32, _tick = 27094, _time = 1.6548e+09, train_seconds = 2.7656e+04)
[2022-06-10 03:49:01,626][root][INFO] - Step 105356800 @ 4092.8 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 105356800, mean_episode_return = 36.902, mean_episode_step = 1256.2, total_loss = 219.14, pg_loss = 178.92, baseline_loss = 45.687, entropy_loss = -5.4761, learner_queue_size = 32, _tick = 27099, _time = 1.6548e+09, train_seconds = 2.7661e+04)
[2022-06-10 03:49:06,630][root][INFO] - Step 105377280 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 105377280, mean_episode_return = 23.79, mean_episode_step = 985.36, total_loss = 58.32, pg_loss = 28.448, baseline_loss = 35.276, entropy_loss = -5.4044, learner_queue_size = 32, _tick = 27104, _time = 1.6548e+09, train_seconds = 2.7666e+04)
[2022-06-10 03:49:11,634][root][INFO] - Step 105395200 @ 3581.2 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 105395200, mean_episode_return = None, mean_episode_step = 930.53, total_loss = -61.96, pg_loss = -73.132, baseline_loss = 16.66, entropy_loss = -5.4878, learner_queue_size = 32, _tick = 27107, _time = 1.6548e+09, train_seconds = 2.7671e+04)
[2022-06-10 03:49:16,639][root][INFO] - Step 105415680 @ 4092.3 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 105415680, mean_episode_return = 96.349, mean_episode_step = 1076.5, total_loss = -110.13, pg_loss = -130.21, baseline_loss = 25.635, entropy_loss = -5.5594, learner_queue_size = 32, _tick = 27114, _time = 1.6548e+09, train_seconds = 2.7676e+04)
[2022-06-10 03:49:21,642][root][INFO] - Step 105436160 @ 4093.1 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 105436160, mean_episode_return = None, mean_episode_step = 1307.7, total_loss = 177.82, pg_loss = 122.18, baseline_loss = 61.258, entropy_loss = -5.6214, learner_queue_size = 32, _tick = 27118, _time = 1.6548e+09, train_seconds = 2.7681e+04)
[2022-06-10 03:49:26,646][root][INFO] - Step 105454080 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 105454080, mean_episode_return = 83.029, mean_episode_step = 1075.0, total_loss = -78.204, pg_loss = -108.58, baseline_loss = 36.25, entropy_loss = -5.8729, learner_queue_size = 32, _tick = 27123, _time = 1.6548e+09, train_seconds = 2.7686e+04)
[2022-06-10 03:49:31,650][root][INFO] - Step 105474560 @ 4092.7 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 105474560, mean_episode_return = 231.86, mean_episode_step = 1268.7, total_loss = 304.47, pg_loss = 242.45, baseline_loss = 67.729, entropy_loss = -5.7073, learner_queue_size = 32, _tick = 27130, _time = 1.6548e+09, train_seconds = 2.7692e+04)
[2022-06-10 03:49:36,654][root][INFO] - Step 105492480 @ 3581.2 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 105492480, mean_episode_return = 22.89, mean_episode_step = 1617.3, total_loss = -127.48, pg_loss = -138.53, baseline_loss = 16.693, entropy_loss = -5.6354, learner_queue_size = 32, _tick = 27135, _time = 1.6548e+09, train_seconds = 2.7696e+04)
[2022-06-10 03:49:41,658][root][INFO] - Step 105512960 @ 4092.8 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 105512960, mean_episode_return = 43.081, mean_episode_step = 1187.7, total_loss = -64.449, pg_loss = -85.401, baseline_loss = 26.517, entropy_loss = -5.566, learner_queue_size = 32, _tick = 27140, _time = 1.6548e+09, train_seconds = 2.7702e+04)
[2022-06-10 03:49:46,662][root][INFO] - Step 105533440 @ 4092.7 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (step = 105533440, mean_episode_return = 6.3697, mean_episode_step = 1256.2, total_loss = 21.601, pg_loss = -13.243, baseline_loss = 40.396, entropy_loss = -5.5525, learner_queue_size = 32, _tick = 27145, _time = 1.6548e+09, train_seconds = 2.7706e+04)
[2022-06-10 03:49:51,667][root][INFO] - Step 105553920 @ 4091.6 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 105553920, mean_episode_return = None, mean_episode_step = 1054.2, total_loss = 111.7, pg_loss = 57.592, baseline_loss = 59.501, entropy_loss = -5.3904, learner_queue_size = 32, _tick = 27150, _time = 1.6548e+09, train_seconds = 2.7712e+04)
[2022-06-10 03:49:56,670][root][INFO] - Step 105571840 @ 3582.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 105571840, mean_episode_return = None, mean_episode_step = 1510.0, total_loss = -34.231, pg_loss = -82.096, baseline_loss = 53.623, entropy_loss = -5.7572, learner_queue_size = 32, _tick = 27154, _time = 1.6548e+09, train_seconds = 2.7716e+04)
[2022-06-10 03:50:01,674][root][INFO] - Step 105592320 @ 4092.3 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 105592320, mean_episode_return = 49.281, mean_episode_step = 1215.9, total_loss = 4.5358, pg_loss = -16.063, baseline_loss = 26.503, entropy_loss = -5.9039, learner_queue_size = 32, _tick = 27160, _time = 1.6548e+09, train_seconds = 2.7722e+04)
[2022-06-10 03:50:06,680][root][INFO] - Step 105610240 @ 3579.8 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 105610240, mean_episode_return = None, mean_episode_step = 1300.6, total_loss = 105.21, pg_loss = 72.982, baseline_loss = 37.908, entropy_loss = -5.6827, learner_queue_size = 32, _tick = 27164, _time = 1.6548e+09, train_seconds = 2.7726e+04)
[2022-06-10 03:50:11,686][root][INFO] - Step 105630720 @ 4091.5 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 105630720, mean_episode_return = 115.91, mean_episode_step = 1425.5, total_loss = -41.725, pg_loss = -62.515, baseline_loss = 26.397, entropy_loss = -5.6068, learner_queue_size = 32, _tick = 27172, _time = 1.6548e+09, train_seconds = 2.7732e+04)
[2022-06-10 03:50:16,690][root][INFO] - Step 105651200 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 105651200, mean_episode_return = 78.05, mean_episode_step = 1303.6, total_loss = -86.672, pg_loss = -102.23, baseline_loss = 21.306, entropy_loss = -5.7492, learner_queue_size = 32, _tick = 27179, _time = 1.6548e+09, train_seconds = 2.7736e+04)
[2022-06-10 03:50:21,694][root][INFO] - Step 105671680 @ 4092.8 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 105671680, mean_episode_return = 25.221, mean_episode_step = 1461.3, total_loss = -92.811, pg_loss = -114.39, baseline_loss = 27.245, entropy_loss = -5.6666, learner_queue_size = 32, _tick = 27185, _time = 1.6548e+09, train_seconds = 2.7742e+04)
[2022-06-10 03:50:26,698][root][INFO] - Step 105689600 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 105689600, mean_episode_return = None, mean_episode_step = 1296.3, total_loss = 839.19, pg_loss = 568.03, baseline_loss = 276.92, entropy_loss = -5.7652, learner_queue_size = 32, _tick = 27189, _time = 1.6548e+09, train_seconds = 2.7746e+04)
[2022-06-10 03:50:31,702][root][INFO] - Step 105710080 @ 4092.6 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 105710080, mean_episode_return = 89.75, mean_episode_step = 1182.5, total_loss = 63.071, pg_loss = -4.5588, baseline_loss = 73.065, entropy_loss = -5.4354, learner_queue_size = 32, _tick = 27195, _time = 1.6548e+09, train_seconds = 2.7752e+04)
[2022-06-10 03:50:36,706][root][INFO] - Step 105728000 @ 3581.1 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (step = 105728000, mean_episode_return = 10.045, mean_episode_step = 1339.5, total_loss = -79.787, pg_loss = -90.535, baseline_loss = 16.267, entropy_loss = -5.5189, learner_queue_size = 32, _tick = 27200, _time = 1.6548e+09, train_seconds = 2.7756e+04)
[2022-06-10 03:50:41,710][root][INFO] - Step 105748480 @ 4092.8 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 105748480, mean_episode_return = 8.7896, mean_episode_step = 1137.8, total_loss = -124.39, pg_loss = -151.83, baseline_loss = 32.884, entropy_loss = -5.442, learner_queue_size = 32, _tick = 27208, _time = 1.6548e+09, train_seconds = 2.7762e+04)
[2022-06-10 03:50:46,714][root][INFO] - Step 105768960 @ 4092.6 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 105768960, mean_episode_return = 35.384, mean_episode_step = 1127.3, total_loss = -229.11, pg_loss = -236.52, baseline_loss = 12.822, entropy_loss = -5.4156, learner_queue_size = 32, _tick = 27213, _time = 1.6548e+09, train_seconds = 2.7766e+04)
[2022-06-10 03:50:51,718][root][INFO] - Step 105789440 @ 4092.8 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 105789440, mean_episode_return = 62.793, mean_episode_step = 1231.8, total_loss = -116.73, pg_loss = -141.84, baseline_loss = 30.541, entropy_loss = -5.4325, learner_queue_size = 32, _tick = 27218, _time = 1.6548e+09, train_seconds = 2.7772e+04)
[2022-06-10 03:50:56,722][root][INFO] - Step 105807360 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 105807360, mean_episode_return = 35.97, mean_episode_step = 1235.4, total_loss = -161.33, pg_loss = -192.11, baseline_loss = 36.264, entropy_loss = -5.4824, learner_queue_size = 32, _tick = 27224, _time = 1.6548e+09, train_seconds = 2.7776e+04)
[2022-06-10 03:51:01,726][root][INFO] - Step 105827840 @ 4092.8 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 105827840, mean_episode_return = 48.951, mean_episode_step = 1403.5, total_loss = 314.86, pg_loss = 225.68, baseline_loss = 94.855, entropy_loss = -5.6745, learner_queue_size = 32, _tick = 27231, _time = 1.6548e+09, train_seconds = 2.7782e+04)
[2022-06-10 03:51:06,730][root][INFO] - Step 105848320 @ 4092.7 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 105848320, mean_episode_return = 74.091, mean_episode_step = 1458.1, total_loss = 45.839, pg_loss = 19.179, baseline_loss = 32.304, entropy_loss = -5.6443, learner_queue_size = 32, _tick = 27238, _time = 1.6548e+09, train_seconds = 2.7786e+04)
[2022-06-10 03:51:11,738][root][INFO] - Step 105868800 @ 4092.8 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 105868800, mean_episode_return = 118.11, mean_episode_step = 1172.9, total_loss = -122.05, pg_loss = -131.53, baseline_loss = 14.681, entropy_loss = -5.2029, learner_queue_size = 32, _tick = 27243, _time = 1.6548e+09, train_seconds = 2.7792e+04)
[2022-06-10 03:51:16,743][root][INFO] - Step 105886720 @ 3577.8 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (step = 105886720, mean_episode_return = 9.365, mean_episode_step = 1191.2, total_loss = -17.304, pg_loss = -75.826, baseline_loss = 63.814, entropy_loss = -5.2918, learner_queue_size = 32, _tick = 27248, _time = 1.6548e+09, train_seconds = 2.7797e+04)
[2022-06-10 03:51:21,749][root][INFO] - Step 105907200 @ 4090.8 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 105907200, mean_episode_return = 33.46, mean_episode_step = 1140.9, total_loss = -158.07, pg_loss = -195.16, baseline_loss = 42.523, entropy_loss = -5.4255, learner_queue_size = 32, _tick = 27251, _time = 1.6548e+09, train_seconds = 2.7802e+04)
[2022-06-10 03:51:26,755][root][INFO] - Step 105925120 @ 3579.7 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 105925120, mean_episode_return = None, mean_episode_step = 1295.3, total_loss = 100.87, pg_loss = 42.243, baseline_loss = 63.994, entropy_loss = -5.3634, learner_queue_size = 32, _tick = 27257, _time = 1.6548e+09, train_seconds = 2.7807e+04)
[2022-06-10 03:51:31,758][root][INFO] - Step 105945600 @ 4093.5 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 105945600, mean_episode_return = None, mean_episode_step = 1389.1, total_loss = -98.358, pg_loss = -103.09, baseline_loss = 10.346, entropy_loss = -5.6141, learner_queue_size = 32, _tick = 27261, _time = 1.6548e+09, train_seconds = 2.7812e+04)
[2022-06-10 03:51:36,762][root][INFO] - Step 105966080 @ 4092.4 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 105966080, mean_episode_return = 7.841, mean_episode_step = 1282.4, total_loss = -82.347, pg_loss = -122.88, baseline_loss = 46.013, entropy_loss = -5.4833, learner_queue_size = 32, _tick = 27266, _time = 1.6548e+09, train_seconds = 2.7817e+04)
[2022-06-10 03:51:41,766][root][INFO] - Step 105984000 @ 3581.3 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 105984000, mean_episode_return = 45.7, mean_episode_step = 1255.1, total_loss = -111.21, pg_loss = -140.23, baseline_loss = 34.568, entropy_loss = -5.542, learner_queue_size = 32, _tick = 27274, _time = 1.6548e+09, train_seconds = 2.7822e+04)
[2022-06-10 03:51:46,770][root][INFO] - Step 106004480 @ 4092.7 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 106004480, mean_episode_return = 99.269, mean_episode_step = 1393.3, total_loss = -98.263, pg_loss = -118.19, baseline_loss = 25.401, entropy_loss = -5.4761, learner_queue_size = 32, _tick = 27281, _time = 1.6548e+09, train_seconds = 2.7827e+04)
[2022-06-10 03:51:51,774][root][INFO] - Step 106022400 @ 3581.3 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 106022400, mean_episode_return = None, mean_episode_step = 1101.2, total_loss = 8.2417, pg_loss = -19.842, baseline_loss = 33.583, entropy_loss = -5.4993, learner_queue_size = 32, _tick = 27286, _time = 1.6548e+09, train_seconds = 2.7832e+04)
[2022-06-10 03:51:56,778][root][INFO] - Step 106042880 @ 4092.6 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 106042880, mean_episode_return = None, mean_episode_step = 1286.9, total_loss = -101.34, pg_loss = -119.25, baseline_loss = 23.335, entropy_loss = -5.4225, learner_queue_size = 32, _tick = 27289, _time = 1.6548e+09, train_seconds = 2.7837e+04)
[2022-06-10 03:52:01,784][root][INFO] - Step 106060800 @ 3579.6 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 106060800, mean_episode_return = 91.638, mean_episode_step = 1346.9, total_loss = -111.31, pg_loss = -128.03, baseline_loss = 22.112, entropy_loss = -5.3904, learner_queue_size = 32, _tick = 27295, _time = 1.6548e+09, train_seconds = 2.7842e+04)
[2022-06-10 03:52:06,790][root][INFO] - Step 106081280 @ 4091.2 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 106081280, mean_episode_return = 27.958, mean_episode_step = 1304.9, total_loss = 55.369, pg_loss = 15.448, baseline_loss = 45.341, entropy_loss = -5.4202, learner_queue_size = 32, _tick = 27302, _time = 1.6548e+09, train_seconds = 2.7847e+04)
[2022-06-10 03:52:11,794][root][INFO] - Step 106101760 @ 4092.8 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 106101760, mean_episode_return = 93.372, mean_episode_step = 1071.0, total_loss = -87.159, pg_loss = -106.73, baseline_loss = 24.969, entropy_loss = -5.3984, learner_queue_size = 32, _tick = 27306, _time = 1.6548e+09, train_seconds = 2.7852e+04)
[2022-06-10 03:52:16,798][root][INFO] - Step 106122240 @ 4092.6 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 106122240, mean_episode_return = None, mean_episode_step = 1268.0, total_loss = 119.44, pg_loss = 79.756, baseline_loss = 45.279, entropy_loss = -5.5953, learner_queue_size = 32, _tick = 27310, _time = 1.6548e+09, train_seconds = 2.7857e+04)
[2022-06-10 03:52:21,802][root][INFO] - Step 106142720 @ 4092.8 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 106142720, mean_episode_return = 66.343, mean_episode_step = 1305.9, total_loss = -63.632, pg_loss = -76.648, baseline_loss = 18.936, entropy_loss = -5.9199, learner_queue_size = 32, _tick = 27317, _time = 1.6548e+09, train_seconds = 2.7862e+04)
[2022-06-10 03:52:26,806][root][INFO] - Step 106160640 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 106160640, mean_episode_return = 42.926, mean_episode_step = 1248.1, total_loss = 8.4568, pg_loss = -11.208, baseline_loss = 25.338, entropy_loss = -5.673, learner_queue_size = 32, _tick = 27323, _time = 1.6548e+09, train_seconds = 2.7867e+04)
[2022-06-10 03:52:31,810][root][INFO] - Step 106181120 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 106181120, mean_episode_return = 45.844, mean_episode_step = 910.58, total_loss = 57.383, pg_loss = 35.926, baseline_loss = 26.988, entropy_loss = -5.5309, learner_queue_size = 32, _tick = 27329, _time = 1.6548e+09, train_seconds = 2.7872e+04)
[2022-06-10 03:52:36,814][root][INFO] - Step 106199040 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 106199040, mean_episode_return = None, mean_episode_step = 1241.2, total_loss = 87.337, pg_loss = 52.644, baseline_loss = 40.262, entropy_loss = -5.5691, learner_queue_size = 32, _tick = 27331, _time = 1.6548e+09, train_seconds = 2.7877e+04)
[2022-06-10 03:52:41,818][root][INFO] - Step 106219520 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 106219520, mean_episode_return = 26.16, mean_episode_step = 1190.4, total_loss = 19.231, pg_loss = -22.362, baseline_loss = 47.083, entropy_loss = -5.4901, learner_queue_size = 32, _tick = 27337, _time = 1.6548e+09, train_seconds = 2.7882e+04)
[2022-06-10 03:52:46,822][root][INFO] - Step 106240000 @ 4092.7 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (step = 106240000, mean_episode_return = 64.277, mean_episode_step = 1376.8, total_loss = 40.978, pg_loss = 6.7897, baseline_loss = 39.668, entropy_loss = -5.4797, learner_queue_size = 32, _tick = 27342, _time = 1.6548e+09, train_seconds = 2.7887e+04)
[2022-06-10 03:52:51,826][root][INFO] - Step 106260480 @ 4092.7 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 106260480, mean_episode_return = 37.469, mean_episode_step = 1613.8, total_loss = -91.61, pg_loss = -104.23, baseline_loss = 18.015, entropy_loss = -5.3908, learner_queue_size = 32, _tick = 27346, _time = 1.6548e+09, train_seconds = 2.7892e+04)
[2022-06-10 03:52:56,830][root][INFO] - Step 106278400 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 106278400, mean_episode_return = 29.87, mean_episode_step = 1184.8, total_loss = 501.03, pg_loss = 381.28, baseline_loss = 125.18, entropy_loss = -5.4182, learner_queue_size = 32, _tick = 27353, _time = 1.6548e+09, train_seconds = 2.7897e+04)
[2022-06-10 03:53:01,834][root][INFO] - Step 106298880 @ 4092.8 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 106298880, mean_episode_return = None, mean_episode_step = 1166.6, total_loss = 316.49, pg_loss = 232.23, baseline_loss = 89.688, entropy_loss = -5.427, learner_queue_size = 32, _tick = 27358, _time = 1.6548e+09, train_seconds = 2.7902e+04)
[2022-06-10 03:53:06,838][root][INFO] - Step 106319360 @ 4092.8 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 106319360, mean_episode_return = 43.541, mean_episode_step = 1384.3, total_loss = 203.46, pg_loss = 130.05, baseline_loss = 78.69, entropy_loss = -5.2802, learner_queue_size = 32, _tick = 27366, _time = 1.6548e+09, train_seconds = 2.7907e+04)
[2022-06-10 03:53:11,842][root][INFO] - Step 106337280 @ 3581.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 106337280, mean_episode_return = None, mean_episode_step = 1393.6, total_loss = 148.14, pg_loss = 95.639, baseline_loss = 57.846, entropy_loss = -5.3457, learner_queue_size = 32, _tick = 27371, _time = 1.6548e+09, train_seconds = 2.7912e+04)
[2022-06-10 03:53:16,846][root][INFO] - Step 106357760 @ 4092.8 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 106357760, mean_episode_return = 54.4, mean_episode_step = 1128.8, total_loss = 340.44, pg_loss = 270.38, baseline_loss = 75.395, entropy_loss = -5.342, learner_queue_size = 32, _tick = 27378, _time = 1.6548e+09, train_seconds = 2.7917e+04)
[2022-06-10 03:53:21,850][root][INFO] - Step 106375680 @ 3581.1 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 106375680, mean_episode_return = 22.62, mean_episode_step = 1148.7, total_loss = 144.87, pg_loss = 97.901, baseline_loss = 52.409, entropy_loss = -5.4406, learner_queue_size = 32, _tick = 27384, _time = 1.6548e+09, train_seconds = 2.7922e+04)
[2022-06-10 03:53:26,854][root][INFO] - Step 106393600 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 106393600, mean_episode_return = 71.585, mean_episode_step = 1347.3, total_loss = -30.417, pg_loss = -60.186, baseline_loss = 35.299, entropy_loss = -5.53, learner_queue_size = 32, _tick = 27390, _time = 1.6548e+09, train_seconds = 2.7927e+04)
[2022-06-10 03:53:31,862][root][INFO] - Step 106414080 @ 4089.8 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 106414080, mean_episode_return = -8.3002, mean_episode_step = 1479.8, total_loss = 71.755, pg_loss = 52.072, baseline_loss = 25.157, entropy_loss = -5.4739, learner_queue_size = 32, _tick = 27397, _time = 1.6548e+09, train_seconds = 2.7932e+04)
[2022-06-10 03:53:36,866][root][INFO] - Step 106434560 @ 4092.3 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 106434560, mean_episode_return = 23.27, mean_episode_step = 1129.8, total_loss = -44.511, pg_loss = -103.87, baseline_loss = 64.823, entropy_loss = -5.4619, learner_queue_size = 32, _tick = 27404, _time = 1.6548e+09, train_seconds = 2.7937e+04)
[2022-06-10 03:53:41,870][root][INFO] - Step 106452480 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 106452480, mean_episode_return = 33.651, mean_episode_step = 1232.2, total_loss = 88.243, pg_loss = 59.251, baseline_loss = 34.574, entropy_loss = -5.5812, learner_queue_size = 32, _tick = 27409, _time = 1.6548e+09, train_seconds = 2.7942e+04)
[2022-06-10 03:53:46,874][root][INFO] - Step 106472960 @ 4092.7 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 106472960, mean_episode_return = None, mean_episode_step = 1288.3, total_loss = 199.44, pg_loss = 166.94, baseline_loss = 37.942, entropy_loss = -5.4443, learner_queue_size = 32, _tick = 27416, _time = 1.6548e+09, train_seconds = 2.7947e+04)
[2022-06-10 03:53:51,878][root][INFO] - Step 106493440 @ 4092.7 SPS. Inference batcher size: 85. Learner queue size: 32. Other stats: (step = 106493440, mean_episode_return = 50.05, mean_episode_step = 814.57, total_loss = 248.23, pg_loss = 175.33, baseline_loss = 78.376, entropy_loss = -5.4784, learner_queue_size = 32, _tick = 27424, _time = 1.6548e+09, train_seconds = 2.7952e+04)
[2022-06-10 03:53:56,882][root][INFO] - Step 106511360 @ 3581.2 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 106511360, mean_episode_return = 5.3897, mean_episode_step = 944.33, total_loss = -115.23, pg_loss = -130.9, baseline_loss = 21.074, entropy_loss = -5.4053, learner_queue_size = 32, _tick = 27429, _time = 1.6548e+09, train_seconds = 2.7957e+04)
[2022-06-10 03:54:01,890][root][INFO] - Step 106531840 @ 4089.5 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 106531840, mean_episode_return = 27.82, mean_episode_step = 875.42, total_loss = -65.093, pg_loss = -95.464, baseline_loss = 35.795, entropy_loss = -5.4231, learner_queue_size = 32, _tick = 27436, _time = 1.6548e+09, train_seconds = 2.7962e+04)
[2022-06-10 03:54:06,894][root][INFO] - Step 106552320 @ 4092.7 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 106552320, mean_episode_return = 38.652, mean_episode_step = 976.51, total_loss = 161.33, pg_loss = 105.52, baseline_loss = 61.345, entropy_loss = -5.5379, learner_queue_size = 32, _tick = 27443, _time = 1.6548e+09, train_seconds = 2.7967e+04)
[2022-06-10 03:54:11,898][root][INFO] - Step 106570240 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 106570240, mean_episode_return = 57.77, mean_episode_step = 943.49, total_loss = 209.01, pg_loss = 133.1, baseline_loss = 81.267, entropy_loss = -5.3544, learner_queue_size = 32, _tick = 27448, _time = 1.6548e+09, train_seconds = 2.7972e+04)
[2022-06-10 03:54:16,902][root][INFO] - Step 106590720 @ 4092.8 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 106590720, mean_episode_return = 101.42, mean_episode_step = 1332.9, total_loss = 133.46, pg_loss = 87.203, baseline_loss = 51.906, entropy_loss = -5.6457, learner_queue_size = 32, _tick = 27455, _time = 1.6548e+09, train_seconds = 2.7977e+04)
[2022-06-10 03:54:21,906][root][INFO] - Step 106611200 @ 4092.7 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 106611200, mean_episode_return = 28.502, mean_episode_step = 1188.8, total_loss = 139.11, pg_loss = 75.158, baseline_loss = 69.52, entropy_loss = -5.5724, learner_queue_size = 32, _tick = 27461, _time = 1.6548e+09, train_seconds = 2.7982e+04)
[2022-06-10 03:54:26,910][root][INFO] - Step 106631680 @ 4092.7 SPS. Inference batcher size: 80. Learner queue size: 32. Other stats: (step = 106631680, mean_episode_return = 17.443, mean_episode_step = 979.01, total_loss = 157.15, pg_loss = 110.52, baseline_loss = 52.004, entropy_loss = -5.3758, learner_queue_size = 32, _tick = 27467, _time = 1.6548e+09, train_seconds = 2.7987e+04)
[2022-06-10 03:54:31,914][root][INFO] - Step 106649600 @ 3581.2 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 106649600, mean_episode_return = 27.06, mean_episode_step = 995.97, total_loss = -256.32, pg_loss = -320.34, baseline_loss = 69.569, entropy_loss = -5.5423, learner_queue_size = 32, _tick = 27474, _time = 1.6548e+09, train_seconds = 2.7992e+04)
[2022-06-10 03:54:36,918][root][INFO] - Step 106670080 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 106670080, mean_episode_return = 54.471, mean_episode_step = 1285.0, total_loss = -198.79, pg_loss = -217.65, baseline_loss = 24.341, entropy_loss = -5.4757, learner_queue_size = 32, _tick = 27481, _time = 1.6548e+09, train_seconds = 2.7997e+04)
[2022-06-10 03:54:41,922][root][INFO] - Step 106690560 @ 4092.6 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 106690560, mean_episode_return = None, mean_episode_step = 1037.4, total_loss = 628.14, pg_loss = 329.36, baseline_loss = 304.44, entropy_loss = -5.6628, learner_queue_size = 32, _tick = 27487, _time = 1.6548e+09, train_seconds = 2.8002e+04)
[2022-06-10 03:54:46,926][root][INFO] - Step 106708480 @ 3581.2 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 106708480, mean_episode_return = None, mean_episode_step = 1089.2, total_loss = 79.257, pg_loss = 29.351, baseline_loss = 55.539, entropy_loss = -5.6324, learner_queue_size = 32, _tick = 27492, _time = 1.6548e+09, train_seconds = 2.8007e+04)
[2022-06-10 03:54:51,932][root][INFO] - Step 106728960 @ 4091.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 106728960, mean_episode_return = 119.31, mean_episode_step = 1373.1, total_loss = -99.505, pg_loss = -116.07, baseline_loss = 22.069, entropy_loss = -5.5084, learner_queue_size = 32, _tick = 27497, _time = 1.6548e+09, train_seconds = 2.8012e+04)
[2022-06-10 03:54:56,934][root][INFO] - Step 106749440 @ 4094.4 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (step = 106749440, mean_episode_return = 52.066, mean_episode_step = 1072.1, total_loss = -84.108, pg_loss = -122.75, baseline_loss = 44.14, entropy_loss = -5.4975, learner_queue_size = 32, _tick = 27504, _time = 1.6548e+09, train_seconds = 2.8017e+04)
[2022-06-10 03:55:01,938][root][INFO] - Step 106767360 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 106767360, mean_episode_return = None, mean_episode_step = 969.88, total_loss = 302.78, pg_loss = 239.8, baseline_loss = 68.589, entropy_loss = -5.6081, learner_queue_size = 32, _tick = 27509, _time = 1.6548e+09, train_seconds = 2.8022e+04)
[2022-06-10 03:55:06,942][root][INFO] - Step 106787840 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 106787840, mean_episode_return = 40.166, mean_episode_step = 1215.8, total_loss = 104.73, pg_loss = 53.124, baseline_loss = 56.97, entropy_loss = -5.3595, learner_queue_size = 32, _tick = 27516, _time = 1.6548e+09, train_seconds = 2.8027e+04)
[2022-06-10 03:55:11,948][root][INFO] - Step 106805760 @ 3579.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 106805760, mean_episode_return = None, mean_episode_step = 1302.4, total_loss = 141.79, pg_loss = 108.51, baseline_loss = 38.878, entropy_loss = -5.6049, learner_queue_size = 32, _tick = 27519, _time = 1.6548e+09, train_seconds = 2.8032e+04)
[2022-06-10 03:55:16,954][root][INFO] - Step 106826240 @ 4091.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 106826240, mean_episode_return = 43.022, mean_episode_step = 1377.0, total_loss = 265.28, pg_loss = 185.27, baseline_loss = 85.633, entropy_loss = -5.6199, learner_queue_size = 32, _tick = 27526, _time = 1.6548e+09, train_seconds = 2.8037e+04)
[2022-06-10 03:55:21,958][root][INFO] - Step 106846720 @ 4092.3 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 106846720, mean_episode_return = 71.406, mean_episode_step = 1064.0, total_loss = 71.891, pg_loss = -3.3441, baseline_loss = 80.776, entropy_loss = -5.5403, learner_queue_size = 32, _tick = 27534, _time = 1.6548e+09, train_seconds = 2.8042e+04)
[2022-06-10 03:55:26,960][root][INFO] - Step 106867200 @ 4094.9 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 106867200, mean_episode_return = None, mean_episode_step = 1040.9, total_loss = 257.96, pg_loss = 188.55, baseline_loss = 74.93, entropy_loss = -5.5147, learner_queue_size = 32, _tick = 27540, _time = 1.6548e+09, train_seconds = 2.8047e+04)
[2022-06-10 03:55:31,966][root][INFO] - Step 106885120 @ 3579.6 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 106885120, mean_episode_return = 19.35, mean_episode_step = 970.48, total_loss = 95.351, pg_loss = 34.902, baseline_loss = 65.948, entropy_loss = -5.4981, learner_queue_size = 32, _tick = 27545, _time = 1.6548e+09, train_seconds = 2.8052e+04)
[2022-06-10 03:55:36,970][root][INFO] - Step 106905600 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 106905600, mean_episode_return = 28.91, mean_episode_step = 1457.2, total_loss = -205.53, pg_loss = -258.32, baseline_loss = 58.166, entropy_loss = -5.3762, learner_queue_size = 32, _tick = 27551, _time = 1.6548e+09, train_seconds = 2.8057e+04)
[2022-06-10 03:55:41,974][root][INFO] - Step 106923520 @ 3581.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 106923520, mean_episode_return = 54.301, mean_episode_step = 1042.6, total_loss = -29.753, pg_loss = -59.749, baseline_loss = 35.667, entropy_loss = -5.6716, learner_queue_size = 32, _tick = 27554, _time = 1.6548e+09, train_seconds = 2.8062e+04)
[2022-06-10 03:55:46,978][root][INFO] - Step 106944000 @ 4092.7 SPS. Inference batcher size: 77. Learner queue size: 32. Other stats: (step = 106944000, mean_episode_return = 29.2, mean_episode_step = 1015.9, total_loss = -44.486, pg_loss = -72.114, baseline_loss = 33.205, entropy_loss = -5.5773, learner_queue_size = 32, _tick = 27560, _time = 1.6548e+09, train_seconds = 2.8067e+04)
[2022-06-10 03:55:51,982][root][INFO] - Step 106964480 @ 4092.6 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 106964480, mean_episode_return = 8.0298, mean_episode_step = 1143.7, total_loss = 186.82, pg_loss = 137.3, baseline_loss = 55.07, entropy_loss = -5.5516, learner_queue_size = 32, _tick = 27566, _time = 1.6548e+09, train_seconds = 2.8072e+04)
[2022-06-10 03:55:56,986][root][INFO] - Step 106982400 @ 3581.2 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 106982400, mean_episode_return = None, mean_episode_step = 1133.5, total_loss = 72.983, pg_loss = 35.041, baseline_loss = 43.571, entropy_loss = -5.6295, learner_queue_size = 32, _tick = 27571, _time = 1.6548e+09, train_seconds = 2.8077e+04)
[2022-06-10 03:56:01,990][root][INFO] - Step 107002880 @ 4092.8 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 107002880, mean_episode_return = 151.01, mean_episode_step = 768.56, total_loss = 220.82, pg_loss = 163.67, baseline_loss = 62.769, entropy_loss = -5.6242, learner_queue_size = 32, _tick = 27578, _time = 1.6548e+09, train_seconds = 2.8082e+04)
[2022-06-10 03:56:06,996][root][INFO] - Step 107020800 @ 3580.0 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 107020800, mean_episode_return = 35.06, mean_episode_step = 1084.3, total_loss = 226.39, pg_loss = 156.99, baseline_loss = 75.01, entropy_loss = -5.6115, learner_queue_size = 32, _tick = 27585, _time = 1.6548e+09, train_seconds = 2.8087e+04)
[2022-06-10 03:56:11,998][root][INFO] - Step 107041280 @ 4094.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 107041280, mean_episode_return = 85.34, mean_episode_step = 1210.0, total_loss = 92.897, pg_loss = 49.038, baseline_loss = 49.449, entropy_loss = -5.5898, learner_queue_size = 32, _tick = 27591, _time = 1.6548e+09, train_seconds = 2.8092e+04)
[2022-06-10 03:56:17,002][root][INFO] - Step 107059200 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 107059200, mean_episode_return = 67.475, mean_episode_step = 951.89, total_loss = -215.97, pg_loss = -254.48, baseline_loss = 44.077, entropy_loss = -5.5719, learner_queue_size = 32, _tick = 27597, _time = 1.6548e+09, train_seconds = 2.8097e+04)
[2022-06-10 03:56:22,006][root][INFO] - Step 107079680 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 107079680, mean_episode_return = 133.86, mean_episode_step = 675.88, total_loss = 142.8, pg_loss = 91.606, baseline_loss = 56.773, entropy_loss = -5.5759, learner_queue_size = 32, _tick = 27604, _time = 1.6548e+09, train_seconds = 2.8102e+04)
[2022-06-10 03:56:27,010][root][INFO] - Step 107100160 @ 4092.8 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 107100160, mean_episode_return = 35.821, mean_episode_step = 816.39, total_loss = 119.37, pg_loss = 85.621, baseline_loss = 39.229, entropy_loss = -5.4833, learner_queue_size = 32, _tick = 27612, _time = 1.6548e+09, train_seconds = 2.8107e+04)
[2022-06-10 03:56:32,014][root][INFO] - Step 107118080 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 107118080, mean_episode_return = 129.36, mean_episode_step = 772.28, total_loss = 307.51, pg_loss = 245.15, baseline_loss = 67.735, entropy_loss = -5.3802, learner_queue_size = 32, _tick = 27619, _time = 1.6548e+09, train_seconds = 2.8112e+04)
[2022-06-10 03:56:37,018][root][INFO] - Step 107138560 @ 4092.8 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 107138560, mean_episode_return = 33.161, mean_episode_step = 1127.9, total_loss = 182.09, pg_loss = 122.95, baseline_loss = 64.574, entropy_loss = -5.4385, learner_queue_size = 32, _tick = 27625, _time = 1.6548e+09, train_seconds = 2.8117e+04)
[2022-06-10 03:56:42,025][root][INFO] - Step 107159040 @ 4090.4 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 107159040, mean_episode_return = 39.391, mean_episode_step = 859.65, total_loss = -149.92, pg_loss = -182.49, baseline_loss = 38.029, entropy_loss = -5.4649, learner_queue_size = 32, _tick = 27633, _time = 1.6548e+09, train_seconds = 2.8122e+04)
[2022-06-10 03:56:47,030][root][INFO] - Step 107176960 @ 3580.3 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 107176960, mean_episode_return = 71.527, mean_episode_step = 852.47, total_loss = -158.24, pg_loss = -207.23, baseline_loss = 54.516, entropy_loss = -5.5241, learner_queue_size = 32, _tick = 27640, _time = 1.6548e+09, train_seconds = 2.8127e+04)
[2022-06-10 03:56:52,034][root][INFO] - Step 107197440 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 107197440, mean_episode_return = 84.255, mean_episode_step = 711.43, total_loss = -72.846, pg_loss = -90.993, baseline_loss = 23.772, entropy_loss = -5.626, learner_queue_size = 32, _tick = 27646, _time = 1.6548e+09, train_seconds = 2.8132e+04)
[2022-06-10 03:56:57,038][root][INFO] - Step 107217920 @ 4092.7 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 107217920, mean_episode_return = 81.677, mean_episode_step = 1001.2, total_loss = -6.5153, pg_loss = -38.927, baseline_loss = 38.071, entropy_loss = -5.6595, learner_queue_size = 32, _tick = 27654, _time = 1.6548e+09, train_seconds = 2.8137e+04)
[2022-06-10 03:57:02,042][root][INFO] - Step 107238400 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 107238400, mean_episode_return = None, mean_episode_step = 1383.5, total_loss = 802.38, pg_loss = 609.98, baseline_loss = 197.83, entropy_loss = -5.4269, learner_queue_size = 32, _tick = 27659, _time = 1.6548e+09, train_seconds = 2.8142e+04)
[2022-06-10 03:57:07,046][root][INFO] - Step 107256320 @ 3581.1 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 107256320, mean_episode_return = 104.45, mean_episode_step = 880.11, total_loss = 60.154, pg_loss = 29.917, baseline_loss = 35.643, entropy_loss = -5.4063, learner_queue_size = 32, _tick = 27665, _time = 1.6548e+09, train_seconds = 2.8147e+04)
[2022-06-10 03:57:12,050][root][INFO] - Step 107276800 @ 4092.8 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 107276800, mean_episode_return = 69.97, mean_episode_step = 1183.8, total_loss = -5.8389, pg_loss = -36.134, baseline_loss = 35.841, entropy_loss = -5.5456, learner_queue_size = 32, _tick = 27672, _time = 1.6548e+09, train_seconds = 2.8152e+04)
[2022-06-10 03:57:17,054][root][INFO] - Step 107297280 @ 4092.8 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 107297280, mean_episode_return = 23.41, mean_episode_step = 942.4, total_loss = 249.04, pg_loss = 164.35, baseline_loss = 90.419, entropy_loss = -5.7313, learner_queue_size = 32, _tick = 27678, _time = 1.6548e+09, train_seconds = 2.8157e+04)
[2022-06-10 03:57:22,058][root][INFO] - Step 107315200 @ 3581.0 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 107315200, mean_episode_return = None, mean_episode_step = 873.56, total_loss = 159.01, pg_loss = 103.86, baseline_loss = 60.996, entropy_loss = -5.85, learner_queue_size = 32, _tick = 27684, _time = 1.6548e+09, train_seconds = 2.8162e+04)
[2022-06-10 03:57:27,062][root][INFO] - Step 107335680 @ 4092.8 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 107335680, mean_episode_return = 43.326, mean_episode_step = 865.7, total_loss = -30.871, pg_loss = -73.622, baseline_loss = 48.304, entropy_loss = -5.5532, learner_queue_size = 32, _tick = 27691, _time = 1.6548e+09, train_seconds = 2.8167e+04)
[2022-06-10 03:57:32,066][root][INFO] - Step 107356160 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 107356160, mean_episode_return = 108.04, mean_episode_step = 820.77, total_loss = -32.515, pg_loss = -59.894, baseline_loss = 32.956, entropy_loss = -5.5773, learner_queue_size = 32, _tick = 27696, _time = 1.6548e+09, train_seconds = 2.8172e+04)
[2022-06-10 03:57:37,070][root][INFO] - Step 107376640 @ 4092.7 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 107376640, mean_episode_return = 39.506, mean_episode_step = 921.52, total_loss = -23.256, pg_loss = -53.411, baseline_loss = 35.69, entropy_loss = -5.5359, learner_queue_size = 32, _tick = 27703, _time = 1.6548e+09, train_seconds = 2.8177e+04)
[2022-06-10 03:57:42,074][root][INFO] - Step 107394560 @ 3581.1 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 107394560, mean_episode_return = 49.31, mean_episode_step = 812.38, total_loss = 599.28, pg_loss = 479.74, baseline_loss = 125.2, entropy_loss = -5.6628, learner_queue_size = 32, _tick = 27706, _time = 1.6548e+09, train_seconds = 2.8182e+04)
[2022-06-10 03:57:47,078][root][INFO] - Step 107415040 @ 4092.8 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 107415040, mean_episode_return = 18.341, mean_episode_step = 928.82, total_loss = 78.277, pg_loss = 45.781, baseline_loss = 38.119, entropy_loss = -5.6229, learner_queue_size = 32, _tick = 27712, _time = 1.6548e+09, train_seconds = 2.8187e+04)
[2022-06-10 03:57:52,082][root][INFO] - Step 107435520 @ 4092.6 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 107435520, mean_episode_return = 46.931, mean_episode_step = 1019.4, total_loss = 141.53, pg_loss = 102.47, baseline_loss = 44.652, entropy_loss = -5.5961, learner_queue_size = 32, _tick = 27720, _time = 1.6548e+09, train_seconds = 2.8192e+04)
[2022-06-10 03:57:57,086][root][INFO] - Step 107453440 @ 3581.2 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 107453440, mean_episode_return = 33.95, mean_episode_step = 1161.6, total_loss = 184.45, pg_loss = 99.732, baseline_loss = 90.265, entropy_loss = -5.5516, learner_queue_size = 32, _tick = 27726, _time = 1.6548e+09, train_seconds = 2.8197e+04)
[2022-06-10 03:58:02,091][root][INFO] - Step 107473920 @ 4091.6 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 107473920, mean_episode_return = 45.51, mean_episode_step = 1556.9, total_loss = 179.82, pg_loss = 49.264, baseline_loss = 136.06, entropy_loss = -5.5005, learner_queue_size = 32, _tick = 27733, _time = 1.6548e+09, train_seconds = 2.8202e+04)
[2022-06-10 03:58:07,094][root][INFO] - Step 107491840 @ 3582.0 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 107491840, mean_episode_return = 43.365, mean_episode_step = 1064.6, total_loss = -84.587, pg_loss = -143.64, baseline_loss = 64.334, entropy_loss = -5.284, learner_queue_size = 32, _tick = 27737, _time = 1.6548e+09, train_seconds = 2.8207e+04)
[2022-06-10 03:58:12,098][root][INFO] - Step 107512320 @ 4092.8 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 107512320, mean_episode_return = 78.83, mean_episode_step = 938.62, total_loss = 262.77, pg_loss = 189.85, baseline_loss = 78.472, entropy_loss = -5.5543, learner_queue_size = 32, _tick = 27743, _time = 1.6548e+09, train_seconds = 2.8212e+04)
[2022-06-10 03:58:17,102][root][INFO] - Step 107532800 @ 4092.7 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 107532800, mean_episode_return = 16.595, mean_episode_step = 1347.0, total_loss = 28.046, pg_loss = -0.45322, baseline_loss = 34.194, entropy_loss = -5.6945, learner_queue_size = 32, _tick = 27751, _time = 1.6548e+09, train_seconds = 2.8217e+04)
[2022-06-10 03:58:22,106][root][INFO] - Step 107550720 @ 3581.2 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 107550720, mean_episode_return = 47.413, mean_episode_step = 985.71, total_loss = -14.175, pg_loss = -63.423, baseline_loss = 54.894, entropy_loss = -5.646, learner_queue_size = 32, _tick = 27755, _time = 1.6548e+09, train_seconds = 2.8222e+04)
[2022-06-10 03:58:27,110][root][INFO] - Step 107571200 @ 4092.5 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 107571200, mean_episode_return = None, mean_episode_step = 933.22, total_loss = 130.76, pg_loss = 74.47, baseline_loss = 61.929, entropy_loss = -5.6433, learner_queue_size = 32, _tick = 27762, _time = 1.6548e+09, train_seconds = 2.8227e+04)
[2022-06-10 03:58:32,117][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 03:58:32,351][root][INFO] - Step 107589120 @ 3579.4 SPS. Inference batcher size: 81. Learner queue size: 32. Other stats: (step = 107591680, mean_episode_return = None, mean_episode_step = 751.62, total_loss = 68.82, pg_loss = 17.201, baseline_loss = 57.146, entropy_loss = -5.5269, learner_queue_size = 32, _tick = 27769, _time = 1.6548e+09, train_seconds = 2.8232e+04)
[2022-06-10 03:58:37,354][root][INFO] - Step 107609600 @ 3910.4 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 107609600, mean_episode_return = 69.274, mean_episode_step = 1032.8, total_loss = 16.426, pg_loss = -15.087, baseline_loss = 37.269, entropy_loss = -5.7562, learner_queue_size = 32, _tick = 27775, _time = 1.6548e+09, train_seconds = 2.8237e+04)
[2022-06-10 03:58:42,358][root][INFO] - Step 107630080 @ 4092.7 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 107630080, mean_episode_return = 8.4998, mean_episode_step = 1003.9, total_loss = 192.03, pg_loss = 148.26, baseline_loss = 49.534, entropy_loss = -5.7592, learner_queue_size = 32, _tick = 27782, _time = 1.6548e+09, train_seconds = 2.8242e+04)
[2022-06-10 03:58:47,362][root][INFO] - Step 107648000 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 107648000, mean_episode_return = 93.346, mean_episode_step = 864.95, total_loss = 129.67, pg_loss = 69.149, baseline_loss = 66.032, entropy_loss = -5.5078, learner_queue_size = 32, _tick = 27788, _time = 1.6548e+09, train_seconds = 2.8247e+04)
[2022-06-10 03:58:52,366][root][INFO] - Step 107668480 @ 4092.7 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 107668480, mean_episode_return = 18.71, mean_episode_step = 966.26, total_loss = 317.18, pg_loss = 236.47, baseline_loss = 86.211, entropy_loss = -5.5032, learner_queue_size = 32, _tick = 27796, _time = 1.6548e+09, train_seconds = 2.8252e+04)
[2022-06-10 03:58:57,372][root][INFO] - Step 107688960 @ 4091.0 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 107688960, mean_episode_return = 36.377, mean_episode_step = 1008.5, total_loss = -48.91, pg_loss = -100.62, baseline_loss = 57.261, entropy_loss = -5.5487, learner_queue_size = 32, _tick = 27804, _time = 1.6548e+09, train_seconds = 2.8257e+04)
[2022-06-10 03:59:02,379][root][INFO] - Step 107706880 @ 3579.2 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 107706880, mean_episode_return = 36.34, mean_episode_step = 1053.2, total_loss = -57.195, pg_loss = -75.341, baseline_loss = 23.797, entropy_loss = -5.6506, learner_queue_size = 32, _tick = 27809, _time = 1.6548e+09, train_seconds = 2.8262e+04)
[2022-06-10 03:59:07,382][root][INFO] - Step 107727360 @ 4093.5 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 107727360, mean_episode_return = 32.343, mean_episode_step = 1089.4, total_loss = -47.55, pg_loss = -56.905, baseline_loss = 14.876, entropy_loss = -5.5213, learner_queue_size = 32, _tick = 27816, _time = 1.6548e+09, train_seconds = 2.8267e+04)
[2022-06-10 03:59:12,386][root][INFO] - Step 107747840 @ 4092.6 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 107747840, mean_episode_return = 51.825, mean_episode_step = 1041.8, total_loss = 14.46, pg_loss = -37.956, baseline_loss = 58.087, entropy_loss = -5.6709, learner_queue_size = 32, _tick = 27823, _time = 1.6548e+09, train_seconds = 2.8272e+04)
[2022-06-10 03:59:17,390][root][INFO] - Step 107768320 @ 4092.7 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 107768320, mean_episode_return = None, mean_episode_step = 1137.0, total_loss = 115.46, pg_loss = 66.095, baseline_loss = 54.89, entropy_loss = -5.5251, learner_queue_size = 32, _tick = 27828, _time = 1.6548e+09, train_seconds = 2.8277e+04)
[2022-06-10 03:59:22,394][root][INFO] - Step 107788800 @ 4092.9 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 107788800, mean_episode_return = 58.514, mean_episode_step = 692.68, total_loss = 40.068, pg_loss = -34.818, baseline_loss = 80.288, entropy_loss = -5.4023, learner_queue_size = 32, _tick = 27835, _time = 1.6548e+09, train_seconds = 2.8282e+04)
[2022-06-10 03:59:27,399][root][INFO] - Step 107806720 @ 3580.6 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 107806720, mean_episode_return = 3.5648, mean_episode_step = 872.47, total_loss = -15.202, pg_loss = -46.112, baseline_loss = 36.47, entropy_loss = -5.5598, learner_queue_size = 32, _tick = 27841, _time = 1.6548e+09, train_seconds = 2.8287e+04)
[2022-06-10 03:59:32,402][root][INFO] - Step 107827200 @ 4093.3 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 107827200, mean_episode_return = 76.358, mean_episode_step = 1009.6, total_loss = -21.881, pg_loss = -49.059, baseline_loss = 32.861, entropy_loss = -5.683, learner_queue_size = 32, _tick = 27848, _time = 1.6548e+09, train_seconds = 2.8292e+04)
[2022-06-10 03:59:37,406][root][INFO] - Step 107847680 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 107847680, mean_episode_return = 83.009, mean_episode_step = 1395.9, total_loss = -17.268, pg_loss = -42.347, baseline_loss = 30.67, entropy_loss = -5.591, learner_queue_size = 32, _tick = 27855, _time = 1.6548e+09, train_seconds = 2.8297e+04)
[2022-06-10 03:59:42,412][root][INFO] - Step 107865600 @ 3579.6 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 107865600, mean_episode_return = -0.59027, mean_episode_step = 1038.7, total_loss = 44.848, pg_loss = 25.454, baseline_loss = 24.624, entropy_loss = -5.23, learner_queue_size = 32, _tick = 27861, _time = 1.6548e+09, train_seconds = 2.8302e+04)
[2022-06-10 03:59:47,418][root][INFO] - Step 107886080 @ 4091.2 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 107886080, mean_episode_return = 46.101, mean_episode_step = 1058.0, total_loss = 86.013, pg_loss = 51.151, baseline_loss = 40.101, entropy_loss = -5.2395, learner_queue_size = 32, _tick = 27869, _time = 1.6548e+09, train_seconds = 2.8307e+04)
[2022-06-10 03:59:52,422][root][INFO] - Step 107906560 @ 4092.7 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 107906560, mean_episode_return = None, mean_episode_step = 915.06, total_loss = 61.159, pg_loss = 23.88, baseline_loss = 42.607, entropy_loss = -5.3271, learner_queue_size = 32, _tick = 27875, _time = 1.6548e+09, train_seconds = 2.8312e+04)
[2022-06-10 03:59:57,426][root][INFO] - Step 107927040 @ 4092.7 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 107927040, mean_episode_return = 95.709, mean_episode_step = 974.81, total_loss = -183.2, pg_loss = -197.51, baseline_loss = 19.477, entropy_loss = -5.1698, learner_queue_size = 32, _tick = 27877, _time = 1.6548e+09, train_seconds = 2.8317e+04)
[2022-06-10 04:00:02,430][root][INFO] - Step 107944960 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 107944960, mean_episode_return = 20.25, mean_episode_step = 961.95, total_loss = -19.434, pg_loss = -46.205, baseline_loss = 31.804, entropy_loss = -5.0333, learner_queue_size = 32, _tick = 27882, _time = 1.6548e+09, train_seconds = 2.8322e+04)
[2022-06-10 04:00:07,434][root][INFO] - Step 107965440 @ 4092.8 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 107965440, mean_episode_return = 66.92, mean_episode_step = 1431.2, total_loss = -8.0981, pg_loss = -47.097, baseline_loss = 44.279, entropy_loss = -5.2802, learner_queue_size = 32, _tick = 27890, _time = 1.6548e+09, train_seconds = 2.8327e+04)
[2022-06-10 04:00:12,438][root][INFO] - Step 107985920 @ 4092.7 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 107985920, mean_episode_return = 19.755, mean_episode_step = 1131.7, total_loss = 15.552, pg_loss = -21.206, baseline_loss = 42.135, entropy_loss = -5.3772, learner_queue_size = 32, _tick = 27896, _time = 1.6548e+09, train_seconds = 2.8332e+04)
[2022-06-10 04:00:17,442][root][INFO] - Step 108003840 @ 3581.0 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 108003840, mean_episode_return = None, mean_episode_step = 1069.6, total_loss = 101.58, pg_loss = 65.838, baseline_loss = 41.393, entropy_loss = -5.6479, learner_queue_size = 32, _tick = 27899, _time = 1.6548e+09, train_seconds = 2.8337e+04)
[2022-06-10 04:00:22,446][root][INFO] - Step 108024320 @ 4092.8 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 108024320, mean_episode_return = 27.915, mean_episode_step = 1126.4, total_loss = -150.56, pg_loss = -161.88, baseline_loss = 17.077, entropy_loss = -5.756, learner_queue_size = 32, _tick = 27906, _time = 1.6548e+09, train_seconds = 2.8342e+04)
[2022-06-10 04:00:27,450][root][INFO] - Step 108042240 @ 3581.2 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 108042240, mean_episode_return = 7.8399, mean_episode_step = 1056.7, total_loss = 5.1585, pg_loss = -4.9849, baseline_loss = 15.969, entropy_loss = -5.8261, learner_queue_size = 32, _tick = 27912, _time = 1.6548e+09, train_seconds = 2.8347e+04)
[2022-06-10 04:00:32,454][root][INFO] - Step 108062720 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 108062720, mean_episode_return = 51.3, mean_episode_step = 878.17, total_loss = 297.22, pg_loss = 224.58, baseline_loss = 77.86, entropy_loss = -5.2144, learner_queue_size = 32, _tick = 27919, _time = 1.6548e+09, train_seconds = 2.8352e+04)
[2022-06-10 04:00:37,458][root][INFO] - Step 108083200 @ 4092.8 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 108083200, mean_episode_return = 56.516, mean_episode_step = 1039.8, total_loss = 144.7, pg_loss = 61.986, baseline_loss = 88.09, entropy_loss = -5.3782, learner_queue_size = 32, _tick = 27927, _time = 1.6548e+09, train_seconds = 2.8357e+04)
[2022-06-10 04:00:42,462][root][INFO] - Step 108101120 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 108101120, mean_episode_return = 30.72, mean_episode_step = 992.37, total_loss = 166.82, pg_loss = 122.81, baseline_loss = 49.28, entropy_loss = -5.2763, learner_queue_size = 32, _tick = 27933, _time = 1.6548e+09, train_seconds = 2.8362e+04)
[2022-06-10 04:00:47,466][root][INFO] - Step 108121600 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 108121600, mean_episode_return = 73.99, mean_episode_step = 899.02, total_loss = 104.88, pg_loss = 18.396, baseline_loss = 91.173, entropy_loss = -4.6839, learner_queue_size = 32, _tick = 27938, _time = 1.6548e+09, train_seconds = 2.8367e+04)
[2022-06-10 04:00:52,470][root][INFO] - Step 108142080 @ 4092.7 SPS. Inference batcher size: 98. Learner queue size: 32. Other stats: (step = 108142080, mean_episode_return = 47.54, mean_episode_step = 1455.6, total_loss = 170.0, pg_loss = 117.47, baseline_loss = 57.921, entropy_loss = -5.3834, learner_queue_size = 32, _tick = 27944, _time = 1.6548e+09, train_seconds = 2.8372e+04)
[2022-06-10 04:00:57,474][root][INFO] - Step 108162560 @ 4092.7 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 108162560, mean_episode_return = 73.65, mean_episode_step = 1182.4, total_loss = 115.23, pg_loss = 33.692, baseline_loss = 86.9, entropy_loss = -5.3646, learner_queue_size = 32, _tick = 27952, _time = 1.6548e+09, train_seconds = 2.8377e+04)
[2022-06-10 04:01:02,478][root][INFO] - Step 108183040 @ 4092.6 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 108183040, mean_episode_return = 104.5, mean_episode_step = 1180.8, total_loss = 100.45, pg_loss = 0.43614, baseline_loss = 105.67, entropy_loss = -5.6568, learner_queue_size = 32, _tick = 27960, _time = 1.6548e+09, train_seconds = 2.8382e+04)
[2022-06-10 04:01:07,482][root][INFO] - Step 108200960 @ 3581.2 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 108200960, mean_episode_return = 111.37, mean_episode_step = 1297.8, total_loss = 12.675, pg_loss = -10.272, baseline_loss = 28.779, entropy_loss = -5.8314, learner_queue_size = 32, _tick = 27965, _time = 1.6548e+09, train_seconds = 2.8387e+04)
[2022-06-10 04:01:12,486][root][INFO] - Step 108221440 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 108221440, mean_episode_return = None, mean_episode_step = 935.91, total_loss = 462.87, pg_loss = 374.64, baseline_loss = 93.715, entropy_loss = -5.4841, learner_queue_size = 32, _tick = 27971, _time = 1.6548e+09, train_seconds = 2.8392e+04)
[2022-06-10 04:01:17,490][root][INFO] - Step 108241920 @ 4092.8 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 108241920, mean_episode_return = 4.3699, mean_episode_step = 1094.9, total_loss = -116.74, pg_loss = -156.65, baseline_loss = 45.36, entropy_loss = -5.4472, learner_queue_size = 32, _tick = 27979, _time = 1.6548e+09, train_seconds = 2.8397e+04)
[2022-06-10 04:01:22,494][root][INFO] - Step 108259840 @ 3581.1 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 108259840, mean_episode_return = 96.28, mean_episode_step = 832.23, total_loss = -92.306, pg_loss = -112.25, baseline_loss = 25.355, entropy_loss = -5.4127, learner_queue_size = 32, _tick = 27984, _time = 1.6548e+09, train_seconds = 2.8402e+04)
[2022-06-10 04:01:27,498][root][INFO] - Step 108280320 @ 4092.8 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 108280320, mean_episode_return = None, mean_episode_step = 911.69, total_loss = 50.151, pg_loss = 20.925, baseline_loss = 34.635, entropy_loss = -5.4086, learner_queue_size = 32, _tick = 27989, _time = 1.6548e+09, train_seconds = 2.8407e+04)
[2022-06-10 04:01:32,502][root][INFO] - Step 108300800 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 108300800, mean_episode_return = 54.701, mean_episode_step = 1107.6, total_loss = -84.552, pg_loss = -160.53, baseline_loss = 81.401, entropy_loss = -5.4279, learner_queue_size = 32, _tick = 27996, _time = 1.6548e+09, train_seconds = 2.8412e+04)
[2022-06-10 04:01:37,506][root][INFO] - Step 108318720 @ 3581.2 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 108318720, mean_episode_return = None, mean_episode_step = 1028.7, total_loss = 261.07, pg_loss = 217.3, baseline_loss = 49.195, entropy_loss = -5.4256, learner_queue_size = 32, _tick = 28002, _time = 1.6548e+09, train_seconds = 2.8417e+04)
[2022-06-10 04:01:42,510][root][INFO] - Step 108339200 @ 4092.7 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (step = 108339200, mean_episode_return = 49.982, mean_episode_step = 1260.5, total_loss = 267.17, pg_loss = 209.21, baseline_loss = 63.3, entropy_loss = -5.3378, learner_queue_size = 32, _tick = 28007, _time = 1.6548e+09, train_seconds = 2.8422e+04)
[2022-06-10 04:01:47,514][root][INFO] - Step 108357120 @ 3581.1 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 108357120, mean_episode_return = 43.231, mean_episode_step = 1056.7, total_loss = -85.945, pg_loss = -121.94, baseline_loss = 41.283, entropy_loss = -5.2922, learner_queue_size = 32, _tick = 28014, _time = 1.6548e+09, train_seconds = 2.8427e+04)
[2022-06-10 04:01:52,521][root][INFO] - Step 108377600 @ 4090.3 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 108377600, mean_episode_return = 111.52, mean_episode_step = 1079.9, total_loss = 355.75, pg_loss = 278.67, baseline_loss = 82.494, entropy_loss = -5.4139, learner_queue_size = 32, _tick = 28022, _time = 1.6548e+09, train_seconds = 2.8432e+04)
[2022-06-10 04:01:57,526][root][INFO] - Step 108395520 @ 3580.4 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 108395520, mean_episode_return = 35.275, mean_episode_step = 866.69, total_loss = 96.536, pg_loss = 48.712, baseline_loss = 53.194, entropy_loss = -5.3689, learner_queue_size = 32, _tick = 28026, _time = 1.6548e+09, train_seconds = 2.8437e+04)
[2022-06-10 04:02:02,531][root][INFO] - Step 108416000 @ 4092.2 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 108416000, mean_episode_return = 60.851, mean_episode_step = 1426.8, total_loss = -68.193, pg_loss = -100.1, baseline_loss = 37.225, entropy_loss = -5.3153, learner_queue_size = 32, _tick = 28033, _time = 1.6548e+09, train_seconds = 2.8442e+04)
[2022-06-10 04:02:07,534][root][INFO] - Step 108436480 @ 4093.2 SPS. Inference batcher size: 77. Learner queue size: 32. Other stats: (step = 108436480, mean_episode_return = 110.26, mean_episode_step = 916.62, total_loss = 133.42, pg_loss = 78.725, baseline_loss = 60.059, entropy_loss = -5.3664, learner_queue_size = 32, _tick = 28038, _time = 1.6548e+09, train_seconds = 2.8447e+04)
[2022-06-10 04:02:12,538][root][INFO] - Step 108454400 @ 3581.2 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 108454400, mean_episode_return = 54.031, mean_episode_step = 1158.8, total_loss = 269.44, pg_loss = 179.89, baseline_loss = 94.897, entropy_loss = -5.3452, learner_queue_size = 32, _tick = 28045, _time = 1.6548e+09, train_seconds = 2.8452e+04)
[2022-06-10 04:02:17,544][root][INFO] - Step 108474880 @ 4091.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 108474880, mean_episode_return = 136.42, mean_episode_step = 1077.8, total_loss = -46.114, pg_loss = -74.872, baseline_loss = 34.115, entropy_loss = -5.3571, learner_queue_size = 32, _tick = 28051, _time = 1.6548e+09, train_seconds = 2.8457e+04)
[2022-06-10 04:02:22,546][root][INFO] - Step 108492800 @ 3582.6 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 108492800, mean_episode_return = 99.404, mean_episode_step = 955.38, total_loss = -131.2, pg_loss = -162.09, baseline_loss = 36.283, entropy_loss = -5.3907, learner_queue_size = 32, _tick = 28057, _time = 1.6548e+09, train_seconds = 2.8462e+04)
[2022-06-10 04:02:27,550][root][INFO] - Step 108513280 @ 4092.7 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 108513280, mean_episode_return = 77.86, mean_episode_step = 1639.5, total_loss = 161.53, pg_loss = 79.736, baseline_loss = 87.201, entropy_loss = -5.4043, learner_queue_size = 32, _tick = 28061, _time = 1.6548e+09, train_seconds = 2.8467e+04)
[2022-06-10 04:02:32,554][root][INFO] - Step 108533760 @ 4092.7 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 108533760, mean_episode_return = 112.99, mean_episode_step = 1150.8, total_loss = -42.87, pg_loss = -58.71, baseline_loss = 21.241, entropy_loss = -5.4012, learner_queue_size = 32, _tick = 28068, _time = 1.6548e+09, train_seconds = 2.8472e+04)
[2022-06-10 04:02:37,558][root][INFO] - Step 108551680 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 108551680, mean_episode_return = 66.373, mean_episode_step = 1167.5, total_loss = -74.312, pg_loss = -109.79, baseline_loss = 40.925, entropy_loss = -5.4431, learner_queue_size = 32, _tick = 28073, _time = 1.6548e+09, train_seconds = 2.8477e+04)
[2022-06-10 04:02:42,562][root][INFO] - Step 108572160 @ 4092.8 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 108572160, mean_episode_return = 94.889, mean_episode_step = 970.61, total_loss = 70.512, pg_loss = 40.513, baseline_loss = 35.382, entropy_loss = -5.3831, learner_queue_size = 32, _tick = 28081, _time = 1.6548e+09, train_seconds = 2.8482e+04)
[2022-06-10 04:02:47,566][root][INFO] - Step 108592640 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 108592640, mean_episode_return = 61.072, mean_episode_step = 915.64, total_loss = 153.66, pg_loss = 129.72, baseline_loss = 29.277, entropy_loss = -5.3392, learner_queue_size = 32, _tick = 28087, _time = 1.6548e+09, train_seconds = 2.8487e+04)
[2022-06-10 04:02:52,570][root][INFO] - Step 108613120 @ 4092.7 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 108613120, mean_episode_return = 16.18, mean_episode_step = 1032.7, total_loss = 18.116, pg_loss = 4.8365, baseline_loss = 18.696, entropy_loss = -5.416, learner_queue_size = 32, _tick = 28093, _time = 1.6548e+09, train_seconds = 2.8492e+04)
[2022-06-10 04:02:57,574][root][INFO] - Step 108631040 @ 3581.2 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 108631040, mean_episode_return = 100.09, mean_episode_step = 815.8, total_loss = -0.063073, pg_loss = -6.7441, baseline_loss = 11.934, entropy_loss = -5.2531, learner_queue_size = 32, _tick = 28098, _time = 1.6548e+09, train_seconds = 2.8497e+04)
[2022-06-10 04:03:02,579][root][INFO] - Step 108651520 @ 4092.6 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 108651520, mean_episode_return = None, mean_episode_step = 925.88, total_loss = 182.78, pg_loss = 155.51, baseline_loss = 32.511, entropy_loss = -5.2346, learner_queue_size = 32, _tick = 28105, _time = 1.6548e+09, train_seconds = 2.8502e+04)
[2022-06-10 04:03:07,586][root][INFO] - Step 108669440 @ 3578.4 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (step = 108669440, mean_episode_return = None, mean_episode_step = 1082.9, total_loss = 42.285, pg_loss = -1.4683, baseline_loss = 48.857, entropy_loss = -5.1038, learner_queue_size = 32, _tick = 28109, _time = 1.6548e+09, train_seconds = 2.8507e+04)
[2022-06-10 04:03:12,591][root][INFO] - Step 108689920 @ 4092.1 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 108689920, mean_episode_return = 115.49, mean_episode_step = 1046.1, total_loss = -50.472, pg_loss = -79.531, baseline_loss = 34.324, entropy_loss = -5.2649, learner_queue_size = 32, _tick = 28116, _time = 1.6548e+09, train_seconds = 2.8512e+04)
[2022-06-10 04:03:17,594][root][INFO] - Step 108707840 @ 3581.7 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 108707840, mean_episode_return = 126.18, mean_episode_step = 1014.0, total_loss = -30.663, pg_loss = -40.268, baseline_loss = 14.983, entropy_loss = -5.3777, learner_queue_size = 32, _tick = 28123, _time = 1.6548e+09, train_seconds = 2.8517e+04)
[2022-06-10 04:03:22,598][root][INFO] - Step 108728320 @ 4092.7 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 108728320, mean_episode_return = 103.5, mean_episode_step = 1278.1, total_loss = 224.47, pg_loss = 186.15, baseline_loss = 43.854, entropy_loss = -5.5315, learner_queue_size = 32, _tick = 28127, _time = 1.6548e+09, train_seconds = 2.8522e+04)
[2022-06-10 04:03:27,602][root][INFO] - Step 108748800 @ 4092.8 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 108748800, mean_episode_return = 55.113, mean_episode_step = 1038.1, total_loss = 53.254, pg_loss = 8.0625, baseline_loss = 50.664, entropy_loss = -5.4729, learner_queue_size = 32, _tick = 28133, _time = 1.6548e+09, train_seconds = 2.8527e+04)
[2022-06-10 04:03:32,606][root][INFO] - Step 108769280 @ 4092.7 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 108769280, mean_episode_return = 22.695, mean_episode_step = 839.55, total_loss = -90.654, pg_loss = -115.71, baseline_loss = 30.314, entropy_loss = -5.2595, learner_queue_size = 32, _tick = 28140, _time = 1.6548e+09, train_seconds = 2.8532e+04)
[2022-06-10 04:03:37,610][root][INFO] - Step 108789760 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 108789760, mean_episode_return = 8.1749, mean_episode_step = 1059.8, total_loss = -102.29, pg_loss = -158.19, baseline_loss = 61.234, entropy_loss = -5.3375, learner_queue_size = 32, _tick = 28146, _time = 1.6548e+09, train_seconds = 2.8537e+04)
[2022-06-10 04:03:42,614][root][INFO] - Step 108810240 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 108810240, mean_episode_return = 40.134, mean_episode_step = 1254.2, total_loss = -21.973, pg_loss = -58.686, baseline_loss = 41.894, entropy_loss = -5.1813, learner_queue_size = 32, _tick = 28153, _time = 1.6548e+09, train_seconds = 2.8542e+04)
[2022-06-10 04:03:47,618][root][INFO] - Step 108828160 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 108828160, mean_episode_return = 82.53, mean_episode_step = 1212.3, total_loss = 19.301, pg_loss = -17.818, baseline_loss = 42.399, entropy_loss = -5.2804, learner_queue_size = 32, _tick = 28158, _time = 1.6548e+09, train_seconds = 2.8547e+04)
[2022-06-10 04:03:52,622][root][INFO] - Step 108848640 @ 4092.7 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 108848640, mean_episode_return = 114.88, mean_episode_step = 1373.2, total_loss = -50.077, pg_loss = -88.218, baseline_loss = 43.162, entropy_loss = -5.0211, learner_queue_size = 32, _tick = 28163, _time = 1.6548e+09, train_seconds = 2.8552e+04)
[2022-06-10 04:03:57,626][root][INFO] - Step 108869120 @ 4092.8 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 108869120, mean_episode_return = None, mean_episode_step = 1250.5, total_loss = 38.824, pg_loss = 8.3939, baseline_loss = 35.413, entropy_loss = -4.9829, learner_queue_size = 32, _tick = 28168, _time = 1.6548e+09, train_seconds = 2.8557e+04)
[2022-06-10 04:04:02,630][root][INFO] - Step 108887040 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 108887040, mean_episode_return = 0.58989, mean_episode_step = 1141.2, total_loss = 27.964, pg_loss = 1.2109, baseline_loss = 31.835, entropy_loss = -5.0816, learner_queue_size = 32, _tick = 28172, _time = 1.6548e+09, train_seconds = 2.8562e+04)
[2022-06-10 04:04:07,634][root][INFO] - Step 108907520 @ 4092.8 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 108907520, mean_episode_return = 51.561, mean_episode_step = 1303.5, total_loss = 93.31, pg_loss = 62.009, baseline_loss = 36.884, entropy_loss = -5.5822, learner_queue_size = 32, _tick = 28178, _time = 1.6548e+09, train_seconds = 2.8567e+04)
[2022-06-10 04:04:12,638][root][INFO] - Step 108928000 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 108928000, mean_episode_return = 16.86, mean_episode_step = 1334.7, total_loss = 211.63, pg_loss = 150.56, baseline_loss = 66.708, entropy_loss = -5.637, learner_queue_size = 32, _tick = 28185, _time = 1.6548e+09, train_seconds = 2.8572e+04)
[2022-06-10 04:04:17,645][root][INFO] - Step 108945920 @ 3579.2 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 108945920, mean_episode_return = 57.555, mean_episode_step = 952.13, total_loss = 32.916, pg_loss = 17.886, baseline_loss = 20.107, entropy_loss = -5.0767, learner_queue_size = 32, _tick = 28191, _time = 1.6548e+09, train_seconds = 2.8578e+04)
[2022-06-10 04:04:22,650][root][INFO] - Step 108966400 @ 4091.7 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (step = 108966400, mean_episode_return = 18.405, mean_episode_step = 973.29, total_loss = -183.56, pg_loss = -204.81, baseline_loss = 26.451, entropy_loss = -5.2014, learner_queue_size = 32, _tick = 28197, _time = 1.6548e+09, train_seconds = 2.8582e+04)
[2022-06-10 04:04:27,656][root][INFO] - Step 108986880 @ 4091.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 108986880, mean_episode_return = 21.01, mean_episode_step = 1108.4, total_loss = -179.97, pg_loss = -214.47, baseline_loss = 39.847, entropy_loss = -5.3468, learner_queue_size = 32, _tick = 28202, _time = 1.6548e+09, train_seconds = 2.8588e+04)
[2022-06-10 04:04:32,658][root][INFO] - Step 109007360 @ 4094.2 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 109007360, mean_episode_return = 110.47, mean_episode_step = 1523.8, total_loss = 25.57, pg_loss = -31.417, baseline_loss = 62.406, entropy_loss = -5.4181, learner_queue_size = 32, _tick = 28208, _time = 1.6548e+09, train_seconds = 2.8592e+04)
[2022-06-10 04:04:37,662][root][INFO] - Step 109025280 @ 3581.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 109025280, mean_episode_return = 66.506, mean_episode_step = 1867.1, total_loss = -3.7408, pg_loss = -33.794, baseline_loss = 35.509, entropy_loss = -5.4557, learner_queue_size = 32, _tick = 28213, _time = 1.6548e+09, train_seconds = 2.8598e+04)
[2022-06-10 04:04:42,666][root][INFO] - Step 109045760 @ 4092.6 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 109045760, mean_episode_return = 47.006, mean_episode_step = 1214.9, total_loss = -40.293, pg_loss = -68.534, baseline_loss = 33.419, entropy_loss = -5.1778, learner_queue_size = 32, _tick = 28221, _time = 1.6548e+09, train_seconds = 2.8602e+04)
[2022-06-10 04:04:47,670][root][INFO] - Step 109066240 @ 4092.9 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 109066240, mean_episode_return = 39.046, mean_episode_step = 1115.6, total_loss = 162.62, pg_loss = 122.43, baseline_loss = 45.72, entropy_loss = -5.5338, learner_queue_size = 32, _tick = 28227, _time = 1.6548e+09, train_seconds = 2.8608e+04)
[2022-06-10 04:04:52,690][root][INFO] - Step 109084160 @ 3569.7 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 109084160, mean_episode_return = 90.341, mean_episode_step = 1156.1, total_loss = 97.513, pg_loss = 22.76, baseline_loss = 80.141, entropy_loss = -5.3884, learner_queue_size = 32, _tick = 28233, _time = 1.6548e+09, train_seconds = 2.8612e+04)
[2022-06-10 04:04:57,694][root][INFO] - Step 109104640 @ 4092.8 SPS. Inference batcher size: 75. Learner queue size: 32. Other stats: (step = 109104640, mean_episode_return = None, mean_episode_step = 1263.9, total_loss = -77.761, pg_loss = -92.04, baseline_loss = 19.803, entropy_loss = -5.5241, learner_queue_size = 32, _tick = 28239, _time = 1.6548e+09, train_seconds = 2.8618e+04)
[2022-06-10 04:05:02,698][root][INFO] - Step 109122560 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 109122560, mean_episode_return = 125.07, mean_episode_step = 1900.7, total_loss = 339.18, pg_loss = 256.63, baseline_loss = 87.983, entropy_loss = -5.4264, learner_queue_size = 32, _tick = 28244, _time = 1.6548e+09, train_seconds = 2.8622e+04)
[2022-06-10 04:05:07,702][root][INFO] - Step 109143040 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 109143040, mean_episode_return = None, mean_episode_step = 1422.4, total_loss = -17.238, pg_loss = -44.038, baseline_loss = 32.173, entropy_loss = -5.3728, learner_queue_size = 32, _tick = 28251, _time = 1.6548e+09, train_seconds = 2.8628e+04)
[2022-06-10 04:05:12,706][root][INFO] - Step 109163520 @ 4092.7 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 109163520, mean_episode_return = 21.55, mean_episode_step = 1392.2, total_loss = 111.99, pg_loss = 84.596, baseline_loss = 32.882, entropy_loss = -5.4891, learner_queue_size = 32, _tick = 28257, _time = 1.6548e+09, train_seconds = 2.8632e+04)
[2022-06-10 04:05:17,710][root][INFO] - Step 109181440 @ 3581.2 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 109181440, mean_episode_return = 69.19, mean_episode_step = 1160.9, total_loss = 119.53, pg_loss = 86.498, baseline_loss = 38.47, entropy_loss = -5.436, learner_queue_size = 32, _tick = 28262, _time = 1.6548e+09, train_seconds = 2.8638e+04)
[2022-06-10 04:05:22,714][root][INFO] - Step 109201920 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 109201920, mean_episode_return = None, mean_episode_step = 1103.3, total_loss = 14.854, pg_loss = -1.0008, baseline_loss = 21.218, entropy_loss = -5.363, learner_queue_size = 32, _tick = 28267, _time = 1.6548e+09, train_seconds = 2.8642e+04)
[2022-06-10 04:05:27,718][root][INFO] - Step 109219840 @ 3581.2 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 109219840, mean_episode_return = 67.122, mean_episode_step = 1285.6, total_loss = 51.216, pg_loss = 39.269, baseline_loss = 17.643, entropy_loss = -5.6959, learner_queue_size = 32, _tick = 28274, _time = 1.6548e+09, train_seconds = 2.8648e+04)
[2022-06-10 04:05:32,722][root][INFO] - Step 109240320 @ 4092.7 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 109240320, mean_episode_return = 5.0148, mean_episode_step = 1598.0, total_loss = 48.285, pg_loss = 0.51283, baseline_loss = 53.151, entropy_loss = -5.3788, learner_queue_size = 32, _tick = 28281, _time = 1.6548e+09, train_seconds = 2.8652e+04)
[2022-06-10 04:05:37,726][root][INFO] - Step 109258240 @ 3581.2 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 109258240, mean_episode_return = 60.141, mean_episode_step = 1370.7, total_loss = -69.248, pg_loss = -78.511, baseline_loss = 14.723, entropy_loss = -5.4603, learner_queue_size = 32, _tick = 28287, _time = 1.6548e+09, train_seconds = 2.8658e+04)
[2022-06-10 04:05:42,730][root][INFO] - Step 109278720 @ 4092.7 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 109278720, mean_episode_return = None, mean_episode_step = 938.75, total_loss = 231.14, pg_loss = 164.91, baseline_loss = 71.639, entropy_loss = -5.4062, learner_queue_size = 32, _tick = 28292, _time = 1.6548e+09, train_seconds = 2.8662e+04)
[2022-06-10 04:05:47,734][root][INFO] - Step 109299200 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 109299200, mean_episode_return = 54.621, mean_episode_step = 1155.3, total_loss = -0.98769, pg_loss = -30.375, baseline_loss = 34.736, entropy_loss = -5.3484, learner_queue_size = 32, _tick = 28297, _time = 1.6548e+09, train_seconds = 2.8668e+04)
[2022-06-10 04:05:52,738][root][INFO] - Step 109317120 @ 3581.2 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 109317120, mean_episode_return = 37.63, mean_episode_step = 879.91, total_loss = 72.906, pg_loss = 14.634, baseline_loss = 63.618, entropy_loss = -5.3457, learner_queue_size = 32, _tick = 28304, _time = 1.6548e+09, train_seconds = 2.8672e+04)
[2022-06-10 04:05:57,742][root][INFO] - Step 109337600 @ 4092.7 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 109337600, mean_episode_return = 66.56, mean_episode_step = 810.91, total_loss = 50.015, pg_loss = 6.8884, baseline_loss = 48.414, entropy_loss = -5.2867, learner_queue_size = 32, _tick = 28310, _time = 1.6548e+09, train_seconds = 2.8678e+04)
[2022-06-10 04:06:02,746][root][INFO] - Step 109355520 @ 3581.2 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 109355520, mean_episode_return = 38.547, mean_episode_step = 963.12, total_loss = 114.15, pg_loss = 54.116, baseline_loss = 65.512, entropy_loss = -5.4787, learner_queue_size = 32, _tick = 28317, _time = 1.6548e+09, train_seconds = 2.8683e+04)
[2022-06-10 04:06:07,750][root][INFO] - Step 109376000 @ 4092.7 SPS. Inference batcher size: 92. Learner queue size: 32. Other stats: (step = 109376000, mean_episode_return = None, mean_episode_step = 1307.5, total_loss = 70.939, pg_loss = 39.056, baseline_loss = 37.588, entropy_loss = -5.7044, learner_queue_size = 32, _tick = 28322, _time = 1.6548e+09, train_seconds = 2.8688e+04)
[2022-06-10 04:06:12,754][root][INFO] - Step 109393920 @ 3581.0 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 109393920, mean_episode_return = 24.23, mean_episode_step = 883.46, total_loss = -16.081, pg_loss = -83.378, baseline_loss = 72.737, entropy_loss = -5.4405, learner_queue_size = 32, _tick = 28329, _time = 1.6548e+09, train_seconds = 2.8693e+04)
[2022-06-10 04:06:17,758][root][INFO] - Step 109414400 @ 4092.8 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 109414400, mean_episode_return = 85.509, mean_episode_step = 1565.5, total_loss = 41.963, pg_loss = 18.226, baseline_loss = 29.135, entropy_loss = -5.3976, learner_queue_size = 32, _tick = 28337, _time = 1.6548e+09, train_seconds = 2.8698e+04)
[2022-06-10 04:06:22,762][root][INFO] - Step 109434880 @ 4092.8 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 109434880, mean_episode_return = 112.66, mean_episode_step = 1140.9, total_loss = 252.88, pg_loss = 189.21, baseline_loss = 68.951, entropy_loss = -5.2792, learner_queue_size = 32, _tick = 28344, _time = 1.6548e+09, train_seconds = 2.8703e+04)
[2022-06-10 04:06:27,766][root][INFO] - Step 109452800 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 109452800, mean_episode_return = 40.713, mean_episode_step = 907.3, total_loss = 196.34, pg_loss = 116.34, baseline_loss = 85.294, entropy_loss = -5.2933, learner_queue_size = 32, _tick = 28350, _time = 1.6548e+09, train_seconds = 2.8708e+04)
[2022-06-10 04:06:32,770][root][INFO] - Step 109473280 @ 4092.7 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 109473280, mean_episode_return = None, mean_episode_step = 899.03, total_loss = 58.249, pg_loss = 14.084, baseline_loss = 49.486, entropy_loss = -5.321, learner_queue_size = 32, _tick = 28356, _time = 1.6548e+09, train_seconds = 2.8713e+04)
[2022-06-10 04:06:37,775][root][INFO] - Step 109493760 @ 4091.9 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 109493760, mean_episode_return = 30.33, mean_episode_step = 936.46, total_loss = -9.1707, pg_loss = -58.529, baseline_loss = 54.684, entropy_loss = -5.3261, learner_queue_size = 32, _tick = 28364, _time = 1.6548e+09, train_seconds = 2.8718e+04)
[2022-06-10 04:06:42,778][root][INFO] - Step 109511680 @ 3581.9 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 109511680, mean_episode_return = 22.796, mean_episode_step = 1013.3, total_loss = 213.47, pg_loss = 165.96, baseline_loss = 52.892, entropy_loss = -5.3824, learner_queue_size = 32, _tick = 28370, _time = 1.6548e+09, train_seconds = 2.8723e+04)
[2022-06-10 04:06:47,782][root][INFO] - Step 109532160 @ 4092.6 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 109532160, mean_episode_return = 55.39, mean_episode_step = 689.81, total_loss = 149.35, pg_loss = 85.896, baseline_loss = 68.751, entropy_loss = -5.2922, learner_queue_size = 32, _tick = 28378, _time = 1.6548e+09, train_seconds = 2.8728e+04)
[2022-06-10 04:06:52,786][root][INFO] - Step 109552640 @ 4092.9 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 109552640, mean_episode_return = None, mean_episode_step = 955.47, total_loss = 20.384, pg_loss = -18.119, baseline_loss = 44.013, entropy_loss = -5.5102, learner_queue_size = 32, _tick = 28384, _time = 1.6548e+09, train_seconds = 2.8733e+04)
[2022-06-10 04:06:57,790][root][INFO] - Step 109570560 @ 3581.2 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 109570560, mean_episode_return = 65.195, mean_episode_step = 1020.2, total_loss = -88.688, pg_loss = -89.191, baseline_loss = 6.1302, entropy_loss = -5.6271, learner_queue_size = 32, _tick = 28390, _time = 1.6548e+09, train_seconds = 2.8738e+04)
[2022-06-10 04:07:02,794][root][INFO] - Step 109591040 @ 4092.7 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 109591040, mean_episode_return = 34.66, mean_episode_step = 947.58, total_loss = 18.147, pg_loss = -3.7328, baseline_loss = 27.104, entropy_loss = -5.224, learner_queue_size = 32, _tick = 28396, _time = 1.6548e+09, train_seconds = 2.8743e+04)
[2022-06-10 04:07:07,798][root][INFO] - Step 109608960 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 109608960, mean_episode_return = 19.91, mean_episode_step = 928.24, total_loss = 27.268, pg_loss = 10.909, baseline_loss = 21.631, entropy_loss = -5.2722, learner_queue_size = 32, _tick = 28403, _time = 1.6548e+09, train_seconds = 2.8748e+04)
[2022-06-10 04:07:12,802][root][INFO] - Step 109629440 @ 4092.7 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (step = 109629440, mean_episode_return = None, mean_episode_step = 791.78, total_loss = -109.82, pg_loss = -123.12, baseline_loss = 18.565, entropy_loss = -5.2619, learner_queue_size = 32, _tick = 28410, _time = 1.6548e+09, train_seconds = 2.8753e+04)
[2022-06-10 04:07:17,806][root][INFO] - Step 109647360 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 109647360, mean_episode_return = 81.68, mean_episode_step = 973.27, total_loss = 87.487, pg_loss = 55.255, baseline_loss = 37.681, entropy_loss = -5.448, learner_queue_size = 32, _tick = 28415, _time = 1.6548e+09, train_seconds = 2.8758e+04)
[2022-06-10 04:07:22,810][root][INFO] - Step 109667840 @ 4092.8 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 109667840, mean_episode_return = None, mean_episode_step = 957.38, total_loss = -6.2082, pg_loss = -33.353, baseline_loss = 32.878, entropy_loss = -5.7333, learner_queue_size = 32, _tick = 28420, _time = 1.6548e+09, train_seconds = 2.8763e+04)
[2022-06-10 04:07:27,814][root][INFO] - Step 109688320 @ 4092.6 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 109688320, mean_episode_return = 10.345, mean_episode_step = 931.87, total_loss = 28.639, pg_loss = 9.6636, baseline_loss = 24.848, entropy_loss = -5.8725, learner_queue_size = 32, _tick = 28426, _time = 1.6548e+09, train_seconds = 2.8768e+04)
[2022-06-10 04:07:32,819][root][INFO] - Step 109708800 @ 4092.1 SPS. Inference batcher size: 80. Learner queue size: 32. Other stats: (step = 109708800, mean_episode_return = 15.97, mean_episode_step = 938.38, total_loss = -12.939, pg_loss = -29.514, baseline_loss = 21.999, entropy_loss = -5.4241, learner_queue_size = 32, _tick = 28432, _time = 1.6548e+09, train_seconds = 2.8773e+04)
[2022-06-10 04:07:37,826][root][INFO] - Step 109726720 @ 3578.9 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 109726720, mean_episode_return = 74.375, mean_episode_step = 890.96, total_loss = 118.07, pg_loss = 88.609, baseline_loss = 34.884, entropy_loss = -5.4185, learner_queue_size = 32, _tick = 28438, _time = 1.6548e+09, train_seconds = 2.8778e+04)
[2022-06-10 04:07:42,830][root][INFO] - Step 109747200 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 109747200, mean_episode_return = 46.87, mean_episode_step = 1121.8, total_loss = 95.976, pg_loss = 67.728, baseline_loss = 33.719, entropy_loss = -5.4709, learner_queue_size = 32, _tick = 28443, _time = 1.6548e+09, train_seconds = 2.8783e+04)
[2022-06-10 04:07:47,834][root][INFO] - Step 109765120 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 109765120, mean_episode_return = None, mean_episode_step = 1267.2, total_loss = 132.54, pg_loss = 94.893, baseline_loss = 43.114, entropy_loss = -5.4671, learner_queue_size = 32, _tick = 28445, _time = 1.6548e+09, train_seconds = 2.8788e+04)
[2022-06-10 04:07:52,838][root][INFO] - Step 109785600 @ 4092.7 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 109785600, mean_episode_return = 101.27, mean_episode_step = 925.96, total_loss = 23.285, pg_loss = -16.187, baseline_loss = 44.925, entropy_loss = -5.4537, learner_queue_size = 32, _tick = 28450, _time = 1.6548e+09, train_seconds = 2.8793e+04)
[2022-06-10 04:07:57,845][root][INFO] - Step 109803520 @ 3579.3 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 109803520, mean_episode_return = None, mean_episode_step = 1061.6, total_loss = -5.865, pg_loss = -18.656, baseline_loss = 18.437, entropy_loss = -5.6462, learner_queue_size = 32, _tick = 28454, _time = 1.6548e+09, train_seconds = 2.8798e+04)
[2022-06-10 04:08:02,850][root][INFO] - Step 109824000 @ 4091.7 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 109824000, mean_episode_return = 61.75, mean_episode_step = 986.99, total_loss = 85.092, pg_loss = -7.7448, baseline_loss = 98.345, entropy_loss = -5.508, learner_queue_size = 32, _tick = 28459, _time = 1.6548e+09, train_seconds = 2.8803e+04)
[2022-06-10 04:08:07,854][root][INFO] - Step 109844480 @ 4092.6 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 109844480, mean_episode_return = None, mean_episode_step = 1028.5, total_loss = 198.67, pg_loss = 146.97, baseline_loss = 56.979, entropy_loss = -5.2775, learner_queue_size = 32, _tick = 28466, _time = 1.6548e+09, train_seconds = 2.8808e+04)
[2022-06-10 04:08:12,858][root][INFO] - Step 109864960 @ 4092.9 SPS. Inference batcher size: 91. Learner queue size: 32. Other stats: (step = 109864960, mean_episode_return = 106.62, mean_episode_step = 1126.0, total_loss = 366.25, pg_loss = 249.83, baseline_loss = 121.68, entropy_loss = -5.2535, learner_queue_size = 32, _tick = 28471, _time = 1.6548e+09, train_seconds = 2.8813e+04)
[2022-06-10 04:08:17,862][root][INFO] - Step 109882880 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 109882880, mean_episode_return = 118.27, mean_episode_step = 1243.7, total_loss = -72.859, pg_loss = -97.314, baseline_loss = 29.462, entropy_loss = -5.0069, learner_queue_size = 32, _tick = 28475, _time = 1.6548e+09, train_seconds = 2.8818e+04)
[2022-06-10 04:08:22,866][root][INFO] - Step 109903360 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 109903360, mean_episode_return = 9.7899, mean_episode_step = 1244.4, total_loss = -125.37, pg_loss = -137.11, baseline_loss = 17.178, entropy_loss = -5.4327, learner_queue_size = 32, _tick = 28483, _time = 1.6548e+09, train_seconds = 2.8823e+04)
[2022-06-10 04:08:27,870][root][INFO] - Step 109921280 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 109921280, mean_episode_return = 105.86, mean_episode_step = 1067.8, total_loss = 166.56, pg_loss = 104.85, baseline_loss = 67.546, entropy_loss = -5.8366, learner_queue_size = 32, _tick = 28490, _time = 1.6548e+09, train_seconds = 2.8828e+04)
[2022-06-10 04:08:32,874][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 04:08:33,132][root][INFO] - Step 109941760 @ 4092.8 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 109944320, mean_episode_return = None, mean_episode_step = 1233.2, total_loss = 3.5316, pg_loss = -31.982, baseline_loss = 41.167, entropy_loss = -5.6526, learner_queue_size = 32, _tick = 28497, _time = 1.6548e+09, train_seconds = 2.8833e+04)
[2022-06-10 04:08:38,138][root][INFO] - Step 109962240 @ 3890.5 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 109962240, mean_episode_return = 128.69, mean_episode_step = 1089.8, total_loss = 223.82, pg_loss = 158.06, baseline_loss = 71.465, entropy_loss = -5.6991, learner_queue_size = 32, _tick = 28502, _time = 1.6548e+09, train_seconds = 2.8838e+04)
[2022-06-10 04:08:43,142][root][INFO] - Step 109982720 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 109982720, mean_episode_return = 130.48, mean_episode_step = 1224.5, total_loss = 80.635, pg_loss = 30.722, baseline_loss = 55.461, entropy_loss = -5.5481, learner_queue_size = 32, _tick = 28509, _time = 1.6548e+09, train_seconds = 2.8843e+04)
[2022-06-10 04:08:48,148][root][INFO] - Step 110003200 @ 4091.3 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (step = 110003200, mean_episode_return = 71.949, mean_episode_step = 1227.6, total_loss = -5.935, pg_loss = -41.852, baseline_loss = 41.678, entropy_loss = -5.7607, learner_queue_size = 32, _tick = 28514, _time = 1.6548e+09, train_seconds = 2.8848e+04)
[2022-06-10 04:08:53,150][root][INFO] - Step 110023680 @ 4094.2 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 110023680, mean_episode_return = None, mean_episode_step = 1136.7, total_loss = 56.332, pg_loss = 14.179, baseline_loss = 47.887, entropy_loss = -5.7345, learner_queue_size = 32, _tick = 28518, _time = 1.6548e+09, train_seconds = 2.8853e+04)
[2022-06-10 04:08:58,156][root][INFO] - Step 110041600 @ 3579.4 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 110041600, mean_episode_return = 59.172, mean_episode_step = 1255.7, total_loss = 116.37, pg_loss = 89.097, baseline_loss = 33.209, entropy_loss = -5.9379, learner_queue_size = 32, _tick = 28522, _time = 1.6548e+09, train_seconds = 2.8858e+04)
[2022-06-10 04:09:03,162][root][INFO] - Step 110062080 @ 4091.4 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 110062080, mean_episode_return = 85.74, mean_episode_step = 1470.0, total_loss = 138.52, pg_loss = 109.4, baseline_loss = 35.015, entropy_loss = -5.9, learner_queue_size = 32, _tick = 28529, _time = 1.6548e+09, train_seconds = 2.8863e+04)
[2022-06-10 04:09:08,166][root][INFO] - Step 110082560 @ 4092.7 SPS. Inference batcher size: 77. Learner queue size: 32. Other stats: (step = 110082560, mean_episode_return = None, mean_episode_step = 1498.0, total_loss = 62.45, pg_loss = 37.727, baseline_loss = 30.207, entropy_loss = -5.4844, learner_queue_size = 32, _tick = 28533, _time = 1.6548e+09, train_seconds = 2.8868e+04)
[2022-06-10 04:09:13,170][root][INFO] - Step 110100480 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 110100480, mean_episode_return = 47.845, mean_episode_step = 1337.2, total_loss = 108.84, pg_loss = 75.596, baseline_loss = 38.747, entropy_loss = -5.5016, learner_queue_size = 32, _tick = 28539, _time = 1.6548e+09, train_seconds = 2.8873e+04)
[2022-06-10 04:09:18,174][root][INFO] - Step 110120960 @ 4092.8 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 110120960, mean_episode_return = 35.641, mean_episode_step = 996.38, total_loss = 294.03, pg_loss = 228.24, baseline_loss = 71.146, entropy_loss = -5.3564, learner_queue_size = 32, _tick = 28546, _time = 1.6548e+09, train_seconds = 2.8878e+04)
[2022-06-10 04:09:23,178][root][INFO] - Step 110141440 @ 4092.7 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 110141440, mean_episode_return = None, mean_episode_step = 1414.7, total_loss = -204.41, pg_loss = -221.04, baseline_loss = 22.21, entropy_loss = -5.583, learner_queue_size = 32, _tick = 28552, _time = 1.6548e+09, train_seconds = 2.8883e+04)
[2022-06-10 04:09:28,182][root][INFO] - Step 110159360 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 110159360, mean_episode_return = 44.81, mean_episode_step = 1416.7, total_loss = 61.33, pg_loss = 0.43584, baseline_loss = 66.762, entropy_loss = -5.8679, learner_queue_size = 32, _tick = 28558, _time = 1.6548e+09, train_seconds = 2.8888e+04)
[2022-06-10 04:09:33,186][root][INFO] - Step 110179840 @ 4092.7 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 110179840, mean_episode_return = None, mean_episode_step = 1537.0, total_loss = 48.967, pg_loss = -0.76951, baseline_loss = 55.528, entropy_loss = -5.7915, learner_queue_size = 32, _tick = 28564, _time = 1.6548e+09, train_seconds = 2.8893e+04)
[2022-06-10 04:09:38,190][root][INFO] - Step 110197760 @ 3581.2 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 110197760, mean_episode_return = None, mean_episode_step = 1279.6, total_loss = -42.816, pg_loss = -58.795, baseline_loss = 21.686, entropy_loss = -5.7072, learner_queue_size = 32, _tick = 28567, _time = 1.6548e+09, train_seconds = 2.8898e+04)
[2022-06-10 04:09:43,194][root][INFO] - Step 110218240 @ 4092.6 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 110218240, mean_episode_return = 16.39, mean_episode_step = 1212.6, total_loss = 177.74, pg_loss = 110.54, baseline_loss = 72.669, entropy_loss = -5.4725, learner_queue_size = 32, _tick = 28573, _time = 1.6548e+09, train_seconds = 2.8903e+04)
[2022-06-10 04:09:48,198][root][INFO] - Step 110238720 @ 4092.8 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 110238720, mean_episode_return = None, mean_episode_step = 1106.2, total_loss = -17.983, pg_loss = -37.894, baseline_loss = 25.249, entropy_loss = -5.3371, learner_queue_size = 32, _tick = 28578, _time = 1.6548e+09, train_seconds = 2.8908e+04)
[2022-06-10 04:09:53,202][root][INFO] - Step 110256640 @ 3581.2 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 110256640, mean_episode_return = 74.32, mean_episode_step = 1257.5, total_loss = 533.5, pg_loss = 387.03, baseline_loss = 151.96, entropy_loss = -5.4896, learner_queue_size = 32, _tick = 28584, _time = 1.6548e+09, train_seconds = 2.8913e+04)
[2022-06-10 04:09:58,206][root][INFO] - Step 110277120 @ 4092.7 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 110277120, mean_episode_return = 83.161, mean_episode_step = 1294.8, total_loss = 243.49, pg_loss = 148.24, baseline_loss = 100.71, entropy_loss = -5.4646, learner_queue_size = 32, _tick = 28591, _time = 1.6548e+09, train_seconds = 2.8918e+04)
[2022-06-10 04:10:03,210][root][INFO] - Step 110297600 @ 4092.7 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 110297600, mean_episode_return = 19.93, mean_episode_step = 1160.5, total_loss = -276.09, pg_loss = -293.37, baseline_loss = 22.903, entropy_loss = -5.6231, learner_queue_size = 32, _tick = 28596, _time = 1.6548e+09, train_seconds = 2.8923e+04)
[2022-06-10 04:10:08,215][root][INFO] - Step 110315520 @ 3580.6 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 110315520, mean_episode_return = 98.009, mean_episode_step = 864.95, total_loss = 126.75, pg_loss = 58.324, baseline_loss = 73.939, entropy_loss = -5.5159, learner_queue_size = 32, _tick = 28603, _time = 1.6548e+09, train_seconds = 2.8928e+04)
[2022-06-10 04:10:13,218][root][INFO] - Step 110333440 @ 3581.7 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 110333440, mean_episode_return = 19.775, mean_episode_step = 863.33, total_loss = -36.885, pg_loss = -80.46, baseline_loss = 48.94, entropy_loss = -5.3651, learner_queue_size = 32, _tick = 28609, _time = 1.6548e+09, train_seconds = 2.8933e+04)
[2022-06-10 04:10:18,222][root][INFO] - Step 110353920 @ 4092.6 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 110353920, mean_episode_return = None, mean_episode_step = 1031.6, total_loss = 98.577, pg_loss = 29.108, baseline_loss = 74.903, entropy_loss = -5.4347, learner_queue_size = 32, _tick = 28615, _time = 1.6548e+09, train_seconds = 2.8938e+04)
[2022-06-10 04:10:23,227][root][INFO] - Step 110374400 @ 4092.3 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (step = 110374400, mean_episode_return = 65.383, mean_episode_step = 1068.9, total_loss = -36.308, pg_loss = -139.88, baseline_loss = 109.5, entropy_loss = -5.9292, learner_queue_size = 32, _tick = 28622, _time = 1.6548e+09, train_seconds = 2.8943e+04)
[2022-06-10 04:10:28,230][root][INFO] - Step 110394880 @ 4093.2 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 110394880, mean_episode_return = None, mean_episode_step = 1048.8, total_loss = 62.022, pg_loss = 27.051, baseline_loss = 40.621, entropy_loss = -5.6495, learner_queue_size = 32, _tick = 28627, _time = 1.6548e+09, train_seconds = 2.8948e+04)
[2022-06-10 04:10:33,236][root][INFO] - Step 110412800 @ 3579.6 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 110412800, mean_episode_return = 54.517, mean_episode_step = 1210.7, total_loss = 88.832, pg_loss = 50.636, baseline_loss = 43.697, entropy_loss = -5.5009, learner_queue_size = 32, _tick = 28631, _time = 1.6548e+09, train_seconds = 2.8953e+04)
[2022-06-10 04:10:38,242][root][INFO] - Step 110433280 @ 4091.2 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 110433280, mean_episode_return = 27.921, mean_episode_step = 1246.1, total_loss = 120.68, pg_loss = 98.233, baseline_loss = 28.081, entropy_loss = -5.6327, learner_queue_size = 32, _tick = 28638, _time = 1.6548e+09, train_seconds = 2.8958e+04)
[2022-06-10 04:10:43,246][root][INFO] - Step 110453760 @ 4092.8 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 110453760, mean_episode_return = None, mean_episode_step = 1037.7, total_loss = 236.44, pg_loss = 135.94, baseline_loss = 105.75, entropy_loss = -5.2476, learner_queue_size = 32, _tick = 28643, _time = 1.6548e+09, train_seconds = 2.8963e+04)
[2022-06-10 04:10:48,250][root][INFO] - Step 110471680 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 110471680, mean_episode_return = 28.284, mean_episode_step = 1246.8, total_loss = -0.18921, pg_loss = -87.829, baseline_loss = 92.947, entropy_loss = -5.3072, learner_queue_size = 32, _tick = 28649, _time = 1.6548e+09, train_seconds = 2.8968e+04)
[2022-06-10 04:10:53,254][root][INFO] - Step 110492160 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 110492160, mean_episode_return = 101.4, mean_episode_step = 1071.8, total_loss = -57.546, pg_loss = -77.63, baseline_loss = 25.65, entropy_loss = -5.5654, learner_queue_size = 32, _tick = 28653, _time = 1.6548e+09, train_seconds = 2.8973e+04)
[2022-06-10 04:10:58,258][root][INFO] - Step 110510080 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 110510080, mean_episode_return = 46.575, mean_episode_step = 1103.4, total_loss = -52.352, pg_loss = -70.862, baseline_loss = 24.14, entropy_loss = -5.631, learner_queue_size = 32, _tick = 28659, _time = 1.6548e+09, train_seconds = 2.8978e+04)
[2022-06-10 04:11:03,262][root][INFO] - Step 110530560 @ 4092.6 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 110530560, mean_episode_return = 64.39, mean_episode_step = 1051.0, total_loss = 113.47, pg_loss = 67.282, baseline_loss = 51.72, entropy_loss = -5.5275, learner_queue_size = 32, _tick = 28665, _time = 1.6548e+09, train_seconds = 2.8983e+04)
[2022-06-10 04:11:08,266][root][INFO] - Step 110551040 @ 4092.8 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 110551040, mean_episode_return = 36.61, mean_episode_step = 957.92, total_loss = -68.508, pg_loss = -86.924, baseline_loss = 23.871, entropy_loss = -5.4539, learner_queue_size = 32, _tick = 28671, _time = 1.6548e+09, train_seconds = 2.8988e+04)
[2022-06-10 04:11:13,270][root][INFO] - Step 110571520 @ 4092.8 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 110571520, mean_episode_return = 73.777, mean_episode_step = 1041.9, total_loss = -49.417, pg_loss = -108.21, baseline_loss = 64.186, entropy_loss = -5.3967, learner_queue_size = 32, _tick = 28677, _time = 1.6548e+09, train_seconds = 2.8993e+04)
[2022-06-10 04:11:18,274][root][INFO] - Step 110589440 @ 3581.1 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 110589440, mean_episode_return = 62.405, mean_episode_step = 997.84, total_loss = -8.8977, pg_loss = -34.516, baseline_loss = 31.004, entropy_loss = -5.3854, learner_queue_size = 32, _tick = 28684, _time = 1.6548e+09, train_seconds = 2.8998e+04)
[2022-06-10 04:11:23,278][root][INFO] - Step 110609920 @ 4092.7 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 110609920, mean_episode_return = 68.263, mean_episode_step = 1016.7, total_loss = 305.28, pg_loss = 239.75, baseline_loss = 70.942, entropy_loss = -5.4063, learner_queue_size = 32, _tick = 28689, _time = 1.6548e+09, train_seconds = 2.9003e+04)
[2022-06-10 04:11:28,282][root][INFO] - Step 110630400 @ 4092.7 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 110630400, mean_episode_return = 61.697, mean_episode_step = 1197.2, total_loss = -3.3985, pg_loss = -89.042, baseline_loss = 91.159, entropy_loss = -5.5157, learner_queue_size = 32, _tick = 28697, _time = 1.6548e+09, train_seconds = 2.9008e+04)
[2022-06-10 04:11:33,286][root][INFO] - Step 110650880 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 110650880, mean_episode_return = None, mean_episode_step = 755.47, total_loss = 201.37, pg_loss = 122.44, baseline_loss = 84.12, entropy_loss = -5.1866, learner_queue_size = 32, _tick = 28704, _time = 1.6548e+09, train_seconds = 2.9013e+04)
[2022-06-10 04:11:38,290][root][INFO] - Step 110668800 @ 3581.2 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 110668800, mean_episode_return = 85.021, mean_episode_step = 938.71, total_loss = -59.347, pg_loss = -125.46, baseline_loss = 71.486, entropy_loss = -5.378, learner_queue_size = 32, _tick = 28709, _time = 1.6548e+09, train_seconds = 2.9018e+04)
[2022-06-10 04:11:43,294][root][INFO] - Step 110689280 @ 4092.5 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 110689280, mean_episode_return = 51.313, mean_episode_step = 1082.6, total_loss = 243.78, pg_loss = 151.71, baseline_loss = 97.623, entropy_loss = -5.5487, learner_queue_size = 32, _tick = 28716, _time = 1.6548e+09, train_seconds = 2.9023e+04)
[2022-06-10 04:11:48,298][root][INFO] - Step 110709760 @ 4093.0 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (step = 110709760, mean_episode_return = 51.225, mean_episode_step = 1029.6, total_loss = 42.528, pg_loss = -0.068914, baseline_loss = 48.238, entropy_loss = -5.6403, learner_queue_size = 32, _tick = 28724, _time = 1.6548e+09, train_seconds = 2.9028e+04)
[2022-06-10 04:11:53,302][root][INFO] - Step 110730240 @ 4092.6 SPS. Inference batcher size: 80. Learner queue size: 32. Other stats: (step = 110730240, mean_episode_return = 31.735, mean_episode_step = 944.57, total_loss = 8.0717, pg_loss = -34.041, baseline_loss = 47.831, entropy_loss = -5.7187, learner_queue_size = 32, _tick = 28731, _time = 1.6548e+09, train_seconds = 2.9033e+04)
[2022-06-10 04:11:58,306][root][INFO] - Step 110748160 @ 3581.2 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 110748160, mean_episode_return = 71.87, mean_episode_step = 856.76, total_loss = 152.94, pg_loss = 87.228, baseline_loss = 71.309, entropy_loss = -5.5995, learner_queue_size = 32, _tick = 28738, _time = 1.6548e+09, train_seconds = 2.9038e+04)
[2022-06-10 04:12:03,310][root][INFO] - Step 110768640 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 110768640, mean_episode_return = 15.04, mean_episode_step = 1077.3, total_loss = 87.406, pg_loss = 52.213, baseline_loss = 40.657, entropy_loss = -5.4648, learner_queue_size = 32, _tick = 28745, _time = 1.6548e+09, train_seconds = 2.9043e+04)
[2022-06-10 04:12:08,314][root][INFO] - Step 110786560 @ 3581.2 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 110786560, mean_episode_return = 41.48, mean_episode_step = 1040.4, total_loss = 310.26, pg_loss = 200.49, baseline_loss = 115.22, entropy_loss = -5.4528, learner_queue_size = 32, _tick = 28752, _time = 1.6548e+09, train_seconds = 2.9048e+04)
[2022-06-10 04:12:13,318][root][INFO] - Step 110807040 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 110807040, mean_episode_return = 12.439, mean_episode_step = 758.17, total_loss = 424.76, pg_loss = 299.58, baseline_loss = 130.51, entropy_loss = -5.3313, learner_queue_size = 32, _tick = 28757, _time = 1.6548e+09, train_seconds = 2.9053e+04)
[2022-06-10 04:12:18,322][root][INFO] - Step 110824960 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 110824960, mean_episode_return = None, mean_episode_step = 1006.7, total_loss = -27.99, pg_loss = -65.504, baseline_loss = 42.974, entropy_loss = -5.4601, learner_queue_size = 32, _tick = 28761, _time = 1.6548e+09, train_seconds = 2.9058e+04)
[2022-06-10 04:12:23,326][root][INFO] - Step 110845440 @ 4092.8 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 110845440, mean_episode_return = 57.646, mean_episode_step = 896.06, total_loss = 82.866, pg_loss = 30.329, baseline_loss = 58.153, entropy_loss = -5.6151, learner_queue_size = 32, _tick = 28769, _time = 1.6548e+09, train_seconds = 2.9063e+04)
[2022-06-10 04:12:28,330][root][INFO] - Step 110863360 @ 3581.1 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 110863360, mean_episode_return = 38.35, mean_episode_step = 901.06, total_loss = 300.45, pg_loss = 218.17, baseline_loss = 88.004, entropy_loss = -5.721, learner_queue_size = 32, _tick = 28776, _time = 1.6548e+09, train_seconds = 2.9068e+04)
[2022-06-10 04:12:33,334][root][INFO] - Step 110883840 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 110883840, mean_episode_return = 89.99, mean_episode_step = 1258.5, total_loss = 225.19, pg_loss = 161.98, baseline_loss = 68.915, entropy_loss = -5.7086, learner_queue_size = 32, _tick = 28782, _time = 1.6548e+09, train_seconds = 2.9073e+04)
[2022-06-10 04:12:38,338][root][INFO] - Step 110904320 @ 4092.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 110904320, mean_episode_return = 83.296, mean_episode_step = 861.66, total_loss = 114.43, pg_loss = 64.506, baseline_loss = 55.499, entropy_loss = -5.5759, learner_queue_size = 32, _tick = 28790, _time = 1.6548e+09, train_seconds = 2.9078e+04)
[2022-06-10 04:12:43,342][root][INFO] - Step 110924800 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 110924800, mean_episode_return = None, mean_episode_step = 880.34, total_loss = 7.2817, pg_loss = -13.174, baseline_loss = 25.842, entropy_loss = -5.3865, learner_queue_size = 32, _tick = 28794, _time = 1.6548e+09, train_seconds = 2.9083e+04)
[2022-06-10 04:12:48,346][root][INFO] - Step 110942720 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 110942720, mean_episode_return = 21.765, mean_episode_step = 788.08, total_loss = 260.62, pg_loss = 201.86, baseline_loss = 64.074, entropy_loss = -5.3168, learner_queue_size = 32, _tick = 28799, _time = 1.6548e+09, train_seconds = 2.9088e+04)
[2022-06-10 04:12:53,350][root][INFO] - Step 110963200 @ 4092.7 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 110963200, mean_episode_return = None, mean_episode_step = 1230.4, total_loss = -116.82, pg_loss = -131.49, baseline_loss = 20.059, entropy_loss = -5.3842, learner_queue_size = 32, _tick = 28805, _time = 1.6548e+09, train_seconds = 2.9093e+04)
[2022-06-10 04:12:58,354][root][INFO] - Step 110983680 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 110983680, mean_episode_return = 40.186, mean_episode_step = 988.29, total_loss = 47.147, pg_loss = -0.46489, baseline_loss = 52.978, entropy_loss = -5.3665, learner_queue_size = 32, _tick = 28811, _time = 1.6548e+09, train_seconds = 2.9098e+04)
[2022-06-10 04:13:03,358][root][INFO] - Step 111001600 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 111001600, mean_episode_return = 57.08, mean_episode_step = 1107.2, total_loss = 259.69, pg_loss = 133.89, baseline_loss = 131.13, entropy_loss = -5.3386, learner_queue_size = 32, _tick = 28814, _time = 1.6548e+09, train_seconds = 2.9103e+04)
[2022-06-10 04:13:08,362][root][INFO] - Step 111022080 @ 4092.6 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 111022080, mean_episode_return = 88.26, mean_episode_step = 1032.7, total_loss = -72.33, pg_loss = -101.01, baseline_loss = 33.951, entropy_loss = -5.271, learner_queue_size = 32, _tick = 28820, _time = 1.6548e+09, train_seconds = 2.9108e+04)
[2022-06-10 04:13:13,366][root][INFO] - Step 111040000 @ 3581.3 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 111040000, mean_episode_return = 32.531, mean_episode_step = 987.15, total_loss = -174.01, pg_loss = -201.28, baseline_loss = 32.634, entropy_loss = -5.3621, learner_queue_size = 32, _tick = 28825, _time = 1.6548e+09, train_seconds = 2.9113e+04)
[2022-06-10 04:13:18,370][root][INFO] - Step 111060480 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 111060480, mean_episode_return = 23.14, mean_episode_step = 1249.9, total_loss = 365.94, pg_loss = 242.67, baseline_loss = 128.62, entropy_loss = -5.3432, learner_queue_size = 32, _tick = 28833, _time = 1.6548e+09, train_seconds = 2.9118e+04)
[2022-06-10 04:13:23,376][root][INFO] - Step 111078400 @ 3579.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 111078400, mean_episode_return = 33.92, mean_episode_step = 1083.2, total_loss = 0.65576, pg_loss = -32.236, baseline_loss = 38.338, entropy_loss = -5.4465, learner_queue_size = 32, _tick = 28839, _time = 1.6548e+09, train_seconds = 2.9123e+04)
[2022-06-10 04:13:28,382][root][INFO] - Step 111098880 @ 4091.2 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (step = 111098880, mean_episode_return = None, mean_episode_step = 1134.1, total_loss = 242.79, pg_loss = 149.28, baseline_loss = 98.951, entropy_loss = -5.4411, learner_queue_size = 32, _tick = 28844, _time = 1.6548e+09, train_seconds = 2.9128e+04)
[2022-06-10 04:13:33,386][root][INFO] - Step 111119360 @ 4092.7 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 111119360, mean_episode_return = 38.755, mean_episode_step = 930.4, total_loss = -98.944, pg_loss = -125.91, baseline_loss = 32.48, entropy_loss = -5.5182, learner_queue_size = 32, _tick = 28851, _time = 1.6548e+09, train_seconds = 2.9133e+04)
[2022-06-10 04:13:38,390][root][INFO] - Step 111137280 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 111137280, mean_episode_return = None, mean_episode_step = 1114.8, total_loss = 4.2317, pg_loss = -27.554, baseline_loss = 36.988, entropy_loss = -5.2021, learner_queue_size = 32, _tick = 28856, _time = 1.6548e+09, train_seconds = 2.9138e+04)
[2022-06-10 04:13:43,394][root][INFO] - Step 111157760 @ 4092.6 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 111157760, mean_episode_return = None, mean_episode_step = 1025.4, total_loss = -37.194, pg_loss = -65.797, baseline_loss = 34.112, entropy_loss = -5.5089, learner_queue_size = 32, _tick = 28863, _time = 1.6548e+09, train_seconds = 2.9143e+04)
[2022-06-10 04:13:48,398][root][INFO] - Step 111175680 @ 3581.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 111175680, mean_episode_return = 8.8098, mean_episode_step = 874.95, total_loss = 140.71, pg_loss = 94.914, baseline_loss = 51.275, entropy_loss = -5.483, learner_queue_size = 32, _tick = 28870, _time = 1.6548e+09, train_seconds = 2.9148e+04)
[2022-06-10 04:13:53,402][root][INFO] - Step 111196160 @ 4092.6 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 111196160, mean_episode_return = 29.55, mean_episode_step = 1059.7, total_loss = 268.85, pg_loss = 200.77, baseline_loss = 73.808, entropy_loss = -5.7289, learner_queue_size = 32, _tick = 28876, _time = 1.6548e+09, train_seconds = 2.9153e+04)
[2022-06-10 04:13:58,406][root][INFO] - Step 111214080 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 111214080, mean_episode_return = 42.01, mean_episode_step = 873.28, total_loss = 77.78, pg_loss = 43.095, baseline_loss = 40.265, entropy_loss = -5.5808, learner_queue_size = 32, _tick = 28882, _time = 1.6548e+09, train_seconds = 2.9158e+04)
[2022-06-10 04:14:03,410][root][INFO] - Step 111234560 @ 4092.8 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 111234560, mean_episode_return = 56.885, mean_episode_step = 1315.1, total_loss = -122.38, pg_loss = -150.82, baseline_loss = 33.935, entropy_loss = -5.4953, learner_queue_size = 32, _tick = 28887, _time = 1.6548e+09, train_seconds = 2.9163e+04)
[2022-06-10 04:14:08,414][root][INFO] - Step 111255040 @ 4092.8 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 111255040, mean_episode_return = 45.66, mean_episode_step = 972.17, total_loss = 178.38, pg_loss = 102.68, baseline_loss = 81.025, entropy_loss = -5.3224, learner_queue_size = 32, _tick = 28893, _time = 1.6548e+09, train_seconds = 2.9168e+04)
[2022-06-10 04:14:13,418][root][INFO] - Step 111272960 @ 3581.2 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (step = 111272960, mean_episode_return = 69.03, mean_episode_step = 949.34, total_loss = 105.68, pg_loss = 62.037, baseline_loss = 49.306, entropy_loss = -5.6607, learner_queue_size = 32, _tick = 28896, _time = 1.6548e+09, train_seconds = 2.9173e+04)
[2022-06-10 04:14:18,424][root][INFO] - Step 111293440 @ 4091.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 111293440, mean_episode_return = None, mean_episode_step = 1243.8, total_loss = -111.89, pg_loss = -140.38, baseline_loss = 34.098, entropy_loss = -5.6031, learner_queue_size = 32, _tick = 28901, _time = 1.6548e+09, train_seconds = 2.9178e+04)
[2022-06-10 04:14:23,426][root][INFO] - Step 111313920 @ 4094.3 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 111313920, mean_episode_return = 27.595, mean_episode_step = 1206.5, total_loss = -224.07, pg_loss = -235.61, baseline_loss = 17.197, entropy_loss = -5.6502, learner_queue_size = 32, _tick = 28909, _time = 1.6548e+09, train_seconds = 2.9183e+04)
[2022-06-10 04:14:28,430][root][INFO] - Step 111331840 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 111331840, mean_episode_return = 62.609, mean_episode_step = 870.75, total_loss = -18.183, pg_loss = -45.737, baseline_loss = 33.283, entropy_loss = -5.7283, learner_queue_size = 32, _tick = 28915, _time = 1.6548e+09, train_seconds = 2.9188e+04)
[2022-06-10 04:14:33,434][root][INFO] - Step 111352320 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 111352320, mean_episode_return = 79.847, mean_episode_step = 817.54, total_loss = 109.58, pg_loss = 24.245, baseline_loss = 90.802, entropy_loss = -5.4698, learner_queue_size = 32, _tick = 28922, _time = 1.6548e+09, train_seconds = 2.9193e+04)
[2022-06-10 04:14:38,438][root][INFO] - Step 111370240 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 111370240, mean_episode_return = 65.885, mean_episode_step = 1155.4, total_loss = 426.19, pg_loss = 328.71, baseline_loss = 103.15, entropy_loss = -5.6741, learner_queue_size = 32, _tick = 28928, _time = 1.6548e+09, train_seconds = 2.9198e+04)
[2022-06-10 04:14:43,443][root][INFO] - Step 111390720 @ 4092.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 111390720, mean_episode_return = 146.77, mean_episode_step = 1155.2, total_loss = -43.571, pg_loss = -61.046, baseline_loss = 22.975, entropy_loss = -5.5008, learner_queue_size = 32, _tick = 28936, _time = 1.6548e+09, train_seconds = 2.9203e+04)
[2022-06-10 04:14:48,449][root][INFO] - Step 111408640 @ 3579.2 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 111408640, mean_episode_return = 33.511, mean_episode_step = 1022.9, total_loss = 33.296, pg_loss = -6.3362, baseline_loss = 45.208, entropy_loss = -5.5755, learner_queue_size = 32, _tick = 28941, _time = 1.6548e+09, train_seconds = 2.9208e+04)
[2022-06-10 04:14:53,456][root][INFO] - Step 111429120 @ 4090.7 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 111429120, mean_episode_return = 57.731, mean_episode_step = 1076.5, total_loss = 139.41, pg_loss = 83.22, baseline_loss = 61.755, entropy_loss = -5.5652, learner_queue_size = 32, _tick = 28946, _time = 1.6548e+09, train_seconds = 2.9213e+04)
[2022-06-10 04:14:58,462][root][INFO] - Step 111449600 @ 4090.8 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 111449600, mean_episode_return = 32.76, mean_episode_step = 1282.0, total_loss = 101.81, pg_loss = 49.182, baseline_loss = 58.104, entropy_loss = -5.4729, learner_queue_size = 32, _tick = 28952, _time = 1.6548e+09, train_seconds = 2.9218e+04)
[2022-06-10 04:15:03,467][root][INFO] - Step 111467520 @ 3581.2 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 111467520, mean_episode_return = None, mean_episode_step = 962.19, total_loss = -138.1, pg_loss = -147.08, baseline_loss = 14.114, entropy_loss = -5.1359, learner_queue_size = 32, _tick = 28957, _time = 1.6548e+09, train_seconds = 2.9223e+04)
[2022-06-10 04:15:08,470][root][INFO] - Step 111488000 @ 4092.8 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 111488000, mean_episode_return = None, mean_episode_step = 763.31, total_loss = -33.233, pg_loss = -79.807, baseline_loss = 52.165, entropy_loss = -5.5908, learner_queue_size = 32, _tick = 28962, _time = 1.6548e+09, train_seconds = 2.9228e+04)
[2022-06-10 04:15:13,474][root][INFO] - Step 111508480 @ 4092.8 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 111508480, mean_episode_return = 65.93, mean_episode_step = 1056.3, total_loss = 62.432, pg_loss = 21.236, baseline_loss = 46.8, entropy_loss = -5.6036, learner_queue_size = 32, _tick = 28969, _time = 1.6548e+09, train_seconds = 2.9233e+04)
[2022-06-10 04:15:18,478][root][INFO] - Step 111526400 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 111526400, mean_episode_return = 24.32, mean_episode_step = 986.2, total_loss = 90.023, pg_loss = 54.355, baseline_loss = 41.281, entropy_loss = -5.613, learner_queue_size = 32, _tick = 28975, _time = 1.6548e+09, train_seconds = 2.9238e+04)
[2022-06-10 04:15:23,481][root][INFO] - Step 111546880 @ 4093.6 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 111546880, mean_episode_return = 43.87, mean_episode_step = 1083.7, total_loss = 6.8443, pg_loss = -27.342, baseline_loss = 39.593, entropy_loss = -5.4075, learner_queue_size = 32, _tick = 28983, _time = 1.6548e+09, train_seconds = 2.9243e+04)
[2022-06-10 04:15:28,486][root][INFO] - Step 111567360 @ 4091.9 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (step = 111567360, mean_episode_return = 53.45, mean_episode_step = 840.77, total_loss = 42.444, pg_loss = -2.8902, baseline_loss = 50.602, entropy_loss = -5.2684, learner_queue_size = 32, _tick = 28990, _time = 1.6548e+09, train_seconds = 2.9248e+04)
[2022-06-10 04:15:33,490][root][INFO] - Step 111585280 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 111585280, mean_episode_return = 58.821, mean_episode_step = 1355.6, total_loss = 297.72, pg_loss = 231.62, baseline_loss = 71.538, entropy_loss = -5.4413, learner_queue_size = 32, _tick = 28994, _time = 1.6548e+09, train_seconds = 2.9253e+04)
[2022-06-10 04:15:38,494][root][INFO] - Step 111605760 @ 4092.8 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 111605760, mean_episode_return = 90.949, mean_episode_step = 995.09, total_loss = -36.91, pg_loss = -70.21, baseline_loss = 38.612, entropy_loss = -5.3123, learner_queue_size = 32, _tick = 29000, _time = 1.6548e+09, train_seconds = 2.9258e+04)
[2022-06-10 04:15:43,498][root][INFO] - Step 111626240 @ 4092.7 SPS. Inference batcher size: 87. Learner queue size: 32. Other stats: (step = 111626240, mean_episode_return = -10.9, mean_episode_step = 1062.1, total_loss = -6.0686, pg_loss = -55.585, baseline_loss = 54.877, entropy_loss = -5.3601, learner_queue_size = 32, _tick = 29007, _time = 1.6548e+09, train_seconds = 2.9263e+04)
[2022-06-10 04:15:48,502][root][INFO] - Step 111646720 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 111646720, mean_episode_return = 64.73, mean_episode_step = 976.27, total_loss = -42.135, pg_loss = -59.145, baseline_loss = 22.638, entropy_loss = -5.6273, learner_queue_size = 32, _tick = 29015, _time = 1.6548e+09, train_seconds = 2.9268e+04)
[2022-06-10 04:15:53,506][root][INFO] - Step 111664640 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 111664640, mean_episode_return = 60.318, mean_episode_step = 862.17, total_loss = -40.717, pg_loss = -69.274, baseline_loss = 34.035, entropy_loss = -5.4784, learner_queue_size = 32, _tick = 29022, _time = 1.6548e+09, train_seconds = 2.9273e+04)
[2022-06-10 04:15:58,510][root][INFO] - Step 111685120 @ 4092.8 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 111685120, mean_episode_return = None, mean_episode_step = 912.56, total_loss = 230.14, pg_loss = 187.82, baseline_loss = 47.746, entropy_loss = -5.4235, learner_queue_size = 32, _tick = 29028, _time = 1.6548e+09, train_seconds = 2.9278e+04)
[2022-06-10 04:16:03,514][root][INFO] - Step 111705600 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 111705600, mean_episode_return = 54.735, mean_episode_step = 1205.4, total_loss = -95.652, pg_loss = -120.36, baseline_loss = 30.201, entropy_loss = -5.4921, learner_queue_size = 32, _tick = 29036, _time = 1.6548e+09, train_seconds = 2.9283e+04)
[2022-06-10 04:16:08,518][root][INFO] - Step 111723520 @ 3581.2 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 111723520, mean_episode_return = 57.103, mean_episode_step = 1123.1, total_loss = 410.41, pg_loss = 318.09, baseline_loss = 97.808, entropy_loss = -5.4906, learner_queue_size = 32, _tick = 29043, _time = 1.6548e+09, train_seconds = 2.9288e+04)
[2022-06-10 04:16:13,522][root][INFO] - Step 111744000 @ 4092.8 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 111744000, mean_episode_return = 87.62, mean_episode_step = 1063.3, total_loss = -210.91, pg_loss = -221.63, baseline_loss = 16.374, entropy_loss = -5.6551, learner_queue_size = 32, _tick = 29049, _time = 1.6548e+09, train_seconds = 2.9293e+04)
[2022-06-10 04:16:18,526][root][INFO] - Step 111761920 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 111761920, mean_episode_return = None, mean_episode_step = 960.94, total_loss = -63.462, pg_loss = -132.4, baseline_loss = 74.434, entropy_loss = -5.4926, learner_queue_size = 32, _tick = 29053, _time = 1.6548e+09, train_seconds = 2.9298e+04)
[2022-06-10 04:16:23,530][root][INFO] - Step 111782400 @ 4092.7 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 111782400, mean_episode_return = 67.861, mean_episode_step = 689.45, total_loss = 411.78, pg_loss = 272.02, baseline_loss = 145.15, entropy_loss = -5.3808, learner_queue_size = 32, _tick = 29057, _time = 1.6548e+09, train_seconds = 2.9303e+04)
[2022-06-10 04:16:28,534][root][INFO] - Step 111800320 @ 3581.2 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (step = 111800320, mean_episode_return = 125.45, mean_episode_step = 893.7, total_loss = -183.09, pg_loss = -212.72, baseline_loss = 35.062, entropy_loss = -5.434, learner_queue_size = 32, _tick = 29062, _time = 1.6548e+09, train_seconds = 2.9308e+04)
[2022-06-10 04:16:33,538][root][INFO] - Step 111820800 @ 4092.7 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 111820800, mean_episode_return = 36.805, mean_episode_step = 807.21, total_loss = 123.63, pg_loss = 67.569, baseline_loss = 61.513, entropy_loss = -5.4485, learner_queue_size = 32, _tick = 29069, _time = 1.6548e+09, train_seconds = 2.9313e+04)
[2022-06-10 04:16:38,543][root][INFO] - Step 111841280 @ 4092.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 111841280, mean_episode_return = 68.256, mean_episode_step = 888.88, total_loss = 1.654, pg_loss = -38.529, baseline_loss = 45.757, entropy_loss = -5.5733, learner_queue_size = 32, _tick = 29075, _time = 1.6548e+09, train_seconds = 2.9318e+04)
[2022-06-10 04:16:43,546][root][INFO] - Step 111861760 @ 4093.3 SPS. Inference batcher size: 73. Learner queue size: 32. Other stats: (step = 111861760, mean_episode_return = None, mean_episode_step = 839.78, total_loss = 389.12, pg_loss = 286.46, baseline_loss = 108.07, entropy_loss = -5.4081, learner_queue_size = 32, _tick = 29080, _time = 1.6548e+09, train_seconds = 2.9323e+04)
[2022-06-10 04:16:48,550][root][INFO] - Step 111879680 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 111879680, mean_episode_return = 25.42, mean_episode_step = 846.48, total_loss = -113.88, pg_loss = -133.9, baseline_loss = 25.487, entropy_loss = -5.4649, learner_queue_size = 32, _tick = 29085, _time = 1.6548e+09, train_seconds = 2.9328e+04)
[2022-06-10 04:16:53,554][root][INFO] - Step 111900160 @ 4092.6 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 111900160, mean_episode_return = 90.641, mean_episode_step = 969.42, total_loss = -45.198, pg_loss = -70.28, baseline_loss = 30.512, entropy_loss = -5.4296, learner_queue_size = 32, _tick = 29090, _time = 1.6548e+09, train_seconds = 2.9333e+04)
[2022-06-10 04:16:58,558][root][INFO] - Step 111920640 @ 4092.8 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 111920640, mean_episode_return = 22.647, mean_episode_step = 1111.0, total_loss = 63.388, pg_loss = 22.519, baseline_loss = 46.513, entropy_loss = -5.6441, learner_queue_size = 32, _tick = 29094, _time = 1.6548e+09, train_seconds = 2.9338e+04)
[2022-06-10 04:17:03,562][root][INFO] - Step 111938560 @ 3581.2 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 111938560, mean_episode_return = 23.29, mean_episode_step = 1024.3, total_loss = -37.427, pg_loss = -63.727, baseline_loss = 31.944, entropy_loss = -5.6437, learner_queue_size = 32, _tick = 29100, _time = 1.6548e+09, train_seconds = 2.9343e+04)
[2022-06-10 04:17:08,566][root][INFO] - Step 111959040 @ 4092.7 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 111959040, mean_episode_return = None, mean_episode_step = 875.91, total_loss = 220.96, pg_loss = 147.12, baseline_loss = 79.388, entropy_loss = -5.5471, learner_queue_size = 32, _tick = 29106, _time = 1.6548e+09, train_seconds = 2.9348e+04)
[2022-06-10 04:17:13,570][root][INFO] - Step 111979520 @ 4092.7 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 111979520, mean_episode_return = 79.911, mean_episode_step = 1135.5, total_loss = 39.616, pg_loss = -3.2362, baseline_loss = 48.437, entropy_loss = -5.5846, learner_queue_size = 32, _tick = 29113, _time = 1.6548e+09, train_seconds = 2.9353e+04)
[2022-06-10 04:17:18,574][root][INFO] - Step 111997440 @ 3581.0 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 111997440, mean_episode_return = 37.366, mean_episode_step = 1099.3, total_loss = -86.874, pg_loss = -109.91, baseline_loss = 28.502, entropy_loss = -5.4684, learner_queue_size = 32, _tick = 29119, _time = 1.6548e+09, train_seconds = 2.9358e+04)
[2022-06-10 04:17:23,578][root][INFO] - Step 112017920 @ 4092.8 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 112017920, mean_episode_return = None, mean_episode_step = 912.69, total_loss = -85.115, pg_loss = -93.169, baseline_loss = 13.588, entropy_loss = -5.5335, learner_queue_size = 32, _tick = 29125, _time = 1.6548e+09, train_seconds = 2.9363e+04)
[2022-06-10 04:17:28,582][root][INFO] - Step 112038400 @ 4092.8 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (step = 112038400, mean_episode_return = 61.834, mean_episode_step = 848.13, total_loss = 182.66, pg_loss = 76.325, baseline_loss = 111.78, entropy_loss = -5.4443, learner_queue_size = 32, _tick = 29132, _time = 1.6548e+09, train_seconds = 2.9368e+04)
[2022-06-10 04:17:33,586][root][INFO] - Step 112056320 @ 3581.2 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 112056320, mean_episode_return = None, mean_episode_step = 963.94, total_loss = 62.312, pg_loss = 15.415, baseline_loss = 52.398, entropy_loss = -5.5009, learner_queue_size = 32, _tick = 29137, _time = 1.6548e+09, train_seconds = 2.9373e+04)
[2022-06-10 04:17:38,590][root][INFO] - Step 112076800 @ 4092.6 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 112076800, mean_episode_return = 47.86, mean_episode_step = 1013.0, total_loss = 73.17, pg_loss = -2.5067, baseline_loss = 81.199, entropy_loss = -5.5227, learner_queue_size = 32, _tick = 29145, _time = 1.6548e+09, train_seconds = 2.9378e+04)
[2022-06-10 04:17:43,594][root][INFO] - Step 112097280 @ 4092.8 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 112097280, mean_episode_return = 47.651, mean_episode_step = 760.63, total_loss = 271.18, pg_loss = 204.18, baseline_loss = 72.171, entropy_loss = -5.1772, learner_queue_size = 32, _tick = 29151, _time = 1.6548e+09, train_seconds = 2.9383e+04)
[2022-06-10 04:17:48,598][root][INFO] - Step 112115200 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 112115200, mean_episode_return = 28.36, mean_episode_step = 1039.8, total_loss = -93.649, pg_loss = -124.57, baseline_loss = 36.222, entropy_loss = -5.3047, learner_queue_size = 32, _tick = 29156, _time = 1.6548e+09, train_seconds = 2.9388e+04)
[2022-06-10 04:17:53,602][root][INFO] - Step 112135680 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 112135680, mean_episode_return = 56.459, mean_episode_step = 852.92, total_loss = -92.67, pg_loss = -195.84, baseline_loss = 108.58, entropy_loss = -5.4098, learner_queue_size = 32, _tick = 29162, _time = 1.6548e+09, train_seconds = 2.9393e+04)
[2022-06-10 04:17:58,608][root][INFO] - Step 112156160 @ 4091.2 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 112156160, mean_episode_return = 114.32, mean_episode_step = 1033.4, total_loss = 65.376, pg_loss = 42.152, baseline_loss = 29.056, entropy_loss = -5.8315, learner_queue_size = 32, _tick = 29168, _time = 1.6548e+09, train_seconds = 2.9398e+04)
[2022-06-10 04:18:03,614][root][INFO] - Step 112176640 @ 4091.0 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 112176640, mean_episode_return = None, mean_episode_step = 1226.0, total_loss = -61.858, pg_loss = -65.309, baseline_loss = 9.0827, entropy_loss = -5.6313, learner_queue_size = 32, _tick = 29174, _time = 1.6548e+09, train_seconds = 2.9403e+04)
[2022-06-10 04:18:08,618][root][INFO] - Step 112194560 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 112194560, mean_episode_return = 81.92, mean_episode_step = 1096.5, total_loss = 88.52, pg_loss = 53.98, baseline_loss = 39.898, entropy_loss = -5.358, learner_queue_size = 32, _tick = 29181, _time = 1.6548e+09, train_seconds = 2.9408e+04)
[2022-06-10 04:18:13,622][root][INFO] - Step 112212480 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 112212480, mean_episode_return = 20.097, mean_episode_step = 1116.9, total_loss = 49.065, pg_loss = 2.8601, baseline_loss = 51.619, entropy_loss = -5.415, learner_queue_size = 32, _tick = 29187, _time = 1.6548e+09, train_seconds = 2.9413e+04)
[2022-06-10 04:18:18,626][root][INFO] - Step 112232960 @ 4092.7 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 112232960, mean_episode_return = None, mean_episode_step = 1046.4, total_loss = -90.694, pg_loss = -113.65, baseline_loss = 28.376, entropy_loss = -5.4167, learner_queue_size = 32, _tick = 29193, _time = 1.6548e+09, train_seconds = 2.9418e+04)
[2022-06-10 04:18:23,630][root][INFO] - Step 112253440 @ 4092.5 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 112253440, mean_episode_return = 88.819, mean_episode_step = 1180.7, total_loss = 67.895, pg_loss = 26.055, baseline_loss = 47.275, entropy_loss = -5.4342, learner_queue_size = 32, _tick = 29197, _time = 1.6548e+09, train_seconds = 2.9423e+04)
[2022-06-10 04:18:28,634][root][INFO] - Step 112271360 @ 3581.4 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 112271360, mean_episode_return = 29.186, mean_episode_step = 1301.9, total_loss = 300.33, pg_loss = 246.13, baseline_loss = 59.8, entropy_loss = -5.605, learner_queue_size = 32, _tick = 29203, _time = 1.6548e+09, train_seconds = 2.9428e+04)
[2022-06-10 04:18:33,638][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 04:18:33,774][root][INFO] - Step 112291840 @ 4092.6 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 112291840, mean_episode_return = 52.335, mean_episode_step = 973.94, total_loss = -172.92, pg_loss = -195.95, baseline_loss = 28.504, entropy_loss = -5.4687, learner_queue_size = 32, _tick = 29209, _time = 1.6548e+09, train_seconds = 2.9433e+04)
[2022-06-10 04:18:38,778][root][INFO] - Step 112312320 @ 3984.5 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 112312320, mean_episode_return = 55.496, mean_episode_step = 992.11, total_loss = -33.886, pg_loss = -60.422, baseline_loss = 32.02, entropy_loss = -5.4844, learner_queue_size = 32, _tick = 29214, _time = 1.6548e+09, train_seconds = 2.9439e+04)
[2022-06-10 04:18:43,782][root][INFO] - Step 112332800 @ 4092.6 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 112332800, mean_episode_return = None, mean_episode_step = 1210.6, total_loss = -39.288, pg_loss = -56.678, baseline_loss = 22.838, entropy_loss = -5.4471, learner_queue_size = 32, _tick = 29220, _time = 1.6548e+09, train_seconds = 2.9444e+04)
[2022-06-10 04:18:48,788][root][INFO] - Step 112350720 @ 3580.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 112350720, mean_episode_return = 90.095, mean_episode_step = 1013.2, total_loss = -52.456, pg_loss = -78.178, baseline_loss = 31.023, entropy_loss = -5.3015, learner_queue_size = 32, _tick = 29226, _time = 1.6548e+09, train_seconds = 2.9449e+04)
[2022-06-10 04:18:53,793][root][INFO] - Step 112371200 @ 4091.3 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 112371200, mean_episode_return = 38.338, mean_episode_step = 1103.9, total_loss = -114.14, pg_loss = -138.45, baseline_loss = 29.773, entropy_loss = -5.4618, learner_queue_size = 32, _tick = 29232, _time = 1.6548e+09, train_seconds = 2.9454e+04)
[2022-06-10 04:18:58,800][root][INFO] - Step 112389120 @ 3579.4 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 112389120, mean_episode_return = -9.8002, mean_episode_step = 1141.6, total_loss = 176.6, pg_loss = 134.27, baseline_loss = 47.723, entropy_loss = -5.3979, learner_queue_size = 32, _tick = 29237, _time = 1.6548e+09, train_seconds = 2.9459e+04)
[2022-06-10 04:19:03,802][root][INFO] - Step 112409600 @ 4094.0 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 112409600, mean_episode_return = 89.072, mean_episode_step = 834.42, total_loss = 51.135, pg_loss = 20.595, baseline_loss = 35.781, entropy_loss = -5.2409, learner_queue_size = 32, _tick = 29244, _time = 1.6548e+09, train_seconds = 2.9464e+04)
[2022-06-10 04:19:08,806][root][INFO] - Step 112430080 @ 4092.4 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 112430080, mean_episode_return = None, mean_episode_step = 934.34, total_loss = 74.699, pg_loss = 42.322, baseline_loss = 37.739, entropy_loss = -5.3628, learner_queue_size = 32, _tick = 29250, _time = 1.6548e+09, train_seconds = 2.9469e+04)
[2022-06-10 04:19:13,810][root][INFO] - Step 112448000 @ 3581.3 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 112448000, mean_episode_return = 13.665, mean_episode_step = 913.32, total_loss = 269.64, pg_loss = 201.18, baseline_loss = 73.886, entropy_loss = -5.4232, learner_queue_size = 32, _tick = 29257, _time = 1.6548e+09, train_seconds = 2.9474e+04)
[2022-06-10 04:19:18,814][root][INFO] - Step 112468480 @ 4092.9 SPS. Inference batcher size: 90. Learner queue size: 32. Other stats: (step = 112468480, mean_episode_return = 38.53, mean_episode_step = 985.57, total_loss = 247.55, pg_loss = 161.14, baseline_loss = 91.792, entropy_loss = -5.3801, learner_queue_size = 32, _tick = 29264, _time = 1.6548e+09, train_seconds = 2.9479e+04)
[2022-06-10 04:19:23,822][root][INFO] - Step 112488960 @ 4089.4 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 112488960, mean_episode_return = 92.769, mean_episode_step = 893.31, total_loss = 106.19, pg_loss = 50.184, baseline_loss = 61.402, entropy_loss = -5.3991, learner_queue_size = 32, _tick = 29269, _time = 1.6548e+09, train_seconds = 2.9484e+04)
[2022-06-10 04:19:28,826][root][INFO] - Step 112506880 @ 3581.2 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 112506880, mean_episode_return = 75.523, mean_episode_step = 853.13, total_loss = -51.373, pg_loss = -97.834, baseline_loss = 51.814, entropy_loss = -5.3535, learner_queue_size = 32, _tick = 29273, _time = 1.6548e+09, train_seconds = 2.9489e+04)
[2022-06-10 04:19:33,830][root][INFO] - Step 112527360 @ 4092.7 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 112527360, mean_episode_return = 12.07, mean_episode_step = 1105.4, total_loss = -147.62, pg_loss = -155.29, baseline_loss = 13.092, entropy_loss = -5.4276, learner_queue_size = 32, _tick = 29279, _time = 1.6548e+09, train_seconds = 2.9494e+04)
[2022-06-10 04:19:38,836][root][INFO] - Step 112545280 @ 3579.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 112545280, mean_episode_return = 15.95, mean_episode_step = 1117.9, total_loss = -33.012, pg_loss = -63.465, baseline_loss = 35.889, entropy_loss = -5.4358, learner_queue_size = 32, _tick = 29286, _time = 1.6548e+09, train_seconds = 2.9499e+04)
[2022-06-10 04:19:43,842][root][INFO] - Step 112565760 @ 4091.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 112565760, mean_episode_return = None, mean_episode_step = 933.34, total_loss = 235.82, pg_loss = 151.47, baseline_loss = 89.854, entropy_loss = -5.5075, learner_queue_size = 32, _tick = 29292, _time = 1.6548e+09, train_seconds = 2.9504e+04)
[2022-06-10 04:19:48,846][root][INFO] - Step 112586240 @ 4092.7 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 112586240, mean_episode_return = 83.279, mean_episode_step = 924.67, total_loss = -60.72, pg_loss = -63.013, baseline_loss = 7.8656, entropy_loss = -5.5731, learner_queue_size = 32, _tick = 29300, _time = 1.6548e+09, train_seconds = 2.9509e+04)
[2022-06-10 04:19:53,850][root][INFO] - Step 112604160 @ 3581.2 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 112604160, mean_episode_return = None, mean_episode_step = 1033.3, total_loss = -48.838, pg_loss = -68.842, baseline_loss = 25.514, entropy_loss = -5.5101, learner_queue_size = 32, _tick = 29304, _time = 1.6548e+09, train_seconds = 2.9514e+04)
[2022-06-10 04:19:58,854][root][INFO] - Step 112624640 @ 4092.6 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 112624640, mean_episode_return = 27.695, mean_episode_step = 1124.0, total_loss = -40.214, pg_loss = -85.463, baseline_loss = 50.546, entropy_loss = -5.2973, learner_queue_size = 32, _tick = 29308, _time = 1.6548e+09, train_seconds = 2.9519e+04)
[2022-06-10 04:20:03,858][root][INFO] - Step 112645120 @ 4092.8 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (step = 112645120, mean_episode_return = 45.11, mean_episode_step = 1038.4, total_loss = -55.524, pg_loss = -96.549, baseline_loss = 46.252, entropy_loss = -5.2264, learner_queue_size = 32, _tick = 29313, _time = 1.6548e+09, train_seconds = 2.9524e+04)
[2022-06-10 04:20:08,862][root][INFO] - Step 112663040 @ 3581.2 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 112663040, mean_episode_return = 48.243, mean_episode_step = 806.8, total_loss = 306.55, pg_loss = 224.1, baseline_loss = 87.649, entropy_loss = -5.2078, learner_queue_size = 32, _tick = 29320, _time = 1.6548e+09, train_seconds = 2.9529e+04)
[2022-06-10 04:20:13,866][root][INFO] - Step 112683520 @ 4092.8 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 112683520, mean_episode_return = 93.58, mean_episode_step = 1306.0, total_loss = 20.154, pg_loss = -3.6591, baseline_loss = 29.357, entropy_loss = -5.5438, learner_queue_size = 32, _tick = 29326, _time = 1.6548e+09, train_seconds = 2.9534e+04)
[2022-06-10 04:20:18,870][root][INFO] - Step 112704000 @ 4092.7 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 112704000, mean_episode_return = None, mean_episode_step = 1107.8, total_loss = 185.12, pg_loss = 115.12, baseline_loss = 75.454, entropy_loss = -5.4528, learner_queue_size = 32, _tick = 29331, _time = 1.6548e+09, train_seconds = 2.9539e+04)
[2022-06-10 04:20:23,874][root][INFO] - Step 112721920 @ 3581.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 112721920, mean_episode_return = None, mean_episode_step = 1049.8, total_loss = -143.05, pg_loss = -157.94, baseline_loss = 20.426, entropy_loss = -5.5339, learner_queue_size = 32, _tick = 29337, _time = 1.6548e+09, train_seconds = 2.9544e+04)
[2022-06-10 04:20:28,878][root][INFO] - Step 112742400 @ 4092.7 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 112742400, mean_episode_return = 39.47, mean_episode_step = 983.18, total_loss = -62.739, pg_loss = -118.57, baseline_loss = 61.349, entropy_loss = -5.515, learner_queue_size = 32, _tick = 29345, _time = 1.6548e+09, train_seconds = 2.9549e+04)
[2022-06-10 04:20:33,882][root][INFO] - Step 112760320 @ 3581.2 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 112760320, mean_episode_return = 45.693, mean_episode_step = 795.97, total_loss = 414.5, pg_loss = 275.03, baseline_loss = 144.8, entropy_loss = -5.3249, learner_queue_size = 32, _tick = 29351, _time = 1.6548e+09, train_seconds = 2.9554e+04)
[2022-06-10 04:20:38,886][root][INFO] - Step 112780800 @ 4092.7 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 112780800, mean_episode_return = 21.876, mean_episode_step = 980.22, total_loss = -42.421, pg_loss = -66.468, baseline_loss = 29.556, entropy_loss = -5.5098, learner_queue_size = 32, _tick = 29357, _time = 1.6548e+09, train_seconds = 2.9559e+04)
[2022-06-10 04:20:43,890][root][INFO] - Step 112801280 @ 4092.8 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 112801280, mean_episode_return = 28.696, mean_episode_step = 943.35, total_loss = -126.49, pg_loss = -134.02, baseline_loss = 13.211, entropy_loss = -5.6723, learner_queue_size = 32, _tick = 29365, _time = 1.6548e+09, train_seconds = 2.9564e+04)
[2022-06-10 04:20:48,894][root][INFO] - Step 112819200 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 112819200, mean_episode_return = 167.24, mean_episode_step = 1184.1, total_loss = -12.407, pg_loss = -21.65, baseline_loss = 14.937, entropy_loss = -5.6935, learner_queue_size = 32, _tick = 29372, _time = 1.6548e+09, train_seconds = 2.9569e+04)
[2022-06-10 04:20:53,898][root][INFO] - Step 112839680 @ 4092.7 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 112839680, mean_episode_return = 39.76, mean_episode_step = 890.64, total_loss = 106.88, pg_loss = 61.199, baseline_loss = 51.049, entropy_loss = -5.3726, learner_queue_size = 32, _tick = 29378, _time = 1.6548e+09, train_seconds = 2.9574e+04)
[2022-06-10 04:20:58,902][root][INFO] - Step 112860160 @ 4092.4 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 112860160, mean_episode_return = 61.475, mean_episode_step = 1316.0, total_loss = 32.507, pg_loss = -4.654, baseline_loss = 42.453, entropy_loss = -5.2923, learner_queue_size = 32, _tick = 29385, _time = 1.6548e+09, train_seconds = 2.9579e+04)
[2022-06-10 04:21:03,906][root][INFO] - Step 112878080 @ 3581.4 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 112878080, mean_episode_return = 105.05, mean_episode_step = 970.12, total_loss = 85.387, pg_loss = 46.927, baseline_loss = 43.917, entropy_loss = -5.4573, learner_queue_size = 32, _tick = 29392, _time = 1.6548e+09, train_seconds = 2.9584e+04)
[2022-06-10 04:21:08,910][root][INFO] - Step 112898560 @ 4092.7 SPS. Inference batcher size: 92. Learner queue size: 32. Other stats: (step = 112898560, mean_episode_return = None, mean_episode_step = 1189.4, total_loss = -44.91, pg_loss = -114.09, baseline_loss = 74.545, entropy_loss = -5.3673, learner_queue_size = 32, _tick = 29399, _time = 1.6548e+09, train_seconds = 2.9589e+04)
[2022-06-10 04:21:13,914][root][INFO] - Step 112916480 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 112916480, mean_episode_return = 33.104, mean_episode_step = 964.73, total_loss = -89.247, pg_loss = -125.93, baseline_loss = 42.11, entropy_loss = -5.426, learner_queue_size = 32, _tick = 29403, _time = 1.6548e+09, train_seconds = 2.9594e+04)
[2022-06-10 04:21:18,918][root][INFO] - Step 112936960 @ 4092.8 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 112936960, mean_episode_return = None, mean_episode_step = 1013.8, total_loss = 56.314, pg_loss = 25.788, baseline_loss = 36.124, entropy_loss = -5.5986, learner_queue_size = 32, _tick = 29408, _time = 1.6548e+09, train_seconds = 2.9599e+04)
[2022-06-10 04:21:23,922][root][INFO] - Step 112954880 @ 3581.1 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 112954880, mean_episode_return = 29.901, mean_episode_step = 1123.6, total_loss = 27.608, pg_loss = 0.47098, baseline_loss = 32.492, entropy_loss = -5.3545, learner_queue_size = 32, _tick = 29414, _time = 1.6548e+09, train_seconds = 2.9604e+04)
[2022-06-10 04:21:28,926][root][INFO] - Step 112975360 @ 4092.7 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 112975360, mean_episode_return = 23.035, mean_episode_step = 835.92, total_loss = 66.327, pg_loss = 31.164, baseline_loss = 40.481, entropy_loss = -5.3172, learner_queue_size = 32, _tick = 29420, _time = 1.6548e+09, train_seconds = 2.9609e+04)
[2022-06-10 04:21:33,930][root][INFO] - Step 112993280 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 112993280, mean_episode_return = -5.3303, mean_episode_step = 968.74, total_loss = 204.06, pg_loss = 163.21, baseline_loss = 46.268, entropy_loss = -5.4147, learner_queue_size = 32, _tick = 29425, _time = 1.6548e+09, train_seconds = 2.9614e+04)
[2022-06-10 04:21:38,934][root][INFO] - Step 113013760 @ 4092.8 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 113013760, mean_episode_return = -20.09, mean_episode_step = 1046.4, total_loss = 219.14, pg_loss = 159.54, baseline_loss = 64.883, entropy_loss = -5.2808, learner_queue_size = 32, _tick = 29433, _time = 1.6548e+09, train_seconds = 2.9619e+04)
[2022-06-10 04:21:43,939][root][INFO] - Step 113034240 @ 4091.8 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 113034240, mean_episode_return = 65.935, mean_episode_step = 856.52, total_loss = 87.484, pg_loss = 25.732, baseline_loss = 67.1, entropy_loss = -5.3481, learner_queue_size = 32, _tick = 29439, _time = 1.6548e+09, train_seconds = 2.9624e+04)
[2022-06-10 04:21:48,942][root][INFO] - Step 113054720 @ 4093.3 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 113054720, mean_episode_return = 49.1, mean_episode_step = 1164.6, total_loss = 88.209, pg_loss = 35.003, baseline_loss = 58.831, entropy_loss = -5.6254, learner_queue_size = 32, _tick = 29446, _time = 1.6548e+09, train_seconds = 2.9629e+04)
[2022-06-10 04:21:53,946][root][INFO] - Step 113072640 @ 3581.4 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (step = 113072640, mean_episode_return = 9.2098, mean_episode_step = 980.0, total_loss = -63.783, pg_loss = -88.683, baseline_loss = 30.252, entropy_loss = -5.3517, learner_queue_size = 32, _tick = 29449, _time = 1.6548e+09, train_seconds = 2.9634e+04)
[2022-06-10 04:21:58,950][root][INFO] - Step 113093120 @ 4092.7 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 113093120, mean_episode_return = 76.946, mean_episode_step = 1045.4, total_loss = -35.66, pg_loss = -68.061, baseline_loss = 37.856, entropy_loss = -5.4552, learner_queue_size = 32, _tick = 29457, _time = 1.6548e+09, train_seconds = 2.9639e+04)
[2022-06-10 04:22:03,955][root][INFO] - Step 113111040 @ 3580.5 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 113111040, mean_episode_return = 25.765, mean_episode_step = 1178.9, total_loss = 172.02, pg_loss = 128.43, baseline_loss = 49.027, entropy_loss = -5.4336, learner_queue_size = 32, _tick = 29461, _time = 1.6548e+09, train_seconds = 2.9644e+04)
[2022-06-10 04:22:08,958][root][INFO] - Step 113131520 @ 4093.5 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 113131520, mean_episode_return = 34.001, mean_episode_step = 1134.4, total_loss = -132.09, pg_loss = -142.1, baseline_loss = 15.448, entropy_loss = -5.4306, learner_queue_size = 32, _tick = 29469, _time = 1.6548e+09, train_seconds = 2.9649e+04)
[2022-06-10 04:22:13,962][root][INFO] - Step 113152000 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 113152000, mean_episode_return = 67.23, mean_episode_step = 1091.4, total_loss = 152.4, pg_loss = 63.496, baseline_loss = 94.26, entropy_loss = -5.3541, learner_queue_size = 32, _tick = 29474, _time = 1.6548e+09, train_seconds = 2.9654e+04)
[2022-06-10 04:22:18,968][root][INFO] - Step 113169920 @ 3579.6 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 113169920, mean_episode_return = None, mean_episode_step = 1426.1, total_loss = 31.769, pg_loss = 7.185, baseline_loss = 29.929, entropy_loss = -5.3456, learner_queue_size = 32, _tick = 29480, _time = 1.6548e+09, train_seconds = 2.9659e+04)
[2022-06-10 04:22:23,974][root][INFO] - Step 113190400 @ 4091.2 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 113190400, mean_episode_return = 35.93, mean_episode_step = 995.32, total_loss = 52.382, pg_loss = -3.1987, baseline_loss = 60.774, entropy_loss = -5.1937, learner_queue_size = 32, _tick = 29485, _time = 1.6548e+09, train_seconds = 2.9664e+04)
[2022-06-10 04:22:28,978][root][INFO] - Step 113208320 @ 3581.2 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 113208320, mean_episode_return = 47.625, mean_episode_step = 1089.9, total_loss = -28.521, pg_loss = -72.019, baseline_loss = 48.88, entropy_loss = -5.3823, learner_queue_size = 32, _tick = 29492, _time = 1.6548e+09, train_seconds = 2.9669e+04)
[2022-06-10 04:22:33,982][root][INFO] - Step 113228800 @ 4092.7 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 113228800, mean_episode_return = 83.267, mean_episode_step = 914.99, total_loss = 193.32, pg_loss = 102.98, baseline_loss = 95.745, entropy_loss = -5.4086, learner_queue_size = 32, _tick = 29500, _time = 1.6548e+09, train_seconds = 2.9674e+04)
[2022-06-10 04:22:38,986][root][INFO] - Step 113249280 @ 4092.7 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 113249280, mean_episode_return = -14.01, mean_episode_step = 1047.8, total_loss = -148.77, pg_loss = -161.8, baseline_loss = 18.336, entropy_loss = -5.3091, learner_queue_size = 32, _tick = 29507, _time = 1.6548e+09, train_seconds = 2.9679e+04)
[2022-06-10 04:22:43,990][root][INFO] - Step 113267200 @ 3581.2 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 113267200, mean_episode_return = 61.303, mean_episode_step = 1135.7, total_loss = 60.639, pg_loss = 1.4559, baseline_loss = 64.58, entropy_loss = -5.3969, learner_queue_size = 32, _tick = 29514, _time = 1.6548e+09, train_seconds = 2.9684e+04)
[2022-06-10 04:22:48,994][root][INFO] - Step 113287680 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 113287680, mean_episode_return = None, mean_episode_step = 1008.4, total_loss = 79.451, pg_loss = 47.741, baseline_loss = 36.936, entropy_loss = -5.2269, learner_queue_size = 32, _tick = 29519, _time = 1.6548e+09, train_seconds = 2.9689e+04)
[2022-06-10 04:22:53,998][root][INFO] - Step 113308160 @ 4092.6 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 113308160, mean_episode_return = 69.443, mean_episode_step = 1112.1, total_loss = 53.258, pg_loss = 22.433, baseline_loss = 36.338, entropy_loss = -5.5135, learner_queue_size = 32, _tick = 29526, _time = 1.6548e+09, train_seconds = 2.9694e+04)
[2022-06-10 04:22:59,001][root][INFO] - Step 113326080 @ 3582.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 113326080, mean_episode_return = 43.664, mean_episode_step = 839.63, total_loss = 299.77, pg_loss = 225.63, baseline_loss = 79.502, entropy_loss = -5.3615, learner_queue_size = 32, _tick = 29532, _time = 1.6548e+09, train_seconds = 2.9699e+04)
[2022-06-10 04:23:04,006][root][INFO] - Step 113346560 @ 4091.8 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 113346560, mean_episode_return = 59.561, mean_episode_step = 1177.7, total_loss = 250.4, pg_loss = 170.17, baseline_loss = 86.06, entropy_loss = -5.8285, learner_queue_size = 32, _tick = 29539, _time = 1.6548e+09, train_seconds = 2.9704e+04)
[2022-06-10 04:23:09,010][root][INFO] - Step 113367040 @ 4092.7 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 113367040, mean_episode_return = 46.77, mean_episode_step = 1022.3, total_loss = 769.8, pg_loss = 221.7, baseline_loss = 553.73, entropy_loss = -5.6287, learner_queue_size = 32, _tick = 29546, _time = 1.6548e+09, train_seconds = 2.9709e+04)
[2022-06-10 04:23:14,016][root][INFO] - Step 113387520 @ 4091.3 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 113387520, mean_episode_return = 22.49, mean_episode_step = 940.88, total_loss = 95.711, pg_loss = 49.236, baseline_loss = 51.879, entropy_loss = -5.4037, learner_queue_size = 32, _tick = 29552, _time = 1.6548e+09, train_seconds = 2.9714e+04)
[2022-06-10 04:23:19,018][root][INFO] - Step 113405440 @ 3582.3 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 113405440, mean_episode_return = 50.06, mean_episode_step = 1137.5, total_loss = 144.79, pg_loss = 112.51, baseline_loss = 37.878, entropy_loss = -5.594, learner_queue_size = 32, _tick = 29559, _time = 1.6548e+09, train_seconds = 2.9719e+04)
[2022-06-10 04:23:24,022][root][INFO] - Step 113423360 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 113423360, mean_episode_return = 70.785, mean_episode_step = 973.78, total_loss = 23.449, pg_loss = -7.3815, baseline_loss = 36.269, entropy_loss = -5.438, learner_queue_size = 32, _tick = 29565, _time = 1.6548e+09, train_seconds = 2.9724e+04)
[2022-06-10 04:23:29,026][root][INFO] - Step 113443840 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 113443840, mean_episode_return = 4.1, mean_episode_step = 1145.0, total_loss = 102.62, pg_loss = 71.788, baseline_loss = 36.396, entropy_loss = -5.5603, learner_queue_size = 32, _tick = 29573, _time = 1.6548e+09, train_seconds = 2.9729e+04)
[2022-06-10 04:23:34,030][root][INFO] - Step 113461760 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 113461760, mean_episode_return = -9.8101, mean_episode_step = 848.89, total_loss = 326.75, pg_loss = 261.04, baseline_loss = 70.983, entropy_loss = -5.2813, learner_queue_size = 32, _tick = 29578, _time = 1.6548e+09, train_seconds = 2.9734e+04)
[2022-06-10 04:23:39,034][root][INFO] - Step 113482240 @ 4092.8 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 113482240, mean_episode_return = 42.844, mean_episode_step = 893.14, total_loss = 344.11, pg_loss = 286.62, baseline_loss = 62.851, entropy_loss = -5.3601, learner_queue_size = 32, _tick = 29584, _time = 1.6548e+09, train_seconds = 2.9739e+04)
[2022-06-10 04:23:44,038][root][INFO] - Step 113502720 @ 4092.6 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 113502720, mean_episode_return = None, mean_episode_step = 1013.0, total_loss = 220.39, pg_loss = 178.23, baseline_loss = 47.141, entropy_loss = -4.9773, learner_queue_size = 32, _tick = 29588, _time = 1.6548e+09, train_seconds = 2.9744e+04)
[2022-06-10 04:23:49,042][root][INFO] - Step 113523200 @ 4092.8 SPS. Inference batcher size: 87. Learner queue size: 32. Other stats: (step = 113523200, mean_episode_return = None, mean_episode_step = 881.38, total_loss = 323.02, pg_loss = 229.4, baseline_loss = 98.687, entropy_loss = -5.0691, learner_queue_size = 32, _tick = 29593, _time = 1.6548e+09, train_seconds = 2.9749e+04)
[2022-06-10 04:23:54,046][root][INFO] - Step 113541120 @ 3581.1 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 113541120, mean_episode_return = 169.14, mean_episode_step = 1106.0, total_loss = -109.45, pg_loss = -145.78, baseline_loss = 41.375, entropy_loss = -5.0526, learner_queue_size = 32, _tick = 29597, _time = 1.6548e+09, train_seconds = 2.9754e+04)
[2022-06-10 04:23:59,050][root][INFO] - Step 113561600 @ 4092.7 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 113561600, mean_episode_return = None, mean_episode_step = 1108.1, total_loss = -25.769, pg_loss = -38.06, baseline_loss = 17.595, entropy_loss = -5.3043, learner_queue_size = 32, _tick = 29603, _time = 1.6548e+09, train_seconds = 2.9759e+04)
[2022-06-10 04:24:04,054][root][INFO] - Step 113579520 @ 3581.2 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 113579520, mean_episode_return = 41.337, mean_episode_step = 1313.4, total_loss = 54.317, pg_loss = 12.315, baseline_loss = 47.209, entropy_loss = -5.2074, learner_queue_size = 32, _tick = 29608, _time = 1.6548e+09, train_seconds = 2.9764e+04)
[2022-06-10 04:24:09,060][root][INFO] - Step 113600000 @ 4091.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 113600000, mean_episode_return = 77.916, mean_episode_step = 1212.8, total_loss = -66.598, pg_loss = -90.593, baseline_loss = 29.426, entropy_loss = -5.4312, learner_queue_size = 32, _tick = 29611, _time = 1.6548e+09, train_seconds = 2.9769e+04)
[2022-06-10 04:24:14,066][root][INFO] - Step 113617920 @ 3579.8 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 113617920, mean_episode_return = None, mean_episode_step = 1128.4, total_loss = -14.461, pg_loss = -40.954, baseline_loss = 31.917, entropy_loss = -5.4239, learner_queue_size = 32, _tick = 29616, _time = 1.6548e+09, train_seconds = 2.9774e+04)
[2022-06-10 04:24:19,070][root][INFO] - Step 113638400 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 113638400, mean_episode_return = 67.195, mean_episode_step = 879.24, total_loss = -188.44, pg_loss = -225.19, baseline_loss = 42.106, entropy_loss = -5.3617, learner_queue_size = 32, _tick = 29621, _time = 1.6548e+09, train_seconds = 2.9779e+04)
[2022-06-10 04:24:24,074][root][INFO] - Step 113658880 @ 4092.7 SPS. Inference batcher size: 77. Learner queue size: 32. Other stats: (step = 113658880, mean_episode_return = 57.202, mean_episode_step = 1288.7, total_loss = 166.02, pg_loss = 78.996, baseline_loss = 92.343, entropy_loss = -5.3137, learner_queue_size = 32, _tick = 29626, _time = 1.6548e+09, train_seconds = 2.9784e+04)
[2022-06-10 04:24:29,078][root][INFO] - Step 113676800 @ 3581.2 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 113676800, mean_episode_return = 153.43, mean_episode_step = 1343.2, total_loss = -4.7384, pg_loss = -36.494, baseline_loss = 37.17, entropy_loss = -5.414, learner_queue_size = 32, _tick = 29631, _time = 1.6548e+09, train_seconds = 2.9789e+04)
[2022-06-10 04:24:34,082][root][INFO] - Step 113697280 @ 4092.7 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 113697280, mean_episode_return = 10.82, mean_episode_step = 1456.3, total_loss = -24.656, pg_loss = -33.265, baseline_loss = 14.307, entropy_loss = -5.6979, learner_queue_size = 32, _tick = 29637, _time = 1.6548e+09, train_seconds = 2.9794e+04)
[2022-06-10 04:24:39,086][root][INFO] - Step 113717760 @ 4092.8 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 113717760, mean_episode_return = None, mean_episode_step = 1219.3, total_loss = 193.98, pg_loss = 151.54, baseline_loss = 47.966, entropy_loss = -5.5243, learner_queue_size = 32, _tick = 29643, _time = 1.6548e+09, train_seconds = 2.9799e+04)
[2022-06-10 04:24:44,090][root][INFO] - Step 113735680 @ 3581.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 113735680, mean_episode_return = 52.396, mean_episode_step = 1216.6, total_loss = 182.31, pg_loss = 145.9, baseline_loss = 41.939, entropy_loss = -5.5315, learner_queue_size = 32, _tick = 29648, _time = 1.6548e+09, train_seconds = 2.9804e+04)
[2022-06-10 04:24:49,094][root][INFO] - Step 113753600 @ 3581.1 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 113753600, mean_episode_return = None, mean_episode_step = 1326.7, total_loss = 32.425, pg_loss = -1.3061, baseline_loss = 39.201, entropy_loss = -5.4695, learner_queue_size = 32, _tick = 29653, _time = 1.6548e+09, train_seconds = 2.9809e+04)
[2022-06-10 04:24:54,098][root][INFO] - Step 113774080 @ 4092.6 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 113774080, mean_episode_return = 46.705, mean_episode_step = 996.53, total_loss = -285.63, pg_loss = -320.17, baseline_loss = 39.865, entropy_loss = -5.3216, learner_queue_size = 32, _tick = 29661, _time = 1.6548e+09, train_seconds = 2.9814e+04)
[2022-06-10 04:24:59,102][root][INFO] - Step 113794560 @ 4092.8 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 113794560, mean_episode_return = 88.61, mean_episode_step = 1149.7, total_loss = 26.52, pg_loss = -17.08, baseline_loss = 48.928, entropy_loss = -5.327, learner_queue_size = 32, _tick = 29669, _time = 1.6548e+09, train_seconds = 2.9819e+04)
[2022-06-10 04:25:04,108][root][INFO] - Step 113812480 @ 3579.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 113812480, mean_episode_return = 69.9, mean_episode_step = 1365.0, total_loss = -279.77, pg_loss = -295.33, baseline_loss = 21.036, entropy_loss = -5.4819, learner_queue_size = 32, _tick = 29674, _time = 1.6548e+09, train_seconds = 2.9824e+04)
[2022-06-10 04:25:09,114][root][INFO] - Step 113832960 @ 4091.1 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 113832960, mean_episode_return = 30.361, mean_episode_step = 1372.6, total_loss = 210.28, pg_loss = 176.56, baseline_loss = 39.406, entropy_loss = -5.6772, learner_queue_size = 32, _tick = 29681, _time = 1.6548e+09, train_seconds = 2.9829e+04)
[2022-06-10 04:25:14,118][root][INFO] - Step 113853440 @ 4092.7 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 113853440, mean_episode_return = None, mean_episode_step = 922.06, total_loss = 848.45, pg_loss = 346.37, baseline_loss = 507.52, entropy_loss = -5.4466, learner_queue_size = 32, _tick = 29686, _time = 1.6548e+09, train_seconds = 2.9834e+04)
[2022-06-10 04:25:19,118][root][INFO] - Step 113871360 @ 3583.5 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 113871360, mean_episode_return = 115.48, mean_episode_step = 1042.5, total_loss = -61.908, pg_loss = -100.46, baseline_loss = 43.908, entropy_loss = -5.3551, learner_queue_size = 32, _tick = 29692, _time = 1.6548e+09, train_seconds = 2.9839e+04)
[2022-06-10 04:25:24,122][root][INFO] - Step 113891840 @ 4093.2 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 113891840, mean_episode_return = 31.83, mean_episode_step = 1150.0, total_loss = -84.094, pg_loss = -105.78, baseline_loss = 27.149, entropy_loss = -5.4611, learner_queue_size = 32, _tick = 29696, _time = 1.6548e+09, train_seconds = 2.9844e+04)
[2022-06-10 04:25:29,126][root][INFO] - Step 113909760 @ 3581.2 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 113909760, mean_episode_return = 33.265, mean_episode_step = 1029.5, total_loss = 16.414, pg_loss = -25.536, baseline_loss = 47.308, entropy_loss = -5.3576, learner_queue_size = 32, _tick = 29701, _time = 1.6548e+09, train_seconds = 2.9849e+04)
[2022-06-10 04:25:34,130][root][INFO] - Step 113930240 @ 4092.7 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 113930240, mean_episode_return = 47.504, mean_episode_step = 1175.8, total_loss = -36.022, pg_loss = -60.188, baseline_loss = 29.917, entropy_loss = -5.7512, learner_queue_size = 32, _tick = 29709, _time = 1.6548e+09, train_seconds = 2.9854e+04)
[2022-06-10 04:25:39,134][root][INFO] - Step 113950720 @ 4092.6 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 113950720, mean_episode_return = 40.945, mean_episode_step = 1176.4, total_loss = 232.17, pg_loss = 190.65, baseline_loss = 46.976, entropy_loss = -5.4584, learner_queue_size = 32, _tick = 29715, _time = 1.6548e+09, train_seconds = 2.9859e+04)
[2022-06-10 04:25:44,138][root][INFO] - Step 113968640 @ 3581.2 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 113968640, mean_episode_return = 19.923, mean_episode_step = 1368.8, total_loss = 161.21, pg_loss = 118.06, baseline_loss = 48.411, entropy_loss = -5.2557, learner_queue_size = 32, _tick = 29721, _time = 1.6548e+09, train_seconds = 2.9864e+04)
[2022-06-10 04:25:49,142][root][INFO] - Step 113989120 @ 4092.8 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 113989120, mean_episode_return = 12.83, mean_episode_step = 959.68, total_loss = 144.42, pg_loss = 80.787, baseline_loss = 68.9, entropy_loss = -5.2643, learner_queue_size = 32, _tick = 29726, _time = 1.6548e+09, train_seconds = 2.9869e+04)
[2022-06-10 04:25:54,146][root][INFO] - Step 114009600 @ 4092.7 SPS. Inference batcher size: 80. Learner queue size: 32. Other stats: (step = 114009600, mean_episode_return = 28.091, mean_episode_step = 1228.2, total_loss = -153.45, pg_loss = -162.3, baseline_loss = 14.441, entropy_loss = -5.5933, learner_queue_size = 32, _tick = 29730, _time = 1.6548e+09, train_seconds = 2.9874e+04)
[2022-06-10 04:25:59,150][root][INFO] - Step 114027520 @ 3581.2 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (step = 114027520, mean_episode_return = 122.49, mean_episode_step = 1444.8, total_loss = 275.03, pg_loss = 214.69, baseline_loss = 65.786, entropy_loss = -5.4476, learner_queue_size = 32, _tick = 29735, _time = 1.6548e+09, train_seconds = 2.9879e+04)
[2022-06-10 04:26:04,156][root][INFO] - Step 114048000 @ 4090.6 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 114048000, mean_episode_return = 91.165, mean_episode_step = 1393.1, total_loss = 13.386, pg_loss = -4.0287, baseline_loss = 22.891, entropy_loss = -5.476, learner_queue_size = 32, _tick = 29743, _time = 1.6548e+09, train_seconds = 2.9884e+04)
[2022-06-10 04:26:09,163][root][INFO] - Step 114068480 @ 4091.0 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 114068480, mean_episode_return = 86.475, mean_episode_step = 1181.6, total_loss = -4.7902, pg_loss = -42.086, baseline_loss = 42.692, entropy_loss = -5.3969, learner_queue_size = 32, _tick = 29750, _time = 1.6548e+09, train_seconds = 2.9889e+04)
[2022-06-10 04:26:14,166][root][INFO] - Step 114086400 @ 3581.6 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 114086400, mean_episode_return = 132.54, mean_episode_step = 1049.5, total_loss = 20.151, pg_loss = -16.173, baseline_loss = 41.66, entropy_loss = -5.336, learner_queue_size = 32, _tick = 29757, _time = 1.6548e+09, train_seconds = 2.9894e+04)
[2022-06-10 04:26:19,170][root][INFO] - Step 114106880 @ 4092.8 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 114106880, mean_episode_return = 74.86, mean_episode_step = 854.32, total_loss = -6.1071, pg_loss = -37.585, baseline_loss = 36.857, entropy_loss = -5.3791, learner_queue_size = 32, _tick = 29765, _time = 1.6548e+09, train_seconds = 2.9899e+04)
[2022-06-10 04:26:24,175][root][INFO] - Step 114124800 @ 3580.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 114124800, mean_episode_return = 32.9, mean_episode_step = 966.18, total_loss = 273.22, pg_loss = 224.38, baseline_loss = 54.135, entropy_loss = -5.2933, learner_queue_size = 32, _tick = 29771, _time = 1.6548e+09, train_seconds = 2.9904e+04)
[2022-06-10 04:26:29,178][root][INFO] - Step 114145280 @ 4093.8 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 114145280, mean_episode_return = None, mean_episode_step = 1111.7, total_loss = 187.43, pg_loss = 114.86, baseline_loss = 77.847, entropy_loss = -5.2699, learner_queue_size = 32, _tick = 29775, _time = 1.6548e+09, train_seconds = 2.9909e+04)
[2022-06-10 04:26:34,182][root][INFO] - Step 114165760 @ 4092.7 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 114165760, mean_episode_return = 18.99, mean_episode_step = 1356.7, total_loss = -9.8917, pg_loss = -52.29, baseline_loss = 48.019, entropy_loss = -5.6204, learner_queue_size = 32, _tick = 29781, _time = 1.6548e+09, train_seconds = 2.9914e+04)
[2022-06-10 04:26:39,186][root][INFO] - Step 114186240 @ 4092.8 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 114186240, mean_episode_return = 96.609, mean_episode_step = 1061.9, total_loss = 257.93, pg_loss = 202.49, baseline_loss = 60.936, entropy_loss = -5.4925, learner_queue_size = 32, _tick = 29786, _time = 1.6548e+09, train_seconds = 2.9919e+04)
[2022-06-10 04:26:44,192][root][INFO] - Step 114206720 @ 4091.1 SPS. Inference batcher size: 75. Learner queue size: 32. Other stats: (step = 114206720, mean_episode_return = 117.76, mean_episode_step = 1049.2, total_loss = 468.29, pg_loss = 344.9, baseline_loss = 128.86, entropy_loss = -5.471, learner_queue_size = 32, _tick = 29793, _time = 1.6548e+09, train_seconds = 2.9924e+04)
[2022-06-10 04:26:49,198][root][INFO] - Step 114224640 @ 3579.8 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 114224640, mean_episode_return = 71.92, mean_episode_step = 1117.1, total_loss = 256.41, pg_loss = 133.92, baseline_loss = 127.8, entropy_loss = -5.3002, learner_queue_size = 32, _tick = 29799, _time = 1.6548e+09, train_seconds = 2.9929e+04)
[2022-06-10 04:26:54,202][root][INFO] - Step 114245120 @ 4092.6 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 114245120, mean_episode_return = 68.04, mean_episode_step = 946.58, total_loss = -178.98, pg_loss = -199.06, baseline_loss = 25.358, entropy_loss = -5.2817, learner_queue_size = 32, _tick = 29806, _time = 1.6548e+09, train_seconds = 2.9934e+04)
[2022-06-10 04:26:59,206][root][INFO] - Step 114265600 @ 4092.8 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 114265600, mean_episode_return = None, mean_episode_step = 1181.0, total_loss = -54.162, pg_loss = -78.591, baseline_loss = 29.911, entropy_loss = -5.4816, learner_queue_size = 32, _tick = 29813, _time = 1.6548e+09, train_seconds = 2.9939e+04)
[2022-06-10 04:27:04,210][root][INFO] - Step 114286080 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 114286080, mean_episode_return = 53.091, mean_episode_step = 933.29, total_loss = 106.41, pg_loss = 76.809, baseline_loss = 35.136, entropy_loss = -5.5323, learner_queue_size = 32, _tick = 29818, _time = 1.6548e+09, train_seconds = 2.9944e+04)
[2022-06-10 04:27:09,214][root][INFO] - Step 114304000 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 114304000, mean_episode_return = 100.55, mean_episode_step = 1044.2, total_loss = 85.287, pg_loss = 43.159, baseline_loss = 47.401, entropy_loss = -5.273, learner_queue_size = 32, _tick = 29822, _time = 1.6548e+09, train_seconds = 2.9949e+04)
[2022-06-10 04:27:14,218][root][INFO] - Step 114321920 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 114321920, mean_episode_return = 5.6697, mean_episode_step = 1259.7, total_loss = 20.423, pg_loss = -6.1619, baseline_loss = 31.837, entropy_loss = -5.2524, learner_queue_size = 32, _tick = 29828, _time = 1.6548e+09, train_seconds = 2.9954e+04)
[2022-06-10 04:27:19,222][root][INFO] - Step 114342400 @ 4092.8 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 114342400, mean_episode_return = 64.655, mean_episode_step = 1005.6, total_loss = -338.72, pg_loss = -383.18, baseline_loss = 49.716, entropy_loss = -5.2638, learner_queue_size = 32, _tick = 29834, _time = 1.6548e+09, train_seconds = 2.9959e+04)
[2022-06-10 04:27:24,226][root][INFO] - Step 114362880 @ 4092.6 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 114362880, mean_episode_return = 152.15, mean_episode_step = 1563.0, total_loss = -134.55, pg_loss = -147.16, baseline_loss = 17.994, entropy_loss = -5.3858, learner_queue_size = 32, _tick = 29842, _time = 1.6548e+09, train_seconds = 2.9964e+04)
[2022-06-10 04:27:29,230][root][INFO] - Step 114380800 @ 3581.2 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 114380800, mean_episode_return = 55.181, mean_episode_step = 1039.8, total_loss = 121.43, pg_loss = 55.955, baseline_loss = 70.679, entropy_loss = -5.2063, learner_queue_size = 32, _tick = 29847, _time = 1.6548e+09, train_seconds = 2.9969e+04)
[2022-06-10 04:27:34,234][root][INFO] - Step 114401280 @ 4092.7 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 114401280, mean_episode_return = 13.92, mean_episode_step = 1254.8, total_loss = 194.12, pg_loss = 122.68, baseline_loss = 76.659, entropy_loss = -5.2189, learner_queue_size = 32, _tick = 29852, _time = 1.6548e+09, train_seconds = 2.9974e+04)
[2022-06-10 04:27:39,239][root][INFO] - Step 114419200 @ 3580.3 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 114419200, mean_episode_return = 68.849, mean_episode_step = 1025.0, total_loss = 271.13, pg_loss = 221.94, baseline_loss = 54.406, entropy_loss = -5.2117, learner_queue_size = 32, _tick = 29858, _time = 1.6548e+09, train_seconds = 2.9979e+04)
[2022-06-10 04:27:44,245][root][INFO] - Step 114439680 @ 4091.2 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 114439680, mean_episode_return = 23.647, mean_episode_step = 904.57, total_loss = -76.475, pg_loss = -107.4, baseline_loss = 36.274, entropy_loss = -5.3514, learner_queue_size = 32, _tick = 29866, _time = 1.6548e+09, train_seconds = 2.9984e+04)
[2022-06-10 04:27:49,250][root][INFO] - Step 114460160 @ 4092.0 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 114460160, mean_episode_return = 100.34, mean_episode_step = 995.75, total_loss = 495.15, pg_loss = 389.13, baseline_loss = 111.45, entropy_loss = -5.4294, learner_queue_size = 32, _tick = 29874, _time = 1.6548e+09, train_seconds = 2.9989e+04)
[2022-06-10 04:27:54,256][root][INFO] - Step 114480640 @ 4091.0 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 114480640, mean_episode_return = 26.587, mean_episode_step = 1090.6, total_loss = 68.559, pg_loss = 40.917, baseline_loss = 32.957, entropy_loss = -5.3149, learner_queue_size = 32, _tick = 29881, _time = 1.6548e+09, train_seconds = 2.9994e+04)
[2022-06-10 04:27:59,262][root][INFO] - Step 114501120 @ 4091.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 114501120, mean_episode_return = 40.47, mean_episode_step = 1017.9, total_loss = 13.969, pg_loss = -26.463, baseline_loss = 45.718, entropy_loss = -5.285, learner_queue_size = 32, _tick = 29888, _time = 1.6548e+09, train_seconds = 2.9999e+04)
[2022-06-10 04:28:04,270][root][INFO] - Step 114519040 @ 3578.3 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 114519040, mean_episode_return = 26.59, mean_episode_step = 832.76, total_loss = 112.94, pg_loss = 43.006, baseline_loss = 75.122, entropy_loss = -5.1865, learner_queue_size = 32, _tick = 29893, _time = 1.6548e+09, train_seconds = 3.0004e+04)
[2022-06-10 04:28:09,274][root][INFO] - Step 114539520 @ 4092.7 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 114539520, mean_episode_return = 83.413, mean_episode_step = 1203.8, total_loss = 88.142, pg_loss = 19.481, baseline_loss = 74.089, entropy_loss = -5.4279, learner_queue_size = 32, _tick = 29899, _time = 1.6548e+09, train_seconds = 3.0009e+04)
[2022-06-10 04:28:14,278][root][INFO] - Step 114560000 @ 4092.8 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 114560000, mean_episode_return = None, mean_episode_step = 865.22, total_loss = -54.371, pg_loss = -102.23, baseline_loss = 53.224, entropy_loss = -5.3659, learner_queue_size = 32, _tick = 29902, _time = 1.6548e+09, train_seconds = 3.0014e+04)
[2022-06-10 04:28:19,282][root][INFO] - Step 114580480 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 114580480, mean_episode_return = 23.49, mean_episode_step = 953.0, total_loss = 94.821, pg_loss = 41.417, baseline_loss = 59.032, entropy_loss = -5.628, learner_queue_size = 32, _tick = 29910, _time = 1.6548e+09, train_seconds = 3.0019e+04)
[2022-06-10 04:28:24,286][root][INFO] - Step 114598400 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 114598400, mean_episode_return = 84.667, mean_episode_step = 929.89, total_loss = 65.811, pg_loss = 29.114, baseline_loss = 42.138, entropy_loss = -5.4408, learner_queue_size = 32, _tick = 29916, _time = 1.6548e+09, train_seconds = 3.0024e+04)
[2022-06-10 04:28:29,290][root][INFO] - Step 114618880 @ 4092.8 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 114618880, mean_episode_return = 88.362, mean_episode_step = 1197.0, total_loss = -228.36, pg_loss = -232.48, baseline_loss = 9.6909, entropy_loss = -5.5631, learner_queue_size = 32, _tick = 29923, _time = 1.6548e+09, train_seconds = 3.0029e+04)
[2022-06-10 04:28:34,294][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 04:28:34,476][root][INFO] - Step 114639360 @ 4092.6 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 114639360, mean_episode_return = 53.221, mean_episode_step = 933.1, total_loss = -97.712, pg_loss = -139.36, baseline_loss = 47.243, entropy_loss = -5.5915, learner_queue_size = 32, _tick = 29931, _time = 1.6548e+09, train_seconds = 3.0034e+04)
[2022-06-10 04:28:39,478][root][INFO] - Step 114657280 @ 3456.8 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 114657280, mean_episode_return = 29.83, mean_episode_step = 1032.9, total_loss = 27.214, pg_loss = -2.9852, baseline_loss = 35.743, entropy_loss = -5.5439, learner_queue_size = 32, _tick = 29938, _time = 1.6548e+09, train_seconds = 3.0039e+04)
[2022-06-10 04:28:44,482][root][INFO] - Step 114677760 @ 4092.7 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 114677760, mean_episode_return = 53.82, mean_episode_step = 1017.8, total_loss = 196.79, pg_loss = 164.29, baseline_loss = 38.032, entropy_loss = -5.5308, learner_queue_size = 32, _tick = 29944, _time = 1.6548e+09, train_seconds = 3.0044e+04)
[2022-06-10 04:28:49,486][root][INFO] - Step 114695680 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 114695680, mean_episode_return = 69.27, mean_episode_step = 1029.2, total_loss = 169.18, pg_loss = 133.13, baseline_loss = 41.547, entropy_loss = -5.5006, learner_queue_size = 32, _tick = 29950, _time = 1.6548e+09, train_seconds = 3.0049e+04)
[2022-06-10 04:28:54,490][root][INFO] - Step 114716160 @ 4092.7 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 114716160, mean_episode_return = 43.731, mean_episode_step = 1034.7, total_loss = 27.93, pg_loss = -15.897, baseline_loss = 49.369, entropy_loss = -5.5425, learner_queue_size = 32, _tick = 29958, _time = 1.6548e+09, train_seconds = 3.0054e+04)
[2022-06-10 04:28:59,494][root][INFO] - Step 114736640 @ 4092.6 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 114736640, mean_episode_return = None, mean_episode_step = 920.31, total_loss = -44.853, pg_loss = -67.689, baseline_loss = 28.468, entropy_loss = -5.632, learner_queue_size = 32, _tick = 29964, _time = 1.6548e+09, train_seconds = 3.0059e+04)
[2022-06-10 04:29:04,498][root][INFO] - Step 114754560 @ 3581.3 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 114754560, mean_episode_return = 53.912, mean_episode_step = 1149.8, total_loss = -78.745, pg_loss = -111.95, baseline_loss = 38.798, entropy_loss = -5.5974, learner_queue_size = 32, _tick = 29971, _time = 1.6548e+09, train_seconds = 3.0064e+04)
[2022-06-10 04:29:09,502][root][INFO] - Step 114775040 @ 4092.6 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 114775040, mean_episode_return = 32.541, mean_episode_step = 1288.6, total_loss = -201.4, pg_loss = -210.36, baseline_loss = 14.737, entropy_loss = -5.7745, learner_queue_size = 32, _tick = 29975, _time = 1.6548e+09, train_seconds = 3.0069e+04)
[2022-06-10 04:29:14,506][root][INFO] - Step 114792960 @ 3581.1 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 114792960, mean_episode_return = 69.751, mean_episode_step = 989.25, total_loss = 63.901, pg_loss = 42.106, baseline_loss = 27.502, entropy_loss = -5.7062, learner_queue_size = 32, _tick = 29979, _time = 1.6548e+09, train_seconds = 3.0074e+04)
[2022-06-10 04:29:19,510][root][INFO] - Step 114813440 @ 4092.8 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (step = 114813440, mean_episode_return = 130.14, mean_episode_step = 742.58, total_loss = 59.235, pg_loss = 35.773, baseline_loss = 28.962, entropy_loss = -5.5003, learner_queue_size = 32, _tick = 29986, _time = 1.6548e+09, train_seconds = 3.0079e+04)
[2022-06-10 04:29:24,514][root][INFO] - Step 114831360 @ 3581.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 114831360, mean_episode_return = 92.84, mean_episode_step = 833.81, total_loss = -51.077, pg_loss = -71.12, baseline_loss = 25.589, entropy_loss = -5.5455, learner_queue_size = 32, _tick = 29992, _time = 1.6548e+09, train_seconds = 3.0084e+04)
[2022-06-10 04:29:29,518][root][INFO] - Step 114851840 @ 4092.7 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 114851840, mean_episode_return = 122.64, mean_episode_step = 924.99, total_loss = -3.3045, pg_loss = -40.176, baseline_loss = 42.382, entropy_loss = -5.5105, learner_queue_size = 32, _tick = 29998, _time = 1.6548e+09, train_seconds = 3.0089e+04)
[2022-06-10 04:29:34,522][root][INFO] - Step 114869760 @ 3581.2 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 114869760, mean_episode_return = None, mean_episode_step = 1081.7, total_loss = 140.51, pg_loss = 97.828, baseline_loss = 48.188, entropy_loss = -5.5021, learner_queue_size = 32, _tick = 30001, _time = 1.6548e+09, train_seconds = 3.0094e+04)
[2022-06-10 04:29:39,526][root][INFO] - Step 114890240 @ 4092.7 SPS. Inference batcher size: 87. Learner queue size: 32. Other stats: (step = 114890240, mean_episode_return = 44.921, mean_episode_step = 986.29, total_loss = -32.193, pg_loss = -71.74, baseline_loss = 44.783, entropy_loss = -5.2361, learner_queue_size = 32, _tick = 30008, _time = 1.6548e+09, train_seconds = 3.0099e+04)
[2022-06-10 04:29:44,530][root][INFO] - Step 114908160 @ 3581.1 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 114908160, mean_episode_return = 60.861, mean_episode_step = 1136.4, total_loss = 12.423, pg_loss = -7.4476, baseline_loss = 25.455, entropy_loss = -5.5846, learner_queue_size = 32, _tick = 30014, _time = 1.6548e+09, train_seconds = 3.0104e+04)
[2022-06-10 04:29:49,534][root][INFO] - Step 114926080 @ 3581.1 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 114926080, mean_episode_return = 96.484, mean_episode_step = 1084.3, total_loss = 128.92, pg_loss = 78.372, baseline_loss = 56.122, entropy_loss = -5.572, learner_queue_size = 32, _tick = 30020, _time = 1.6548e+09, train_seconds = 3.0109e+04)
[2022-06-10 04:29:54,538][root][INFO] - Step 114946560 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 114946560, mean_episode_return = 142.85, mean_episode_step = 893.33, total_loss = 0.99478, pg_loss = -26.739, baseline_loss = 33.335, entropy_loss = -5.601, learner_queue_size = 32, _tick = 30027, _time = 1.6548e+09, train_seconds = 3.0114e+04)
[2022-06-10 04:29:59,542][root][INFO] - Step 114967040 @ 4092.8 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 114967040, mean_episode_return = None, mean_episode_step = 938.94, total_loss = 114.74, pg_loss = 79.918, baseline_loss = 40.175, entropy_loss = -5.3544, learner_queue_size = 32, _tick = 30032, _time = 1.6548e+09, train_seconds = 3.0119e+04)
[2022-06-10 04:30:04,546][root][INFO] - Step 114987520 @ 4092.7 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 114987520, mean_episode_return = 16.3, mean_episode_step = 1125.9, total_loss = -133.22, pg_loss = -142.68, baseline_loss = 14.443, entropy_loss = -4.9786, learner_queue_size = 32, _tick = 30038, _time = 1.6548e+09, train_seconds = 3.0124e+04)
[2022-06-10 04:30:09,550][root][INFO] - Step 115005440 @ 3581.1 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (step = 115005440, mean_episode_return = 22.116, mean_episode_step = 1072.3, total_loss = 284.24, pg_loss = 182.4, baseline_loss = 107.05, entropy_loss = -5.2057, learner_queue_size = 32, _tick = 30043, _time = 1.6548e+09, train_seconds = 3.0129e+04)
[2022-06-10 04:30:14,554][root][INFO] - Step 115025920 @ 4092.7 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 115025920, mean_episode_return = None, mean_episode_step = 1494.6, total_loss = 34.419, pg_loss = 0.95765, baseline_loss = 39.235, entropy_loss = -5.7743, learner_queue_size = 32, _tick = 30049, _time = 1.6548e+09, train_seconds = 3.0134e+04)
[2022-06-10 04:30:19,559][root][INFO] - Step 115046400 @ 4092.4 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 115046400, mean_episode_return = 63.93, mean_episode_step = 1193.8, total_loss = -43.594, pg_loss = -77.777, baseline_loss = 39.524, entropy_loss = -5.3404, learner_queue_size = 32, _tick = 30055, _time = 1.6548e+09, train_seconds = 3.0139e+04)
[2022-06-10 04:30:24,562][root][INFO] - Step 115066880 @ 4093.2 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 115066880, mean_episode_return = 28.815, mean_episode_step = 1151.8, total_loss = 207.51, pg_loss = 124.47, baseline_loss = 88.412, entropy_loss = -5.3713, learner_queue_size = 32, _tick = 30062, _time = 1.6548e+09, train_seconds = 3.0144e+04)
[2022-06-10 04:30:29,566][root][INFO] - Step 115084800 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 115084800, mean_episode_return = 52.589, mean_episode_step = 977.94, total_loss = -19.813, pg_loss = -58.558, baseline_loss = 43.925, entropy_loss = -5.1801, learner_queue_size = 32, _tick = 30067, _time = 1.6548e+09, train_seconds = 3.0149e+04)
[2022-06-10 04:30:34,570][root][INFO] - Step 115105280 @ 4092.7 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 115105280, mean_episode_return = 21.957, mean_episode_step = 1086.9, total_loss = 11.256, pg_loss = -13.026, baseline_loss = 29.966, entropy_loss = -5.6833, learner_queue_size = 32, _tick = 30072, _time = 1.6548e+09, train_seconds = 3.0154e+04)
[2022-06-10 04:30:39,574][root][INFO] - Step 115123200 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 115123200, mean_episode_return = 51.981, mean_episode_step = 987.81, total_loss = 76.327, pg_loss = 62.016, baseline_loss = 19.91, entropy_loss = -5.598, learner_queue_size = 32, _tick = 30076, _time = 1.6548e+09, train_seconds = 3.0159e+04)
[2022-06-10 04:30:44,578][root][INFO] - Step 115143680 @ 4092.8 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 115143680, mean_episode_return = None, mean_episode_step = 1132.2, total_loss = 43.829, pg_loss = 23.96, baseline_loss = 25.157, entropy_loss = -5.2881, learner_queue_size = 32, _tick = 30083, _time = 1.6548e+09, train_seconds = 3.0164e+04)
[2022-06-10 04:30:49,582][root][INFO] - Step 115164160 @ 4092.7 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 115164160, mean_episode_return = 108.92, mean_episode_step = 1127.3, total_loss = -118.3, pg_loss = -123.59, baseline_loss = 10.657, entropy_loss = -5.3662, learner_queue_size = 32, _tick = 30090, _time = 1.6548e+09, train_seconds = 3.0169e+04)
[2022-06-10 04:30:54,586][root][INFO] - Step 115182080 @ 3581.2 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 115182080, mean_episode_return = 77.335, mean_episode_step = 1187.0, total_loss = 93.851, pg_loss = 40.793, baseline_loss = 58.433, entropy_loss = -5.3751, learner_queue_size = 32, _tick = 30097, _time = 1.6548e+09, train_seconds = 3.0174e+04)
[2022-06-10 04:30:59,590][root][INFO] - Step 115202560 @ 4092.8 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 115202560, mean_episode_return = 124.31, mean_episode_step = 1289.6, total_loss = -175.66, pg_loss = -189.23, baseline_loss = 18.888, entropy_loss = -5.3216, learner_queue_size = 32, _tick = 30104, _time = 1.6548e+09, train_seconds = 3.0179e+04)
[2022-06-10 04:31:04,594][root][INFO] - Step 115223040 @ 4092.7 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 115223040, mean_episode_return = None, mean_episode_step = 1045.8, total_loss = 203.98, pg_loss = 153.48, baseline_loss = 55.696, entropy_loss = -5.1976, learner_queue_size = 32, _tick = 30110, _time = 1.6548e+09, train_seconds = 3.0184e+04)
[2022-06-10 04:31:09,598][root][INFO] - Step 115240960 @ 3581.1 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 115240960, mean_episode_return = None, mean_episode_step = 1190.9, total_loss = 41.521, pg_loss = 5.341, baseline_loss = 41.516, entropy_loss = -5.3364, learner_queue_size = 32, _tick = 30115, _time = 1.6548e+09, train_seconds = 3.0189e+04)
[2022-06-10 04:31:14,602][root][INFO] - Step 115261440 @ 4092.7 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 115261440, mean_episode_return = 26.88, mean_episode_step = 952.22, total_loss = -79.918, pg_loss = -118.54, baseline_loss = 43.977, entropy_loss = -5.3594, learner_queue_size = 32, _tick = 30123, _time = 1.6548e+09, train_seconds = 3.0194e+04)
[2022-06-10 04:31:19,606][root][INFO] - Step 115279360 @ 3581.2 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 115279360, mean_episode_return = 22.97, mean_episode_step = 1179.4, total_loss = -108.74, pg_loss = -119.13, baseline_loss = 15.895, entropy_loss = -5.5102, learner_queue_size = 32, _tick = 30129, _time = 1.6548e+09, train_seconds = 3.0199e+04)
[2022-06-10 04:31:24,610][root][INFO] - Step 115299840 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 115299840, mean_episode_return = 2.8797, mean_episode_step = 1064.1, total_loss = 117.0, pg_loss = 77.526, baseline_loss = 44.851, entropy_loss = -5.3793, learner_queue_size = 32, _tick = 30136, _time = 1.6548e+09, train_seconds = 3.0204e+04)
[2022-06-10 04:31:29,614][root][INFO] - Step 115320320 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 115320320, mean_episode_return = 89.399, mean_episode_step = 1076.6, total_loss = -170.91, pg_loss = -194.17, baseline_loss = 28.713, entropy_loss = -5.4515, learner_queue_size = 32, _tick = 30143, _time = 1.6548e+09, train_seconds = 3.0209e+04)
[2022-06-10 04:31:34,618][root][INFO] - Step 115338240 @ 3581.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 115338240, mean_episode_return = None, mean_episode_step = 1046.4, total_loss = 217.72, pg_loss = 148.81, baseline_loss = 74.339, entropy_loss = -5.4226, learner_queue_size = 32, _tick = 30148, _time = 1.6548e+09, train_seconds = 3.0214e+04)
[2022-06-10 04:31:39,622][root][INFO] - Step 115358720 @ 4092.8 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 115358720, mean_episode_return = 60.302, mean_episode_step = 1041.0, total_loss = -42.194, pg_loss = -113.46, baseline_loss = 76.514, entropy_loss = -5.2474, learner_queue_size = 32, _tick = 30154, _time = 1.6548e+09, train_seconds = 3.0219e+04)
[2022-06-10 04:31:44,626][root][INFO] - Step 115379200 @ 4092.7 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 115379200, mean_episode_return = None, mean_episode_step = 1032.5, total_loss = 94.576, pg_loss = 71.055, baseline_loss = 29.085, entropy_loss = -5.5641, learner_queue_size = 32, _tick = 30159, _time = 1.6548e+09, train_seconds = 3.0224e+04)
[2022-06-10 04:31:49,630][root][INFO] - Step 115397120 @ 3581.1 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 115397120, mean_episode_return = 139.28, mean_episode_step = 787.7, total_loss = 128.93, pg_loss = 80.216, baseline_loss = 54.328, entropy_loss = -5.6188, learner_queue_size = 32, _tick = 30166, _time = 1.6548e+09, train_seconds = 3.0229e+04)
[2022-06-10 04:31:54,634][root][INFO] - Step 115417600 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 115417600, mean_episode_return = 52.104, mean_episode_step = 961.53, total_loss = -70.921, pg_loss = -100.08, baseline_loss = 34.58, entropy_loss = -5.4179, learner_queue_size = 32, _tick = 30173, _time = 1.6548e+09, train_seconds = 3.0234e+04)
[2022-06-10 04:31:59,638][root][INFO] - Step 115438080 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 115438080, mean_episode_return = 163.56, mean_episode_step = 1218.9, total_loss = -86.612, pg_loss = -104.12, baseline_loss = 22.827, entropy_loss = -5.3218, learner_queue_size = 32, _tick = 30181, _time = 1.6548e+09, train_seconds = 3.0239e+04)
[2022-06-10 04:32:04,643][root][INFO] - Step 115456000 @ 3580.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 115456000, mean_episode_return = 56.15, mean_episode_step = 1071.9, total_loss = -27.491, pg_loss = -64.208, baseline_loss = 42.003, entropy_loss = -5.2865, learner_queue_size = 32, _tick = 30187, _time = 1.6548e+09, train_seconds = 3.0244e+04)
[2022-06-10 04:32:09,646][root][INFO] - Step 115476480 @ 4093.8 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 115476480, mean_episode_return = 42.36, mean_episode_step = 782.26, total_loss = 151.31, pg_loss = 89.281, baseline_loss = 67.335, entropy_loss = -5.3011, learner_queue_size = 32, _tick = 30190, _time = 1.6548e+09, train_seconds = 3.025e+04)
[2022-06-10 04:32:14,650][root][INFO] - Step 115494400 @ 3581.0 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 115494400, mean_episode_return = None, mean_episode_step = 1131.8, total_loss = 72.185, pg_loss = 39.325, baseline_loss = 38.288, entropy_loss = -5.4285, learner_queue_size = 32, _tick = 30194, _time = 1.6548e+09, train_seconds = 3.0254e+04)
[2022-06-10 04:32:19,654][root][INFO] - Step 115514880 @ 4093.0 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 115514880, mean_episode_return = 105.7, mean_episode_step = 1111.4, total_loss = -95.842, pg_loss = -133.38, baseline_loss = 42.889, entropy_loss = -5.3529, learner_queue_size = 32, _tick = 30201, _time = 1.6548e+09, train_seconds = 3.026e+04)
[2022-06-10 04:32:24,658][root][INFO] - Step 115532800 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 115532800, mean_episode_return = 80.004, mean_episode_step = 1038.9, total_loss = -195.63, pg_loss = -206.18, baseline_loss = 16.098, entropy_loss = -5.5468, learner_queue_size = 32, _tick = 30207, _time = 1.6548e+09, train_seconds = 3.0264e+04)
[2022-06-10 04:32:29,662][root][INFO] - Step 115553280 @ 4092.6 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 115553280, mean_episode_return = 38.611, mean_episode_step = 839.7, total_loss = -77.684, pg_loss = -108.47, baseline_loss = 36.28, entropy_loss = -5.4902, learner_queue_size = 32, _tick = 30214, _time = 1.6548e+09, train_seconds = 3.027e+04)
[2022-06-10 04:32:34,667][root][INFO] - Step 115573760 @ 4091.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 115573760, mean_episode_return = None, mean_episode_step = 1061.5, total_loss = -186.18, pg_loss = -194.33, baseline_loss = 13.885, entropy_loss = -5.7322, learner_queue_size = 32, _tick = 30218, _time = 1.6548e+09, train_seconds = 3.0274e+04)
[2022-06-10 04:32:39,670][root][INFO] - Step 115591680 @ 3582.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 115591680, mean_episode_return = 37.29, mean_episode_step = 954.36, total_loss = -50.823, pg_loss = -85.087, baseline_loss = 39.775, entropy_loss = -5.5109, learner_queue_size = 32, _tick = 30225, _time = 1.6548e+09, train_seconds = 3.028e+04)
[2022-06-10 04:32:44,674][root][INFO] - Step 115612160 @ 4092.8 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 115612160, mean_episode_return = None, mean_episode_step = 1056.6, total_loss = -11.064, pg_loss = -28.477, baseline_loss = 22.874, entropy_loss = -5.462, learner_queue_size = 32, _tick = 30229, _time = 1.6548e+09, train_seconds = 3.0284e+04)
[2022-06-10 04:32:49,680][root][INFO] - Step 115630080 @ 3579.8 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 115630080, mean_episode_return = None, mean_episode_step = 1060.1, total_loss = -91.535, pg_loss = -108.78, baseline_loss = 22.641, entropy_loss = -5.396, learner_queue_size = 32, _tick = 30235, _time = 1.6548e+09, train_seconds = 3.029e+04)
[2022-06-10 04:32:54,682][root][INFO] - Step 115650560 @ 4094.2 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 115650560, mean_episode_return = 34.971, mean_episode_step = 1102.0, total_loss = -126.31, pg_loss = -141.8, baseline_loss = 20.736, entropy_loss = -5.2408, learner_queue_size = 32, _tick = 30241, _time = 1.6548e+09, train_seconds = 3.0294e+04)
[2022-06-10 04:32:59,686][root][INFO] - Step 115671040 @ 4092.7 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 115671040, mean_episode_return = None, mean_episode_step = 1103.1, total_loss = 127.46, pg_loss = 85.037, baseline_loss = 47.738, entropy_loss = -5.3122, learner_queue_size = 32, _tick = 30247, _time = 1.6548e+09, train_seconds = 3.03e+04)
[2022-06-10 04:33:04,690][root][INFO] - Step 115688960 @ 3581.2 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 115688960, mean_episode_return = 92.339, mean_episode_step = 1234.3, total_loss = 31.34, pg_loss = 1.2129, baseline_loss = 35.511, entropy_loss = -5.3844, learner_queue_size = 32, _tick = 30252, _time = 1.6548e+09, train_seconds = 3.0304e+04)
[2022-06-10 04:33:09,694][root][INFO] - Step 115709440 @ 4092.7 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 115709440, mean_episode_return = 29.53, mean_episode_step = 1040.1, total_loss = 113.31, pg_loss = 4.9068, baseline_loss = 113.76, entropy_loss = -5.3585, learner_queue_size = 32, _tick = 30260, _time = 1.6548e+09, train_seconds = 3.031e+04)
[2022-06-10 04:33:14,698][root][INFO] - Step 115729920 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 115729920, mean_episode_return = 45.152, mean_episode_step = 1088.6, total_loss = -49.493, pg_loss = -67.788, baseline_loss = 23.694, entropy_loss = -5.3991, learner_queue_size = 32, _tick = 30268, _time = 1.6548e+09, train_seconds = 3.0314e+04)
[2022-06-10 04:33:19,702][root][INFO] - Step 115750400 @ 4092.7 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 115750400, mean_episode_return = 76.494, mean_episode_step = 1079.5, total_loss = 164.28, pg_loss = 117.89, baseline_loss = 51.869, entropy_loss = -5.4763, learner_queue_size = 32, _tick = 30276, _time = 1.6548e+09, train_seconds = 3.032e+04)
[2022-06-10 04:33:24,706][root][INFO] - Step 115768320 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 115768320, mean_episode_return = 61.79, mean_episode_step = 1115.3, total_loss = 17.517, pg_loss = -29.709, baseline_loss = 52.732, entropy_loss = -5.5058, learner_queue_size = 32, _tick = 30283, _time = 1.6548e+09, train_seconds = 3.0324e+04)
[2022-06-10 04:33:29,710][root][INFO] - Step 115788800 @ 4092.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 115788800, mean_episode_return = -1.35, mean_episode_step = 981.24, total_loss = 155.89, pg_loss = 99.459, baseline_loss = 61.894, entropy_loss = -5.46, learner_queue_size = 32, _tick = 30289, _time = 1.6548e+09, train_seconds = 3.033e+04)
[2022-06-10 04:33:34,714][root][INFO] - Step 115809280 @ 4092.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 115809280, mean_episode_return = 35.58, mean_episode_step = 1061.5, total_loss = 314.04, pg_loss = 237.58, baseline_loss = 81.985, entropy_loss = -5.5208, learner_queue_size = 32, _tick = 30296, _time = 1.6548e+09, train_seconds = 3.0334e+04)
[2022-06-10 04:33:39,718][root][INFO] - Step 115829760 @ 4092.8 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 115829760, mean_episode_return = 17.18, mean_episode_step = 1100.1, total_loss = -72.023, pg_loss = -80.916, baseline_loss = 14.425, entropy_loss = -5.5328, learner_queue_size = 32, _tick = 30304, _time = 1.6548e+09, train_seconds = 3.034e+04)
[2022-06-10 04:33:44,722][root][INFO] - Step 115847680 @ 3581.1 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 115847680, mean_episode_return = None, mean_episode_step = 1136.8, total_loss = 286.49, pg_loss = 228.81, baseline_loss = 63.142, entropy_loss = -5.4616, learner_queue_size = 32, _tick = 30309, _time = 1.6548e+09, train_seconds = 3.0344e+04)
[2022-06-10 04:33:49,726][root][INFO] - Step 115868160 @ 4092.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 115868160, mean_episode_return = 148.89, mean_episode_step = 993.26, total_loss = -96.375, pg_loss = -116.13, baseline_loss = 25.156, entropy_loss = -5.4029, learner_queue_size = 32, _tick = 30315, _time = 1.6548e+09, train_seconds = 3.035e+04)
[2022-06-10 04:33:54,730][root][INFO] - Step 115886080 @ 3581.4 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 115886080, mean_episode_return = 18.466, mean_episode_step = 1076.6, total_loss = -303.19, pg_loss = -329.05, baseline_loss = 31.274, entropy_loss = -5.4154, learner_queue_size = 32, _tick = 30321, _time = 1.6548e+09, train_seconds = 3.0354e+04)
[2022-06-10 04:33:59,734][root][INFO] - Step 115906560 @ 4092.7 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 115906560, mean_episode_return = 114.85, mean_episode_step = 1267.8, total_loss = 197.49, pg_loss = 107.56, baseline_loss = 95.462, entropy_loss = -5.5315, learner_queue_size = 32, _tick = 30327, _time = 1.6548e+09, train_seconds = 3.036e+04)
[2022-06-10 04:34:04,738][root][INFO] - Step 115927040 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 115927040, mean_episode_return = None, mean_episode_step = 1164.2, total_loss = -89.257, pg_loss = -101.59, baseline_loss = 18.069, entropy_loss = -5.7377, learner_queue_size = 32, _tick = 30334, _time = 1.6548e+09, train_seconds = 3.0364e+04)
[2022-06-10 04:34:09,744][root][INFO] - Step 115944960 @ 3579.6 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 115944960, mean_episode_return = 144.75, mean_episode_step = 1027.5, total_loss = 167.53, pg_loss = 99.537, baseline_loss = 73.608, entropy_loss = -5.6203, learner_queue_size = 32, _tick = 30338, _time = 1.6548e+09, train_seconds = 3.037e+04)
[2022-06-10 04:34:14,750][root][INFO] - Step 115965440 @ 4091.2 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 115965440, mean_episode_return = 21.72, mean_episode_step = 959.65, total_loss = 105.99, pg_loss = 64.806, baseline_loss = 46.631, entropy_loss = -5.4445, learner_queue_size = 32, _tick = 30346, _time = 1.6548e+09, train_seconds = 3.0375e+04)
[2022-06-10 04:34:19,754][root][INFO] - Step 115985920 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 115985920, mean_episode_return = 134.8, mean_episode_step = 1007.0, total_loss = -101.59, pg_loss = -116.58, baseline_loss = 20.505, entropy_loss = -5.5105, learner_queue_size = 32, _tick = 30352, _time = 1.6548e+09, train_seconds = 3.038e+04)
[2022-06-10 04:34:24,758][root][INFO] - Step 116006400 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 116006400, mean_episode_return = 56.9, mean_episode_step = 1275.3, total_loss = 44.576, pg_loss = 27.277, baseline_loss = 22.828, entropy_loss = -5.5282, learner_queue_size = 32, _tick = 30359, _time = 1.6548e+09, train_seconds = 3.0385e+04)
[2022-06-10 04:34:29,762][root][INFO] - Step 116024320 @ 3581.2 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 116024320, mean_episode_return = 29.77, mean_episode_step = 1046.6, total_loss = -158.51, pg_loss = -177.42, baseline_loss = 24.546, entropy_loss = -5.6311, learner_queue_size = 32, _tick = 30364, _time = 1.6548e+09, train_seconds = 3.039e+04)
[2022-06-10 04:34:34,766][root][INFO] - Step 116044800 @ 4092.6 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 116044800, mean_episode_return = None, mean_episode_step = 1162.9, total_loss = -30.387, pg_loss = -45.448, baseline_loss = 20.549, entropy_loss = -5.4884, learner_queue_size = 32, _tick = 30369, _time = 1.6548e+09, train_seconds = 3.0395e+04)
[2022-06-10 04:34:39,772][root][INFO] - Step 116062720 @ 3579.6 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (step = 116062720, mean_episode_return = 30.46, mean_episode_step = 1220.2, total_loss = -81.661, pg_loss = -98.351, baseline_loss = 22.286, entropy_loss = -5.5961, learner_queue_size = 32, _tick = 30375, _time = 1.6548e+09, train_seconds = 3.04e+04)
[2022-06-10 04:34:44,778][root][INFO] - Step 116083200 @ 4091.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 116083200, mean_episode_return = 49.023, mean_episode_step = 1109.8, total_loss = 120.94, pg_loss = 79.845, baseline_loss = 46.628, entropy_loss = -5.5364, learner_queue_size = 32, _tick = 30382, _time = 1.6548e+09, train_seconds = 3.0405e+04)
[2022-06-10 04:34:49,782][root][INFO] - Step 116103680 @ 4092.8 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 116103680, mean_episode_return = None, mean_episode_step = 1157.5, total_loss = -215.48, pg_loss = -231.04, baseline_loss = 21.03, entropy_loss = -5.4635, learner_queue_size = 32, _tick = 30387, _time = 1.6548e+09, train_seconds = 3.041e+04)
[2022-06-10 04:34:54,786][root][INFO] - Step 116124160 @ 4092.8 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 116124160, mean_episode_return = 53.871, mean_episode_step = 1200.7, total_loss = -78.945, pg_loss = -107.6, baseline_loss = 34.325, entropy_loss = -5.6698, learner_queue_size = 32, _tick = 30394, _time = 1.6548e+09, train_seconds = 3.0415e+04)
[2022-06-10 04:34:59,790][root][INFO] - Step 116144640 @ 4092.8 SPS. Inference batcher size: 83. Learner queue size: 32. Other stats: (step = 116144640, mean_episode_return = 42.201, mean_episode_step = 1257.2, total_loss = 56.751, pg_loss = 34.285, baseline_loss = 28.149, entropy_loss = -5.6828, learner_queue_size = 32, _tick = 30399, _time = 1.6548e+09, train_seconds = 3.042e+04)
[2022-06-10 04:35:04,794][root][INFO] - Step 116165120 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 116165120, mean_episode_return = 14.39, mean_episode_step = 884.22, total_loss = 323.65, pg_loss = 215.1, baseline_loss = 114.08, entropy_loss = -5.5335, learner_queue_size = 32, _tick = 30406, _time = 1.6548e+09, train_seconds = 3.0425e+04)
[2022-06-10 04:35:09,798][root][INFO] - Step 116183040 @ 3581.1 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 116183040, mean_episode_return = None, mean_episode_step = 1245.9, total_loss = 178.62, pg_loss = 122.93, baseline_loss = 61.379, entropy_loss = -5.6865, learner_queue_size = 32, _tick = 30409, _time = 1.6548e+09, train_seconds = 3.043e+04)
[2022-06-10 04:35:14,802][root][INFO] - Step 116203520 @ 4092.8 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 116203520, mean_episode_return = 16.48, mean_episode_step = 1228.0, total_loss = -5.0842, pg_loss = -17.129, baseline_loss = 17.615, entropy_loss = -5.57, learner_queue_size = 32, _tick = 30413, _time = 1.6548e+09, train_seconds = 3.0435e+04)
[2022-06-10 04:35:19,806][root][INFO] - Step 116224000 @ 4092.7 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (step = 116224000, mean_episode_return = None, mean_episode_step = 1283.8, total_loss = 319.73, pg_loss = 216.45, baseline_loss = 108.99, entropy_loss = -5.7018, learner_queue_size = 32, _tick = 30419, _time = 1.6548e+09, train_seconds = 3.044e+04)
[2022-06-10 04:35:24,810][root][INFO] - Step 116241920 @ 3581.1 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 116241920, mean_episode_return = 48.61, mean_episode_step = 1055.0, total_loss = -37.971, pg_loss = -100.28, baseline_loss = 67.962, entropy_loss = -5.6546, learner_queue_size = 32, _tick = 30425, _time = 1.6548e+09, train_seconds = 3.0445e+04)
[2022-06-10 04:35:29,815][root][INFO] - Step 116262400 @ 4092.3 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 116262400, mean_episode_return = 95.551, mean_episode_step = 1409.2, total_loss = -72.658, pg_loss = -89.372, baseline_loss = 22.654, entropy_loss = -5.9396, learner_queue_size = 32, _tick = 30431, _time = 1.6548e+09, train_seconds = 3.045e+04)
[2022-06-10 04:35:34,818][root][INFO] - Step 116280320 @ 3581.5 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 116280320, mean_episode_return = 32.887, mean_episode_step = 1129.9, total_loss = 381.54, pg_loss = 324.51, baseline_loss = 62.874, entropy_loss = -5.8476, learner_queue_size = 32, _tick = 30438, _time = 1.6548e+09, train_seconds = 3.0455e+04)
[2022-06-10 04:35:39,822][root][INFO] - Step 116300800 @ 4092.8 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 116300800, mean_episode_return = None, mean_episode_step = 1097.5, total_loss = 47.924, pg_loss = 8.0862, baseline_loss = 45.515, entropy_loss = -5.6766, learner_queue_size = 32, _tick = 30443, _time = 1.6548e+09, train_seconds = 3.046e+04)
[2022-06-10 04:35:44,826][root][INFO] - Step 116321280 @ 4092.7 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 116321280, mean_episode_return = 13.985, mean_episode_step = 1266.4, total_loss = 79.194, pg_loss = 54.92, baseline_loss = 30.009, entropy_loss = -5.7353, learner_queue_size = 32, _tick = 30450, _time = 1.6548e+09, train_seconds = 3.0465e+04)
[2022-06-10 04:35:49,830][root][INFO] - Step 116341760 @ 4092.6 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 116341760, mean_episode_return = None, mean_episode_step = 1032.2, total_loss = -49.096, pg_loss = -57.411, baseline_loss = 14.057, entropy_loss = -5.7416, learner_queue_size = 32, _tick = 30456, _time = 1.6548e+09, train_seconds = 3.047e+04)
[2022-06-10 04:35:54,834][root][INFO] - Step 116359680 @ 3581.2 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 116359680, mean_episode_return = 64.537, mean_episode_step = 1018.7, total_loss = 533.31, pg_loss = 191.17, baseline_loss = 347.75, entropy_loss = -5.6152, learner_queue_size = 32, _tick = 30463, _time = 1.6548e+09, train_seconds = 3.0475e+04)
[2022-06-10 04:35:59,838][root][INFO] - Step 116380160 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 116380160, mean_episode_return = 15.58, mean_episode_step = 1037.9, total_loss = -46.156, pg_loss = -74.046, baseline_loss = 33.316, entropy_loss = -5.4265, learner_queue_size = 32, _tick = 30467, _time = 1.6548e+09, train_seconds = 3.048e+04)
[2022-06-10 04:36:04,842][root][INFO] - Step 116400640 @ 4092.8 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 116400640, mean_episode_return = 85.397, mean_episode_step = 1131.4, total_loss = 131.99, pg_loss = 77.351, baseline_loss = 60.496, entropy_loss = -5.8565, learner_queue_size = 32, _tick = 30474, _time = 1.6548e+09, train_seconds = 3.0485e+04)
[2022-06-10 04:36:09,846][root][INFO] - Step 116421120 @ 4092.7 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 116421120, mean_episode_return = 26.196, mean_episode_step = 998.06, total_loss = 137.52, pg_loss = 98.015, baseline_loss = 45.152, entropy_loss = -5.6444, learner_queue_size = 32, _tick = 30477, _time = 1.6548e+09, train_seconds = 3.049e+04)
[2022-06-10 04:36:14,850][root][INFO] - Step 116439040 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 116439040, mean_episode_return = 23.246, mean_episode_step = 1187.7, total_loss = 31.337, pg_loss = -9.9855, baseline_loss = 46.691, entropy_loss = -5.3681, learner_queue_size = 32, _tick = 30481, _time = 1.6548e+09, train_seconds = 3.0495e+04)
[2022-06-10 04:36:19,854][root][INFO] - Step 116459520 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 116459520, mean_episode_return = 125.85, mean_episode_step = 804.4, total_loss = 20.489, pg_loss = -1.8242, baseline_loss = 27.563, entropy_loss = -5.2502, learner_queue_size = 32, _tick = 30488, _time = 1.6548e+09, train_seconds = 3.05e+04)
[2022-06-10 04:36:24,858][root][INFO] - Step 116480000 @ 4092.8 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 116480000, mean_episode_return = None, mean_episode_step = 1011.6, total_loss = 369.1, pg_loss = 266.55, baseline_loss = 107.88, entropy_loss = -5.3284, learner_queue_size = 32, _tick = 30492, _time = 1.6548e+09, train_seconds = 3.0505e+04)
[2022-06-10 04:36:29,863][root][INFO] - Step 116500480 @ 4092.3 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (step = 116500480, mean_episode_return = 125.87, mean_episode_step = 1131.6, total_loss = -23.939, pg_loss = -44.657, baseline_loss = 26.151, entropy_loss = -5.4331, learner_queue_size = 32, _tick = 30499, _time = 1.6548e+09, train_seconds = 3.051e+04)
[2022-06-10 04:36:34,866][root][INFO] - Step 116518400 @ 3581.5 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 116518400, mean_episode_return = 40.095, mean_episode_step = 1041.7, total_loss = -72.488, pg_loss = -104.35, baseline_loss = 37.207, entropy_loss = -5.3422, learner_queue_size = 32, _tick = 30504, _time = 1.6548e+09, train_seconds = 3.0515e+04)
[2022-06-10 04:36:39,870][root][INFO] - Step 116538880 @ 4092.3 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 116538880, mean_episode_return = 25.226, mean_episode_step = 1218.9, total_loss = 72.039, pg_loss = 26.068, baseline_loss = 51.303, entropy_loss = -5.3324, learner_queue_size = 32, _tick = 30511, _time = 1.6548e+09, train_seconds = 3.052e+04)
[2022-06-10 04:36:44,874][root][INFO] - Step 116559360 @ 4093.2 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 116559360, mean_episode_return = None, mean_episode_step = 1358.8, total_loss = 69.588, pg_loss = 27.653, baseline_loss = 47.432, entropy_loss = -5.4963, learner_queue_size = 32, _tick = 30514, _time = 1.6548e+09, train_seconds = 3.0525e+04)
[2022-06-10 04:36:49,878][root][INFO] - Step 116579840 @ 4092.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (step = 116579840, mean_episode_return = None, mean_episode_step = 1024.3, total_loss = 5.1004, pg_loss = -21.689, baseline_loss = 32.245, entropy_loss = -5.4557, learner_queue_size = 32, _tick = 30518, _time = 1.6548e+09, train_seconds = 3.053e+04)
[2022-06-10 04:36:54,882][root][INFO] - Step 116600320 @ 4092.7 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 116600320, mean_episode_return = -1.0503, mean_episode_step = 1275.7, total_loss = 28.483, pg_loss = -11.404, baseline_loss = 45.514, entropy_loss = -5.6282, learner_queue_size = 32, _tick = 30523, _time = 1.6548e+09, train_seconds = 3.0535e+04)
[2022-06-10 04:36:59,886][root][INFO] - Step 116618240 @ 3581.3 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 116618240, mean_episode_return = 41.427, mean_episode_step = 1235.4, total_loss = -70.817, pg_loss = -97.649, baseline_loss = 32.392, entropy_loss = -5.56, learner_queue_size = 32, _tick = 30528, _time = 1.6548e+09, train_seconds = 3.054e+04)
[2022-06-10 04:37:04,891][root][INFO] - Step 116638720 @ 4091.5 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 116638720, mean_episode_return = 20.0, mean_episode_step = 843.46, total_loss = 625.2, pg_loss = 472.41, baseline_loss = 158.25, entropy_loss = -5.4656, learner_queue_size = 32, _tick = 30534, _time = 1.6548e+09, train_seconds = 3.0545e+04)
[2022-06-10 04:37:09,897][root][INFO] - Step 116656640 @ 3579.8 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 116656640, mean_episode_return = None, mean_episode_step = 1388.8, total_loss = 66.716, pg_loss = 18.862, baseline_loss = 53.579, entropy_loss = -5.7254, learner_queue_size = 32, _tick = 30537, _time = 1.6548e+09, train_seconds = 3.055e+04)
[2022-06-10 04:37:14,902][root][INFO] - Step 116677120 @ 4092.2 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 116677120, mean_episode_return = 56.63, mean_episode_step = 1296.7, total_loss = 87.941, pg_loss = 53.149, baseline_loss = 40.323, entropy_loss = -5.5316, learner_queue_size = 32, _tick = 30543, _time = 1.6548e+09, train_seconds = 3.0555e+04)
[2022-06-10 04:37:19,909][root][INFO] - Step 116695040 @ 3579.3 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 116695040, mean_episode_return = 56.071, mean_episode_step = 1237.3, total_loss = 377.53, pg_loss = 283.25, baseline_loss = 99.718, entropy_loss = -5.4377, learner_queue_size = 32, _tick = 30548, _time = 1.6548e+09, train_seconds = 3.056e+04)
[2022-06-10 04:37:24,914][root][INFO] - Step 116715520 @ 4091.6 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 116715520, mean_episode_return = 43.8, mean_episode_step = 1301.5, total_loss = 55.346, pg_loss = 23.268, baseline_loss = 37.45, entropy_loss = -5.3721, learner_queue_size = 32, _tick = 30556, _time = 1.6548e+09, train_seconds = 3.0565e+04)
[2022-06-10 04:37:29,918][root][INFO] - Step 116736000 @ 4092.8 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 116736000, mean_episode_return = 96.401, mean_episode_step = 1482.1, total_loss = -142.3, pg_loss = -146.64, baseline_loss = 9.9534, entropy_loss = -5.6151, learner_queue_size = 32, _tick = 30562, _time = 1.6548e+09, train_seconds = 3.057e+04)
[2022-06-10 04:37:34,922][root][INFO] - Step 116753920 @ 3581.1 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (step = 116753920, mean_episode_return = 45.791, mean_episode_step = 1319.3, total_loss = 161.65, pg_loss = 98.213, baseline_loss = 69.115, entropy_loss = -5.682, learner_queue_size = 32, _tick = 30569, _time = 1.6548e+09, train_seconds = 3.0575e+04)
[2022-06-10 04:37:39,926][root][INFO] - Step 116774400 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 116774400, mean_episode_return = 159.0, mean_episode_step = 872.12, total_loss = -19.936, pg_loss = -47.69, baseline_loss = 33.237, entropy_loss = -5.4836, learner_queue_size = 32, _tick = 30575, _time = 1.6548e+09, train_seconds = 3.058e+04)
[2022-06-10 04:37:44,930][root][INFO] - Step 116794880 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 116794880, mean_episode_return = 122.82, mean_episode_step = 1172.3, total_loss = 126.94, pg_loss = 71.617, baseline_loss = 60.944, entropy_loss = -5.6245, learner_queue_size = 32, _tick = 30582, _time = 1.6548e+09, train_seconds = 3.0585e+04)
[2022-06-10 04:37:49,934][root][INFO] - Step 116815360 @ 4092.6 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 116815360, mean_episode_return = 49.32, mean_episode_step = 1066.9, total_loss = -82.203, pg_loss = -134.15, baseline_loss = 57.503, entropy_loss = -5.5522, learner_queue_size = 32, _tick = 30588, _time = 1.6548e+09, train_seconds = 3.059e+04)
[2022-06-10 04:37:54,938][root][INFO] - Step 116835840 @ 4092.8 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 116835840, mean_episode_return = 13.87, mean_episode_step = 1247.4, total_loss = -30.558, pg_loss = -62.78, baseline_loss = 37.613, entropy_loss = -5.3916, learner_queue_size = 32, _tick = 30594, _time = 1.6548e+09, train_seconds = 3.0595e+04)
[2022-06-10 04:37:59,942][root][INFO] - Step 116853760 @ 3581.2 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 116853760, mean_episode_return = None, mean_episode_step = 1237.5, total_loss = 147.23, pg_loss = 108.61, baseline_loss = 44.313, entropy_loss = -5.6937, learner_queue_size = 32, _tick = 30598, _time = 1.6548e+09, train_seconds = 3.06e+04)
[2022-06-10 04:38:04,946][root][INFO] - Step 116874240 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 116874240, mean_episode_return = 76.6, mean_episode_step = 920.47, total_loss = 59.168, pg_loss = 15.305, baseline_loss = 49.286, entropy_loss = -5.4233, learner_queue_size = 32, _tick = 30605, _time = 1.6548e+09, train_seconds = 3.0605e+04)
[2022-06-10 04:38:09,950][root][INFO] - Step 116894720 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 116894720, mean_episode_return = 56.04, mean_episode_step = 844.57, total_loss = -43.501, pg_loss = -94.687, baseline_loss = 56.527, entropy_loss = -5.3407, learner_queue_size = 32, _tick = 30613, _time = 1.6548e+09, train_seconds = 3.061e+04)
[2022-06-10 04:38:14,954][root][INFO] - Step 116915200 @ 4092.7 SPS. Inference batcher size: 81. Learner queue size: 32. Other stats: (step = 116915200, mean_episode_return = 70.767, mean_episode_step = 964.67, total_loss = 38.315, pg_loss = -43.353, baseline_loss = 86.906, entropy_loss = -5.2379, learner_queue_size = 32, _tick = 30620, _time = 1.6548e+09, train_seconds = 3.0615e+04)
[2022-06-10 04:38:19,959][root][INFO] - Step 116933120 @ 3580.7 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 116933120, mean_episode_return = 81.8, mean_episode_step = 962.13, total_loss = 218.1, pg_loss = 116.17, baseline_loss = 107.47, entropy_loss = -5.5368, learner_queue_size = 32, _tick = 30627, _time = 1.6548e+09, train_seconds = 3.062e+04)
[2022-06-10 04:38:24,964][root][INFO] - Step 116951040 @ 3579.8 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 116951040, mean_episode_return = 85.039, mean_episode_step = 792.72, total_loss = 216.59, pg_loss = 165.89, baseline_loss = 56.184, entropy_loss = -5.4878, learner_queue_size = 32, _tick = 30633, _time = 1.6548e+09, train_seconds = 3.0625e+04)
[2022-06-10 04:38:29,970][root][INFO] - Step 116971520 @ 4091.6 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 116971520, mean_episode_return = None, mean_episode_step = 864.81, total_loss = 3.3171, pg_loss = -13.867, baseline_loss = 22.757, entropy_loss = -5.5725, learner_queue_size = 32, _tick = 30639, _time = 1.6548e+09, train_seconds = 3.063e+04)
[2022-06-10 04:38:34,974][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 04:38:35,193][root][INFO] - Step 116989440 @ 3581.1 SPS. Inference batcher size: 88. Learner queue size: 32. Other stats: (step = 116992000, mean_episode_return = 56.851, mean_episode_step = 800.85, total_loss = 309.88, pg_loss = 237.1, baseline_loss = 78.392, entropy_loss = -5.6096, learner_queue_size = 32, _tick = 30646, _time = 1.6548e+09, train_seconds = 3.0635e+04)
[2022-06-10 04:38:40,198][root][INFO] - Step 117009920 @ 3920.4 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 117009920, mean_episode_return = None, mean_episode_step = 793.34, total_loss = 266.87, pg_loss = 206.98, baseline_loss = 65.325, entropy_loss = -5.4311, learner_queue_size = 32, _tick = 30652, _time = 1.6548e+09, train_seconds = 3.064e+04)
[2022-06-10 04:38:45,202][root][INFO] - Step 117030400 @ 4092.8 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 117030400, mean_episode_return = 86.471, mean_episode_step = 1069.3, total_loss = 135.05, pg_loss = 93.573, baseline_loss = 46.843, entropy_loss = -5.3703, learner_queue_size = 32, _tick = 30658, _time = 1.6548e+09, train_seconds = 3.0645e+04)
[2022-06-10 04:38:50,206][root][INFO] - Step 117048320 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 117048320, mean_episode_return = 54.37, mean_episode_step = 1056.2, total_loss = -9.8705, pg_loss = -41.308, baseline_loss = 36.845, entropy_loss = -5.4077, learner_queue_size = 32, _tick = 30663, _time = 1.6548e+09, train_seconds = 3.065e+04)
[2022-06-10 04:38:55,210][root][INFO] - Step 117068800 @ 4092.7 SPS. Inference batcher size: 91. Learner queue size: 32. Other stats: (step = 117068800, mean_episode_return = 114.67, mean_episode_step = 1185.8, total_loss = -12.869, pg_loss = -44.965, baseline_loss = 37.554, entropy_loss = -5.4584, learner_queue_size = 32, _tick = 30667, _time = 1.6548e+09, train_seconds = 3.0655e+04)
[2022-06-10 04:39:00,216][root][INFO] - Step 117086720 @ 3579.7 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 117086720, mean_episode_return = 63.281, mean_episode_step = 1020.9, total_loss = 33.201, pg_loss = 8.7219, baseline_loss = 30.102, entropy_loss = -5.6234, learner_queue_size = 32, _tick = 30671, _time = 1.6548e+09, train_seconds = 3.066e+04)
[2022-06-10 04:39:05,222][root][INFO] - Step 117107200 @ 4091.2 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 117107200, mean_episode_return = 20.845, mean_episode_step = 1044.2, total_loss = -142.49, pg_loss = -194.85, baseline_loss = 57.89, entropy_loss = -5.5223, learner_queue_size = 32, _tick = 30675, _time = 1.6548e+09, train_seconds = 3.0665e+04)
[2022-06-10 04:39:10,226][root][INFO] - Step 117125120 @ 3581.2 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 117125120, mean_episode_return = 52.08, mean_episode_step = 1165.1, total_loss = 46.713, pg_loss = 15.022, baseline_loss = 37.352, entropy_loss = -5.6605, learner_queue_size = 32, _tick = 30680, _time = 1.6548e+09, train_seconds = 3.067e+04)
[2022-06-10 04:39:15,232][root][INFO] - Step 117145600 @ 4091.4 SPS. Inference batcher size: 105. Learner queue size: 32. Other stats: (step = 117145600, mean_episode_return = 36.682, mean_episode_step = 1301.5, total_loss = -299.67, pg_loss = -341.71, baseline_loss = 47.401, entropy_loss = -5.3566, learner_queue_size = 32, _tick = 30684, _time = 1.6548e+09, train_seconds = 3.0675e+04)
[2022-06-10 04:39:20,234][root][INFO] - Step 117163520 @ 3582.3 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 117163520, mean_episode_return = 133.21, mean_episode_step = 1225.9, total_loss = 20.338, pg_loss = -27.99, baseline_loss = 53.732, entropy_loss = -5.4038, learner_queue_size = 32, _tick = 30689, _time = 1.6548e+09, train_seconds = 3.068e+04)
[2022-06-10 04:39:25,238][root][INFO] - Step 117184000 @ 4092.8 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 117184000, mean_episode_return = 8.1498, mean_episode_step = 1081.5, total_loss = -212.89, pg_loss = -224.08, baseline_loss = 16.504, entropy_loss = -5.3141, learner_queue_size = 32, _tick = 30696, _time = 1.6548e+09, train_seconds = 3.0685e+04)
[2022-06-10 04:39:30,242][root][INFO] - Step 117201920 @ 3581.1 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 117201920, mean_episode_return = 19.577, mean_episode_step = 1087.1, total_loss = 72.065, pg_loss = 5.5678, baseline_loss = 71.754, entropy_loss = -5.2567, learner_queue_size = 32, _tick = 30701, _time = 1.6548e+09, train_seconds = 3.069e+04)
[2022-06-10 04:39:35,246][root][INFO] - Step 117222400 @ 4092.8 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 117222400, mean_episode_return = 64.123, mean_episode_step = 813.07, total_loss = 113.02, pg_loss = 54.675, baseline_loss = 63.631, entropy_loss = -5.2815, learner_queue_size = 32, _tick = 30707, _time = 1.6548e+09, train_seconds = 3.0695e+04)
[2022-06-10 04:39:40,250][root][INFO] - Step 117242880 @ 4092.7 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 117242880, mean_episode_return = None, mean_episode_step = 1158.0, total_loss = -136.93, pg_loss = -143.74, baseline_loss = 12.16, entropy_loss = -5.3475, learner_queue_size = 32, _tick = 30712, _time = 1.6548e+09, train_seconds = 3.07e+04)
[2022-06-10 04:39:45,254][root][INFO] - Step 117260800 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 117260800, mean_episode_return = 69.977, mean_episode_step = 1122.0, total_loss = 126.04, pg_loss = 79.114, baseline_loss = 52.377, entropy_loss = -5.4473, learner_queue_size = 32, _tick = 30718, _time = 1.6548e+09, train_seconds = 3.0705e+04)
[2022-06-10 04:39:50,258][root][INFO] - Step 117281280 @ 4092.8 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 117281280, mean_episode_return = 59.624, mean_episode_step = 865.72, total_loss = 24.791, pg_loss = -16.035, baseline_loss = 46.481, entropy_loss = -5.655, learner_queue_size = 32, _tick = 30726, _time = 1.6548e+09, train_seconds = 3.071e+04)
[2022-06-10 04:39:55,264][root][INFO] - Step 117299200 @ 3579.5 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 117299200, mean_episode_return = 116.56, mean_episode_step = 1372.4, total_loss = -81.055, pg_loss = -89.609, baseline_loss = 14.274, entropy_loss = -5.72, learner_queue_size = 32, _tick = 30731, _time = 1.6548e+09, train_seconds = 3.0715e+04)
[2022-06-10 04:40:00,270][root][INFO] - Step 117319680 @ 4091.1 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 117319680, mean_episode_return = 53.609, mean_episode_step = 812.63, total_loss = 33.877, pg_loss = 10.8, baseline_loss = 28.738, entropy_loss = -5.6615, learner_queue_size = 32, _tick = 30737, _time = 1.6548e+09, train_seconds = 3.072e+04)
[2022-06-10 04:40:05,274][root][INFO] - Step 117337600 @ 3581.2 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (step = 117337600, mean_episode_return = None, mean_episode_step = 1009.0, total_loss = 329.73, pg_loss = 243.41, baseline_loss = 91.928, entropy_loss = -5.6075, learner_queue_size = 32, _tick = 30742, _time = 1.6548e+09, train_seconds = 3.0725e+04)
[2022-06-10 04:40:10,278][root][INFO] - Step 117358080 @ 4092.8 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 117358080, mean_episode_return = 21.55, mean_episode_step = 1109.1, total_loss = -43.218, pg_loss = -70.505, baseline_loss = 33.219, entropy_loss = -5.9318, learner_queue_size = 32, _tick = 30750, _time = 1.6548e+09, train_seconds = 3.073e+04)
[2022-06-10 04:40:15,282][root][INFO] - Step 117376000 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 117376000, mean_episode_return = 134.79, mean_episode_step = 750.47, total_loss = -44.289, pg_loss = -81.309, baseline_loss = 42.89, entropy_loss = -5.8704, learner_queue_size = 32, _tick = 30757, _time = 1.6548e+09, train_seconds = 3.0735e+04)
[2022-06-10 04:40:20,286][root][INFO] - Step 117396480 @ 4092.8 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (step = 117396480, mean_episode_return = 48.166, mean_episode_step = 1018.7, total_loss = -1.6224, pg_loss = -36.245, baseline_loss = 40.142, entropy_loss = -5.519, learner_queue_size = 32, _tick = 30765, _time = 1.6548e+09, train_seconds = 3.074e+04)
[2022-06-10 04:40:25,290][root][INFO] - Step 117416960 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 117416960, mean_episode_return = None, mean_episode_step = 898.06, total_loss = 331.27, pg_loss = 259.2, baseline_loss = 77.251, entropy_loss = -5.1843, learner_queue_size = 32, _tick = 30769, _time = 1.6548e+09, train_seconds = 3.0745e+04)
[2022-06-10 04:40:30,294][root][INFO] - Step 117437440 @ 4092.6 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 117437440, mean_episode_return = 47.739, mean_episode_step = 774.84, total_loss = 280.45, pg_loss = 185.0, baseline_loss = 100.71, entropy_loss = -5.266, learner_queue_size = 32, _tick = 30777, _time = 1.6548e+09, train_seconds = 3.075e+04)
[2022-06-10 04:40:35,298][root][INFO] - Step 117455360 @ 3581.2 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 117455360, mean_episode_return = 45.131, mean_episode_step = 1048.7, total_loss = 113.83, pg_loss = 59.268, baseline_loss = 59.88, entropy_loss = -5.3131, learner_queue_size = 32, _tick = 30781, _time = 1.6548e+09, train_seconds = 3.0755e+04)
[2022-06-10 04:40:40,302][root][INFO] - Step 117475840 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 117475840, mean_episode_return = None, mean_episode_step = 999.31, total_loss = -56.997, pg_loss = -74.105, baseline_loss = 22.352, entropy_loss = -5.2443, learner_queue_size = 32, _tick = 30782, _time = 1.6548e+09, train_seconds = 3.076e+04)
[2022-06-10 04:40:45,306][root][INFO] - Step 117496320 @ 4092.8 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 117496320, mean_episode_return = 34.041, mean_episode_step = 1147.4, total_loss = -84.698, pg_loss = -107.16, baseline_loss = 27.671, entropy_loss = -5.2075, learner_queue_size = 32, _tick = 30788, _time = 1.6548e+09, train_seconds = 3.0765e+04)
[2022-06-10 04:40:50,310][root][INFO] - Step 117516800 @ 4092.7 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 117516800, mean_episode_return = 26.034, mean_episode_step = 795.1, total_loss = -105.0, pg_loss = -168.59, baseline_loss = 68.761, entropy_loss = -5.1624, learner_queue_size = 32, _tick = 30794, _time = 1.6548e+09, train_seconds = 3.077e+04)
[2022-06-10 04:40:55,314][root][INFO] - Step 117534720 @ 3581.2 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 117534720, mean_episode_return = None, mean_episode_step = 976.0, total_loss = 244.58, pg_loss = 185.75, baseline_loss = 64.179, entropy_loss = -5.3456, learner_queue_size = 32, _tick = 30799, _time = 1.6548e+09, train_seconds = 3.0775e+04)
[2022-06-10 04:41:00,318][root][INFO] - Step 117555200 @ 4092.5 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 117555200, mean_episode_return = None, mean_episode_step = 1023.0, total_loss = 18.344, pg_loss = -10.125, baseline_loss = 33.902, entropy_loss = -5.4337, learner_queue_size = 32, _tick = 30805, _time = 1.6548e+09, train_seconds = 3.078e+04)
[2022-06-10 04:41:05,322][root][INFO] - Step 117575680 @ 4092.9 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 117575680, mean_episode_return = None, mean_episode_step = 1307.4, total_loss = 164.42, pg_loss = 126.65, baseline_loss = 43.19, entropy_loss = -5.4259, learner_queue_size = 32, _tick = 30809, _time = 1.6548e+09, train_seconds = 3.0785e+04)
[2022-06-10 04:41:10,326][root][INFO] - Step 117593600 @ 3581.0 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 117593600, mean_episode_return = None, mean_episode_step = 1288.0, total_loss = -4.756, pg_loss = -23.52, baseline_loss = 24.216, entropy_loss = -5.4526, learner_queue_size = 32, _tick = 30814, _time = 1.6548e+09, train_seconds = 3.079e+04)
[2022-06-10 04:41:15,330][root][INFO] - Step 117614080 @ 4093.0 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 117614080, mean_episode_return = 104.99, mean_episode_step = 1281.2, total_loss = 2.7412, pg_loss = -11.81, baseline_loss = 19.988, entropy_loss = -5.4375, learner_queue_size = 32, _tick = 30820, _time = 1.6548e+09, train_seconds = 3.0795e+04)
[2022-06-10 04:41:20,334][root][INFO] - Step 117634560 @ 4092.7 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 117634560, mean_episode_return = 46.811, mean_episode_step = 1033.6, total_loss = -36.121, pg_loss = -99.852, baseline_loss = 69.2, entropy_loss = -5.4694, learner_queue_size = 32, _tick = 30827, _time = 1.6548e+09, train_seconds = 3.08e+04)
[2022-06-10 04:41:25,338][root][INFO] - Step 117652480 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 117652480, mean_episode_return = 75.473, mean_episode_step = 1030.8, total_loss = 48.57, pg_loss = -3.8755, baseline_loss = 57.942, entropy_loss = -5.4963, learner_queue_size = 32, _tick = 30832, _time = 1.6548e+09, train_seconds = 3.0805e+04)
[2022-06-10 04:41:30,342][root][INFO] - Step 117672960 @ 4092.7 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 117672960, mean_episode_return = None, mean_episode_step = 1028.9, total_loss = -13.446, pg_loss = -43.909, baseline_loss = 36.076, entropy_loss = -5.6124, learner_queue_size = 32, _tick = 30838, _time = 1.6548e+09, train_seconds = 3.081e+04)
[2022-06-10 04:41:35,346][root][INFO] - Step 117690880 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 117690880, mean_episode_return = 59.001, mean_episode_step = 1162.5, total_loss = -12.903, pg_loss = -40.16, baseline_loss = 33.02, entropy_loss = -5.7637, learner_queue_size = 32, _tick = 30843, _time = 1.6548e+09, train_seconds = 3.0815e+04)
[2022-06-10 04:41:40,353][root][INFO] - Step 117711360 @ 4090.4 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 117711360, mean_episode_return = 45.073, mean_episode_step = 1118.7, total_loss = -19.016, pg_loss = -43.368, baseline_loss = 29.815, entropy_loss = -5.4638, learner_queue_size = 32, _tick = 30850, _time = 1.6548e+09, train_seconds = 3.082e+04)
[2022-06-10 04:41:45,358][root][INFO] - Step 117731840 @ 4091.9 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 117731840, mean_episode_return = 10.35, mean_episode_step = 1262.9, total_loss = 228.03, pg_loss = 159.76, baseline_loss = 73.817, entropy_loss = -5.5498, learner_queue_size = 32, _tick = 30855, _time = 1.6548e+09, train_seconds = 3.0825e+04)
[2022-06-10 04:41:50,364][root][INFO] - Step 117749760 @ 3579.5 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 117749760, mean_episode_return = 17.653, mean_episode_step = 1327.4, total_loss = -166.12, pg_loss = -207.7, baseline_loss = 47.339, entropy_loss = -5.7592, learner_queue_size = 32, _tick = 30859, _time = 1.6548e+09, train_seconds = 3.083e+04)
[2022-06-10 04:41:55,370][root][INFO] - Step 117770240 @ 4091.3 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 117770240, mean_episode_return = 32.68, mean_episode_step = 1421.7, total_loss = 196.52, pg_loss = 160.59, baseline_loss = 41.701, entropy_loss = -5.7778, learner_queue_size = 32, _tick = 30867, _time = 1.6548e+09, train_seconds = 3.0835e+04)
[2022-06-10 04:42:00,374][root][INFO] - Step 117788160 @ 3581.1 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 117788160, mean_episode_return = 121.86, mean_episode_step = 1208.9, total_loss = 83.479, pg_loss = 55.782, baseline_loss = 33.085, entropy_loss = -5.3887, learner_queue_size = 32, _tick = 30874, _time = 1.6548e+09, train_seconds = 3.084e+04)
[2022-06-10 04:42:05,378][root][INFO] - Step 117808640 @ 4092.8 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 117808640, mean_episode_return = None, mean_episode_step = 1281.3, total_loss = -129.74, pg_loss = -155.26, baseline_loss = 31.212, entropy_loss = -5.6916, learner_queue_size = 32, _tick = 30879, _time = 1.6548e+09, train_seconds = 3.0845e+04)
[2022-06-10 04:42:10,382][root][INFO] - Step 117829120 @ 4092.7 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 117829120, mean_episode_return = 81.276, mean_episode_step = 982.25, total_loss = 58.218, pg_loss = 27.958, baseline_loss = 35.727, entropy_loss = -5.4673, learner_queue_size = 32, _tick = 30887, _time = 1.6548e+09, train_seconds = 3.085e+04)
[2022-06-10 04:42:15,386][root][INFO] - Step 117849600 @ 4092.8 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 117849600, mean_episode_return = 54.351, mean_episode_step = 1024.8, total_loss = -8.6029, pg_loss = -46.899, baseline_loss = 43.72, entropy_loss = -5.4237, learner_queue_size = 32, _tick = 30894, _time = 1.6548e+09, train_seconds = 3.0855e+04)
[2022-06-10 04:42:20,390][root][INFO] - Step 117867520 @ 3581.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 117867520, mean_episode_return = 145.29, mean_episode_step = 1241.3, total_loss = -5.1699, pg_loss = -33.791, baseline_loss = 34.52, entropy_loss = -5.8985, learner_queue_size = 32, _tick = 30900, _time = 1.6548e+09, train_seconds = 3.086e+04)
[2022-06-10 04:42:25,394][root][INFO] - Step 117888000 @ 4092.7 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 117888000, mean_episode_return = 58.097, mean_episode_step = 1060.0, total_loss = -40.629, pg_loss = -54.287, baseline_loss = 19.501, entropy_loss = -5.8425, learner_queue_size = 32, _tick = 30908, _time = 1.6548e+09, train_seconds = 3.0865e+04)
[2022-06-10 04:42:30,398][root][INFO] - Step 117908480 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 117908480, mean_episode_return = 21.075, mean_episode_step = 996.28, total_loss = -88.853, pg_loss = -103.82, baseline_loss = 20.831, entropy_loss = -5.8686, learner_queue_size = 32, _tick = 30915, _time = 1.6548e+09, train_seconds = 3.087e+04)
[2022-06-10 04:42:35,402][root][INFO] - Step 117926400 @ 3581.1 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 117926400, mean_episode_return = 55.949, mean_episode_step = 726.33, total_loss = -29.577, pg_loss = -69.739, baseline_loss = 45.737, entropy_loss = -5.5746, learner_queue_size = 32, _tick = 30921, _time = 1.6548e+09, train_seconds = 3.0875e+04)
[2022-06-10 04:42:40,406][root][INFO] - Step 117946880 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 117946880, mean_episode_return = 65.7, mean_episode_step = 975.74, total_loss = 95.949, pg_loss = 59.625, baseline_loss = 42.162, entropy_loss = -5.837, learner_queue_size = 32, _tick = 30927, _time = 1.6548e+09, train_seconds = 3.088e+04)
[2022-06-10 04:42:45,411][root][INFO] - Step 117967360 @ 4092.1 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 117967360, mean_episode_return = 39.212, mean_episode_step = 1201.6, total_loss = 58.431, pg_loss = 18.297, baseline_loss = 45.818, entropy_loss = -5.6842, learner_queue_size = 32, _tick = 30933, _time = 1.6548e+09, train_seconds = 3.0885e+04)
[2022-06-10 04:42:50,414][root][INFO] - Step 117985280 @ 3581.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 117985280, mean_episode_return = 34.092, mean_episode_step = 1074.4, total_loss = 153.23, pg_loss = 84.217, baseline_loss = 74.695, entropy_loss = -5.6808, learner_queue_size = 32, _tick = 30939, _time = 1.6548e+09, train_seconds = 3.089e+04)
[2022-06-10 04:42:55,418][root][INFO] - Step 118005760 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 118005760, mean_episode_return = 18.895, mean_episode_step = 745.33, total_loss = 44.866, pg_loss = -2.1101, baseline_loss = 52.873, entropy_loss = -5.897, learner_queue_size = 32, _tick = 30946, _time = 1.6548e+09, train_seconds = 3.0895e+04)
[2022-06-10 04:43:00,422][root][INFO] - Step 118026240 @ 4092.8 SPS. Inference batcher size: 91. Learner queue size: 32. Other stats: (step = 118026240, mean_episode_return = None, mean_episode_step = 1057.2, total_loss = 31.54, pg_loss = 0.40729, baseline_loss = 36.854, entropy_loss = -5.7208, learner_queue_size = 32, _tick = 30952, _time = 1.6548e+09, train_seconds = 3.09e+04)
[2022-06-10 04:43:05,426][root][INFO] - Step 118044160 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 118044160, mean_episode_return = 22.22, mean_episode_step = 698.38, total_loss = 491.85, pg_loss = 354.83, baseline_loss = 142.73, entropy_loss = -5.7035, learner_queue_size = 32, _tick = 30958, _time = 1.6548e+09, train_seconds = 3.0905e+04)
[2022-06-10 04:43:10,430][root][INFO] - Step 118064640 @ 4092.8 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 118064640, mean_episode_return = 115.62, mean_episode_step = 1201.6, total_loss = -9.3475, pg_loss = -31.25, baseline_loss = 27.609, entropy_loss = -5.7068, learner_queue_size = 32, _tick = 30965, _time = 1.6548e+09, train_seconds = 3.091e+04)
[2022-06-10 04:43:15,434][root][INFO] - Step 118082560 @ 3581.1 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 118082560, mean_episode_return = 21.345, mean_episode_step = 1017.5, total_loss = 258.65, pg_loss = 186.88, baseline_loss = 77.344, entropy_loss = -5.5679, learner_queue_size = 32, _tick = 30971, _time = 1.6548e+09, train_seconds = 3.0915e+04)
[2022-06-10 04:43:20,438][root][INFO] - Step 118103040 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 118103040, mean_episode_return = 46.39, mean_episode_step = 943.48, total_loss = 73.283, pg_loss = -3.2039, baseline_loss = 82.115, entropy_loss = -5.6275, learner_queue_size = 32, _tick = 30978, _time = 1.6548e+09, train_seconds = 3.092e+04)
[2022-06-10 04:43:25,442][root][INFO] - Step 118123520 @ 4092.7 SPS. Inference batcher size: 80. Learner queue size: 32. Other stats: (step = 118123520, mean_episode_return = 6.9848, mean_episode_step = 936.84, total_loss = 215.91, pg_loss = 99.015, baseline_loss = 122.35, entropy_loss = -5.4631, learner_queue_size = 32, _tick = 30985, _time = 1.6548e+09, train_seconds = 3.0925e+04)
[2022-06-10 04:43:30,447][root][INFO] - Step 118141440 @ 3580.3 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 118141440, mean_episode_return = 76.35, mean_episode_step = 999.28, total_loss = 180.71, pg_loss = 110.7, baseline_loss = 75.524, entropy_loss = -5.5089, learner_queue_size = 32, _tick = 30989, _time = 1.6548e+09, train_seconds = 3.093e+04)
[2022-06-10 04:43:35,450][root][INFO] - Step 118161920 @ 4093.6 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 118161920, mean_episode_return = 41.413, mean_episode_step = 1000.3, total_loss = -244.48, pg_loss = -259.64, baseline_loss = 21.054, entropy_loss = -5.8916, learner_queue_size = 32, _tick = 30994, _time = 1.6548e+09, train_seconds = 3.0935e+04)
[2022-06-10 04:43:40,454][root][INFO] - Step 118179840 @ 3581.2 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 118179840, mean_episode_return = 45.676, mean_episode_step = 898.63, total_loss = 32.354, pg_loss = -34.357, baseline_loss = 72.534, entropy_loss = -5.8227, learner_queue_size = 32, _tick = 31000, _time = 1.6548e+09, train_seconds = 3.094e+04)
[2022-06-10 04:43:45,458][root][INFO] - Step 118200320 @ 4092.8 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 118200320, mean_episode_return = 131.01, mean_episode_step = 1055.9, total_loss = -177.64, pg_loss = -189.3, baseline_loss = 17.548, entropy_loss = -5.8862, learner_queue_size = 32, _tick = 31007, _time = 1.6548e+09, train_seconds = 3.0945e+04)
[2022-06-10 04:43:50,464][root][INFO] - Step 118218240 @ 3579.9 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 118218240, mean_episode_return = 94.928, mean_episode_step = 1097.0, total_loss = 128.46, pg_loss = 76.278, baseline_loss = 57.834, entropy_loss = -5.6475, learner_queue_size = 32, _tick = 31011, _time = 1.6548e+09, train_seconds = 3.095e+04)
[2022-06-10 04:43:55,466][root][INFO] - Step 118238720 @ 4094.1 SPS. Inference batcher size: 84. Learner queue size: 32. Other stats: (step = 118238720, mean_episode_return = 70.306, mean_episode_step = 1018.6, total_loss = -22.89, pg_loss = -53.574, baseline_loss = 36.622, entropy_loss = -5.9378, learner_queue_size = 32, _tick = 31019, _time = 1.6548e+09, train_seconds = 3.0955e+04)
[2022-06-10 04:44:00,470][root][INFO] - Step 118259200 @ 4092.7 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 118259200, mean_episode_return = 135.03, mean_episode_step = 1266.6, total_loss = -104.11, pg_loss = -121.75, baseline_loss = 23.831, entropy_loss = -6.1939, learner_queue_size = 32, _tick = 31024, _time = 1.6548e+09, train_seconds = 3.096e+04)
[2022-06-10 04:44:05,474][root][INFO] - Step 118277120 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 118277120, mean_episode_return = -18.15, mean_episode_step = 858.59, total_loss = -38.794, pg_loss = -61.657, baseline_loss = 28.656, entropy_loss = -5.7922, learner_queue_size = 32, _tick = 31030, _time = 1.6548e+09, train_seconds = 3.0965e+04)
[2022-06-10 04:44:10,478][root][INFO] - Step 118297600 @ 4092.7 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 118297600, mean_episode_return = 20.625, mean_episode_step = 942.76, total_loss = 180.6, pg_loss = 116.27, baseline_loss = 70.068, entropy_loss = -5.7287, learner_queue_size = 32, _tick = 31036, _time = 1.6548e+09, train_seconds = 3.097e+04)
[2022-06-10 04:44:15,482][root][INFO] - Step 118315520 @ 3581.2 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 118315520, mean_episode_return = 128.97, mean_episode_step = 956.58, total_loss = 19.05, pg_loss = -13.747, baseline_loss = 38.472, entropy_loss = -5.6752, learner_queue_size = 32, _tick = 31042, _time = 1.6548e+09, train_seconds = 3.0975e+04)
[2022-06-10 04:44:20,486][root][INFO] - Step 118336000 @ 4092.7 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 118336000, mean_episode_return = 60.491, mean_episode_step = 1094.7, total_loss = 244.89, pg_loss = 164.77, baseline_loss = 85.927, entropy_loss = -5.8151, learner_queue_size = 32, _tick = 31048, _time = 1.6548e+09, train_seconds = 3.098e+04)
[2022-06-10 04:44:25,490][root][INFO] - Step 118356480 @ 4092.7 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 118356480, mean_episode_return = 134.82, mean_episode_step = 954.62, total_loss = 212.23, pg_loss = 162.11, baseline_loss = 55.712, entropy_loss = -5.5967, learner_queue_size = 32, _tick = 31054, _time = 1.6548e+09, train_seconds = 3.0985e+04)
[2022-06-10 04:44:30,494][root][INFO] - Step 118374400 @ 3581.1 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 118374400, mean_episode_return = 60.91, mean_episode_step = 1016.2, total_loss = -134.59, pg_loss = -162.86, baseline_loss = 33.967, entropy_loss = -5.695, learner_queue_size = 32, _tick = 31061, _time = 1.6548e+09, train_seconds = 3.099e+04)
[2022-06-10 04:44:35,498][root][INFO] - Step 118394880 @ 4092.8 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 118394880, mean_episode_return = 57.065, mean_episode_step = 1006.5, total_loss = -84.522, pg_loss = -108.72, baseline_loss = 29.804, entropy_loss = -5.6071, learner_queue_size = 32, _tick = 31067, _time = 1.6548e+09, train_seconds = 3.0995e+04)
[2022-06-10 04:44:40,502][root][INFO] - Step 118415360 @ 4092.7 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 118415360, mean_episode_return = None, mean_episode_step = 1089.6, total_loss = -149.72, pg_loss = -168.11, baseline_loss = 24.093, entropy_loss = -5.6941, learner_queue_size = 32, _tick = 31072, _time = 1.6548e+09, train_seconds = 3.1e+04)
[2022-06-10 04:44:45,506][root][INFO] - Step 118433280 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 118433280, mean_episode_return = 38.349, mean_episode_step = 1202.2, total_loss = 267.13, pg_loss = 198.46, baseline_loss = 74.58, entropy_loss = -5.906, learner_queue_size = 32, _tick = 31078, _time = 1.6548e+09, train_seconds = 3.1005e+04)
[2022-06-10 04:44:50,510][root][INFO] - Step 118453760 @ 4092.7 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 118453760, mean_episode_return = 38.87, mean_episode_step = 1037.9, total_loss = 998.24, pg_loss = 286.59, baseline_loss = 717.7, entropy_loss = -6.0515, learner_queue_size = 32, _tick = 31084, _time = 1.6548e+09, train_seconds = 3.101e+04)
[2022-06-10 04:44:55,514][root][INFO] - Step 118471680 @ 3581.1 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 118471680, mean_episode_return = 76.669, mean_episode_step = 1097.8, total_loss = 22.719, pg_loss = -34.351, baseline_loss = 63.123, entropy_loss = -6.0524, learner_queue_size = 32, _tick = 31090, _time = 1.6548e+09, train_seconds = 3.1015e+04)
[2022-06-10 04:45:00,518][root][INFO] - Step 118492160 @ 4092.8 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 118492160, mean_episode_return = None, mean_episode_step = 1000.4, total_loss = 347.71, pg_loss = 225.28, baseline_loss = 128.21, entropy_loss = -5.773, learner_queue_size = 32, _tick = 31097, _time = 1.6548e+09, train_seconds = 3.102e+04)
[2022-06-10 04:45:05,522][root][INFO] - Step 118512640 @ 4092.6 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 118512640, mean_episode_return = 152.59, mean_episode_step = 785.54, total_loss = -110.1, pg_loss = -143.82, baseline_loss = 39.319, entropy_loss = -5.6073, learner_queue_size = 32, _tick = 31105, _time = 1.6548e+09, train_seconds = 3.1025e+04)
[2022-06-10 04:45:10,526][root][INFO] - Step 118530560 @ 3581.3 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 118530560, mean_episode_return = 42.546, mean_episode_step = 929.7, total_loss = -57.032, pg_loss = -98.728, baseline_loss = 47.426, entropy_loss = -5.7294, learner_queue_size = 32, _tick = 31110, _time = 1.6548e+09, train_seconds = 3.103e+04)
[2022-06-10 04:45:15,530][root][INFO] - Step 118551040 @ 4092.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 118551040, mean_episode_return = 65.953, mean_episode_step = 985.04, total_loss = 102.47, pg_loss = -19.507, baseline_loss = 127.78, entropy_loss = -5.7971, learner_queue_size = 32, _tick = 31115, _time = 1.6548e+09, train_seconds = 3.1035e+04)
[2022-06-10 04:45:20,534][root][INFO] - Step 118568960 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 118568960, mean_episode_return = 85.727, mean_episode_step = 860.44, total_loss = 26.512, pg_loss = -22.227, baseline_loss = 54.306, entropy_loss = -5.5666, learner_queue_size = 32, _tick = 31122, _time = 1.6548e+09, train_seconds = 3.104e+04)
[2022-06-10 04:45:25,538][root][INFO] - Step 118589440 @ 4092.7 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 118589440, mean_episode_return = 35.371, mean_episode_step = 751.44, total_loss = 131.06, pg_loss = 35.572, baseline_loss = 100.99, entropy_loss = -5.5012, learner_queue_size = 32, _tick = 31130, _time = 1.6548e+09, train_seconds = 3.1045e+04)
[2022-06-10 04:45:30,542][root][INFO] - Step 118609920 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 118609920, mean_episode_return = None, mean_episode_step = 990.16, total_loss = -118.51, pg_loss = -132.66, baseline_loss = 19.779, entropy_loss = -5.6326, learner_queue_size = 32, _tick = 31135, _time = 1.6548e+09, train_seconds = 3.105e+04)
[2022-06-10 04:45:35,546][root][INFO] - Step 118627840 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 118627840, mean_episode_return = 36.721, mean_episode_step = 1004.2, total_loss = 56.756, pg_loss = 16.238, baseline_loss = 46.215, entropy_loss = -5.6971, learner_queue_size = 32, _tick = 31141, _time = 1.6548e+09, train_seconds = 3.1055e+04)
[2022-06-10 04:45:40,550][root][INFO] - Step 118648320 @ 4092.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 118648320, mean_episode_return = 41.271, mean_episode_step = 1214.0, total_loss = -14.794, pg_loss = -38.594, baseline_loss = 29.402, entropy_loss = -5.6025, learner_queue_size = 32, _tick = 31148, _time = 1.6548e+09, train_seconds = 3.106e+04)
[2022-06-10 04:45:45,554][root][INFO] - Step 118668800 @ 4092.8 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 118668800, mean_episode_return = 81.45, mean_episode_step = 1015.5, total_loss = 31.997, pg_loss = 2.5647, baseline_loss = 34.902, entropy_loss = -5.4695, learner_queue_size = 32, _tick = 31154, _time = 1.6548e+09, train_seconds = 3.1065e+04)
[2022-06-10 04:45:50,558][root][INFO] - Step 118686720 @ 3581.1 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 118686720, mean_episode_return = 64.32, mean_episode_step = 836.12, total_loss = 274.3, pg_loss = 188.79, baseline_loss = 91.053, entropy_loss = -5.538, learner_queue_size = 32, _tick = 31161, _time = 1.6548e+09, train_seconds = 3.107e+04)
[2022-06-10 04:45:55,562][root][INFO] - Step 118707200 @ 4092.8 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 118707200, mean_episode_return = 23.54, mean_episode_step = 1204.7, total_loss = 105.33, pg_loss = 50.863, baseline_loss = 59.981, entropy_loss = -5.516, learner_queue_size = 32, _tick = 31164, _time = 1.6548e+09, train_seconds = 3.1075e+04)
[2022-06-10 04:46:00,566][root][INFO] - Step 118725120 @ 3581.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 118725120, mean_episode_return = 62.721, mean_episode_step = 1015.5, total_loss = 10.528, pg_loss = -32.473, baseline_loss = 48.394, entropy_loss = -5.3937, learner_queue_size = 32, _tick = 31171, _time = 1.6548e+09, train_seconds = 3.108e+04)
[2022-06-10 04:46:05,570][root][INFO] - Step 118745600 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 118745600, mean_episode_return = 29.536, mean_episode_step = 1113.6, total_loss = -61.374, pg_loss = -96.834, baseline_loss = 41.062, entropy_loss = -5.6033, learner_queue_size = 32, _tick = 31177, _time = 1.6548e+09, train_seconds = 3.1085e+04)
[2022-06-10 04:46:10,574][root][INFO] - Step 118763520 @ 3581.2 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 118763520, mean_episode_return = None, mean_episode_step = 1299.4, total_loss = 101.91, pg_loss = 71.902, baseline_loss = 35.809, entropy_loss = -5.8032, learner_queue_size = 32, _tick = 31181, _time = 1.6548e+09, train_seconds = 3.109e+04)
[2022-06-10 04:46:15,579][root][INFO] - Step 118784000 @ 4091.8 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 118784000, mean_episode_return = 50.83, mean_episode_step = 979.62, total_loss = 187.57, pg_loss = 131.3, baseline_loss = 61.998, entropy_loss = -5.7301, learner_queue_size = 32, _tick = 31187, _time = 1.6548e+09, train_seconds = 3.1095e+04)
[2022-06-10 04:46:20,582][root][INFO] - Step 118801920 @ 3582.0 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 118801920, mean_episode_return = None, mean_episode_step = 1060.7, total_loss = 13.8, pg_loss = -1.5772, baseline_loss = 21.036, entropy_loss = -5.6582, learner_queue_size = 32, _tick = 31192, _time = 1.6548e+09, train_seconds = 3.11e+04)
[2022-06-10 04:46:25,586][root][INFO] - Step 118822400 @ 4092.7 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 118822400, mean_episode_return = 77.564, mean_episode_step = 1035.7, total_loss = 93.73, pg_loss = 46.93, baseline_loss = 52.379, entropy_loss = -5.5799, learner_queue_size = 32, _tick = 31199, _time = 1.6548e+09, train_seconds = 3.1105e+04)
[2022-06-10 04:46:30,590][root][INFO] - Step 118840320 @ 3581.2 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 118840320, mean_episode_return = 15.485, mean_episode_step = 1189.3, total_loss = 470.46, pg_loss = 308.1, baseline_loss = 168.01, entropy_loss = -5.6391, learner_queue_size = 32, _tick = 31203, _time = 1.6548e+09, train_seconds = 3.111e+04)
[2022-06-10 04:46:35,594][root][INFO] - Step 118860800 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 118860800, mean_episode_return = 15.32, mean_episode_step = 1336.1, total_loss = -293.42, pg_loss = -310.74, baseline_loss = 23.039, entropy_loss = -5.7152, learner_queue_size = 32, _tick = 31210, _time = 1.6548e+09, train_seconds = 3.1115e+04)
[2022-06-10 04:46:40,598][root][INFO] - Step 118878720 @ 3581.1 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 118878720, mean_episode_return = 72.684, mean_episode_step = 1250.1, total_loss = -237.65, pg_loss = -293.68, baseline_loss = 61.509, entropy_loss = -5.4788, learner_queue_size = 32, _tick = 31216, _time = 1.6548e+09, train_seconds = 3.112e+04)
[2022-06-10 04:46:45,602][root][INFO] - Step 118896640 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 118896640, mean_episode_return = 118.15, mean_episode_step = 1204.8, total_loss = -134.53, pg_loss = -142.89, baseline_loss = 14.064, entropy_loss = -5.7036, learner_queue_size = 32, _tick = 31221, _time = 1.6548e+09, train_seconds = 3.1125e+04)
[2022-06-10 04:46:50,606][root][INFO] - Step 118917120 @ 4092.6 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 118917120, mean_episode_return = 78.065, mean_episode_step = 919.65, total_loss = 133.8, pg_loss = 105.31, baseline_loss = 33.942, entropy_loss = -5.451, learner_queue_size = 32, _tick = 31227, _time = 1.6548e+09, train_seconds = 3.113e+04)
[2022-06-10 04:46:55,610][root][INFO] - Step 118937600 @ 4092.8 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 118937600, mean_episode_return = None, mean_episode_step = 983.16, total_loss = 471.47, pg_loss = 357.91, baseline_loss = 119.04, entropy_loss = -5.4852, learner_queue_size = 32, _tick = 31229, _time = 1.6548e+09, train_seconds = 3.1135e+04)
[2022-06-10 04:47:00,614][root][INFO] - Step 118958080 @ 4092.6 SPS. Inference batcher size: 77. Learner queue size: 32. Other stats: (step = 118958080, mean_episode_return = 85.879, mean_episode_step = 1202.6, total_loss = -160.8, pg_loss = -172.39, baseline_loss = 17.413, entropy_loss = -5.8263, learner_queue_size = 32, _tick = 31237, _time = 1.6548e+09, train_seconds = 3.114e+04)
[2022-06-10 04:47:05,618][root][INFO] - Step 118976000 @ 3581.2 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 118976000, mean_episode_return = 59.54, mean_episode_step = 831.76, total_loss = 220.8, pg_loss = 107.99, baseline_loss = 118.57, entropy_loss = -5.7659, learner_queue_size = 32, _tick = 31243, _time = 1.6548e+09, train_seconds = 3.1145e+04)
[2022-06-10 04:47:10,622][root][INFO] - Step 118996480 @ 4092.7 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 118996480, mean_episode_return = 50.873, mean_episode_step = 926.14, total_loss = -164.17, pg_loss = -201.14, baseline_loss = 42.554, entropy_loss = -5.5797, learner_queue_size = 32, _tick = 31251, _time = 1.6548e+09, train_seconds = 3.115e+04)
[2022-06-10 04:47:15,626][root][INFO] - Step 119016960 @ 4092.8 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 119016960, mean_episode_return = 4.3197, mean_episode_step = 1143.9, total_loss = 265.69, pg_loss = 186.13, baseline_loss = 85.182, entropy_loss = -5.6228, learner_queue_size = 32, _tick = 31257, _time = 1.6548e+09, train_seconds = 3.1155e+04)
[2022-06-10 04:47:20,632][root][INFO] - Step 119037440 @ 4091.2 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 119037440, mean_episode_return = 95.39, mean_episode_step = 881.4, total_loss = 84.437, pg_loss = 24.786, baseline_loss = 65.108, entropy_loss = -5.4572, learner_queue_size = 32, _tick = 31264, _time = 1.6548e+09, train_seconds = 3.116e+04)
[2022-06-10 04:47:25,638][root][INFO] - Step 119055360 @ 3579.6 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 119055360, mean_episode_return = 51.395, mean_episode_step = 955.45, total_loss = -95.415, pg_loss = -112.38, baseline_loss = 22.428, entropy_loss = -5.4597, learner_queue_size = 32, _tick = 31267, _time = 1.6548e+09, train_seconds = 3.1165e+04)
[2022-06-10 04:47:30,642][root][INFO] - Step 119075840 @ 4092.7 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 119075840, mean_episode_return = 26.015, mean_episode_step = 1168.8, total_loss = -6.631, pg_loss = -107.62, baseline_loss = 106.62, entropy_loss = -5.6269, learner_queue_size = 32, _tick = 31273, _time = 1.6548e+09, train_seconds = 3.117e+04)
[2022-06-10 04:47:35,647][root][INFO] - Step 119096320 @ 4091.9 SPS. Inference batcher size: 76. Learner queue size: 32. Other stats: (step = 119096320, mean_episode_return = 108.06, mean_episode_step = 1251.2, total_loss = 53.241, pg_loss = -20.318, baseline_loss = 79.348, entropy_loss = -5.7893, learner_queue_size = 32, _tick = 31280, _time = 1.6548e+09, train_seconds = 3.1176e+04)
[2022-06-10 04:47:40,650][root][INFO] - Step 119114240 @ 3581.9 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 119114240, mean_episode_return = 33.766, mean_episode_step = 1374.4, total_loss = 79.225, pg_loss = 42.423, baseline_loss = 42.723, entropy_loss = -5.9213, learner_queue_size = 32, _tick = 31285, _time = 1.6548e+09, train_seconds = 3.118e+04)
[2022-06-10 04:47:45,654][root][INFO] - Step 119134720 @ 4092.7 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 119134720, mean_episode_return = 27.991, mean_episode_step = 1245.1, total_loss = -132.45, pg_loss = -157.52, baseline_loss = 30.925, entropy_loss = -5.8527, learner_queue_size = 32, _tick = 31290, _time = 1.6548e+09, train_seconds = 3.1186e+04)
[2022-06-10 04:47:50,658][root][INFO] - Step 119155200 @ 4092.8 SPS. Inference batcher size: 81. Learner queue size: 32. Other stats: (step = 119155200, mean_episode_return = 99.17, mean_episode_step = 1066.8, total_loss = -69.399, pg_loss = -79.035, baseline_loss = 15.53, entropy_loss = -5.8938, learner_queue_size = 32, _tick = 31296, _time = 1.6548e+09, train_seconds = 3.119e+04)
[2022-06-10 04:47:55,662][root][INFO] - Step 119173120 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 119173120, mean_episode_return = None, mean_episode_step = 1124.1, total_loss = 222.21, pg_loss = 171.58, baseline_loss = 56.299, entropy_loss = -5.677, learner_queue_size = 32, _tick = 31301, _time = 1.6548e+09, train_seconds = 3.1196e+04)
[2022-06-10 04:48:00,666][root][INFO] - Step 119191040 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 119191040, mean_episode_return = 126.34, mean_episode_step = 1412.9, total_loss = 333.97, pg_loss = 275.17, baseline_loss = 64.436, entropy_loss = -5.6384, learner_queue_size = 32, _tick = 31308, _time = 1.6548e+09, train_seconds = 3.12e+04)
[2022-06-10 04:48:05,670][root][INFO] - Step 119211520 @ 4092.8 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 119211520, mean_episode_return = 11.54, mean_episode_step = 1010.7, total_loss = 194.54, pg_loss = 87.594, baseline_loss = 112.55, entropy_loss = -5.6111, learner_queue_size = 32, _tick = 31314, _time = 1.6548e+09, train_seconds = 3.1206e+04)
[2022-06-10 04:48:10,674][root][INFO] - Step 119229440 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 119229440, mean_episode_return = 93.231, mean_episode_step = 946.73, total_loss = -14.263, pg_loss = -62.589, baseline_loss = 53.879, entropy_loss = -5.5524, learner_queue_size = 32, _tick = 31321, _time = 1.6548e+09, train_seconds = 3.121e+04)
[2022-06-10 04:48:15,678][root][INFO] - Step 119249920 @ 4092.8 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 119249920, mean_episode_return = 24.991, mean_episode_step = 884.58, total_loss = 132.74, pg_loss = 44.726, baseline_loss = 93.601, entropy_loss = -5.5909, learner_queue_size = 32, _tick = 31325, _time = 1.6548e+09, train_seconds = 3.1216e+04)
[2022-06-10 04:48:20,682][root][INFO] - Step 119270400 @ 4092.4 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 119270400, mean_episode_return = 22.355, mean_episode_step = 1419.2, total_loss = -69.538, pg_loss = -87.305, baseline_loss = 23.387, entropy_loss = -5.6206, learner_queue_size = 32, _tick = 31332, _time = 1.6548e+09, train_seconds = 3.122e+04)
[2022-06-10 04:48:25,686][root][INFO] - Step 119288320 @ 3581.4 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 119288320, mean_episode_return = 47.739, mean_episode_step = 941.01, total_loss = 117.63, pg_loss = 67.43, baseline_loss = 55.725, entropy_loss = -5.5279, learner_queue_size = 32, _tick = 31337, _time = 1.6548e+09, train_seconds = 3.1226e+04)
[2022-06-10 04:48:30,690][root][INFO] - Step 119308800 @ 4092.6 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (step = 119308800, mean_episode_return = -14.51, mean_episode_step = 1016.9, total_loss = -17.592, pg_loss = -36.003, baseline_loss = 24.2, entropy_loss = -5.7887, learner_queue_size = 32, _tick = 31345, _time = 1.6548e+09, train_seconds = 3.123e+04)
[2022-06-10 04:48:35,694][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 04:48:35,838][root][INFO] - Step 119329280 @ 4092.7 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 119329280, mean_episode_return = 50.365, mean_episode_step = 933.0, total_loss = -2.9078, pg_loss = -33.941, baseline_loss = 36.65, entropy_loss = -5.6166, learner_queue_size = 32, _tick = 31352, _time = 1.6548e+09, train_seconds = 3.1236e+04)
[2022-06-10 04:48:40,842][root][INFO] - Step 119349760 @ 3978.3 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 119349760, mean_episode_return = 48.731, mean_episode_step = 939.88, total_loss = 90.804, pg_loss = 57.249, baseline_loss = 39.236, entropy_loss = -5.6818, learner_queue_size = 32, _tick = 31360, _time = 1.6548e+09, train_seconds = 3.1241e+04)
[2022-06-10 04:48:45,846][root][INFO] - Step 119367680 @ 3581.2 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 119367680, mean_episode_return = 58.351, mean_episode_step = 1234.2, total_loss = 83.507, pg_loss = 40.459, baseline_loss = 48.551, entropy_loss = -5.5029, learner_queue_size = 32, _tick = 31367, _time = 1.6548e+09, train_seconds = 3.1246e+04)
[2022-06-10 04:48:50,850][root][INFO] - Step 119388160 @ 4092.8 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 119388160, mean_episode_return = 34.81, mean_episode_step = 715.02, total_loss = -52.827, pg_loss = -102.62, baseline_loss = 55.383, entropy_loss = -5.5909, learner_queue_size = 32, _tick = 31374, _time = 1.6548e+09, train_seconds = 3.1251e+04)
[2022-06-10 04:48:55,858][root][INFO] - Step 119406080 @ 3578.3 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 119406080, mean_episode_return = 16.38, mean_episode_step = 1044.2, total_loss = 17.166, pg_loss = -27.327, baseline_loss = 50.299, entropy_loss = -5.8068, learner_queue_size = 32, _tick = 31380, _time = 1.6548e+09, train_seconds = 3.1256e+04)
[2022-06-10 04:49:00,862][root][INFO] - Step 119426560 @ 4092.7 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 119426560, mean_episode_return = None, mean_episode_step = 972.28, total_loss = 309.08, pg_loss = 254.37, baseline_loss = 60.382, entropy_loss = -5.6684, learner_queue_size = 32, _tick = 31387, _time = 1.6548e+09, train_seconds = 3.1261e+04)
[2022-06-10 04:49:05,866][root][INFO] - Step 119444480 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 119444480, mean_episode_return = 80.347, mean_episode_step = 795.56, total_loss = 273.47, pg_loss = 155.88, baseline_loss = 123.14, entropy_loss = -5.5466, learner_queue_size = 32, _tick = 31394, _time = 1.6548e+09, train_seconds = 3.1266e+04)
[2022-06-10 04:49:10,870][root][INFO] - Step 119464960 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 119464960, mean_episode_return = 135.04, mean_episode_step = 975.76, total_loss = 176.48, pg_loss = 110.62, baseline_loss = 71.415, entropy_loss = -5.5513, learner_queue_size = 32, _tick = 31398, _time = 1.6548e+09, train_seconds = 3.1271e+04)
[2022-06-10 04:49:15,874][root][INFO] - Step 119485440 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 119485440, mean_episode_return = 64.88, mean_episode_step = 1074.9, total_loss = -28.442, pg_loss = -69.818, baseline_loss = 46.827, entropy_loss = -5.4513, learner_queue_size = 32, _tick = 31402, _time = 1.6548e+09, train_seconds = 3.1276e+04)
[2022-06-10 04:49:20,878][root][INFO] - Step 119505920 @ 4092.8 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 119505920, mean_episode_return = 161.54, mean_episode_step = 1176.7, total_loss = -37.873, pg_loss = -69.242, baseline_loss = 36.968, entropy_loss = -5.599, learner_queue_size = 32, _tick = 31407, _time = 1.6548e+09, train_seconds = 3.1281e+04)
[2022-06-10 04:49:25,882][root][INFO] - Step 119526400 @ 4092.7 SPS. Inference batcher size: 88. Learner queue size: 32. Other stats: (step = 119526400, mean_episode_return = 19.55, mean_episode_step = 1273.3, total_loss = 212.65, pg_loss = 158.71, baseline_loss = 59.49, entropy_loss = -5.5513, learner_queue_size = 32, _tick = 31414, _time = 1.6548e+09, train_seconds = 3.1286e+04)
[2022-06-10 04:49:30,886][root][INFO] - Step 119544320 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 119544320, mean_episode_return = -7.0502, mean_episode_step = 1331.5, total_loss = 208.58, pg_loss = 152.33, baseline_loss = 61.708, entropy_loss = -5.4561, learner_queue_size = 32, _tick = 31420, _time = 1.6548e+09, train_seconds = 3.1291e+04)
[2022-06-10 04:49:35,890][root][INFO] - Step 119564800 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 119564800, mean_episode_return = 31.35, mean_episode_step = 1118.6, total_loss = -0.11998, pg_loss = -43.997, baseline_loss = 49.452, entropy_loss = -5.5754, learner_queue_size = 32, _tick = 31426, _time = 1.6548e+09, train_seconds = 3.1296e+04)
[2022-06-10 04:49:40,894][root][INFO] - Step 119585280 @ 4092.8 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 119585280, mean_episode_return = 9.9999, mean_episode_step = 900.82, total_loss = 319.23, pg_loss = 225.67, baseline_loss = 99.188, entropy_loss = -5.6212, learner_queue_size = 32, _tick = 31432, _time = 1.6548e+09, train_seconds = 3.1301e+04)
[2022-06-10 04:49:45,898][root][INFO] - Step 119603200 @ 3581.2 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 119603200, mean_episode_return = 36.191, mean_episode_step = 1157.2, total_loss = 45.761, pg_loss = 6.3437, baseline_loss = 44.967, entropy_loss = -5.5504, learner_queue_size = 32, _tick = 31439, _time = 1.6548e+09, train_seconds = 3.1306e+04)
[2022-06-10 04:49:50,902][root][INFO] - Step 119623680 @ 4092.7 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 119623680, mean_episode_return = 11.82, mean_episode_step = 830.18, total_loss = -10.781, pg_loss = -39.003, baseline_loss = 33.486, entropy_loss = -5.2641, learner_queue_size = 32, _tick = 31446, _time = 1.6548e+09, train_seconds = 3.1311e+04)
[2022-06-10 04:49:55,906][root][INFO] - Step 119644160 @ 4092.7 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 119644160, mean_episode_return = 123.58, mean_episode_step = 918.96, total_loss = -8.0247, pg_loss = -65.22, baseline_loss = 62.789, entropy_loss = -5.594, learner_queue_size = 32, _tick = 31451, _time = 1.6548e+09, train_seconds = 3.1316e+04)
[2022-06-10 04:50:00,910][root][INFO] - Step 119662080 @ 3581.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 119662080, mean_episode_return = 71.552, mean_episode_step = 1000.5, total_loss = -68.978, pg_loss = -97.666, baseline_loss = 34.184, entropy_loss = -5.4958, learner_queue_size = 32, _tick = 31455, _time = 1.6548e+09, train_seconds = 3.1321e+04)
[2022-06-10 04:50:05,914][root][INFO] - Step 119682560 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 119682560, mean_episode_return = 15.29, mean_episode_step = 1190.0, total_loss = 74.027, pg_loss = 34.316, baseline_loss = 45.28, entropy_loss = -5.5692, learner_queue_size = 32, _tick = 31463, _time = 1.6548e+09, train_seconds = 3.1326e+04)
[2022-06-10 04:50:10,918][root][INFO] - Step 119700480 @ 3581.1 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 119700480, mean_episode_return = 54.28, mean_episode_step = 865.5, total_loss = -37.476, pg_loss = -69.631, baseline_loss = 37.807, entropy_loss = -5.6524, learner_queue_size = 32, _tick = 31469, _time = 1.6548e+09, train_seconds = 3.1331e+04)
[2022-06-10 04:50:15,922][root][INFO] - Step 119720960 @ 4092.8 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 119720960, mean_episode_return = 115.81, mean_episode_step = 1248.7, total_loss = 78.457, pg_loss = 65.924, baseline_loss = 18.287, entropy_loss = -5.7536, learner_queue_size = 32, _tick = 31477, _time = 1.6548e+09, train_seconds = 3.1336e+04)
[2022-06-10 04:50:20,926][root][INFO] - Step 119738880 @ 3581.2 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 119738880, mean_episode_return = 80.875, mean_episode_step = 999.67, total_loss = 245.16, pg_loss = 200.16, baseline_loss = 50.543, entropy_loss = -5.544, learner_queue_size = 32, _tick = 31482, _time = 1.6548e+09, train_seconds = 3.1341e+04)
[2022-06-10 04:50:25,934][root][INFO] - Step 119759360 @ 4089.5 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 119759360, mean_episode_return = 86.857, mean_episode_step = 1124.4, total_loss = 15.9, pg_loss = -20.265, baseline_loss = 41.632, entropy_loss = -5.467, learner_queue_size = 32, _tick = 31488, _time = 1.6548e+09, train_seconds = 3.1346e+04)
[2022-06-10 04:50:30,938][root][INFO] - Step 119777280 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 119777280, mean_episode_return = 1.09, mean_episode_step = 999.82, total_loss = 20.814, pg_loss = -43.893, baseline_loss = 69.991, entropy_loss = -5.284, learner_queue_size = 32, _tick = 31493, _time = 1.6548e+09, train_seconds = 3.1351e+04)
[2022-06-10 04:50:35,942][root][INFO] - Step 119795200 @ 3581.2 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 119795200, mean_episode_return = 0.8698, mean_episode_step = 792.84, total_loss = 62.507, pg_loss = 13.743, baseline_loss = 54.139, entropy_loss = -5.3757, learner_queue_size = 32, _tick = 31498, _time = 1.6548e+09, train_seconds = 3.1356e+04)
[2022-06-10 04:50:40,947][root][INFO] - Step 119815680 @ 4092.8 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 119815680, mean_episode_return = None, mean_episode_step = 1229.4, total_loss = 275.19, pg_loss = 224.19, baseline_loss = 56.448, entropy_loss = -5.4473, learner_queue_size = 32, _tick = 31503, _time = 1.6548e+09, train_seconds = 3.1361e+04)
[2022-06-10 04:50:45,950][root][INFO] - Step 119836160 @ 4092.6 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 119836160, mean_episode_return = 129.9, mean_episode_step = 1069.9, total_loss = 43.023, pg_loss = 0.67233, baseline_loss = 47.805, entropy_loss = -5.4548, learner_queue_size = 32, _tick = 31508, _time = 1.6548e+09, train_seconds = 3.1366e+04)
[2022-06-10 04:50:50,954][root][INFO] - Step 119854080 @ 3581.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 119854080, mean_episode_return = None, mean_episode_step = 1084.5, total_loss = -111.61, pg_loss = -128.36, baseline_loss = 22.206, entropy_loss = -5.4575, learner_queue_size = 32, _tick = 31513, _time = 1.6548e+09, train_seconds = 3.1371e+04)
[2022-06-10 04:50:55,958][root][INFO] - Step 119874560 @ 4092.8 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 119874560, mean_episode_return = 111.86, mean_episode_step = 1004.3, total_loss = 39.557, pg_loss = 7.2237, baseline_loss = 37.913, entropy_loss = -5.5795, learner_queue_size = 32, _tick = 31518, _time = 1.6548e+09, train_seconds = 3.1376e+04)
[2022-06-10 04:51:00,962][root][INFO] - Step 119892480 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 119892480, mean_episode_return = 10.69, mean_episode_step = 1170.6, total_loss = 226.14, pg_loss = 192.96, baseline_loss = 38.715, entropy_loss = -5.5256, learner_queue_size = 32, _tick = 31523, _time = 1.6548e+09, train_seconds = 3.1381e+04)
[2022-06-10 04:51:05,966][root][INFO] - Step 119912960 @ 4092.7 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 119912960, mean_episode_return = 21.79, mean_episode_step = 1020.8, total_loss = -32.789, pg_loss = -50.814, baseline_loss = 23.601, entropy_loss = -5.5758, learner_queue_size = 32, _tick = 31529, _time = 1.6548e+09, train_seconds = 3.1386e+04)
[2022-06-10 04:51:10,970][root][INFO] - Step 119930880 @ 3581.0 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 119930880, mean_episode_return = 168.17, mean_episode_step = 1044.2, total_loss = 108.82, pg_loss = 55.822, baseline_loss = 58.517, entropy_loss = -5.5205, learner_queue_size = 32, _tick = 31535, _time = 1.6548e+09, train_seconds = 3.1391e+04)
[2022-06-10 04:51:15,974][root][INFO] - Step 119951360 @ 4092.8 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 119951360, mean_episode_return = 58.191, mean_episode_step = 1308.5, total_loss = 490.61, pg_loss = 362.95, baseline_loss = 133.2, entropy_loss = -5.529, learner_queue_size = 32, _tick = 31541, _time = 1.6548e+09, train_seconds = 3.1396e+04)
[2022-06-10 04:51:20,978][root][INFO] - Step 119971840 @ 4092.8 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 119971840, mean_episode_return = None, mean_episode_step = 1107.5, total_loss = 71.394, pg_loss = 33.54, baseline_loss = 43.366, entropy_loss = -5.5115, learner_queue_size = 32, _tick = 31547, _time = 1.6548e+09, train_seconds = 3.1401e+04)
[2022-06-10 04:51:25,982][root][INFO] - Step 119989760 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 119989760, mean_episode_return = 10.95, mean_episode_step = 1357.1, total_loss = -8.3961, pg_loss = -74.841, baseline_loss = 71.946, entropy_loss = -5.5019, learner_queue_size = 32, _tick = 31553, _time = 1.6548e+09, train_seconds = 3.1406e+04)
[2022-06-10 04:51:30,986][root][INFO] - Step 120010240 @ 4092.7 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 120010240, mean_episode_return = 56.271, mean_episode_step = 1218.8, total_loss = 9.5482, pg_loss = -46.297, baseline_loss = 61.348, entropy_loss = -5.5027, learner_queue_size = 32, _tick = 31560, _time = 1.6548e+09, train_seconds = 3.1411e+04)
[2022-06-10 04:51:35,990][root][INFO] - Step 120028160 @ 3581.2 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 120028160, mean_episode_return = 13.63, mean_episode_step = 1108.2, total_loss = 268.98, pg_loss = 211.19, baseline_loss = 63.341, entropy_loss = -5.5551, learner_queue_size = 32, _tick = 31566, _time = 1.6548e+09, train_seconds = 3.1416e+04)
[2022-06-10 04:51:40,994][root][INFO] - Step 120048640 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 120048640, mean_episode_return = 57.374, mean_episode_step = 1198.1, total_loss = -61.496, pg_loss = -93.569, baseline_loss = 37.599, entropy_loss = -5.5256, learner_queue_size = 32, _tick = 31573, _time = 1.6548e+09, train_seconds = 3.1421e+04)
[2022-06-10 04:51:45,998][root][INFO] - Step 120069120 @ 4092.8 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 120069120, mean_episode_return = 36.21, mean_episode_step = 1076.8, total_loss = 275.55, pg_loss = 201.22, baseline_loss = 79.873, entropy_loss = -5.5426, learner_queue_size = 32, _tick = 31576, _time = 1.6548e+09, train_seconds = 3.1426e+04)
[2022-06-10 04:51:51,002][root][INFO] - Step 120087040 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 120087040, mean_episode_return = 4.7303, mean_episode_step = 1110.4, total_loss = 6.5975, pg_loss = -18.195, baseline_loss = 30.261, entropy_loss = -5.4691, learner_queue_size = 32, _tick = 31582, _time = 1.6548e+09, train_seconds = 3.1431e+04)
[2022-06-10 04:51:56,006][root][INFO] - Step 120107520 @ 4092.7 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (step = 120107520, mean_episode_return = 170.21, mean_episode_step = 1167.4, total_loss = -141.0, pg_loss = -147.52, baseline_loss = 11.899, entropy_loss = -5.3753, learner_queue_size = 32, _tick = 31590, _time = 1.6548e+09, train_seconds = 3.1436e+04)
[2022-06-10 04:52:01,010][root][INFO] - Step 120128000 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 120128000, mean_episode_return = 32.96, mean_episode_step = 1195.5, total_loss = 69.976, pg_loss = 25.348, baseline_loss = 50.022, entropy_loss = -5.3949, learner_queue_size = 32, _tick = 31595, _time = 1.6548e+09, train_seconds = 3.1441e+04)
[2022-06-10 04:52:06,014][root][INFO] - Step 120148480 @ 4092.8 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 120148480, mean_episode_return = -8.9001, mean_episode_step = 1087.1, total_loss = -39.206, pg_loss = -95.587, baseline_loss = 61.921, entropy_loss = -5.5398, learner_queue_size = 32, _tick = 31599, _time = 1.6548e+09, train_seconds = 3.1446e+04)
[2022-06-10 04:52:11,022][root][INFO] - Step 120166400 @ 3578.2 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 120166400, mean_episode_return = 151.8, mean_episode_step = 1122.1, total_loss = -171.69, pg_loss = -200.23, baseline_loss = 34.059, entropy_loss = -5.5228, learner_queue_size = 32, _tick = 31603, _time = 1.6548e+09, train_seconds = 3.1451e+04)
[2022-06-10 04:52:16,026][root][INFO] - Step 120186880 @ 4092.9 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 120186880, mean_episode_return = None, mean_episode_step = 1213.3, total_loss = 285.08, pg_loss = 232.57, baseline_loss = 58.107, entropy_loss = -5.5921, learner_queue_size = 32, _tick = 31608, _time = 1.6548e+09, train_seconds = 3.1456e+04)
[2022-06-10 04:52:21,030][root][INFO] - Step 120204800 @ 3581.1 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 120204800, mean_episode_return = 29.88, mean_episode_step = 993.47, total_loss = 120.59, pg_loss = 91.066, baseline_loss = 35.178, entropy_loss = -5.6503, learner_queue_size = 32, _tick = 31613, _time = 1.6548e+09, train_seconds = 3.1461e+04)
[2022-06-10 04:52:26,034][root][INFO] - Step 120225280 @ 4092.8 SPS. Inference batcher size: 73. Learner queue size: 32. Other stats: (step = 120225280, mean_episode_return = 55.767, mean_episode_step = 990.72, total_loss = 129.26, pg_loss = 78.771, baseline_loss = 56.051, entropy_loss = -5.5667, learner_queue_size = 32, _tick = 31620, _time = 1.6548e+09, train_seconds = 3.1466e+04)
[2022-06-10 04:52:31,038][root][INFO] - Step 120245760 @ 4092.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 120245760, mean_episode_return = 60.706, mean_episode_step = 1422.9, total_loss = -34.527, pg_loss = -64.894, baseline_loss = 36.009, entropy_loss = -5.6424, learner_queue_size = 32, _tick = 31626, _time = 1.6548e+09, train_seconds = 3.1471e+04)
[2022-06-10 04:52:36,042][root][INFO] - Step 120266240 @ 4092.7 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 120266240, mean_episode_return = 93.018, mean_episode_step = 1056.3, total_loss = 253.0, pg_loss = 103.24, baseline_loss = 155.37, entropy_loss = -5.6128, learner_queue_size = 32, _tick = 31632, _time = 1.6548e+09, train_seconds = 3.1476e+04)
[2022-06-10 04:52:41,046][root][INFO] - Step 120284160 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 120284160, mean_episode_return = 69.58, mean_episode_step = 1196.0, total_loss = 28.626, pg_loss = -5.5456, baseline_loss = 39.833, entropy_loss = -5.6616, learner_queue_size = 32, _tick = 31637, _time = 1.6548e+09, train_seconds = 3.1481e+04)
[2022-06-10 04:52:46,050][root][INFO] - Step 120304640 @ 4092.7 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 120304640, mean_episode_return = 27.003, mean_episode_step = 1007.2, total_loss = 72.448, pg_loss = 12.948, baseline_loss = 65.048, entropy_loss = -5.5485, learner_queue_size = 32, _tick = 31644, _time = 1.6548e+09, train_seconds = 3.1486e+04)
[2022-06-10 04:52:51,054][root][INFO] - Step 120325120 @ 4092.8 SPS. Inference batcher size: 78. Learner queue size: 32. Other stats: (step = 120325120, mean_episode_return = 14.55, mean_episode_step = 1459.1, total_loss = -231.93, pg_loss = -236.17, baseline_loss = 9.9247, entropy_loss = -5.6888, learner_queue_size = 32, _tick = 31650, _time = 1.6548e+09, train_seconds = 3.1491e+04)
[2022-06-10 04:52:56,058][root][INFO] - Step 120343040 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 120343040, mean_episode_return = 16.267, mean_episode_step = 1037.9, total_loss = -17.09, pg_loss = -43.672, baseline_loss = 32.258, entropy_loss = -5.6761, learner_queue_size = 32, _tick = 31655, _time = 1.6548e+09, train_seconds = 3.1496e+04)
[2022-06-10 04:53:01,062][root][INFO] - Step 120363520 @ 4092.8 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 120363520, mean_episode_return = 124.02, mean_episode_step = 1081.2, total_loss = -136.75, pg_loss = -150.57, baseline_loss = 19.584, entropy_loss = -5.7642, learner_queue_size = 32, _tick = 31663, _time = 1.6548e+09, train_seconds = 3.1501e+04)
[2022-06-10 04:53:06,066][root][INFO] - Step 120384000 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 120384000, mean_episode_return = 66.29, mean_episode_step = 1001.7, total_loss = 128.05, pg_loss = 96.35, baseline_loss = 37.442, entropy_loss = -5.7455, learner_queue_size = 32, _tick = 31670, _time = 1.6548e+09, train_seconds = 3.1506e+04)
[2022-06-10 04:53:11,070][root][INFO] - Step 120401920 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 120401920, mean_episode_return = 46.971, mean_episode_step = 1127.1, total_loss = 29.48, pg_loss = 0.8474, baseline_loss = 34.32, entropy_loss = -5.6868, learner_queue_size = 32, _tick = 31673, _time = 1.6548e+09, train_seconds = 3.1511e+04)
[2022-06-10 04:53:16,077][root][INFO] - Step 120422400 @ 4089.9 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 120422400, mean_episode_return = 121.1, mean_episode_step = 931.31, total_loss = 23.595, pg_loss = -22.024, baseline_loss = 51.162, entropy_loss = -5.5433, learner_queue_size = 32, _tick = 31681, _time = 1.6548e+09, train_seconds = 3.1516e+04)
[2022-06-10 04:53:21,082][root][INFO] - Step 120442880 @ 4092.2 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 120442880, mean_episode_return = 39.71, mean_episode_step = 1130.6, total_loss = -184.86, pg_loss = -244.69, baseline_loss = 65.284, entropy_loss = -5.4564, learner_queue_size = 32, _tick = 31689, _time = 1.6548e+09, train_seconds = 3.1521e+04)
[2022-06-10 04:53:26,086][root][INFO] - Step 120460800 @ 3581.2 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 120460800, mean_episode_return = 85.647, mean_episode_step = 784.16, total_loss = -84.197, pg_loss = -128.42, baseline_loss = 49.772, entropy_loss = -5.5513, learner_queue_size = 32, _tick = 31695, _time = 1.6548e+09, train_seconds = 3.1526e+04)
[2022-06-10 04:53:31,091][root][INFO] - Step 120481280 @ 4092.2 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 120481280, mean_episode_return = 89.689, mean_episode_step = 1098.6, total_loss = 143.62, pg_loss = 95.965, baseline_loss = 53.477, entropy_loss = -5.8223, learner_queue_size = 32, _tick = 31700, _time = 1.6548e+09, train_seconds = 3.1531e+04)
[2022-06-10 04:53:36,094][root][INFO] - Step 120501760 @ 4093.3 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 120501760, mean_episode_return = None, mean_episode_step = 1078.9, total_loss = 115.23, pg_loss = 82.165, baseline_loss = 38.828, entropy_loss = -5.7641, learner_queue_size = 32, _tick = 31705, _time = 1.6548e+09, train_seconds = 3.1536e+04)
[2022-06-10 04:53:41,098][root][INFO] - Step 120519680 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 120519680, mean_episode_return = None, mean_episode_step = 959.56, total_loss = 35.134, pg_loss = -3.987, baseline_loss = 44.824, entropy_loss = -5.703, learner_queue_size = 32, _tick = 31710, _time = 1.6548e+09, train_seconds = 3.1541e+04)
[2022-06-10 04:53:46,102][root][INFO] - Step 120540160 @ 4092.6 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 120540160, mean_episode_return = 49.06, mean_episode_step = 939.55, total_loss = 97.284, pg_loss = 19.939, baseline_loss = 82.955, entropy_loss = -5.6105, learner_queue_size = 32, _tick = 31716, _time = 1.6548e+09, train_seconds = 3.1546e+04)
[2022-06-10 04:53:51,105][root][INFO] - Step 120558080 @ 3581.5 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 120558080, mean_episode_return = 19.655, mean_episode_step = 734.87, total_loss = 74.405, pg_loss = -18.349, baseline_loss = 98.267, entropy_loss = -5.5132, learner_queue_size = 32, _tick = 31721, _time = 1.6548e+09, train_seconds = 3.1551e+04)
[2022-06-10 04:53:56,110][root][INFO] - Step 120578560 @ 4092.4 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 120578560, mean_episode_return = 36.82, mean_episode_step = 1139.6, total_loss = -57.002, pg_loss = -130.15, baseline_loss = 78.906, entropy_loss = -5.7572, learner_queue_size = 32, _tick = 31728, _time = 1.6548e+09, train_seconds = 3.1556e+04)
[2022-06-10 04:54:01,114][root][INFO] - Step 120599040 @ 4092.6 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 120599040, mean_episode_return = 65.995, mean_episode_step = 1002.2, total_loss = -175.56, pg_loss = -192.31, baseline_loss = 22.445, entropy_loss = -5.7013, learner_queue_size = 32, _tick = 31733, _time = 1.6548e+09, train_seconds = 3.1561e+04)
[2022-06-10 04:54:06,118][root][INFO] - Step 120619520 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 120619520, mean_episode_return = 137.33, mean_episode_step = 1184.9, total_loss = 269.31, pg_loss = 175.03, baseline_loss = 99.979, entropy_loss = -5.7013, learner_queue_size = 32, _tick = 31739, _time = 1.6548e+09, train_seconds = 3.1566e+04)
[2022-06-10 04:54:11,122][root][INFO] - Step 120637440 @ 3581.2 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 120637440, mean_episode_return = 191.71, mean_episode_step = 1218.4, total_loss = -59.57, pg_loss = -74.108, baseline_loss = 20.23, entropy_loss = -5.6923, learner_queue_size = 32, _tick = 31744, _time = 1.6548e+09, train_seconds = 3.1571e+04)
[2022-06-10 04:54:16,126][root][INFO] - Step 120655360 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 120655360, mean_episode_return = 21.18, mean_episode_step = 1221.3, total_loss = 64.843, pg_loss = 34.595, baseline_loss = 35.982, entropy_loss = -5.7334, learner_queue_size = 32, _tick = 31749, _time = 1.6548e+09, train_seconds = 3.1576e+04)
[2022-06-10 04:54:21,130][root][INFO] - Step 120675840 @ 4092.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 120675840, mean_episode_return = 12.41, mean_episode_step = 962.92, total_loss = 249.36, pg_loss = 196.1, baseline_loss = 58.841, entropy_loss = -5.5851, learner_queue_size = 32, _tick = 31756, _time = 1.6548e+09, train_seconds = 3.1581e+04)
[2022-06-10 04:54:26,134][root][INFO] - Step 120696320 @ 4092.8 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 120696320, mean_episode_return = 68.532, mean_episode_step = 1104.2, total_loss = 586.31, pg_loss = 465.46, baseline_loss = 126.4, entropy_loss = -5.5417, learner_queue_size = 32, _tick = 31762, _time = 1.6548e+09, train_seconds = 3.1586e+04)
[2022-06-10 04:54:31,138][root][INFO] - Step 120714240 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 120714240, mean_episode_return = None, mean_episode_step = 1142.1, total_loss = -96.55, pg_loss = -118.86, baseline_loss = 27.863, entropy_loss = -5.5547, learner_queue_size = 32, _tick = 31768, _time = 1.6548e+09, train_seconds = 3.1591e+04)
[2022-06-10 04:54:36,143][root][INFO] - Step 120734720 @ 4092.0 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 120734720, mean_episode_return = 51.081, mean_episode_step = 1028.1, total_loss = 19.23, pg_loss = -5.1528, baseline_loss = 30.083, entropy_loss = -5.6995, learner_queue_size = 32, _tick = 31774, _time = 1.6548e+09, train_seconds = 3.1596e+04)
[2022-06-10 04:54:41,146][root][INFO] - Step 120755200 @ 4093.3 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 120755200, mean_episode_return = None, mean_episode_step = 1290.9, total_loss = 425.21, pg_loss = 304.6, baseline_loss = 126.24, entropy_loss = -5.6334, learner_queue_size = 32, _tick = 31776, _time = 1.6548e+09, train_seconds = 3.1601e+04)
[2022-06-10 04:54:46,150][root][INFO] - Step 120773120 @ 3581.3 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (step = 120773120, mean_episode_return = 33.466, mean_episode_step = 968.1, total_loss = 236.79, pg_loss = 175.5, baseline_loss = 67.082, entropy_loss = -5.7931, learner_queue_size = 32, _tick = 31782, _time = 1.6548e+09, train_seconds = 3.1606e+04)
[2022-06-10 04:54:51,154][root][INFO] - Step 120791040 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 120791040, mean_episode_return = 10.03, mean_episode_step = 1191.4, total_loss = 227.93, pg_loss = 170.07, baseline_loss = 63.576, entropy_loss = -5.7225, learner_queue_size = 32, _tick = 31786, _time = 1.6548e+09, train_seconds = 3.1611e+04)
[2022-06-10 04:54:56,158][root][INFO] - Step 120811520 @ 4092.8 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 120811520, mean_episode_return = 65.579, mean_episode_step = 1257.1, total_loss = -48.218, pg_loss = -61.581, baseline_loss = 19.013, entropy_loss = -5.6499, learner_queue_size = 32, _tick = 31793, _time = 1.6548e+09, train_seconds = 3.1616e+04)
[2022-06-10 04:55:01,162][root][INFO] - Step 120832000 @ 4092.7 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (step = 120832000, mean_episode_return = 68.77, mean_episode_step = 1117.1, total_loss = 135.78, pg_loss = 91.583, baseline_loss = 49.749, entropy_loss = -5.5566, learner_queue_size = 32, _tick = 31798, _time = 1.6548e+09, train_seconds = 3.1621e+04)
[2022-06-10 04:55:06,166][root][INFO] - Step 120852480 @ 4092.7 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 120852480, mean_episode_return = 45.417, mean_episode_step = 1248.6, total_loss = 23.775, pg_loss = -2.8622, baseline_loss = 32.01, entropy_loss = -5.3721, learner_queue_size = 32, _tick = 31804, _time = 1.6548e+09, train_seconds = 3.1626e+04)
[2022-06-10 04:55:11,170][root][INFO] - Step 120872960 @ 4092.8 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 120872960, mean_episode_return = -17.12, mean_episode_step = 1343.4, total_loss = -135.89, pg_loss = -159.77, baseline_loss = 29.616, entropy_loss = -5.7375, learner_queue_size = 32, _tick = 31811, _time = 1.6548e+09, train_seconds = 3.1631e+04)
[2022-06-10 04:55:16,174][root][INFO] - Step 120890880 @ 3581.1 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 120890880, mean_episode_return = None, mean_episode_step = 1302.9, total_loss = 11.14, pg_loss = -17.813, baseline_loss = 34.642, entropy_loss = -5.6892, learner_queue_size = 32, _tick = 31816, _time = 1.6548e+09, train_seconds = 3.1636e+04)
[2022-06-10 04:55:21,180][root][INFO] - Step 120908800 @ 3579.5 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 120908800, mean_episode_return = 14.91, mean_episode_step = 1215.1, total_loss = 21.854, pg_loss = -22.559, baseline_loss = 49.922, entropy_loss = -5.5092, learner_queue_size = 32, _tick = 31822, _time = 1.6548e+09, train_seconds = 3.1641e+04)
[2022-06-10 04:55:26,186][root][INFO] - Step 120929280 @ 4091.1 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 120929280, mean_episode_return = None, mean_episode_step = 1077.8, total_loss = 195.41, pg_loss = 138.75, baseline_loss = 62.313, entropy_loss = -5.6565, learner_queue_size = 32, _tick = 31828, _time = 1.6548e+09, train_seconds = 3.1646e+04)
[2022-06-10 04:55:31,190][root][INFO] - Step 120949760 @ 4092.9 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 120949760, mean_episode_return = None, mean_episode_step = 1236.5, total_loss = 68.258, pg_loss = 31.472, baseline_loss = 42.431, entropy_loss = -5.6448, learner_queue_size = 32, _tick = 31833, _time = 1.6548e+09, train_seconds = 3.1651e+04)
[2022-06-10 04:55:36,196][root][INFO] - Step 120970240 @ 4091.0 SPS. Inference batcher size: 86. Learner queue size: 32. Other stats: (step = 120970240, mean_episode_return = 44.552, mean_episode_step = 1363.1, total_loss = 60.492, pg_loss = 23.144, baseline_loss = 43.016, entropy_loss = -5.6675, learner_queue_size = 32, _tick = 31837, _time = 1.6548e+09, train_seconds = 3.1656e+04)
[2022-06-10 04:55:41,202][root][INFO] - Step 120988160 @ 3579.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 120988160, mean_episode_return = 46.944, mean_episode_step = 957.74, total_loss = 92.314, pg_loss = 56.416, baseline_loss = 41.4, entropy_loss = -5.5018, learner_queue_size = 32, _tick = 31843, _time = 1.6548e+09, train_seconds = 3.1661e+04)
[2022-06-10 04:55:46,208][root][INFO] - Step 121006080 @ 3579.7 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 121006080, mean_episode_return = 49.931, mean_episode_step = 1091.5, total_loss = -177.26, pg_loss = -213.78, baseline_loss = 42.121, entropy_loss = -5.5963, learner_queue_size = 32, _tick = 31849, _time = 1.6548e+09, train_seconds = 3.1666e+04)
[2022-06-10 04:55:51,214][root][INFO] - Step 121026560 @ 4090.8 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 121026560, mean_episode_return = 59.325, mean_episode_step = 1089.4, total_loss = -209.58, pg_loss = -220.47, baseline_loss = 16.565, entropy_loss = -5.6743, learner_queue_size = 32, _tick = 31854, _time = 1.6548e+09, train_seconds = 3.1671e+04)
[2022-06-10 04:55:56,218][root][INFO] - Step 121047040 @ 4093.1 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 121047040, mean_episode_return = 49.034, mean_episode_step = 1209.6, total_loss = 830.44, pg_loss = 360.88, baseline_loss = 475.26, entropy_loss = -5.6944, learner_queue_size = 32, _tick = 31862, _time = 1.6548e+09, train_seconds = 3.1676e+04)
[2022-06-10 04:56:01,222][root][INFO] - Step 121067520 @ 4092.7 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 121067520, mean_episode_return = 41.103, mean_episode_step = 984.95, total_loss = 465.34, pg_loss = 272.21, baseline_loss = 198.86, entropy_loss = -5.7341, learner_queue_size = 32, _tick = 31868, _time = 1.6548e+09, train_seconds = 3.1681e+04)
[2022-06-10 04:56:06,226][root][INFO] - Step 121088000 @ 4092.8 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 121088000, mean_episode_return = 111.57, mean_episode_step = 825.46, total_loss = -33.075, pg_loss = -60.981, baseline_loss = 33.635, entropy_loss = -5.7291, learner_queue_size = 32, _tick = 31876, _time = 1.6548e+09, train_seconds = 3.1686e+04)
[2022-06-10 04:56:11,230][root][INFO] - Step 121105920 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 121105920, mean_episode_return = 89.84, mean_episode_step = 975.23, total_loss = 63.425, pg_loss = 31.764, baseline_loss = 37.432, entropy_loss = -5.7716, learner_queue_size = 32, _tick = 31883, _time = 1.6548e+09, train_seconds = 3.1691e+04)
[2022-06-10 04:56:16,234][root][INFO] - Step 121126400 @ 4092.2 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 121126400, mean_episode_return = 52.573, mean_episode_step = 931.66, total_loss = -73.821, pg_loss = -108.49, baseline_loss = 40.39, entropy_loss = -5.718, learner_queue_size = 32, _tick = 31890, _time = 1.6548e+09, train_seconds = 3.1696e+04)
[2022-06-10 04:56:21,241][root][INFO] - Step 121144320 @ 3579.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 121144320, mean_episode_return = 40.751, mean_episode_step = 842.65, total_loss = -25.678, pg_loss = -66.965, baseline_loss = 46.852, entropy_loss = -5.5646, learner_queue_size = 32, _tick = 31897, _time = 1.6548e+09, train_seconds = 3.1701e+04)
[2022-06-10 04:56:26,246][root][INFO] - Step 121164800 @ 4091.6 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 121164800, mean_episode_return = 108.59, mean_episode_step = 854.58, total_loss = 19.875, pg_loss = -28.314, baseline_loss = 53.918, entropy_loss = -5.7288, learner_queue_size = 32, _tick = 31905, _time = 1.6548e+09, train_seconds = 3.1706e+04)
[2022-06-10 04:56:31,250][root][INFO] - Step 121185280 @ 4092.7 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 121185280, mean_episode_return = 45.81, mean_episode_step = 888.42, total_loss = 459.08, pg_loss = 322.44, baseline_loss = 142.5, entropy_loss = -5.8669, learner_queue_size = 32, _tick = 31912, _time = 1.6548e+09, train_seconds = 3.1711e+04)
[2022-06-10 04:56:36,254][root][INFO] - Step 121203200 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 121203200, mean_episode_return = None, mean_episode_step = 1130.8, total_loss = -6.2093, pg_loss = -19.973, baseline_loss = 19.419, entropy_loss = -5.6549, learner_queue_size = 32, _tick = 31916, _time = 1.6548e+09, train_seconds = 3.1716e+04)
[2022-06-10 04:56:41,259][root][INFO] - Step 121223680 @ 4091.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 121223680, mean_episode_return = None, mean_episode_step = 1092.4, total_loss = 104.19, pg_loss = 72.411, baseline_loss = 37.411, entropy_loss = -5.6299, learner_queue_size = 32, _tick = 31922, _time = 1.6548e+09, train_seconds = 3.1721e+04)
[2022-06-10 04:56:46,262][root][INFO] - Step 121241600 @ 3582.1 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 121241600, mean_episode_return = 81.49, mean_episode_step = 870.96, total_loss = 124.72, pg_loss = 36.739, baseline_loss = 93.469, entropy_loss = -5.493, learner_queue_size = 32, _tick = 31927, _time = 1.6548e+09, train_seconds = 3.1726e+04)
[2022-06-10 04:56:51,266][root][INFO] - Step 121262080 @ 4092.5 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 121262080, mean_episode_return = 49.687, mean_episode_step = 983.97, total_loss = 4.9401, pg_loss = -35.955, baseline_loss = 46.745, entropy_loss = -5.8499, learner_queue_size = 32, _tick = 31933, _time = 1.6548e+09, train_seconds = 3.1731e+04)
[2022-06-10 04:56:56,270][root][INFO] - Step 121280000 @ 3581.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 121280000, mean_episode_return = 105.76, mean_episode_step = 888.62, total_loss = -27.209, pg_loss = -60.668, baseline_loss = 39.305, entropy_loss = -5.8459, learner_queue_size = 32, _tick = 31938, _time = 1.6548e+09, train_seconds = 3.1736e+04)
[2022-06-10 04:57:01,274][root][INFO] - Step 121300480 @ 4092.8 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 121300480, mean_episode_return = 17.73, mean_episode_step = 860.48, total_loss = 102.15, pg_loss = 56.468, baseline_loss = 51.512, entropy_loss = -5.8318, learner_queue_size = 32, _tick = 31944, _time = 1.6548e+09, train_seconds = 3.1741e+04)
[2022-06-10 04:57:06,278][root][INFO] - Step 121320960 @ 4092.8 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 121320960, mean_episode_return = 44.841, mean_episode_step = 1088.0, total_loss = 270.54, pg_loss = 197.31, baseline_loss = 78.997, entropy_loss = -5.7619, learner_queue_size = 32, _tick = 31952, _time = 1.6548e+09, train_seconds = 3.1746e+04)
[2022-06-10 04:57:11,282][root][INFO] - Step 121338880 @ 3581.2 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 121338880, mean_episode_return = 83.765, mean_episode_step = 876.95, total_loss = 98.682, pg_loss = 54.103, baseline_loss = 50.357, entropy_loss = -5.7773, learner_queue_size = 32, _tick = 31958, _time = 1.6548e+09, train_seconds = 3.1751e+04)
[2022-06-10 04:57:16,286][root][INFO] - Step 121359360 @ 4092.6 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (step = 121359360, mean_episode_return = 10.41, mean_episode_step = 938.03, total_loss = -103.06, pg_loss = -133.68, baseline_loss = 36.351, entropy_loss = -5.7261, learner_queue_size = 32, _tick = 31964, _time = 1.6548e+09, train_seconds = 3.1756e+04)
[2022-06-10 04:57:21,291][root][INFO] - Step 121377280 @ 3580.6 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 121377280, mean_episode_return = 52.921, mean_episode_step = 1055.8, total_loss = 483.97, pg_loss = 409.31, baseline_loss = 80.421, entropy_loss = -5.7565, learner_queue_size = 32, _tick = 31969, _time = 1.6548e+09, train_seconds = 3.1761e+04)
[2022-06-10 04:57:26,294][root][INFO] - Step 121397760 @ 4093.4 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 121397760, mean_episode_return = None, mean_episode_step = 973.41, total_loss = 177.1, pg_loss = 144.61, baseline_loss = 38.219, entropy_loss = -5.7228, learner_queue_size = 32, _tick = 31974, _time = 1.6548e+09, train_seconds = 3.1766e+04)
[2022-06-10 04:57:31,298][root][INFO] - Step 121418240 @ 4092.8 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 121418240, mean_episode_return = 51.541, mean_episode_step = 1122.9, total_loss = -75.529, pg_loss = -94.034, baseline_loss = 24.184, entropy_loss = -5.6781, learner_queue_size = 32, _tick = 31980, _time = 1.6548e+09, train_seconds = 3.1771e+04)
[2022-06-10 04:57:36,302][root][INFO] - Step 121436160 @ 3581.0 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 121436160, mean_episode_return = 126.28, mean_episode_step = 1012.0, total_loss = 172.61, pg_loss = 119.21, baseline_loss = 59.054, entropy_loss = -5.6481, learner_queue_size = 32, _tick = 31986, _time = 1.6548e+09, train_seconds = 3.1776e+04)
[2022-06-10 04:57:41,306][root][INFO] - Step 121456640 @ 4092.9 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 121456640, mean_episode_return = 93.31, mean_episode_step = 1042.0, total_loss = -71.129, pg_loss = -97.765, baseline_loss = 32.227, entropy_loss = -5.5921, learner_queue_size = 32, _tick = 31990, _time = 1.6548e+09, train_seconds = 3.1781e+04)
[2022-06-10 04:57:46,310][root][INFO] - Step 121477120 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 121477120, mean_episode_return = 161.01, mean_episode_step = 990.09, total_loss = -135.35, pg_loss = -142.12, baseline_loss = 12.572, entropy_loss = -5.8043, learner_queue_size = 32, _tick = 31998, _time = 1.6548e+09, train_seconds = 3.1786e+04)
[2022-06-10 04:57:51,314][root][INFO] - Step 121495040 @ 3581.2 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 121495040, mean_episode_return = None, mean_episode_step = 1039.3, total_loss = -30.281, pg_loss = -80.979, baseline_loss = 56.588, entropy_loss = -5.8901, learner_queue_size = 32, _tick = 32003, _time = 1.6548e+09, train_seconds = 3.1791e+04)
[2022-06-10 04:57:56,318][root][INFO] - Step 121515520 @ 4092.7 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 121515520, mean_episode_return = 51.168, mean_episode_step = 1009.4, total_loss = 185.92, pg_loss = 130.05, baseline_loss = 61.548, entropy_loss = -5.6729, learner_queue_size = 32, _tick = 32009, _time = 1.6548e+09, train_seconds = 3.1796e+04)
[2022-06-10 04:58:01,322][root][INFO] - Step 121536000 @ 4092.7 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 121536000, mean_episode_return = 68.555, mean_episode_step = 957.98, total_loss = 269.44, pg_loss = 201.95, baseline_loss = 73.07, entropy_loss = -5.5837, learner_queue_size = 32, _tick = 32015, _time = 1.6548e+09, train_seconds = 3.1801e+04)
[2022-06-10 04:58:06,326][root][INFO] - Step 121556480 @ 4092.8 SPS. Inference batcher size: 75. Learner queue size: 32. Other stats: (step = 121556480, mean_episode_return = 28.963, mean_episode_step = 1254.7, total_loss = -125.49, pg_loss = -198.54, baseline_loss = 78.715, entropy_loss = -5.658, learner_queue_size = 32, _tick = 32022, _time = 1.6548e+09, train_seconds = 3.1806e+04)
[2022-06-10 04:58:11,330][root][INFO] - Step 121574400 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 121574400, mean_episode_return = None, mean_episode_step = 1111.2, total_loss = -79.22, pg_loss = -104.86, baseline_loss = 31.089, entropy_loss = -5.4507, learner_queue_size = 32, _tick = 32026, _time = 1.6548e+09, train_seconds = 3.1811e+04)
[2022-06-10 04:58:16,334][root][INFO] - Step 121594880 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 121594880, mean_episode_return = 95.147, mean_episode_step = 967.68, total_loss = -147.43, pg_loss = -163.52, baseline_loss = 21.905, entropy_loss = -5.8189, learner_queue_size = 32, _tick = 32032, _time = 1.6548e+09, train_seconds = 3.1816e+04)
[2022-06-10 04:58:21,338][root][INFO] - Step 121612800 @ 3581.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 121612800, mean_episode_return = 68.69, mean_episode_step = 1099.1, total_loss = 15.304, pg_loss = -17.733, baseline_loss = 38.81, entropy_loss = -5.773, learner_queue_size = 32, _tick = 32036, _time = 1.6548e+09, train_seconds = 3.1821e+04)
[2022-06-10 04:58:26,342][root][INFO] - Step 121633280 @ 4092.7 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 121633280, mean_episode_return = 43.53, mean_episode_step = 845.82, total_loss = 207.62, pg_loss = 132.79, baseline_loss = 80.559, entropy_loss = -5.7244, learner_queue_size = 32, _tick = 32042, _time = 1.6548e+09, train_seconds = 3.1826e+04)
[2022-06-10 04:58:31,346][root][INFO] - Step 121651200 @ 3581.1 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 121651200, mean_episode_return = 103.15, mean_episode_step = 978.38, total_loss = 31.829, pg_loss = 7.8897, baseline_loss = 29.78, entropy_loss = -5.8405, learner_queue_size = 32, _tick = 32048, _time = 1.6548e+09, train_seconds = 3.1831e+04)
[2022-06-10 04:58:36,350][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 04:58:36,499][root][INFO] - Step 121671680 @ 4092.7 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 121671680, mean_episode_return = 49.74, mean_episode_step = 1128.8, total_loss = -22.541, pg_loss = -47.093, baseline_loss = 30.356, entropy_loss = -5.8039, learner_queue_size = 32, _tick = 32053, _time = 1.6548e+09, train_seconds = 3.1836e+04)
[2022-06-10 04:58:41,502][root][INFO] - Step 121689600 @ 3478.0 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 121689600, mean_episode_return = 81.919, mean_episode_step = 836.12, total_loss = 344.0, pg_loss = 270.35, baseline_loss = 79.299, entropy_loss = -5.6545, learner_queue_size = 32, _tick = 32059, _time = 1.6548e+09, train_seconds = 3.1841e+04)
[2022-06-10 04:58:46,506][root][INFO] - Step 121710080 @ 4093.0 SPS. Inference batcher size: 87. Learner queue size: 32. Other stats: (step = 121710080, mean_episode_return = 23.66, mean_episode_step = 892.04, total_loss = -37.48, pg_loss = -99.976, baseline_loss = 68.03, entropy_loss = -5.5337, learner_queue_size = 32, _tick = 32067, _time = 1.6548e+09, train_seconds = 3.1846e+04)
[2022-06-10 04:58:51,510][root][INFO] - Step 121728000 @ 3581.1 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 121728000, mean_episode_return = 41.3, mean_episode_step = 858.24, total_loss = 26.277, pg_loss = -9.0273, baseline_loss = 40.984, entropy_loss = -5.6799, learner_queue_size = 32, _tick = 32073, _time = 1.6548e+09, train_seconds = 3.1851e+04)
[2022-06-10 04:58:56,514][root][INFO] - Step 121748480 @ 4092.8 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 121748480, mean_episode_return = 28.565, mean_episode_step = 1343.7, total_loss = 121.1, pg_loss = 62.73, baseline_loss = 64.149, entropy_loss = -5.7763, learner_queue_size = 32, _tick = 32081, _time = 1.6548e+09, train_seconds = 3.1856e+04)
[2022-06-10 04:59:01,519][root][INFO] - Step 121766400 @ 3580.5 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 121766400, mean_episode_return = 5.3048, mean_episode_step = 1025.4, total_loss = -71.391, pg_loss = -95.435, baseline_loss = 29.967, entropy_loss = -5.9235, learner_queue_size = 32, _tick = 32086, _time = 1.6548e+09, train_seconds = 3.1861e+04)
[2022-06-10 04:59:06,522][root][INFO] - Step 121786880 @ 4093.3 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 121786880, mean_episode_return = 32.298, mean_episode_step = 971.76, total_loss = -79.833, pg_loss = -108.95, baseline_loss = 34.975, entropy_loss = -5.8608, learner_queue_size = 32, _tick = 32092, _time = 1.6548e+09, train_seconds = 3.1866e+04)
[2022-06-10 04:59:11,526][root][INFO] - Step 121807360 @ 4092.8 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 121807360, mean_episode_return = 37.14, mean_episode_step = 1060.3, total_loss = 161.6, pg_loss = 131.55, baseline_loss = 35.858, entropy_loss = -5.8093, learner_queue_size = 32, _tick = 32098, _time = 1.6548e+09, train_seconds = 3.1871e+04)
[2022-06-10 04:59:16,530][root][INFO] - Step 121827840 @ 4092.7 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 121827840, mean_episode_return = 54.041, mean_episode_step = 782.85, total_loss = -131.32, pg_loss = -152.75, baseline_loss = 27.214, entropy_loss = -5.7791, learner_queue_size = 32, _tick = 32105, _time = 1.6548e+09, train_seconds = 3.1876e+04)
[2022-06-10 04:59:21,535][root][INFO] - Step 121845760 @ 3580.8 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 121845760, mean_episode_return = 85.334, mean_episode_step = 801.2, total_loss = -2.5012, pg_loss = -35.374, baseline_loss = 38.684, entropy_loss = -5.8107, learner_queue_size = 32, _tick = 32110, _time = 1.6548e+09, train_seconds = 3.1881e+04)
[2022-06-10 04:59:26,538][root][INFO] - Step 121866240 @ 4093.2 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 121866240, mean_episode_return = 77.514, mean_episode_step = 885.51, total_loss = -123.72, pg_loss = -134.77, baseline_loss = 16.906, entropy_loss = -5.8543, learner_queue_size = 32, _tick = 32117, _time = 1.6548e+09, train_seconds = 3.1886e+04)
[2022-06-10 04:59:31,542][root][INFO] - Step 121884160 @ 3580.8 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 121884160, mean_episode_return = 102.94, mean_episode_step = 892.97, total_loss = -248.41, pg_loss = -260.57, baseline_loss = 17.947, entropy_loss = -5.7837, learner_queue_size = 32, _tick = 32124, _time = 1.6548e+09, train_seconds = 3.1891e+04)
[2022-06-10 04:59:36,546][root][INFO] - Step 121904640 @ 4093.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 121904640, mean_episode_return = 31.762, mean_episode_step = 1426.9, total_loss = -118.24, pg_loss = -128.18, baseline_loss = 15.738, entropy_loss = -5.7958, learner_queue_size = 32, _tick = 32127, _time = 1.6548e+09, train_seconds = 3.1896e+04)
[2022-06-10 04:59:41,550][root][INFO] - Step 121925120 @ 4092.6 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 121925120, mean_episode_return = 70.54, mean_episode_step = 963.31, total_loss = -19.499, pg_loss = -48.565, baseline_loss = 34.897, entropy_loss = -5.8316, learner_queue_size = 32, _tick = 32133, _time = 1.6548e+09, train_seconds = 3.1901e+04)
[2022-06-10 04:59:46,554][root][INFO] - Step 121943040 @ 3581.1 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 121943040, mean_episode_return = None, mean_episode_step = 960.44, total_loss = 42.702, pg_loss = 13.822, baseline_loss = 34.786, entropy_loss = -5.9062, learner_queue_size = 32, _tick = 32138, _time = 1.6548e+09, train_seconds = 3.1906e+04)
[2022-06-10 04:59:51,558][root][INFO] - Step 121963520 @ 4092.7 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 121963520, mean_episode_return = 29.945, mean_episode_step = 988.43, total_loss = 53.635, pg_loss = 34.197, baseline_loss = 25.238, entropy_loss = -5.8, learner_queue_size = 32, _tick = 32145, _time = 1.6548e+09, train_seconds = 3.1911e+04)
[2022-06-10 04:59:56,562][root][INFO] - Step 121981440 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 121981440, mean_episode_return = None, mean_episode_step = 1112.6, total_loss = 67.407, pg_loss = 37.085, baseline_loss = 36.08, entropy_loss = -5.7579, learner_queue_size = 32, _tick = 32150, _time = 1.6548e+09, train_seconds = 3.1916e+04)
[2022-06-10 05:00:01,567][root][INFO] - Step 122001920 @ 4092.2 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 122001920, mean_episode_return = 42.581, mean_episode_step = 978.27, total_loss = 170.83, pg_loss = 136.94, baseline_loss = 39.505, entropy_loss = -5.6116, learner_queue_size = 32, _tick = 32158, _time = 1.6548e+09, train_seconds = 3.1921e+04)
[2022-06-10 05:00:06,570][root][INFO] - Step 122022400 @ 4093.2 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 122022400, mean_episode_return = 11.037, mean_episode_step = 1033.7, total_loss = 58.138, pg_loss = 3.1244, baseline_loss = 60.485, entropy_loss = -5.4706, learner_queue_size = 32, _tick = 32163, _time = 1.6548e+09, train_seconds = 3.1926e+04)
[2022-06-10 05:00:11,574][root][INFO] - Step 122040320 @ 3581.2 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 122040320, mean_episode_return = 92.259, mean_episode_step = 1243.0, total_loss = 135.76, pg_loss = 83.975, baseline_loss = 57.349, entropy_loss = -5.5634, learner_queue_size = 32, _tick = 32168, _time = 1.6548e+09, train_seconds = 3.1931e+04)
[2022-06-10 05:00:16,578][root][INFO] - Step 122060800 @ 4092.7 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (step = 122060800, mean_episode_return = -3.0001, mean_episode_step = 948.4, total_loss = 201.96, pg_loss = 148.17, baseline_loss = 59.282, entropy_loss = -5.4989, learner_queue_size = 32, _tick = 32176, _time = 1.6548e+09, train_seconds = 3.1936e+04)
[2022-06-10 05:00:21,584][root][INFO] - Step 122081280 @ 4090.7 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 122081280, mean_episode_return = 5.2598, mean_episode_step = 1275.6, total_loss = 3.6397, pg_loss = -50.058, baseline_loss = 59.035, entropy_loss = -5.3375, learner_queue_size = 32, _tick = 32179, _time = 1.6548e+09, train_seconds = 3.1941e+04)
[2022-06-10 05:00:26,590][root][INFO] - Step 122099200 @ 3580.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 122099200, mean_episode_return = 67.776, mean_episode_step = 1077.2, total_loss = 119.6, pg_loss = 50.454, baseline_loss = 74.536, entropy_loss = -5.3931, learner_queue_size = 32, _tick = 32186, _time = 1.6548e+09, train_seconds = 3.1946e+04)
[2022-06-10 05:00:31,594][root][INFO] - Step 122119680 @ 4092.7 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 122119680, mean_episode_return = None, mean_episode_step = 1149.2, total_loss = 220.27, pg_loss = 171.15, baseline_loss = 54.393, entropy_loss = -5.2783, learner_queue_size = 32, _tick = 32191, _time = 1.6548e+09, train_seconds = 3.1951e+04)
[2022-06-10 05:00:36,600][root][INFO] - Step 122140160 @ 4091.1 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 122140160, mean_episode_return = 77.107, mean_episode_step = 820.65, total_loss = 25.327, pg_loss = -32.578, baseline_loss = 63.342, entropy_loss = -5.4357, learner_queue_size = 32, _tick = 32198, _time = 1.6548e+09, train_seconds = 3.1956e+04)
[2022-06-10 05:00:41,606][root][INFO] - Step 122158080 @ 3579.6 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 122158080, mean_episode_return = 8.9249, mean_episode_step = 1028.4, total_loss = 218.48, pg_loss = 159.28, baseline_loss = 64.719, entropy_loss = -5.5234, learner_queue_size = 32, _tick = 32204, _time = 1.6548e+09, train_seconds = 3.1961e+04)
[2022-06-10 05:00:46,610][root][INFO] - Step 122178560 @ 4092.8 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 122178560, mean_episode_return = None, mean_episode_step = 1013.2, total_loss = 187.51, pg_loss = 136.64, baseline_loss = 56.177, entropy_loss = -5.3074, learner_queue_size = 32, _tick = 32210, _time = 1.6548e+09, train_seconds = 3.1966e+04)
[2022-06-10 05:00:51,614][root][INFO] - Step 122199040 @ 4092.8 SPS. Inference batcher size: 77. Learner queue size: 32. Other stats: (step = 122199040, mean_episode_return = None, mean_episode_step = 1065.7, total_loss = 48.001, pg_loss = 16.023, baseline_loss = 37.749, entropy_loss = -5.772, learner_queue_size = 32, _tick = 32217, _time = 1.6548e+09, train_seconds = 3.1971e+04)
[2022-06-10 05:00:56,618][root][INFO] - Step 122216960 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 122216960, mean_episode_return = 99.711, mean_episode_step = 953.0, total_loss = 29.844, pg_loss = -10.631, baseline_loss = 46.121, entropy_loss = -5.6463, learner_queue_size = 32, _tick = 32222, _time = 1.6548e+09, train_seconds = 3.1976e+04)
[2022-06-10 05:01:01,622][root][INFO] - Step 122237440 @ 4092.4 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 122237440, mean_episode_return = None, mean_episode_step = 1080.9, total_loss = 173.15, pg_loss = 131.67, baseline_loss = 47.009, entropy_loss = -5.5289, learner_queue_size = 32, _tick = 32227, _time = 1.6548e+09, train_seconds = 3.1981e+04)
[2022-06-10 05:01:06,626][root][INFO] - Step 122257920 @ 4093.0 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 122257920, mean_episode_return = 77.29, mean_episode_step = 1222.0, total_loss = -162.3, pg_loss = -176.64, baseline_loss = 19.783, entropy_loss = -5.4379, learner_queue_size = 32, _tick = 32234, _time = 1.6548e+09, train_seconds = 3.1986e+04)
[2022-06-10 05:01:11,630][root][INFO] - Step 122275840 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 122275840, mean_episode_return = 91.78, mean_episode_step = 890.96, total_loss = 430.66, pg_loss = 319.77, baseline_loss = 116.29, entropy_loss = -5.4034, learner_queue_size = 32, _tick = 32240, _time = 1.6548e+09, train_seconds = 3.1991e+04)
[2022-06-10 05:01:16,634][root][INFO] - Step 122296320 @ 4092.8 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 122296320, mean_episode_return = None, mean_episode_step = 935.62, total_loss = 11.761, pg_loss = -11.74, baseline_loss = 28.895, entropy_loss = -5.3943, learner_queue_size = 32, _tick = 32247, _time = 1.6548e+09, train_seconds = 3.1996e+04)
[2022-06-10 05:01:21,638][root][INFO] - Step 122316800 @ 4092.6 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 122316800, mean_episode_return = 65.436, mean_episode_step = 951.42, total_loss = -167.15, pg_loss = -182.94, baseline_loss = 21.218, entropy_loss = -5.4304, learner_queue_size = 32, _tick = 32253, _time = 1.6548e+09, train_seconds = 3.2001e+04)
[2022-06-10 05:01:26,642][root][INFO] - Step 122334720 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 122334720, mean_episode_return = 30.597, mean_episode_step = 968.05, total_loss = -106.73, pg_loss = -127.45, baseline_loss = 26.249, entropy_loss = -5.5295, learner_queue_size = 32, _tick = 32258, _time = 1.6548e+09, train_seconds = 3.2006e+04)
[2022-06-10 05:01:31,646][root][INFO] - Step 122355200 @ 4092.9 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 122355200, mean_episode_return = 30.8, mean_episode_step = 815.71, total_loss = 122.54, pg_loss = 83.39, baseline_loss = 44.601, entropy_loss = -5.4467, learner_queue_size = 32, _tick = 32264, _time = 1.6548e+09, train_seconds = 3.2012e+04)
[2022-06-10 05:01:36,650][root][INFO] - Step 122375680 @ 4092.5 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 122375680, mean_episode_return = 33.705, mean_episode_step = 844.73, total_loss = 51.412, pg_loss = -20.741, baseline_loss = 77.596, entropy_loss = -5.443, learner_queue_size = 32, _tick = 32270, _time = 1.6548e+09, train_seconds = 3.2016e+04)
[2022-06-10 05:01:41,654][root][INFO] - Step 122393600 @ 3581.3 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 122393600, mean_episode_return = 79.5, mean_episode_step = 799.26, total_loss = -46.938, pg_loss = -74.96, baseline_loss = 33.57, entropy_loss = -5.5472, learner_queue_size = 32, _tick = 32274, _time = 1.6548e+09, train_seconds = 3.2022e+04)
[2022-06-10 05:01:46,658][root][INFO] - Step 122414080 @ 4092.7 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 122414080, mean_episode_return = 32.943, mean_episode_step = 819.67, total_loss = 300.27, pg_loss = 219.08, baseline_loss = 86.668, entropy_loss = -5.488, learner_queue_size = 32, _tick = 32282, _time = 1.6548e+09, train_seconds = 3.2026e+04)
[2022-06-10 05:01:51,662][root][INFO] - Step 122432000 @ 3581.2 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (step = 122432000, mean_episode_return = 72.909, mean_episode_step = 869.88, total_loss = 233.71, pg_loss = 132.08, baseline_loss = 107.1, entropy_loss = -5.4712, learner_queue_size = 32, _tick = 32289, _time = 1.6548e+09, train_seconds = 3.2032e+04)
[2022-06-10 05:01:56,666][root][INFO] - Step 122452480 @ 4092.6 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 122452480, mean_episode_return = 53.807, mean_episode_step = 865.53, total_loss = 6.9212, pg_loss = -20.607, baseline_loss = 33.184, entropy_loss = -5.6555, learner_queue_size = 32, _tick = 32295, _time = 1.6548e+09, train_seconds = 3.2036e+04)
[2022-06-10 05:02:01,670][root][INFO] - Step 122472960 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 122472960, mean_episode_return = 59.85, mean_episode_step = 851.69, total_loss = -246.7, pg_loss = -254.33, baseline_loss = 13.213, entropy_loss = -5.5873, learner_queue_size = 32, _tick = 32303, _time = 1.6548e+09, train_seconds = 3.2042e+04)
[2022-06-10 05:02:06,674][root][INFO] - Step 122493440 @ 4092.8 SPS. Inference batcher size: 48. Learner queue size: 13. Other stats: (step = 122493440, mean_episode_return = None, mean_episode_step = 1154.7, total_loss = 26.814, pg_loss = -6.0475, baseline_loss = 38.376, entropy_loss = -5.514, learner_queue_size = 32, _tick = 32307, _time = 1.6548e+09, train_seconds = 3.2046e+04)
[2022-06-10 05:02:11,678][root][INFO] - Step 122511360 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 122511360, mean_episode_return = 31.084, mean_episode_step = 888.98, total_loss = 37.361, pg_loss = -22.993, baseline_loss = 65.859, entropy_loss = -5.5055, learner_queue_size = 32, _tick = 32314, _time = 1.6548e+09, train_seconds = 3.2052e+04)
[2022-06-10 05:02:16,690][root][INFO] - Step 122531840 @ 4086.2 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 122531840, mean_episode_return = None, mean_episode_step = 892.06, total_loss = 172.98, pg_loss = 102.83, baseline_loss = 75.751, entropy_loss = -5.6082, learner_queue_size = 32, _tick = 32319, _time = 1.6548e+09, train_seconds = 3.2056e+04)
[2022-06-10 05:02:21,694][root][INFO] - Step 122549760 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 122549760, mean_episode_return = 54.114, mean_episode_step = 976.08, total_loss = 104.25, pg_loss = 62.184, baseline_loss = 47.771, entropy_loss = -5.7037, learner_queue_size = 32, _tick = 32326, _time = 1.6548e+09, train_seconds = 3.2062e+04)
[2022-06-10 05:02:26,698][root][INFO] - Step 122570240 @ 4092.8 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 122570240, mean_episode_return = 79.783, mean_episode_step = 934.6, total_loss = -88.418, pg_loss = -119.41, baseline_loss = 36.613, entropy_loss = -5.62, learner_queue_size = 32, _tick = 32334, _time = 1.6548e+09, train_seconds = 3.2066e+04)
[2022-06-10 05:02:31,702][root][INFO] - Step 122590720 @ 4092.7 SPS. Inference batcher size: 90. Learner queue size: 32. Other stats: (step = 122590720, mean_episode_return = 38.907, mean_episode_step = 864.22, total_loss = 86.373, pg_loss = 33.847, baseline_loss = 58.014, entropy_loss = -5.4891, learner_queue_size = 32, _tick = 32341, _time = 1.6548e+09, train_seconds = 3.2072e+04)
[2022-06-10 05:02:36,714][root][INFO] - Step 122608640 @ 3575.4 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 122608640, mean_episode_return = 5.2798, mean_episode_step = 958.09, total_loss = 43.587, pg_loss = 2.3507, baseline_loss = 46.793, entropy_loss = -5.5566, learner_queue_size = 32, _tick = 32344, _time = 1.6548e+09, train_seconds = 3.2076e+04)
[2022-06-10 05:02:41,726][root][INFO] - Step 122629120 @ 4085.9 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (step = 122629120, mean_episode_return = 91.12, mean_episode_step = 801.73, total_loss = 24.682, pg_loss = -11.023, baseline_loss = 40.928, entropy_loss = -5.2235, learner_queue_size = 32, _tick = 32352, _time = 1.6548e+09, train_seconds = 3.2082e+04)
[2022-06-10 05:02:46,738][root][INFO] - Step 122647040 @ 3575.7 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 122647040, mean_episode_return = 20.02, mean_episode_step = 1050.9, total_loss = 20.363, pg_loss = -45.342, baseline_loss = 71.152, entropy_loss = -5.4468, learner_queue_size = 32, _tick = 32359, _time = 1.6548e+09, train_seconds = 3.2086e+04)
[2022-06-10 05:02:51,742][root][INFO] - Step 122667520 @ 4092.7 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 122667520, mean_episode_return = 25.45, mean_episode_step = 774.03, total_loss = 87.748, pg_loss = 15.42, baseline_loss = 77.891, entropy_loss = -5.5632, learner_queue_size = 32, _tick = 32366, _time = 1.6548e+09, train_seconds = 3.2092e+04)
[2022-06-10 05:02:56,746][root][INFO] - Step 122685440 @ 3581.2 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 122685440, mean_episode_return = 71.235, mean_episode_step = 916.61, total_loss = 159.25, pg_loss = 94.768, baseline_loss = 70.043, entropy_loss = -5.5626, learner_queue_size = 32, _tick = 32371, _time = 1.6548e+09, train_seconds = 3.2097e+04)
[2022-06-10 05:03:01,752][root][INFO] - Step 122705920 @ 4091.1 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (step = 122705920, mean_episode_return = 97.909, mean_episode_step = 968.29, total_loss = 159.17, pg_loss = 115.89, baseline_loss = 48.735, entropy_loss = -5.4522, learner_queue_size = 32, _tick = 32378, _time = 1.6548e+09, train_seconds = 3.2102e+04)
[2022-06-10 05:03:06,758][root][INFO] - Step 122726400 @ 4091.1 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (step = 122726400, mean_episode_return = 46.663, mean_episode_step = 694.41, total_loss = 148.95, pg_loss = 74.08, baseline_loss = 80.257, entropy_loss = -5.3914, learner_queue_size = 32, _tick = 32384, _time = 1.6548e+09, train_seconds = 3.2107e+04)
[2022-06-10 05:03:11,766][root][INFO] - Step 122744320 @ 3578.3 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (step = 122744320, mean_episode_return = 114.6, mean_episode_step = 747.6, total_loss = -64.152, pg_loss = -103.15, baseline_loss = 44.444, entropy_loss = -5.4419, learner_queue_size = 32, _tick = 32389, _time = 1.6548e+09, train_seconds = 3.2112e+04)
[2022-06-10 05:03:16,771][root][INFO] - Step 122764800 @ 4092.1 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 122764800, mean_episode_return = None, mean_episode_step = 1070.3, total_loss = -185.2, pg_loss = -189.11, baseline_loss = 9.6381, entropy_loss = -5.7213, learner_queue_size = 32, _tick = 32395, _time = 1.6548e+09, train_seconds = 3.2117e+04)
[2022-06-10 05:03:21,774][root][INFO] - Step 122782720 @ 3581.7 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (step = 122782720, mean_episode_return = 16.75, mean_episode_step = 938.29, total_loss = 40.957, pg_loss = 8.2986, baseline_loss = 38.367, entropy_loss = -5.7087, learner_queue_size = 32, _tick = 32401, _time = 1.6548e+09, train_seconds = 3.2122e+04)
[2022-06-10 05:03:26,778][root][INFO] - Step 122803200 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 122803200, mean_episode_return = None, mean_episode_step = 827.5, total_loss = 236.11, pg_loss = 185.6, baseline_loss = 56.024, entropy_loss = -5.5148, learner_queue_size = 32, _tick = 32405, _time = 1.6548e+09, train_seconds = 3.2127e+04)
[2022-06-10 05:03:31,782][root][INFO] - Step 122821120 @ 3581.2 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 122821120, mean_episode_return = 72.512, mean_episode_step = 867.5, total_loss = 49.063, pg_loss = 15.567, baseline_loss = 39.048, entropy_loss = -5.5514, learner_queue_size = 32, _tick = 32411, _time = 1.6548e+09, train_seconds = 3.2132e+04)
[2022-06-10 05:03:36,787][root][INFO] - Step 122841600 @ 4092.2 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 122841600, mean_episode_return = 48.06, mean_episode_step = 958.67, total_loss = 323.22, pg_loss = 245.58, baseline_loss = 83.123, entropy_loss = -5.4779, learner_queue_size = 32, _tick = 32418, _time = 1.6548e+09, train_seconds = 3.2137e+04)
[2022-06-10 05:03:41,790][root][INFO] - Step 122859520 @ 3581.5 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 122859520, mean_episode_return = 41.991, mean_episode_step = 717.54, total_loss = 97.713, pg_loss = 43.401, baseline_loss = 59.786, entropy_loss = -5.4746, learner_queue_size = 32, _tick = 32423, _time = 1.6548e+09, train_seconds = 3.2142e+04)
[2022-06-10 05:03:46,794][root][INFO] - Step 122880000 @ 4092.9 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 122880000, mean_episode_return = 90.375, mean_episode_step = 878.95, total_loss = 121.56, pg_loss = 51.824, baseline_loss = 75.265, entropy_loss = -5.533, learner_queue_size = 32, _tick = 32430, _time = 1.6548e+09, train_seconds = 3.2147e+04)
[2022-06-10 05:03:51,797][root][INFO] - Step 122897920 @ 3581.6 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 122897920, mean_episode_return = 85.98, mean_episode_step = 1027.8, total_loss = 47.591, pg_loss = 10.961, baseline_loss = 42.141, entropy_loss = -5.51, learner_queue_size = 32, _tick = 32435, _time = 1.6548e+09, train_seconds = 3.2152e+04)
[2022-06-10 05:03:56,802][root][INFO] - Step 122918400 @ 4092.0 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 122918400, mean_episode_return = 1.18, mean_episode_step = 894.88, total_loss = 310.74, pg_loss = 234.95, baseline_loss = 81.169, entropy_loss = -5.3847, learner_queue_size = 32, _tick = 32442, _time = 1.6548e+09, train_seconds = 3.2157e+04)
[2022-06-10 05:04:01,806][root][INFO] - Step 122938880 @ 4092.6 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 122938880, mean_episode_return = -5.7002, mean_episode_step = 953.91, total_loss = 11.843, pg_loss = -22.979, baseline_loss = 40.385, entropy_loss = -5.5632, learner_queue_size = 32, _tick = 32447, _time = 1.6548e+09, train_seconds = 3.2162e+04)
[2022-06-10 05:04:06,810][root][INFO] - Step 122956800 @ 3581.3 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 122956800, mean_episode_return = 64.731, mean_episode_step = 1045.7, total_loss = 108.01, pg_loss = 63.397, baseline_loss = 49.954, entropy_loss = -5.3427, learner_queue_size = 32, _tick = 32452, _time = 1.6548e+09, train_seconds = 3.2167e+04)
[2022-06-10 05:04:11,814][root][INFO] - Step 122977280 @ 4092.8 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (step = 122977280, mean_episode_return = 40.16, mean_episode_step = 969.55, total_loss = 24.437, pg_loss = -23.961, baseline_loss = 53.559, entropy_loss = -5.1613, learner_queue_size = 32, _tick = 32459, _time = 1.6548e+09, train_seconds = 3.2172e+04)
[2022-06-10 05:04:16,819][root][INFO] - Step 122997760 @ 4092.0 SPS. Inference batcher size: 82. Learner queue size: 32. Other stats: (step = 122997760, mean_episode_return = 71.55, mean_episode_step = 949.95, total_loss = 52.687, pg_loss = -12.902, baseline_loss = 70.8, entropy_loss = -5.2113, learner_queue_size = 32, _tick = 32466, _time = 1.6548e+09, train_seconds = 3.2177e+04)
[2022-06-10 05:04:21,822][root][INFO] - Step 123015680 @ 3581.8 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 123015680, mean_episode_return = 61.986, mean_episode_step = 1072.5, total_loss = 90.185, pg_loss = 46.841, baseline_loss = 48.627, entropy_loss = -5.2842, learner_queue_size = 32, _tick = 32472, _time = 1.6548e+09, train_seconds = 3.2182e+04)
[2022-06-10 05:04:26,826][root][INFO] - Step 123036160 @ 4092.7 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (step = 123036160, mean_episode_return = 2.3549, mean_episode_step = 984.87, total_loss = 86.329, pg_loss = 32.236, baseline_loss = 59.328, entropy_loss = -5.2352, learner_queue_size = 32, _tick = 32478, _time = 1.6548e+09, train_seconds = 3.2187e+04)
[2022-06-10 05:04:31,830][root][INFO] - Step 123056640 @ 4092.6 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 123056640, mean_episode_return = 62.164, mean_episode_step = 977.76, total_loss = 74.172, pg_loss = 39.416, baseline_loss = 40.26, entropy_loss = -5.5032, learner_queue_size = 32, _tick = 32484, _time = 1.6548e+09, train_seconds = 3.2192e+04)
[2022-06-10 05:04:36,834][root][INFO] - Step 123074560 @ 3581.1 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 123074560, mean_episode_return = 48.88, mean_episode_step = 995.3, total_loss = 209.65, pg_loss = 75.677, baseline_loss = 139.51, entropy_loss = -5.5425, learner_queue_size = 32, _tick = 32490, _time = 1.6548e+09, train_seconds = 3.2197e+04)
[2022-06-10 05:04:41,838][root][INFO] - Step 123095040 @ 4092.5 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 123095040, mean_episode_return = 86.22, mean_episode_step = 1077.0, total_loss = 41.728, pg_loss = 0.20652, baseline_loss = 46.827, entropy_loss = -5.3056, learner_queue_size = 32, _tick = 32497, _time = 1.6548e+09, train_seconds = 3.2202e+04)
[2022-06-10 05:04:46,842][root][INFO] - Step 123115520 @ 4093.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 123115520, mean_episode_return = 11.26, mean_episode_step = 1119.8, total_loss = 17.52, pg_loss = -32.618, baseline_loss = 55.278, entropy_loss = -5.1398, learner_queue_size = 32, _tick = 32505, _time = 1.6548e+09, train_seconds = 3.2207e+04)
[2022-06-10 05:04:51,846][root][INFO] - Step 123136000 @ 4092.5 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (step = 123136000, mean_episode_return = 42.01, mean_episode_step = 1014.3, total_loss = -1.503, pg_loss = -35.747, baseline_loss = 39.654, entropy_loss = -5.41, learner_queue_size = 32, _tick = 32512, _time = 1.6548e+09, train_seconds = 3.2212e+04)
[2022-06-10 05:04:56,850][root][INFO] - Step 123153920 @ 3581.3 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 123153920, mean_episode_return = 58.861, mean_episode_step = 1205.3, total_loss = -40.241, pg_loss = -63.507, baseline_loss = 28.761, entropy_loss = -5.4945, learner_queue_size = 32, _tick = 32518, _time = 1.6548e+09, train_seconds = 3.2217e+04)
[2022-06-10 05:05:01,854][root][INFO] - Step 123174400 @ 4092.8 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 123174400, mean_episode_return = 19.045, mean_episode_step = 974.67, total_loss = 68.192, pg_loss = 18.009, baseline_loss = 55.79, entropy_loss = -5.6065, learner_queue_size = 32, _tick = 32526, _time = 1.6548e+09, train_seconds = 3.2222e+04)
[2022-06-10 05:05:06,858][root][INFO] - Step 123194880 @ 4092.7 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 123194880, mean_episode_return = 100.77, mean_episode_step = 1012.0, total_loss = 58.763, pg_loss = 25.111, baseline_loss = 39.001, entropy_loss = -5.349, learner_queue_size = 32, _tick = 32534, _time = 1.6548e+09, train_seconds = 3.2227e+04)
[2022-06-10 05:05:11,862][root][INFO] - Step 123212800 @ 3580.8 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 123212800, mean_episode_return = None, mean_episode_step = 1056.0, total_loss = 177.11, pg_loss = 128.73, baseline_loss = 53.944, entropy_loss = -5.5579, learner_queue_size = 32, _tick = 32540, _time = 1.6548e+09, train_seconds = 3.2232e+04)
[2022-06-10 05:05:16,866][root][INFO] - Step 123230720 @ 3581.5 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 123230720, mean_episode_return = 8.225, mean_episode_step = 945.4, total_loss = 116.76, pg_loss = -7.755, baseline_loss = 129.96, entropy_loss = -5.4492, learner_queue_size = 32, _tick = 32546, _time = 1.6548e+09, train_seconds = 3.2237e+04)
[2022-06-10 05:05:21,870][root][INFO] - Step 123251200 @ 4092.7 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 123251200, mean_episode_return = 47.316, mean_episode_step = 966.1, total_loss = 26.127, pg_loss = -21.964, baseline_loss = 53.736, entropy_loss = -5.6456, learner_queue_size = 32, _tick = 32553, _time = 1.6548e+09, train_seconds = 3.2242e+04)
[2022-06-10 05:05:26,874][root][INFO] - Step 123269120 @ 3581.2 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 123269120, mean_episode_return = 22.55, mean_episode_step = 951.03, total_loss = 184.9, pg_loss = 125.62, baseline_loss = 64.836, entropy_loss = -5.5549, learner_queue_size = 32, _tick = 32558, _time = 1.6548e+09, train_seconds = 3.2247e+04)
[2022-06-10 05:05:31,878][root][INFO] - Step 123289600 @ 4092.7 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 123289600, mean_episode_return = 57.572, mean_episode_step = 886.3, total_loss = 137.59, pg_loss = 74.072, baseline_loss = 68.925, entropy_loss = -5.4108, learner_queue_size = 32, _tick = 32564, _time = 1.6548e+09, train_seconds = 3.2252e+04)
[2022-06-10 05:05:36,882][root][INFO] - Step 123310080 @ 4092.7 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 123310080, mean_episode_return = 154.73, mean_episode_step = 905.27, total_loss = 221.97, pg_loss = 189.84, baseline_loss = 37.383, entropy_loss = -5.2575, learner_queue_size = 32, _tick = 32571, _time = 1.6548e+09, train_seconds = 3.2257e+04)
[2022-06-10 05:05:41,886][root][INFO] - Step 123328000 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 123328000, mean_episode_return = 18.333, mean_episode_step = 913.56, total_loss = -67.461, pg_loss = -105.9, baseline_loss = 43.873, entropy_loss = -5.4372, learner_queue_size = 32, _tick = 32578, _time = 1.6548e+09, train_seconds = 3.2262e+04)
[2022-06-10 05:05:46,890][root][INFO] - Step 123348480 @ 4092.8 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 123348480, mean_episode_return = 61.46, mean_episode_step = 1051.3, total_loss = -137.16, pg_loss = -165.91, baseline_loss = 34.338, entropy_loss = -5.5891, learner_queue_size = 32, _tick = 32584, _time = 1.6548e+09, train_seconds = 3.2267e+04)
[2022-06-10 05:05:51,894][root][INFO] - Step 123368960 @ 4092.8 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 123368960, mean_episode_return = 68.247, mean_episode_step = 1074.6, total_loss = 50.142, pg_loss = 15.71, baseline_loss = 40.177, entropy_loss = -5.7447, learner_queue_size = 32, _tick = 32588, _time = 1.6548e+09, train_seconds = 3.2272e+04)
[2022-06-10 05:05:56,898][root][INFO] - Step 123386880 @ 3580.8 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 123386880, mean_episode_return = 95.199, mean_episode_step = 953.1, total_loss = 297.91, pg_loss = 210.69, baseline_loss = 92.922, entropy_loss = -5.7028, learner_queue_size = 32, _tick = 32593, _time = 1.6548e+09, train_seconds = 3.2277e+04)
[2022-06-10 05:06:01,902][root][INFO] - Step 123407360 @ 4093.0 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 123407360, mean_episode_return = 136.22, mean_episode_step = 1054.8, total_loss = 35.01, pg_loss = 15.928, baseline_loss = 24.657, entropy_loss = -5.5755, learner_queue_size = 32, _tick = 32600, _time = 1.6548e+09, train_seconds = 3.2282e+04)
[2022-06-10 05:06:06,906][root][INFO] - Step 123427840 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 123427840, mean_episode_return = None, mean_episode_step = 1107.9, total_loss = -173.58, pg_loss = -184.35, baseline_loss = 16.394, entropy_loss = -5.6253, learner_queue_size = 32, _tick = 32604, _time = 1.6548e+09, train_seconds = 3.2287e+04)
[2022-06-10 05:06:11,910][root][INFO] - Step 123445760 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 123445760, mean_episode_return = 59.141, mean_episode_step = 960.32, total_loss = 171.84, pg_loss = 116.66, baseline_loss = 60.778, entropy_loss = -5.6019, learner_queue_size = 32, _tick = 32609, _time = 1.6548e+09, train_seconds = 3.2292e+04)
[2022-06-10 05:06:16,914][root][INFO] - Step 123466240 @ 4092.7 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 123466240, mean_episode_return = 68.97, mean_episode_step = 1200.5, total_loss = 132.88, pg_loss = 98.944, baseline_loss = 39.499, entropy_loss = -5.566, learner_queue_size = 32, _tick = 32616, _time = 1.6548e+09, train_seconds = 3.2297e+04)
[2022-06-10 05:06:21,918][root][INFO] - Step 123486720 @ 4092.8 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 123486720, mean_episode_return = 80.815, mean_episode_step = 1205.6, total_loss = 84.204, pg_loss = 29.99, baseline_loss = 59.776, entropy_loss = -5.5628, learner_queue_size = 32, _tick = 32621, _time = 1.6548e+09, train_seconds = 3.2302e+04)
[2022-06-10 05:06:26,922][root][INFO] - Step 123504640 @ 3581.2 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 123504640, mean_episode_return = None, mean_episode_step = 854.91, total_loss = -143.07, pg_loss = -187.59, baseline_loss = 50.14, entropy_loss = -5.6238, learner_queue_size = 32, _tick = 32626, _time = 1.6548e+09, train_seconds = 3.2307e+04)
[2022-06-10 05:06:31,926][root][INFO] - Step 123525120 @ 4092.6 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 123525120, mean_episode_return = None, mean_episode_step = 1354.5, total_loss = 133.43, pg_loss = 57.77, baseline_loss = 81.2, entropy_loss = -5.5434, learner_queue_size = 32, _tick = 32632, _time = 1.6548e+09, train_seconds = 3.2312e+04)
[2022-06-10 05:06:36,933][root][INFO] - Step 123543040 @ 3579.4 SPS. Inference batcher size: 92. Learner queue size: 32. Other stats: (step = 123543040, mean_episode_return = 39.4, mean_episode_step = 1117.6, total_loss = 262.15, pg_loss = 185.82, baseline_loss = 82.004, entropy_loss = -5.6668, learner_queue_size = 32, _tick = 32635, _time = 1.6548e+09, train_seconds = 3.2317e+04)
[2022-06-10 05:06:41,938][root][INFO] - Step 123563520 @ 4091.5 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 123563520, mean_episode_return = 95.51, mean_episode_step = 939.41, total_loss = 142.66, pg_loss = 91.742, baseline_loss = 56.63, entropy_loss = -5.7156, learner_queue_size = 32, _tick = 32643, _time = 1.6548e+09, train_seconds = 3.2322e+04)
[2022-06-10 05:06:46,944][root][INFO] - Step 123584000 @ 4091.1 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 123584000, mean_episode_return = None, mean_episode_step = 977.06, total_loss = 398.93, pg_loss = 344.16, baseline_loss = 60.377, entropy_loss = -5.6045, learner_queue_size = 32, _tick = 32649, _time = 1.6548e+09, train_seconds = 3.2327e+04)
[2022-06-10 05:06:51,946][root][INFO] - Step 123601920 @ 3582.5 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 123601920, mean_episode_return = -2.21, mean_episode_step = 1017.3, total_loss = 495.69, pg_loss = 414.74, baseline_loss = 86.538, entropy_loss = -5.5852, learner_queue_size = 32, _tick = 32655, _time = 1.6548e+09, train_seconds = 3.2332e+04)
[2022-06-10 05:06:56,950][root][INFO] - Step 123622400 @ 4092.8 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 123622400, mean_episode_return = None, mean_episode_step = 806.59, total_loss = 67.982, pg_loss = 49.613, baseline_loss = 24.013, entropy_loss = -5.6452, learner_queue_size = 32, _tick = 32661, _time = 1.6548e+09, train_seconds = 3.2337e+04)
[2022-06-10 05:07:01,955][root][INFO] - Step 123640320 @ 3580.3 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 123640320, mean_episode_return = 144.53, mean_episode_step = 908.78, total_loss = 169.05, pg_loss = 106.53, baseline_loss = 68.081, entropy_loss = -5.5597, learner_queue_size = 32, _tick = 32668, _time = 1.6548e+09, train_seconds = 3.2342e+04)
[2022-06-10 05:07:06,961][root][INFO] - Step 123660800 @ 4091.1 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (step = 123660800, mean_episode_return = 28.05, mean_episode_step = 876.7, total_loss = -2.9933, pg_loss = -99.692, baseline_loss = 102.13, entropy_loss = -5.433, learner_queue_size = 32, _tick = 32673, _time = 1.6548e+09, train_seconds = 3.2347e+04)
[2022-06-10 05:07:11,966][root][INFO] - Step 123681280 @ 4092.0 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 123681280, mean_episode_return = 62.957, mean_episode_step = 955.59, total_loss = -123.65, pg_loss = -150.07, baseline_loss = 32.042, entropy_loss = -5.617, learner_queue_size = 32, _tick = 32679, _time = 1.6548e+09, train_seconds = 3.2352e+04)
[2022-06-10 05:07:16,970][root][INFO] - Step 123699200 @ 3581.1 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (step = 123699200, mean_episode_return = 63.5, mean_episode_step = 1143.9, total_loss = -95.786, pg_loss = -96.839, baseline_loss = 7.0574, entropy_loss = -6.0041, learner_queue_size = 32, _tick = 32686, _time = 1.6548e+09, train_seconds = 3.2357e+04)
[2022-06-10 05:07:21,974][root][INFO] - Step 123719680 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 123719680, mean_episode_return = 73.913, mean_episode_step = 1150.4, total_loss = 280.99, pg_loss = 237.21, baseline_loss = 49.575, entropy_loss = -5.7928, learner_queue_size = 32, _tick = 32693, _time = 1.6548e+09, train_seconds = 3.2362e+04)
[2022-06-10 05:07:26,978][root][INFO] - Step 123740160 @ 4092.4 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 123740160, mean_episode_return = 1.27, mean_episode_step = 951.25, total_loss = 93.489, pg_loss = 28.332, baseline_loss = 70.883, entropy_loss = -5.7257, learner_queue_size = 32, _tick = 32701, _time = 1.6548e+09, train_seconds = 3.2367e+04)
[2022-06-10 05:07:31,982][root][INFO] - Step 123758080 @ 3581.4 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 123758080, mean_episode_return = 68.745, mean_episode_step = 815.94, total_loss = 21.129, pg_loss = -9.3231, baseline_loss = 36.208, entropy_loss = -5.756, learner_queue_size = 32, _tick = 32706, _time = 1.6548e+09, train_seconds = 3.2372e+04)
[2022-06-10 05:07:36,986][root][INFO] - Step 123778560 @ 4092.7 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 123778560, mean_episode_return = 73.71, mean_episode_step = 977.09, total_loss = -19.607, pg_loss = -28.807, baseline_loss = 14.962, entropy_loss = -5.7612, learner_queue_size = 32, _tick = 32713, _time = 1.6548e+09, train_seconds = 3.2377e+04)
[2022-06-10 05:07:41,991][root][INFO] - Step 123799040 @ 4091.6 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 123799040, mean_episode_return = -3.4036, mean_episode_step = 1092.5, total_loss = -123.78, pg_loss = -143.43, baseline_loss = 25.283, entropy_loss = -5.6264, learner_queue_size = 32, _tick = 32720, _time = 1.6548e+09, train_seconds = 3.2382e+04)
[2022-06-10 05:07:46,994][root][INFO] - Step 123816960 @ 3582.1 SPS. Inference batcher size: 97. Learner queue size: 32. Other stats: (step = 123816960, mean_episode_return = None, mean_episode_step = 894.53, total_loss = -87.888, pg_loss = -103.81, baseline_loss = 21.362, entropy_loss = -5.4425, learner_queue_size = 32, _tick = 32724, _time = 1.6548e+09, train_seconds = 3.2387e+04)
[2022-06-10 05:07:51,998][root][INFO] - Step 123834880 @ 3581.2 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 123834880, mean_episode_return = 40.194, mean_episode_step = 1231.4, total_loss = -6.8551, pg_loss = -33.496, baseline_loss = 32.536, entropy_loss = -5.8947, learner_queue_size = 32, _tick = 32730, _time = 1.6548e+09, train_seconds = 3.2392e+04)
[2022-06-10 05:07:57,002][root][INFO] - Step 123855360 @ 4092.6 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 123855360, mean_episode_return = None, mean_episode_step = 993.81, total_loss = 117.85, pg_loss = 87.531, baseline_loss = 36.115, entropy_loss = -5.7916, learner_queue_size = 32, _tick = 32735, _time = 1.6548e+09, train_seconds = 3.2397e+04)
[2022-06-10 05:08:02,006][root][INFO] - Step 123875840 @ 4092.8 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 123875840, mean_episode_return = 53.851, mean_episode_step = 937.3, total_loss = 387.48, pg_loss = 282.53, baseline_loss = 110.63, entropy_loss = -5.6762, learner_queue_size = 32, _tick = 32740, _time = 1.6548e+09, train_seconds = 3.2402e+04)
[2022-06-10 05:08:07,010][root][INFO] - Step 123893760 @ 3581.2 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 123893760, mean_episode_return = 123.82, mean_episode_step = 1021.6, total_loss = -215.75, pg_loss = -237.19, baseline_loss = 27.103, entropy_loss = -5.6618, learner_queue_size = 32, _tick = 32744, _time = 1.6548e+09, train_seconds = 3.2407e+04)
[2022-06-10 05:08:12,014][root][INFO] - Step 123914240 @ 4092.7 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 123914240, mean_episode_return = 143.77, mean_episode_step = 1182.9, total_loss = 94.996, pg_loss = 41.092, baseline_loss = 59.588, entropy_loss = -5.6844, learner_queue_size = 32, _tick = 32751, _time = 1.6548e+09, train_seconds = 3.2412e+04)
[2022-06-10 05:08:17,018][root][INFO] - Step 123932160 @ 3581.1 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 123932160, mean_episode_return = 12.17, mean_episode_step = 1244.9, total_loss = -78.372, pg_loss = -115.52, baseline_loss = 43.055, entropy_loss = -5.9054, learner_queue_size = 32, _tick = 32758, _time = 1.6548e+09, train_seconds = 3.2417e+04)
[2022-06-10 05:08:22,022][root][INFO] - Step 123952640 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 123952640, mean_episode_return = 52.97, mean_episode_step = 1170.2, total_loss = 91.403, pg_loss = 55.4, baseline_loss = 41.859, entropy_loss = -5.8551, learner_queue_size = 32, _tick = 32762, _time = 1.6548e+09, train_seconds = 3.2422e+04)
[2022-06-10 05:08:27,027][root][INFO] - Step 123973120 @ 4092.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 123973120, mean_episode_return = 29.393, mean_episode_step = 1226.1, total_loss = 347.96, pg_loss = 265.22, baseline_loss = 88.639, entropy_loss = -5.9, learner_queue_size = 32, _tick = 32769, _time = 1.6548e+09, train_seconds = 3.2427e+04)
[2022-06-10 05:08:32,030][root][INFO] - Step 123991040 @ 3581.5 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 123991040, mean_episode_return = 52.345, mean_episode_step = 1037.0, total_loss = -17.246, pg_loss = -99.2, baseline_loss = 87.821, entropy_loss = -5.867, learner_queue_size = 32, _tick = 32776, _time = 1.6548e+09, train_seconds = 3.2432e+04)
[2022-06-10 05:08:37,034][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 05:08:37,180][root][INFO] - Step 124011520 @ 4092.9 SPS. Inference batcher size: 91. Learner queue size: 32. Other stats: (step = 124011520, mean_episode_return = None, mean_episode_step = 1167.5, total_loss = 111.02, pg_loss = 70.501, baseline_loss = 46.362, entropy_loss = -5.8462, learner_queue_size = 32, _tick = 32782, _time = 1.6548e+09, train_seconds = 3.2437e+04)
[2022-06-10 05:08:42,182][root][INFO] - Step 124029440 @ 3480.9 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 124029440, mean_episode_return = 61.922, mean_episode_step = 1101.3, total_loss = 366.64, pg_loss = 265.54, baseline_loss = 107.02, entropy_loss = -5.9303, learner_queue_size = 32, _tick = 32788, _time = 1.6548e+09, train_seconds = 3.2442e+04)
[2022-06-10 05:08:47,186][root][INFO] - Step 124049920 @ 4092.8 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 124049920, mean_episode_return = 64.97, mean_episode_step = 1100.0, total_loss = -58.88, pg_loss = -86.353, baseline_loss = 33.374, entropy_loss = -5.9005, learner_queue_size = 32, _tick = 32795, _time = 1.6548e+09, train_seconds = 3.2447e+04)
[2022-06-10 05:08:52,190][root][INFO] - Step 124067840 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 124067840, mean_episode_return = 126.34, mean_episode_step = 1206.3, total_loss = 228.78, pg_loss = 119.13, baseline_loss = 115.51, entropy_loss = -5.8525, learner_queue_size = 32, _tick = 32801, _time = 1.6548e+09, train_seconds = 3.2452e+04)
[2022-06-10 05:08:57,194][root][INFO] - Step 124088320 @ 4092.7 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 124088320, mean_episode_return = 45.977, mean_episode_step = 997.27, total_loss = 265.94, pg_loss = 195.53, baseline_loss = 76.17, entropy_loss = -5.7621, learner_queue_size = 32, _tick = 32809, _time = 1.6548e+09, train_seconds = 3.2457e+04)
[2022-06-10 05:09:02,198][root][INFO] - Step 124106240 @ 3581.1 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 124106240, mean_episode_return = 15.203, mean_episode_step = 1129.0, total_loss = -116.47, pg_loss = -147.75, baseline_loss = 37.035, entropy_loss = -5.7509, learner_queue_size = 32, _tick = 32816, _time = 1.6548e+09, train_seconds = 3.2462e+04)
[2022-06-10 05:09:07,209][root][INFO] - Step 124126720 @ 4086.9 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 124126720, mean_episode_return = 5.9347, mean_episode_step = 1318.2, total_loss = 49.981, pg_loss = 32.592, baseline_loss = 23.304, entropy_loss = -5.9161, learner_queue_size = 32, _tick = 32820, _time = 1.6548e+09, train_seconds = 3.2467e+04)
[2022-06-10 05:09:12,214][root][INFO] - Step 124147200 @ 4091.9 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 124147200, mean_episode_return = 75.304, mean_episode_step = 1149.2, total_loss = 147.29, pg_loss = 89.187, baseline_loss = 63.913, entropy_loss = -5.8123, learner_queue_size = 32, _tick = 32827, _time = 1.6548e+09, train_seconds = 3.2472e+04)
[2022-06-10 05:09:17,218][root][INFO] - Step 124165120 @ 3580.8 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 124165120, mean_episode_return = None, mean_episode_step = 878.22, total_loss = -37.038, pg_loss = -55.038, baseline_loss = 23.652, entropy_loss = -5.6526, learner_queue_size = 32, _tick = 32832, _time = 1.6548e+09, train_seconds = 3.2477e+04)
[2022-06-10 05:09:22,222][root][INFO] - Step 124185600 @ 4093.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 124185600, mean_episode_return = None, mean_episode_step = 1041.5, total_loss = 507.3, pg_loss = 348.89, baseline_loss = 164.14, entropy_loss = -5.7258, learner_queue_size = 32, _tick = 32836, _time = 1.6548e+09, train_seconds = 3.2482e+04)
[2022-06-10 05:09:27,226][root][INFO] - Step 124203520 @ 3581.2 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 124203520, mean_episode_return = 68.409, mean_episode_step = 1143.0, total_loss = 201.07, pg_loss = 122.93, baseline_loss = 83.749, entropy_loss = -5.6183, learner_queue_size = 32, _tick = 32841, _time = 1.6548e+09, train_seconds = 3.2487e+04)
[2022-06-10 05:09:32,230][root][INFO] - Step 124224000 @ 4092.7 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 124224000, mean_episode_return = 13.42, mean_episode_step = 859.4, total_loss = 100.65, pg_loss = 58.684, baseline_loss = 47.439, entropy_loss = -5.4716, learner_queue_size = 32, _tick = 32847, _time = 1.6548e+09, train_seconds = 3.2492e+04)
[2022-06-10 05:09:37,234][root][INFO] - Step 124244480 @ 4092.7 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 124244480, mean_episode_return = 55.41, mean_episode_step = 1071.6, total_loss = 1.2695, pg_loss = -57.582, baseline_loss = 64.476, entropy_loss = -5.6241, learner_queue_size = 32, _tick = 32853, _time = 1.6548e+09, train_seconds = 3.2497e+04)
[2022-06-10 05:09:42,239][root][INFO] - Step 124262400 @ 3580.5 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 124262400, mean_episode_return = 27.11, mean_episode_step = 1106.6, total_loss = -46.08, pg_loss = -108.97, baseline_loss = 68.571, entropy_loss = -5.6808, learner_queue_size = 32, _tick = 32858, _time = 1.6548e+09, train_seconds = 3.2502e+04)
[2022-06-10 05:09:47,242][root][INFO] - Step 124282880 @ 4093.2 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 124282880, mean_episode_return = 26.69, mean_episode_step = 1119.3, total_loss = 139.17, pg_loss = 74.811, baseline_loss = 70.067, entropy_loss = -5.7046, learner_queue_size = 32, _tick = 32866, _time = 1.6548e+09, train_seconds = 3.2507e+04)
[2022-06-10 05:09:52,246][root][INFO] - Step 124303360 @ 4092.9 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 124303360, mean_episode_return = 45.301, mean_episode_step = 1159.2, total_loss = 25.054, pg_loss = -11.717, baseline_loss = 42.436, entropy_loss = -5.6649, learner_queue_size = 32, _tick = 32873, _time = 1.6548e+09, train_seconds = 3.2512e+04)
[2022-06-10 05:09:57,252][root][INFO] - Step 124321280 @ 3580.0 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 124321280, mean_episode_return = 141.29, mean_episode_step = 975.19, total_loss = 159.54, pg_loss = 103.83, baseline_loss = 61.362, entropy_loss = -5.6439, learner_queue_size = 32, _tick = 32878, _time = 1.6548e+09, train_seconds = 3.2517e+04)
[2022-06-10 05:10:02,254][root][INFO] - Step 124341760 @ 4094.0 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 124341760, mean_episode_return = 22.27, mean_episode_step = 1251.9, total_loss = -59.278, pg_loss = -103.51, baseline_loss = 49.889, entropy_loss = -5.6619, learner_queue_size = 32, _tick = 32885, _time = 1.6548e+09, train_seconds = 3.2522e+04)
[2022-06-10 05:10:07,258][root][INFO] - Step 124362240 @ 4092.5 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 124362240, mean_episode_return = 37.333, mean_episode_step = 945.96, total_loss = 211.36, pg_loss = 133.75, baseline_loss = 83.277, entropy_loss = -5.6702, learner_queue_size = 32, _tick = 32891, _time = 1.6548e+09, train_seconds = 3.2527e+04)
[2022-06-10 05:10:12,262][root][INFO] - Step 124380160 @ 3581.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 124380160, mean_episode_return = 73.921, mean_episode_step = 1118.9, total_loss = 168.11, pg_loss = 120.5, baseline_loss = 53.326, entropy_loss = -5.721, learner_queue_size = 32, _tick = 32897, _time = 1.6548e+09, train_seconds = 3.2532e+04)
[2022-06-10 05:10:17,266][root][INFO] - Step 124400640 @ 4092.8 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 124400640, mean_episode_return = 29.38, mean_episode_step = 976.2, total_loss = 143.21, pg_loss = 90.869, baseline_loss = 58.06, entropy_loss = -5.7237, learner_queue_size = 32, _tick = 32905, _time = 1.6548e+09, train_seconds = 3.2537e+04)
[2022-06-10 05:10:22,270][root][INFO] - Step 124418560 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 124418560, mean_episode_return = 28.15, mean_episode_step = 1160.1, total_loss = 520.29, pg_loss = 402.92, baseline_loss = 123.06, entropy_loss = -5.6902, learner_queue_size = 32, _tick = 32910, _time = 1.6548e+09, train_seconds = 3.2542e+04)
[2022-06-10 05:10:27,274][root][INFO] - Step 124439040 @ 4092.7 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (step = 124439040, mean_episode_return = 45.481, mean_episode_step = 1126.1, total_loss = 181.97, pg_loss = 134.43, baseline_loss = 53.183, entropy_loss = -5.6441, learner_queue_size = 32, _tick = 32917, _time = 1.6548e+09, train_seconds = 3.2547e+04)
[2022-06-10 05:10:32,278][root][INFO] - Step 124459520 @ 4092.8 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 124459520, mean_episode_return = 55.291, mean_episode_step = 936.87, total_loss = 338.44, pg_loss = 215.37, baseline_loss = 128.54, entropy_loss = -5.4663, learner_queue_size = 32, _tick = 32923, _time = 1.6548e+09, train_seconds = 3.2552e+04)
[2022-06-10 05:10:37,282][root][INFO] - Step 124477440 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 124477440, mean_episode_return = 46.5, mean_episode_step = 993.84, total_loss = -172.61, pg_loss = -184.99, baseline_loss = 17.954, entropy_loss = -5.5783, learner_queue_size = 32, _tick = 32930, _time = 1.6548e+09, train_seconds = 3.2557e+04)
[2022-06-10 05:10:42,286][root][INFO] - Step 124497920 @ 4092.7 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (step = 124497920, mean_episode_return = 61.54, mean_episode_step = 916.82, total_loss = 216.67, pg_loss = 142.17, baseline_loss = 80.246, entropy_loss = -5.7471, learner_queue_size = 32, _tick = 32937, _time = 1.6548e+09, train_seconds = 3.2562e+04)
[2022-06-10 05:10:47,290][root][INFO] - Step 124518400 @ 4092.7 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 124518400, mean_episode_return = 53.361, mean_episode_step = 797.44, total_loss = 65.905, pg_loss = 11.757, baseline_loss = 59.777, entropy_loss = -5.6278, learner_queue_size = 32, _tick = 32945, _time = 1.6548e+09, train_seconds = 3.2567e+04)
[2022-06-10 05:10:52,294][root][INFO] - Step 124538880 @ 4092.6 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 124538880, mean_episode_return = 27.0, mean_episode_step = 981.94, total_loss = 86.635, pg_loss = 58.268, baseline_loss = 33.803, entropy_loss = -5.4367, learner_queue_size = 32, _tick = 32951, _time = 1.6548e+09, train_seconds = 3.2572e+04)
[2022-06-10 05:10:57,298][root][INFO] - Step 124556800 @ 3581.2 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 124556800, mean_episode_return = 77.145, mean_episode_step = 1049.0, total_loss = -89.529, pg_loss = -115.15, baseline_loss = 31.278, entropy_loss = -5.6623, learner_queue_size = 32, _tick = 32958, _time = 1.6548e+09, train_seconds = 3.2577e+04)
[2022-06-10 05:11:02,304][root][INFO] - Step 124577280 @ 4090.9 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 124577280, mean_episode_return = 43.2, mean_episode_step = 1134.3, total_loss = 113.31, pg_loss = 51.934, baseline_loss = 67.119, entropy_loss = -5.7427, learner_queue_size = 32, _tick = 32965, _time = 1.6548e+09, train_seconds = 3.2582e+04)
[2022-06-10 05:11:07,310][root][INFO] - Step 124597760 @ 4091.2 SPS. Inference batcher size: 93. Learner queue size: 32. Other stats: (step = 124597760, mean_episode_return = 92.433, mean_episode_step = 1156.5, total_loss = 93.974, pg_loss = 36.176, baseline_loss = 63.442, entropy_loss = -5.6435, learner_queue_size = 32, _tick = 32972, _time = 1.6548e+09, train_seconds = 3.2587e+04)
[2022-06-10 05:11:12,314][root][INFO] - Step 124615680 @ 3581.2 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 124615680, mean_episode_return = -5.3453, mean_episode_step = 1076.1, total_loss = -33.022, pg_loss = -64.307, baseline_loss = 36.647, entropy_loss = -5.362, learner_queue_size = 32, _tick = 32975, _time = 1.6548e+09, train_seconds = 3.2592e+04)
[2022-06-10 05:11:17,318][root][INFO] - Step 124636160 @ 4092.7 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 124636160, mean_episode_return = None, mean_episode_step = 1127.2, total_loss = 19.575, pg_loss = -17.03, baseline_loss = 41.88, entropy_loss = -5.2751, learner_queue_size = 32, _tick = 32981, _time = 1.6548e+09, train_seconds = 3.2597e+04)
[2022-06-10 05:11:22,322][root][INFO] - Step 124654080 @ 3581.2 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 124654080, mean_episode_return = 60.495, mean_episode_step = 1019.8, total_loss = 103.42, pg_loss = 61.906, baseline_loss = 46.804, entropy_loss = -5.2921, learner_queue_size = 32, _tick = 32987, _time = 1.6548e+09, train_seconds = 3.2602e+04)
[2022-06-10 05:11:27,326][root][INFO] - Step 124674560 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 124674560, mean_episode_return = None, mean_episode_step = 882.69, total_loss = 118.82, pg_loss = 66.458, baseline_loss = 57.72, entropy_loss = -5.3631, learner_queue_size = 32, _tick = 32993, _time = 1.6548e+09, train_seconds = 3.2607e+04)
[2022-06-10 05:11:32,330][root][INFO] - Step 124695040 @ 4092.7 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 124695040, mean_episode_return = 61.11, mean_episode_step = 697.12, total_loss = 220.95, pg_loss = 166.23, baseline_loss = 59.94, entropy_loss = -5.2219, learner_queue_size = 32, _tick = 32999, _time = 1.6548e+09, train_seconds = 3.2612e+04)
[2022-06-10 05:11:37,335][root][INFO] - Step 124712960 @ 3580.6 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 124712960, mean_episode_return = None, mean_episode_step = 1001.4, total_loss = 38.3, pg_loss = 18.317, baseline_loss = 25.36, entropy_loss = -5.3759, learner_queue_size = 32, _tick = 33004, _time = 1.6548e+09, train_seconds = 3.2617e+04)
[2022-06-10 05:11:42,338][root][INFO] - Step 124733440 @ 4093.4 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 124733440, mean_episode_return = None, mean_episode_step = 937.28, total_loss = 35.616, pg_loss = 8.1351, baseline_loss = 32.925, entropy_loss = -5.4444, learner_queue_size = 32, _tick = 33010, _time = 1.6548e+09, train_seconds = 3.2622e+04)
[2022-06-10 05:11:47,342][root][INFO] - Step 124753920 @ 4092.6 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 124753920, mean_episode_return = 58.771, mean_episode_step = 977.85, total_loss = 176.37, pg_loss = 94.37, baseline_loss = 87.317, entropy_loss = -5.3201, learner_queue_size = 32, _tick = 33015, _time = 1.6548e+09, train_seconds = 3.2627e+04)
[2022-06-10 05:11:52,346][root][INFO] - Step 124771840 @ 3581.2 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 124771840, mean_episode_return = 15.74, mean_episode_step = 1268.8, total_loss = 116.74, pg_loss = 10.856, baseline_loss = 111.57, entropy_loss = -5.6778, learner_queue_size = 32, _tick = 33020, _time = 1.6548e+09, train_seconds = 3.2632e+04)
[2022-06-10 05:11:57,350][root][INFO] - Step 124792320 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 124792320, mean_episode_return = 141.99, mean_episode_step = 1110.0, total_loss = 49.19, pg_loss = 8.8553, baseline_loss = 45.895, entropy_loss = -5.5597, learner_queue_size = 32, _tick = 33028, _time = 1.6548e+09, train_seconds = 3.2637e+04)
[2022-06-10 05:12:02,354][root][INFO] - Step 124812800 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 124812800, mean_episode_return = None, mean_episode_step = 1101.5, total_loss = 169.03, pg_loss = 130.36, baseline_loss = 44.164, entropy_loss = -5.4939, learner_queue_size = 32, _tick = 33034, _time = 1.6548e+09, train_seconds = 3.2642e+04)
[2022-06-10 05:12:07,359][root][INFO] - Step 124830720 @ 3580.6 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (step = 124830720, mean_episode_return = 74.59, mean_episode_step = 1172.3, total_loss = 90.583, pg_loss = -28.409, baseline_loss = 124.24, entropy_loss = -5.2511, learner_queue_size = 32, _tick = 33039, _time = 1.6548e+09, train_seconds = 3.2647e+04)
[2022-06-10 05:12:12,362][root][INFO] - Step 124851200 @ 4093.4 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 124851200, mean_episode_return = None, mean_episode_step = 1119.1, total_loss = 187.8, pg_loss = 140.12, baseline_loss = 53.086, entropy_loss = -5.4047, learner_queue_size = 32, _tick = 33044, _time = 1.6548e+09, train_seconds = 3.2652e+04)
[2022-06-10 05:12:17,366][root][INFO] - Step 124869120 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 124869120, mean_episode_return = None, mean_episode_step = 963.91, total_loss = 32.4, pg_loss = -6.6174, baseline_loss = 44.504, entropy_loss = -5.4866, learner_queue_size = 32, _tick = 33049, _time = 1.6548e+09, train_seconds = 3.2657e+04)
[2022-06-10 05:12:22,370][root][INFO] - Step 124889600 @ 4092.8 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 124889600, mean_episode_return = 56.896, mean_episode_step = 874.29, total_loss = 84.416, pg_loss = 32.261, baseline_loss = 57.719, entropy_loss = -5.5632, learner_queue_size = 32, _tick = 33057, _time = 1.6548e+09, train_seconds = 3.2662e+04)
[2022-06-10 05:12:27,374][root][INFO] - Step 124910080 @ 4092.7 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 124910080, mean_episode_return = 69.844, mean_episode_step = 1102.8, total_loss = 163.74, pg_loss = 107.99, baseline_loss = 61.186, entropy_loss = -5.4449, learner_queue_size = 32, _tick = 33064, _time = 1.6548e+09, train_seconds = 3.2667e+04)
[2022-06-10 05:12:32,378][root][INFO] - Step 124930560 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 124930560, mean_episode_return = None, mean_episode_step = 1082.6, total_loss = 143.36, pg_loss = 105.67, baseline_loss = 43.278, entropy_loss = -5.5882, learner_queue_size = 32, _tick = 33071, _time = 1.6548e+09, train_seconds = 3.2672e+04)
[2022-06-10 05:12:37,382][root][INFO] - Step 124951040 @ 4092.6 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 124951040, mean_episode_return = 53.871, mean_episode_step = 959.72, total_loss = 252.23, pg_loss = 181.48, baseline_loss = 76.067, entropy_loss = -5.3197, learner_queue_size = 32, _tick = 33076, _time = 1.6548e+09, train_seconds = 3.2677e+04)
[2022-06-10 05:12:42,388][root][INFO] - Step 124968960 @ 3579.7 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 124968960, mean_episode_return = None, mean_episode_step = 1085.6, total_loss = -82.049, pg_loss = -107.32, baseline_loss = 30.764, entropy_loss = -5.489, learner_queue_size = 32, _tick = 33081, _time = 1.6548e+09, train_seconds = 3.2682e+04)
[2022-06-10 05:12:47,394][root][INFO] - Step 124989440 @ 4091.2 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 124989440, mean_episode_return = 49.729, mean_episode_step = 1509.9, total_loss = -167.21, pg_loss = -181.8, baseline_loss = 20.461, entropy_loss = -5.8641, learner_queue_size = 32, _tick = 33087, _time = 1.6548e+09, train_seconds = 3.2687e+04)
[2022-06-10 05:12:52,398][root][INFO] - Step 125009920 @ 4092.7 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 125009920, mean_episode_return = None, mean_episode_step = 1247.1, total_loss = -20.556, pg_loss = -46.705, baseline_loss = 31.916, entropy_loss = -5.7673, learner_queue_size = 32, _tick = 33092, _time = 1.6548e+09, train_seconds = 3.2692e+04)
[2022-06-10 05:12:57,402][root][INFO] - Step 125030400 @ 4092.7 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (step = 125030400, mean_episode_return = 46.77, mean_episode_step = 1110.9, total_loss = 323.29, pg_loss = 249.8, baseline_loss = 79.324, entropy_loss = -5.8352, learner_queue_size = 32, _tick = 33100, _time = 1.6548e+09, train_seconds = 3.2697e+04)
[2022-06-10 05:13:02,408][root][INFO] - Step 125048320 @ 3579.8 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 125048320, mean_episode_return = 108.75, mean_episode_step = 1165.5, total_loss = 290.97, pg_loss = 215.18, baseline_loss = 81.563, entropy_loss = -5.7694, learner_queue_size = 32, _tick = 33107, _time = 1.6548e+09, train_seconds = 3.2702e+04)
[2022-06-10 05:13:07,410][root][INFO] - Step 125068800 @ 4094.3 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 125068800, mean_episode_return = 27.522, mean_episode_step = 1025.2, total_loss = -16.28, pg_loss = -41.892, baseline_loss = 31.218, entropy_loss = -5.6054, learner_queue_size = 32, _tick = 33114, _time = 1.6548e+09, train_seconds = 3.2707e+04)
[2022-06-10 05:13:12,414][root][INFO] - Step 125089280 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 125089280, mean_episode_return = None, mean_episode_step = 888.09, total_loss = -199.2, pg_loss = -212.81, baseline_loss = 19.368, entropy_loss = -5.7551, learner_queue_size = 32, _tick = 33120, _time = 1.6548e+09, train_seconds = 3.2712e+04)
[2022-06-10 05:13:17,418][root][INFO] - Step 125107200 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 125107200, mean_episode_return = 63.54, mean_episode_step = 1095.4, total_loss = -103.58, pg_loss = -124.84, baseline_loss = 27.15, entropy_loss = -5.895, learner_queue_size = 32, _tick = 33125, _time = 1.6548e+09, train_seconds = 3.2717e+04)
[2022-06-10 05:13:22,422][root][INFO] - Step 125127680 @ 4092.8 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 125127680, mean_episode_return = 55.865, mean_episode_step = 750.45, total_loss = 260.29, pg_loss = 201.26, baseline_loss = 65.034, entropy_loss = -6.0045, learner_queue_size = 32, _tick = 33131, _time = 1.6548e+09, train_seconds = 3.2722e+04)
[2022-06-10 05:13:27,426][root][INFO] - Step 125145600 @ 3581.1 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 125145600, mean_episode_return = None, mean_episode_step = 862.5, total_loss = 444.84, pg_loss = 372.82, baseline_loss = 77.883, entropy_loss = -5.8728, learner_queue_size = 32, _tick = 33136, _time = 1.6548e+09, train_seconds = 3.2727e+04)
[2022-06-10 05:13:32,430][root][INFO] - Step 125166080 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 125166080, mean_episode_return = 88.107, mean_episode_step = 1094.0, total_loss = 109.14, pg_loss = 61.318, baseline_loss = 53.593, entropy_loss = -5.7709, learner_queue_size = 32, _tick = 33144, _time = 1.6548e+09, train_seconds = 3.2732e+04)
[2022-06-10 05:13:37,434][root][INFO] - Step 125184000 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 125184000, mean_episode_return = -10.49, mean_episode_step = 729.12, total_loss = 130.93, pg_loss = 95.997, baseline_loss = 40.371, entropy_loss = -5.4401, learner_queue_size = 32, _tick = 33151, _time = 1.6548e+09, train_seconds = 3.2737e+04)
[2022-06-10 05:13:42,438][root][INFO] - Step 125204480 @ 4092.8 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 125204480, mean_episode_return = 70.97, mean_episode_step = 1060.6, total_loss = -267.95, pg_loss = -278.94, baseline_loss = 16.705, entropy_loss = -5.7133, learner_queue_size = 32, _tick = 33157, _time = 1.6548e+09, train_seconds = 3.2742e+04)
[2022-06-10 05:13:47,444][root][INFO] - Step 125224960 @ 4092.5 SPS. Inference batcher size: 79. Learner queue size: 32. Other stats: (step = 125224960, mean_episode_return = 79.631, mean_episode_step = 949.24, total_loss = 59.438, pg_loss = -14.938, baseline_loss = 80.102, entropy_loss = -5.726, learner_queue_size = 32, _tick = 33163, _time = 1.6548e+09, train_seconds = 3.2747e+04)
[2022-06-10 05:13:52,450][root][INFO] - Step 125242880 @ 3578.5 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 125242880, mean_episode_return = 104.76, mean_episode_step = 1254.4, total_loss = 201.65, pg_loss = 122.07, baseline_loss = 85.379, entropy_loss = -5.7965, learner_queue_size = 32, _tick = 33169, _time = 1.6548e+09, train_seconds = 3.2752e+04)
[2022-06-10 05:13:57,454][root][INFO] - Step 125263360 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 125263360, mean_episode_return = None, mean_episode_step = 962.81, total_loss = 638.84, pg_loss = 448.85, baseline_loss = 195.77, entropy_loss = -5.7709, learner_queue_size = 32, _tick = 33173, _time = 1.6548e+09, train_seconds = 3.2757e+04)
[2022-06-10 05:14:02,458][root][INFO] - Step 125283840 @ 4092.7 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 125283840, mean_episode_return = 48.309, mean_episode_step = 1011.6, total_loss = 254.3, pg_loss = 181.05, baseline_loss = 79.041, entropy_loss = -5.7903, learner_queue_size = 32, _tick = 33181, _time = 1.6548e+09, train_seconds = 3.2762e+04)
[2022-06-10 05:14:07,462][root][INFO] - Step 125301760 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 125301760, mean_episode_return = None, mean_episode_step = 946.62, total_loss = 50.065, pg_loss = 20.988, baseline_loss = 34.798, entropy_loss = -5.7214, learner_queue_size = 32, _tick = 33187, _time = 1.6548e+09, train_seconds = 3.2767e+04)
[2022-06-10 05:14:12,466][root][INFO] - Step 125322240 @ 4092.8 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 125322240, mean_episode_return = 67.69, mean_episode_step = 944.6, total_loss = 196.59, pg_loss = 93.353, baseline_loss = 108.95, entropy_loss = -5.719, learner_queue_size = 32, _tick = 33193, _time = 1.6548e+09, train_seconds = 3.2772e+04)
[2022-06-10 05:14:17,472][root][INFO] - Step 125340160 @ 3579.6 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 125340160, mean_episode_return = None, mean_episode_step = 1333.1, total_loss = 174.53, pg_loss = 79.55, baseline_loss = 100.79, entropy_loss = -5.8166, learner_queue_size = 32, _tick = 33197, _time = 1.6548e+09, train_seconds = 3.2777e+04)
[2022-06-10 05:14:22,478][root][INFO] - Step 125360640 @ 4091.2 SPS. Inference batcher size: 83. Learner queue size: 32. Other stats: (step = 125360640, mean_episode_return = 28.11, mean_episode_step = 936.58, total_loss = -89.387, pg_loss = -140.3, baseline_loss = 56.726, entropy_loss = -5.816, learner_queue_size = 32, _tick = 33203, _time = 1.6548e+09, train_seconds = 3.2782e+04)
[2022-06-10 05:14:27,482][root][INFO] - Step 125381120 @ 4092.8 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 125381120, mean_episode_return = 68.738, mean_episode_step = 1098.8, total_loss = 5.7509, pg_loss = -30.618, baseline_loss = 42.245, entropy_loss = -5.8754, learner_queue_size = 32, _tick = 33210, _time = 1.6548e+09, train_seconds = 3.2787e+04)
[2022-06-10 05:14:32,486][root][INFO] - Step 125399040 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 125399040, mean_episode_return = 71.289, mean_episode_step = 1061.9, total_loss = -6.7552, pg_loss = -50.276, baseline_loss = 49.389, entropy_loss = -5.868, learner_queue_size = 32, _tick = 33214, _time = 1.6548e+09, train_seconds = 3.2792e+04)
[2022-06-10 05:14:37,492][root][INFO] - Step 125419520 @ 4091.0 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 125419520, mean_episode_return = 37.675, mean_episode_step = 975.8, total_loss = -22.873, pg_loss = -61.995, baseline_loss = 44.897, entropy_loss = -5.7745, learner_queue_size = 32, _tick = 33221, _time = 1.6548e+09, train_seconds = 3.2797e+04)
[2022-06-10 05:14:42,498][root][INFO] - Step 125437440 @ 3579.7 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 125437440, mean_episode_return = 114.99, mean_episode_step = 1148.4, total_loss = 404.08, pg_loss = 309.97, baseline_loss = 100.13, entropy_loss = -6.023, learner_queue_size = 32, _tick = 33228, _time = 1.6548e+09, train_seconds = 3.2802e+04)
[2022-06-10 05:14:47,502][root][INFO] - Step 125457920 @ 4092.7 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 125457920, mean_episode_return = 62.725, mean_episode_step = 822.66, total_loss = 108.95, pg_loss = 63.65, baseline_loss = 51.144, entropy_loss = -5.8426, learner_queue_size = 32, _tick = 33236, _time = 1.6548e+09, train_seconds = 3.2807e+04)
[2022-06-10 05:14:52,506][root][INFO] - Step 125478400 @ 4092.8 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 125478400, mean_episode_return = 95.99, mean_episode_step = 899.51, total_loss = -68.907, pg_loss = -95.591, baseline_loss = 32.56, entropy_loss = -5.8761, learner_queue_size = 32, _tick = 33242, _time = 1.6548e+09, train_seconds = 3.2812e+04)
[2022-06-10 05:14:57,510][root][INFO] - Step 125498880 @ 4092.8 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 125498880, mean_episode_return = 47.097, mean_episode_step = 851.99, total_loss = 41.129, pg_loss = 23.534, baseline_loss = 23.476, entropy_loss = -5.8805, learner_queue_size = 32, _tick = 33249, _time = 1.6548e+09, train_seconds = 3.2817e+04)
[2022-06-10 05:15:02,514][root][INFO] - Step 125516800 @ 3581.1 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (step = 125516800, mean_episode_return = 31.88, mean_episode_step = 833.55, total_loss = 263.88, pg_loss = 199.86, baseline_loss = 69.807, entropy_loss = -5.7867, learner_queue_size = 32, _tick = 33255, _time = 1.6548e+09, train_seconds = 3.2822e+04)
[2022-06-10 05:15:07,518][root][INFO] - Step 125537280 @ 4092.6 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 125537280, mean_episode_return = 92.349, mean_episode_step = 816.13, total_loss = 86.181, pg_loss = 57.248, baseline_loss = 34.741, entropy_loss = -5.8072, learner_queue_size = 32, _tick = 33261, _time = 1.6548e+09, train_seconds = 3.2827e+04)
[2022-06-10 05:15:12,522][root][INFO] - Step 125557760 @ 4092.8 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 125557760, mean_episode_return = 38.17, mean_episode_step = 752.16, total_loss = 171.6, pg_loss = 121.28, baseline_loss = 56.084, entropy_loss = -5.7647, learner_queue_size = 32, _tick = 33268, _time = 1.6548e+09, train_seconds = 3.2832e+04)
[2022-06-10 05:15:17,526][root][INFO] - Step 125575680 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 125575680, mean_episode_return = None, mean_episode_step = 636.81, total_loss = 126.66, pg_loss = 86.754, baseline_loss = 45.49, entropy_loss = -5.5818, learner_queue_size = 32, _tick = 33272, _time = 1.6548e+09, train_seconds = 3.2837e+04)
[2022-06-10 05:15:22,530][root][INFO] - Step 125596160 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 125596160, mean_episode_return = 45.02, mean_episode_step = 856.17, total_loss = 117.96, pg_loss = 76.482, baseline_loss = 46.992, entropy_loss = -5.5151, learner_queue_size = 32, _tick = 33279, _time = 1.6548e+09, train_seconds = 3.2842e+04)
[2022-06-10 05:15:27,534][root][INFO] - Step 125616640 @ 4092.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 125616640, mean_episode_return = 54.817, mean_episode_step = 884.24, total_loss = 21.027, pg_loss = -54.209, baseline_loss = 80.762, entropy_loss = -5.5266, learner_queue_size = 32, _tick = 33284, _time = 1.6548e+09, train_seconds = 3.2847e+04)
[2022-06-10 05:15:32,538][root][INFO] - Step 125634560 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 125634560, mean_episode_return = 40.22, mean_episode_step = 1008.1, total_loss = 72.721, pg_loss = 46.368, baseline_loss = 31.969, entropy_loss = -5.6156, learner_queue_size = 32, _tick = 33288, _time = 1.6548e+09, train_seconds = 3.2852e+04)
[2022-06-10 05:15:37,542][root][INFO] - Step 125655040 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 125655040, mean_episode_return = 16.535, mean_episode_step = 1230.0, total_loss = 119.85, pg_loss = 62.296, baseline_loss = 63.082, entropy_loss = -5.526, learner_queue_size = 32, _tick = 33296, _time = 1.6548e+09, train_seconds = 3.2857e+04)
[2022-06-10 05:15:42,546][root][INFO] - Step 125672960 @ 3581.2 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 125672960, mean_episode_return = 53.96, mean_episode_step = 927.55, total_loss = -146.03, pg_loss = -169.6, baseline_loss = 29.012, entropy_loss = -5.4395, learner_queue_size = 32, _tick = 33299, _time = 1.6548e+09, train_seconds = 3.2862e+04)
[2022-06-10 05:15:47,550][root][INFO] - Step 125690880 @ 3581.0 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 125690880, mean_episode_return = 20.13, mean_episode_step = 966.06, total_loss = 89.871, pg_loss = 44.973, baseline_loss = 50.451, entropy_loss = -5.5533, learner_queue_size = 32, _tick = 33304, _time = 1.6548e+09, train_seconds = 3.2867e+04)
[2022-06-10 05:15:52,557][root][INFO] - Step 125711360 @ 4090.3 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 125711360, mean_episode_return = 67.007, mean_episode_step = 1237.4, total_loss = -78.827, pg_loss = -140.51, baseline_loss = 67.244, entropy_loss = -5.5571, learner_queue_size = 32, _tick = 33310, _time = 1.6548e+09, train_seconds = 3.2872e+04)
[2022-06-10 05:15:57,564][root][INFO] - Step 125729280 @ 3579.3 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 125729280, mean_episode_return = 48.17, mean_episode_step = 1248.8, total_loss = 116.99, pg_loss = 59.23, baseline_loss = 63.282, entropy_loss = -5.5198, learner_queue_size = 32, _tick = 33317, _time = 1.6548e+09, train_seconds = 3.2877e+04)
[2022-06-10 05:16:02,566][root][INFO] - Step 125749760 @ 4094.2 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 125749760, mean_episode_return = 119.93, mean_episode_step = 1068.7, total_loss = -248.12, pg_loss = -287.71, baseline_loss = 45.123, entropy_loss = -5.5248, learner_queue_size = 32, _tick = 33322, _time = 1.6548e+09, train_seconds = 3.2882e+04)
[2022-06-10 05:16:07,570][root][INFO] - Step 125770240 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 125770240, mean_episode_return = 83.499, mean_episode_step = 1272.4, total_loss = 114.57, pg_loss = 21.378, baseline_loss = 98.808, entropy_loss = -5.6161, learner_queue_size = 32, _tick = 33328, _time = 1.6548e+09, train_seconds = 3.2887e+04)
[2022-06-10 05:16:12,574][root][INFO] - Step 125788160 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 125788160, mean_episode_return = 49.016, mean_episode_step = 1139.5, total_loss = -136.07, pg_loss = -156.39, baseline_loss = 25.96, entropy_loss = -5.6483, learner_queue_size = 32, _tick = 33333, _time = 1.6548e+09, train_seconds = 3.2892e+04)
[2022-06-10 05:16:17,578][root][INFO] - Step 125808640 @ 4092.8 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 125808640, mean_episode_return = 38.511, mean_episode_step = 1322.2, total_loss = 61.086, pg_loss = 20.321, baseline_loss = 46.587, entropy_loss = -5.8215, learner_queue_size = 32, _tick = 33338, _time = 1.6548e+09, train_seconds = 3.2897e+04)
[2022-06-10 05:16:22,582][root][INFO] - Step 125826560 @ 3581.1 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 125826560, mean_episode_return = 38.072, mean_episode_step = 1106.6, total_loss = -57.632, pg_loss = -90.254, baseline_loss = 38.351, entropy_loss = -5.7286, learner_queue_size = 32, _tick = 33343, _time = 1.6548e+09, train_seconds = 3.2902e+04)
[2022-06-10 05:16:27,586][root][INFO] - Step 125847040 @ 4092.8 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (step = 125847040, mean_episode_return = None, mean_episode_step = 1237.2, total_loss = 22.46, pg_loss = -4.6321, baseline_loss = 33.032, entropy_loss = -5.9398, learner_queue_size = 32, _tick = 33348, _time = 1.6548e+09, train_seconds = 3.2907e+04)
[2022-06-10 05:16:32,590][root][INFO] - Step 125867520 @ 4092.6 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 125867520, mean_episode_return = 46.791, mean_episode_step = 1342.2, total_loss = -41.792, pg_loss = -58.812, baseline_loss = 22.881, entropy_loss = -5.861, learner_queue_size = 32, _tick = 33354, _time = 1.6548e+09, train_seconds = 3.2912e+04)
[2022-06-10 05:16:37,594][root][INFO] - Step 125888000 @ 4092.8 SPS. Inference batcher size: 1. Learner queue size: 13. Other stats: (step = 125888000, mean_episode_return = None, mean_episode_step = 1220.0, total_loss = 173.75, pg_loss = 127.03, baseline_loss = 52.528, entropy_loss = -5.8044, learner_queue_size = 32, _tick = 33361, _time = 1.6548e+09, train_seconds = 3.2917e+04)
[2022-06-10 05:16:42,598][root][INFO] - Step 125905920 @ 3581.1 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (step = 125905920, mean_episode_return = 142.22, mean_episode_step = 1053.7, total_loss = 53.719, pg_loss = 22.097, baseline_loss = 37.375, entropy_loss = -5.7532, learner_queue_size = 32, _tick = 33366, _time = 1.6548e+09, train_seconds = 3.2922e+04)
[2022-06-10 05:16:47,602][root][INFO] - Step 125926400 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 125926400, mean_episode_return = 27.46, mean_episode_step = 1270.9, total_loss = -98.83, pg_loss = -113.42, baseline_loss = 20.269, entropy_loss = -5.6742, learner_queue_size = 32, _tick = 33372, _time = 1.6548e+09, train_seconds = 3.2927e+04)
[2022-06-10 05:16:52,606][root][INFO] - Step 125944320 @ 3581.1 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (step = 125944320, mean_episode_return = None, mean_episode_step = 1154.8, total_loss = -0.47551, pg_loss = -19.195, baseline_loss = 24.334, entropy_loss = -5.6145, learner_queue_size = 32, _tick = 33374, _time = 1.6548e+09, train_seconds = 3.2932e+04)
[2022-06-10 05:16:57,611][root][INFO] - Step 125964800 @ 4092.4 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 125964800, mean_episode_return = 24.33, mean_episode_step = 1230.7, total_loss = 51.257, pg_loss = 8.4922, baseline_loss = 48.446, entropy_loss = -5.6816, learner_queue_size = 32, _tick = 33382, _time = 1.6548e+09, train_seconds = 3.2937e+04)
[2022-06-10 05:17:02,614][root][INFO] - Step 125985280 @ 4093.0 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 125985280, mean_episode_return = 100.5, mean_episode_step = 1314.3, total_loss = -98.293, pg_loss = -155.08, baseline_loss = 62.53, entropy_loss = -5.7436, learner_queue_size = 32, _tick = 33389, _time = 1.6548e+09, train_seconds = 3.2942e+04)
[2022-06-10 05:17:07,618][root][INFO] - Step 126005760 @ 4092.6 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 126005760, mean_episode_return = -12.28, mean_episode_step = 1069.4, total_loss = 104.13, pg_loss = 37.663, baseline_loss = 72.126, entropy_loss = -5.6541, learner_queue_size = 32, _tick = 33396, _time = 1.6548e+09, train_seconds = 3.2947e+04)
[2022-06-10 05:17:12,622][root][INFO] - Step 126023680 @ 3581.2 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (step = 126023680, mean_episode_return = 33.561, mean_episode_step = 1274.5, total_loss = -127.67, pg_loss = -140.96, baseline_loss = 18.885, entropy_loss = -5.604, learner_queue_size = 32, _tick = 33401, _time = 1.6548e+09, train_seconds = 3.2952e+04)
[2022-06-10 05:17:17,626][root][INFO] - Step 126044160 @ 4092.8 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 126044160, mean_episode_return = None, mean_episode_step = 1251.1, total_loss = -160.95, pg_loss = -179.73, baseline_loss = 24.425, entropy_loss = -5.6407, learner_queue_size = 32, _tick = 33408, _time = 1.6548e+09, train_seconds = 3.2957e+04)
[2022-06-10 05:17:22,630][root][INFO] - Step 126064640 @ 4092.7 SPS. Inference batcher size: 97. Learner queue size: 32. Other stats: (step = 126064640, mean_episode_return = 31.807, mean_episode_step = 1295.3, total_loss = -32.576, pg_loss = -53.35, baseline_loss = 26.643, entropy_loss = -5.8682, learner_queue_size = 32, _tick = 33416, _time = 1.6548e+09, train_seconds = 3.2962e+04)
[2022-06-10 05:17:27,634][root][INFO] - Step 126082560 @ 3581.1 SPS. Inference batcher size: 95. Learner queue size: 32. Other stats: (step = 126082560, mean_episode_return = 51.594, mean_episode_step = 1030.6, total_loss = 62.316, pg_loss = 42.1, baseline_loss = 25.894, entropy_loss = -5.6771, learner_queue_size = 32, _tick = 33422, _time = 1.6548e+09, train_seconds = 3.2967e+04)
[2022-06-10 05:17:32,639][root][INFO] - Step 126103040 @ 4091.7 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (step = 126103040, mean_episode_return = 61.697, mean_episode_step = 1172.4, total_loss = 119.24, pg_loss = 74.016, baseline_loss = 50.783, entropy_loss = -5.5546, learner_queue_size = 32, _tick = 33430, _time = 1.6548e+09, train_seconds = 3.2972e+04)
[2022-06-10 05:17:37,642][root][INFO] - Step 126123520 @ 4093.7 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 126123520, mean_episode_return = None, mean_episode_step = 1100.8, total_loss = 324.04, pg_loss = 230.9, baseline_loss = 98.585, entropy_loss = -5.4538, learner_queue_size = 32, _tick = 33432, _time = 1.6548e+09, train_seconds = 3.2977e+04)
[2022-06-10 05:17:42,646][root][INFO] - Step 126141440 @ 3581.2 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 126141440, mean_episode_return = 23.9, mean_episode_step = 1000.4, total_loss = 139.51, pg_loss = 76.387, baseline_loss = 68.678, entropy_loss = -5.5527, learner_queue_size = 32, _tick = 33439, _time = 1.6548e+09, train_seconds = 3.2982e+04)
[2022-06-10 05:17:47,650][root][INFO] - Step 126161920 @ 4092.5 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 126161920, mean_episode_return = 45.825, mean_episode_step = 967.28, total_loss = 42.256, pg_loss = 10.036, baseline_loss = 37.823, entropy_loss = -5.6021, learner_queue_size = 32, _tick = 33446, _time = 1.6548e+09, train_seconds = 3.2988e+04)
[2022-06-10 05:17:52,654][root][INFO] - Step 126182400 @ 4093.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 126182400, mean_episode_return = None, mean_episode_step = 1414.3, total_loss = 58.093, pg_loss = 40.967, baseline_loss = 23.061, entropy_loss = -5.9348, learner_queue_size = 32, _tick = 33452, _time = 1.6548e+09, train_seconds = 3.2992e+04)
[2022-06-10 05:17:57,658][root][INFO] - Step 126202880 @ 4092.4 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 126202880, mean_episode_return = 22.56, mean_episode_step = 1373.1, total_loss = 95.988, pg_loss = 61.668, baseline_loss = 40.102, entropy_loss = -5.782, learner_queue_size = 32, _tick = 33458, _time = 1.6548e+09, train_seconds = 3.2998e+04)
[2022-06-10 05:18:02,662][root][INFO] - Step 126220800 @ 3581.3 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 126220800, mean_episode_return = 55.42, mean_episode_step = 1219.6, total_loss = 107.52, pg_loss = 71.247, baseline_loss = 41.878, entropy_loss = -5.6083, learner_queue_size = 32, _tick = 33465, _time = 1.6548e+09, train_seconds = 3.3002e+04)
[2022-06-10 05:18:07,666][root][INFO] - Step 126241280 @ 4092.5 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 126241280, mean_episode_return = None, mean_episode_step = 1094.4, total_loss = 322.96, pg_loss = 276.09, baseline_loss = 52.554, entropy_loss = -5.6872, learner_queue_size = 32, _tick = 33470, _time = 1.6548e+09, train_seconds = 3.3008e+04)
[2022-06-10 05:18:12,670][root][INFO] - Step 126261760 @ 4093.0 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 126261760, mean_episode_return = 46.621, mean_episode_step = 1292.7, total_loss = 152.75, pg_loss = 61.993, baseline_loss = 96.398, entropy_loss = -5.6396, learner_queue_size = 32, _tick = 33475, _time = 1.6548e+09, train_seconds = 3.3012e+04)
[2022-06-10 05:18:17,674][root][INFO] - Step 126279680 @ 3580.8 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 126279680, mean_episode_return = None, mean_episode_step = 1035.7, total_loss = 97.797, pg_loss = 40.137, baseline_loss = 63.402, entropy_loss = -5.7421, learner_queue_size = 32, _tick = 33481, _time = 1.6548e+09, train_seconds = 3.3018e+04)
[2022-06-10 05:18:22,679][root][INFO] - Step 126300160 @ 4092.3 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 126300160, mean_episode_return = 33.453, mean_episode_step = 1085.9, total_loss = 183.19, pg_loss = 144.08, baseline_loss = 44.897, entropy_loss = -5.7861, learner_queue_size = 32, _tick = 33487, _time = 1.6548e+09, train_seconds = 3.3022e+04)
[2022-06-10 05:18:27,682][root][INFO] - Step 126318080 @ 3582.0 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 126318080, mean_episode_return = 38.884, mean_episode_step = 1350.5, total_loss = -102.75, pg_loss = -136.52, baseline_loss = 39.601, entropy_loss = -5.829, learner_queue_size = 32, _tick = 33493, _time = 1.6548e+09, train_seconds = 3.3028e+04)
[2022-06-10 05:18:32,686][root][INFO] - Step 126338560 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 126338560, mean_episode_return = 69.68, mean_episode_step = 999.84, total_loss = 90.598, pg_loss = 46.35, baseline_loss = 50.007, entropy_loss = -5.7585, learner_queue_size = 32, _tick = 33500, _time = 1.6548e+09, train_seconds = 3.3032e+04)
[2022-06-10 05:18:37,690][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 05:18:37,821][root][INFO] - Step 126359040 @ 4092.7 SPS. Inference batcher size: 83. Learner queue size: 32. Other stats: (step = 126359040, mean_episode_return = None, mean_episode_step = 1173.2, total_loss = -118.97, pg_loss = -134.49, baseline_loss = 21.305, entropy_loss = -5.7846, learner_queue_size = 32, _tick = 33504, _time = 1.6548e+09, train_seconds = 3.3038e+04)
[2022-06-10 05:18:42,826][root][INFO] - Step 126379520 @ 3987.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (step = 126379520, mean_episode_return = 61.116, mean_episode_step = 994.68, total_loss = 286.46, pg_loss = 217.03, baseline_loss = 75.159, entropy_loss = -5.7284, learner_queue_size = 32, _tick = 33511, _time = 1.6548e+09, train_seconds = 3.3043e+04)
[2022-06-10 05:18:47,830][root][INFO] - Step 126397440 @ 3581.2 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 126397440, mean_episode_return = 16.97, mean_episode_step = 1360.4, total_loss = -166.29, pg_loss = -179.35, baseline_loss = 18.721, entropy_loss = -5.6639, learner_queue_size = 32, _tick = 33518, _time = 1.6548e+09, train_seconds = 3.3048e+04)
[2022-06-10 05:18:52,834][root][INFO] - Step 126417920 @ 4092.5 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 126417920, mean_episode_return = 45.96, mean_episode_step = 1207.8, total_loss = -39.604, pg_loss = -55.257, baseline_loss = 21.264, entropy_loss = -5.6108, learner_queue_size = 32, _tick = 33524, _time = 1.6548e+09, train_seconds = 3.3053e+04)
[2022-06-10 05:18:57,838][root][INFO] - Step 126438400 @ 4093.0 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 126438400, mean_episode_return = 54.27, mean_episode_step = 1014.8, total_loss = 244.15, pg_loss = 164.53, baseline_loss = 85.081, entropy_loss = -5.4599, learner_queue_size = 32, _tick = 33530, _time = 1.6548e+09, train_seconds = 3.3058e+04)
[2022-06-10 05:19:02,842][root][INFO] - Step 126456320 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 126456320, mean_episode_return = 10.05, mean_episode_step = 1369.7, total_loss = -61.554, pg_loss = -98.342, baseline_loss = 42.36, entropy_loss = -5.5722, learner_queue_size = 32, _tick = 33536, _time = 1.6548e+09, train_seconds = 3.3063e+04)
[2022-06-10 05:19:07,846][root][INFO] - Step 126476800 @ 4092.8 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 126476800, mean_episode_return = 131.45, mean_episode_step = 1173.1, total_loss = -119.98, pg_loss = -125.26, baseline_loss = 11.045, entropy_loss = -5.7686, learner_queue_size = 32, _tick = 33542, _time = 1.6548e+09, train_seconds = 3.3068e+04)
[2022-06-10 05:19:12,850][root][INFO] - Step 126497280 @ 4092.7 SPS. Inference batcher size: 97. Learner queue size: 32. Other stats: (step = 126497280, mean_episode_return = 21.81, mean_episode_step = 1167.5, total_loss = 182.15, pg_loss = 125.16, baseline_loss = 62.645, entropy_loss = -5.6548, learner_queue_size = 32, _tick = 33549, _time = 1.6548e+09, train_seconds = 3.3073e+04)
[2022-06-10 05:19:17,854][root][INFO] - Step 126515200 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 126515200, mean_episode_return = None, mean_episode_step = 1158.3, total_loss = 104.41, pg_loss = 71.49, baseline_loss = 38.527, entropy_loss = -5.6084, learner_queue_size = 32, _tick = 33555, _time = 1.6548e+09, train_seconds = 3.3078e+04)
[2022-06-10 05:19:22,858][root][INFO] - Step 126535680 @ 4092.8 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 126535680, mean_episode_return = 21.36, mean_episode_step = 1233.2, total_loss = 256.28, pg_loss = 174.32, baseline_loss = 87.549, entropy_loss = -5.5809, learner_queue_size = 32, _tick = 33562, _time = 1.6548e+09, train_seconds = 3.3083e+04)
[2022-06-10 05:19:27,863][root][INFO] - Step 126553600 @ 3580.4 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 126553600, mean_episode_return = 67.924, mean_episode_step = 1202.2, total_loss = 155.78, pg_loss = 40.314, baseline_loss = 121.08, entropy_loss = -5.6144, learner_queue_size = 32, _tick = 33567, _time = 1.6548e+09, train_seconds = 3.3088e+04)
[2022-06-10 05:19:32,866][root][INFO] - Step 126574080 @ 4093.5 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 126574080, mean_episode_return = 55.803, mean_episode_step = 1038.3, total_loss = -212.79, pg_loss = -236.13, baseline_loss = 28.951, entropy_loss = -5.6096, learner_queue_size = 32, _tick = 33572, _time = 1.6548e+09, train_seconds = 3.3093e+04)
[2022-06-10 05:19:37,870][root][INFO] - Step 126594560 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 126594560, mean_episode_return = 31.487, mean_episode_step = 885.71, total_loss = -109.17, pg_loss = -195.73, baseline_loss = 92.151, entropy_loss = -5.5948, learner_queue_size = 32, _tick = 33578, _time = 1.6548e+09, train_seconds = 3.3098e+04)
[2022-06-10 05:19:42,874][root][INFO] - Step 126615040 @ 4092.5 SPS. Inference batcher size: 98. Learner queue size: 32. Other stats: (step = 126615040, mean_episode_return = 8.0073, mean_episode_step = 1006.8, total_loss = 60.522, pg_loss = -17.42, baseline_loss = 83.602, entropy_loss = -5.6606, learner_queue_size = 32, _tick = 33584, _time = 1.6548e+09, train_seconds = 3.3103e+04)
[2022-06-10 05:19:47,881][root][INFO] - Step 126632960 @ 3579.4 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 126632960, mean_episode_return = 54.941, mean_episode_step = 1387.8, total_loss = -191.03, pg_loss = -191.42, baseline_loss = 6.1964, entropy_loss = -5.7989, learner_queue_size = 32, _tick = 33589, _time = 1.6548e+09, train_seconds = 3.3108e+04)
[2022-06-10 05:19:52,886][root][INFO] - Step 126653440 @ 4091.7 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 126653440, mean_episode_return = 50.171, mean_episode_step = 1017.8, total_loss = 45.002, pg_loss = 24.878, baseline_loss = 25.84, entropy_loss = -5.7161, learner_queue_size = 32, _tick = 33596, _time = 1.6548e+09, train_seconds = 3.3113e+04)
[2022-06-10 05:19:57,892][root][INFO] - Step 126671360 @ 3579.5 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 126671360, mean_episode_return = 30.731, mean_episode_step = 1069.6, total_loss = 178.0, pg_loss = 139.07, baseline_loss = 44.712, entropy_loss = -5.7792, learner_queue_size = 32, _tick = 33601, _time = 1.6548e+09, train_seconds = 3.3118e+04)
[2022-06-10 05:20:02,898][root][INFO] - Step 126691840 @ 4091.0 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 126691840, mean_episode_return = None, mean_episode_step = 1101.0, total_loss = 35.299, pg_loss = 9.2758, baseline_loss = 31.749, entropy_loss = -5.7255, learner_queue_size = 32, _tick = 33605, _time = 1.6548e+09, train_seconds = 3.3123e+04)
[2022-06-10 05:20:07,902][root][INFO] - Step 126712320 @ 4093.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 126712320, mean_episode_return = 84.674, mean_episode_step = 934.26, total_loss = 102.74, pg_loss = 8.6994, baseline_loss = 99.712, entropy_loss = -5.6746, learner_queue_size = 32, _tick = 33611, _time = 1.6548e+09, train_seconds = 3.3128e+04)
[2022-06-10 05:20:12,906][root][INFO] - Step 126732800 @ 4092.8 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 126732800, mean_episode_return = -11.83, mean_episode_step = 1247.0, total_loss = 74.769, pg_loss = 45.863, baseline_loss = 34.571, entropy_loss = -5.6659, learner_queue_size = 32, _tick = 33617, _time = 1.6548e+09, train_seconds = 3.3133e+04)
[2022-06-10 05:20:17,910][root][INFO] - Step 126750720 @ 3581.1 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 126750720, mean_episode_return = None, mean_episode_step = 1113.3, total_loss = 77.972, pg_loss = 42.279, baseline_loss = 41.25, entropy_loss = -5.557, learner_queue_size = 32, _tick = 33622, _time = 1.6548e+09, train_seconds = 3.3138e+04)
[2022-06-10 05:20:22,914][root][INFO] - Step 126771200 @ 4092.7 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 126771200, mean_episode_return = None, mean_episode_step = 981.34, total_loss = 0.61197, pg_loss = -39.394, baseline_loss = 45.725, entropy_loss = -5.7186, learner_queue_size = 32, _tick = 33627, _time = 1.6548e+09, train_seconds = 3.3143e+04)
[2022-06-10 05:20:27,918][root][INFO] - Step 126791680 @ 4092.7 SPS. Inference batcher size: 73. Learner queue size: 32. Other stats: (step = 126791680, mean_episode_return = 70.914, mean_episode_step = 770.71, total_loss = 204.23, pg_loss = 130.46, baseline_loss = 79.443, entropy_loss = -5.6691, learner_queue_size = 32, _tick = 33633, _time = 1.6548e+09, train_seconds = 3.3148e+04)
[2022-06-10 05:20:32,922][root][INFO] - Step 126809600 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 126809600, mean_episode_return = 44.281, mean_episode_step = 1056.8, total_loss = 140.71, pg_loss = 121.01, baseline_loss = 25.348, entropy_loss = -5.6504, learner_queue_size = 32, _tick = 33638, _time = 1.6548e+09, train_seconds = 3.3153e+04)
[2022-06-10 05:20:37,926][root][INFO] - Step 126830080 @ 4092.8 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 126830080, mean_episode_return = 28.99, mean_episode_step = 1147.9, total_loss = 364.51, pg_loss = 298.72, baseline_loss = 71.304, entropy_loss = -5.5133, learner_queue_size = 32, _tick = 33643, _time = 1.6548e+09, train_seconds = 3.3158e+04)
[2022-06-10 05:20:42,930][root][INFO] - Step 126850560 @ 4092.7 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 126850560, mean_episode_return = 51.245, mean_episode_step = 1130.0, total_loss = -52.709, pg_loss = -243.77, baseline_loss = 196.59, entropy_loss = -5.528, learner_queue_size = 32, _tick = 33649, _time = 1.6548e+09, train_seconds = 3.3163e+04)
[2022-06-10 05:20:47,934][root][INFO] - Step 126868480 @ 3581.1 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (step = 126868480, mean_episode_return = None, mean_episode_step = 1047.5, total_loss = 59.694, pg_loss = 0.18792, baseline_loss = 65.124, entropy_loss = -5.6184, learner_queue_size = 32, _tick = 33655, _time = 1.6548e+09, train_seconds = 3.3168e+04)
[2022-06-10 05:20:52,938][root][INFO] - Step 126886400 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 126886400, mean_episode_return = None, mean_episode_step = 1310.5, total_loss = -13.429, pg_loss = -29.073, baseline_loss = 21.3, entropy_loss = -5.6558, learner_queue_size = 32, _tick = 33661, _time = 1.6548e+09, train_seconds = 3.3173e+04)
[2022-06-10 05:20:57,942][root][INFO] - Step 126906880 @ 4092.7 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 126906880, mean_episode_return = 72.3, mean_episode_step = 776.79, total_loss = 360.46, pg_loss = 318.96, baseline_loss = 47.238, entropy_loss = -5.7367, learner_queue_size = 32, _tick = 33668, _time = 1.6548e+09, train_seconds = 3.3178e+04)
[2022-06-10 05:21:02,946][root][INFO] - Step 126924800 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 126924800, mean_episode_return = 36.158, mean_episode_step = 777.6, total_loss = 1.5981, pg_loss = -51.937, baseline_loss = 59.227, entropy_loss = -5.6926, learner_queue_size = 32, _tick = 33673, _time = 1.6548e+09, train_seconds = 3.3183e+04)
[2022-06-10 05:21:07,950][root][INFO] - Step 126945280 @ 4092.2 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 126945280, mean_episode_return = 28.669, mean_episode_step = 1013.5, total_loss = 20.819, pg_loss = -1.2395, baseline_loss = 27.691, entropy_loss = -5.6326, learner_queue_size = 32, _tick = 33681, _time = 1.6548e+09, train_seconds = 3.3188e+04)
[2022-06-10 05:21:12,954][root][INFO] - Step 126965760 @ 4093.2 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 126965760, mean_episode_return = 42.089, mean_episode_step = 1071.6, total_loss = 17.838, pg_loss = -30.626, baseline_loss = 54.174, entropy_loss = -5.7099, learner_queue_size = 32, _tick = 33689, _time = 1.6548e+09, train_seconds = 3.3193e+04)
[2022-06-10 05:21:17,958][root][INFO] - Step 126983680 @ 3581.1 SPS. Inference batcher size: 75. Learner queue size: 32. Other stats: (step = 126983680, mean_episode_return = 20.74, mean_episode_step = 1042.4, total_loss = 317.35, pg_loss = 230.72, baseline_loss = 92.347, entropy_loss = -5.718, learner_queue_size = 32, _tick = 33694, _time = 1.6548e+09, train_seconds = 3.3198e+04)
[2022-06-10 05:21:22,962][root][INFO] - Step 127001600 @ 3581.1 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 127001600, mean_episode_return = 25.69, mean_episode_step = 1053.2, total_loss = 43.706, pg_loss = -6.8553, baseline_loss = 56.304, entropy_loss = -5.7424, learner_queue_size = 32, _tick = 33701, _time = 1.6548e+09, train_seconds = 3.3203e+04)
[2022-06-10 05:21:27,966][root][INFO] - Step 127022080 @ 4092.8 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 127022080, mean_episode_return = None, mean_episode_step = 1148.2, total_loss = 147.92, pg_loss = 108.29, baseline_loss = 45.375, entropy_loss = -5.751, learner_queue_size = 32, _tick = 33706, _time = 1.6548e+09, train_seconds = 3.3208e+04)
[2022-06-10 05:21:32,970][root][INFO] - Step 127042560 @ 4092.7 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 127042560, mean_episode_return = -8.2301, mean_episode_step = 1151.2, total_loss = -29.079, pg_loss = -53.175, baseline_loss = 29.803, entropy_loss = -5.7072, learner_queue_size = 32, _tick = 33710, _time = 1.6548e+09, train_seconds = 3.3213e+04)
[2022-06-10 05:21:37,974][root][INFO] - Step 127060480 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 127060480, mean_episode_return = 27.971, mean_episode_step = 1291.6, total_loss = 90.965, pg_loss = 49.843, baseline_loss = 46.777, entropy_loss = -5.6549, learner_queue_size = 32, _tick = 33716, _time = 1.6548e+09, train_seconds = 3.3218e+04)
[2022-06-10 05:21:42,978][root][INFO] - Step 127080960 @ 4092.7 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 127080960, mean_episode_return = 53.75, mean_episode_step = 839.39, total_loss = 143.4, pg_loss = 44.949, baseline_loss = 104.15, entropy_loss = -5.6979, learner_queue_size = 32, _tick = 33723, _time = 1.6548e+09, train_seconds = 3.3223e+04)
[2022-06-10 05:21:47,982][root][INFO] - Step 127101440 @ 4092.8 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 127101440, mean_episode_return = 6.2696, mean_episode_step = 1115.0, total_loss = 84.73, pg_loss = 32.001, baseline_loss = 58.359, entropy_loss = -5.6297, learner_queue_size = 32, _tick = 33729, _time = 1.6548e+09, train_seconds = 3.3228e+04)
[2022-06-10 05:21:52,986][root][INFO] - Step 127119360 @ 3581.1 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 127119360, mean_episode_return = 33.387, mean_episode_step = 1065.4, total_loss = -9.5654, pg_loss = -33.318, baseline_loss = 29.465, entropy_loss = -5.7123, learner_queue_size = 32, _tick = 33734, _time = 1.6548e+09, train_seconds = 3.3233e+04)
[2022-06-10 05:21:57,990][root][INFO] - Step 127139840 @ 4092.8 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 127139840, mean_episode_return = 11.74, mean_episode_step = 1032.5, total_loss = -66.208, pg_loss = -87.577, baseline_loss = 27.017, entropy_loss = -5.6489, learner_queue_size = 32, _tick = 33739, _time = 1.6548e+09, train_seconds = 3.3238e+04)
[2022-06-10 05:22:02,994][root][INFO] - Step 127157760 @ 3581.1 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 127157760, mean_episode_return = 17.56, mean_episode_step = 1116.9, total_loss = 123.0, pg_loss = 95.002, baseline_loss = 33.659, entropy_loss = -5.6593, learner_queue_size = 32, _tick = 33745, _time = 1.6548e+09, train_seconds = 3.3243e+04)
[2022-06-10 05:22:07,999][root][INFO] - Step 127178240 @ 4091.9 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (step = 127178240, mean_episode_return = None, mean_episode_step = 885.5, total_loss = -105.4, pg_loss = -124.47, baseline_loss = 24.572, entropy_loss = -5.5104, learner_queue_size = 32, _tick = 33751, _time = 1.6548e+09, train_seconds = 3.3248e+04)
[2022-06-10 05:22:13,002][root][INFO] - Step 127198720 @ 4093.5 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 127198720, mean_episode_return = None, mean_episode_step = 1075.5, total_loss = 136.1, pg_loss = 103.17, baseline_loss = 38.671, entropy_loss = -5.7389, learner_queue_size = 32, _tick = 33756, _time = 1.6548e+09, train_seconds = 3.3253e+04)
[2022-06-10 05:22:18,006][root][INFO] - Step 127216640 @ 3581.2 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 127216640, mean_episode_return = 120.29, mean_episode_step = 1139.3, total_loss = -18.318, pg_loss = -35.075, baseline_loss = 22.448, entropy_loss = -5.6917, learner_queue_size = 32, _tick = 33761, _time = 1.6548e+09, train_seconds = 3.3258e+04)
[2022-06-10 05:22:23,010][root][INFO] - Step 127237120 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 127237120, mean_episode_return = 4.8899, mean_episode_step = 1023.1, total_loss = 573.71, pg_loss = 476.67, baseline_loss = 102.63, entropy_loss = -5.5977, learner_queue_size = 32, _tick = 33769, _time = 1.6548e+09, train_seconds = 3.3263e+04)
[2022-06-10 05:22:28,014][root][INFO] - Step 127255040 @ 3581.0 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 127255040, mean_episode_return = 40.62, mean_episode_step = 1220.0, total_loss = -329.67, pg_loss = -362.9, baseline_loss = 38.873, entropy_loss = -5.6409, learner_queue_size = 32, _tick = 33774, _time = 1.6548e+09, train_seconds = 3.3268e+04)
[2022-06-10 05:22:33,018][root][INFO] - Step 127275520 @ 4092.8 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 127275520, mean_episode_return = 61.232, mean_episode_step = 880.14, total_loss = 459.94, pg_loss = 350.16, baseline_loss = 115.47, entropy_loss = -5.6887, learner_queue_size = 32, _tick = 33780, _time = 1.6548e+09, train_seconds = 3.3273e+04)
[2022-06-10 05:22:38,022][root][INFO] - Step 127293440 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 127293440, mean_episode_return = 60.86, mean_episode_step = 1108.5, total_loss = 84.491, pg_loss = 36.734, baseline_loss = 53.352, entropy_loss = -5.5952, learner_queue_size = 32, _tick = 33786, _time = 1.6548e+09, train_seconds = 3.3278e+04)
[2022-06-10 05:22:43,026][root][INFO] - Step 127313920 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 127313920, mean_episode_return = 24.065, mean_episode_step = 1011.7, total_loss = 21.23, pg_loss = -12.613, baseline_loss = 39.293, entropy_loss = -5.4509, learner_queue_size = 32, _tick = 33791, _time = 1.6548e+09, train_seconds = 3.3283e+04)
[2022-06-10 05:22:48,032][root][INFO] - Step 127334400 @ 4090.9 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 127334400, mean_episode_return = None, mean_episode_step = 1172.8, total_loss = 221.63, pg_loss = 171.76, baseline_loss = 55.591, entropy_loss = -5.7226, learner_queue_size = 32, _tick = 33798, _time = 1.6548e+09, train_seconds = 3.3288e+04)
[2022-06-10 05:22:53,038][root][INFO] - Step 127352320 @ 3579.8 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 127352320, mean_episode_return = 90.12, mean_episode_step = 1212.5, total_loss = 546.72, pg_loss = 426.79, baseline_loss = 125.72, entropy_loss = -5.7854, learner_queue_size = 32, _tick = 33805, _time = 1.6548e+09, train_seconds = 3.3293e+04)
[2022-06-10 05:22:58,042][root][INFO] - Step 127372800 @ 4092.8 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 127372800, mean_episode_return = -24.43, mean_episode_step = 1095.0, total_loss = 204.9, pg_loss = 146.21, baseline_loss = 64.666, entropy_loss = -5.9801, learner_queue_size = 32, _tick = 33812, _time = 1.6548e+09, train_seconds = 3.3298e+04)
[2022-06-10 05:23:03,046][root][INFO] - Step 127390720 @ 3581.0 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 127390720, mean_episode_return = 72.99, mean_episode_step = 911.09, total_loss = 57.652, pg_loss = -4.6298, baseline_loss = 67.958, entropy_loss = -5.6759, learner_queue_size = 32, _tick = 33817, _time = 1.6548e+09, train_seconds = 3.3303e+04)
[2022-06-10 05:23:08,050][root][INFO] - Step 127411200 @ 4092.8 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 127411200, mean_episode_return = None, mean_episode_step = 904.47, total_loss = 234.17, pg_loss = 165.05, baseline_loss = 74.838, entropy_loss = -5.7122, learner_queue_size = 32, _tick = 33824, _time = 1.6548e+09, train_seconds = 3.3308e+04)
[2022-06-10 05:23:13,054][root][INFO] - Step 127429120 @ 3581.1 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 127429120, mean_episode_return = 62.495, mean_episode_step = 1082.0, total_loss = 139.04, pg_loss = 70.335, baseline_loss = 74.414, entropy_loss = -5.7135, learner_queue_size = 32, _tick = 33830, _time = 1.6548e+09, train_seconds = 3.3313e+04)
[2022-06-10 05:23:18,058][root][INFO] - Step 127449600 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 127449600, mean_episode_return = 55.42, mean_episode_step = 1294.7, total_loss = 75.523, pg_loss = 18.345, baseline_loss = 62.985, entropy_loss = -5.8069, learner_queue_size = 32, _tick = 33838, _time = 1.6548e+09, train_seconds = 3.3318e+04)
[2022-06-10 05:23:23,062][root][INFO] - Step 127470080 @ 4092.7 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 127470080, mean_episode_return = 15.395, mean_episode_step = 1060.8, total_loss = 122.12, pg_loss = 39.521, baseline_loss = 88.14, entropy_loss = -5.5374, learner_queue_size = 32, _tick = 33846, _time = 1.6548e+09, train_seconds = 3.3323e+04)
[2022-06-10 05:23:28,066][root][INFO] - Step 127490560 @ 4092.8 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 127490560, mean_episode_return = 59.47, mean_episode_step = 883.27, total_loss = -190.01, pg_loss = -210.99, baseline_loss = 26.383, entropy_loss = -5.4069, learner_queue_size = 32, _tick = 33852, _time = 1.6548e+09, train_seconds = 3.3328e+04)
[2022-06-10 05:23:33,070][root][INFO] - Step 127508480 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 127508480, mean_episode_return = 76.169, mean_episode_step = 1018.9, total_loss = -181.55, pg_loss = -195.8, baseline_loss = 19.878, entropy_loss = -5.6344, learner_queue_size = 32, _tick = 33858, _time = 1.6548e+09, train_seconds = 3.3333e+04)
[2022-06-10 05:23:38,074][root][INFO] - Step 127528960 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 127528960, mean_episode_return = 25.196, mean_episode_step = 804.34, total_loss = -59.385, pg_loss = -66.831, baseline_loss = 13.378, entropy_loss = -5.9315, learner_queue_size = 32, _tick = 33866, _time = 1.6548e+09, train_seconds = 3.3338e+04)
[2022-06-10 05:23:43,079][root][INFO] - Step 127549440 @ 4092.4 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 127549440, mean_episode_return = 50.54, mean_episode_step = 883.78, total_loss = 179.93, pg_loss = 123.92, baseline_loss = 61.883, entropy_loss = -5.8785, learner_queue_size = 32, _tick = 33874, _time = 1.6548e+09, train_seconds = 3.3343e+04)
[2022-06-10 05:23:48,082][root][INFO] - Step 127567360 @ 3581.4 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 127567360, mean_episode_return = None, mean_episode_step = 913.38, total_loss = 242.16, pg_loss = 181.23, baseline_loss = 66.862, entropy_loss = -5.9384, learner_queue_size = 32, _tick = 33879, _time = 1.6548e+09, train_seconds = 3.3348e+04)
[2022-06-10 05:23:53,088][root][INFO] - Step 127587840 @ 4090.8 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 127587840, mean_episode_return = 63.513, mean_episode_step = 835.78, total_loss = -321.34, pg_loss = -343.87, baseline_loss = 28.382, entropy_loss = -5.8549, learner_queue_size = 32, _tick = 33886, _time = 1.6548e+09, train_seconds = 3.3353e+04)
[2022-06-10 05:23:58,094][root][INFO] - Step 127605760 @ 3579.6 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 127605760, mean_episode_return = 111.06, mean_episode_step = 1013.4, total_loss = 213.85, pg_loss = 161.22, baseline_loss = 58.482, entropy_loss = -5.8532, learner_queue_size = 32, _tick = 33893, _time = 1.6548e+09, train_seconds = 3.3358e+04)
[2022-06-10 05:24:03,101][root][INFO] - Step 127623680 @ 3579.6 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 127623680, mean_episode_return = None, mean_episode_step = 904.12, total_loss = 187.42, pg_loss = 140.89, baseline_loss = 52.306, entropy_loss = -5.7834, learner_queue_size = 32, _tick = 33898, _time = 1.6548e+09, train_seconds = 3.3363e+04)
[2022-06-10 05:24:08,106][root][INFO] - Step 127644160 @ 4091.5 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 127644160, mean_episode_return = 32.205, mean_episode_step = 905.61, total_loss = 45.873, pg_loss = -10.837, baseline_loss = 62.466, entropy_loss = -5.7556, learner_queue_size = 32, _tick = 33904, _time = 1.6548e+09, train_seconds = 3.3368e+04)
[2022-06-10 05:24:13,110][root][INFO] - Step 127664640 @ 4092.8 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 127664640, mean_episode_return = 91.944, mean_episode_step = 771.36, total_loss = -117.95, pg_loss = -253.57, baseline_loss = 141.32, entropy_loss = -5.7053, learner_queue_size = 32, _tick = 33910, _time = 1.6548e+09, train_seconds = 3.3373e+04)
[2022-06-10 05:24:18,114][root][INFO] - Step 127682560 @ 3580.9 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 127682560, mean_episode_return = 30.405, mean_episode_step = 1148.8, total_loss = -64.383, pg_loss = -100.67, baseline_loss = 42.107, entropy_loss = -5.8247, learner_queue_size = 32, _tick = 33916, _time = 1.6548e+09, train_seconds = 3.3378e+04)
[2022-06-10 05:24:23,121][root][INFO] - Step 127703040 @ 4090.2 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 127703040, mean_episode_return = 62.821, mean_episode_step = 1016.3, total_loss = 165.6, pg_loss = 118.07, baseline_loss = 53.254, entropy_loss = -5.7288, learner_queue_size = 32, _tick = 33921, _time = 1.6548e+09, train_seconds = 3.3383e+04)
[2022-06-10 05:24:28,126][root][INFO] - Step 127720960 @ 3580.6 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 127720960, mean_episode_return = 147.34, mean_episode_step = 1164.2, total_loss = 149.35, pg_loss = 95.021, baseline_loss = 60.091, entropy_loss = -5.7674, learner_queue_size = 32, _tick = 33927, _time = 1.6548e+09, train_seconds = 3.3388e+04)
[2022-06-10 05:24:33,130][root][INFO] - Step 127741440 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 127741440, mean_episode_return = 22.05, mean_episode_step = 991.69, total_loss = 4.0168, pg_loss = -81.613, baseline_loss = 91.425, entropy_loss = -5.795, learner_queue_size = 32, _tick = 33934, _time = 1.6548e+09, train_seconds = 3.3393e+04)
[2022-06-10 05:24:38,134][root][INFO] - Step 127759360 @ 3581.2 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 127759360, mean_episode_return = 30.864, mean_episode_step = 1002.1, total_loss = -91.72, pg_loss = -108.9, baseline_loss = 23.005, entropy_loss = -5.8248, learner_queue_size = 32, _tick = 33941, _time = 1.6548e+09, train_seconds = 3.3398e+04)
[2022-06-10 05:24:43,138][root][INFO] - Step 127779840 @ 4092.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 127779840, mean_episode_return = 27.1, mean_episode_step = 933.06, total_loss = 286.08, pg_loss = 225.34, baseline_loss = 66.606, entropy_loss = -5.8606, learner_queue_size = 32, _tick = 33949, _time = 1.6548e+09, train_seconds = 3.3403e+04)
[2022-06-10 05:24:48,142][root][INFO] - Step 127797760 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 127797760, mean_episode_return = 159.84, mean_episode_step = 1098.8, total_loss = 144.42, pg_loss = 105.47, baseline_loss = 44.82, entropy_loss = -5.8689, learner_queue_size = 32, _tick = 33955, _time = 1.6548e+09, train_seconds = 3.3408e+04)
[2022-06-10 05:24:53,146][root][INFO] - Step 127818240 @ 4092.7 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 127818240, mean_episode_return = None, mean_episode_step = 949.0, total_loss = 698.97, pg_loss = 613.46, baseline_loss = 91.307, entropy_loss = -5.8035, learner_queue_size = 32, _tick = 33962, _time = 1.6548e+09, train_seconds = 3.3413e+04)
[2022-06-10 05:24:58,150][root][INFO] - Step 127836160 @ 3580.9 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 127836160, mean_episode_return = 29.98, mean_episode_step = 1022.7, total_loss = 59.915, pg_loss = 31.827, baseline_loss = 33.875, entropy_loss = -5.7865, learner_queue_size = 32, _tick = 33968, _time = 1.6548e+09, train_seconds = 3.3418e+04)
[2022-06-10 05:25:03,154][root][INFO] - Step 127856640 @ 4093.0 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 127856640, mean_episode_return = 137.4, mean_episode_step = 967.88, total_loss = 240.12, pg_loss = 124.1, baseline_loss = 121.89, entropy_loss = -5.8668, learner_queue_size = 32, _tick = 33975, _time = 1.6548e+09, train_seconds = 3.3423e+04)
[2022-06-10 05:25:08,158][root][INFO] - Step 127877120 @ 4092.7 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (step = 127877120, mean_episode_return = 58.58, mean_episode_step = 1279.5, total_loss = -129.95, pg_loss = -146.82, baseline_loss = 22.908, entropy_loss = -6.0382, learner_queue_size = 32, _tick = 33981, _time = 1.6548e+09, train_seconds = 3.3428e+04)
[2022-06-10 05:25:13,162][root][INFO] - Step 127897600 @ 4092.6 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 127897600, mean_episode_return = 78.52, mean_episode_step = 986.73, total_loss = 46.853, pg_loss = 1.5884, baseline_loss = 51.114, entropy_loss = -5.8489, learner_queue_size = 32, _tick = 33988, _time = 1.6548e+09, train_seconds = 3.3433e+04)
[2022-06-10 05:25:18,167][root][INFO] - Step 127918080 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 127918080, mean_episode_return = 67.237, mean_episode_step = 792.44, total_loss = -71.718, pg_loss = -114.27, baseline_loss = 48.352, entropy_loss = -5.8013, learner_queue_size = 32, _tick = 33995, _time = 1.6548e+09, train_seconds = 3.3438e+04)
[2022-06-10 05:25:23,170][root][INFO] - Step 127938560 @ 4092.5 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 127938560, mean_episode_return = None, mean_episode_step = 972.69, total_loss = -121.8, pg_loss = -147.3, baseline_loss = 31.306, entropy_loss = -5.8062, learner_queue_size = 32, _tick = 34001, _time = 1.6548e+09, train_seconds = 3.3443e+04)
[2022-06-10 05:25:28,174][root][INFO] - Step 127956480 @ 3581.4 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 127956480, mean_episode_return = None, mean_episode_step = 911.34, total_loss = 209.62, pg_loss = 152.02, baseline_loss = 63.246, entropy_loss = -5.6436, learner_queue_size = 32, _tick = 34005, _time = 1.6548e+09, train_seconds = 3.3448e+04)
[2022-06-10 05:25:33,178][root][INFO] - Step 127976960 @ 4092.6 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 127976960, mean_episode_return = 32.29, mean_episode_step = 1058.2, total_loss = 57.052, pg_loss = -9.9701, baseline_loss = 72.916, entropy_loss = -5.894, learner_queue_size = 32, _tick = 34011, _time = 1.6548e+09, train_seconds = 3.3453e+04)
[2022-06-10 05:25:38,182][root][INFO] - Step 127994880 @ 3581.2 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 127994880, mean_episode_return = None, mean_episode_step = 886.62, total_loss = -145.81, pg_loss = -175.68, baseline_loss = 35.706, entropy_loss = -5.8354, learner_queue_size = 32, _tick = 34017, _time = 1.6548e+09, train_seconds = 3.3458e+04)
[2022-06-10 05:25:43,186][root][INFO] - Step 128015360 @ 4092.7 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 128015360, mean_episode_return = None, mean_episode_step = 859.0, total_loss = 309.69, pg_loss = 223.02, baseline_loss = 92.575, entropy_loss = -5.9078, learner_queue_size = 32, _tick = 34024, _time = 1.6548e+09, train_seconds = 3.3463e+04)
[2022-06-10 05:25:48,190][root][INFO] - Step 128033280 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 128033280, mean_episode_return = None, mean_episode_step = 872.31, total_loss = 61.011, pg_loss = 34.35, baseline_loss = 32.774, entropy_loss = -6.1131, learner_queue_size = 32, _tick = 34030, _time = 1.6548e+09, train_seconds = 3.3468e+04)
[2022-06-10 05:25:53,194][root][INFO] - Step 128053760 @ 4092.7 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 128053760, mean_episode_return = 30.155, mean_episode_step = 945.29, total_loss = 57.651, pg_loss = 20.789, baseline_loss = 42.708, entropy_loss = -5.8467, learner_queue_size = 32, _tick = 34033, _time = 1.6548e+09, train_seconds = 3.3473e+04)
[2022-06-10 05:25:58,198][root][INFO] - Step 128074240 @ 4092.8 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 128074240, mean_episode_return = None, mean_episode_step = 908.81, total_loss = 33.044, pg_loss = -47.095, baseline_loss = 85.963, entropy_loss = -5.8248, learner_queue_size = 32, _tick = 34039, _time = 1.6548e+09, train_seconds = 3.3478e+04)
[2022-06-10 05:26:03,202][root][INFO] - Step 128092160 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 128092160, mean_episode_return = 68.877, mean_episode_step = 843.21, total_loss = 141.44, pg_loss = 53.889, baseline_loss = 93.447, entropy_loss = -5.8931, learner_queue_size = 32, _tick = 34045, _time = 1.6548e+09, train_seconds = 3.3483e+04)
[2022-06-10 05:26:08,207][root][INFO] - Step 128112640 @ 4092.2 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 128112640, mean_episode_return = 63.813, mean_episode_step = 960.5, total_loss = 190.9, pg_loss = 123.73, baseline_loss = 73.077, entropy_loss = -5.9072, learner_queue_size = 32, _tick = 34050, _time = 1.6548e+09, train_seconds = 3.3488e+04)
[2022-06-10 05:26:13,210][root][INFO] - Step 128133120 @ 4093.2 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 128133120, mean_episode_return = 99.658, mean_episode_step = 1052.7, total_loss = 71.211, pg_loss = 31.327, baseline_loss = 45.827, entropy_loss = -5.9424, learner_queue_size = 32, _tick = 34058, _time = 1.6548e+09, train_seconds = 3.3493e+04)
[2022-06-10 05:26:18,214][root][INFO] - Step 128151040 @ 3581.2 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 128151040, mean_episode_return = 8.0049, mean_episode_step = 1042.2, total_loss = 25.501, pg_loss = -14.88, baseline_loss = 46.295, entropy_loss = -5.9143, learner_queue_size = 32, _tick = 34064, _time = 1.6548e+09, train_seconds = 3.3498e+04)
[2022-06-10 05:26:23,218][root][INFO] - Step 128171520 @ 4092.7 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 128171520, mean_episode_return = 17.035, mean_episode_step = 897.08, total_loss = -208.33, pg_loss = -227.28, baseline_loss = 24.858, entropy_loss = -5.91, learner_queue_size = 32, _tick = 34069, _time = 1.6548e+09, train_seconds = 3.3503e+04)
[2022-06-10 05:26:28,222][root][INFO] - Step 128189440 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 128189440, mean_episode_return = 2.7797, mean_episode_step = 1005.3, total_loss = -61.873, pg_loss = -75.932, baseline_loss = 20.076, entropy_loss = -6.0159, learner_queue_size = 32, _tick = 34075, _time = 1.6548e+09, train_seconds = 3.3508e+04)
[2022-06-10 05:26:33,226][root][INFO] - Step 128209920 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 128209920, mean_episode_return = 50.501, mean_episode_step = 1040.2, total_loss = 574.35, pg_loss = 403.95, baseline_loss = 176.42, entropy_loss = -6.0186, learner_queue_size = 32, _tick = 34082, _time = 1.6548e+09, train_seconds = 3.3513e+04)
[2022-06-10 05:26:38,230][root][INFO] - Step 128230400 @ 4092.7 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 128230400, mean_episode_return = 88.431, mean_episode_step = 937.7, total_loss = 99.707, pg_loss = 66.57, baseline_loss = 39.093, entropy_loss = -5.9555, learner_queue_size = 32, _tick = 34090, _time = 1.6548e+09, train_seconds = 3.3518e+04)
[2022-06-10 05:26:43,236][root][INFO] - Step 128248320 @ 3579.7 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 128248320, mean_episode_return = 83.128, mean_episode_step = 851.13, total_loss = -64.507, pg_loss = -84.722, baseline_loss = 26.216, entropy_loss = -6.0012, learner_queue_size = 32, _tick = 34096, _time = 1.6548e+09, train_seconds = 3.3523e+04)
[2022-06-10 05:26:48,242][root][INFO] - Step 128268800 @ 4091.1 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (step = 128268800, mean_episode_return = 14.78, mean_episode_step = 1127.2, total_loss = -34.576, pg_loss = -62.106, baseline_loss = 33.602, entropy_loss = -6.0716, learner_queue_size = 32, _tick = 34102, _time = 1.6548e+09, train_seconds = 3.3528e+04)
[2022-06-10 05:26:53,249][root][INFO] - Step 128289280 @ 4090.5 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 128289280, mean_episode_return = 48.886, mean_episode_step = 1005.5, total_loss = -221.34, pg_loss = -251.27, baseline_loss = 36.005, entropy_loss = -6.0779, learner_queue_size = 32, _tick = 34109, _time = 1.6548e+09, train_seconds = 3.3533e+04)
[2022-06-10 05:26:58,254][root][INFO] - Step 128307200 @ 3580.3 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 128307200, mean_episode_return = 13.725, mean_episode_step = 1023.5, total_loss = 47.179, pg_loss = 20.791, baseline_loss = 32.486, entropy_loss = -6.0988, learner_queue_size = 32, _tick = 34113, _time = 1.6548e+09, train_seconds = 3.3538e+04)
[2022-06-10 05:27:03,258][root][INFO] - Step 128327680 @ 4092.7 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 128327680, mean_episode_return = 31.84, mean_episode_step = 925.68, total_loss = 189.73, pg_loss = 119.86, baseline_loss = 76.025, entropy_loss = -6.1573, learner_queue_size = 32, _tick = 34120, _time = 1.6548e+09, train_seconds = 3.3543e+04)
[2022-06-10 05:27:08,262][root][INFO] - Step 128348160 @ 4092.2 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 128348160, mean_episode_return = 96.054, mean_episode_step = 661.09, total_loss = 23.894, pg_loss = -16.143, baseline_loss = 45.991, entropy_loss = -5.9539, learner_queue_size = 32, _tick = 34127, _time = 1.6548e+09, train_seconds = 3.3548e+04)
[2022-06-10 05:27:13,266][root][INFO] - Step 128368640 @ 4093.3 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 128368640, mean_episode_return = 40.128, mean_episode_step = 675.99, total_loss = 206.07, pg_loss = 149.31, baseline_loss = 62.554, entropy_loss = -5.7938, learner_queue_size = 32, _tick = 34134, _time = 1.6548e+09, train_seconds = 3.3553e+04)
[2022-06-10 05:27:18,270][root][INFO] - Step 128386560 @ 3581.1 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 128386560, mean_episode_return = 5.29, mean_episode_step = 1168.5, total_loss = 306.84, pg_loss = 206.98, baseline_loss = 105.84, entropy_loss = -5.981, learner_queue_size = 32, _tick = 34139, _time = 1.6548e+09, train_seconds = 3.3558e+04)
[2022-06-10 05:27:23,274][root][INFO] - Step 128407040 @ 4092.7 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 128407040, mean_episode_return = 80.57, mean_episode_step = 967.68, total_loss = -84.305, pg_loss = -101.49, baseline_loss = 22.983, entropy_loss = -5.7958, learner_queue_size = 32, _tick = 34145, _time = 1.6548e+09, train_seconds = 3.3563e+04)
[2022-06-10 05:27:28,278][root][INFO] - Step 128424960 @ 3581.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 128424960, mean_episode_return = 53.181, mean_episode_step = 1053.6, total_loss = -93.436, pg_loss = -184.61, baseline_loss = 97.281, entropy_loss = -6.1093, learner_queue_size = 32, _tick = 34151, _time = 1.6548e+09, train_seconds = 3.3568e+04)
[2022-06-10 05:27:33,282][root][INFO] - Step 128445440 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 128445440, mean_episode_return = 6.8098, mean_episode_step = 877.57, total_loss = -150.15, pg_loss = -162.98, baseline_loss = 18.957, entropy_loss = -6.1258, learner_queue_size = 32, _tick = 34156, _time = 1.6548e+09, train_seconds = 3.3573e+04)
[2022-06-10 05:27:38,288][root][INFO] - Step 128465920 @ 4091.1 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 128465920, mean_episode_return = None, mean_episode_step = 936.84, total_loss = 79.171, pg_loss = 34.281, baseline_loss = 51.092, entropy_loss = -6.202, learner_queue_size = 32, _tick = 34162, _time = 1.6548e+09, train_seconds = 3.3578e+04)
[2022-06-10 05:27:43,290][root][INFO] - Step 128483840 @ 3582.6 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 128483840, mean_episode_return = 42.256, mean_episode_step = 986.8, total_loss = -23.277, pg_loss = -80.083, baseline_loss = 62.812, entropy_loss = -6.0056, learner_queue_size = 32, _tick = 34169, _time = 1.6548e+09, train_seconds = 3.3583e+04)
[2022-06-10 05:27:48,294][root][INFO] - Step 128504320 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 128504320, mean_episode_return = 14.52, mean_episode_step = 722.84, total_loss = 142.59, pg_loss = 83.236, baseline_loss = 65.245, entropy_loss = -5.8897, learner_queue_size = 32, _tick = 34177, _time = 1.6548e+09, train_seconds = 3.3588e+04)
[2022-06-10 05:27:53,298][root][INFO] - Step 128524800 @ 4092.7 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (step = 128524800, mean_episode_return = -8.7601, mean_episode_step = 890.73, total_loss = -63.594, pg_loss = -87.325, baseline_loss = 29.643, entropy_loss = -5.9122, learner_queue_size = 32, _tick = 34183, _time = 1.6548e+09, train_seconds = 3.3593e+04)
[2022-06-10 05:27:58,302][root][INFO] - Step 128545280 @ 4092.7 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 128545280, mean_episode_return = None, mean_episode_step = 1233.5, total_loss = 273.59, pg_loss = 191.63, baseline_loss = 87.975, entropy_loss = -6.0118, learner_queue_size = 32, _tick = 34189, _time = 1.6548e+09, train_seconds = 3.3598e+04)
[2022-06-10 05:28:03,306][root][INFO] - Step 128563200 @ 3581.1 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 128563200, mean_episode_return = 69.52, mean_episode_step = 934.01, total_loss = -14.25, pg_loss = -46.123, baseline_loss = 37.81, entropy_loss = -5.9371, learner_queue_size = 32, _tick = 34195, _time = 1.6548e+09, train_seconds = 3.3603e+04)
[2022-06-10 05:28:08,310][root][INFO] - Step 128583680 @ 4092.8 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 128583680, mean_episode_return = None, mean_episode_step = 1145.9, total_loss = 192.44, pg_loss = 138.09, baseline_loss = 60.294, entropy_loss = -5.9422, learner_queue_size = 32, _tick = 34200, _time = 1.6548e+09, train_seconds = 3.3608e+04)
[2022-06-10 05:28:13,314][root][INFO] - Step 128601600 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 128601600, mean_episode_return = 101.45, mean_episode_step = 1197.0, total_loss = -146.62, pg_loss = -165.58, baseline_loss = 25.104, entropy_loss = -6.148, learner_queue_size = 32, _tick = 34207, _time = 1.6548e+09, train_seconds = 3.3613e+04)
[2022-06-10 05:28:18,318][root][INFO] - Step 128622080 @ 4092.7 SPS. Inference batcher size: 78. Learner queue size: 32. Other stats: (step = 128622080, mean_episode_return = 35.215, mean_episode_step = 1005.2, total_loss = 47.053, pg_loss = 14.43, baseline_loss = 38.716, entropy_loss = -6.093, learner_queue_size = 32, _tick = 34215, _time = 1.6548e+09, train_seconds = 3.3618e+04)
[2022-06-10 05:28:23,324][root][INFO] - Step 128642560 @ 4091.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 128642560, mean_episode_return = 15.995, mean_episode_step = 914.51, total_loss = 390.2, pg_loss = 291.16, baseline_loss = 105.07, entropy_loss = -6.024, learner_queue_size = 32, _tick = 34223, _time = 1.6548e+09, train_seconds = 3.3623e+04)
[2022-06-10 05:28:28,330][root][INFO] - Step 128663040 @ 4091.1 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 128663040, mean_episode_return = 58.081, mean_episode_step = 1043.9, total_loss = 204.61, pg_loss = 156.38, baseline_loss = 54.123, entropy_loss = -5.8896, learner_queue_size = 32, _tick = 34229, _time = 1.6548e+09, train_seconds = 3.3628e+04)
[2022-06-10 05:28:33,334][root][INFO] - Step 128680960 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 128680960, mean_episode_return = 52.086, mean_episode_step = 1018.0, total_loss = -56.455, pg_loss = -82.394, baseline_loss = 31.727, entropy_loss = -5.7874, learner_queue_size = 32, _tick = 34233, _time = 1.6548e+09, train_seconds = 3.3633e+04)
[2022-06-10 05:28:38,338][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 05:28:38,488][root][INFO] - Step 128701440 @ 4092.8 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 128701440, mean_episode_return = 14.11, mean_episode_step = 934.88, total_loss = -36.635, pg_loss = -75.263, baseline_loss = 44.52, entropy_loss = -5.8933, learner_queue_size = 32, _tick = 34240, _time = 1.6548e+09, train_seconds = 3.3638e+04)
[2022-06-10 05:28:43,495][root][INFO] - Step 128719360 @ 3475.0 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 128719360, mean_episode_return = 152.7, mean_episode_step = 1038.6, total_loss = 87.958, pg_loss = 48.936, baseline_loss = 44.858, entropy_loss = -5.8367, learner_queue_size = 32, _tick = 34247, _time = 1.6548e+09, train_seconds = 3.3643e+04)
[2022-06-10 05:28:48,498][root][INFO] - Step 128739840 @ 4093.4 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 128739840, mean_episode_return = None, mean_episode_step = 642.06, total_loss = -48.714, pg_loss = -71.222, baseline_loss = 28.522, entropy_loss = -6.0139, learner_queue_size = 32, _tick = 34252, _time = 1.6548e+09, train_seconds = 3.3648e+04)
[2022-06-10 05:28:53,502][root][INFO] - Step 128760320 @ 4092.7 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 128760320, mean_episode_return = 5.9197, mean_episode_step = 1076.6, total_loss = 69.814, pg_loss = 32.74, baseline_loss = 43.175, entropy_loss = -6.1008, learner_queue_size = 32, _tick = 34260, _time = 1.6548e+09, train_seconds = 3.3653e+04)
[2022-06-10 05:28:58,506][root][INFO] - Step 128778240 @ 3581.0 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (step = 128778240, mean_episode_return = None, mean_episode_step = 1181.2, total_loss = 1.0856, pg_loss = -9.6289, baseline_loss = 16.656, entropy_loss = -5.9419, learner_queue_size = 32, _tick = 34265, _time = 1.6548e+09, train_seconds = 3.3658e+04)
[2022-06-10 05:29:03,510][root][INFO] - Step 128798720 @ 4092.9 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 128798720, mean_episode_return = 184.25, mean_episode_step = 847.19, total_loss = 304.44, pg_loss = 227.09, baseline_loss = 83.189, entropy_loss = -5.8333, learner_queue_size = 32, _tick = 34272, _time = 1.6548e+09, train_seconds = 3.3663e+04)
[2022-06-10 05:29:08,514][root][INFO] - Step 128819200 @ 4092.7 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 128819200, mean_episode_return = 94.94, mean_episode_step = 883.31, total_loss = -94.947, pg_loss = -121.71, baseline_loss = 32.399, entropy_loss = -5.6398, learner_queue_size = 32, _tick = 34279, _time = 1.6548e+09, train_seconds = 3.3668e+04)
[2022-06-10 05:29:13,518][root][INFO] - Step 128837120 @ 3581.2 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 128837120, mean_episode_return = 16.225, mean_episode_step = 1165.0, total_loss = 105.24, pg_loss = 50.689, baseline_loss = 60.047, entropy_loss = -5.5006, learner_queue_size = 32, _tick = 34285, _time = 1.6548e+09, train_seconds = 3.3673e+04)
[2022-06-10 05:29:18,522][root][INFO] - Step 128857600 @ 4092.6 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 128857600, mean_episode_return = None, mean_episode_step = 1128.6, total_loss = -50.314, pg_loss = -62.311, baseline_loss = 17.433, entropy_loss = -5.4365, learner_queue_size = 32, _tick = 34292, _time = 1.6548e+09, train_seconds = 3.3678e+04)
[2022-06-10 05:29:23,528][root][INFO] - Step 128875520 @ 3580.0 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 128875520, mean_episode_return = None, mean_episode_step = 1137.6, total_loss = 87.774, pg_loss = 30.89, baseline_loss = 62.418, entropy_loss = -5.5337, learner_queue_size = 32, _tick = 34296, _time = 1.6548e+09, train_seconds = 3.3683e+04)
[2022-06-10 05:29:28,530][root][INFO] - Step 128896000 @ 4094.1 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (step = 128896000, mean_episode_return = None, mean_episode_step = 1085.8, total_loss = -241.95, pg_loss = -244.18, baseline_loss = 7.8962, entropy_loss = -5.6645, learner_queue_size = 32, _tick = 34301, _time = 1.6548e+09, train_seconds = 3.3688e+04)
[2022-06-10 05:29:33,534][root][INFO] - Step 128916480 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 128916480, mean_episode_return = None, mean_episode_step = 1011.2, total_loss = -77.73, pg_loss = -92.039, baseline_loss = 20.041, entropy_loss = -5.7315, learner_queue_size = 32, _tick = 34308, _time = 1.6548e+09, train_seconds = 3.3693e+04)
[2022-06-10 05:29:38,538][root][INFO] - Step 128936960 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 128936960, mean_episode_return = None, mean_episode_step = 1241.2, total_loss = -43.775, pg_loss = -73.553, baseline_loss = 35.673, entropy_loss = -5.8947, learner_queue_size = 32, _tick = 34313, _time = 1.6548e+09, train_seconds = 3.3698e+04)
[2022-06-10 05:29:43,542][root][INFO] - Step 128957440 @ 4092.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 128957440, mean_episode_return = 78.521, mean_episode_step = 1008.5, total_loss = 101.69, pg_loss = 36.674, baseline_loss = 70.813, entropy_loss = -5.7974, learner_queue_size = 32, _tick = 34319, _time = 1.6548e+09, train_seconds = 3.3703e+04)
[2022-06-10 05:29:48,546][root][INFO] - Step 128977920 @ 4092.8 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 128977920, mean_episode_return = 65.049, mean_episode_step = 1054.7, total_loss = 204.48, pg_loss = 65.582, baseline_loss = 144.56, entropy_loss = -5.6592, learner_queue_size = 32, _tick = 34327, _time = 1.6548e+09, train_seconds = 3.3708e+04)
[2022-06-10 05:29:53,550][root][INFO] - Step 128995840 @ 3581.1 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 128995840, mean_episode_return = 98.957, mean_episode_step = 957.14, total_loss = -124.51, pg_loss = -150.91, baseline_loss = 32.026, entropy_loss = -5.6269, learner_queue_size = 32, _tick = 34333, _time = 1.6548e+09, train_seconds = 3.3713e+04)
[2022-06-10 05:29:58,554][root][INFO] - Step 129016320 @ 4092.7 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 129016320, mean_episode_return = 24.17, mean_episode_step = 829.54, total_loss = 55.724, pg_loss = 14.646, baseline_loss = 46.579, entropy_loss = -5.5009, learner_queue_size = 32, _tick = 34341, _time = 1.6548e+09, train_seconds = 3.3718e+04)
[2022-06-10 05:30:03,558][root][INFO] - Step 129034240 @ 3581.2 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 129034240, mean_episode_return = 71.007, mean_episode_step = 933.79, total_loss = -139.07, pg_loss = -215.4, baseline_loss = 81.839, entropy_loss = -5.5051, learner_queue_size = 32, _tick = 34347, _time = 1.6548e+09, train_seconds = 3.3723e+04)
[2022-06-10 05:30:08,562][root][INFO] - Step 129054720 @ 4092.6 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 129054720, mean_episode_return = 42.606, mean_episode_step = 716.46, total_loss = -66.748, pg_loss = -96.22, baseline_loss = 34.682, entropy_loss = -5.2108, learner_queue_size = 32, _tick = 34355, _time = 1.6548e+09, train_seconds = 3.3728e+04)
[2022-06-10 05:30:13,566][root][INFO] - Step 129072640 @ 3581.2 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 129072640, mean_episode_return = 19.655, mean_episode_step = 940.13, total_loss = -53.358, pg_loss = -82.289, baseline_loss = 34.654, entropy_loss = -5.7228, learner_queue_size = 32, _tick = 34362, _time = 1.6548e+09, train_seconds = 3.3733e+04)
[2022-06-10 05:30:18,570][root][INFO] - Step 129093120 @ 4092.7 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 129093120, mean_episode_return = 10.75, mean_episode_step = 899.99, total_loss = -13.234, pg_loss = -53.804, baseline_loss = 46.051, entropy_loss = -5.4809, learner_queue_size = 32, _tick = 34367, _time = 1.6548e+09, train_seconds = 3.3738e+04)
[2022-06-10 05:30:23,575][root][INFO] - Step 129113600 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 129113600, mean_episode_return = 95.5, mean_episode_step = 908.07, total_loss = -21.854, pg_loss = -64.444, baseline_loss = 48.271, entropy_loss = -5.6804, learner_queue_size = 32, _tick = 34374, _time = 1.6548e+09, train_seconds = 3.3743e+04)
[2022-06-10 05:30:28,578][root][INFO] - Step 129131520 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 129131520, mean_episode_return = None, mean_episode_step = 932.5, total_loss = 225.17, pg_loss = 124.8, baseline_loss = 105.92, entropy_loss = -5.5546, learner_queue_size = 32, _tick = 34380, _time = 1.6548e+09, train_seconds = 3.3748e+04)
[2022-06-10 05:30:33,582][root][INFO] - Step 129152000 @ 4092.6 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 129152000, mean_episode_return = -5.39, mean_episode_step = 662.11, total_loss = 481.63, pg_loss = 352.06, baseline_loss = 135.05, entropy_loss = -5.4891, learner_queue_size = 32, _tick = 34387, _time = 1.6548e+09, train_seconds = 3.3753e+04)
[2022-06-10 05:30:38,586][root][INFO] - Step 129172480 @ 4092.7 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 129172480, mean_episode_return = 67.215, mean_episode_step = 950.56, total_loss = 272.81, pg_loss = 123.1, baseline_loss = 155.13, entropy_loss = -5.4238, learner_queue_size = 32, _tick = 34394, _time = 1.6548e+09, train_seconds = 3.3758e+04)
[2022-06-10 05:30:43,590][root][INFO] - Step 129190400 @ 3581.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 129190400, mean_episode_return = None, mean_episode_step = 981.16, total_loss = 339.87, pg_loss = 273.22, baseline_loss = 72.207, entropy_loss = -5.5545, learner_queue_size = 32, _tick = 34399, _time = 1.6548e+09, train_seconds = 3.3763e+04)
[2022-06-10 05:30:48,594][root][INFO] - Step 129210880 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 129210880, mean_episode_return = 88.62, mean_episode_step = 1024.0, total_loss = -191.44, pg_loss = -205.0, baseline_loss = 19.166, entropy_loss = -5.6054, learner_queue_size = 32, _tick = 34405, _time = 1.6548e+09, train_seconds = 3.3768e+04)
[2022-06-10 05:30:53,598][root][INFO] - Step 129231360 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 129231360, mean_episode_return = 19.39, mean_episode_step = 900.07, total_loss = -93.818, pg_loss = -97.603, baseline_loss = 9.6728, entropy_loss = -5.888, learner_queue_size = 32, _tick = 34413, _time = 1.6548e+09, train_seconds = 3.3773e+04)
[2022-06-10 05:30:58,602][root][INFO] - Step 129249280 @ 3581.1 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 129249280, mean_episode_return = 30.9, mean_episode_step = 1026.6, total_loss = 4.1792, pg_loss = -46.489, baseline_loss = 56.537, entropy_loss = -5.8689, learner_queue_size = 32, _tick = 34419, _time = 1.6548e+09, train_seconds = 3.3778e+04)
[2022-06-10 05:31:03,607][root][INFO] - Step 129269760 @ 4091.6 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 129269760, mean_episode_return = 23.57, mean_episode_step = 825.09, total_loss = -20.145, pg_loss = -31.826, baseline_loss = 17.538, entropy_loss = -5.857, learner_queue_size = 32, _tick = 34425, _time = 1.6548e+09, train_seconds = 3.3783e+04)
[2022-06-10 05:31:08,613][root][INFO] - Step 129290240 @ 4091.1 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 129290240, mean_episode_return = 30.485, mean_episode_step = 908.95, total_loss = 61.39, pg_loss = 18.257, baseline_loss = 48.964, entropy_loss = -5.8317, learner_queue_size = 32, _tick = 34432, _time = 1.6548e+09, train_seconds = 3.3788e+04)
[2022-06-10 05:31:13,618][root][INFO] - Step 129308160 @ 3580.7 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 129308160, mean_episode_return = 63.405, mean_episode_step = 1180.6, total_loss = 374.95, pg_loss = 253.26, baseline_loss = 127.5, entropy_loss = -5.7983, learner_queue_size = 32, _tick = 34439, _time = 1.6548e+09, train_seconds = 3.3793e+04)
[2022-06-10 05:31:18,622][root][INFO] - Step 129328640 @ 4092.6 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 129328640, mean_episode_return = 65.431, mean_episode_step = 971.91, total_loss = 394.47, pg_loss = 203.91, baseline_loss = 196.11, entropy_loss = -5.5546, learner_queue_size = 32, _tick = 34446, _time = 1.6548e+09, train_seconds = 3.3798e+04)
[2022-06-10 05:31:23,626][root][INFO] - Step 129346560 @ 3581.2 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 129346560, mean_episode_return = 129.2, mean_episode_step = 1297.6, total_loss = -306.97, pg_loss = -357.31, baseline_loss = 56.094, entropy_loss = -5.7533, learner_queue_size = 32, _tick = 34452, _time = 1.6548e+09, train_seconds = 3.3803e+04)
[2022-06-10 05:31:28,630][root][INFO] - Step 129367040 @ 4092.7 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 129367040, mean_episode_return = 88.593, mean_episode_step = 998.38, total_loss = -54.345, pg_loss = -81.544, baseline_loss = 32.999, entropy_loss = -5.8006, learner_queue_size = 32, _tick = 34459, _time = 1.6548e+09, train_seconds = 3.3808e+04)
[2022-06-10 05:31:33,634][root][INFO] - Step 129387520 @ 4092.4 SPS. Inference batcher size: 123. Learner queue size: 32. Other stats: (step = 129387520, mean_episode_return = 24.68, mean_episode_step = 893.8, total_loss = 57.371, pg_loss = 18.14, baseline_loss = 44.962, entropy_loss = -5.731, learner_queue_size = 32, _tick = 34465, _time = 1.6548e+09, train_seconds = 3.3813e+04)
[2022-06-10 05:31:38,638][root][INFO] - Step 129405440 @ 3581.5 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 129405440, mean_episode_return = None, mean_episode_step = 951.91, total_loss = 158.76, pg_loss = 122.11, baseline_loss = 42.425, entropy_loss = -5.7778, learner_queue_size = 32, _tick = 34471, _time = 1.6548e+09, train_seconds = 3.3818e+04)
[2022-06-10 05:31:43,642][root][INFO] - Step 129423360 @ 3581.2 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 129423360, mean_episode_return = None, mean_episode_step = 857.06, total_loss = 139.0, pg_loss = 115.93, baseline_loss = 28.855, entropy_loss = -5.7813, learner_queue_size = 32, _tick = 34475, _time = 1.6548e+09, train_seconds = 3.3823e+04)
[2022-06-10 05:31:48,649][root][INFO] - Step 129443840 @ 4090.6 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 129443840, mean_episode_return = 63.82, mean_episode_step = 1046.9, total_loss = -18.594, pg_loss = -31.203, baseline_loss = 18.36, entropy_loss = -5.7509, learner_queue_size = 32, _tick = 34482, _time = 1.6548e+09, train_seconds = 3.3828e+04)
[2022-06-10 05:31:53,654][root][INFO] - Step 129461760 @ 3580.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 129461760, mean_episode_return = -9.7001, mean_episode_step = 826.6, total_loss = 180.01, pg_loss = 110.25, baseline_loss = 75.424, entropy_loss = -5.6672, learner_queue_size = 32, _tick = 34488, _time = 1.6548e+09, train_seconds = 3.3834e+04)
[2022-06-10 05:31:58,663][root][INFO] - Step 129482240 @ 4089.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 129482240, mean_episode_return = 34.595, mean_episode_step = 856.22, total_loss = 154.3, pg_loss = 60.256, baseline_loss = 99.605, entropy_loss = -5.5583, learner_queue_size = 32, _tick = 34496, _time = 1.6548e+09, train_seconds = 3.3838e+04)
[2022-06-10 05:32:03,666][root][INFO] - Step 129502720 @ 4092.9 SPS. Inference batcher size: 89. Learner queue size: 32. Other stats: (step = 129502720, mean_episode_return = 96.401, mean_episode_step = 880.78, total_loss = 267.83, pg_loss = 184.64, baseline_loss = 88.78, entropy_loss = -5.5821, learner_queue_size = 32, _tick = 34501, _time = 1.6548e+09, train_seconds = 3.3844e+04)
[2022-06-10 05:32:08,670][root][INFO] - Step 129520640 @ 3581.3 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 129520640, mean_episode_return = 85.396, mean_episode_step = 920.07, total_loss = 212.23, pg_loss = 135.39, baseline_loss = 82.067, entropy_loss = -5.232, learner_queue_size = 32, _tick = 34508, _time = 1.6548e+09, train_seconds = 3.3848e+04)
[2022-06-10 05:32:13,674][root][INFO] - Step 129541120 @ 4092.8 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 129541120, mean_episode_return = None, mean_episode_step = 932.31, total_loss = -174.02, pg_loss = -196.35, baseline_loss = 27.7, entropy_loss = -5.371, learner_queue_size = 32, _tick = 34513, _time = 1.6548e+09, train_seconds = 3.3854e+04)
[2022-06-10 05:32:18,678][root][INFO] - Step 129561600 @ 4092.8 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 129561600, mean_episode_return = 47.85, mean_episode_step = 714.32, total_loss = 156.01, pg_loss = 55.449, baseline_loss = 106.15, entropy_loss = -5.5967, learner_queue_size = 32, _tick = 34519, _time = 1.6548e+09, train_seconds = 3.3858e+04)
[2022-06-10 05:32:23,682][root][INFO] - Step 129579520 @ 3581.1 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 129579520, mean_episode_return = None, mean_episode_step = 897.03, total_loss = 84.512, pg_loss = 40.464, baseline_loss = 49.919, entropy_loss = -5.872, learner_queue_size = 32, _tick = 34524, _time = 1.6548e+09, train_seconds = 3.3864e+04)
[2022-06-10 05:32:28,686][root][INFO] - Step 129600000 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 129600000, mean_episode_return = 29.91, mean_episode_step = 838.61, total_loss = -164.11, pg_loss = -184.3, baseline_loss = 25.865, entropy_loss = -5.6685, learner_queue_size = 32, _tick = 34532, _time = 1.6548e+09, train_seconds = 3.3868e+04)
[2022-06-10 05:32:33,690][root][INFO] - Step 129617920 @ 3581.2 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 129617920, mean_episode_return = 57.091, mean_episode_step = 1169.5, total_loss = 553.77, pg_loss = 236.09, baseline_loss = 323.3, entropy_loss = -5.6195, learner_queue_size = 32, _tick = 34536, _time = 1.6548e+09, train_seconds = 3.3874e+04)
[2022-06-10 05:32:38,694][root][INFO] - Step 129635840 @ 3581.2 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 129635840, mean_episode_return = 42.62, mean_episode_step = 963.1, total_loss = -131.15, pg_loss = -177.39, baseline_loss = 51.881, entropy_loss = -5.6475, learner_queue_size = 32, _tick = 34542, _time = 1.6548e+09, train_seconds = 3.3878e+04)
[2022-06-10 05:32:43,698][root][INFO] - Step 129656320 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 129656320, mean_episode_return = 29.471, mean_episode_step = 1124.0, total_loss = 52.833, pg_loss = 18.266, baseline_loss = 40.343, entropy_loss = -5.7761, learner_queue_size = 32, _tick = 34549, _time = 1.6548e+09, train_seconds = 3.3884e+04)
[2022-06-10 05:32:48,704][root][INFO] - Step 129674240 @ 3579.4 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 129674240, mean_episode_return = None, mean_episode_step = 1042.7, total_loss = -65.188, pg_loss = -83.484, baseline_loss = 24.04, entropy_loss = -5.744, learner_queue_size = 32, _tick = 34553, _time = 1.6548e+09, train_seconds = 3.3888e+04)
[2022-06-10 05:32:53,710][root][INFO] - Step 129694720 @ 4091.4 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 129694720, mean_episode_return = 37.835, mean_episode_step = 1263.3, total_loss = 155.46, pg_loss = 107.37, baseline_loss = 53.979, entropy_loss = -5.8871, learner_queue_size = 32, _tick = 34559, _time = 1.6548e+09, train_seconds = 3.3894e+04)
[2022-06-10 05:32:58,714][root][INFO] - Step 129715200 @ 4092.7 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 129715200, mean_episode_return = None, mean_episode_step = 1213.3, total_loss = 254.97, pg_loss = 183.87, baseline_loss = 76.947, entropy_loss = -5.8461, learner_queue_size = 32, _tick = 34564, _time = 1.6548e+09, train_seconds = 3.3898e+04)
[2022-06-10 05:33:03,718][root][INFO] - Step 129733120 @ 3581.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 129733120, mean_episode_return = 91.34, mean_episode_step = 1221.9, total_loss = -16.288, pg_loss = -79.443, baseline_loss = 68.99, entropy_loss = -5.8361, learner_queue_size = 32, _tick = 34570, _time = 1.6548e+09, train_seconds = 3.3904e+04)
[2022-06-10 05:33:08,722][root][INFO] - Step 129753600 @ 4092.8 SPS. Inference batcher size: 84. Learner queue size: 32. Other stats: (step = 129753600, mean_episode_return = 100.3, mean_episode_step = 947.44, total_loss = -13.468, pg_loss = -36.545, baseline_loss = 28.957, entropy_loss = -5.8802, learner_queue_size = 32, _tick = 34577, _time = 1.6548e+09, train_seconds = 3.3908e+04)
[2022-06-10 05:33:13,726][root][INFO] - Step 129771520 @ 3581.1 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 129771520, mean_episode_return = 20.45, mean_episode_step = 983.97, total_loss = 65.617, pg_loss = 11.858, baseline_loss = 59.578, entropy_loss = -5.8194, learner_queue_size = 32, _tick = 34584, _time = 1.6548e+09, train_seconds = 3.3914e+04)
[2022-06-10 05:33:18,730][root][INFO] - Step 129792000 @ 4092.7 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 129792000, mean_episode_return = None, mean_episode_step = 1089.6, total_loss = -7.0626, pg_loss = -18.788, baseline_loss = 17.574, entropy_loss = -5.8486, learner_queue_size = 32, _tick = 34591, _time = 1.6548e+09, train_seconds = 3.3918e+04)
[2022-06-10 05:33:23,734][root][INFO] - Step 129812480 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 129812480, mean_episode_return = None, mean_episode_step = 735.25, total_loss = 328.5, pg_loss = 248.21, baseline_loss = 86.048, entropy_loss = -5.7635, learner_queue_size = 32, _tick = 34598, _time = 1.6548e+09, train_seconds = 3.3924e+04)
[2022-06-10 05:33:28,738][root][INFO] - Step 129830400 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 129830400, mean_episode_return = None, mean_episode_step = 1012.1, total_loss = 11.175, pg_loss = -24.748, baseline_loss = 41.684, entropy_loss = -5.7608, learner_queue_size = 32, _tick = 34603, _time = 1.6548e+09, train_seconds = 3.3928e+04)
[2022-06-10 05:33:33,743][root][INFO] - Step 129850880 @ 4092.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 129850880, mean_episode_return = 18.13, mean_episode_step = 1040.6, total_loss = 6.8414, pg_loss = -25.159, baseline_loss = 37.952, entropy_loss = -5.9519, learner_queue_size = 32, _tick = 34610, _time = 1.6548e+09, train_seconds = 3.3934e+04)
[2022-06-10 05:33:38,746][root][INFO] - Step 129871360 @ 4093.4 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 129871360, mean_episode_return = 47.12, mean_episode_step = 850.01, total_loss = 198.12, pg_loss = 133.47, baseline_loss = 70.555, entropy_loss = -5.9051, learner_queue_size = 32, _tick = 34616, _time = 1.6548e+09, train_seconds = 3.3939e+04)
[2022-06-10 05:33:43,750][root][INFO] - Step 129889280 @ 3581.2 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 129889280, mean_episode_return = 70.956, mean_episode_step = 846.17, total_loss = -8.971, pg_loss = -44.869, baseline_loss = 41.78, entropy_loss = -5.8827, learner_queue_size = 32, _tick = 34622, _time = 1.6548e+09, train_seconds = 3.3944e+04)
[2022-06-10 05:33:48,754][root][INFO] - Step 129909760 @ 4092.7 SPS. Inference batcher size: 86. Learner queue size: 32. Other stats: (step = 129909760, mean_episode_return = 59.803, mean_episode_step = 846.6, total_loss = -64.812, pg_loss = -99.816, baseline_loss = 40.783, entropy_loss = -5.7789, learner_queue_size = 32, _tick = 34628, _time = 1.6548e+09, train_seconds = 3.3949e+04)
[2022-06-10 05:33:53,758][root][INFO] - Step 129927680 @ 3581.1 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 129927680, mean_episode_return = 81.55, mean_episode_step = 796.86, total_loss = 17.53, pg_loss = -19.966, baseline_loss = 43.252, entropy_loss = -5.756, learner_queue_size = 32, _tick = 34633, _time = 1.6548e+09, train_seconds = 3.3954e+04)
[2022-06-10 05:33:58,762][root][INFO] - Step 129948160 @ 4092.7 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 129948160, mean_episode_return = None, mean_episode_step = 831.88, total_loss = 259.34, pg_loss = 200.76, baseline_loss = 64.367, entropy_loss = -5.7896, learner_queue_size = 32, _tick = 34639, _time = 1.6548e+09, train_seconds = 3.3959e+04)
[2022-06-10 05:34:03,764][root][INFO] - Step 129966080 @ 3582.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 129966080, mean_episode_return = 45.305, mean_episode_step = 865.95, total_loss = -20.308, pg_loss = -78.604, baseline_loss = 64.12, entropy_loss = -5.8236, learner_queue_size = 32, _tick = 34643, _time = 1.6548e+09, train_seconds = 3.3964e+04)
[2022-06-10 05:34:08,766][root][INFO] - Step 129986560 @ 4094.2 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 129986560, mean_episode_return = 64.507, mean_episode_step = 861.53, total_loss = 229.63, pg_loss = 180.82, baseline_loss = 54.588, entropy_loss = -5.7843, learner_queue_size = 32, _tick = 34651, _time = 1.6548e+09, train_seconds = 3.3969e+04)
[2022-06-10 05:34:13,770][root][INFO] - Step 130007040 @ 4092.7 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 130007040, mean_episode_return = 94.729, mean_episode_step = 910.59, total_loss = 126.89, pg_loss = 85.667, baseline_loss = 46.954, entropy_loss = -5.7345, learner_queue_size = 32, _tick = 34658, _time = 1.6548e+09, train_seconds = 3.3974e+04)
[2022-06-10 05:34:18,774][root][INFO] - Step 130027520 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 130027520, mean_episode_return = None, mean_episode_step = 794.0, total_loss = 102.24, pg_loss = 72.576, baseline_loss = 35.265, entropy_loss = -5.6052, learner_queue_size = 32, _tick = 34664, _time = 1.6548e+09, train_seconds = 3.3979e+04)
[2022-06-10 05:34:23,780][root][INFO] - Step 130045440 @ 3579.6 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 130045440, mean_episode_return = 14.31, mean_episode_step = 908.09, total_loss = 106.44, pg_loss = 53.457, baseline_loss = 58.682, entropy_loss = -5.698, learner_queue_size = 32, _tick = 34668, _time = 1.6548e+09, train_seconds = 3.3984e+04)
[2022-06-10 05:34:28,786][root][INFO] - Step 130065920 @ 4091.2 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 130065920, mean_episode_return = 38.13, mean_episode_step = 878.61, total_loss = 77.134, pg_loss = 5.8741, baseline_loss = 76.622, entropy_loss = -5.3616, learner_queue_size = 32, _tick = 34675, _time = 1.6548e+09, train_seconds = 3.3989e+04)
[2022-06-10 05:34:33,790][root][INFO] - Step 130086400 @ 4092.8 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 130086400, mean_episode_return = 31.873, mean_episode_step = 931.19, total_loss = -10.66, pg_loss = -36.945, baseline_loss = 31.631, entropy_loss = -5.3465, learner_queue_size = 32, _tick = 34681, _time = 1.6548e+09, train_seconds = 3.3994e+04)
[2022-06-10 05:34:38,794][root][INFO] - Step 130104320 @ 3581.1 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 130104320, mean_episode_return = None, mean_episode_step = 934.53, total_loss = -16.744, pg_loss = -22.659, baseline_loss = 11.618, entropy_loss = -5.7028, learner_queue_size = 32, _tick = 34686, _time = 1.6548e+09, train_seconds = 3.3999e+04)
[2022-06-10 05:34:43,798][root][INFO] - Step 130124800 @ 4092.8 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 130124800, mean_episode_return = 83.31, mean_episode_step = 821.58, total_loss = 283.28, pg_loss = 191.37, baseline_loss = 97.586, entropy_loss = -5.6743, learner_queue_size = 32, _tick = 34691, _time = 1.6548e+09, train_seconds = 3.4004e+04)
[2022-06-10 05:34:48,802][root][INFO] - Step 130145280 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 130145280, mean_episode_return = None, mean_episode_step = 1007.6, total_loss = -27.812, pg_loss = -42.883, baseline_loss = 20.67, entropy_loss = -5.5988, learner_queue_size = 32, _tick = 34696, _time = 1.6548e+09, train_seconds = 3.4009e+04)
[2022-06-10 05:34:53,806][root][INFO] - Step 130163200 @ 3581.2 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 130163200, mean_episode_return = 199.17, mean_episode_step = 996.91, total_loss = 207.07, pg_loss = 155.58, baseline_loss = 57.272, entropy_loss = -5.7816, learner_queue_size = 32, _tick = 34700, _time = 1.6548e+09, train_seconds = 3.4014e+04)
[2022-06-10 05:34:58,810][root][INFO] - Step 130183680 @ 4092.7 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 130183680, mean_episode_return = 45.4, mean_episode_step = 1074.9, total_loss = 66.183, pg_loss = 27.11, baseline_loss = 44.768, entropy_loss = -5.6951, learner_queue_size = 32, _tick = 34707, _time = 1.6548e+09, train_seconds = 3.4019e+04)
[2022-06-10 05:35:03,814][root][INFO] - Step 130204160 @ 4092.7 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 130204160, mean_episode_return = 55.59, mean_episode_step = 1160.0, total_loss = -51.393, pg_loss = -81.637, baseline_loss = 36.068, entropy_loss = -5.8237, learner_queue_size = 32, _tick = 34713, _time = 1.6548e+09, train_seconds = 3.4024e+04)
[2022-06-10 05:35:08,818][root][INFO] - Step 130224640 @ 4092.6 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 130224640, mean_episode_return = 24.8, mean_episode_step = 962.91, total_loss = 269.7, pg_loss = 208.04, baseline_loss = 67.456, entropy_loss = -5.7904, learner_queue_size = 32, _tick = 34721, _time = 1.6548e+09, train_seconds = 3.4029e+04)
[2022-06-10 05:35:13,822][root][INFO] - Step 130242560 @ 3581.2 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 130242560, mean_episode_return = 65.605, mean_episode_step = 1065.1, total_loss = -21.144, pg_loss = -50.122, baseline_loss = 34.826, entropy_loss = -5.8475, learner_queue_size = 32, _tick = 34727, _time = 1.6548e+09, train_seconds = 3.4034e+04)
[2022-06-10 05:35:18,826][root][INFO] - Step 130263040 @ 4092.7 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 130263040, mean_episode_return = 21.27, mean_episode_step = 988.89, total_loss = 84.246, pg_loss = 32.072, baseline_loss = 57.703, entropy_loss = -5.5291, learner_queue_size = 32, _tick = 34733, _time = 1.6548e+09, train_seconds = 3.4039e+04)
[2022-06-10 05:35:23,830][root][INFO] - Step 130280960 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 130280960, mean_episode_return = None, mean_episode_step = 1207.2, total_loss = 155.62, pg_loss = 96.728, baseline_loss = 64.669, entropy_loss = -5.7757, learner_queue_size = 32, _tick = 34738, _time = 1.6548e+09, train_seconds = 3.4044e+04)
[2022-06-10 05:35:28,834][root][INFO] - Step 130301440 @ 4092.7 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 130301440, mean_episode_return = 118.83, mean_episode_step = 817.05, total_loss = 0.42328, pg_loss = -55.612, baseline_loss = 61.548, entropy_loss = -5.5122, learner_queue_size = 32, _tick = 34745, _time = 1.6548e+09, train_seconds = 3.4049e+04)
[2022-06-10 05:35:33,838][root][INFO] - Step 130321920 @ 4092.8 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 130321920, mean_episode_return = None, mean_episode_step = 943.09, total_loss = -131.38, pg_loss = -150.8, baseline_loss = 25.157, entropy_loss = -5.7452, learner_queue_size = 32, _tick = 34752, _time = 1.6548e+09, train_seconds = 3.4054e+04)
[2022-06-10 05:35:38,842][root][INFO] - Step 130342400 @ 4092.7 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 130342400, mean_episode_return = 53.59, mean_episode_step = 1096.6, total_loss = 175.07, pg_loss = 78.442, baseline_loss = 102.44, entropy_loss = -5.8067, learner_queue_size = 32, _tick = 34758, _time = 1.6548e+09, train_seconds = 3.4059e+04)
[2022-06-10 05:35:43,846][root][INFO] - Step 130362880 @ 4092.7 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 130362880, mean_episode_return = 32.514, mean_episode_step = 1043.4, total_loss = 313.46, pg_loss = 231.99, baseline_loss = 87.174, entropy_loss = -5.7019, learner_queue_size = 32, _tick = 34763, _time = 1.6548e+09, train_seconds = 3.4064e+04)
[2022-06-10 05:35:48,851][root][INFO] - Step 130380800 @ 3580.6 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 130380800, mean_episode_return = 14.2, mean_episode_step = 879.19, total_loss = 278.36, pg_loss = 215.97, baseline_loss = 68.095, entropy_loss = -5.7066, learner_queue_size = 32, _tick = 34767, _time = 1.6548e+09, train_seconds = 3.4069e+04)
[2022-06-10 05:35:53,854][root][INFO] - Step 130398720 @ 3581.6 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 130398720, mean_episode_return = 172.49, mean_episode_step = 1176.6, total_loss = 44.448, pg_loss = 22.691, baseline_loss = 27.491, entropy_loss = -5.7337, learner_queue_size = 32, _tick = 34773, _time = 1.6548e+09, train_seconds = 3.4074e+04)
[2022-06-10 05:35:58,858][root][INFO] - Step 130419200 @ 4092.8 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 130419200, mean_episode_return = 135.86, mean_episode_step = 1262.2, total_loss = 98.118, pg_loss = 63.202, baseline_loss = 40.506, entropy_loss = -5.5887, learner_queue_size = 32, _tick = 34780, _time = 1.6548e+09, train_seconds = 3.4079e+04)
[2022-06-10 05:36:03,862][root][INFO] - Step 130439680 @ 4092.7 SPS. Inference batcher size: 77. Learner queue size: 32. Other stats: (step = 130439680, mean_episode_return = 29.144, mean_episode_step = 1173.1, total_loss = 147.56, pg_loss = 29.03, baseline_loss = 124.19, entropy_loss = -5.6677, learner_queue_size = 32, _tick = 34788, _time = 1.6548e+09, train_seconds = 3.4084e+04)
[2022-06-10 05:36:08,866][root][INFO] - Step 130457600 @ 3581.2 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 130457600, mean_episode_return = 110.81, mean_episode_step = 828.76, total_loss = 21.841, pg_loss = -37.792, baseline_loss = 65.29, entropy_loss = -5.6578, learner_queue_size = 32, _tick = 34795, _time = 1.6548e+09, train_seconds = 3.4089e+04)
[2022-06-10 05:36:13,870][root][INFO] - Step 130478080 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 130478080, mean_episode_return = 51.093, mean_episode_step = 937.94, total_loss = 475.04, pg_loss = 316.59, baseline_loss = 164.17, entropy_loss = -5.7249, learner_queue_size = 32, _tick = 34803, _time = 1.6548e+09, train_seconds = 3.4094e+04)
[2022-06-10 05:36:18,876][root][INFO] - Step 130496000 @ 3579.5 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 130496000, mean_episode_return = None, mean_episode_step = 946.56, total_loss = 540.15, pg_loss = 411.93, baseline_loss = 134.03, entropy_loss = -5.8149, learner_queue_size = 32, _tick = 34808, _time = 1.6548e+09, train_seconds = 3.4099e+04)
[2022-06-10 05:36:23,882][root][INFO] - Step 130516480 @ 4091.0 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 130516480, mean_episode_return = None, mean_episode_step = 870.69, total_loss = 369.52, pg_loss = 257.64, baseline_loss = 117.78, entropy_loss = -5.907, learner_queue_size = 32, _tick = 34814, _time = 1.6548e+09, train_seconds = 3.4104e+04)
[2022-06-10 05:36:28,886][root][INFO] - Step 130536960 @ 4093.1 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 130536960, mean_episode_return = 33.09, mean_episode_step = 757.52, total_loss = 111.19, pg_loss = 54.964, baseline_loss = 62.047, entropy_loss = -5.8217, learner_queue_size = 32, _tick = 34821, _time = 1.6548e+09, train_seconds = 3.4109e+04)
[2022-06-10 05:36:33,890][root][INFO] - Step 130557440 @ 4092.6 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 130557440, mean_episode_return = 80.639, mean_episode_step = 735.77, total_loss = 417.0, pg_loss = 337.62, baseline_loss = 84.978, entropy_loss = -5.6031, learner_queue_size = 32, _tick = 34829, _time = 1.6548e+09, train_seconds = 3.4114e+04)
[2022-06-10 05:36:38,894][root][INFO] - Step 130575360 @ 3581.2 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 130575360, mean_episode_return = 48.23, mean_episode_step = 686.97, total_loss = 131.31, pg_loss = 55.05, baseline_loss = 82.021, entropy_loss = -5.7601, learner_queue_size = 32, _tick = 34835, _time = 1.6548e+09, train_seconds = 3.4119e+04)
[2022-06-10 05:36:43,900][root][INFO] - Step 130595840 @ 4091.0 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 130595840, mean_episode_return = 38.97, mean_episode_step = 668.56, total_loss = -68.549, pg_loss = -111.08, baseline_loss = 48.504, entropy_loss = -5.9721, learner_queue_size = 32, _tick = 34842, _time = 1.6548e+09, train_seconds = 3.4124e+04)
[2022-06-10 05:36:48,906][root][INFO] - Step 130616320 @ 4091.1 SPS. Inference batcher size: 84. Learner queue size: 32. Other stats: (step = 130616320, mean_episode_return = 106.99, mean_episode_step = 876.42, total_loss = 3.6796, pg_loss = -36.406, baseline_loss = 46.17, entropy_loss = -6.0843, learner_queue_size = 32, _tick = 34849, _time = 1.6548e+09, train_seconds = 3.4129e+04)
[2022-06-10 05:36:53,912][root][INFO] - Step 130634240 @ 3579.7 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 130634240, mean_episode_return = 100.24, mean_episode_step = 855.79, total_loss = 180.91, pg_loss = 134.41, baseline_loss = 52.522, entropy_loss = -6.0292, learner_queue_size = 32, _tick = 34855, _time = 1.6548e+09, train_seconds = 3.4134e+04)
[2022-06-10 05:36:58,915][root][INFO] - Step 130654720 @ 4093.3 SPS. Inference batcher size: 85. Learner queue size: 32. Other stats: (step = 130654720, mean_episode_return = 26.61, mean_episode_step = 859.76, total_loss = -23.224, pg_loss = -59.934, baseline_loss = 42.727, entropy_loss = -6.0174, learner_queue_size = 32, _tick = 34862, _time = 1.6548e+09, train_seconds = 3.4139e+04)
[2022-06-10 05:37:03,918][root][INFO] - Step 130675200 @ 4093.8 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 130675200, mean_episode_return = 36.715, mean_episode_step = 791.34, total_loss = 53.215, pg_loss = 18.574, baseline_loss = 40.647, entropy_loss = -6.0068, learner_queue_size = 32, _tick = 34867, _time = 1.6548e+09, train_seconds = 3.4144e+04)
[2022-06-10 05:37:08,922][root][INFO] - Step 130693120 @ 3581.1 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 130693120, mean_episode_return = 138.54, mean_episode_step = 835.58, total_loss = -174.13, pg_loss = -183.82, baseline_loss = 15.482, entropy_loss = -5.7853, learner_queue_size = 32, _tick = 34872, _time = 1.6548e+09, train_seconds = 3.4149e+04)
[2022-06-10 05:37:13,926][root][INFO] - Step 130713600 @ 4092.8 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 130713600, mean_episode_return = 63.76, mean_episode_step = 814.84, total_loss = 101.17, pg_loss = 53.941, baseline_loss = 52.993, entropy_loss = -5.7662, learner_queue_size = 32, _tick = 34878, _time = 1.6548e+09, train_seconds = 3.4154e+04)
[2022-06-10 05:37:18,930][root][INFO] - Step 130731520 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 130731520, mean_episode_return = 112.74, mean_episode_step = 847.67, total_loss = -69.847, pg_loss = -89.48, baseline_loss = 25.519, entropy_loss = -5.8858, learner_queue_size = 32, _tick = 34883, _time = 1.6548e+09, train_seconds = 3.4159e+04)
[2022-06-10 05:37:23,935][root][INFO] - Step 130752000 @ 4092.2 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 130752000, mean_episode_return = 18.747, mean_episode_step = 795.4, total_loss = -33.528, pg_loss = -71.707, baseline_loss = 44.215, entropy_loss = -6.0357, learner_queue_size = 32, _tick = 34890, _time = 1.6548e+09, train_seconds = 3.4164e+04)
[2022-06-10 05:37:28,938][root][INFO] - Step 130772480 @ 4093.3 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (step = 130772480, mean_episode_return = 79.748, mean_episode_step = 908.27, total_loss = 245.07, pg_loss = 204.2, baseline_loss = 47.009, entropy_loss = -6.1382, learner_queue_size = 32, _tick = 34895, _time = 1.6548e+09, train_seconds = 3.4169e+04)
[2022-06-10 05:37:33,942][root][INFO] - Step 130790400 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 130790400, mean_episode_return = 65.81, mean_episode_step = 1033.2, total_loss = 140.62, pg_loss = 89.458, baseline_loss = 57.309, entropy_loss = -6.1507, learner_queue_size = 32, _tick = 34900, _time = 1.6548e+09, train_seconds = 3.4174e+04)
[2022-06-10 05:37:38,946][root][INFO] - Step 130810880 @ 4092.7 SPS. Inference batcher size: 75. Learner queue size: 32. Other stats: (step = 130810880, mean_episode_return = 8.7598, mean_episode_step = 903.89, total_loss = 65.592, pg_loss = 45.395, baseline_loss = 25.908, entropy_loss = -5.7114, learner_queue_size = 32, _tick = 34908, _time = 1.6548e+09, train_seconds = 3.4179e+04)
[2022-06-10 05:37:43,950][root][INFO] - Step 130828800 @ 3581.2 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 130828800, mean_episode_return = 32.583, mean_episode_step = 894.37, total_loss = -48.343, pg_loss = -84.5, baseline_loss = 41.834, entropy_loss = -5.6766, learner_queue_size = 32, _tick = 34914, _time = 1.6548e+09, train_seconds = 3.4184e+04)
[2022-06-10 05:37:48,954][root][INFO] - Step 130849280 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 130849280, mean_episode_return = 38.181, mean_episode_step = 809.42, total_loss = 19.938, pg_loss = -10.776, baseline_loss = 36.368, entropy_loss = -5.6542, learner_queue_size = 32, _tick = 34920, _time = 1.6548e+09, train_seconds = 3.4189e+04)
[2022-06-10 05:37:53,958][root][INFO] - Step 130869760 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 130869760, mean_episode_return = 37.513, mean_episode_step = 1120.1, total_loss = 218.15, pg_loss = 122.02, baseline_loss = 102.13, entropy_loss = -6.0033, learner_queue_size = 32, _tick = 34927, _time = 1.6548e+09, train_seconds = 3.4194e+04)
[2022-06-10 05:37:58,962][root][INFO] - Step 130887680 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 130887680, mean_episode_return = None, mean_episode_step = 922.59, total_loss = 92.397, pg_loss = 20.464, baseline_loss = 77.653, entropy_loss = -5.721, learner_queue_size = 32, _tick = 34930, _time = 1.6548e+09, train_seconds = 3.4199e+04)
[2022-06-10 05:38:03,966][root][INFO] - Step 130908160 @ 4092.8 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 130908160, mean_episode_return = 36.99, mean_episode_step = 804.13, total_loss = 48.283, pg_loss = -9.7795, baseline_loss = 63.832, entropy_loss = -5.7689, learner_queue_size = 32, _tick = 34936, _time = 1.6548e+09, train_seconds = 3.4204e+04)
[2022-06-10 05:38:08,970][root][INFO] - Step 130928640 @ 4092.7 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 130928640, mean_episode_return = 21.15, mean_episode_step = 916.0, total_loss = -67.098, pg_loss = -92.77, baseline_loss = 31.354, entropy_loss = -5.6816, learner_queue_size = 32, _tick = 34942, _time = 1.6548e+09, train_seconds = 3.4209e+04)
[2022-06-10 05:38:13,974][root][INFO] - Step 130946560 @ 3581.1 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (step = 130946560, mean_episode_return = 46.903, mean_episode_step = 1054.6, total_loss = 21.062, pg_loss = -42.461, baseline_loss = 69.52, entropy_loss = -5.9973, learner_queue_size = 32, _tick = 34948, _time = 1.6548e+09, train_seconds = 3.4214e+04)
[2022-06-10 05:38:18,978][root][INFO] - Step 130967040 @ 4092.6 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 130967040, mean_episode_return = 10.61, mean_episode_step = 841.94, total_loss = 230.63, pg_loss = 179.58, baseline_loss = 56.997, entropy_loss = -5.9468, learner_queue_size = 32, _tick = 34954, _time = 1.6548e+09, train_seconds = 3.4219e+04)
[2022-06-10 05:38:23,982][root][INFO] - Step 130984960 @ 3581.3 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 130984960, mean_episode_return = None, mean_episode_step = 1114.2, total_loss = 175.49, pg_loss = 76.075, baseline_loss = 105.35, entropy_loss = -5.9387, learner_queue_size = 32, _tick = 34958, _time = 1.6548e+09, train_seconds = 3.4224e+04)
[2022-06-10 05:38:28,986][root][INFO] - Step 131002880 @ 3581.2 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 131002880, mean_episode_return = None, mean_episode_step = 957.41, total_loss = -50.923, pg_loss = -68.147, baseline_loss = 22.827, entropy_loss = -5.6031, learner_queue_size = 32, _tick = 34964, _time = 1.6548e+09, train_seconds = 3.4229e+04)
[2022-06-10 05:38:33,990][root][INFO] - Step 131023360 @ 4092.7 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 131023360, mean_episode_return = 20.405, mean_episode_step = 933.68, total_loss = 370.74, pg_loss = 301.64, baseline_loss = 74.822, entropy_loss = -5.7176, learner_queue_size = 32, _tick = 34970, _time = 1.6548e+09, train_seconds = 3.4234e+04)
[2022-06-10 05:38:38,994][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 05:38:39,155][root][INFO] - Step 131043840 @ 4092.7 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 131043840, mean_episode_return = 14.907, mean_episode_step = 826.5, total_loss = -72.937, pg_loss = -117.27, baseline_loss = 49.209, entropy_loss = -4.8762, learner_queue_size = 32, _tick = 34977, _time = 1.6548e+09, train_seconds = 3.4239e+04)
[2022-06-10 05:38:44,158][root][INFO] - Step 131064320 @ 3966.0 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 131064320, mean_episode_return = None, mean_episode_step = 1030.6, total_loss = 131.52, pg_loss = 64.627, baseline_loss = 72.609, entropy_loss = -5.7161, learner_queue_size = 32, _tick = 34983, _time = 1.6548e+09, train_seconds = 3.4244e+04)
[2022-06-10 05:38:49,162][root][INFO] - Step 131082240 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 131082240, mean_episode_return = 9.4465, mean_episode_step = 762.58, total_loss = 42.224, pg_loss = 12.556, baseline_loss = 35.574, entropy_loss = -5.906, learner_queue_size = 32, _tick = 34989, _time = 1.6548e+09, train_seconds = 3.4249e+04)
[2022-06-10 05:38:54,166][root][INFO] - Step 131102720 @ 4092.7 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 131102720, mean_episode_return = 48.32, mean_episode_step = 1063.5, total_loss = -11.532, pg_loss = -71.748, baseline_loss = 65.921, entropy_loss = -5.7043, learner_queue_size = 32, _tick = 34997, _time = 1.6548e+09, train_seconds = 3.4254e+04)
[2022-06-10 05:38:59,172][root][INFO] - Step 131120640 @ 3579.7 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 131120640, mean_episode_return = 72.675, mean_episode_step = 1134.9, total_loss = -12.832, pg_loss = -27.406, baseline_loss = 20.094, entropy_loss = -5.5201, learner_queue_size = 32, _tick = 35003, _time = 1.6548e+09, train_seconds = 3.4259e+04)
[2022-06-10 05:39:04,174][root][INFO] - Step 131141120 @ 4094.3 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 131141120, mean_episode_return = 67.223, mean_episode_step = 861.95, total_loss = -146.45, pg_loss = -213.52, baseline_loss = 72.458, entropy_loss = -5.3902, learner_queue_size = 32, _tick = 35010, _time = 1.6548e+09, train_seconds = 3.4264e+04)
[2022-06-10 05:39:09,178][root][INFO] - Step 131159040 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 131159040, mean_episode_return = 37.718, mean_episode_step = 1054.5, total_loss = -111.17, pg_loss = -143.47, baseline_loss = 37.912, entropy_loss = -5.6149, learner_queue_size = 32, _tick = 35016, _time = 1.6548e+09, train_seconds = 3.4269e+04)
[2022-06-10 05:39:14,182][root][INFO] - Step 131179520 @ 4092.8 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 131179520, mean_episode_return = 86.151, mean_episode_step = 1062.3, total_loss = -311.27, pg_loss = -326.18, baseline_loss = 20.66, entropy_loss = -5.7447, learner_queue_size = 32, _tick = 35022, _time = 1.6548e+09, train_seconds = 3.4274e+04)
[2022-06-10 05:39:19,186][root][INFO] - Step 131197440 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 131197440, mean_episode_return = 33.636, mean_episode_step = 1075.4, total_loss = 255.67, pg_loss = 183.9, baseline_loss = 77.386, entropy_loss = -5.6177, learner_queue_size = 32, _tick = 35026, _time = 1.6548e+09, train_seconds = 3.4279e+04)
[2022-06-10 05:39:24,194][root][INFO] - Step 131217920 @ 4089.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 131217920, mean_episode_return = 71.175, mean_episode_step = 924.41, total_loss = 280.38, pg_loss = 150.42, baseline_loss = 135.58, entropy_loss = -5.6231, learner_queue_size = 32, _tick = 35032, _time = 1.6548e+09, train_seconds = 3.4284e+04)
[2022-06-10 05:39:29,198][root][INFO] - Step 131235840 @ 3581.4 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 131235840, mean_episode_return = 95.94, mean_episode_step = 982.1, total_loss = 471.17, pg_loss = 312.91, baseline_loss = 164.08, entropy_loss = -5.8271, learner_queue_size = 32, _tick = 35038, _time = 1.6548e+09, train_seconds = 3.4289e+04)
[2022-06-10 05:39:34,202][root][INFO] - Step 131256320 @ 4092.8 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 131256320, mean_episode_return = 26.01, mean_episode_step = 1046.0, total_loss = -60.605, pg_loss = -83.838, baseline_loss = 28.981, entropy_loss = -5.7486, learner_queue_size = 32, _tick = 35045, _time = 1.6548e+09, train_seconds = 3.4294e+04)
[2022-06-10 05:39:39,207][root][INFO] - Step 131276800 @ 4092.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 131276800, mean_episode_return = 45.978, mean_episode_step = 715.44, total_loss = 223.19, pg_loss = 145.91, baseline_loss = 83.002, entropy_loss = -5.7293, learner_queue_size = 32, _tick = 35051, _time = 1.6548e+09, train_seconds = 3.4299e+04)
[2022-06-10 05:39:44,210][root][INFO] - Step 131297280 @ 4093.3 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (step = 131297280, mean_episode_return = 102.58, mean_episode_step = 889.38, total_loss = 120.11, pg_loss = 55.968, baseline_loss = 69.834, entropy_loss = -5.6912, learner_queue_size = 32, _tick = 35058, _time = 1.6548e+09, train_seconds = 3.4304e+04)
[2022-06-10 05:39:49,214][root][INFO] - Step 131315200 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 131315200, mean_episode_return = 56.552, mean_episode_step = 834.57, total_loss = -76.248, pg_loss = -105.84, baseline_loss = 35.423, entropy_loss = -5.8273, learner_queue_size = 32, _tick = 35063, _time = 1.6548e+09, train_seconds = 3.4309e+04)
[2022-06-10 05:39:54,218][root][INFO] - Step 131335680 @ 4092.8 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 131335680, mean_episode_return = 93.469, mean_episode_step = 896.49, total_loss = -89.203, pg_loss = -122.84, baseline_loss = 39.465, entropy_loss = -5.832, learner_queue_size = 32, _tick = 35071, _time = 1.6548e+09, train_seconds = 3.4314e+04)
[2022-06-10 05:39:59,222][root][INFO] - Step 131356160 @ 4092.7 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 131356160, mean_episode_return = -1.9, mean_episode_step = 795.38, total_loss = 314.86, pg_loss = 235.12, baseline_loss = 85.517, entropy_loss = -5.7811, learner_queue_size = 32, _tick = 35079, _time = 1.6548e+09, train_seconds = 3.4319e+04)
[2022-06-10 05:40:04,226][root][INFO] - Step 131374080 @ 3581.2 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 131374080, mean_episode_return = None, mean_episode_step = 975.16, total_loss = 57.483, pg_loss = 34.128, baseline_loss = 29.17, entropy_loss = -5.8153, learner_queue_size = 32, _tick = 35084, _time = 1.6548e+09, train_seconds = 3.4324e+04)
[2022-06-10 05:40:09,230][root][INFO] - Step 131394560 @ 4092.7 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (step = 131394560, mean_episode_return = None, mean_episode_step = 895.09, total_loss = 592.35, pg_loss = 497.44, baseline_loss = 100.62, entropy_loss = -5.7175, learner_queue_size = 32, _tick = 35089, _time = 1.6548e+09, train_seconds = 3.4329e+04)
[2022-06-10 05:40:14,234][root][INFO] - Step 131415040 @ 4092.4 SPS. Inference batcher size: 77. Learner queue size: 32. Other stats: (step = 131415040, mean_episode_return = 24.957, mean_episode_step = 879.82, total_loss = -72.32, pg_loss = -101.62, baseline_loss = 35.009, entropy_loss = -5.7088, learner_queue_size = 32, _tick = 35093, _time = 1.6548e+09, train_seconds = 3.4334e+04)
[2022-06-10 05:40:19,238][root][INFO] - Step 131432960 @ 3581.3 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 131432960, mean_episode_return = 88.841, mean_episode_step = 766.44, total_loss = 291.05, pg_loss = 142.15, baseline_loss = 154.62, entropy_loss = -5.7277, learner_queue_size = 32, _tick = 35100, _time = 1.6548e+09, train_seconds = 3.4339e+04)
[2022-06-10 05:40:24,242][root][INFO] - Step 131453440 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 131453440, mean_episode_return = 29.941, mean_episode_step = 1071.8, total_loss = -138.88, pg_loss = -162.36, baseline_loss = 29.353, entropy_loss = -5.8647, learner_queue_size = 32, _tick = 35106, _time = 1.6548e+09, train_seconds = 3.4344e+04)
[2022-06-10 05:40:29,246][root][INFO] - Step 131473920 @ 4092.7 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (step = 131473920, mean_episode_return = 122.94, mean_episode_step = 933.77, total_loss = 46.348, pg_loss = -8.3691, baseline_loss = 60.718, entropy_loss = -6.0005, learner_queue_size = 32, _tick = 35114, _time = 1.6548e+09, train_seconds = 3.4349e+04)
[2022-06-10 05:40:34,252][root][INFO] - Step 131491840 @ 3579.4 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 131491840, mean_episode_return = 57.15, mean_episode_step = 925.76, total_loss = 42.48, pg_loss = 14.226, baseline_loss = 34.244, entropy_loss = -5.9901, learner_queue_size = 32, _tick = 35120, _time = 1.6548e+09, train_seconds = 3.4354e+04)
[2022-06-10 05:40:39,258][root][INFO] - Step 131512320 @ 4091.5 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 131512320, mean_episode_return = 51.487, mean_episode_step = 726.93, total_loss = 44.532, pg_loss = 23.394, baseline_loss = 27.123, entropy_loss = -5.9851, learner_queue_size = 32, _tick = 35127, _time = 1.6548e+09, train_seconds = 3.4359e+04)
[2022-06-10 05:40:44,262][root][INFO] - Step 131530240 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 131530240, mean_episode_return = 83.959, mean_episode_step = 945.96, total_loss = 35.469, pg_loss = 10.494, baseline_loss = 30.955, entropy_loss = -5.9796, learner_queue_size = 32, _tick = 35132, _time = 1.6548e+09, train_seconds = 3.4364e+04)
[2022-06-10 05:40:49,266][root][INFO] - Step 131550720 @ 4092.7 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 131550720, mean_episode_return = 81.575, mean_episode_step = 1186.9, total_loss = -132.6, pg_loss = -146.48, baseline_loss = 19.7, entropy_loss = -5.8194, learner_queue_size = 32, _tick = 35138, _time = 1.6548e+09, train_seconds = 3.4369e+04)
[2022-06-10 05:40:54,270][root][INFO] - Step 131568640 @ 3581.2 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 131568640, mean_episode_return = 82.702, mean_episode_step = 1034.9, total_loss = 277.76, pg_loss = 179.56, baseline_loss = 104.1, entropy_loss = -5.8926, learner_queue_size = 32, _tick = 35144, _time = 1.6548e+09, train_seconds = 3.4374e+04)
[2022-06-10 05:40:59,274][root][INFO] - Step 131589120 @ 4092.7 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 131589120, mean_episode_return = 10.08, mean_episode_step = 910.04, total_loss = 224.87, pg_loss = 116.65, baseline_loss = 114.1, entropy_loss = -5.8835, learner_queue_size = 32, _tick = 35150, _time = 1.6548e+09, train_seconds = 3.4379e+04)
[2022-06-10 05:41:04,278][root][INFO] - Step 131609600 @ 4092.7 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 131609600, mean_episode_return = 32.57, mean_episode_step = 815.53, total_loss = -160.96, pg_loss = -181.78, baseline_loss = 26.635, entropy_loss = -5.8115, learner_queue_size = 32, _tick = 35155, _time = 1.6548e+09, train_seconds = 3.4384e+04)
[2022-06-10 05:41:09,282][root][INFO] - Step 131627520 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 131627520, mean_episode_return = 70.359, mean_episode_step = 873.21, total_loss = 179.9, pg_loss = 111.35, baseline_loss = 74.434, entropy_loss = -5.8788, learner_queue_size = 32, _tick = 35162, _time = 1.6548e+09, train_seconds = 3.4389e+04)
[2022-06-10 05:41:14,286][root][INFO] - Step 131648000 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 131648000, mean_episode_return = None, mean_episode_step = 914.22, total_loss = -137.86, pg_loss = -140.27, baseline_loss = 8.4164, entropy_loss = -6.0044, learner_queue_size = 32, _tick = 35168, _time = 1.6548e+09, train_seconds = 3.4394e+04)
[2022-06-10 05:41:19,290][root][INFO] - Step 131668480 @ 4092.8 SPS. Inference batcher size: 91. Learner queue size: 32. Other stats: (step = 131668480, mean_episode_return = 13.2, mean_episode_step = 1047.9, total_loss = -182.2, pg_loss = -191.05, baseline_loss = 14.878, entropy_loss = -6.0282, learner_queue_size = 32, _tick = 35175, _time = 1.6548e+09, train_seconds = 3.4399e+04)
[2022-06-10 05:41:24,294][root][INFO] - Step 131686400 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 131686400, mean_episode_return = 163.4, mean_episode_step = 918.61, total_loss = -107.27, pg_loss = -119.61, baseline_loss = 18.359, entropy_loss = -6.0146, learner_queue_size = 32, _tick = 35181, _time = 1.6548e+09, train_seconds = 3.4404e+04)
[2022-06-10 05:41:29,298][root][INFO] - Step 131706880 @ 4092.7 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 131706880, mean_episode_return = 48.416, mean_episode_step = 973.54, total_loss = -55.859, pg_loss = -82.814, baseline_loss = 32.862, entropy_loss = -5.9069, learner_queue_size = 32, _tick = 35188, _time = 1.6548e+09, train_seconds = 3.4409e+04)
[2022-06-10 05:41:34,302][root][INFO] - Step 131727360 @ 4092.8 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 131727360, mean_episode_return = None, mean_episode_step = 885.5, total_loss = 232.64, pg_loss = 168.74, baseline_loss = 69.919, entropy_loss = -6.0167, learner_queue_size = 32, _tick = 35194, _time = 1.6548e+09, train_seconds = 3.4414e+04)
[2022-06-10 05:41:39,306][root][INFO] - Step 131745280 @ 3581.1 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 131745280, mean_episode_return = None, mean_episode_step = 1002.1, total_loss = 241.37, pg_loss = 171.88, baseline_loss = 75.297, entropy_loss = -5.8089, learner_queue_size = 32, _tick = 35198, _time = 1.6548e+09, train_seconds = 3.4419e+04)
[2022-06-10 05:41:44,310][root][INFO] - Step 131765760 @ 4092.6 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 131765760, mean_episode_return = None, mean_episode_step = 1003.9, total_loss = 64.925, pg_loss = 4.8104, baseline_loss = 66.217, entropy_loss = -6.1021, learner_queue_size = 32, _tick = 35203, _time = 1.6548e+09, train_seconds = 3.4424e+04)
[2022-06-10 05:41:49,314][root][INFO] - Step 131783680 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 131783680, mean_episode_return = 21.49, mean_episode_step = 844.76, total_loss = -119.17, pg_loss = -130.95, baseline_loss = 17.746, entropy_loss = -5.9724, learner_queue_size = 32, _tick = 35210, _time = 1.6548e+09, train_seconds = 3.4429e+04)
[2022-06-10 05:41:54,318][root][INFO] - Step 131804160 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 131804160, mean_episode_return = None, mean_episode_step = 1035.5, total_loss = 371.92, pg_loss = 281.51, baseline_loss = 96.419, entropy_loss = -6.0084, learner_queue_size = 32, _tick = 35213, _time = 1.6548e+09, train_seconds = 3.4434e+04)
[2022-06-10 05:41:59,322][root][INFO] - Step 131822080 @ 3581.2 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 131822080, mean_episode_return = 61.05, mean_episode_step = 922.9, total_loss = -90.484, pg_loss = -134.21, baseline_loss = 49.585, entropy_loss = -5.8607, learner_queue_size = 32, _tick = 35220, _time = 1.6548e+09, train_seconds = 3.4439e+04)
[2022-06-10 05:42:04,334][root][INFO] - Step 131842560 @ 4086.2 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 131842560, mean_episode_return = 36.27, mean_episode_step = 1078.8, total_loss = 381.68, pg_loss = 304.61, baseline_loss = 82.98, entropy_loss = -5.908, learner_queue_size = 32, _tick = 35225, _time = 1.6548e+09, train_seconds = 3.4444e+04)
[2022-06-10 05:42:09,338][root][INFO] - Step 131860480 @ 3581.0 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 131860480, mean_episode_return = 68.018, mean_episode_step = 796.64, total_loss = 8.5636, pg_loss = -22.386, baseline_loss = 36.776, entropy_loss = -5.8259, learner_queue_size = 32, _tick = 35232, _time = 1.6548e+09, train_seconds = 3.4449e+04)
[2022-06-10 05:42:14,342][root][INFO] - Step 131880960 @ 4092.8 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 131880960, mean_episode_return = 188.49, mean_episode_step = 1283.4, total_loss = 22.725, pg_loss = -16.964, baseline_loss = 45.513, entropy_loss = -5.8236, learner_queue_size = 32, _tick = 35239, _time = 1.6548e+09, train_seconds = 3.4454e+04)
[2022-06-10 05:42:19,346][root][INFO] - Step 131901440 @ 4092.7 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 131901440, mean_episode_return = 38.025, mean_episode_step = 1058.2, total_loss = 318.25, pg_loss = 240.37, baseline_loss = 83.958, entropy_loss = -6.0817, learner_queue_size = 32, _tick = 35244, _time = 1.6548e+09, train_seconds = 3.4459e+04)
[2022-06-10 05:42:24,350][root][INFO] - Step 131919360 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 131919360, mean_episode_return = 30.3, mean_episode_step = 977.01, total_loss = -18.863, pg_loss = -48.641, baseline_loss = 35.659, entropy_loss = -5.8811, learner_queue_size = 32, _tick = 35249, _time = 1.6548e+09, train_seconds = 3.4464e+04)
[2022-06-10 05:42:29,354][root][INFO] - Step 131939840 @ 4092.6 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 131939840, mean_episode_return = 77.569, mean_episode_step = 1265.6, total_loss = 275.08, pg_loss = 212.75, baseline_loss = 68.343, entropy_loss = -6.0055, learner_queue_size = 32, _tick = 35255, _time = 1.6548e+09, train_seconds = 3.4469e+04)
[2022-06-10 05:42:34,358][root][INFO] - Step 131957760 @ 3581.3 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 131957760, mean_episode_return = None, mean_episode_step = 968.44, total_loss = 179.76, pg_loss = 131.64, baseline_loss = 53.992, entropy_loss = -5.8657, learner_queue_size = 32, _tick = 35259, _time = 1.6548e+09, train_seconds = 3.4474e+04)
[2022-06-10 05:42:39,362][root][INFO] - Step 131978240 @ 4092.7 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 131978240, mean_episode_return = 26.76, mean_episode_step = 1073.0, total_loss = -88.169, pg_loss = -128.77, baseline_loss = 46.527, entropy_loss = -5.9254, learner_queue_size = 32, _tick = 35265, _time = 1.6548e+09, train_seconds = 3.4479e+04)
[2022-06-10 05:42:44,366][root][INFO] - Step 131998720 @ 4092.7 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 131998720, mean_episode_return = None, mean_episode_step = 1155.8, total_loss = -102.79, pg_loss = -121.19, baseline_loss = 24.622, entropy_loss = -6.2294, learner_queue_size = 32, _tick = 35270, _time = 1.6548e+09, train_seconds = 3.4484e+04)
[2022-06-10 05:42:49,373][root][INFO] - Step 132019200 @ 4090.6 SPS. Inference batcher size: 87. Learner queue size: 32. Other stats: (step = 132019200, mean_episode_return = 57.269, mean_episode_step = 1077.1, total_loss = 46.08, pg_loss = 35.472, baseline_loss = 16.653, entropy_loss = -6.0443, learner_queue_size = 32, _tick = 35277, _time = 1.6548e+09, train_seconds = 3.4489e+04)
[2022-06-10 05:42:54,379][root][INFO] - Step 132037120 @ 3579.5 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 132037120, mean_episode_return = 80.309, mean_episode_step = 816.69, total_loss = 139.17, pg_loss = 85.722, baseline_loss = 59.322, entropy_loss = -5.8721, learner_queue_size = 32, _tick = 35283, _time = 1.6548e+09, train_seconds = 3.4494e+04)
[2022-06-10 05:42:59,382][root][INFO] - Step 132057600 @ 4093.6 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 132057600, mean_episode_return = None, mean_episode_step = 1169.8, total_loss = 256.83, pg_loss = 194.74, baseline_loss = 68.087, entropy_loss = -5.9962, learner_queue_size = 32, _tick = 35287, _time = 1.6548e+09, train_seconds = 3.4499e+04)
[2022-06-10 05:43:04,386][root][INFO] - Step 132075520 @ 3581.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 132075520, mean_episode_return = 147.74, mean_episode_step = 970.95, total_loss = 11.355, pg_loss = -39.172, baseline_loss = 56.374, entropy_loss = -5.8471, learner_queue_size = 32, _tick = 35293, _time = 1.6548e+09, train_seconds = 3.4504e+04)
[2022-06-10 05:43:09,390][root][INFO] - Step 132096000 @ 4092.8 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 132096000, mean_episode_return = 32.675, mean_episode_step = 1182.2, total_loss = -115.69, pg_loss = -158.34, baseline_loss = 48.543, entropy_loss = -5.8991, learner_queue_size = 32, _tick = 35299, _time = 1.6548e+09, train_seconds = 3.4509e+04)
[2022-06-10 05:43:14,394][root][INFO] - Step 132116480 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 132116480, mean_episode_return = None, mean_episode_step = 926.28, total_loss = -78.106, pg_loss = -98.49, baseline_loss = 26.251, entropy_loss = -5.8675, learner_queue_size = 32, _tick = 35306, _time = 1.6548e+09, train_seconds = 3.4514e+04)
[2022-06-10 05:43:19,398][root][INFO] - Step 132134400 @ 3581.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 132134400, mean_episode_return = 148.72, mean_episode_step = 1018.4, total_loss = -70.258, pg_loss = -99.912, baseline_loss = 35.511, entropy_loss = -5.8569, learner_queue_size = 32, _tick = 35311, _time = 1.6548e+09, train_seconds = 3.4519e+04)
[2022-06-10 05:43:24,402][root][INFO] - Step 132154880 @ 4092.6 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 132154880, mean_episode_return = 42.748, mean_episode_step = 1034.5, total_loss = -169.19, pg_loss = -181.0, baseline_loss = 17.799, entropy_loss = -5.9979, learner_queue_size = 32, _tick = 35319, _time = 1.6548e+09, train_seconds = 3.4524e+04)
[2022-06-10 05:43:29,406][root][INFO] - Step 132175360 @ 4092.8 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 132175360, mean_episode_return = 62.29, mean_episode_step = 974.0, total_loss = 109.08, pg_loss = 70.52, baseline_loss = 44.529, entropy_loss = -5.9672, learner_queue_size = 32, _tick = 35325, _time = 1.6548e+09, train_seconds = 3.4529e+04)
[2022-06-10 05:43:34,410][root][INFO] - Step 132193280 @ 3581.1 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 132193280, mean_episode_return = 10.225, mean_episode_step = 1230.6, total_loss = 358.13, pg_loss = 286.86, baseline_loss = 77.203, entropy_loss = -5.9334, learner_queue_size = 32, _tick = 35330, _time = 1.6548e+09, train_seconds = 3.4534e+04)
[2022-06-10 05:43:39,414][root][INFO] - Step 132213760 @ 4092.7 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 132213760, mean_episode_return = None, mean_episode_step = 1267.9, total_loss = 138.89, pg_loss = 107.37, baseline_loss = 37.322, entropy_loss = -5.805, learner_queue_size = 32, _tick = 35336, _time = 1.6548e+09, train_seconds = 3.4539e+04)
[2022-06-10 05:43:44,418][root][INFO] - Step 132231680 @ 3581.1 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 132231680, mean_episode_return = None, mean_episode_step = 1102.8, total_loss = -112.49, pg_loss = -123.77, baseline_loss = 17.007, entropy_loss = -5.7318, learner_queue_size = 32, _tick = 35339, _time = 1.6548e+09, train_seconds = 3.4544e+04)
[2022-06-10 05:43:49,422][root][INFO] - Step 132252160 @ 4092.6 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 132252160, mean_episode_return = 61.48, mean_episode_step = 1317.0, total_loss = 312.88, pg_loss = 244.17, baseline_loss = 74.56, entropy_loss = -5.8476, learner_queue_size = 32, _tick = 35345, _time = 1.6548e+09, train_seconds = 3.4549e+04)
[2022-06-10 05:43:54,426][root][INFO] - Step 132272640 @ 4092.8 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 132272640, mean_episode_return = 46.961, mean_episode_step = 1094.4, total_loss = 1.9342, pg_loss = -35.406, baseline_loss = 43.162, entropy_loss = -5.8212, learner_queue_size = 32, _tick = 35351, _time = 1.6548e+09, train_seconds = 3.4554e+04)
[2022-06-10 05:43:59,430][root][INFO] - Step 132290560 @ 3581.1 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 132290560, mean_episode_return = None, mean_episode_step = 1002.2, total_loss = -46.503, pg_loss = -104.47, baseline_loss = 63.785, entropy_loss = -5.818, learner_queue_size = 32, _tick = 35355, _time = 1.6548e+09, train_seconds = 3.4559e+04)
[2022-06-10 05:44:04,434][root][INFO] - Step 132308480 @ 3581.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 132308480, mean_episode_return = 31.385, mean_episode_step = 1275.1, total_loss = 75.852, pg_loss = 10.888, baseline_loss = 70.848, entropy_loss = -5.8842, learner_queue_size = 32, _tick = 35360, _time = 1.6548e+09, train_seconds = 3.4564e+04)
[2022-06-10 05:44:09,439][root][INFO] - Step 132328960 @ 4092.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 132328960, mean_episode_return = 85.84, mean_episode_step = 945.95, total_loss = 219.97, pg_loss = 174.14, baseline_loss = 51.685, entropy_loss = -5.8485, learner_queue_size = 32, _tick = 35367, _time = 1.6548e+09, train_seconds = 3.4569e+04)
[2022-06-10 05:44:14,442][root][INFO] - Step 132349440 @ 4093.3 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 132349440, mean_episode_return = 32.755, mean_episode_step = 1030.6, total_loss = 135.64, pg_loss = 80.036, baseline_loss = 61.156, entropy_loss = -5.5496, learner_queue_size = 32, _tick = 35374, _time = 1.6548e+09, train_seconds = 3.4574e+04)
[2022-06-10 05:44:19,446][root][INFO] - Step 132367360 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 132367360, mean_episode_return = 31.03, mean_episode_step = 1371.0, total_loss = 318.68, pg_loss = 208.56, baseline_loss = 115.93, entropy_loss = -5.809, learner_queue_size = 32, _tick = 35380, _time = 1.6548e+09, train_seconds = 3.4579e+04)
[2022-06-10 05:44:24,450][root][INFO] - Step 132387840 @ 4092.8 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 132387840, mean_episode_return = 59.85, mean_episode_step = 1313.9, total_loss = 201.15, pg_loss = 130.82, baseline_loss = 75.929, entropy_loss = -5.5963, learner_queue_size = 32, _tick = 35386, _time = 1.6548e+09, train_seconds = 3.4584e+04)
[2022-06-10 05:44:29,454][root][INFO] - Step 132408320 @ 4092.6 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 132408320, mean_episode_return = 5.5949, mean_episode_step = 1233.6, total_loss = -124.49, pg_loss = -159.13, baseline_loss = 40.38, entropy_loss = -5.7433, learner_queue_size = 32, _tick = 35392, _time = 1.6548e+09, train_seconds = 3.4589e+04)
[2022-06-10 05:44:34,461][root][INFO] - Step 132426240 @ 3579.2 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 132426240, mean_episode_return = 56.984, mean_episode_step = 1291.0, total_loss = 78.826, pg_loss = 44.181, baseline_loss = 40.559, entropy_loss = -5.9132, learner_queue_size = 32, _tick = 35397, _time = 1.6548e+09, train_seconds = 3.4594e+04)
[2022-06-10 05:44:39,466][root][INFO] - Step 132446720 @ 4091.8 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 132446720, mean_episode_return = None, mean_episode_step = 1164.0, total_loss = 102.75, pg_loss = 60.88, baseline_loss = 47.524, entropy_loss = -5.6544, learner_queue_size = 32, _tick = 35403, _time = 1.6548e+09, train_seconds = 3.4599e+04)
[2022-06-10 05:44:44,470][root][INFO] - Step 132467200 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 132467200, mean_episode_return = 20.49, mean_episode_step = 1029.4, total_loss = -0.70247, pg_loss = -49.218, baseline_loss = 54.26, entropy_loss = -5.7443, learner_queue_size = 32, _tick = 35411, _time = 1.6548e+09, train_seconds = 3.4604e+04)
[2022-06-10 05:44:49,474][root][INFO] - Step 132487680 @ 4092.8 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 132487680, mean_episode_return = None, mean_episode_step = 1264.5, total_loss = 4.4001, pg_loss = -36.06, baseline_loss = 46.292, entropy_loss = -5.8322, learner_queue_size = 32, _tick = 35417, _time = 1.6548e+09, train_seconds = 3.4609e+04)
[2022-06-10 05:44:54,478][root][INFO] - Step 132508160 @ 4092.7 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 132508160, mean_episode_return = 75.584, mean_episode_step = 1258.0, total_loss = 483.92, pg_loss = 368.41, baseline_loss = 121.21, entropy_loss = -5.704, learner_queue_size = 32, _tick = 35422, _time = 1.6548e+09, train_seconds = 3.4614e+04)
[2022-06-10 05:44:59,482][root][INFO] - Step 132526080 @ 3581.2 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (step = 132526080, mean_episode_return = 54.17, mean_episode_step = 779.14, total_loss = 112.39, pg_loss = 48.818, baseline_loss = 68.973, entropy_loss = -5.3992, learner_queue_size = 32, _tick = 35428, _time = 1.6548e+09, train_seconds = 3.4619e+04)
[2022-06-10 05:45:04,486][root][INFO] - Step 132546560 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 132546560, mean_episode_return = 30.48, mean_episode_step = 1199.2, total_loss = 55.997, pg_loss = -52.259, baseline_loss = 113.81, entropy_loss = -5.5574, learner_queue_size = 32, _tick = 35435, _time = 1.6548e+09, train_seconds = 3.4624e+04)
[2022-06-10 05:45:09,490][root][INFO] - Step 132564480 @ 3581.2 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 132564480, mean_episode_return = 64.915, mean_episode_step = 906.62, total_loss = -63.147, pg_loss = -93.682, baseline_loss = 36.362, entropy_loss = -5.8264, learner_queue_size = 32, _tick = 35441, _time = 1.6548e+09, train_seconds = 3.4629e+04)
[2022-06-10 05:45:14,494][root][INFO] - Step 132584960 @ 4092.7 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (step = 132584960, mean_episode_return = 87.253, mean_episode_step = 786.35, total_loss = 16.821, pg_loss = -39.522, baseline_loss = 62.224, entropy_loss = -5.8815, learner_queue_size = 32, _tick = 35448, _time = 1.6548e+09, train_seconds = 3.4634e+04)
[2022-06-10 05:45:19,498][root][INFO] - Step 132605440 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 132605440, mean_episode_return = 31.9, mean_episode_step = 1015.0, total_loss = -144.78, pg_loss = -187.4, baseline_loss = 48.393, entropy_loss = -5.7712, learner_queue_size = 32, _tick = 35454, _time = 1.6548e+09, train_seconds = 3.4639e+04)
[2022-06-10 05:45:24,502][root][INFO] - Step 132623360 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 132623360, mean_episode_return = None, mean_episode_step = 1001.5, total_loss = -38.74, pg_loss = -65.84, baseline_loss = 32.859, entropy_loss = -5.7592, learner_queue_size = 32, _tick = 35457, _time = 1.6548e+09, train_seconds = 3.4644e+04)
[2022-06-10 05:45:29,506][root][INFO] - Step 132643840 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 132643840, mean_episode_return = 26.06, mean_episode_step = 1193.6, total_loss = 0.8443, pg_loss = -32.669, baseline_loss = 39.463, entropy_loss = -5.9496, learner_queue_size = 32, _tick = 35465, _time = 1.6548e+09, train_seconds = 3.4649e+04)
[2022-06-10 05:45:34,510][root][INFO] - Step 132664320 @ 4092.7 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 132664320, mean_episode_return = 26.025, mean_episode_step = 836.01, total_loss = 165.85, pg_loss = 107.34, baseline_loss = 64.333, entropy_loss = -5.8242, learner_queue_size = 32, _tick = 35471, _time = 1.6548e+09, train_seconds = 3.4654e+04)
[2022-06-10 05:45:39,514][root][INFO] - Step 132684800 @ 4092.7 SPS. Inference batcher size: 86. Learner queue size: 32. Other stats: (step = 132684800, mean_episode_return = 43.21, mean_episode_step = 1012.0, total_loss = -252.51, pg_loss = -277.13, baseline_loss = 30.342, entropy_loss = -5.7244, learner_queue_size = 32, _tick = 35477, _time = 1.6548e+09, train_seconds = 3.4659e+04)
[2022-06-10 05:45:44,519][root][INFO] - Step 132702720 @ 3580.6 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 132702720, mean_episode_return = 44.165, mean_episode_step = 916.15, total_loss = 101.49, pg_loss = 7.8341, baseline_loss = 99.303, entropy_loss = -5.6438, learner_queue_size = 32, _tick = 35483, _time = 1.6548e+09, train_seconds = 3.4664e+04)
[2022-06-10 05:45:49,523][root][INFO] - Step 132723200 @ 4092.9 SPS. Inference batcher size: 112. Learner queue size: 32. Other stats: (step = 132723200, mean_episode_return = 47.941, mean_episode_step = 1180.6, total_loss = -117.21, pg_loss = -133.89, baseline_loss = 22.326, entropy_loss = -5.6487, learner_queue_size = 32, _tick = 35489, _time = 1.6548e+09, train_seconds = 3.4669e+04)
[2022-06-10 05:45:54,526][root][INFO] - Step 132741120 @ 3581.5 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 132741120, mean_episode_return = 80.78, mean_episode_step = 1012.2, total_loss = 226.45, pg_loss = 146.74, baseline_loss = 85.504, entropy_loss = -5.7895, learner_queue_size = 32, _tick = 35496, _time = 1.6548e+09, train_seconds = 3.4674e+04)
[2022-06-10 05:45:59,530][root][INFO] - Step 132761600 @ 4092.4 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (step = 132761600, mean_episode_return = 90.456, mean_episode_step = 1039.3, total_loss = 96.51, pg_loss = 32.316, baseline_loss = 69.913, entropy_loss = -5.7191, learner_queue_size = 32, _tick = 35504, _time = 1.6548e+09, train_seconds = 3.4679e+04)
[2022-06-10 05:46:04,534][root][INFO] - Step 132779520 @ 3581.4 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 132779520, mean_episode_return = 54.156, mean_episode_step = 1144.7, total_loss = -60.186, pg_loss = -84.822, baseline_loss = 30.032, entropy_loss = -5.3959, learner_queue_size = 32, _tick = 35509, _time = 1.6548e+09, train_seconds = 3.4684e+04)
[2022-06-10 05:46:09,538][root][INFO] - Step 132800000 @ 4092.8 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 132800000, mean_episode_return = 136.14, mean_episode_step = 1090.3, total_loss = 31.998, pg_loss = -9.4606, baseline_loss = 47.379, entropy_loss = -5.9211, learner_queue_size = 32, _tick = 35514, _time = 1.6548e+09, train_seconds = 3.4689e+04)
[2022-06-10 05:46:14,542][root][INFO] - Step 132820480 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 132820480, mean_episode_return = 27.46, mean_episode_step = 952.91, total_loss = 37.034, pg_loss = -13.91, baseline_loss = 56.713, entropy_loss = -5.7686, learner_queue_size = 32, _tick = 35520, _time = 1.6548e+09, train_seconds = 3.4694e+04)
[2022-06-10 05:46:19,546][root][INFO] - Step 132840960 @ 4092.7 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 132840960, mean_episode_return = 116.01, mean_episode_step = 973.51, total_loss = 213.91, pg_loss = 163.08, baseline_loss = 56.692, entropy_loss = -5.8615, learner_queue_size = 32, _tick = 35527, _time = 1.6548e+09, train_seconds = 3.4699e+04)
[2022-06-10 05:46:24,552][root][INFO] - Step 132858880 @ 3579.4 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 132858880, mean_episode_return = 231.71, mean_episode_step = 1282.8, total_loss = 487.57, pg_loss = 388.71, baseline_loss = 104.8, entropy_loss = -5.9372, learner_queue_size = 32, _tick = 35534, _time = 1.6548e+09, train_seconds = 3.4704e+04)
[2022-06-10 05:46:29,558][root][INFO] - Step 132879360 @ 4091.4 SPS. Inference batcher size: 81. Learner queue size: 32. Other stats: (step = 132879360, mean_episode_return = 42.393, mean_episode_step = 957.98, total_loss = 110.56, pg_loss = 77.656, baseline_loss = 38.681, entropy_loss = -5.7785, learner_queue_size = 32, _tick = 35539, _time = 1.6548e+09, train_seconds = 3.4709e+04)
[2022-06-10 05:46:34,562][root][INFO] - Step 132897280 @ 3581.2 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 132897280, mean_episode_return = None, mean_episode_step = 1007.4, total_loss = 19.002, pg_loss = -22.977, baseline_loss = 47.426, entropy_loss = -5.4472, learner_queue_size = 32, _tick = 35542, _time = 1.6548e+09, train_seconds = 3.4714e+04)
[2022-06-10 05:46:39,566][root][INFO] - Step 132917760 @ 4092.7 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 132917760, mean_episode_return = 105.39, mean_episode_step = 1100.4, total_loss = 23.054, pg_loss = -19.119, baseline_loss = 47.774, entropy_loss = -5.6019, learner_queue_size = 32, _tick = 35550, _time = 1.6548e+09, train_seconds = 3.4719e+04)
[2022-06-10 05:46:44,570][root][INFO] - Step 132938240 @ 4092.6 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 132938240, mean_episode_return = 43.2, mean_episode_step = 1037.1, total_loss = -422.57, pg_loss = -476.9, baseline_loss = 60.121, entropy_loss = -5.7865, learner_queue_size = 32, _tick = 35558, _time = 1.6548e+09, train_seconds = 3.4724e+04)
[2022-06-10 05:46:49,574][root][INFO] - Step 132956160 @ 3581.2 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 132956160, mean_episode_return = 54.011, mean_episode_step = 1001.8, total_loss = -111.58, pg_loss = -123.63, baseline_loss = 18.185, entropy_loss = -6.1311, learner_queue_size = 32, _tick = 35565, _time = 1.6548e+09, train_seconds = 3.4729e+04)
[2022-06-10 05:46:54,578][root][INFO] - Step 132976640 @ 4092.8 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 132976640, mean_episode_return = 87.28, mean_episode_step = 895.49, total_loss = -85.253, pg_loss = -93.552, baseline_loss = 14.202, entropy_loss = -5.9034, learner_queue_size = 32, _tick = 35569, _time = 1.6548e+09, train_seconds = 3.4734e+04)
[2022-06-10 05:46:59,582][root][INFO] - Step 132997120 @ 4092.7 SPS. Inference batcher size: 76. Learner queue size: 32. Other stats: (step = 132997120, mean_episode_return = 30.025, mean_episode_step = 784.47, total_loss = 305.79, pg_loss = 230.16, baseline_loss = 81.462, entropy_loss = -5.8349, learner_queue_size = 32, _tick = 35576, _time = 1.6548e+09, train_seconds = 3.4739e+04)
[2022-06-10 05:47:04,586][root][INFO] - Step 133015040 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 133015040, mean_episode_return = 44.661, mean_episode_step = 981.22, total_loss = 187.29, pg_loss = 143.87, baseline_loss = 48.91, entropy_loss = -5.4836, learner_queue_size = 32, _tick = 35582, _time = 1.6548e+09, train_seconds = 3.4744e+04)
[2022-06-10 05:47:09,590][root][INFO] - Step 133035520 @ 4092.7 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 133035520, mean_episode_return = 136.42, mean_episode_step = 865.32, total_loss = 4.3963, pg_loss = -45.457, baseline_loss = 55.459, entropy_loss = -5.6058, learner_queue_size = 32, _tick = 35590, _time = 1.6548e+09, train_seconds = 3.4749e+04)
[2022-06-10 05:47:14,594][root][INFO] - Step 133056000 @ 4092.7 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 133056000, mean_episode_return = None, mean_episode_step = 705.38, total_loss = -109.66, pg_loss = -124.04, baseline_loss = 20.075, entropy_loss = -5.6994, learner_queue_size = 32, _tick = 35597, _time = 1.6548e+09, train_seconds = 3.4754e+04)
[2022-06-10 05:47:19,600][root][INFO] - Step 133073920 @ 3579.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 133073920, mean_episode_return = 25.394, mean_episode_step = 911.57, total_loss = -27.011, pg_loss = -39.076, baseline_loss = 17.984, entropy_loss = -5.918, learner_queue_size = 32, _tick = 35604, _time = 1.6548e+09, train_seconds = 3.4759e+04)
[2022-06-10 05:47:24,606][root][INFO] - Step 133094400 @ 4091.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 133094400, mean_episode_return = 80.53, mean_episode_step = 979.4, total_loss = 159.1, pg_loss = 120.0, baseline_loss = 45.031, entropy_loss = -5.9358, learner_queue_size = 32, _tick = 35610, _time = 1.6548e+09, train_seconds = 3.4764e+04)
[2022-06-10 05:47:29,610][root][INFO] - Step 133114880 @ 4092.4 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 133114880, mean_episode_return = None, mean_episode_step = 1051.0, total_loss = -66.878, pg_loss = -70.762, baseline_loss = 9.7778, entropy_loss = -5.8941, learner_queue_size = 32, _tick = 35615, _time = 1.6548e+09, train_seconds = 3.4769e+04)
[2022-06-10 05:47:34,615][root][INFO] - Step 133132800 @ 3580.9 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 133132800, mean_episode_return = 33.52, mean_episode_step = 1007.1, total_loss = 194.92, pg_loss = 144.65, baseline_loss = 56.242, entropy_loss = -5.9691, learner_queue_size = 32, _tick = 35620, _time = 1.6548e+09, train_seconds = 3.4774e+04)
[2022-06-10 05:47:39,618][root][INFO] - Step 133153280 @ 4093.4 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 133153280, mean_episode_return = 67.41, mean_episode_step = 886.85, total_loss = -16.598, pg_loss = -52.986, baseline_loss = 42.174, entropy_loss = -5.7865, learner_queue_size = 32, _tick = 35627, _time = 1.6548e+09, train_seconds = 3.4779e+04)
[2022-06-10 05:47:44,622][root][INFO] - Step 133171200 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 133171200, mean_episode_return = 31.801, mean_episode_step = 1070.4, total_loss = 131.37, pg_loss = 87.783, baseline_loss = 49.444, entropy_loss = -5.8599, learner_queue_size = 32, _tick = 35634, _time = 1.6548e+09, train_seconds = 3.4784e+04)
[2022-06-10 05:47:49,626][root][INFO] - Step 133191680 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 133191680, mean_episode_return = 92.796, mean_episode_step = 761.19, total_loss = 502.13, pg_loss = 391.5, baseline_loss = 116.36, entropy_loss = -5.725, learner_queue_size = 32, _tick = 35641, _time = 1.6548e+09, train_seconds = 3.4789e+04)
[2022-06-10 05:47:54,630][root][INFO] - Step 133209600 @ 3581.1 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 133209600, mean_episode_return = 66.39, mean_episode_step = 885.57, total_loss = -55.845, pg_loss = -81.317, baseline_loss = 31.063, entropy_loss = -5.5905, learner_queue_size = 32, _tick = 35645, _time = 1.6548e+09, train_seconds = 3.4794e+04)
[2022-06-10 05:47:59,634][root][INFO] - Step 133230080 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 133230080, mean_episode_return = None, mean_episode_step = 1219.8, total_loss = 48.504, pg_loss = -4.9704, baseline_loss = 59.174, entropy_loss = -5.6991, learner_queue_size = 32, _tick = 35650, _time = 1.6548e+09, train_seconds = 3.4799e+04)
[2022-06-10 05:48:04,638][root][INFO] - Step 133250560 @ 4092.8 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 133250560, mean_episode_return = 35.725, mean_episode_step = 1133.1, total_loss = 243.93, pg_loss = 177.5, baseline_loss = 71.829, entropy_loss = -5.3944, learner_queue_size = 32, _tick = 35656, _time = 1.6548e+09, train_seconds = 3.4804e+04)
[2022-06-10 05:48:09,642][root][INFO] - Step 133268480 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 133268480, mean_episode_return = 32.775, mean_episode_step = 1095.5, total_loss = 244.31, pg_loss = 112.52, baseline_loss = 137.22, entropy_loss = -5.4273, learner_queue_size = 32, _tick = 35661, _time = 1.6548e+09, train_seconds = 3.4809e+04)
[2022-06-10 05:48:14,646][root][INFO] - Step 133288960 @ 4092.8 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 133288960, mean_episode_return = 44.905, mean_episode_step = 967.16, total_loss = 108.57, pg_loss = 62.3, baseline_loss = 51.945, entropy_loss = -5.6783, learner_queue_size = 32, _tick = 35667, _time = 1.6548e+09, train_seconds = 3.4814e+04)
[2022-06-10 05:48:19,650][root][INFO] - Step 133306880 @ 3581.0 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 133306880, mean_episode_return = None, mean_episode_step = 995.19, total_loss = 35.591, pg_loss = -7.7209, baseline_loss = 48.896, entropy_loss = -5.5837, learner_queue_size = 32, _tick = 35672, _time = 1.6548e+09, train_seconds = 3.482e+04)
[2022-06-10 05:48:24,654][root][INFO] - Step 133327360 @ 4092.6 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 133327360, mean_episode_return = 58.712, mean_episode_step = 1151.1, total_loss = -93.17, pg_loss = -136.68, baseline_loss = 49.345, entropy_loss = -5.8351, learner_queue_size = 32, _tick = 35679, _time = 1.6548e+09, train_seconds = 3.4824e+04)
[2022-06-10 05:48:29,658][root][INFO] - Step 133345280 @ 3581.4 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 133345280, mean_episode_return = None, mean_episode_step = 1234.8, total_loss = -31.222, pg_loss = -47.394, baseline_loss = 21.86, entropy_loss = -5.6884, learner_queue_size = 32, _tick = 35684, _time = 1.6548e+09, train_seconds = 3.483e+04)
[2022-06-10 05:48:34,662][root][INFO] - Step 133365760 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 133365760, mean_episode_return = None, mean_episode_step = 1106.2, total_loss = 101.84, pg_loss = 70.705, baseline_loss = 36.55, entropy_loss = -5.413, learner_queue_size = 32, _tick = 35691, _time = 1.6548e+09, train_seconds = 3.4834e+04)
[2022-06-10 05:48:39,666][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 05:48:39,791][root][INFO] - Step 133383680 @ 3581.2 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (step = 133383680, mean_episode_return = 32.041, mean_episode_step = 1078.7, total_loss = -41.462, pg_loss = -98.786, baseline_loss = 62.861, entropy_loss = -5.5366, learner_queue_size = 32, _tick = 35695, _time = 1.6548e+09, train_seconds = 3.484e+04)
[2022-06-10 05:48:44,794][root][INFO] - Step 133404160 @ 3993.8 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 133404160, mean_episode_return = 53.515, mean_episode_step = 1044.3, total_loss = 559.47, pg_loss = 431.54, baseline_loss = 133.66, entropy_loss = -5.7398, learner_queue_size = 32, _tick = 35702, _time = 1.6548e+09, train_seconds = 3.4845e+04)
[2022-06-10 05:48:49,798][root][INFO] - Step 133422080 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 133422080, mean_episode_return = 85.06, mean_episode_step = 987.67, total_loss = -23.525, pg_loss = -38.485, baseline_loss = 20.236, entropy_loss = -5.2764, learner_queue_size = 32, _tick = 35709, _time = 1.6548e+09, train_seconds = 3.485e+04)
[2022-06-10 05:48:54,802][root][INFO] - Step 133442560 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 133442560, mean_episode_return = 36.15, mean_episode_step = 1031.8, total_loss = -52.685, pg_loss = -63.86, baseline_loss = 16.888, entropy_loss = -5.7131, learner_queue_size = 32, _tick = 35717, _time = 1.6548e+09, train_seconds = 3.4855e+04)
[2022-06-10 05:48:59,806][root][INFO] - Step 133463040 @ 4092.7 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 133463040, mean_episode_return = -9.4802, mean_episode_step = 1222.8, total_loss = 195.15, pg_loss = 152.4, baseline_loss = 48.575, entropy_loss = -5.8225, learner_queue_size = 32, _tick = 35724, _time = 1.6548e+09, train_seconds = 3.486e+04)
[2022-06-10 05:49:04,810][root][INFO] - Step 133480960 @ 3581.2 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 133480960, mean_episode_return = None, mean_episode_step = 846.06, total_loss = 212.66, pg_loss = 144.78, baseline_loss = 73.691, entropy_loss = -5.8117, learner_queue_size = 32, _tick = 35728, _time = 1.6548e+09, train_seconds = 3.4865e+04)
[2022-06-10 05:49:09,814][root][INFO] - Step 133501440 @ 4092.7 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 133501440, mean_episode_return = 43.293, mean_episode_step = 723.94, total_loss = -47.601, pg_loss = -65.023, baseline_loss = 23.002, entropy_loss = -5.5797, learner_queue_size = 32, _tick = 35736, _time = 1.6548e+09, train_seconds = 3.487e+04)
[2022-06-10 05:49:14,818][root][INFO] - Step 133521920 @ 4092.7 SPS. Inference batcher size: 85. Learner queue size: 32. Other stats: (step = 133521920, mean_episode_return = 45.56, mean_episode_step = 886.59, total_loss = 120.33, pg_loss = 79.816, baseline_loss = 46.313, entropy_loss = -5.7974, learner_queue_size = 32, _tick = 35741, _time = 1.6548e+09, train_seconds = 3.4875e+04)
[2022-06-10 05:49:19,822][root][INFO] - Step 133539840 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 133539840, mean_episode_return = 51.261, mean_episode_step = 1210.5, total_loss = -92.074, pg_loss = -141.3, baseline_loss = 55.041, entropy_loss = -5.8201, learner_queue_size = 32, _tick = 35746, _time = 1.6548e+09, train_seconds = 3.488e+04)
[2022-06-10 05:49:24,827][root][INFO] - Step 133560320 @ 4091.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 133560320, mean_episode_return = 34.37, mean_episode_step = 1194.3, total_loss = 241.37, pg_loss = 159.04, baseline_loss = 88.147, entropy_loss = -5.8161, learner_queue_size = 32, _tick = 35754, _time = 1.6548e+09, train_seconds = 3.4885e+04)
[2022-06-10 05:49:29,830][root][INFO] - Step 133580800 @ 4093.9 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 133580800, mean_episode_return = 24.151, mean_episode_step = 855.46, total_loss = -107.6, pg_loss = -134.46, baseline_loss = 32.628, entropy_loss = -5.7701, learner_queue_size = 32, _tick = 35762, _time = 1.6548e+09, train_seconds = 3.489e+04)
[2022-06-10 05:49:34,836][root][INFO] - Step 133601280 @ 4091.1 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (step = 133601280, mean_episode_return = 64.28, mean_episode_step = 993.06, total_loss = 133.88, pg_loss = 69.367, baseline_loss = 70.498, entropy_loss = -5.9843, learner_queue_size = 32, _tick = 35769, _time = 1.6548e+09, train_seconds = 3.4895e+04)
[2022-06-10 05:49:39,842][root][INFO] - Step 133619200 @ 3579.6 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 133619200, mean_episode_return = 31.651, mean_episode_step = 827.87, total_loss = 39.799, pg_loss = 5.734, baseline_loss = 39.823, entropy_loss = -5.7582, learner_queue_size = 32, _tick = 35775, _time = 1.6548e+09, train_seconds = 3.49e+04)
[2022-06-10 05:49:44,848][root][INFO] - Step 133639680 @ 4090.7 SPS. Inference batcher size: 83. Learner queue size: 32. Other stats: (step = 133639680, mean_episode_return = 23.5, mean_episode_step = 1026.3, total_loss = -157.68, pg_loss = -191.1, baseline_loss = 39.361, entropy_loss = -5.9389, learner_queue_size = 32, _tick = 35783, _time = 1.6548e+09, train_seconds = 3.4905e+04)
[2022-06-10 05:49:49,854][root][INFO] - Step 133657600 @ 3580.0 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 133657600, mean_episode_return = 36.721, mean_episode_step = 1015.8, total_loss = -45.355, pg_loss = -63.225, baseline_loss = 23.903, entropy_loss = -6.0331, learner_queue_size = 32, _tick = 35789, _time = 1.6548e+09, train_seconds = 3.491e+04)
[2022-06-10 05:49:54,858][root][INFO] - Step 133678080 @ 4092.8 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 133678080, mean_episode_return = 90.024, mean_episode_step = 1069.2, total_loss = -192.54, pg_loss = -201.79, baseline_loss = 15.076, entropy_loss = -5.8254, learner_queue_size = 32, _tick = 35795, _time = 1.6548e+09, train_seconds = 3.4915e+04)
[2022-06-10 05:49:59,862][root][INFO] - Step 133696000 @ 3581.1 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 133696000, mean_episode_return = None, mean_episode_step = 1218.4, total_loss = 363.55, pg_loss = 249.73, baseline_loss = 119.71, entropy_loss = -5.8834, learner_queue_size = 32, _tick = 35800, _time = 1.6548e+09, train_seconds = 3.492e+04)
[2022-06-10 05:50:04,866][root][INFO] - Step 133716480 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 133716480, mean_episode_return = 47.295, mean_episode_step = 916.94, total_loss = -94.966, pg_loss = -118.91, baseline_loss = 29.517, entropy_loss = -5.5766, learner_queue_size = 32, _tick = 35808, _time = 1.6548e+09, train_seconds = 3.4925e+04)
[2022-06-10 05:50:09,870][root][INFO] - Step 133734400 @ 3581.1 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 133734400, mean_episode_return = 13.275, mean_episode_step = 788.34, total_loss = -71.577, pg_loss = -140.35, baseline_loss = 74.381, entropy_loss = -5.6047, learner_queue_size = 32, _tick = 35815, _time = 1.6548e+09, train_seconds = 3.493e+04)
[2022-06-10 05:50:14,872][root][INFO] - Step 133754880 @ 4094.4 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 133754880, mean_episode_return = 79.385, mean_episode_step = 806.58, total_loss = 205.61, pg_loss = 149.29, baseline_loss = 62.097, entropy_loss = -5.7752, learner_queue_size = 32, _tick = 35822, _time = 1.6548e+09, train_seconds = 3.4935e+04)
[2022-06-10 05:50:19,874][root][INFO] - Step 133775360 @ 4094.3 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 133775360, mean_episode_return = 35.615, mean_episode_step = 924.7, total_loss = -51.144, pg_loss = -91.093, baseline_loss = 45.504, entropy_loss = -5.5555, learner_queue_size = 32, _tick = 35827, _time = 1.6548e+09, train_seconds = 3.494e+04)
[2022-06-10 05:50:24,879][root][INFO] - Step 133795840 @ 4092.3 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 133795840, mean_episode_return = 56.93, mean_episode_step = 853.32, total_loss = -214.21, pg_loss = -261.99, baseline_loss = 53.453, entropy_loss = -5.6808, learner_queue_size = 32, _tick = 35834, _time = 1.6548e+09, train_seconds = 3.4945e+04)
[2022-06-10 05:50:29,882][root][INFO] - Step 133813760 @ 3581.5 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 133813760, mean_episode_return = 9.7898, mean_episode_step = 1072.8, total_loss = 102.14, pg_loss = 12.951, baseline_loss = 94.776, entropy_loss = -5.5827, learner_queue_size = 32, _tick = 35840, _time = 1.6548e+09, train_seconds = 3.495e+04)
[2022-06-10 05:50:34,886][root][INFO] - Step 133834240 @ 4092.8 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 133834240, mean_episode_return = 68.426, mean_episode_step = 777.83, total_loss = -187.95, pg_loss = -222.25, baseline_loss = 40.022, entropy_loss = -5.7246, learner_queue_size = 32, _tick = 35847, _time = 1.6548e+09, train_seconds = 3.4955e+04)
[2022-06-10 05:50:39,890][root][INFO] - Step 133854720 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 133854720, mean_episode_return = None, mean_episode_step = 915.34, total_loss = -3.7189, pg_loss = -52.156, baseline_loss = 54.181, entropy_loss = -5.7436, learner_queue_size = 32, _tick = 35853, _time = 1.6548e+09, train_seconds = 3.496e+04)
[2022-06-10 05:50:44,894][root][INFO] - Step 133872640 @ 3581.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 133872640, mean_episode_return = None, mean_episode_step = 937.0, total_loss = 60.119, pg_loss = 29.496, baseline_loss = 36.497, entropy_loss = -5.8733, learner_queue_size = 32, _tick = 35857, _time = 1.6548e+09, train_seconds = 3.4965e+04)
[2022-06-10 05:50:49,898][root][INFO] - Step 133893120 @ 4092.7 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 133893120, mean_episode_return = None, mean_episode_step = 1138.5, total_loss = 254.18, pg_loss = 180.82, baseline_loss = 79.053, entropy_loss = -5.6937, learner_queue_size = 32, _tick = 35863, _time = 1.6548e+09, train_seconds = 3.497e+04)
[2022-06-10 05:50:54,902][root][INFO] - Step 133913600 @ 4092.7 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (step = 133913600, mean_episode_return = None, mean_episode_step = 1054.9, total_loss = 119.01, pg_loss = 78.009, baseline_loss = 46.454, entropy_loss = -5.4574, learner_queue_size = 32, _tick = 35870, _time = 1.6548e+09, train_seconds = 3.4975e+04)
[2022-06-10 05:50:59,906][root][INFO] - Step 133931520 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 133931520, mean_episode_return = 42.515, mean_episode_step = 1001.2, total_loss = -68.988, pg_loss = -92.282, baseline_loss = 28.83, entropy_loss = -5.5365, learner_queue_size = 32, _tick = 35877, _time = 1.6548e+09, train_seconds = 3.498e+04)
[2022-06-10 05:51:04,910][root][INFO] - Step 133952000 @ 4092.7 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 133952000, mean_episode_return = 87.45, mean_episode_step = 1069.0, total_loss = 102.53, pg_loss = 66.856, baseline_loss = 41.449, entropy_loss = -5.7748, learner_queue_size = 32, _tick = 35883, _time = 1.6548e+09, train_seconds = 3.4985e+04)
[2022-06-10 05:51:09,914][root][INFO] - Step 133972480 @ 4092.8 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 133972480, mean_episode_return = 16.15, mean_episode_step = 968.41, total_loss = 177.36, pg_loss = 117.2, baseline_loss = 66.01, entropy_loss = -5.8491, learner_queue_size = 32, _tick = 35889, _time = 1.6548e+09, train_seconds = 3.499e+04)
[2022-06-10 05:51:14,919][root][INFO] - Step 133990400 @ 3580.7 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 133990400, mean_episode_return = None, mean_episode_step = 847.22, total_loss = 234.62, pg_loss = 165.34, baseline_loss = 74.854, entropy_loss = -5.5766, learner_queue_size = 32, _tick = 35895, _time = 1.6548e+09, train_seconds = 3.4995e+04)
[2022-06-10 05:51:19,922][root][INFO] - Step 134010880 @ 4093.1 SPS. Inference batcher size: 84. Learner queue size: 32. Other stats: (step = 134010880, mean_episode_return = None, mean_episode_step = 878.53, total_loss = -71.462, pg_loss = -89.444, baseline_loss = 23.802, entropy_loss = -5.8193, learner_queue_size = 32, _tick = 35900, _time = 1.6548e+09, train_seconds = 3.5e+04)
[2022-06-10 05:51:24,926][root][INFO] - Step 134031360 @ 4092.8 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 134031360, mean_episode_return = 83.59, mean_episode_step = 902.1, total_loss = 234.28, pg_loss = 182.21, baseline_loss = 57.902, entropy_loss = -5.8346, learner_queue_size = 32, _tick = 35907, _time = 1.6548e+09, train_seconds = 3.5005e+04)
[2022-06-10 05:51:29,930][root][INFO] - Step 134049280 @ 3581.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 134049280, mean_episode_return = 95.297, mean_episode_step = 1425.9, total_loss = -163.08, pg_loss = -170.83, baseline_loss = 13.734, entropy_loss = -5.9875, learner_queue_size = 32, _tick = 35913, _time = 1.6548e+09, train_seconds = 3.501e+04)
[2022-06-10 05:51:34,934][root][INFO] - Step 134069760 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 134069760, mean_episode_return = 27.923, mean_episode_step = 860.46, total_loss = 24.702, pg_loss = -26.123, baseline_loss = 56.75, entropy_loss = -5.9252, learner_queue_size = 32, _tick = 35919, _time = 1.6548e+09, train_seconds = 3.5015e+04)
[2022-06-10 05:51:39,941][root][INFO] - Step 134087680 @ 3579.2 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 134087680, mean_episode_return = 151.44, mean_episode_step = 917.47, total_loss = -124.65, pg_loss = -135.65, baseline_loss = 16.857, entropy_loss = -5.8544, learner_queue_size = 32, _tick = 35925, _time = 1.6548e+09, train_seconds = 3.502e+04)
[2022-06-10 05:51:44,946][root][INFO] - Step 134108160 @ 4091.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 134108160, mean_episode_return = 79.627, mean_episode_step = 1062.1, total_loss = 122.27, pg_loss = 74.293, baseline_loss = 53.872, entropy_loss = -5.8913, learner_queue_size = 32, _tick = 35931, _time = 1.6548e+09, train_seconds = 3.5025e+04)
[2022-06-10 05:51:49,950][root][INFO] - Step 134126080 @ 3581.1 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 134126080, mean_episode_return = 53.306, mean_episode_step = 1043.1, total_loss = 30.422, pg_loss = -6.1106, baseline_loss = 42.385, entropy_loss = -5.853, learner_queue_size = 32, _tick = 35936, _time = 1.6548e+09, train_seconds = 3.503e+04)
[2022-06-10 05:51:54,954][root][INFO] - Step 134146560 @ 4092.7 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 134146560, mean_episode_return = 34.588, mean_episode_step = 1156.4, total_loss = 2.4862, pg_loss = -49.568, baseline_loss = 57.871, entropy_loss = -5.8168, learner_queue_size = 32, _tick = 35941, _time = 1.6548e+09, train_seconds = 3.5035e+04)
[2022-06-10 05:51:59,958][root][INFO] - Step 134164480 @ 3581.2 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (step = 134164480, mean_episode_return = None, mean_episode_step = 1179.5, total_loss = -42.267, pg_loss = -74.978, baseline_loss = 38.655, entropy_loss = -5.944, learner_queue_size = 32, _tick = 35945, _time = 1.6548e+09, train_seconds = 3.504e+04)
[2022-06-10 05:52:04,962][root][INFO] - Step 134184960 @ 4092.7 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 134184960, mean_episode_return = 53.183, mean_episode_step = 1216.3, total_loss = 5.5355, pg_loss = -22.163, baseline_loss = 33.81, entropy_loss = -6.1107, learner_queue_size = 32, _tick = 35953, _time = 1.6548e+09, train_seconds = 3.5045e+04)
[2022-06-10 05:52:09,966][root][INFO] - Step 134205440 @ 4092.7 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 134205440, mean_episode_return = 124.87, mean_episode_step = 891.32, total_loss = 48.942, pg_loss = 23.912, baseline_loss = 31.25, entropy_loss = -6.2198, learner_queue_size = 32, _tick = 35958, _time = 1.6548e+09, train_seconds = 3.505e+04)
[2022-06-10 05:52:14,970][root][INFO] - Step 134225920 @ 4092.6 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (step = 134225920, mean_episode_return = 0.20982, mean_episode_step = 1016.1, total_loss = 76.602, pg_loss = 60.567, baseline_loss = 22.16, entropy_loss = -6.1249, learner_queue_size = 32, _tick = 35965, _time = 1.6548e+09, train_seconds = 3.5055e+04)
[2022-06-10 05:52:19,974][root][INFO] - Step 134243840 @ 3581.3 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 134243840, mean_episode_return = 30.19, mean_episode_step = 996.12, total_loss = 124.16, pg_loss = 97.949, baseline_loss = 32.205, entropy_loss = -5.991, learner_queue_size = 32, _tick = 35970, _time = 1.6548e+09, train_seconds = 3.506e+04)
[2022-06-10 05:52:24,984][root][INFO] - Step 134264320 @ 4087.6 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 134264320, mean_episode_return = 40.884, mean_episode_step = 1033.7, total_loss = -11.004, pg_loss = -43.624, baseline_loss = 38.474, entropy_loss = -5.8536, learner_queue_size = 32, _tick = 35977, _time = 1.6548e+09, train_seconds = 3.5065e+04)
[2022-06-10 05:52:29,990][root][INFO] - Step 134282240 @ 3579.8 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 134282240, mean_episode_return = 23.58, mean_episode_step = 995.27, total_loss = -261.85, pg_loss = -268.41, baseline_loss = 12.491, entropy_loss = -5.9353, learner_queue_size = 32, _tick = 35982, _time = 1.6548e+09, train_seconds = 3.507e+04)
[2022-06-10 05:52:34,994][root][INFO] - Step 134302720 @ 4092.7 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 134302720, mean_episode_return = 8.5496, mean_episode_step = 824.98, total_loss = 166.24, pg_loss = 98.812, baseline_loss = 73.299, entropy_loss = -5.8746, learner_queue_size = 32, _tick = 35988, _time = 1.6548e+09, train_seconds = 3.5075e+04)
[2022-06-10 05:52:39,998][root][INFO] - Step 134323200 @ 4092.8 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 134323200, mean_episode_return = None, mean_episode_step = 800.31, total_loss = 42.748, pg_loss = -9.4757, baseline_loss = 58.167, entropy_loss = -5.9431, learner_queue_size = 32, _tick = 35994, _time = 1.6548e+09, train_seconds = 3.508e+04)
[2022-06-10 05:52:45,002][root][INFO] - Step 134341120 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 134341120, mean_episode_return = None, mean_episode_step = 1027.9, total_loss = 393.9, pg_loss = 315.36, baseline_loss = 84.454, entropy_loss = -5.9138, learner_queue_size = 32, _tick = 35999, _time = 1.6548e+09, train_seconds = 3.5085e+04)
[2022-06-10 05:52:50,006][root][INFO] - Step 134361600 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 134361600, mean_episode_return = 84.077, mean_episode_step = 1013.9, total_loss = 237.61, pg_loss = 185.25, baseline_loss = 58.27, entropy_loss = -5.9157, learner_queue_size = 32, _tick = 36006, _time = 1.6548e+09, train_seconds = 3.509e+04)
[2022-06-10 05:52:55,010][root][INFO] - Step 134379520 @ 3581.2 SPS. Inference batcher size: 88. Learner queue size: 32. Other stats: (step = 134379520, mean_episode_return = 5.3796, mean_episode_step = 1191.2, total_loss = 233.2, pg_loss = 151.84, baseline_loss = 87.038, entropy_loss = -5.6757, learner_queue_size = 32, _tick = 36013, _time = 1.6548e+09, train_seconds = 3.5095e+04)
[2022-06-10 05:53:00,014][root][INFO] - Step 134400000 @ 4092.7 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (step = 134400000, mean_episode_return = 12.01, mean_episode_step = 797.33, total_loss = 178.61, pg_loss = 124.64, baseline_loss = 59.717, entropy_loss = -5.7459, learner_queue_size = 32, _tick = 36021, _time = 1.6548e+09, train_seconds = 3.51e+04)
[2022-06-10 05:53:05,018][root][INFO] - Step 134420480 @ 4092.7 SPS. Inference batcher size: 76. Learner queue size: 32. Other stats: (step = 134420480, mean_episode_return = 23.8, mean_episode_step = 950.58, total_loss = 214.4, pg_loss = 142.3, baseline_loss = 77.719, entropy_loss = -5.6195, learner_queue_size = 32, _tick = 36028, _time = 1.6548e+09, train_seconds = 3.5105e+04)
[2022-06-10 05:53:10,022][root][INFO] - Step 134440960 @ 4092.7 SPS. Inference batcher size: 75. Learner queue size: 32. Other stats: (step = 134440960, mean_episode_return = 49.267, mean_episode_step = 765.41, total_loss = -56.77, pg_loss = -89.257, baseline_loss = 37.953, entropy_loss = -5.4656, learner_queue_size = 32, _tick = 36034, _time = 1.6548e+09, train_seconds = 3.511e+04)
[2022-06-10 05:53:15,028][root][INFO] - Step 134458880 @ 3579.9 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (step = 134458880, mean_episode_return = 5.3398, mean_episode_step = 660.04, total_loss = 265.13, pg_loss = 178.69, baseline_loss = 91.777, entropy_loss = -5.3397, learner_queue_size = 32, _tick = 36041, _time = 1.6548e+09, train_seconds = 3.5115e+04)
[2022-06-10 05:53:20,033][root][INFO] - Step 134479360 @ 4091.4 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 134479360, mean_episode_return = None, mean_episode_step = 785.53, total_loss = 55.428, pg_loss = 1.0377, baseline_loss = 59.614, entropy_loss = -5.2229, learner_queue_size = 32, _tick = 36046, _time = 1.6548e+09, train_seconds = 3.512e+04)
[2022-06-10 05:53:25,038][root][INFO] - Step 134499840 @ 4092.2 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 134499840, mean_episode_return = 53.13, mean_episode_step = 1295.8, total_loss = 7.0365, pg_loss = -39.064, baseline_loss = 51.889, entropy_loss = -5.789, learner_queue_size = 32, _tick = 36050, _time = 1.6548e+09, train_seconds = 3.5125e+04)
[2022-06-10 05:53:30,042][root][INFO] - Step 134517760 @ 3581.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 134517760, mean_episode_return = 62.565, mean_episode_step = 908.12, total_loss = 29.402, pg_loss = -5.5897, baseline_loss = 40.932, entropy_loss = -5.9394, learner_queue_size = 32, _tick = 36057, _time = 1.6548e+09, train_seconds = 3.513e+04)
[2022-06-10 05:53:35,046][root][INFO] - Step 134538240 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 134538240, mean_episode_return = 17.42, mean_episode_step = 1091.6, total_loss = 118.57, pg_loss = 59.511, baseline_loss = 64.894, entropy_loss = -5.8394, learner_queue_size = 32, _tick = 36064, _time = 1.6548e+09, train_seconds = 3.5135e+04)
[2022-06-10 05:53:40,050][root][INFO] - Step 134558720 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 134558720, mean_episode_return = 22.01, mean_episode_step = 825.81, total_loss = 373.49, pg_loss = 250.14, baseline_loss = 129.04, entropy_loss = -5.6954, learner_queue_size = 32, _tick = 36070, _time = 1.6548e+09, train_seconds = 3.514e+04)
[2022-06-10 05:53:45,054][root][INFO] - Step 134576640 @ 3581.2 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 134576640, mean_episode_return = 1.7198, mean_episode_step = 995.1, total_loss = -200.19, pg_loss = -205.72, baseline_loss = 11.474, entropy_loss = -5.9435, learner_queue_size = 32, _tick = 36076, _time = 1.6548e+09, train_seconds = 3.5145e+04)
[2022-06-10 05:53:50,058][root][INFO] - Step 134597120 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 134597120, mean_episode_return = 39.33, mean_episode_step = 959.93, total_loss = 55.779, pg_loss = 25.669, baseline_loss = 36.032, entropy_loss = -5.9221, learner_queue_size = 32, _tick = 36081, _time = 1.6548e+09, train_seconds = 3.515e+04)
[2022-06-10 05:53:55,062][root][INFO] - Step 134617600 @ 4092.7 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 134617600, mean_episode_return = 12.57, mean_episode_step = 1086.7, total_loss = 56.906, pg_loss = 30.363, baseline_loss = 32.37, entropy_loss = -5.8261, learner_queue_size = 32, _tick = 36089, _time = 1.6548e+09, train_seconds = 3.5155e+04)
[2022-06-10 05:54:00,066][root][INFO] - Step 134635520 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 134635520, mean_episode_return = 73.447, mean_episode_step = 1135.7, total_loss = -56.142, pg_loss = -103.14, baseline_loss = 52.795, entropy_loss = -5.7924, learner_queue_size = 32, _tick = 36095, _time = 1.6548e+09, train_seconds = 3.516e+04)
[2022-06-10 05:54:05,070][root][INFO] - Step 134656000 @ 4092.7 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 134656000, mean_episode_return = 24.056, mean_episode_step = 891.37, total_loss = 76.309, pg_loss = 40.172, baseline_loss = 41.584, entropy_loss = -5.4471, learner_queue_size = 32, _tick = 36099, _time = 1.6548e+09, train_seconds = 3.5165e+04)
[2022-06-10 05:54:10,074][root][INFO] - Step 134676480 @ 4092.7 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 134676480, mean_episode_return = 43.68, mean_episode_step = 1111.3, total_loss = 8.8843, pg_loss = -22.699, baseline_loss = 37.41, entropy_loss = -5.8266, learner_queue_size = 32, _tick = 36106, _time = 1.6548e+09, train_seconds = 3.517e+04)
[2022-06-10 05:54:15,078][root][INFO] - Step 134696960 @ 4092.8 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 134696960, mean_episode_return = 49.795, mean_episode_step = 1012.7, total_loss = -116.61, pg_loss = -151.28, baseline_loss = 40.593, entropy_loss = -5.9247, learner_queue_size = 32, _tick = 36112, _time = 1.6548e+09, train_seconds = 3.5175e+04)
[2022-06-10 05:54:20,082][root][INFO] - Step 134714880 @ 3581.1 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 134714880, mean_episode_return = 89.08, mean_episode_step = 735.93, total_loss = 93.727, pg_loss = 54.55, baseline_loss = 44.956, entropy_loss = -5.7786, learner_queue_size = 32, _tick = 36118, _time = 1.6548e+09, train_seconds = 3.518e+04)
[2022-06-10 05:54:25,091][root][INFO] - Step 134735360 @ 4088.5 SPS. Inference batcher size: 83. Learner queue size: 32. Other stats: (step = 134735360, mean_episode_return = -1.11, mean_episode_step = 976.25, total_loss = 86.819, pg_loss = 53.885, baseline_loss = 38.696, entropy_loss = -5.7618, learner_queue_size = 32, _tick = 36123, _time = 1.6548e+09, train_seconds = 3.5185e+04)
[2022-06-10 05:54:30,094][root][INFO] - Step 134753280 @ 3581.9 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 134753280, mean_episode_return = 20.01, mean_episode_step = 1063.9, total_loss = -211.24, pg_loss = -228.22, baseline_loss = 22.691, entropy_loss = -5.7125, learner_queue_size = 32, _tick = 36128, _time = 1.6548e+09, train_seconds = 3.519e+04)
[2022-06-10 05:54:35,099][root][INFO] - Step 134773760 @ 4092.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 134773760, mean_episode_return = 54.541, mean_episode_step = 1223.1, total_loss = 247.67, pg_loss = 159.3, baseline_loss = 94.21, entropy_loss = -5.8416, learner_queue_size = 32, _tick = 36135, _time = 1.6548e+09, train_seconds = 3.5195e+04)
[2022-06-10 05:54:40,102][root][INFO] - Step 134794240 @ 4093.3 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 134794240, mean_episode_return = 40.936, mean_episode_step = 1146.3, total_loss = -102.12, pg_loss = -134.96, baseline_loss = 38.683, entropy_loss = -5.8362, learner_queue_size = 32, _tick = 36143, _time = 1.6548e+09, train_seconds = 3.52e+04)
[2022-06-10 05:54:45,106][root][INFO] - Step 134812160 @ 3581.2 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 134812160, mean_episode_return = 102.71, mean_episode_step = 996.02, total_loss = 285.08, pg_loss = 219.45, baseline_loss = 71.569, entropy_loss = -5.942, learner_queue_size = 32, _tick = 36148, _time = 1.6548e+09, train_seconds = 3.5205e+04)
[2022-06-10 05:54:50,110][root][INFO] - Step 134832640 @ 4092.7 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 134832640, mean_episode_return = 18.4, mean_episode_step = 1104.2, total_loss = -131.12, pg_loss = -148.22, baseline_loss = 22.919, entropy_loss = -5.817, learner_queue_size = 32, _tick = 36155, _time = 1.6548e+09, train_seconds = 3.521e+04)
[2022-06-10 05:54:55,114][root][INFO] - Step 134850560 @ 3581.2 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 134850560, mean_episode_return = 31.45, mean_episode_step = 992.27, total_loss = 28.189, pg_loss = -17.084, baseline_loss = 51.203, entropy_loss = -5.9294, learner_queue_size = 32, _tick = 36161, _time = 1.6548e+09, train_seconds = 3.5215e+04)
[2022-06-10 05:55:00,118][root][INFO] - Step 134871040 @ 4092.8 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 134871040, mean_episode_return = 85.698, mean_episode_step = 909.31, total_loss = -98.204, pg_loss = -125.09, baseline_loss = 32.432, entropy_loss = -5.5489, learner_queue_size = 32, _tick = 36167, _time = 1.6548e+09, train_seconds = 3.522e+04)
[2022-06-10 05:55:05,122][root][INFO] - Step 134888960 @ 3581.1 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 134888960, mean_episode_return = 83.249, mean_episode_step = 706.75, total_loss = 218.98, pg_loss = 135.87, baseline_loss = 88.667, entropy_loss = -5.5626, learner_queue_size = 32, _tick = 36173, _time = 1.6548e+09, train_seconds = 3.5225e+04)
[2022-06-10 05:55:10,126][root][INFO] - Step 134909440 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 134909440, mean_episode_return = 116.14, mean_episode_step = 1057.1, total_loss = 10.492, pg_loss = -46.888, baseline_loss = 63.144, entropy_loss = -5.7638, learner_queue_size = 32, _tick = 36179, _time = 1.6548e+09, train_seconds = 3.523e+04)
[2022-06-10 05:55:15,130][root][INFO] - Step 134927360 @ 3581.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 134927360, mean_episode_return = 76.149, mean_episode_step = 836.23, total_loss = -60.638, pg_loss = -91.039, baseline_loss = 36.305, entropy_loss = -5.905, learner_queue_size = 32, _tick = 36186, _time = 1.6548e+09, train_seconds = 3.5235e+04)
[2022-06-10 05:55:20,136][root][INFO] - Step 134947840 @ 4091.1 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 134947840, mean_episode_return = 17.023, mean_episode_step = 929.74, total_loss = -89.446, pg_loss = -155.94, baseline_loss = 72.42, entropy_loss = -5.9234, learner_queue_size = 32, _tick = 36193, _time = 1.6548e+09, train_seconds = 3.524e+04)
[2022-06-10 05:55:25,142][root][INFO] - Step 134965760 @ 3579.6 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 134965760, mean_episode_return = 6.1797, mean_episode_step = 1107.2, total_loss = -32.056, pg_loss = -45.789, baseline_loss = 19.741, entropy_loss = -6.0078, learner_queue_size = 32, _tick = 36199, _time = 1.6548e+09, train_seconds = 3.5245e+04)
[2022-06-10 05:55:30,146][root][INFO] - Step 134986240 @ 4092.8 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 134986240, mean_episode_return = 125.72, mean_episode_step = 896.89, total_loss = -39.69, pg_loss = -87.805, baseline_loss = 53.992, entropy_loss = -5.8762, learner_queue_size = 32, _tick = 36203, _time = 1.6548e+09, train_seconds = 3.525e+04)
[2022-06-10 05:55:35,150][root][INFO] - Step 135006720 @ 4092.7 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 135006720, mean_episode_return = 31.403, mean_episode_step = 873.46, total_loss = 106.24, pg_loss = 17.005, baseline_loss = 94.997, entropy_loss = -5.7599, learner_queue_size = 32, _tick = 36210, _time = 1.6548e+09, train_seconds = 3.5255e+04)
[2022-06-10 05:55:40,158][root][INFO] - Step 135024640 @ 3578.0 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 135024640, mean_episode_return = 29.071, mean_episode_step = 1011.0, total_loss = 143.73, pg_loss = 62.965, baseline_loss = 86.565, entropy_loss = -5.8026, learner_queue_size = 32, _tick = 36214, _time = 1.6548e+09, train_seconds = 3.526e+04)
[2022-06-10 05:55:45,162][root][INFO] - Step 135045120 @ 4093.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 135045120, mean_episode_return = None, mean_episode_step = 906.66, total_loss = 354.25, pg_loss = 268.86, baseline_loss = 91.223, entropy_loss = -5.8366, learner_queue_size = 32, _tick = 36220, _time = 1.6548e+09, train_seconds = 3.5265e+04)
[2022-06-10 05:55:50,166][root][INFO] - Step 135063040 @ 3581.1 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 135063040, mean_episode_return = 9.39, mean_episode_step = 757.61, total_loss = 203.42, pg_loss = 111.94, baseline_loss = 96.935, entropy_loss = -5.4536, learner_queue_size = 32, _tick = 36227, _time = 1.6548e+09, train_seconds = 3.527e+04)
[2022-06-10 05:55:55,170][root][INFO] - Step 135083520 @ 4092.7 SPS. Inference batcher size: 63. Learner queue size: 32. Other stats: (step = 135083520, mean_episode_return = 16.06, mean_episode_step = 1453.2, total_loss = 82.719, pg_loss = -13.101, baseline_loss = 101.59, entropy_loss = -5.7678, learner_queue_size = 32, _tick = 36235, _time = 1.6548e+09, train_seconds = 3.5275e+04)
[2022-06-10 05:56:00,174][root][INFO] - Step 135101440 @ 3581.1 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 135101440, mean_episode_return = 8.9296, mean_episode_step = 1056.0, total_loss = 93.361, pg_loss = 57.913, baseline_loss = 41.428, entropy_loss = -5.98, learner_queue_size = 32, _tick = 36239, _time = 1.6548e+09, train_seconds = 3.528e+04)
[2022-06-10 05:56:05,178][root][INFO] - Step 135121920 @ 4092.8 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 135121920, mean_episode_return = 18.335, mean_episode_step = 769.57, total_loss = 221.43, pg_loss = 190.17, baseline_loss = 37.234, entropy_loss = -5.9758, learner_queue_size = 32, _tick = 36246, _time = 1.6548e+09, train_seconds = 3.5285e+04)
[2022-06-10 05:56:10,182][root][INFO] - Step 135139840 @ 3581.1 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 135139840, mean_episode_return = 20.38, mean_episode_step = 901.18, total_loss = -55.553, pg_loss = -74.746, baseline_loss = 25.131, entropy_loss = -5.9381, learner_queue_size = 32, _tick = 36252, _time = 1.6548e+09, train_seconds = 3.529e+04)
[2022-06-10 05:56:15,189][root][INFO] - Step 135160320 @ 4090.7 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 135160320, mean_episode_return = 54.439, mean_episode_step = 896.77, total_loss = -61.681, pg_loss = -81.438, baseline_loss = 25.658, entropy_loss = -5.9002, learner_queue_size = 32, _tick = 36258, _time = 1.6548e+09, train_seconds = 3.5295e+04)
[2022-06-10 05:56:20,194][root][INFO] - Step 135180800 @ 4091.4 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 135180800, mean_episode_return = None, mean_episode_step = 963.56, total_loss = 231.03, pg_loss = 181.97, baseline_loss = 54.89, entropy_loss = -5.8307, learner_queue_size = 32, _tick = 36264, _time = 1.6548e+09, train_seconds = 3.53e+04)
[2022-06-10 05:56:25,200][root][INFO] - Step 135198720 @ 3579.6 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 135198720, mean_episode_return = 88.16, mean_episode_step = 1382.4, total_loss = 60.082, pg_loss = 28.471, baseline_loss = 37.346, entropy_loss = -5.7353, learner_queue_size = 32, _tick = 36270, _time = 1.6548e+09, train_seconds = 3.5305e+04)
[2022-06-10 05:56:30,206][root][INFO] - Step 135219200 @ 4091.3 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 135219200, mean_episode_return = 58.287, mean_episode_step = 1099.4, total_loss = -73.156, pg_loss = -122.89, baseline_loss = 55.462, entropy_loss = -5.7256, learner_queue_size = 32, _tick = 36276, _time = 1.6548e+09, train_seconds = 3.531e+04)
[2022-06-10 05:56:35,210][root][INFO] - Step 135239680 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 135239680, mean_episode_return = None, mean_episode_step = 926.47, total_loss = 185.72, pg_loss = 111.28, baseline_loss = 80.085, entropy_loss = -5.6398, learner_queue_size = 32, _tick = 36280, _time = 1.6548e+09, train_seconds = 3.5315e+04)
[2022-06-10 05:56:40,214][root][INFO] - Step 135257600 @ 3581.2 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 135257600, mean_episode_return = None, mean_episode_step = 1381.1, total_loss = 1373.5, pg_loss = 856.51, baseline_loss = 522.42, entropy_loss = -5.4158, learner_queue_size = 32, _tick = 36286, _time = 1.6548e+09, train_seconds = 3.532e+04)
[2022-06-10 05:56:45,218][root][INFO] - Step 135275520 @ 3581.1 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 135275520, mean_episode_return = 85.96, mean_episode_step = 1015.7, total_loss = -115.01, pg_loss = -150.02, baseline_loss = 40.145, entropy_loss = -5.1353, learner_queue_size = 32, _tick = 36292, _time = 1.6548e+09, train_seconds = 3.5325e+04)
[2022-06-10 05:56:50,223][root][INFO] - Step 135296000 @ 4092.2 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 135296000, mean_episode_return = None, mean_episode_step = 954.88, total_loss = 86.417, pg_loss = 32.296, baseline_loss = 59.825, entropy_loss = -5.7038, learner_queue_size = 32, _tick = 36297, _time = 1.6548e+09, train_seconds = 3.533e+04)
[2022-06-10 05:56:55,226][root][INFO] - Step 135316480 @ 4093.3 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 135316480, mean_episode_return = 152.4, mean_episode_step = 927.63, total_loss = -24.062, pg_loss = -39.575, baseline_loss = 21.355, entropy_loss = -5.8427, learner_queue_size = 32, _tick = 36304, _time = 1.6548e+09, train_seconds = 3.5335e+04)
[2022-06-10 05:57:00,230][root][INFO] - Step 135334400 @ 3581.2 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 135334400, mean_episode_return = 30.71, mean_episode_step = 940.15, total_loss = 221.24, pg_loss = 164.69, baseline_loss = 62.368, entropy_loss = -5.8178, learner_queue_size = 32, _tick = 36307, _time = 1.6548e+09, train_seconds = 3.534e+04)
[2022-06-10 05:57:05,234][root][INFO] - Step 135354880 @ 4092.7 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 135354880, mean_episode_return = 95.298, mean_episode_step = 863.74, total_loss = 277.84, pg_loss = 211.5, baseline_loss = 72.12, entropy_loss = -5.7859, learner_queue_size = 32, _tick = 36312, _time = 1.6548e+09, train_seconds = 3.5345e+04)
[2022-06-10 05:57:10,238][root][INFO] - Step 135372800 @ 3581.1 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 135372800, mean_episode_return = 45.805, mean_episode_step = 994.28, total_loss = -182.97, pg_loss = -207.71, baseline_loss = 30.54, entropy_loss = -5.8022, learner_queue_size = 32, _tick = 36318, _time = 1.6548e+09, train_seconds = 3.535e+04)
[2022-06-10 05:57:15,242][root][INFO] - Step 135393280 @ 4092.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 135393280, mean_episode_return = 39.8, mean_episode_step = 933.38, total_loss = -20.4, pg_loss = -54.681, baseline_loss = 40.091, entropy_loss = -5.8106, learner_queue_size = 32, _tick = 36326, _time = 1.6548e+09, train_seconds = 3.5355e+04)
[2022-06-10 05:57:20,246][root][INFO] - Step 135411200 @ 3581.1 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 135411200, mean_episode_return = 65.369, mean_episode_step = 1025.9, total_loss = 145.97, pg_loss = 94.689, baseline_loss = 57.066, entropy_loss = -5.7828, learner_queue_size = 32, _tick = 36333, _time = 1.6548e+09, train_seconds = 3.536e+04)
[2022-06-10 05:57:25,250][root][INFO] - Step 135431680 @ 4092.8 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 135431680, mean_episode_return = 83.495, mean_episode_step = 1081.5, total_loss = 7.1908, pg_loss = -37.183, baseline_loss = 50.084, entropy_loss = -5.7103, learner_queue_size = 32, _tick = 36339, _time = 1.6548e+09, train_seconds = 3.5365e+04)
[2022-06-10 05:57:30,254][root][INFO] - Step 135452160 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 135452160, mean_episode_return = -1.3552, mean_episode_step = 860.59, total_loss = 19.124, pg_loss = -20.75, baseline_loss = 45.49, entropy_loss = -5.6163, learner_queue_size = 32, _tick = 36346, _time = 1.6548e+09, train_seconds = 3.537e+04)
[2022-06-10 05:57:35,258][root][INFO] - Step 135470080 @ 3580.9 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 135470080, mean_episode_return = 47.766, mean_episode_step = 1157.4, total_loss = 168.09, pg_loss = 18.331, baseline_loss = 155.48, entropy_loss = -5.7198, learner_queue_size = 32, _tick = 36353, _time = 1.6548e+09, train_seconds = 3.5375e+04)
[2022-06-10 05:57:40,264][root][INFO] - Step 135490560 @ 4091.0 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 135490560, mean_episode_return = 22.3, mean_episode_step = 829.91, total_loss = 441.08, pg_loss = 318.94, baseline_loss = 127.79, entropy_loss = -5.648, learner_queue_size = 32, _tick = 36360, _time = 1.6548e+09, train_seconds = 3.538e+04)
[2022-06-10 05:57:45,270][root][INFO] - Step 135511040 @ 4091.4 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 135511040, mean_episode_return = 20.67, mean_episode_step = 1010.9, total_loss = 199.86, pg_loss = 126.04, baseline_loss = 79.538, entropy_loss = -5.719, learner_queue_size = 32, _tick = 36366, _time = 1.6548e+09, train_seconds = 3.5385e+04)
[2022-06-10 05:57:50,274][root][INFO] - Step 135528960 @ 3581.2 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 135528960, mean_episode_return = 56.233, mean_episode_step = 783.51, total_loss = 179.85, pg_loss = 108.13, baseline_loss = 77.393, entropy_loss = -5.6737, learner_queue_size = 32, _tick = 36372, _time = 1.6548e+09, train_seconds = 3.539e+04)
[2022-06-10 05:57:55,278][root][INFO] - Step 135549440 @ 4092.6 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 135549440, mean_episode_return = 64.455, mean_episode_step = 1016.4, total_loss = 190.88, pg_loss = 127.71, baseline_loss = 68.869, entropy_loss = -5.699, learner_queue_size = 32, _tick = 36377, _time = 1.6548e+09, train_seconds = 3.5395e+04)
[2022-06-10 05:58:00,282][root][INFO] - Step 135569920 @ 4092.8 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 135569920, mean_episode_return = 100.45, mean_episode_step = 680.19, total_loss = -228.43, pg_loss = -249.5, baseline_loss = 26.667, entropy_loss = -5.6002, learner_queue_size = 32, _tick = 36383, _time = 1.6548e+09, train_seconds = 3.54e+04)
[2022-06-10 05:58:05,286][root][INFO] - Step 135587840 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 135587840, mean_episode_return = -1.095, mean_episode_step = 807.45, total_loss = 70.78, pg_loss = -7.2158, baseline_loss = 83.536, entropy_loss = -5.5401, learner_queue_size = 32, _tick = 36389, _time = 1.6548e+09, train_seconds = 3.5405e+04)
[2022-06-10 05:58:10,292][root][INFO] - Step 135608320 @ 4090.8 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 135608320, mean_episode_return = None, mean_episode_step = 969.09, total_loss = 269.84, pg_loss = 208.94, baseline_loss = 66.455, entropy_loss = -5.5529, learner_queue_size = 32, _tick = 36395, _time = 1.6548e+09, train_seconds = 3.541e+04)
[2022-06-10 05:58:15,298][root][INFO] - Step 135626240 @ 3580.0 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 135626240, mean_episode_return = None, mean_episode_step = 793.5, total_loss = 35.62, pg_loss = 1.2903, baseline_loss = 39.68, entropy_loss = -5.3508, learner_queue_size = 32, _tick = 36401, _time = 1.6548e+09, train_seconds = 3.5415e+04)
[2022-06-10 05:58:20,365][root][INFO] - Step 135646720 @ 4041.5 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 135646720, mean_episode_return = None, mean_episode_step = 1037.9, total_loss = 258.89, pg_loss = 196.66, baseline_loss = 67.846, entropy_loss = -5.619, learner_queue_size = 32, _tick = 36407, _time = 1.6548e+09, train_seconds = 3.542e+04)
[2022-06-10 05:58:25,370][root][INFO] - Step 135664640 @ 3580.8 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 135664640, mean_episode_return = 118.7, mean_episode_step = 810.87, total_loss = 130.15, pg_loss = 35.658, baseline_loss = 99.845, entropy_loss = -5.3524, learner_queue_size = 32, _tick = 36411, _time = 1.6548e+09, train_seconds = 3.5425e+04)
[2022-06-10 05:58:30,378][root][INFO] - Step 135685120 @ 4089.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 135685120, mean_episode_return = 38.84, mean_episode_step = 908.95, total_loss = -10.123, pg_loss = -34.214, baseline_loss = 29.702, entropy_loss = -5.6112, learner_queue_size = 32, _tick = 36418, _time = 1.6548e+09, train_seconds = 3.543e+04)
[2022-06-10 05:58:35,382][root][INFO] - Step 135705600 @ 4092.7 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 135705600, mean_episode_return = 22.36, mean_episode_step = 1008.5, total_loss = 172.59, pg_loss = 92.959, baseline_loss = 85.121, entropy_loss = -5.492, learner_queue_size = 32, _tick = 36424, _time = 1.6548e+09, train_seconds = 3.5435e+04)
[2022-06-10 05:58:40,386][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 05:58:40,635][root][INFO] - Step 135723520 @ 3581.3 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (step = 135726080, mean_episode_return = 701.05, mean_episode_step = 1179.3, total_loss = -184.7, pg_loss = -236.99, baseline_loss = 57.943, entropy_loss = -5.6517, learner_queue_size = 32, _tick = 36429, _time = 1.6548e+09, train_seconds = 3.544e+04)
[2022-06-10 05:58:45,638][root][INFO] - Step 135744000 @ 3899.5 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 135744000, mean_episode_return = None, mean_episode_step = 971.03, total_loss = 19.672, pg_loss = -32.482, baseline_loss = 57.866, entropy_loss = -5.712, learner_queue_size = 32, _tick = 36434, _time = 1.6548e+09, train_seconds = 3.5445e+04)
[2022-06-10 05:58:50,642][root][INFO] - Step 135764480 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 135764480, mean_episode_return = 34.658, mean_episode_step = 1006.6, total_loss = 91.043, pg_loss = 39.502, baseline_loss = 57.418, entropy_loss = -5.8772, learner_queue_size = 32, _tick = 36441, _time = 1.6548e+09, train_seconds = 3.545e+04)
[2022-06-10 05:58:55,647][root][INFO] - Step 135784960 @ 4092.2 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 135784960, mean_episode_return = 21.87, mean_episode_step = 998.27, total_loss = 118.48, pg_loss = 73.03, baseline_loss = 51.229, entropy_loss = -5.7824, learner_queue_size = 32, _tick = 36448, _time = 1.6548e+09, train_seconds = 3.5456e+04)
[2022-06-10 05:59:00,650][root][INFO] - Step 135802880 @ 3581.7 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (step = 135802880, mean_episode_return = 77.204, mean_episode_step = 1173.0, total_loss = 170.38, pg_loss = 102.76, baseline_loss = 73.427, entropy_loss = -5.8037, learner_queue_size = 32, _tick = 36454, _time = 1.6548e+09, train_seconds = 3.546e+04)
[2022-06-10 05:59:05,654][root][INFO] - Step 135820800 @ 3581.1 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (step = 135820800, mean_episode_return = 44.291, mean_episode_step = 1063.5, total_loss = -138.12, pg_loss = -147.81, baseline_loss = 15.522, entropy_loss = -5.8276, learner_queue_size = 32, _tick = 36459, _time = 1.6548e+09, train_seconds = 3.5466e+04)
[2022-06-10 05:59:10,658][root][INFO] - Step 135841280 @ 4092.7 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 135841280, mean_episode_return = 128.73, mean_episode_step = 1359.2, total_loss = 186.02, pg_loss = 136.25, baseline_loss = 55.674, entropy_loss = -5.9121, learner_queue_size = 32, _tick = 36467, _time = 1.6548e+09, train_seconds = 3.547e+04)
[2022-06-10 05:59:15,662][root][INFO] - Step 135859200 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 135859200, mean_episode_return = None, mean_episode_step = 827.16, total_loss = -17.539, pg_loss = -35.187, baseline_loss = 23.664, entropy_loss = -6.0161, learner_queue_size = 32, _tick = 36471, _time = 1.6548e+09, train_seconds = 3.5476e+04)
[2022-06-10 05:59:20,668][root][INFO] - Step 135879680 @ 4090.8 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 135879680, mean_episode_return = 85.197, mean_episode_step = 910.57, total_loss = -134.66, pg_loss = -148.34, baseline_loss = 19.602, entropy_loss = -5.9173, learner_queue_size = 32, _tick = 36479, _time = 1.6548e+09, train_seconds = 3.548e+04)
[2022-06-10 05:59:25,674][root][INFO] - Step 135900160 @ 4091.3 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 135900160, mean_episode_return = 48.694, mean_episode_step = 953.06, total_loss = 96.107, pg_loss = 45.87, baseline_loss = 56.219, entropy_loss = -5.9826, learner_queue_size = 32, _tick = 36487, _time = 1.6548e+09, train_seconds = 3.5486e+04)
[2022-06-10 05:59:30,678][root][INFO] - Step 135920640 @ 4092.9 SPS. Inference batcher size: 75. Learner queue size: 32. Other stats: (step = 135920640, mean_episode_return = 38.92, mean_episode_step = 818.41, total_loss = -41.699, pg_loss = -66.355, baseline_loss = 30.577, entropy_loss = -5.9209, learner_queue_size = 32, _tick = 36493, _time = 1.6548e+09, train_seconds = 3.549e+04)
[2022-06-10 05:59:35,685][root][INFO] - Step 135938560 @ 3579.1 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 135938560, mean_episode_return = 46.134, mean_episode_step = 1004.1, total_loss = -191.49, pg_loss = -194.64, baseline_loss = 9.139, entropy_loss = -5.9884, learner_queue_size = 32, _tick = 36500, _time = 1.6548e+09, train_seconds = 3.5496e+04)
[2022-06-10 05:59:40,690][root][INFO] - Step 135959040 @ 4091.8 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 135959040, mean_episode_return = 121.09, mean_episode_step = 713.32, total_loss = 184.48, pg_loss = 134.68, baseline_loss = 55.781, entropy_loss = -5.9725, learner_queue_size = 32, _tick = 36507, _time = 1.6548e+09, train_seconds = 3.55e+04)
[2022-06-10 05:59:45,695][root][INFO] - Step 135979520 @ 4092.0 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 135979520, mean_episode_return = 98.045, mean_episode_step = 915.46, total_loss = 115.04, pg_loss = 55.741, baseline_loss = 65.247, entropy_loss = -5.9473, learner_queue_size = 32, _tick = 36514, _time = 1.6548e+09, train_seconds = 3.5506e+04)
[2022-06-10 05:59:50,698][root][INFO] - Step 135997440 @ 3581.6 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 135997440, mean_episode_return = 12.42, mean_episode_step = 873.82, total_loss = -171.89, pg_loss = -185.56, baseline_loss = 19.61, entropy_loss = -5.9429, learner_queue_size = 32, _tick = 36521, _time = 1.6548e+09, train_seconds = 3.551e+04)
[2022-06-10 05:59:55,702][root][INFO] - Step 136017920 @ 4092.9 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 136017920, mean_episode_return = None, mean_episode_step = 922.91, total_loss = -1.6784, pg_loss = -41.738, baseline_loss = 45.834, entropy_loss = -5.7747, learner_queue_size = 32, _tick = 36528, _time = 1.6548e+09, train_seconds = 3.5516e+04)
[2022-06-10 06:00:00,706][root][INFO] - Step 136035840 @ 3581.2 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 136035840, mean_episode_return = 75.97, mean_episode_step = 863.4, total_loss = 232.95, pg_loss = 191.4, baseline_loss = 47.392, entropy_loss = -5.8466, learner_queue_size = 32, _tick = 36534, _time = 1.6548e+09, train_seconds = 3.552e+04)
[2022-06-10 06:00:05,710][root][INFO] - Step 136056320 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 136056320, mean_episode_return = 23.27, mean_episode_step = 795.03, total_loss = 242.83, pg_loss = 151.63, baseline_loss = 96.971, entropy_loss = -5.7648, learner_queue_size = 32, _tick = 36537, _time = 1.6548e+09, train_seconds = 3.5526e+04)
[2022-06-10 06:00:10,714][root][INFO] - Step 136076800 @ 4092.7 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 136076800, mean_episode_return = 174.05, mean_episode_step = 870.93, total_loss = 7.3379, pg_loss = -24.294, baseline_loss = 37.241, entropy_loss = -5.6091, learner_queue_size = 32, _tick = 36541, _time = 1.6548e+09, train_seconds = 3.553e+04)
[2022-06-10 06:00:15,720][root][INFO] - Step 136094720 @ 3579.7 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 136094720, mean_episode_return = 191.03, mean_episode_step = 1092.9, total_loss = 78.541, pg_loss = 37.217, baseline_loss = 47.001, entropy_loss = -5.6767, learner_queue_size = 32, _tick = 36546, _time = 1.6548e+09, train_seconds = 3.5536e+04)
[2022-06-10 06:00:20,726][root][INFO] - Step 136115200 @ 4091.2 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 136115200, mean_episode_return = None, mean_episode_step = 1193.9, total_loss = -96.617, pg_loss = -108.21, baseline_loss = 17.429, entropy_loss = -5.8388, learner_queue_size = 32, _tick = 36552, _time = 1.6548e+09, train_seconds = 3.554e+04)
[2022-06-10 06:00:25,730][root][INFO] - Step 136135680 @ 4092.7 SPS. Inference batcher size: 97. Learner queue size: 32. Other stats: (step = 136135680, mean_episode_return = 56.49, mean_episode_step = 916.09, total_loss = 31.641, pg_loss = 9.4179, baseline_loss = 28.077, entropy_loss = -5.8538, learner_queue_size = 32, _tick = 36558, _time = 1.6548e+09, train_seconds = 3.5546e+04)
[2022-06-10 06:00:30,734][root][INFO] - Step 136153600 @ 3581.1 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 136153600, mean_episode_return = 20.64, mean_episode_step = 916.47, total_loss = 348.57, pg_loss = 289.95, baseline_loss = 64.629, entropy_loss = -6.0108, learner_queue_size = 32, _tick = 36563, _time = 1.6548e+09, train_seconds = 3.555e+04)
[2022-06-10 06:00:35,738][root][INFO] - Step 136174080 @ 4092.7 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 136174080, mean_episode_return = 56.651, mean_episode_step = 1056.9, total_loss = 54.584, pg_loss = 27.718, baseline_loss = 32.821, entropy_loss = -5.9552, learner_queue_size = 32, _tick = 36571, _time = 1.6548e+09, train_seconds = 3.5556e+04)
[2022-06-10 06:00:40,742][root][INFO] - Step 136192000 @ 3581.2 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 136192000, mean_episode_return = 60.114, mean_episode_step = 1116.4, total_loss = 185.73, pg_loss = 146.12, baseline_loss = 45.491, entropy_loss = -5.8837, learner_queue_size = 32, _tick = 36577, _time = 1.6548e+09, train_seconds = 3.556e+04)
[2022-06-10 06:00:45,746][root][INFO] - Step 136212480 @ 4092.8 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 136212480, mean_episode_return = 27.69, mean_episode_step = 936.21, total_loss = -2.1615, pg_loss = -32.814, baseline_loss = 36.117, entropy_loss = -5.4646, learner_queue_size = 32, _tick = 36584, _time = 1.6548e+09, train_seconds = 3.5566e+04)
[2022-06-10 06:00:50,758][root][INFO] - Step 136230400 @ 3575.4 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (step = 136230400, mean_episode_return = 19.63, mean_episode_step = 906.47, total_loss = 46.033, pg_loss = 4.0665, baseline_loss = 47.495, entropy_loss = -5.529, learner_queue_size = 32, _tick = 36589, _time = 1.6548e+09, train_seconds = 3.5571e+04)
[2022-06-10 06:00:55,770][root][INFO] - Step 136250880 @ 4086.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 136250880, mean_episode_return = 50.574, mean_episode_step = 958.15, total_loss = 128.17, pg_loss = 100.34, baseline_loss = 33.283, entropy_loss = -5.4467, learner_queue_size = 32, _tick = 36594, _time = 1.6548e+09, train_seconds = 3.5576e+04)
[2022-06-10 06:01:00,774][root][INFO] - Step 136268800 @ 3581.2 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 136268800, mean_episode_return = 63.87, mean_episode_step = 1320.5, total_loss = 71.19, pg_loss = 43.323, baseline_loss = 33.533, entropy_loss = -5.666, learner_queue_size = 32, _tick = 36600, _time = 1.6548e+09, train_seconds = 3.5581e+04)
[2022-06-10 06:01:05,778][root][INFO] - Step 136289280 @ 4092.7 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 136289280, mean_episode_return = None, mean_episode_step = 1101.9, total_loss = -40.766, pg_loss = -62.323, baseline_loss = 27.218, entropy_loss = -5.6614, learner_queue_size = 32, _tick = 36605, _time = 1.6548e+09, train_seconds = 3.5586e+04)
[2022-06-10 06:01:10,782][root][INFO] - Step 136309760 @ 4092.7 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 136309760, mean_episode_return = 76.836, mean_episode_step = 1129.8, total_loss = 101.91, pg_loss = 65.316, baseline_loss = 42.54, entropy_loss = -5.9424, learner_queue_size = 32, _tick = 36611, _time = 1.6548e+09, train_seconds = 3.5591e+04)
[2022-06-10 06:01:15,786][root][INFO] - Step 136327680 @ 3581.1 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 136327680, mean_episode_return = 57.379, mean_episode_step = 1014.9, total_loss = 433.19, pg_loss = 362.49, baseline_loss = 76.68, entropy_loss = -5.9801, learner_queue_size = 32, _tick = 36618, _time = 1.6548e+09, train_seconds = 3.5596e+04)
[2022-06-10 06:01:20,790][root][INFO] - Step 136348160 @ 4092.7 SPS. Inference batcher size: 80. Learner queue size: 32. Other stats: (step = 136348160, mean_episode_return = 79.98, mean_episode_step = 932.78, total_loss = 87.201, pg_loss = 57.956, baseline_loss = 35.215, entropy_loss = -5.9701, learner_queue_size = 32, _tick = 36626, _time = 1.6548e+09, train_seconds = 3.5601e+04)
[2022-06-10 06:01:25,794][root][INFO] - Step 136366080 @ 3581.2 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 136366080, mean_episode_return = 66.006, mean_episode_step = 944.26, total_loss = 54.823, pg_loss = 15.926, baseline_loss = 44.682, entropy_loss = -5.7848, learner_queue_size = 32, _tick = 36631, _time = 1.6548e+09, train_seconds = 3.5606e+04)
[2022-06-10 06:01:30,798][root][INFO] - Step 136386560 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 136386560, mean_episode_return = 87.619, mean_episode_step = 931.27, total_loss = 257.59, pg_loss = 187.83, baseline_loss = 75.666, entropy_loss = -5.9068, learner_queue_size = 32, _tick = 36639, _time = 1.6548e+09, train_seconds = 3.5611e+04)
[2022-06-10 06:01:35,802][root][INFO] - Step 136407040 @ 4092.7 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 136407040, mean_episode_return = 28.06, mean_episode_step = 881.12, total_loss = -50.632, pg_loss = -85.363, baseline_loss = 40.363, entropy_loss = -5.6324, learner_queue_size = 32, _tick = 36647, _time = 1.6548e+09, train_seconds = 3.5616e+04)
[2022-06-10 06:01:40,806][root][INFO] - Step 136427520 @ 4092.8 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 136427520, mean_episode_return = 26.81, mean_episode_step = 1090.1, total_loss = 155.33, pg_loss = 107.61, baseline_loss = 53.362, entropy_loss = -5.634, learner_queue_size = 32, _tick = 36654, _time = 1.6548e+09, train_seconds = 3.5621e+04)
[2022-06-10 06:01:45,810][root][INFO] - Step 136445440 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 136445440, mean_episode_return = 146.43, mean_episode_step = 912.24, total_loss = 59.126, pg_loss = 13.633, baseline_loss = 50.994, entropy_loss = -5.5014, learner_queue_size = 32, _tick = 36660, _time = 1.6548e+09, train_seconds = 3.5626e+04)
[2022-06-10 06:01:50,814][root][INFO] - Step 136465920 @ 4092.7 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 136465920, mean_episode_return = 91.15, mean_episode_step = 646.02, total_loss = 238.24, pg_loss = 162.8, baseline_loss = 80.82, entropy_loss = -5.3794, learner_queue_size = 32, _tick = 36666, _time = 1.6548e+09, train_seconds = 3.5631e+04)
[2022-06-10 06:01:55,818][root][INFO] - Step 136483840 @ 3581.1 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 136483840, mean_episode_return = 13.73, mean_episode_step = 970.88, total_loss = 85.228, pg_loss = 40.002, baseline_loss = 51.049, entropy_loss = -5.8227, learner_queue_size = 32, _tick = 36671, _time = 1.6548e+09, train_seconds = 3.5636e+04)
[2022-06-10 06:02:00,822][root][INFO] - Step 136504320 @ 4092.8 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 136504320, mean_episode_return = None, mean_episode_step = 793.88, total_loss = 206.52, pg_loss = 140.61, baseline_loss = 71.677, entropy_loss = -5.7652, learner_queue_size = 32, _tick = 36677, _time = 1.6548e+09, train_seconds = 3.5641e+04)
[2022-06-10 06:02:05,826][root][INFO] - Step 136524800 @ 4092.5 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 136524800, mean_episode_return = 33.43, mean_episode_step = 877.74, total_loss = 61.789, pg_loss = 3.9823, baseline_loss = 63.419, entropy_loss = -5.6123, learner_queue_size = 32, _tick = 36683, _time = 1.6548e+09, train_seconds = 3.5646e+04)
[2022-06-10 06:02:10,830][root][INFO] - Step 136542720 @ 3581.0 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (step = 136542720, mean_episode_return = None, mean_episode_step = 1063.9, total_loss = 87.477, pg_loss = 53.319, baseline_loss = 39.989, entropy_loss = -5.8309, learner_queue_size = 32, _tick = 36688, _time = 1.6548e+09, train_seconds = 3.5651e+04)
[2022-06-10 06:02:15,834][root][INFO] - Step 136560640 @ 3581.4 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 136560640, mean_episode_return = 43.895, mean_episode_step = 896.63, total_loss = -103.24, pg_loss = -131.45, baseline_loss = 33.887, entropy_loss = -5.6793, learner_queue_size = 32, _tick = 36695, _time = 1.6548e+09, train_seconds = 3.5656e+04)
[2022-06-10 06:02:20,838][root][INFO] - Step 136581120 @ 4092.8 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 136581120, mean_episode_return = 120.67, mean_episode_step = 879.69, total_loss = -69.131, pg_loss = -89.156, baseline_loss = 25.879, entropy_loss = -5.8542, learner_queue_size = 32, _tick = 36701, _time = 1.6548e+09, train_seconds = 3.5661e+04)
[2022-06-10 06:02:25,842][root][INFO] - Step 136601600 @ 4092.8 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 136601600, mean_episode_return = None, mean_episode_step = 931.38, total_loss = 204.71, pg_loss = 129.65, baseline_loss = 80.991, entropy_loss = -5.9375, learner_queue_size = 32, _tick = 36707, _time = 1.6548e+09, train_seconds = 3.5666e+04)
[2022-06-10 06:02:30,846][root][INFO] - Step 136619520 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 136619520, mean_episode_return = 78.88, mean_episode_step = 905.86, total_loss = -4.8473, pg_loss = -35.748, baseline_loss = 36.713, entropy_loss = -5.8115, learner_queue_size = 32, _tick = 36713, _time = 1.6548e+09, train_seconds = 3.5671e+04)
[2022-06-10 06:02:35,850][root][INFO] - Step 136640000 @ 4092.8 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 136640000, mean_episode_return = 68.83, mean_episode_step = 1021.3, total_loss = 186.83, pg_loss = 89.265, baseline_loss = 103.39, entropy_loss = -5.8251, learner_queue_size = 32, _tick = 36721, _time = 1.6548e+09, train_seconds = 3.5676e+04)
[2022-06-10 06:02:40,854][root][INFO] - Step 136660480 @ 4092.7 SPS. Inference batcher size: 73. Learner queue size: 32. Other stats: (step = 136660480, mean_episode_return = 2.9198, mean_episode_step = 722.25, total_loss = 355.17, pg_loss = 256.68, baseline_loss = 104.21, entropy_loss = -5.7143, learner_queue_size = 32, _tick = 36726, _time = 1.6548e+09, train_seconds = 3.5681e+04)
[2022-06-10 06:02:45,858][root][INFO] - Step 136678400 @ 3581.2 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 136678400, mean_episode_return = 56.131, mean_episode_step = 900.01, total_loss = 212.13, pg_loss = 124.32, baseline_loss = 93.484, entropy_loss = -5.6801, learner_queue_size = 32, _tick = 36733, _time = 1.6548e+09, train_seconds = 3.5686e+04)
[2022-06-10 06:02:50,862][root][INFO] - Step 136696320 @ 3581.1 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 136696320, mean_episode_return = 56.647, mean_episode_step = 954.44, total_loss = -9.8319, pg_loss = -35.643, baseline_loss = 31.8, entropy_loss = -5.9889, learner_queue_size = 32, _tick = 36738, _time = 1.6548e+09, train_seconds = 3.5691e+04)
[2022-06-10 06:02:55,866][root][INFO] - Step 136716800 @ 4092.8 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 136716800, mean_episode_return = 60.455, mean_episode_step = 792.95, total_loss = -46.46, pg_loss = -81.746, baseline_loss = 41.181, entropy_loss = -5.8956, learner_queue_size = 32, _tick = 36744, _time = 1.6548e+09, train_seconds = 3.5696e+04)
[2022-06-10 06:03:00,870][root][INFO] - Step 136734720 @ 3581.1 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 136734720, mean_episode_return = None, mean_episode_step = 1024.2, total_loss = 416.9, pg_loss = 292.78, baseline_loss = 130.01, entropy_loss = -5.8869, learner_queue_size = 32, _tick = 36749, _time = 1.6548e+09, train_seconds = 3.5701e+04)
[2022-06-10 06:03:05,874][root][INFO] - Step 136755200 @ 4092.7 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 136755200, mean_episode_return = None, mean_episode_step = 1124.5, total_loss = 421.33, pg_loss = 325.21, baseline_loss = 102.01, entropy_loss = -5.8878, learner_queue_size = 32, _tick = 36754, _time = 1.6548e+09, train_seconds = 3.5706e+04)
[2022-06-10 06:03:10,878][root][INFO] - Step 136773120 @ 3581.2 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 136773120, mean_episode_return = 72.07, mean_episode_step = 1012.2, total_loss = -33.84, pg_loss = -54.269, baseline_loss = 26.177, entropy_loss = -5.7478, learner_queue_size = 32, _tick = 36761, _time = 1.6548e+09, train_seconds = 3.5711e+04)
[2022-06-10 06:03:15,882][root][INFO] - Step 136793600 @ 4092.7 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (step = 136793600, mean_episode_return = 96.25, mean_episode_step = 966.08, total_loss = 55.337, pg_loss = 2.5816, baseline_loss = 58.359, entropy_loss = -5.6033, learner_queue_size = 32, _tick = 36767, _time = 1.6548e+09, train_seconds = 3.5716e+04)
[2022-06-10 06:03:20,886][root][INFO] - Step 136814080 @ 4092.7 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 136814080, mean_episode_return = 61.425, mean_episode_step = 981.81, total_loss = -172.14, pg_loss = -189.12, baseline_loss = 22.692, entropy_loss = -5.7055, learner_queue_size = 32, _tick = 36771, _time = 1.6548e+09, train_seconds = 3.5721e+04)
[2022-06-10 06:03:25,891][root][INFO] - Step 136834560 @ 4091.8 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 136834560, mean_episode_return = None, mean_episode_step = 1013.9, total_loss = -22.963, pg_loss = -36.757, baseline_loss = 19.591, entropy_loss = -5.7974, learner_queue_size = 32, _tick = 36775, _time = 1.6548e+09, train_seconds = 3.5726e+04)
[2022-06-10 06:03:30,894][root][INFO] - Step 136852480 @ 3581.9 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 136852480, mean_episode_return = 52.579, mean_episode_step = 1029.2, total_loss = 271.77, pg_loss = 220.17, baseline_loss = 57.449, entropy_loss = -5.8506, learner_queue_size = 32, _tick = 36780, _time = 1.6548e+09, train_seconds = 3.5731e+04)
[2022-06-10 06:03:35,898][root][INFO] - Step 136870400 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 136870400, mean_episode_return = 35.411, mean_episode_step = 961.48, total_loss = 44.745, pg_loss = 8.0559, baseline_loss = 42.366, entropy_loss = -5.6772, learner_queue_size = 32, _tick = 36785, _time = 1.6548e+09, train_seconds = 3.5736e+04)
[2022-06-10 06:03:40,902][root][INFO] - Step 136890880 @ 4092.8 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 136890880, mean_episode_return = 11.09, mean_episode_step = 1049.9, total_loss = 139.9, pg_loss = 64.871, baseline_loss = 80.739, entropy_loss = -5.7134, learner_queue_size = 32, _tick = 36791, _time = 1.6548e+09, train_seconds = 3.5741e+04)
[2022-06-10 06:03:45,906][root][INFO] - Step 136911360 @ 4092.7 SPS. Inference batcher size: 80. Learner queue size: 32. Other stats: (step = 136911360, mean_episode_return = 45.775, mean_episode_step = 1010.3, total_loss = 217.74, pg_loss = 135.49, baseline_loss = 88.032, entropy_loss = -5.7786, learner_queue_size = 32, _tick = 36797, _time = 1.6548e+09, train_seconds = 3.5746e+04)
[2022-06-10 06:03:50,910][root][INFO] - Step 136931840 @ 4092.7 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 136931840, mean_episode_return = 141.42, mean_episode_step = 1118.0, total_loss = 61.505, pg_loss = 15.262, baseline_loss = 51.859, entropy_loss = -5.6161, learner_queue_size = 32, _tick = 36801, _time = 1.6548e+09, train_seconds = 3.5751e+04)
[2022-06-10 06:03:55,914][root][INFO] - Step 136949760 @ 3581.1 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 136949760, mean_episode_return = -7.4301, mean_episode_step = 865.26, total_loss = 58.05, pg_loss = 23.098, baseline_loss = 40.453, entropy_loss = -5.5019, learner_queue_size = 32, _tick = 36806, _time = 1.6548e+09, train_seconds = 3.5756e+04)
[2022-06-10 06:04:00,917][root][INFO] - Step 136970240 @ 4093.2 SPS. Inference batcher size: 79. Learner queue size: 32. Other stats: (step = 136970240, mean_episode_return = 21.73, mean_episode_step = 1028.8, total_loss = -22.61, pg_loss = -55.869, baseline_loss = 39.06, entropy_loss = -5.8011, learner_queue_size = 32, _tick = 36813, _time = 1.6548e+09, train_seconds = 3.5761e+04)
[2022-06-10 06:04:05,928][root][INFO] - Step 136990720 @ 4087.4 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 136990720, mean_episode_return = None, mean_episode_step = 1137.3, total_loss = 100.55, pg_loss = 58.818, baseline_loss = 47.563, entropy_loss = -5.8267, learner_queue_size = 32, _tick = 36817, _time = 1.6548e+09, train_seconds = 3.5766e+04)
[2022-06-10 06:04:10,930][root][INFO] - Step 137011200 @ 4094.3 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (step = 137011200, mean_episode_return = None, mean_episode_step = 748.78, total_loss = 114.61, pg_loss = 77.786, baseline_loss = 42.489, entropy_loss = -5.6643, learner_queue_size = 32, _tick = 36824, _time = 1.6548e+09, train_seconds = 3.5771e+04)
[2022-06-10 06:04:15,934][root][INFO] - Step 137029120 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 137029120, mean_episode_return = None, mean_episode_step = 942.06, total_loss = 116.69, pg_loss = 63.413, baseline_loss = 59.017, entropy_loss = -5.7401, learner_queue_size = 32, _tick = 36830, _time = 1.6548e+09, train_seconds = 3.5776e+04)
[2022-06-10 06:04:20,938][root][INFO] - Step 137049600 @ 4092.8 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 137049600, mean_episode_return = 86.11, mean_episode_step = 826.82, total_loss = -81.098, pg_loss = -104.81, baseline_loss = 29.353, entropy_loss = -5.6423, learner_queue_size = 32, _tick = 36838, _time = 1.6548e+09, train_seconds = 3.5781e+04)
[2022-06-10 06:04:25,942][root][INFO] - Step 137070080 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 137070080, mean_episode_return = 61.87, mean_episode_step = 924.78, total_loss = 11.664, pg_loss = -20.868, baseline_loss = 38.365, entropy_loss = -5.8331, learner_queue_size = 32, _tick = 36844, _time = 1.6548e+09, train_seconds = 3.5786e+04)
[2022-06-10 06:04:30,946][root][INFO] - Step 137088000 @ 3581.1 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (step = 137088000, mean_episode_return = 111.2, mean_episode_step = 819.81, total_loss = 137.54, pg_loss = 112.04, baseline_loss = 31.308, entropy_loss = -5.8061, learner_queue_size = 32, _tick = 36849, _time = 1.6548e+09, train_seconds = 3.5791e+04)
[2022-06-10 06:04:35,950][root][INFO] - Step 137108480 @ 4092.7 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 137108480, mean_episode_return = 66.135, mean_episode_step = 1041.8, total_loss = -17.146, pg_loss = -33.808, baseline_loss = 22.452, entropy_loss = -5.7892, learner_queue_size = 32, _tick = 36856, _time = 1.6548e+09, train_seconds = 3.5796e+04)
[2022-06-10 06:04:40,954][root][INFO] - Step 137126400 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 137126400, mean_episode_return = 75.055, mean_episode_step = 990.86, total_loss = 366.97, pg_loss = 284.49, baseline_loss = 88.102, entropy_loss = -5.6201, learner_queue_size = 32, _tick = 36861, _time = 1.6548e+09, train_seconds = 3.5801e+04)
[2022-06-10 06:04:45,958][root][INFO] - Step 137146880 @ 4092.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 137146880, mean_episode_return = 13.35, mean_episode_step = 993.67, total_loss = -107.5, pg_loss = -121.3, baseline_loss = 19.312, entropy_loss = -5.516, learner_queue_size = 32, _tick = 36866, _time = 1.6548e+09, train_seconds = 3.5806e+04)
[2022-06-10 06:04:50,963][root][INFO] - Step 137167360 @ 4091.5 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 137167360, mean_episode_return = 65.15, mean_episode_step = 883.56, total_loss = 66.537, pg_loss = 29.231, baseline_loss = 43.031, entropy_loss = -5.7256, learner_queue_size = 32, _tick = 36871, _time = 1.6548e+09, train_seconds = 3.5811e+04)
[2022-06-10 06:04:55,966][root][INFO] - Step 137185280 @ 3582.2 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 137185280, mean_episode_return = 34.704, mean_episode_step = 1059.9, total_loss = 148.39, pg_loss = 107.05, baseline_loss = 47.179, entropy_loss = -5.844, learner_queue_size = 32, _tick = 36877, _time = 1.6548e+09, train_seconds = 3.5816e+04)
[2022-06-10 06:05:00,970][root][INFO] - Step 137205760 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 137205760, mean_episode_return = 61.375, mean_episode_step = 957.98, total_loss = 87.473, pg_loss = 33.844, baseline_loss = 59.514, entropy_loss = -5.8845, learner_queue_size = 32, _tick = 36884, _time = 1.6548e+09, train_seconds = 3.5821e+04)
[2022-06-10 06:05:05,974][root][INFO] - Step 137223680 @ 3581.1 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 137223680, mean_episode_return = 13.763, mean_episode_step = 840.28, total_loss = -155.59, pg_loss = -163.54, baseline_loss = 13.79, entropy_loss = -5.8402, learner_queue_size = 32, _tick = 36889, _time = 1.6548e+09, train_seconds = 3.5826e+04)
[2022-06-10 06:05:10,978][root][INFO] - Step 137244160 @ 4092.8 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (step = 137244160, mean_episode_return = 33.81, mean_episode_step = 875.06, total_loss = 80.211, pg_loss = 24.003, baseline_loss = 62.017, entropy_loss = -5.809, learner_queue_size = 32, _tick = 36897, _time = 1.6548e+09, train_seconds = 3.5831e+04)
[2022-06-10 06:05:15,982][root][INFO] - Step 137262080 @ 3581.2 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 137262080, mean_episode_return = -11.05, mean_episode_step = 882.03, total_loss = 185.42, pg_loss = 138.9, baseline_loss = 52.352, entropy_loss = -5.8253, learner_queue_size = 32, _tick = 36903, _time = 1.6548e+09, train_seconds = 3.5836e+04)
[2022-06-10 06:05:20,986][root][INFO] - Step 137282560 @ 4092.7 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 137282560, mean_episode_return = 52.765, mean_episode_step = 935.2, total_loss = 111.37, pg_loss = 76.193, baseline_loss = 40.919, entropy_loss = -5.7373, learner_queue_size = 32, _tick = 36910, _time = 1.6548e+09, train_seconds = 3.5841e+04)
[2022-06-10 06:05:25,990][root][INFO] - Step 137303040 @ 4092.6 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 137303040, mean_episode_return = 37.222, mean_episode_step = 859.49, total_loss = 106.86, pg_loss = 65.38, baseline_loss = 47.233, entropy_loss = -5.7553, learner_queue_size = 32, _tick = 36918, _time = 1.6548e+09, train_seconds = 3.5846e+04)
[2022-06-10 06:05:30,997][root][INFO] - Step 137323520 @ 4090.8 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (step = 137323520, mean_episode_return = -14.58, mean_episode_step = 940.03, total_loss = 276.42, pg_loss = 191.86, baseline_loss = 90.255, entropy_loss = -5.7008, learner_queue_size = 32, _tick = 36926, _time = 1.6548e+09, train_seconds = 3.5851e+04)
[2022-06-10 06:05:36,004][root][INFO] - Step 137341440 @ 3579.0 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 137341440, mean_episode_return = 39.24, mean_episode_step = 778.76, total_loss = -240.46, pg_loss = -260.45, baseline_loss = 25.771, entropy_loss = -5.782, learner_queue_size = 32, _tick = 36929, _time = 1.6548e+09, train_seconds = 3.5856e+04)
[2022-06-10 06:05:41,006][root][INFO] - Step 137361920 @ 4094.0 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 137361920, mean_episode_return = None, mean_episode_step = 897.31, total_loss = -66.897, pg_loss = -100.57, baseline_loss = 39.547, entropy_loss = -5.8743, learner_queue_size = 32, _tick = 36934, _time = 1.6548e+09, train_seconds = 3.5861e+04)
[2022-06-10 06:05:46,010][root][INFO] - Step 137379840 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 137379840, mean_episode_return = 121.88, mean_episode_step = 1069.4, total_loss = 159.51, pg_loss = 113.15, baseline_loss = 52.226, entropy_loss = -5.8665, learner_queue_size = 32, _tick = 36939, _time = 1.6548e+09, train_seconds = 3.5866e+04)
[2022-06-10 06:05:51,014][root][INFO] - Step 137400320 @ 4092.7 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 137400320, mean_episode_return = 39.816, mean_episode_step = 796.73, total_loss = -3.0466, pg_loss = -20.681, baseline_loss = 23.56, entropy_loss = -5.9258, learner_queue_size = 32, _tick = 36946, _time = 1.6548e+09, train_seconds = 3.5871e+04)
[2022-06-10 06:05:56,018][root][INFO] - Step 137420800 @ 4092.7 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 137420800, mean_episode_return = 11.44, mean_episode_step = 923.71, total_loss = 145.51, pg_loss = 82.097, baseline_loss = 69.386, entropy_loss = -5.9751, learner_queue_size = 32, _tick = 36954, _time = 1.6548e+09, train_seconds = 3.5876e+04)
[2022-06-10 06:06:01,024][root][INFO] - Step 137438720 @ 3579.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 137438720, mean_episode_return = 64.82, mean_episode_step = 987.2, total_loss = -132.98, pg_loss = -142.54, baseline_loss = 15.67, entropy_loss = -6.1086, learner_queue_size = 32, _tick = 36961, _time = 1.6548e+09, train_seconds = 3.5881e+04)
[2022-06-10 06:06:06,030][root][INFO] - Step 137459200 @ 4091.2 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 137459200, mean_episode_return = 95.871, mean_episode_step = 816.73, total_loss = -88.759, pg_loss = -108.39, baseline_loss = 25.696, entropy_loss = -6.0652, learner_queue_size = 32, _tick = 36968, _time = 1.6548e+09, train_seconds = 3.5886e+04)
[2022-06-10 06:06:11,034][root][INFO] - Step 137477120 @ 3581.2 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 137477120, mean_episode_return = 2.25, mean_episode_step = 1143.5, total_loss = 109.07, pg_loss = 56.743, baseline_loss = 58.391, entropy_loss = -6.0673, learner_queue_size = 32, _tick = 36974, _time = 1.6548e+09, train_seconds = 3.5891e+04)
[2022-06-10 06:06:16,038][root][INFO] - Step 137497600 @ 4092.7 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 137497600, mean_episode_return = 2.35, mean_episode_step = 998.76, total_loss = 147.28, pg_loss = 86.968, baseline_loss = 66.305, entropy_loss = -5.9887, learner_queue_size = 32, _tick = 36980, _time = 1.6548e+09, train_seconds = 3.5896e+04)
[2022-06-10 06:06:21,042][root][INFO] - Step 137515520 @ 3581.2 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 137515520, mean_episode_return = 63.235, mean_episode_step = 811.89, total_loss = -33.249, pg_loss = -66.948, baseline_loss = 39.552, entropy_loss = -5.854, learner_queue_size = 32, _tick = 36986, _time = 1.6548e+09, train_seconds = 3.5901e+04)
[2022-06-10 06:06:26,046][root][INFO] - Step 137536000 @ 4092.7 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 137536000, mean_episode_return = 103.46, mean_episode_step = 869.48, total_loss = -86.595, pg_loss = -132.84, baseline_loss = 52.056, entropy_loss = -5.8155, learner_queue_size = 32, _tick = 36994, _time = 1.6548e+09, train_seconds = 3.5906e+04)
[2022-06-10 06:06:31,050][root][INFO] - Step 137556480 @ 4092.7 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (step = 137556480, mean_episode_return = 4.1996, mean_episode_step = 849.06, total_loss = -118.84, pg_loss = -156.02, baseline_loss = 43.018, entropy_loss = -5.8319, learner_queue_size = 32, _tick = 37001, _time = 1.6548e+09, train_seconds = 3.5911e+04)
[2022-06-10 06:06:36,054][root][INFO] - Step 137576960 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 137576960, mean_episode_return = None, mean_episode_step = 824.69, total_loss = 141.26, pg_loss = 72.664, baseline_loss = 74.484, entropy_loss = -5.8902, learner_queue_size = 32, _tick = 37007, _time = 1.6548e+09, train_seconds = 3.5916e+04)
[2022-06-10 06:06:41,058][root][INFO] - Step 137594880 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 137594880, mean_episode_return = 53.924, mean_episode_step = 925.19, total_loss = -185.83, pg_loss = -192.76, baseline_loss = 12.947, entropy_loss = -6.0185, learner_queue_size = 32, _tick = 37013, _time = 1.6548e+09, train_seconds = 3.5921e+04)
[2022-06-10 06:06:46,062][root][INFO] - Step 137615360 @ 4092.8 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 137615360, mean_episode_return = None, mean_episode_step = 913.41, total_loss = -8.2151, pg_loss = -35.597, baseline_loss = 33.136, entropy_loss = -5.7541, learner_queue_size = 32, _tick = 37017, _time = 1.6548e+09, train_seconds = 3.5926e+04)
[2022-06-10 06:06:51,066][root][INFO] - Step 137635840 @ 4092.6 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 137635840, mean_episode_return = None, mean_episode_step = 1047.0, total_loss = 62.619, pg_loss = 45.647, baseline_loss = 23.048, entropy_loss = -6.076, learner_queue_size = 32, _tick = 37022, _time = 1.6548e+09, train_seconds = 3.5931e+04)
[2022-06-10 06:06:56,070][root][INFO] - Step 137653760 @ 3581.2 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 137653760, mean_episode_return = None, mean_episode_step = 994.78, total_loss = 436.56, pg_loss = 358.62, baseline_loss = 84.017, entropy_loss = -6.0755, learner_queue_size = 32, _tick = 37026, _time = 1.6548e+09, train_seconds = 3.5936e+04)
[2022-06-10 06:07:01,074][root][INFO] - Step 137674240 @ 4092.8 SPS. Inference batcher size: 75. Learner queue size: 32. Other stats: (step = 137674240, mean_episode_return = None, mean_episode_step = 936.47, total_loss = 344.81, pg_loss = 258.27, baseline_loss = 92.577, entropy_loss = -6.0441, learner_queue_size = 32, _tick = 37030, _time = 1.6548e+09, train_seconds = 3.5941e+04)
[2022-06-10 06:07:06,078][root][INFO] - Step 137692160 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 137692160, mean_episode_return = 32.05, mean_episode_step = 1024.4, total_loss = -74.501, pg_loss = -84.541, baseline_loss = 16.001, entropy_loss = -5.9612, learner_queue_size = 32, _tick = 37036, _time = 1.6548e+09, train_seconds = 3.5946e+04)
[2022-06-10 06:07:11,082][root][INFO] - Step 137712640 @ 4092.6 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 137712640, mean_episode_return = 23.53, mean_episode_step = 1070.9, total_loss = 413.51, pg_loss = 319.9, baseline_loss = 99.454, entropy_loss = -5.8431, learner_queue_size = 32, _tick = 37041, _time = 1.6548e+09, train_seconds = 3.5951e+04)
[2022-06-10 06:07:16,088][root][INFO] - Step 137730560 @ 3579.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 137730560, mean_episode_return = None, mean_episode_step = 1010.8, total_loss = 423.93, pg_loss = 336.51, baseline_loss = 93.208, entropy_loss = -5.7854, learner_queue_size = 32, _tick = 37045, _time = 1.6548e+09, train_seconds = 3.5956e+04)
[2022-06-10 06:07:21,090][root][INFO] - Step 137751040 @ 4094.4 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 137751040, mean_episode_return = 9.7297, mean_episode_step = 1266.0, total_loss = -98.888, pg_loss = -112.07, baseline_loss = 19.122, entropy_loss = -5.9405, learner_queue_size = 32, _tick = 37051, _time = 1.6548e+09, train_seconds = 3.5961e+04)
[2022-06-10 06:07:26,094][root][INFO] - Step 137768960 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 137768960, mean_episode_return = 4.6397, mean_episode_step = 1159.7, total_loss = 18.923, pg_loss = -11.697, baseline_loss = 36.697, entropy_loss = -6.078, learner_queue_size = 32, _tick = 37058, _time = 1.6548e+09, train_seconds = 3.5966e+04)
[2022-06-10 06:07:31,098][root][INFO] - Step 137789440 @ 4092.8 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 137789440, mean_episode_return = 45.024, mean_episode_step = 1112.6, total_loss = 200.21, pg_loss = 149.05, baseline_loss = 57.067, entropy_loss = -5.9037, learner_queue_size = 32, _tick = 37065, _time = 1.6548e+09, train_seconds = 3.5971e+04)
[2022-06-10 06:07:36,102][root][INFO] - Step 137809920 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 137809920, mean_episode_return = 39.055, mean_episode_step = 796.32, total_loss = 263.04, pg_loss = 111.53, baseline_loss = 157.46, entropy_loss = -5.9473, learner_queue_size = 32, _tick = 37071, _time = 1.6548e+09, train_seconds = 3.5976e+04)
[2022-06-10 06:07:41,106][root][INFO] - Step 137827840 @ 3581.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 137827840, mean_episode_return = None, mean_episode_step = 1011.2, total_loss = 319.86, pg_loss = 232.63, baseline_loss = 93.107, entropy_loss = -5.8763, learner_queue_size = 32, _tick = 37076, _time = 1.6548e+09, train_seconds = 3.5981e+04)
[2022-06-10 06:07:46,110][root][INFO] - Step 137848320 @ 4092.8 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 137848320, mean_episode_return = 57.361, mean_episode_step = 908.62, total_loss = 112.73, pg_loss = 66.328, baseline_loss = 52.163, entropy_loss = -5.7621, learner_queue_size = 32, _tick = 37082, _time = 1.6548e+09, train_seconds = 3.5986e+04)
[2022-06-10 06:07:51,114][root][INFO] - Step 137868800 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 137868800, mean_episode_return = None, mean_episode_step = 936.69, total_loss = 121.45, pg_loss = 87.373, baseline_loss = 39.747, entropy_loss = -5.667, learner_queue_size = 32, _tick = 37089, _time = 1.6548e+09, train_seconds = 3.5991e+04)
[2022-06-10 06:07:56,118][root][INFO] - Step 137886720 @ 3580.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 137886720, mean_episode_return = 12.14, mean_episode_step = 1033.7, total_loss = -0.0063019, pg_loss = -37.671, baseline_loss = 43.435, entropy_loss = -5.7707, learner_queue_size = 32, _tick = 37093, _time = 1.6548e+09, train_seconds = 3.5996e+04)
[2022-06-10 06:08:01,122][root][INFO] - Step 137907200 @ 4093.2 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 137907200, mean_episode_return = 77.455, mean_episode_step = 1181.4, total_loss = 74.522, pg_loss = 42.266, baseline_loss = 38.11, entropy_loss = -5.8541, learner_queue_size = 32, _tick = 37100, _time = 1.6548e+09, train_seconds = 3.6001e+04)
[2022-06-10 06:08:06,128][root][INFO] - Step 137927680 @ 4091.0 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 137927680, mean_episode_return = 37.625, mean_episode_step = 1192.2, total_loss = -144.05, pg_loss = -201.88, baseline_loss = 63.656, entropy_loss = -5.8267, learner_queue_size = 32, _tick = 37104, _time = 1.6548e+09, train_seconds = 3.6006e+04)
[2022-06-10 06:08:11,134][root][INFO] - Step 137948160 @ 4091.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 137948160, mean_episode_return = None, mean_episode_step = 988.91, total_loss = 97.71, pg_loss = 49.476, baseline_loss = 54.067, entropy_loss = -5.8336, learner_queue_size = 32, _tick = 37109, _time = 1.6548e+09, train_seconds = 3.6011e+04)
[2022-06-10 06:08:16,138][root][INFO] - Step 137966080 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 137966080, mean_episode_return = 49.297, mean_episode_step = 1025.5, total_loss = 469.23, pg_loss = 334.9, baseline_loss = 140.15, entropy_loss = -5.8209, learner_queue_size = 32, _tick = 37116, _time = 1.6548e+09, train_seconds = 3.6016e+04)
[2022-06-10 06:08:21,144][root][INFO] - Step 137986560 @ 4091.3 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (step = 137986560, mean_episode_return = 34.345, mean_episode_step = 1011.1, total_loss = 174.55, pg_loss = 121.3, baseline_loss = 58.985, entropy_loss = -5.7398, learner_queue_size = 32, _tick = 37124, _time = 1.6548e+09, train_seconds = 3.6021e+04)
[2022-06-10 06:08:26,150][root][INFO] - Step 138004480 @ 3579.4 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 138004480, mean_episode_return = 46.27, mean_episode_step = 1139.5, total_loss = -39.623, pg_loss = -75.155, baseline_loss = 41.281, entropy_loss = -5.7479, learner_queue_size = 32, _tick = 37130, _time = 1.6548e+09, train_seconds = 3.6026e+04)
[2022-06-10 06:08:31,154][root][INFO] - Step 138024960 @ 4092.7 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 138024960, mean_episode_return = 47.42, mean_episode_step = 840.31, total_loss = 90.586, pg_loss = 52.99, baseline_loss = 43.365, entropy_loss = -5.7686, learner_queue_size = 32, _tick = 37138, _time = 1.6548e+09, train_seconds = 3.6031e+04)
[2022-06-10 06:08:36,158][root][INFO] - Step 138042880 @ 3581.2 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 138042880, mean_episode_return = None, mean_episode_step = 918.16, total_loss = 85.012, pg_loss = 50.3, baseline_loss = 40.339, entropy_loss = -5.6273, learner_queue_size = 32, _tick = 37143, _time = 1.6548e+09, train_seconds = 3.6036e+04)
[2022-06-10 06:08:41,162][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 06:08:41,286][root][INFO] - Step 138063360 @ 4092.7 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 138063360, mean_episode_return = -18.01, mean_episode_step = 1006.2, total_loss = -127.09, pg_loss = -163.83, baseline_loss = 42.367, entropy_loss = -5.6251, learner_queue_size = 32, _tick = 37149, _time = 1.6548e+09, train_seconds = 3.6041e+04)
[2022-06-10 06:08:46,290][root][INFO] - Step 138083840 @ 3993.8 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 138083840, mean_episode_return = None, mean_episode_step = 908.59, total_loss = 102.54, pg_loss = 46.945, baseline_loss = 61.13, entropy_loss = -5.5374, learner_queue_size = 32, _tick = 37154, _time = 1.6548e+09, train_seconds = 3.6046e+04)
[2022-06-10 06:08:51,294][root][INFO] - Step 138104320 @ 4092.5 SPS. Inference batcher size: 90. Learner queue size: 32. Other stats: (step = 138104320, mean_episode_return = 34.81, mean_episode_step = 1034.4, total_loss = 77.036, pg_loss = 43.241, baseline_loss = 39.415, entropy_loss = -5.6209, learner_queue_size = 32, _tick = 37161, _time = 1.6548e+09, train_seconds = 3.6051e+04)
[2022-06-10 06:08:56,301][root][INFO] - Step 138122240 @ 3579.3 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 138122240, mean_episode_return = 86.94, mean_episode_step = 1101.9, total_loss = 48.378, pg_loss = 15.94, baseline_loss = 38.11, entropy_loss = -5.6721, learner_queue_size = 32, _tick = 37168, _time = 1.6548e+09, train_seconds = 3.6056e+04)
[2022-06-10 06:09:01,306][root][INFO] - Step 138142720 @ 4091.7 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 138142720, mean_episode_return = 2.4796, mean_episode_step = 943.93, total_loss = -39.101, pg_loss = -44.974, baseline_loss = 11.754, entropy_loss = -5.8802, learner_queue_size = 32, _tick = 37176, _time = 1.6548e+09, train_seconds = 3.6061e+04)
[2022-06-10 06:09:06,310][root][INFO] - Step 138160640 @ 3581.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 138160640, mean_episode_return = -3.9503, mean_episode_step = 1060.1, total_loss = -95.13, pg_loss = -101.54, baseline_loss = 12.265, entropy_loss = -5.853, learner_queue_size = 32, _tick = 37182, _time = 1.6548e+09, train_seconds = 3.6066e+04)
[2022-06-10 06:09:11,314][root][INFO] - Step 138181120 @ 4092.8 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 138181120, mean_episode_return = 6.4473, mean_episode_step = 892.61, total_loss = -135.99, pg_loss = -158.7, baseline_loss = 28.549, entropy_loss = -5.8395, learner_queue_size = 32, _tick = 37187, _time = 1.6548e+09, train_seconds = 3.6071e+04)
[2022-06-10 06:09:16,318][root][INFO] - Step 138199040 @ 3581.0 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 138199040, mean_episode_return = None, mean_episode_step = 1007.6, total_loss = 87.819, pg_loss = 41.606, baseline_loss = 52.099, entropy_loss = -5.8858, learner_queue_size = 32, _tick = 37193, _time = 1.6548e+09, train_seconds = 3.6076e+04)
[2022-06-10 06:09:21,322][root][INFO] - Step 138219520 @ 4092.8 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 138219520, mean_episode_return = None, mean_episode_step = 958.78, total_loss = 30.544, pg_loss = 2.3494, baseline_loss = 33.964, entropy_loss = -5.7702, learner_queue_size = 32, _tick = 37200, _time = 1.6548e+09, train_seconds = 3.6081e+04)
[2022-06-10 06:09:26,326][root][INFO] - Step 138240000 @ 4092.7 SPS. Inference batcher size: 0. Learner queue size: 14. Other stats: (step = 138240000, mean_episode_return = 33.72, mean_episode_step = 995.34, total_loss = 49.404, pg_loss = 3.8208, baseline_loss = 51.352, entropy_loss = -5.7694, learner_queue_size = 32, _tick = 37207, _time = 1.6548e+09, train_seconds = 3.6086e+04)
[2022-06-10 06:09:31,334][root][INFO] - Step 138257920 @ 3578.3 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 138257920, mean_episode_return = 40.777, mean_episode_step = 897.77, total_loss = 84.787, pg_loss = 38.895, baseline_loss = 51.51, entropy_loss = -5.617, learner_queue_size = 32, _tick = 37212, _time = 1.6548e+09, train_seconds = 3.6091e+04)
[2022-06-10 06:09:36,338][root][INFO] - Step 138278400 @ 4092.8 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 138278400, mean_episode_return = -6.3601, mean_episode_step = 955.0, total_loss = 11.843, pg_loss = -64.216, baseline_loss = 81.692, entropy_loss = -5.6335, learner_queue_size = 32, _tick = 37219, _time = 1.6548e+09, train_seconds = 3.6096e+04)
[2022-06-10 06:09:41,342][root][INFO] - Step 138296320 @ 3581.1 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 138296320, mean_episode_return = 65.564, mean_episode_step = 825.4, total_loss = -298.48, pg_loss = -344.89, baseline_loss = 52.237, entropy_loss = -5.8282, learner_queue_size = 32, _tick = 37226, _time = 1.6548e+09, train_seconds = 3.6101e+04)
[2022-06-10 06:09:46,350][root][INFO] - Step 138316800 @ 4089.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 138316800, mean_episode_return = 25.333, mean_episode_step = 776.39, total_loss = -5.1955, pg_loss = -49.777, baseline_loss = 50.294, entropy_loss = -5.7124, learner_queue_size = 32, _tick = 37232, _time = 1.6548e+09, train_seconds = 3.6106e+04)
[2022-06-10 06:09:51,355][root][INFO] - Step 138337280 @ 4091.5 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 138337280, mean_episode_return = 91.571, mean_episode_step = 966.41, total_loss = 112.44, pg_loss = 83.48, baseline_loss = 34.893, entropy_loss = -5.9316, learner_queue_size = 32, _tick = 37240, _time = 1.6548e+09, train_seconds = 3.6111e+04)
[2022-06-10 06:09:56,358][root][INFO] - Step 138355200 @ 3582.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 138355200, mean_episode_return = 48.64, mean_episode_step = 1026.5, total_loss = 97.349, pg_loss = 70.272, baseline_loss = 33.043, entropy_loss = -5.9653, learner_queue_size = 32, _tick = 37243, _time = 1.6548e+09, train_seconds = 3.6116e+04)
[2022-06-10 06:10:01,362][root][INFO] - Step 138375680 @ 4092.8 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 138375680, mean_episode_return = 141.89, mean_episode_step = 963.58, total_loss = -160.58, pg_loss = -161.8, baseline_loss = 7.1531, entropy_loss = -5.9346, learner_queue_size = 32, _tick = 37250, _time = 1.6548e+09, train_seconds = 3.6121e+04)
[2022-06-10 06:10:06,366][root][INFO] - Step 138396160 @ 4092.7 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 138396160, mean_episode_return = 183.95, mean_episode_step = 1106.3, total_loss = -24.179, pg_loss = -53.097, baseline_loss = 34.782, entropy_loss = -5.8635, learner_queue_size = 32, _tick = 37257, _time = 1.6548e+09, train_seconds = 3.6126e+04)
[2022-06-10 06:10:11,374][root][INFO] - Step 138414080 @ 3578.5 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 138414080, mean_episode_return = None, mean_episode_step = 987.84, total_loss = 291.81, pg_loss = 230.08, baseline_loss = 67.647, entropy_loss = -5.9212, learner_queue_size = 32, _tick = 37262, _time = 1.6548e+09, train_seconds = 3.6131e+04)
[2022-06-10 06:10:16,377][root][INFO] - Step 138434560 @ 4093.4 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 138434560, mean_episode_return = 42.674, mean_episode_step = 1012.1, total_loss = 127.3, pg_loss = 79.824, baseline_loss = 53.253, entropy_loss = -5.7776, learner_queue_size = 32, _tick = 37268, _time = 1.6548e+09, train_seconds = 3.6136e+04)
[2022-06-10 06:10:21,382][root][INFO] - Step 138452480 @ 3580.4 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 138452480, mean_episode_return = 94.269, mean_episode_step = 1033.1, total_loss = 52.267, pg_loss = 25.328, baseline_loss = 32.671, entropy_loss = -5.7318, learner_queue_size = 32, _tick = 37274, _time = 1.6548e+09, train_seconds = 3.6141e+04)
[2022-06-10 06:10:26,386][root][INFO] - Step 138472960 @ 4092.5 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 138472960, mean_episode_return = -9.9001, mean_episode_step = 853.69, total_loss = 355.05, pg_loss = 155.8, baseline_loss = 204.87, entropy_loss = -5.6185, learner_queue_size = 32, _tick = 37280, _time = 1.6548e+09, train_seconds = 3.6146e+04)
[2022-06-10 06:10:31,390][root][INFO] - Step 138493440 @ 4092.9 SPS. Inference batcher size: 76. Learner queue size: 32. Other stats: (step = 138493440, mean_episode_return = 43.385, mean_episode_step = 851.35, total_loss = 108.37, pg_loss = 11.208, baseline_loss = 102.63, entropy_loss = -5.4659, learner_queue_size = 32, _tick = 37288, _time = 1.6548e+09, train_seconds = 3.6151e+04)
[2022-06-10 06:10:36,394][root][INFO] - Step 138511360 @ 3581.2 SPS. Inference batcher size: 92. Learner queue size: 32. Other stats: (step = 138511360, mean_episode_return = None, mean_episode_step = 1032.0, total_loss = -30.556, pg_loss = -68.57, baseline_loss = 43.555, entropy_loss = -5.5408, learner_queue_size = 32, _tick = 37294, _time = 1.6548e+09, train_seconds = 3.6156e+04)
[2022-06-10 06:10:41,398][root][INFO] - Step 138531840 @ 4092.7 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 138531840, mean_episode_return = 82.889, mean_episode_step = 934.75, total_loss = -139.74, pg_loss = -170.74, baseline_loss = 36.55, entropy_loss = -5.55, learner_queue_size = 32, _tick = 37301, _time = 1.6548e+09, train_seconds = 3.6161e+04)
[2022-06-10 06:10:46,402][root][INFO] - Step 138549760 @ 3581.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 138549760, mean_episode_return = 45.152, mean_episode_step = 951.13, total_loss = 91.997, pg_loss = 56.703, baseline_loss = 41.003, entropy_loss = -5.7086, learner_queue_size = 32, _tick = 37304, _time = 1.6548e+09, train_seconds = 3.6166e+04)
[2022-06-10 06:10:51,406][root][INFO] - Step 138570240 @ 4092.7 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 138570240, mean_episode_return = 38.753, mean_episode_step = 664.36, total_loss = -252.51, pg_loss = -278.26, baseline_loss = 31.393, entropy_loss = -5.645, learner_queue_size = 32, _tick = 37312, _time = 1.6548e+09, train_seconds = 3.6171e+04)
[2022-06-10 06:10:56,410][root][INFO] - Step 138590720 @ 4092.8 SPS. Inference batcher size: 88. Learner queue size: 32. Other stats: (step = 138590720, mean_episode_return = 53.433, mean_episode_step = 1001.9, total_loss = -326.47, pg_loss = -348.87, baseline_loss = 28.267, entropy_loss = -5.8628, learner_queue_size = 32, _tick = 37318, _time = 1.6548e+09, train_seconds = 3.6176e+04)
[2022-06-10 06:11:01,414][root][INFO] - Step 138608640 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 138608640, mean_episode_return = 54.646, mean_episode_step = 1215.8, total_loss = -129.65, pg_loss = -144.09, baseline_loss = 20.331, entropy_loss = -5.8853, learner_queue_size = 32, _tick = 37323, _time = 1.6548e+09, train_seconds = 3.6181e+04)
[2022-06-10 06:11:06,418][root][INFO] - Step 138629120 @ 4092.7 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 138629120, mean_episode_return = None, mean_episode_step = 890.59, total_loss = 272.57, pg_loss = 211.81, baseline_loss = 66.739, entropy_loss = -5.9792, learner_queue_size = 32, _tick = 37328, _time = 1.6548e+09, train_seconds = 3.6186e+04)
[2022-06-10 06:11:11,422][root][INFO] - Step 138647040 @ 3581.1 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 138647040, mean_episode_return = 5.7898, mean_episode_step = 846.06, total_loss = 161.73, pg_loss = 120.13, baseline_loss = 47.485, entropy_loss = -5.8872, learner_queue_size = 32, _tick = 37335, _time = 1.6548e+09, train_seconds = 3.6191e+04)
[2022-06-10 06:11:16,426][root][INFO] - Step 138667520 @ 4092.8 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 138667520, mean_episode_return = None, mean_episode_step = 1015.1, total_loss = 150.81, pg_loss = 103.79, baseline_loss = 52.621, entropy_loss = -5.5968, learner_queue_size = 32, _tick = 37341, _time = 1.6548e+09, train_seconds = 3.6196e+04)
[2022-06-10 06:11:21,430][root][INFO] - Step 138688000 @ 4092.6 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 138688000, mean_episode_return = -4.24, mean_episode_step = 1016.7, total_loss = 200.87, pg_loss = 117.52, baseline_loss = 89.199, entropy_loss = -5.8477, learner_queue_size = 32, _tick = 37349, _time = 1.6548e+09, train_seconds = 3.6201e+04)
[2022-06-10 06:11:26,434][root][INFO] - Step 138708480 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 138708480, mean_episode_return = 13.54, mean_episode_step = 845.38, total_loss = -127.53, pg_loss = -191.1, baseline_loss = 69.259, entropy_loss = -5.6861, learner_queue_size = 32, _tick = 37355, _time = 1.6548e+09, train_seconds = 3.6206e+04)
[2022-06-10 06:11:31,438][root][INFO] - Step 138726400 @ 3581.2 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 138726400, mean_episode_return = 163.59, mean_episode_step = 810.6, total_loss = 289.1, pg_loss = 183.18, baseline_loss = 112.0, entropy_loss = -6.0857, learner_queue_size = 32, _tick = 37361, _time = 1.6548e+09, train_seconds = 3.6211e+04)
[2022-06-10 06:11:36,442][root][INFO] - Step 138746880 @ 4092.7 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 138746880, mean_episode_return = 91.17, mean_episode_step = 944.88, total_loss = -43.316, pg_loss = -97.883, baseline_loss = 60.569, entropy_loss = -6.0019, learner_queue_size = 32, _tick = 37367, _time = 1.6548e+09, train_seconds = 3.6216e+04)
[2022-06-10 06:11:41,446][root][INFO] - Step 138767360 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 138767360, mean_episode_return = 40.68, mean_episode_step = 831.34, total_loss = 675.96, pg_loss = 574.71, baseline_loss = 107.23, entropy_loss = -5.9723, learner_queue_size = 32, _tick = 37374, _time = 1.6548e+09, train_seconds = 3.6221e+04)
[2022-06-10 06:11:46,451][root][INFO] - Step 138785280 @ 3580.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 138785280, mean_episode_return = 35.953, mean_episode_step = 686.28, total_loss = -337.7, pg_loss = -394.67, baseline_loss = 62.74, entropy_loss = -5.768, learner_queue_size = 32, _tick = 37380, _time = 1.6548e+09, train_seconds = 3.6226e+04)
[2022-06-10 06:11:51,454][root][INFO] - Step 138805760 @ 4093.3 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 138805760, mean_episode_return = 7.7098, mean_episode_step = 885.78, total_loss = -24.698, pg_loss = -53.691, baseline_loss = 34.98, entropy_loss = -5.9859, learner_queue_size = 32, _tick = 37386, _time = 1.6548e+09, train_seconds = 3.6231e+04)
[2022-06-10 06:11:56,458][root][INFO] - Step 138826240 @ 4092.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 138826240, mean_episode_return = 25.38, mean_episode_step = 1094.3, total_loss = -33.496, pg_loss = -76.047, baseline_loss = 48.478, entropy_loss = -5.9268, learner_queue_size = 32, _tick = 37392, _time = 1.6548e+09, train_seconds = 3.6236e+04)
[2022-06-10 06:12:01,462][root][INFO] - Step 138844160 @ 3581.1 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 138844160, mean_episode_return = 49.51, mean_episode_step = 850.1, total_loss = -44.777, pg_loss = -84.423, baseline_loss = 45.805, entropy_loss = -6.1583, learner_queue_size = 32, _tick = 37398, _time = 1.6548e+09, train_seconds = 3.6241e+04)
[2022-06-10 06:12:06,466][root][INFO] - Step 138864640 @ 4092.7 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 138864640, mean_episode_return = 42.255, mean_episode_step = 991.54, total_loss = 121.0, pg_loss = 80.113, baseline_loss = 46.641, entropy_loss = -5.7493, learner_queue_size = 32, _tick = 37406, _time = 1.6548e+09, train_seconds = 3.6246e+04)
[2022-06-10 06:12:11,470][root][INFO] - Step 138885120 @ 4092.7 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 138885120, mean_episode_return = 74.358, mean_episode_step = 1090.4, total_loss = 218.93, pg_loss = 161.2, baseline_loss = 63.848, entropy_loss = -6.1245, learner_queue_size = 32, _tick = 37412, _time = 1.6548e+09, train_seconds = 3.6251e+04)
[2022-06-10 06:12:16,474][root][INFO] - Step 138903040 @ 3581.1 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 138903040, mean_episode_return = None, mean_episode_step = 840.75, total_loss = -21.224, pg_loss = -71.315, baseline_loss = 56.117, entropy_loss = -6.0264, learner_queue_size = 32, _tick = 37415, _time = 1.6548e+09, train_seconds = 3.6256e+04)
[2022-06-10 06:12:21,478][root][INFO] - Step 138923520 @ 4092.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 138923520, mean_episode_return = 67.708, mean_episode_step = 931.93, total_loss = 195.98, pg_loss = 132.41, baseline_loss = 69.56, entropy_loss = -5.9875, learner_queue_size = 32, _tick = 37420, _time = 1.6548e+09, train_seconds = 3.6261e+04)
[2022-06-10 06:12:26,482][root][INFO] - Step 138941440 @ 3581.0 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 138941440, mean_episode_return = 164.9, mean_episode_step = 982.05, total_loss = 438.89, pg_loss = 349.43, baseline_loss = 95.389, entropy_loss = -5.9318, learner_queue_size = 32, _tick = 37423, _time = 1.6548e+09, train_seconds = 3.6266e+04)
[2022-06-10 06:12:31,486][root][INFO] - Step 138961920 @ 4093.0 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 138961920, mean_episode_return = None, mean_episode_step = 948.12, total_loss = -142.41, pg_loss = -168.75, baseline_loss = 32.378, entropy_loss = -6.0354, learner_queue_size = 32, _tick = 37428, _time = 1.6548e+09, train_seconds = 3.6271e+04)
[2022-06-10 06:12:36,490][root][INFO] - Step 138982400 @ 4092.7 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 138982400, mean_episode_return = None, mean_episode_step = 870.41, total_loss = 16.113, pg_loss = -3.6433, baseline_loss = 25.742, entropy_loss = -5.9858, learner_queue_size = 32, _tick = 37433, _time = 1.6548e+09, train_seconds = 3.6276e+04)
[2022-06-10 06:12:41,494][root][INFO] - Step 139000320 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 139000320, mean_episode_return = 4.0897, mean_episode_step = 1262.6, total_loss = 217.97, pg_loss = 153.77, baseline_loss = 70.252, entropy_loss = -6.0462, learner_queue_size = 32, _tick = 37439, _time = 1.6548e+09, train_seconds = 3.6281e+04)
[2022-06-10 06:12:46,498][root][INFO] - Step 139020800 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 139020800, mean_episode_return = 28.545, mean_episode_step = 1004.1, total_loss = -48.007, pg_loss = -80.733, baseline_loss = 38.68, entropy_loss = -5.9535, learner_queue_size = 32, _tick = 37444, _time = 1.6548e+09, train_seconds = 3.6286e+04)
[2022-06-10 06:12:51,502][root][INFO] - Step 139038720 @ 3581.2 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 139038720, mean_episode_return = 74.569, mean_episode_step = 982.22, total_loss = -174.32, pg_loss = -188.23, baseline_loss = 19.971, entropy_loss = -6.0635, learner_queue_size = 32, _tick = 37450, _time = 1.6548e+09, train_seconds = 3.6291e+04)
[2022-06-10 06:12:56,506][root][INFO] - Step 139059200 @ 4092.6 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 139059200, mean_episode_return = None, mean_episode_step = 1049.1, total_loss = 215.17, pg_loss = 168.35, baseline_loss = 52.76, entropy_loss = -5.938, learner_queue_size = 32, _tick = 37457, _time = 1.6548e+09, train_seconds = 3.6296e+04)
[2022-06-10 06:13:01,510][root][INFO] - Step 139077120 @ 3581.2 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 139077120, mean_episode_return = 28.565, mean_episode_step = 1131.5, total_loss = -130.3, pg_loss = -191.98, baseline_loss = 67.56, entropy_loss = -5.8848, learner_queue_size = 32, _tick = 37464, _time = 1.6548e+09, train_seconds = 3.6301e+04)
[2022-06-10 06:13:06,514][root][INFO] - Step 139097600 @ 4092.7 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 139097600, mean_episode_return = 50.797, mean_episode_step = 1042.3, total_loss = 1142.5, pg_loss = 165.36, baseline_loss = 983.23, entropy_loss = -6.0726, learner_queue_size = 32, _tick = 37472, _time = 1.6548e+09, train_seconds = 3.6306e+04)
[2022-06-10 06:13:11,520][root][INFO] - Step 139118080 @ 4091.1 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 139118080, mean_episode_return = 102.53, mean_episode_step = 980.81, total_loss = 131.25, pg_loss = 77.437, baseline_loss = 59.582, entropy_loss = -5.7676, learner_queue_size = 32, _tick = 37480, _time = 1.6548e+09, train_seconds = 3.6311e+04)
[2022-06-10 06:13:16,527][root][INFO] - Step 139136000 @ 3579.3 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 139136000, mean_episode_return = 60.301, mean_episode_step = 725.23, total_loss = 283.44, pg_loss = 193.71, baseline_loss = 95.609, entropy_loss = -5.8778, learner_queue_size = 32, _tick = 37487, _time = 1.6548e+09, train_seconds = 3.6316e+04)
[2022-06-10 06:13:21,530][root][INFO] - Step 139156480 @ 4093.3 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 139156480, mean_episode_return = 15.87, mean_episode_step = 930.12, total_loss = 178.41, pg_loss = 109.32, baseline_loss = 74.838, entropy_loss = -5.7511, learner_queue_size = 32, _tick = 37495, _time = 1.6548e+09, train_seconds = 3.6321e+04)
[2022-06-10 06:13:26,534][root][INFO] - Step 139174400 @ 3581.1 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 139174400, mean_episode_return = 47.225, mean_episode_step = 850.89, total_loss = -119.7, pg_loss = -147.32, baseline_loss = 33.389, entropy_loss = -5.7786, learner_queue_size = 32, _tick = 37500, _time = 1.6548e+09, train_seconds = 3.6326e+04)
[2022-06-10 06:13:31,538][root][INFO] - Step 139194880 @ 4092.6 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 139194880, mean_episode_return = 38.91, mean_episode_step = 846.85, total_loss = 194.24, pg_loss = 133.65, baseline_loss = 66.63, entropy_loss = -6.0427, learner_queue_size = 32, _tick = 37508, _time = 1.6548e+09, train_seconds = 3.6331e+04)
[2022-06-10 06:13:36,542][root][INFO] - Step 139215360 @ 4092.8 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 139215360, mean_episode_return = 106.95, mean_episode_step = 821.98, total_loss = 118.9, pg_loss = 57.141, baseline_loss = 67.44, entropy_loss = -5.6809, learner_queue_size = 32, _tick = 37515, _time = 1.6548e+09, train_seconds = 3.6336e+04)
[2022-06-10 06:13:41,546][root][INFO] - Step 139233280 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 139233280, mean_episode_return = 62.681, mean_episode_step = 1267.8, total_loss = -130.58, pg_loss = -197.35, baseline_loss = 72.533, entropy_loss = -5.7647, learner_queue_size = 32, _tick = 37521, _time = 1.6548e+09, train_seconds = 3.6341e+04)
[2022-06-10 06:13:46,550][root][INFO] - Step 139253760 @ 4092.7 SPS. Inference batcher size: 84. Learner queue size: 32. Other stats: (step = 139253760, mean_episode_return = 22.51, mean_episode_step = 864.78, total_loss = 99.848, pg_loss = 55.566, baseline_loss = 50.075, entropy_loss = -5.7935, learner_queue_size = 32, _tick = 37526, _time = 1.6548e+09, train_seconds = 3.6346e+04)
[2022-06-10 06:13:51,554][root][INFO] - Step 139271680 @ 3581.0 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 139271680, mean_episode_return = 71.507, mean_episode_step = 998.35, total_loss = 210.33, pg_loss = 161.46, baseline_loss = 54.71, entropy_loss = -5.8381, learner_queue_size = 32, _tick = 37532, _time = 1.6548e+09, train_seconds = 3.6351e+04)
[2022-06-10 06:13:56,558][root][INFO] - Step 139292160 @ 4092.9 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 139292160, mean_episode_return = 60.045, mean_episode_step = 834.4, total_loss = 179.17, pg_loss = 111.93, baseline_loss = 73.034, entropy_loss = -5.796, learner_queue_size = 32, _tick = 37536, _time = 1.6548e+09, train_seconds = 3.6356e+04)
[2022-06-10 06:14:01,563][root][INFO] - Step 139312640 @ 4091.8 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 139312640, mean_episode_return = None, mean_episode_step = 1003.3, total_loss = -24.17, pg_loss = -42.612, baseline_loss = 24.373, entropy_loss = -5.9311, learner_queue_size = 32, _tick = 37542, _time = 1.6548e+09, train_seconds = 3.6361e+04)
[2022-06-10 06:14:06,566][root][INFO] - Step 139330560 @ 3582.0 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 139330560, mean_episode_return = None, mean_episode_step = 821.84, total_loss = 80.746, pg_loss = 13.277, baseline_loss = 73.123, entropy_loss = -5.6531, learner_queue_size = 32, _tick = 37545, _time = 1.6548e+09, train_seconds = 3.6366e+04)
[2022-06-10 06:14:11,570][root][INFO] - Step 139351040 @ 4092.7 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 139351040, mean_episode_return = 21.25, mean_episode_step = 848.35, total_loss = 223.04, pg_loss = 137.38, baseline_loss = 91.108, entropy_loss = -5.4477, learner_queue_size = 32, _tick = 37551, _time = 1.6548e+09, train_seconds = 3.6371e+04)
[2022-06-10 06:14:16,576][root][INFO] - Step 139368960 @ 3579.7 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 139368960, mean_episode_return = None, mean_episode_step = 1056.4, total_loss = 233.27, pg_loss = 170.2, baseline_loss = 68.519, entropy_loss = -5.4472, learner_queue_size = 32, _tick = 37555, _time = 1.6548e+09, train_seconds = 3.6376e+04)
[2022-06-10 06:14:21,582][root][INFO] - Step 139389440 @ 4091.1 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 139389440, mean_episode_return = 1.7297, mean_episode_step = 1039.5, total_loss = 70.049, pg_loss = 33.899, baseline_loss = 41.705, entropy_loss = -5.5553, learner_queue_size = 32, _tick = 37563, _time = 1.6548e+09, train_seconds = 3.6381e+04)
[2022-06-10 06:14:26,586][root][INFO] - Step 139407360 @ 3581.2 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 139407360, mean_episode_return = 164.14, mean_episode_step = 1014.3, total_loss = 99.1, pg_loss = 57.476, baseline_loss = 47.483, entropy_loss = -5.8589, learner_queue_size = 32, _tick = 37569, _time = 1.6548e+09, train_seconds = 3.6386e+04)
[2022-06-10 06:14:31,590][root][INFO] - Step 139427840 @ 4092.6 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 139427840, mean_episode_return = 64.747, mean_episode_step = 920.37, total_loss = 26.749, pg_loss = -19.242, baseline_loss = 51.746, entropy_loss = -5.755, learner_queue_size = 32, _tick = 37577, _time = 1.6548e+09, train_seconds = 3.6391e+04)
[2022-06-10 06:14:36,596][root][INFO] - Step 139445760 @ 3579.8 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 139445760, mean_episode_return = 49.1, mean_episode_step = 688.98, total_loss = -6.5621, pg_loss = -49.268, baseline_loss = 48.488, entropy_loss = -5.7813, learner_queue_size = 32, _tick = 37581, _time = 1.6548e+09, train_seconds = 3.6396e+04)
[2022-06-10 06:14:41,602][root][INFO] - Step 139466240 @ 4091.1 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 139466240, mean_episode_return = 31.965, mean_episode_step = 934.45, total_loss = -6.7388, pg_loss = -84.68, baseline_loss = 83.899, entropy_loss = -5.958, learner_queue_size = 32, _tick = 37586, _time = 1.6548e+09, train_seconds = 3.6401e+04)
[2022-06-10 06:14:46,606][root][INFO] - Step 139484160 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 139484160, mean_episode_return = 73.17, mean_episode_step = 926.22, total_loss = -141.69, pg_loss = -165.0, baseline_loss = 29.221, entropy_loss = -5.9084, learner_queue_size = 32, _tick = 37593, _time = 1.6548e+09, train_seconds = 3.6406e+04)
[2022-06-10 06:14:51,610][root][INFO] - Step 139504640 @ 4092.8 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 139504640, mean_episode_return = 87.435, mean_episode_step = 723.38, total_loss = 103.15, pg_loss = 64.449, baseline_loss = 44.528, entropy_loss = -5.832, learner_queue_size = 32, _tick = 37600, _time = 1.6548e+09, train_seconds = 3.6411e+04)
[2022-06-10 06:14:56,614][root][INFO] - Step 139522560 @ 3581.1 SPS. Inference batcher size: 62. Learner queue size: 32. Other stats: (step = 139522560, mean_episode_return = 51.832, mean_episode_step = 923.77, total_loss = 191.0, pg_loss = 146.47, baseline_loss = 50.336, entropy_loss = -5.8019, learner_queue_size = 32, _tick = 37605, _time = 1.6548e+09, train_seconds = 3.6416e+04)
[2022-06-10 06:15:01,620][root][INFO] - Step 139543040 @ 4091.1 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 139543040, mean_episode_return = 5.5997, mean_episode_step = 1187.8, total_loss = -5.3483, pg_loss = -31.592, baseline_loss = 32.059, entropy_loss = -5.8146, learner_queue_size = 32, _tick = 37613, _time = 1.6548e+09, train_seconds = 3.6421e+04)
[2022-06-10 06:15:06,626][root][INFO] - Step 139563520 @ 4091.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 139563520, mean_episode_return = 55.46, mean_episode_step = 1179.0, total_loss = 182.19, pg_loss = 131.59, baseline_loss = 56.447, entropy_loss = -5.8401, learner_queue_size = 32, _tick = 37620, _time = 1.6548e+09, train_seconds = 3.6426e+04)
[2022-06-10 06:15:11,630][root][INFO] - Step 139581440 @ 3581.1 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (step = 139581440, mean_episode_return = 54.101, mean_episode_step = 903.41, total_loss = 48.075, pg_loss = -8.2289, baseline_loss = 61.818, entropy_loss = -5.5139, learner_queue_size = 32, _tick = 37627, _time = 1.6548e+09, train_seconds = 3.6431e+04)
[2022-06-10 06:15:16,634][root][INFO] - Step 139601920 @ 4092.6 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 139601920, mean_episode_return = 105.18, mean_episode_step = 884.59, total_loss = 58.301, pg_loss = 8.0406, baseline_loss = 55.818, entropy_loss = -5.5577, learner_queue_size = 32, _tick = 37635, _time = 1.6548e+09, train_seconds = 3.6436e+04)
[2022-06-10 06:15:21,640][root][INFO] - Step 139619840 @ 3579.7 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 139619840, mean_episode_return = 41.001, mean_episode_step = 721.24, total_loss = -54.605, pg_loss = -83.282, baseline_loss = 34.44, entropy_loss = -5.763, learner_queue_size = 32, _tick = 37639, _time = 1.6548e+09, train_seconds = 3.6441e+04)
[2022-06-10 06:15:26,646][root][INFO] - Step 139640320 @ 4091.1 SPS. Inference batcher size: 92. Learner queue size: 32. Other stats: (step = 139640320, mean_episode_return = 147.98, mean_episode_step = 1452.7, total_loss = 130.16, pg_loss = 97.92, baseline_loss = 38.224, entropy_loss = -5.9818, learner_queue_size = 32, _tick = 37646, _time = 1.6548e+09, train_seconds = 3.6446e+04)
[2022-06-10 06:15:31,650][root][INFO] - Step 139660800 @ 4092.7 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 139660800, mean_episode_return = 19.72, mean_episode_step = 971.2, total_loss = -31.363, pg_loss = -93.783, baseline_loss = 68.199, entropy_loss = -5.7786, learner_queue_size = 32, _tick = 37654, _time = 1.6548e+09, train_seconds = 3.6452e+04)
[2022-06-10 06:15:36,654][root][INFO] - Step 139681280 @ 4092.8 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 139681280, mean_episode_return = None, mean_episode_step = 807.34, total_loss = 154.73, pg_loss = 89.119, baseline_loss = 71.434, entropy_loss = -5.8193, learner_queue_size = 32, _tick = 37659, _time = 1.6548e+09, train_seconds = 3.6456e+04)
[2022-06-10 06:15:41,658][root][INFO] - Step 139699200 @ 3581.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 139699200, mean_episode_return = 91.18, mean_episode_step = 847.14, total_loss = -125.88, pg_loss = -137.02, baseline_loss = 17.149, entropy_loss = -6.0066, learner_queue_size = 32, _tick = 37664, _time = 1.6548e+09, train_seconds = 3.6462e+04)
[2022-06-10 06:15:46,662][root][INFO] - Step 139719680 @ 4092.7 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (step = 139719680, mean_episode_return = 129.2, mean_episode_step = 841.71, total_loss = 1005.8, pg_loss = 715.7, baseline_loss = 296.05, entropy_loss = -5.9296, learner_queue_size = 32, _tick = 37671, _time = 1.6548e+09, train_seconds = 3.6466e+04)
[2022-06-10 06:15:51,666][root][INFO] - Step 139737600 @ 3581.1 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 139737600, mean_episode_return = 49.756, mean_episode_step = 847.97, total_loss = 128.79, pg_loss = 77.46, baseline_loss = 57.116, entropy_loss = -5.7892, learner_queue_size = 32, _tick = 37678, _time = 1.6548e+09, train_seconds = 3.6472e+04)
[2022-06-10 06:15:56,670][root][INFO] - Step 139758080 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 139758080, mean_episode_return = 72.308, mean_episode_step = 971.51, total_loss = 315.76, pg_loss = 199.23, baseline_loss = 122.32, entropy_loss = -5.7945, learner_queue_size = 32, _tick = 37686, _time = 1.6548e+09, train_seconds = 3.6476e+04)
[2022-06-10 06:16:01,674][root][INFO] - Step 139778560 @ 4092.7 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (step = 139778560, mean_episode_return = None, mean_episode_step = 884.09, total_loss = -110.3, pg_loss = -126.2, baseline_loss = 21.614, entropy_loss = -5.7124, learner_queue_size = 32, _tick = 37690, _time = 1.6548e+09, train_seconds = 3.6482e+04)
[2022-06-10 06:16:06,682][root][INFO] - Step 139796480 @ 3578.6 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 139796480, mean_episode_return = None, mean_episode_step = 985.97, total_loss = 137.87, pg_loss = 92.235, baseline_loss = 51.398, entropy_loss = -5.7642, learner_queue_size = 32, _tick = 37694, _time = 1.6548e+09, train_seconds = 3.6486e+04)
[2022-06-10 06:16:11,686][root][INFO] - Step 139816960 @ 4092.3 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 139816960, mean_episode_return = 78.972, mean_episode_step = 927.09, total_loss = -270.81, pg_loss = -280.54, baseline_loss = 15.263, entropy_loss = -5.5275, learner_queue_size = 32, _tick = 37700, _time = 1.6548e+09, train_seconds = 3.6492e+04)
[2022-06-10 06:16:16,690][root][INFO] - Step 139837440 @ 4092.7 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (step = 139837440, mean_episode_return = 36.62, mean_episode_step = 1222.0, total_loss = 114.57, pg_loss = 75.401, baseline_loss = 45.052, entropy_loss = -5.885, learner_queue_size = 32, _tick = 37705, _time = 1.6548e+09, train_seconds = 3.6496e+04)
[2022-06-10 06:16:21,694][root][INFO] - Step 139855360 @ 3581.0 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 139855360, mean_episode_return = 118.13, mean_episode_step = 915.5, total_loss = -133.69, pg_loss = -155.95, baseline_loss = 27.852, entropy_loss = -5.5864, learner_queue_size = 32, _tick = 37711, _time = 1.6548e+09, train_seconds = 3.6502e+04)
[2022-06-10 06:16:26,698][root][INFO] - Step 139875840 @ 4092.8 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (step = 139875840, mean_episode_return = 7.7498, mean_episode_step = 866.3, total_loss = -20.144, pg_loss = -56.904, baseline_loss = 42.522, entropy_loss = -5.7618, learner_queue_size = 32, _tick = 37718, _time = 1.6548e+09, train_seconds = 3.6506e+04)
[2022-06-10 06:16:31,703][root][INFO] - Step 139893760 @ 3580.2 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 139893760, mean_episode_return = 150.2, mean_episode_step = 902.17, total_loss = 95.402, pg_loss = 4.4267, baseline_loss = 96.575, entropy_loss = -5.5996, learner_queue_size = 32, _tick = 37723, _time = 1.6548e+09, train_seconds = 3.6512e+04)
[2022-06-10 06:16:36,706][root][INFO] - Step 139914240 @ 4093.8 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (step = 139914240, mean_episode_return = None, mean_episode_step = 977.34, total_loss = -15.684, pg_loss = -58.289, baseline_loss = 48.351, entropy_loss = -5.7465, learner_queue_size = 32, _tick = 37729, _time = 1.6548e+09, train_seconds = 3.6516e+04)
[2022-06-10 06:16:41,710][root][INFO] - Step 139934720 @ 4092.7 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 139934720, mean_episode_return = None, mean_episode_step = 930.69, total_loss = 117.43, pg_loss = 52.485, baseline_loss = 70.863, entropy_loss = -5.9229, learner_queue_size = 32, _tick = 37734, _time = 1.6548e+09, train_seconds = 3.6522e+04)
[2022-06-10 06:16:46,714][root][INFO] - Step 139952640 @ 3581.2 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 139952640, mean_episode_return = 49.075, mean_episode_step = 811.89, total_loss = 21.278, pg_loss = -35.143, baseline_loss = 62.008, entropy_loss = -5.5873, learner_queue_size = 32, _tick = 37741, _time = 1.6548e+09, train_seconds = 3.6526e+04)
[2022-06-10 06:16:51,718][root][INFO] - Step 139973120 @ 4092.7 SPS. Inference batcher size: 35. Learner queue size: 32. Other stats: (step = 139973120, mean_episode_return = 19.03, mean_episode_step = 874.51, total_loss = 43.117, pg_loss = -104.05, baseline_loss = 152.74, entropy_loss = -5.574, learner_queue_size = 32, _tick = 37747, _time = 1.6548e+09, train_seconds = 3.6532e+04)
[2022-06-10 06:16:56,722][root][INFO] - Step 139991040 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 139991040, mean_episode_return = -1.09, mean_episode_step = 1230.2, total_loss = -78.108, pg_loss = -151.83, baseline_loss = 79.414, entropy_loss = -5.6921, learner_queue_size = 32, _tick = 37752, _time = 1.6548e+09, train_seconds = 3.6536e+04)
[2022-06-10 06:17:01,726][root][INFO] - Step 140011520 @ 4092.8 SPS. Inference batcher size: 91. Learner queue size: 32. Other stats: (step = 140011520, mean_episode_return = 102.45, mean_episode_step = 997.15, total_loss = 36.125, pg_loss = -27.507, baseline_loss = 69.408, entropy_loss = -5.7765, learner_queue_size = 32, _tick = 37758, _time = 1.6548e+09, train_seconds = 3.6542e+04)
[2022-06-10 06:17:06,730][root][INFO] - Step 140032000 @ 4092.7 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (step = 140032000, mean_episode_return = 82.937, mean_episode_step = 986.24, total_loss = -125.21, pg_loss = -176.89, baseline_loss = 57.405, entropy_loss = -5.7252, learner_queue_size = 32, _tick = 37764, _time = 1.6548e+09, train_seconds = 3.6546e+04)
[2022-06-10 06:17:11,734][root][INFO] - Step 140049920 @ 3581.1 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 140049920, mean_episode_return = 123.84, mean_episode_step = 778.96, total_loss = 127.13, pg_loss = 104.34, baseline_loss = 28.475, entropy_loss = -5.6924, learner_queue_size = 32, _tick = 37769, _time = 1.6548e+09, train_seconds = 3.6552e+04)
[2022-06-10 06:17:16,738][root][INFO] - Step 140070400 @ 4092.7 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (step = 140070400, mean_episode_return = 37.845, mean_episode_step = 1023.3, total_loss = 99.513, pg_loss = 71.341, baseline_loss = 33.887, entropy_loss = -5.7147, learner_queue_size = 32, _tick = 37776, _time = 1.6548e+09, train_seconds = 3.6556e+04)
[2022-06-10 06:17:21,742][root][INFO] - Step 140090880 @ 4092.8 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 140090880, mean_episode_return = 50.547, mean_episode_step = 860.45, total_loss = -297.3, pg_loss = -336.25, baseline_loss = 44.659, entropy_loss = -5.7108, learner_queue_size = 32, _tick = 37783, _time = 1.6548e+09, train_seconds = 3.6562e+04)
[2022-06-10 06:17:26,746][root][INFO] - Step 140108800 @ 3581.1 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 140108800, mean_episode_return = 78.254, mean_episode_step = 1160.2, total_loss = 107.49, pg_loss = 67.216, baseline_loss = 46.156, entropy_loss = -5.8767, learner_queue_size = 32, _tick = 37790, _time = 1.6548e+09, train_seconds = 3.6567e+04)
[2022-06-10 06:17:31,750][root][INFO] - Step 140129280 @ 4092.7 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 140129280, mean_episode_return = 43.57, mean_episode_step = 793.86, total_loss = -164.2, pg_loss = -201.99, baseline_loss = 43.575, entropy_loss = -5.7782, learner_queue_size = 32, _tick = 37796, _time = 1.6548e+09, train_seconds = 3.6572e+04)
[2022-06-10 06:17:36,755][root][INFO] - Step 140149760 @ 4092.0 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 140149760, mean_episode_return = 22.16, mean_episode_step = 1121.3, total_loss = 57.183, pg_loss = 38.762, baseline_loss = 24.224, entropy_loss = -5.803, learner_queue_size = 32, _tick = 37803, _time = 1.6548e+09, train_seconds = 3.6577e+04)
[2022-06-10 06:17:41,758][root][INFO] - Step 140167680 @ 3581.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 140167680, mean_episode_return = 27.961, mean_episode_step = 782.52, total_loss = 88.942, pg_loss = 24.323, baseline_loss = 70.373, entropy_loss = -5.7539, learner_queue_size = 32, _tick = 37807, _time = 1.6548e+09, train_seconds = 3.6582e+04)
[2022-06-10 06:17:46,762][root][INFO] - Step 140188160 @ 4092.8 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 140188160, mean_episode_return = None, mean_episode_step = 842.25, total_loss = 124.45, pg_loss = 70.781, baseline_loss = 59.416, entropy_loss = -5.7476, learner_queue_size = 32, _tick = 37813, _time = 1.6548e+09, train_seconds = 3.6587e+04)
[2022-06-10 06:17:51,766][root][INFO] - Step 140208640 @ 4092.7 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 140208640, mean_episode_return = 135.38, mean_episode_step = 907.41, total_loss = 107.73, pg_loss = 85.373, baseline_loss = 28.371, entropy_loss = -6.0167, learner_queue_size = 32, _tick = 37820, _time = 1.6548e+09, train_seconds = 3.6592e+04)
[2022-06-10 06:17:56,770][root][INFO] - Step 140226560 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 140226560, mean_episode_return = 89.915, mean_episode_step = 897.23, total_loss = 420.52, pg_loss = 346.94, baseline_loss = 79.559, entropy_loss = -5.9716, learner_queue_size = 32, _tick = 37825, _time = 1.6548e+09, train_seconds = 3.6597e+04)
[2022-06-10 06:18:01,775][root][INFO] - Step 140247040 @ 4091.7 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 140247040, mean_episode_return = None, mean_episode_step = 833.31, total_loss = 32.118, pg_loss = 6.6421, baseline_loss = 31.551, entropy_loss = -6.075, learner_queue_size = 32, _tick = 37829, _time = 1.6548e+09, train_seconds = 3.6602e+04)
[2022-06-10 06:18:06,778][root][INFO] - Step 140267520 @ 4093.6 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (step = 140267520, mean_episode_return = 53.18, mean_episode_step = 858.16, total_loss = 147.39, pg_loss = 94.744, baseline_loss = 58.605, entropy_loss = -5.959, learner_queue_size = 32, _tick = 37836, _time = 1.6548e+09, train_seconds = 3.6607e+04)
[2022-06-10 06:18:11,786][root][INFO] - Step 140288000 @ 4090.0 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 140288000, mean_episode_return = 28.63, mean_episode_step = 1082.5, total_loss = -75.551, pg_loss = -94.49, baseline_loss = 24.943, entropy_loss = -6.004, learner_queue_size = 32, _tick = 37842, _time = 1.6548e+09, train_seconds = 3.6612e+04)
[2022-06-10 06:18:16,790][root][INFO] - Step 140305920 @ 3580.9 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 140305920, mean_episode_return = 160.2, mean_episode_step = 1000.6, total_loss = 9.9617, pg_loss = -9.8968, baseline_loss = 25.51, entropy_loss = -5.6518, learner_queue_size = 32, _tick = 37849, _time = 1.6548e+09, train_seconds = 3.6617e+04)
[2022-06-10 06:18:21,794][root][INFO] - Step 140326400 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 140326400, mean_episode_return = 96.536, mean_episode_step = 1151.8, total_loss = -263.22, pg_loss = -267.63, baseline_loss = 10.225, entropy_loss = -5.8134, learner_queue_size = 32, _tick = 37857, _time = 1.6548e+09, train_seconds = 3.6622e+04)
[2022-06-10 06:18:26,798][root][INFO] - Step 140344320 @ 3581.2 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 140344320, mean_episode_return = 27.937, mean_episode_step = 960.76, total_loss = -26.111, pg_loss = -149.95, baseline_loss = 129.48, entropy_loss = -5.6408, learner_queue_size = 32, _tick = 37864, _time = 1.6548e+09, train_seconds = 3.6627e+04)
[2022-06-10 06:18:31,802][root][INFO] - Step 140364800 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 140364800, mean_episode_return = 5.3047, mean_episode_step = 920.11, total_loss = 39.467, pg_loss = 2.0557, baseline_loss = 43.011, entropy_loss = -5.5994, learner_queue_size = 32, _tick = 37871, _time = 1.6548e+09, train_seconds = 3.6632e+04)
[2022-06-10 06:18:36,806][root][INFO] - Step 140385280 @ 4092.7 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 140385280, mean_episode_return = 22.86, mean_episode_step = 1158.2, total_loss = -39.612, pg_loss = -63.048, baseline_loss = 29.345, entropy_loss = -5.9089, learner_queue_size = 32, _tick = 37877, _time = 1.6548e+09, train_seconds = 3.6637e+04)
[2022-06-10 06:18:41,810][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 06:18:41,936][root][INFO] - Step 140403200 @ 3581.1 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (step = 140403200, mean_episode_return = 34.24, mean_episode_step = 898.89, total_loss = 119.7, pg_loss = 85.496, baseline_loss = 40.098, entropy_loss = -5.8981, learner_queue_size = 32, _tick = 37881, _time = 1.6548e+09, train_seconds = 3.6642e+04)
[2022-06-10 06:18:46,940][root][INFO] - Step 140423680 @ 3992.0 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 140423680, mean_episode_return = None, mean_episode_step = 939.81, total_loss = 22.903, pg_loss = -4.9696, baseline_loss = 33.615, entropy_loss = -5.7419, learner_queue_size = 32, _tick = 37887, _time = 1.6548e+09, train_seconds = 3.6647e+04)
[2022-06-10 06:18:51,946][root][INFO] - Step 140444160 @ 4091.1 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 140444160, mean_episode_return = None, mean_episode_step = 978.53, total_loss = 64.381, pg_loss = 37.88, baseline_loss = 32.311, entropy_loss = -5.8093, learner_queue_size = 32, _tick = 37893, _time = 1.6548e+09, train_seconds = 3.6652e+04)
[2022-06-10 06:18:56,950][root][INFO] - Step 140462080 @ 3581.3 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 140462080, mean_episode_return = 64.611, mean_episode_step = 780.01, total_loss = 133.95, pg_loss = 72.485, baseline_loss = 67.236, entropy_loss = -5.7695, learner_queue_size = 32, _tick = 37898, _time = 1.6548e+09, train_seconds = 3.6657e+04)
[2022-06-10 06:19:01,954][root][INFO] - Step 140482560 @ 4092.8 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 140482560, mean_episode_return = 46.08, mean_episode_step = 1118.2, total_loss = -197.75, pg_loss = -209.67, baseline_loss = 17.76, entropy_loss = -5.8368, learner_queue_size = 32, _tick = 37904, _time = 1.6548e+09, train_seconds = 3.6662e+04)
[2022-06-10 06:19:06,958][root][INFO] - Step 140503040 @ 4092.7 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 140503040, mean_episode_return = 24.397, mean_episode_step = 1262.1, total_loss = -92.214, pg_loss = -174.3, baseline_loss = 87.872, entropy_loss = -5.7853, learner_queue_size = 32, _tick = 37911, _time = 1.6548e+09, train_seconds = 3.6667e+04)
[2022-06-10 06:19:11,962][root][INFO] - Step 140520960 @ 3581.2 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 140520960, mean_episode_return = 82.007, mean_episode_step = 905.44, total_loss = 83.458, pg_loss = 25.855, baseline_loss = 63.41, entropy_loss = -5.8065, learner_queue_size = 32, _tick = 37917, _time = 1.6548e+09, train_seconds = 3.6672e+04)
[2022-06-10 06:19:16,966][root][INFO] - Step 140541440 @ 4092.6 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 140541440, mean_episode_return = None, mean_episode_step = 752.5, total_loss = 97.374, pg_loss = 50.831, baseline_loss = 52.328, entropy_loss = -5.7851, learner_queue_size = 32, _tick = 37923, _time = 1.6548e+09, train_seconds = 3.6677e+04)
[2022-06-10 06:19:21,970][root][INFO] - Step 140561920 @ 4092.8 SPS. Inference batcher size: 70. Learner queue size: 32. Other stats: (step = 140561920, mean_episode_return = 35.412, mean_episode_step = 978.33, total_loss = -129.03, pg_loss = -143.74, baseline_loss = 20.439, entropy_loss = -5.733, learner_queue_size = 32, _tick = 37931, _time = 1.6548e+09, train_seconds = 3.6682e+04)
[2022-06-10 06:19:26,974][root][INFO] - Step 140582400 @ 4092.7 SPS. Inference batcher size: 78. Learner queue size: 32. Other stats: (step = 140582400, mean_episode_return = 19.205, mean_episode_step = 1313.5, total_loss = 89.338, pg_loss = 57.267, baseline_loss = 37.929, entropy_loss = -5.8576, learner_queue_size = 32, _tick = 37937, _time = 1.6548e+09, train_seconds = 3.6687e+04)
[2022-06-10 06:19:31,978][root][INFO] - Step 140600320 @ 3581.2 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 140600320, mean_episode_return = -10.86, mean_episode_step = 1231.6, total_loss = 100.72, pg_loss = 56.608, baseline_loss = 49.893, entropy_loss = -5.7823, learner_queue_size = 32, _tick = 37943, _time = 1.6548e+09, train_seconds = 3.6692e+04)
[2022-06-10 06:19:36,982][root][INFO] - Step 140623360 @ 4604.3 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 140623360, mean_episode_return = None, mean_episode_step = 990.31, total_loss = 377.45, pg_loss = 220.25, baseline_loss = 163.09, entropy_loss = -5.8847, learner_queue_size = 32, _tick = 37950, _time = 1.6548e+09, train_seconds = 3.6697e+04)
[2022-06-10 06:19:41,986][root][INFO] - Step 140641280 @ 3581.2 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 140641280, mean_episode_return = 18.12, mean_episode_step = 1027.8, total_loss = 46.569, pg_loss = 7.8036, baseline_loss = 44.408, entropy_loss = -5.6431, learner_queue_size = 32, _tick = 37956, _time = 1.6548e+09, train_seconds = 3.6702e+04)
[2022-06-10 06:19:46,990][root][INFO] - Step 140661760 @ 4092.7 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (step = 140661760, mean_episode_return = 17.31, mean_episode_step = 826.89, total_loss = 8.614, pg_loss = -18.662, baseline_loss = 32.633, entropy_loss = -5.3571, learner_queue_size = 32, _tick = 37960, _time = 1.6548e+09, train_seconds = 3.6707e+04)
[2022-06-10 06:19:51,995][root][INFO] - Step 140682240 @ 4091.9 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (step = 140682240, mean_episode_return = 72.02, mean_episode_step = 1071.3, total_loss = 80.681, pg_loss = -27.261, baseline_loss = 113.55, entropy_loss = -5.609, learner_queue_size = 32, _tick = 37967, _time = 1.6548e+09, train_seconds = 3.6712e+04)
[2022-06-10 06:19:56,998][root][INFO] - Step 140700160 @ 3581.9 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 140700160, mean_episode_return = 59.53, mean_episode_step = 1006.1, total_loss = -71.97, pg_loss = -124.77, baseline_loss = 58.432, entropy_loss = -5.6324, learner_queue_size = 32, _tick = 37973, _time = 1.6548e+09, train_seconds = 3.6717e+04)
[2022-06-10 06:20:02,002][root][INFO] - Step 140720640 @ 4092.7 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (step = 140720640, mean_episode_return = 92.221, mean_episode_step = 1458.3, total_loss = 118.17, pg_loss = 91.573, baseline_loss = 32.72, entropy_loss = -6.1192, learner_queue_size = 32, _tick = 37981, _time = 1.6548e+09, train_seconds = 3.6722e+04)
[2022-06-10 06:20:07,008][root][INFO] - Step 140741120 @ 4091.1 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (step = 140741120, mean_episode_return = None, mean_episode_step = 1175.3, total_loss = -94.82, pg_loss = -110.81, baseline_loss = 21.741, entropy_loss = -5.7489, learner_queue_size = 32, _tick = 37987, _time = 1.6548e+09, train_seconds = 3.6727e+04)
[2022-06-10 06:20:12,010][root][INFO] - Step 140759040 @ 3582.6 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 140759040, mean_episode_return = None, mean_episode_step = 1099.9, total_loss = 62.801, pg_loss = 23.328, baseline_loss = 45.095, entropy_loss = -5.6221, learner_queue_size = 32, _tick = 37992, _time = 1.6548e+09, train_seconds = 3.6732e+04)
[2022-06-10 06:20:17,014][root][INFO] - Step 140779520 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 140779520, mean_episode_return = 47.17, mean_episode_step = 1193.7, total_loss = -4.6586, pg_loss = -31.696, baseline_loss = 32.718, entropy_loss = -5.68, learner_queue_size = 32, _tick = 37999, _time = 1.6548e+09, train_seconds = 3.6737e+04)
[2022-06-10 06:20:22,018][root][INFO] - Step 140797440 @ 3581.1 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (step = 140797440, mean_episode_return = 186.94, mean_episode_step = 807.48, total_loss = 116.46, pg_loss = 62.561, baseline_loss = 59.718, entropy_loss = -5.8214, learner_queue_size = 32, _tick = 38003, _time = 1.6548e+09, train_seconds = 3.6742e+04)
[2022-06-10 06:20:27,022][root][INFO] - Step 140817920 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 140817920, mean_episode_return = None, mean_episode_step = 880.34, total_loss = -211.66, pg_loss = -223.86, baseline_loss = 17.948, entropy_loss = -5.7474, learner_queue_size = 32, _tick = 38007, _time = 1.6548e+09, train_seconds = 3.6747e+04)
[2022-06-10 06:20:32,026][root][INFO] - Step 140838400 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 140838400, mean_episode_return = 111.79, mean_episode_step = 980.68, total_loss = 17.692, pg_loss = -9.8698, baseline_loss = 33.382, entropy_loss = -5.8195, learner_queue_size = 32, _tick = 38014, _time = 1.6548e+09, train_seconds = 3.6752e+04)
[2022-06-10 06:20:37,030][root][INFO] - Step 140856320 @ 3581.1 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 140856320, mean_episode_return = 52.122, mean_episode_step = 987.0, total_loss = 168.88, pg_loss = 115.79, baseline_loss = 59.084, entropy_loss = -5.9939, learner_queue_size = 32, _tick = 38020, _time = 1.6548e+09, train_seconds = 3.6757e+04)
[2022-06-10 06:20:42,035][root][INFO] - Step 140876800 @ 4092.0 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 140876800, mean_episode_return = 91.755, mean_episode_step = 1246.7, total_loss = 139.91, pg_loss = 58.84, baseline_loss = 87.013, entropy_loss = -5.9439, learner_queue_size = 32, _tick = 38027, _time = 1.6548e+09, train_seconds = 3.6762e+04)
[2022-06-10 06:20:47,040][root][INFO] - Step 140897280 @ 4092.4 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 140897280, mean_episode_return = 72.979, mean_episode_step = 1284.0, total_loss = -7.4404, pg_loss = -28.802, baseline_loss = 27.342, entropy_loss = -5.9806, learner_queue_size = 32, _tick = 38034, _time = 1.6548e+09, train_seconds = 3.6767e+04)
[2022-06-10 06:20:52,042][root][INFO] - Step 140915200 @ 3582.2 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 140915200, mean_episode_return = 90.289, mean_episode_step = 888.3, total_loss = 199.71, pg_loss = 140.32, baseline_loss = 65.243, entropy_loss = -5.8564, learner_queue_size = 32, _tick = 38040, _time = 1.6548e+09, train_seconds = 3.6772e+04)
[2022-06-10 06:20:57,046][root][INFO] - Step 140933120 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 140933120, mean_episode_return = 5.4398, mean_episode_step = 1433.5, total_loss = 47.199, pg_loss = 10.302, baseline_loss = 42.767, entropy_loss = -5.8699, learner_queue_size = 32, _tick = 38046, _time = 1.6548e+09, train_seconds = 3.6777e+04)
[2022-06-10 06:21:02,050][root][INFO] - Step 140953600 @ 4092.7 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 140953600, mean_episode_return = None, mean_episode_step = 1130.5, total_loss = 69.043, pg_loss = 4.1344, baseline_loss = 70.712, entropy_loss = -5.8028, learner_queue_size = 32, _tick = 38051, _time = 1.6548e+09, train_seconds = 3.6782e+04)
[2022-06-10 06:21:07,054][root][INFO] - Step 140974080 @ 4092.7 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 140974080, mean_episode_return = 45.835, mean_episode_step = 841.57, total_loss = -2.9825, pg_loss = -37.349, baseline_loss = 40.051, entropy_loss = -5.6845, learner_queue_size = 32, _tick = 38059, _time = 1.6548e+09, train_seconds = 3.6787e+04)
[2022-06-10 06:21:12,058][root][INFO] - Step 140992000 @ 3581.2 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 140992000, mean_episode_return = 100.01, mean_episode_step = 1823.2, total_loss = -129.11, pg_loss = -168.26, baseline_loss = 44.856, entropy_loss = -5.7147, learner_queue_size = 32, _tick = 38066, _time = 1.6548e+09, train_seconds = 3.6792e+04)
[2022-06-10 06:21:17,062][root][INFO] - Step 141012480 @ 4092.8 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 141012480, mean_episode_return = 73.5, mean_episode_step = 742.36, total_loss = -172.64, pg_loss = -210.36, baseline_loss = 43.298, entropy_loss = -5.5818, learner_queue_size = 32, _tick = 38074, _time = 1.6548e+09, train_seconds = 3.6797e+04)
[2022-06-10 06:21:22,066][root][INFO] - Step 141030400 @ 3580.9 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 141030400, mean_episode_return = 39.11, mean_episode_step = 941.1, total_loss = 71.283, pg_loss = 29.288, baseline_loss = 47.851, entropy_loss = -5.8559, learner_queue_size = 32, _tick = 38079, _time = 1.6548e+09, train_seconds = 3.6802e+04)
[2022-06-10 06:21:27,070][root][INFO] - Step 141050880 @ 4093.0 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (step = 141050880, mean_episode_return = 75.804, mean_episode_step = 1168.6, total_loss = -86.836, pg_loss = -91.767, baseline_loss = 11.134, entropy_loss = -6.2039, learner_queue_size = 32, _tick = 38085, _time = 1.6548e+09, train_seconds = 3.6807e+04)
[2022-06-10 06:21:32,074][root][INFO] - Step 141071360 @ 4092.7 SPS. Inference batcher size: 75. Learner queue size: 32. Other stats: (step = 141071360, mean_episode_return = 115.18, mean_episode_step = 831.44, total_loss = 100.57, pg_loss = 56.252, baseline_loss = 50.422, entropy_loss = -6.0997, learner_queue_size = 32, _tick = 38090, _time = 1.6548e+09, train_seconds = 3.6812e+04)
[2022-06-10 06:21:37,078][root][INFO] - Step 141091840 @ 4092.7 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 141091840, mean_episode_return = 38.272, mean_episode_step = 1030.5, total_loss = 134.78, pg_loss = 88.414, baseline_loss = 52.504, entropy_loss = -6.1386, learner_queue_size = 32, _tick = 38097, _time = 1.6548e+09, train_seconds = 3.6817e+04)
[2022-06-10 06:21:42,082][root][INFO] - Step 141109760 @ 3581.1 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 141109760, mean_episode_return = 15.69, mean_episode_step = 1125.5, total_loss = -152.13, pg_loss = -158.28, baseline_loss = 12.358, entropy_loss = -6.208, learner_queue_size = 32, _tick = 38104, _time = 1.6548e+09, train_seconds = 3.6822e+04)
[2022-06-10 06:21:47,086][root][INFO] - Step 141130240 @ 4092.7 SPS. Inference batcher size: 65. Learner queue size: 32. Other stats: (step = 141130240, mean_episode_return = 44.996, mean_episode_step = 1153.6, total_loss = -22.489, pg_loss = -30.269, baseline_loss = 14.004, entropy_loss = -6.2238, learner_queue_size = 32, _tick = 38111, _time = 1.6548e+09, train_seconds = 3.6827e+04)
[2022-06-10 06:21:52,090][root][INFO] - Step 141150720 @ 4092.8 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 141150720, mean_episode_return = 48.256, mean_episode_step = 867.29, total_loss = -64.894, pg_loss = -93.596, baseline_loss = 34.839, entropy_loss = -6.1363, learner_queue_size = 32, _tick = 38119, _time = 1.6548e+09, train_seconds = 3.6832e+04)
[2022-06-10 06:21:57,094][root][INFO] - Step 141171200 @ 4092.6 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 141171200, mean_episode_return = 70.43, mean_episode_step = 1152.7, total_loss = 477.85, pg_loss = 391.84, baseline_loss = 92.178, entropy_loss = -6.1672, learner_queue_size = 32, _tick = 38126, _time = 1.6548e+09, train_seconds = 3.6837e+04)
[2022-06-10 06:22:02,098][root][INFO] - Step 141189120 @ 3581.2 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 141189120, mean_episode_return = 56.132, mean_episode_step = 777.55, total_loss = 306.26, pg_loss = 216.92, baseline_loss = 95.389, entropy_loss = -6.0508, learner_queue_size = 32, _tick = 38132, _time = 1.6548e+09, train_seconds = 3.6842e+04)
[2022-06-10 06:22:07,102][root][INFO] - Step 141209600 @ 4092.8 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 141209600, mean_episode_return = 22.137, mean_episode_step = 1069.6, total_loss = 19.079, pg_loss = -22.706, baseline_loss = 47.754, entropy_loss = -5.9689, learner_queue_size = 32, _tick = 38138, _time = 1.6548e+09, train_seconds = 3.6847e+04)
[2022-06-10 06:22:12,105][root][INFO] - Step 141227520 @ 3581.8 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 141227520, mean_episode_return = -12.22, mean_episode_step = 919.15, total_loss = 191.68, pg_loss = 151.19, baseline_loss = 46.37, entropy_loss = -5.8817, learner_queue_size = 32, _tick = 38143, _time = 1.6548e+09, train_seconds = 3.6852e+04)
[2022-06-10 06:22:17,110][root][INFO] - Step 141248000 @ 4091.9 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 141248000, mean_episode_return = 55.719, mean_episode_step = 1094.8, total_loss = -192.28, pg_loss = -222.5, baseline_loss = 36.157, entropy_loss = -5.9415, learner_queue_size = 32, _tick = 38149, _time = 1.6548e+09, train_seconds = 3.6857e+04)
[2022-06-10 06:22:22,116][root][INFO] - Step 141265920 @ 3579.6 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 141265920, mean_episode_return = 40.74, mean_episode_step = 1418.0, total_loss = 157.3, pg_loss = 104.78, baseline_loss = 58.519, entropy_loss = -5.9985, learner_queue_size = 32, _tick = 38156, _time = 1.6548e+09, train_seconds = 3.6862e+04)
[2022-06-10 06:22:27,122][root][INFO] - Step 141286400 @ 4091.1 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (step = 141286400, mean_episode_return = 6.2297, mean_episode_step = 1383.2, total_loss = -82.781, pg_loss = -115.65, baseline_loss = 39.021, entropy_loss = -6.1473, learner_queue_size = 32, _tick = 38163, _time = 1.6548e+09, train_seconds = 3.6867e+04)
[2022-06-10 06:22:32,126][root][INFO] - Step 141306880 @ 4092.8 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 141306880, mean_episode_return = 89.511, mean_episode_step = 1052.3, total_loss = -24.028, pg_loss = -57.319, baseline_loss = 39.502, entropy_loss = -6.2102, learner_queue_size = 32, _tick = 38168, _time = 1.6548e+09, train_seconds = 3.6872e+04)
[2022-06-10 06:22:37,130][root][INFO] - Step 141324800 @ 3581.1 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 141324800, mean_episode_return = 54.385, mean_episode_step = 1287.2, total_loss = -97.255, pg_loss = -111.19, baseline_loss = 20.049, entropy_loss = -6.118, learner_queue_size = 32, _tick = 38175, _time = 1.6548e+09, train_seconds = 3.6877e+04)
[2022-06-10 06:22:42,134][root][INFO] - Step 141345280 @ 4092.7 SPS. Inference batcher size: 37. Learner queue size: 32. Other stats: (step = 141345280, mean_episode_return = None, mean_episode_step = 1040.8, total_loss = 163.7, pg_loss = 116.36, baseline_loss = 53.394, entropy_loss = -6.0558, learner_queue_size = 32, _tick = 38180, _time = 1.6548e+09, train_seconds = 3.6882e+04)
[2022-06-10 06:22:47,138][root][INFO] - Step 141363200 @ 3581.1 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (step = 141363200, mean_episode_return = None, mean_episode_step = 1031.5, total_loss = 186.77, pg_loss = 143.59, baseline_loss = 49.147, entropy_loss = -5.9686, learner_queue_size = 32, _tick = 38186, _time = 1.6548e+09, train_seconds = 3.6887e+04)
[2022-06-10 06:22:52,142][root][INFO] - Step 141383680 @ 4092.8 SPS. Inference batcher size: 72. Learner queue size: 32. Other stats: (step = 141383680, mean_episode_return = 35.912, mean_episode_step = 1007.3, total_loss = 23.074, pg_loss = -7.0742, baseline_loss = 36.121, entropy_loss = -5.9734, learner_queue_size = 32, _tick = 38190, _time = 1.6548e+09, train_seconds = 3.6892e+04)
[2022-06-10 06:22:57,147][root][INFO] - Step 141401600 @ 3580.7 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 141401600, mean_episode_return = 65.681, mean_episode_step = 1443.1, total_loss = 128.98, pg_loss = 88.852, baseline_loss = 46.143, entropy_loss = -6.0175, learner_queue_size = 32, _tick = 38196, _time = 1.6548e+09, train_seconds = 3.6897e+04)
[2022-06-10 06:23:02,150][root][INFO] - Step 141416960 @ 3069.9 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (step = 141416960, mean_episode_return = 34.077, mean_episode_step = 1482.3, total_loss = -88.887, pg_loss = -128.0, baseline_loss = 45.018, entropy_loss = -5.9068, learner_queue_size = 32, _tick = 38201, _time = 1.6548e+09, train_seconds = 3.6902e+04)
[2022-06-10 06:23:07,154][root][INFO] - Step 141429760 @ 2557.9 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (step = 141429760, mean_episode_return = 41.36, mean_episode_step = 1355.0, total_loss = 285.42, pg_loss = 224.92, baseline_loss = 66.287, entropy_loss = -5.7851, learner_queue_size = 32, _tick = 38205, _time = 1.6548e+09, train_seconds = 3.6907e+04)
[2022-06-10 06:23:12,158][root][INFO] - Step 141447680 @ 3581.1 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (step = 141447680, mean_episode_return = 89.284, mean_episode_step = 1044.4, total_loss = 148.39, pg_loss = 96.997, baseline_loss = 57.269, entropy_loss = -5.8773, learner_queue_size = 32, _tick = 38209, _time = 1.6548e+09, train_seconds = 3.6912e+04)
[2022-06-10 06:23:17,162][root][INFO] - Step 141468160 @ 4092.7 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 141468160, mean_episode_return = 54.764, mean_episode_step = 880.03, total_loss = 118.86, pg_loss = 47.902, baseline_loss = 76.838, entropy_loss = -5.8778, learner_queue_size = 32, _tick = 38216, _time = 1.6548e+09, train_seconds = 3.6917e+04)
[2022-06-10 06:23:22,166][root][INFO] - Step 141488640 @ 4092.8 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 141488640, mean_episode_return = None, mean_episode_step = 934.62, total_loss = 138.5, pg_loss = 98.39, baseline_loss = 45.805, entropy_loss = -5.6973, learner_queue_size = 32, _tick = 38221, _time = 1.6548e+09, train_seconds = 3.6922e+04)
[2022-06-10 06:23:27,170][root][INFO] - Step 141509120 @ 4092.7 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (step = 141509120, mean_episode_return = 15.369, mean_episode_step = 1581.4, total_loss = -44.802, pg_loss = -57.985, baseline_loss = 19.071, entropy_loss = -5.8874, learner_queue_size = 32, _tick = 38225, _time = 1.6548e+09, train_seconds = 3.6927e+04)
[2022-06-10 06:23:32,174][root][INFO] - Step 141529600 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 141529600, mean_episode_return = 13.88, mean_episode_step = 991.82, total_loss = 198.55, pg_loss = 143.5, baseline_loss = 61.004, entropy_loss = -5.9527, learner_queue_size = 32, _tick = 38232, _time = 1.6548e+09, train_seconds = 3.6932e+04)
[2022-06-10 06:23:37,178][root][INFO] - Step 141547520 @ 3581.1 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 141547520, mean_episode_return = None, mean_episode_step = 913.44, total_loss = -101.94, pg_loss = -117.97, baseline_loss = 21.848, entropy_loss = -5.817, learner_queue_size = 32, _tick = 38237, _time = 1.6548e+09, train_seconds = 3.6937e+04)
[2022-06-10 06:23:42,182][root][INFO] - Step 141565440 @ 3581.1 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (step = 141565440, mean_episode_return = None, mean_episode_step = 870.88, total_loss = 158.97, pg_loss = 105.37, baseline_loss = 59.418, entropy_loss = -5.8135, learner_queue_size = 32, _tick = 38243, _time = 1.6548e+09, train_seconds = 3.6942e+04)
[2022-06-10 06:23:47,186][root][INFO] - Step 141585920 @ 4092.7 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 141585920, mean_episode_return = 63.8, mean_episode_step = 1183.2, total_loss = -37.362, pg_loss = -83.013, baseline_loss = 51.368, entropy_loss = -5.7166, learner_queue_size = 32, _tick = 38250, _time = 1.6548e+09, train_seconds = 3.6947e+04)
[2022-06-10 06:23:52,190][root][INFO] - Step 141603840 @ 3581.2 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 141603840, mean_episode_return = None, mean_episode_step = 1530.2, total_loss = -111.5, pg_loss = -130.69, baseline_loss = 25.028, entropy_loss = -5.84, learner_queue_size = 32, _tick = 38256, _time = 1.6548e+09, train_seconds = 3.6952e+04)
[2022-06-10 06:23:57,194][root][INFO] - Step 141624320 @ 4092.7 SPS. Inference batcher size: 32. Learner queue size: 32. Other stats: (step = 141624320, mean_episode_return = -23.89, mean_episode_step = 1184.0, total_loss = -76.651, pg_loss = -99.748, baseline_loss = 28.794, entropy_loss = -5.6968, learner_queue_size = 32, _tick = 38263, _time = 1.6548e+09, train_seconds = 3.6957e+04)
[2022-06-10 06:24:02,198][root][INFO] - Step 141644800 @ 4092.8 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (step = 141644800, mean_episode_return = 76.31, mean_episode_step = 1139.6, total_loss = 111.17, pg_loss = 60.176, baseline_loss = 56.902, entropy_loss = -5.9081, learner_queue_size = 32, _tick = 38267, _time = 1.6548e+09, train_seconds = 3.6962e+04)
[2022-06-10 06:24:07,202][root][INFO] - Step 141662720 @ 3581.1 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (step = 141662720, mean_episode_return = 67.26, mean_episode_step = 983.52, total_loss = -67.251, pg_loss = -87.783, baseline_loss = 26.378, entropy_loss = -5.846, learner_queue_size = 32, _tick = 38274, _time = 1.6548e+09, train_seconds = 3.6967e+04)
[2022-06-10 06:24:12,206][root][INFO] - Step 141683200 @ 4092.7 SPS. Inference batcher size: 36. Learner queue size: 32. Other stats: (step = 141683200, mean_episode_return = 75.229, mean_episode_step = 951.01, total_loss = -84.46, pg_loss = -114.29, baseline_loss = 35.656, entropy_loss = -5.827, learner_queue_size = 32, _tick = 38281, _time = 1.6548e+09, train_seconds = 3.6972e+04)
[2022-06-10 06:24:17,210][root][INFO] - Step 141703680 @ 4092.8 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (step = 141703680, mean_episode_return = 46.5, mean_episode_step = 962.18, total_loss = 238.78, pg_loss = 209.43, baseline_loss = 35.303, entropy_loss = -5.9549, learner_queue_size = 32, _tick = 38288, _time = 1.6548e+09, train_seconds = 3.6977e+04)
[2022-06-10 06:24:22,214][root][INFO] - Step 141721600 @ 3581.1 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 141721600, mean_episode_return = None, mean_episode_step = 1498.3, total_loss = -97.818, pg_loss = -112.3, baseline_loss = 20.369, entropy_loss = -5.8859, learner_queue_size = 32, _tick = 38294, _time = 1.6548e+09, train_seconds = 3.6982e+04)
[2022-06-10 06:24:27,226][root][INFO] - Step 141742080 @ 4086.1 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 141742080, mean_episode_return = 5.6197, mean_episode_step = 1063.4, total_loss = 80.276, pg_loss = 38.765, baseline_loss = 47.63, entropy_loss = -6.1198, learner_queue_size = 32, _tick = 38302, _time = 1.6548e+09, train_seconds = 3.6987e+04)
[2022-06-10 06:24:32,230][root][INFO] - Step 141762560 @ 4092.9 SPS. Inference batcher size: 43. Learner queue size: 32. Other stats: (step = 141762560, mean_episode_return = 68.526, mean_episode_step = 865.45, total_loss = 40.948, pg_loss = 18.403, baseline_loss = 28.66, entropy_loss = -6.1146, learner_queue_size = 32, _tick = 38310, _time = 1.6548e+09, train_seconds = 3.6992e+04)
[2022-06-10 06:24:37,234][root][INFO] - Step 141780480 @ 3581.1 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 141780480, mean_episode_return = 51.819, mean_episode_step = 1141.7, total_loss = -50.149, pg_loss = -83.122, baseline_loss = 39.079, entropy_loss = -6.1054, learner_queue_size = 32, _tick = 38316, _time = 1.6548e+09, train_seconds = 3.6997e+04)
[2022-06-10 06:24:42,238][root][INFO] - Step 141800960 @ 4092.8 SPS. Inference batcher size: 46. Learner queue size: 32. Other stats: (step = 141800960, mean_episode_return = 19.2, mean_episode_step = 871.51, total_loss = -36.717, pg_loss = -57.93, baseline_loss = 27.071, entropy_loss = -5.8582, learner_queue_size = 32, _tick = 38323, _time = 1.6548e+09, train_seconds = 3.7002e+04)
[2022-06-10 06:24:47,242][root][INFO] - Step 141821440 @ 4092.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 141821440, mean_episode_return = 43.8, mean_episode_step = 875.42, total_loss = 29.347, pg_loss = -19.74, baseline_loss = 54.982, entropy_loss = -5.8953, learner_queue_size = 32, _tick = 38331, _time = 1.6548e+09, train_seconds = 3.7007e+04)
[2022-06-10 06:24:52,246][root][INFO] - Step 141839360 @ 3581.1 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 141839360, mean_episode_return = 45.92, mean_episode_step = 957.35, total_loss = 120.66, pg_loss = 80.465, baseline_loss = 46.254, entropy_loss = -6.0594, learner_queue_size = 32, _tick = 38338, _time = 1.6548e+09, train_seconds = 3.7012e+04)
[2022-06-10 06:24:57,250][root][INFO] - Step 141859840 @ 4092.8 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 141859840, mean_episode_return = 54.516, mean_episode_step = 971.61, total_loss = 33.974, pg_loss = -16.889, baseline_loss = 56.846, entropy_loss = -5.9823, learner_queue_size = 32, _tick = 38346, _time = 1.6548e+09, train_seconds = 3.7017e+04)
[2022-06-10 06:25:02,254][root][INFO] - Step 141877760 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 141877760, mean_episode_return = 63.921, mean_episode_step = 1089.3, total_loss = 172.06, pg_loss = 123.12, baseline_loss = 54.875, entropy_loss = -5.9337, learner_queue_size = 32, _tick = 38353, _time = 1.6548e+09, train_seconds = 3.7022e+04)
[2022-06-10 06:25:07,258][root][INFO] - Step 141898240 @ 4092.7 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (step = 141898240, mean_episode_return = 23.688, mean_episode_step = 635.21, total_loss = -236.59, pg_loss = -244.64, baseline_loss = 13.93, entropy_loss = -5.8804, learner_queue_size = 32, _tick = 38358, _time = 1.6548e+09, train_seconds = 3.7027e+04)
[2022-06-10 06:25:12,264][root][INFO] - Step 141916160 @ 3579.6 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 141916160, mean_episode_return = 75.542, mean_episode_step = 817.09, total_loss = -146.73, pg_loss = -157.28, baseline_loss = 16.622, entropy_loss = -6.0632, learner_queue_size = 32, _tick = 38365, _time = 1.6548e+09, train_seconds = 3.7032e+04)
[2022-06-10 06:25:17,270][root][INFO] - Step 141936640 @ 4091.3 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 141936640, mean_episode_return = None, mean_episode_step = 775.5, total_loss = 59.033, pg_loss = 32.318, baseline_loss = 32.758, entropy_loss = -6.0429, learner_queue_size = 32, _tick = 38372, _time = 1.6548e+09, train_seconds = 3.7037e+04)
[2022-06-10 06:25:22,274][root][INFO] - Step 141957120 @ 4092.7 SPS. Inference batcher size: 69. Learner queue size: 32. Other stats: (step = 141957120, mean_episode_return = 31.694, mean_episode_step = 774.95, total_loss = 201.9, pg_loss = 138.76, baseline_loss = 69.243, entropy_loss = -6.1038, learner_queue_size = 32, _tick = 38377, _time = 1.6548e+09, train_seconds = 3.7042e+04)
[2022-06-10 06:25:27,278][root][INFO] - Step 141977600 @ 4092.8 SPS. Inference batcher size: 56. Learner queue size: 32. Other stats: (step = 141977600, mean_episode_return = 51.426, mean_episode_step = 743.42, total_loss = 133.83, pg_loss = 82.14, baseline_loss = 57.58, entropy_loss = -5.8859, learner_queue_size = 32, _tick = 38384, _time = 1.6548e+09, train_seconds = 3.7047e+04)
[2022-06-10 06:25:32,282][root][INFO] - Step 141995520 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 141995520, mean_episode_return = 60.19, mean_episode_step = 722.19, total_loss = 109.65, pg_loss = 43.932, baseline_loss = 71.599, entropy_loss = -5.8859, learner_queue_size = 32, _tick = 38389, _time = 1.6548e+09, train_seconds = 3.7052e+04)
[2022-06-10 06:25:37,286][root][INFO] - Step 142016000 @ 4092.7 SPS. Inference batcher size: 33. Learner queue size: 32. Other stats: (step = 142016000, mean_episode_return = None, mean_episode_step = 614.56, total_loss = -107.78, pg_loss = -129.37, baseline_loss = 27.323, entropy_loss = -5.7348, learner_queue_size = 32, _tick = 38395, _time = 1.6548e+09, train_seconds = 3.7057e+04)
[2022-06-10 06:25:42,290][root][INFO] - Step 142033920 @ 3581.2 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 142033920, mean_episode_return = 18.63, mean_episode_step = 822.84, total_loss = 190.0, pg_loss = 135.82, baseline_loss = 59.858, entropy_loss = -5.6815, learner_queue_size = 32, _tick = 38402, _time = 1.6548e+09, train_seconds = 3.7062e+04)
[2022-06-10 06:25:47,294][root][INFO] - Step 142054400 @ 4092.7 SPS. Inference batcher size: 50. Learner queue size: 32. Other stats: (step = 142054400, mean_episode_return = 32.43, mean_episode_step = 1452.6, total_loss = 8.6156, pg_loss = -12.723, baseline_loss = 26.914, entropy_loss = -5.5753, learner_queue_size = 32, _tick = 38408, _time = 1.6548e+09, train_seconds = 3.7067e+04)
[2022-06-10 06:25:52,298][root][INFO] - Step 142074880 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 142074880, mean_episode_return = 21.66, mean_episode_step = 903.42, total_loss = 420.52, pg_loss = 259.72, baseline_loss = 165.75, entropy_loss = -4.9378, learner_queue_size = 32, _tick = 38414, _time = 1.6548e+09, train_seconds = 3.7072e+04)
[2022-06-10 06:25:57,302][root][INFO] - Step 142092800 @ 3581.1 SPS. Inference batcher size: 40. Learner queue size: 32. Other stats: (step = 142092800, mean_episode_return = 34.331, mean_episode_step = 814.98, total_loss = 131.9, pg_loss = 37.134, baseline_loss = 99.968, entropy_loss = -5.2055, learner_queue_size = 32, _tick = 38418, _time = 1.6548e+09, train_seconds = 3.7077e+04)
[2022-06-10 06:26:02,306][root][INFO] - Step 142113280 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 142113280, mean_episode_return = None, mean_episode_step = 1015.3, total_loss = 133.14, pg_loss = 88.299, baseline_loss = 50.495, entropy_loss = -5.6579, learner_queue_size = 32, _tick = 38424, _time = 1.6548e+09, train_seconds = 3.7082e+04)
[2022-06-10 06:26:07,310][root][INFO] - Step 142133760 @ 4092.7 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 142133760, mean_episode_return = None, mean_episode_step = 1060.8, total_loss = 237.77, pg_loss = 183.01, baseline_loss = 60.686, entropy_loss = -5.9331, learner_queue_size = 32, _tick = 38430, _time = 1.6548e+09, train_seconds = 3.7087e+04)
[2022-06-10 06:26:12,314][root][INFO] - Step 142154240 @ 4092.7 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 142154240, mean_episode_return = 53.687, mean_episode_step = 1467.8, total_loss = 531.25, pg_loss = 372.01, baseline_loss = 165.06, entropy_loss = -5.8197, learner_queue_size = 32, _tick = 38436, _time = 1.6548e+09, train_seconds = 3.7092e+04)
[2022-06-10 06:26:17,318][root][INFO] - Step 142172160 @ 3581.2 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (step = 142172160, mean_episode_return = 51.014, mean_episode_step = 892.89, total_loss = -57.749, pg_loss = -78.307, baseline_loss = 26.212, entropy_loss = -5.6541, learner_queue_size = 32, _tick = 38442, _time = 1.6548e+09, train_seconds = 3.7097e+04)
[2022-06-10 06:26:22,322][root][INFO] - Step 142192640 @ 4092.7 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (step = 142192640, mean_episode_return = 108.58, mean_episode_step = 1024.5, total_loss = 133.24, pg_loss = 82.852, baseline_loss = 56.139, entropy_loss = -5.7512, learner_queue_size = 32, _tick = 38450, _time = 1.6548e+09, train_seconds = 3.7102e+04)
[2022-06-10 06:26:27,326][root][INFO] - Step 142213120 @ 4092.7 SPS. Inference batcher size: 64. Learner queue size: 32. Other stats: (step = 142213120, mean_episode_return = 29.6, mean_episode_step = 837.25, total_loss = 158.2, pg_loss = 102.12, baseline_loss = 61.629, entropy_loss = -5.5462, learner_queue_size = 32, _tick = 38458, _time = 1.6548e+09, train_seconds = 3.7107e+04)
[2022-06-10 06:26:32,330][root][INFO] - Step 142231040 @ 3581.2 SPS. Inference batcher size: 38. Learner queue size: 32. Other stats: (step = 142231040, mean_episode_return = 11.29, mean_episode_step = 1073.4, total_loss = 217.46, pg_loss = 169.41, baseline_loss = 53.792, entropy_loss = -5.7332, learner_queue_size = 32, _tick = 38463, _time = 1.6548e+09, train_seconds = 3.7112e+04)
[2022-06-10 06:26:37,334][root][INFO] - Step 142251520 @ 4092.6 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 142251520, mean_episode_return = 60.522, mean_episode_step = 669.95, total_loss = 632.31, pg_loss = 485.14, baseline_loss = 152.81, entropy_loss = -5.6414, learner_queue_size = 32, _tick = 38470, _time = 1.6548e+09, train_seconds = 3.7117e+04)
[2022-06-10 06:26:42,338][root][INFO] - Step 142272000 @ 4092.8 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (step = 142272000, mean_episode_return = 32.582, mean_episode_step = 977.77, total_loss = 34.621, pg_loss = -8.9648, baseline_loss = 49.266, entropy_loss = -5.6803, learner_queue_size = 32, _tick = 38476, _time = 1.6548e+09, train_seconds = 3.7122e+04)
[2022-06-10 06:26:47,342][root][INFO] - Step 142289920 @ 3581.1 SPS. Inference batcher size: 57. Learner queue size: 32. Other stats: (step = 142289920, mean_episode_return = 26.212, mean_episode_step = 728.78, total_loss = -123.58, pg_loss = -143.31, baseline_loss = 25.147, entropy_loss = -5.4173, learner_queue_size = 32, _tick = 38481, _time = 1.6548e+09, train_seconds = 3.7127e+04)
[2022-06-10 06:26:52,346][root][INFO] - Step 142310400 @ 4092.8 SPS. Inference batcher size: 53. Learner queue size: 32. Other stats: (step = 142310400, mean_episode_return = 64.465, mean_episode_step = 813.43, total_loss = -166.01, pg_loss = -213.6, baseline_loss = 53.032, entropy_loss = -5.4344, learner_queue_size = 32, _tick = 38486, _time = 1.6548e+09, train_seconds = 3.7132e+04)
[2022-06-10 06:26:57,350][root][INFO] - Step 142328320 @ 3581.1 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 142328320, mean_episode_return = None, mean_episode_step = 813.84, total_loss = 59.056, pg_loss = 13.285, baseline_loss = 51.017, entropy_loss = -5.2455, learner_queue_size = 32, _tick = 38492, _time = 1.6548e+09, train_seconds = 3.7137e+04)
[2022-06-10 06:27:02,357][root][INFO] - Step 142348800 @ 4090.3 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 142348800, mean_episode_return = None, mean_episode_step = 583.56, total_loss = 346.83, pg_loss = 277.47, baseline_loss = 74.813, entropy_loss = -5.4592, learner_queue_size = 32, _tick = 38499, _time = 1.6548e+09, train_seconds = 3.7142e+04)
[2022-06-10 06:27:07,362][root][INFO] - Step 142369280 @ 4091.9 SPS. Inference batcher size: 75. Learner queue size: 32. Other stats: (step = 142369280, mean_episode_return = 115.72, mean_episode_step = 780.47, total_loss = 125.76, pg_loss = 27.753, baseline_loss = 103.74, entropy_loss = -5.7311, learner_queue_size = 32, _tick = 38507, _time = 1.6548e+09, train_seconds = 3.7147e+04)
[2022-06-10 06:27:12,368][root][INFO] - Step 142387200 @ 3580.0 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (step = 142387200, mean_episode_return = 59.984, mean_episode_step = 945.09, total_loss = 309.33, pg_loss = 239.84, baseline_loss = 74.887, entropy_loss = -5.3895, learner_queue_size = 32, _tick = 38514, _time = 1.6548e+09, train_seconds = 3.7152e+04)
[2022-06-10 06:27:17,374][root][INFO] - Step 142405120 @ 3579.7 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 142405120, mean_episode_return = 35.98, mean_episode_step = 948.86, total_loss = -95.171, pg_loss = -116.12, baseline_loss = 26.697, entropy_loss = -5.7491, learner_queue_size = 32, _tick = 38519, _time = 1.6548e+09, train_seconds = 3.7157e+04)
[2022-06-10 06:27:22,378][root][INFO] - Step 142425600 @ 4092.5 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 142425600, mean_episode_return = None, mean_episode_step = 927.91, total_loss = 49.485, pg_loss = 26.298, baseline_loss = 29.191, entropy_loss = -6.0038, learner_queue_size = 32, _tick = 38525, _time = 1.6548e+09, train_seconds = 3.7162e+04)
[2022-06-10 06:27:27,382][root][INFO] - Step 142443520 @ 3581.1 SPS. Inference batcher size: 30. Learner queue size: 32. Other stats: (step = 142443520, mean_episode_return = 55.54, mean_episode_step = 671.87, total_loss = 273.04, pg_loss = 224.85, baseline_loss = 53.907, entropy_loss = -5.7097, learner_queue_size = 32, _tick = 38531, _time = 1.6548e+09, train_seconds = 3.7167e+04)
[2022-06-10 06:27:32,386][root][INFO] - Step 142464000 @ 4092.7 SPS. Inference batcher size: 52. Learner queue size: 32. Other stats: (step = 142464000, mean_episode_return = 13.095, mean_episode_step = 869.28, total_loss = 66.624, pg_loss = 34.377, baseline_loss = 38.06, entropy_loss = -5.8125, learner_queue_size = 32, _tick = 38538, _time = 1.6548e+09, train_seconds = 3.7172e+04)
[2022-06-10 06:27:37,390][root][INFO] - Step 142484480 @ 4092.8 SPS. Inference batcher size: 47. Learner queue size: 32. Other stats: (step = 142484480, mean_episode_return = None, mean_episode_step = 1070.9, total_loss = -126.06, pg_loss = -163.7, baseline_loss = 43.516, entropy_loss = -5.8726, learner_queue_size = 32, _tick = 38543, _time = 1.6548e+09, train_seconds = 3.7177e+04)
[2022-06-10 06:27:42,394][root][INFO] - Step 142504960 @ 4092.7 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (step = 142504960, mean_episode_return = None, mean_episode_step = 1157.7, total_loss = 663.66, pg_loss = 290.34, baseline_loss = 379.09, entropy_loss = -5.7712, learner_queue_size = 32, _tick = 38550, _time = 1.6548e+09, train_seconds = 3.7182e+04)
[2022-06-10 06:27:47,398][root][INFO] - Step 142522880 @ 3581.2 SPS. Inference batcher size: 51. Learner queue size: 32. Other stats: (step = 142522880, mean_episode_return = 82.925, mean_episode_step = 1048.0, total_loss = 114.32, pg_loss = 69.236, baseline_loss = 50.971, entropy_loss = -5.8892, learner_queue_size = 32, _tick = 38557, _time = 1.6548e+09, train_seconds = 3.7187e+04)
[2022-06-10 06:27:52,402][root][INFO] - Step 142543360 @ 4092.7 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (step = 142543360, mean_episode_return = 110.66, mean_episode_step = 931.45, total_loss = 11.932, pg_loss = -29.133, baseline_loss = 46.874, entropy_loss = -5.8093, learner_queue_size = 32, _tick = 38565, _time = 1.6548e+09, train_seconds = 3.7192e+04)
[2022-06-10 06:27:57,406][root][INFO] - Step 142561280 @ 3581.1 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 142561280, mean_episode_return = None, mean_episode_step = 982.75, total_loss = 157.55, pg_loss = 127.5, baseline_loss = 35.857, entropy_loss = -5.8048, learner_queue_size = 32, _tick = 38568, _time = 1.6548e+09, train_seconds = 3.7197e+04)
[2022-06-10 06:28:02,410][root][INFO] - Step 142581760 @ 4092.7 SPS. Inference batcher size: 54. Learner queue size: 32. Other stats: (step = 142581760, mean_episode_return = 92.91, mean_episode_step = 1084.5, total_loss = 102.09, pg_loss = 49.621, baseline_loss = 58.335, entropy_loss = -5.8657, learner_queue_size = 32, _tick = 38576, _time = 1.6548e+09, train_seconds = 3.7202e+04)
[2022-06-10 06:28:07,414][root][INFO] - Step 142602240 @ 4092.5 SPS. Inference batcher size: 42. Learner queue size: 32. Other stats: (step = 142602240, mean_episode_return = 26.27, mean_episode_step = 908.64, total_loss = 167.53, pg_loss = 128.95, baseline_loss = 44.474, entropy_loss = -5.8934, learner_queue_size = 32, _tick = 38581, _time = 1.6548e+09, train_seconds = 3.7207e+04)
[2022-06-10 06:28:12,418][root][INFO] - Step 142620160 @ 3581.3 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (step = 142620160, mean_episode_return = 72.066, mean_episode_step = 844.79, total_loss = -151.03, pg_loss = -186.81, baseline_loss = 41.627, entropy_loss = -5.8536, learner_queue_size = 32, _tick = 38587, _time = 1.6548e+09, train_seconds = 3.7212e+04)
[2022-06-10 06:28:17,422][root][INFO] - Step 142640640 @ 4092.2 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 142640640, mean_episode_return = None, mean_episode_step = 990.88, total_loss = -93.813, pg_loss = -105.24, baseline_loss = 17.372, entropy_loss = -5.9475, learner_queue_size = 32, _tick = 38594, _time = 1.6548e+09, train_seconds = 3.7217e+04)
[2022-06-10 06:28:22,426][root][INFO] - Step 142658560 @ 3581.6 SPS. Inference batcher size: 55. Learner queue size: 32. Other stats: (step = 142658560, mean_episode_return = 47.225, mean_episode_step = 864.82, total_loss = -16.247, pg_loss = -47.07, baseline_loss = 36.829, entropy_loss = -6.0059, learner_queue_size = 32, _tick = 38600, _time = 1.6548e+09, train_seconds = 3.7222e+04)
[2022-06-10 06:28:27,430][root][INFO] - Step 142679040 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 142679040, mean_episode_return = None, mean_episode_step = 870.34, total_loss = 99.341, pg_loss = 58.283, baseline_loss = 47.19, entropy_loss = -6.1322, learner_queue_size = 32, _tick = 38607, _time = 1.6548e+09, train_seconds = 3.7227e+04)
[2022-06-10 06:28:32,434][root][INFO] - Step 142696960 @ 3581.2 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (step = 142696960, mean_episode_return = 33.118, mean_episode_step = 913.81, total_loss = -58.234, pg_loss = -76.073, baseline_loss = 24.053, entropy_loss = -6.2137, learner_queue_size = 32, _tick = 38612, _time = 1.6548e+09, train_seconds = 3.7232e+04)
[2022-06-10 06:28:37,438][root][INFO] - Step 142717440 @ 4092.7 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (step = 142717440, mean_episode_return = 78.09, mean_episode_step = 949.97, total_loss = -173.47, pg_loss = -181.07, baseline_loss = 13.805, entropy_loss = -6.2097, learner_queue_size = 32, _tick = 38620, _time = 1.6548e+09, train_seconds = 3.7237e+04)
[2022-06-10 06:28:42,442][root][INFO] - Saving checkpoint to /home/jaelee/nethack/version_euiyulsong/neurips-2021-the-nethack-challenge2/nethack_baselines/torchbeast/outputs/2022-06-09/20-07-51/checkpoint.tar
[2022-06-10 06:28:42,678][root][INFO] - Step 142735360 @ 3581.2 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (step = 142737920, mean_episode_return = None, mean_episode_step = 812.56, total_loss = 125.57, pg_loss = 95.534, baseline_loss = 36.33, entropy_loss = -6.2916, learner_queue_size = 32, _tick = 38627, _time = 1.6548e+09, train_seconds = 3.7242e+04)
[2022-06-10 06:28:47,682][root][INFO] - Step 142755840 @ 3908.4 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 142755840, mean_episode_return = 68.987, mean_episode_step = 1326.9, total_loss = 56.509, pg_loss = 34.815, baseline_loss = 27.822, entropy_loss = -6.1284, learner_queue_size = 32, _tick = 38633, _time = 1.6548e+09, train_seconds = 3.7248e+04)
[2022-06-10 06:28:52,686][root][INFO] - Step 142776320 @ 4092.7 SPS. Inference batcher size: 58. Learner queue size: 32. Other stats: (step = 142776320, mean_episode_return = None, mean_episode_step = 915.34, total_loss = 139.7, pg_loss = 108.24, baseline_loss = 37.697, entropy_loss = -6.2337, learner_queue_size = 32, _tick = 38639, _time = 1.6548e+09, train_seconds = 3.7252e+04)
[2022-06-10 06:28:57,691][root][INFO] - Step 142796800 @ 4091.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (step = 142796800, mean_episode_return = 31.907, mean_episode_step = 827.13, total_loss = 86.035, pg_loss = 38.131, baseline_loss = 53.973, entropy_loss = -6.0701, learner_queue_size = 32, _tick = 38646, _time = 1.6548e+09, train_seconds = 3.7258e+04)
[2022-06-10 06:29:02,694][root][INFO] - Step 142814720 @ 3582.3 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (step = 142814720, mean_episode_return = None, mean_episode_step = 1272.1, total_loss = 364.87, pg_loss = 293.98, baseline_loss = 77.032, entropy_loss = -6.1478, learner_queue_size = 32, _tick = 38650, _time = 1.6548e+09, train_seconds = 3.7262e+04)
[2022-06-10 06:29:07,698][root][INFO] - Step 142835200 @ 4092.7 SPS. Inference batcher size: 4